<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="526cee55e2936716b5481f8a933bd217" category="inline-link-macro">如何在 NetApp 和 VMware Tanzu Basic 中使用 VVOL ，第 1 部分</block>
  <block id="c2240101c5a3a188541ce87c59265df9" category="list-text"><block ref="c2240101c5a3a188541ce87c59265df9" category="inline-link-macro-rx"></block></block>
  <block id="2e933c421900ce4ed68883bfdf00a487" category="inline-link-macro">如何在 NetApp 和 VMware Tanzu Basic 中使用 VVOL ，第 2 部分</block>
  <block id="fe72963b1d3021a9f6d8ae34414601c3" category="list-text"><block ref="fe72963b1d3021a9f6d8ae34414601c3" category="inline-link-macro-rx"></block></block>
  <block id="4c1c4ad5c7782eafb30ad4704dbf4419" category="inline-link-macro">如何在 NetApp 和 VMware Tanzu Basic 中使用 VVOL ，第 3 部分</block>
  <block id="4d066173d8401c92a19650e99dcaae5d" category="list-text"><block ref="4d066173d8401c92a19650e99dcaae5d" category="inline-link-macro-rx"></block></block>
  <block id="c232cfc0ae9806d3ad6d34a51df58229" category="section-title">采用 NetApp 技术的 Red Hat OpenShift</block>
  <block id="3699cb747ce71b2fed488fef61ad35be" category="inline-link-macro">工作负载迁移—采用 NetApp 的 Red Hat OpenShift</block>
  <block id="750b570f7c6cacf7b9f43c1c7919ad96" category="inline-link-macro">有关 thePub 的 AI 博客</block>
  <block id="183754618306c7f8d7df04f981d234f0" category="list-text"><block ref="183754618306c7f8d7df04f981d234f0" category="inline-link-macro-rx"></block></block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="1cf7e301510c711b73d2b182b9dcf084" category="doc">用例</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">错误：缺少图形映像</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">此处</block>
  <block id="be5acbec67071810913f6782071a73eb" category="section-title">存储设计</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">架构</block>
  <block id="9a50201aa3bf66a7a0337ccf29d20c90" category="section-title">解决方案技术</block>
  <block id="2b0d957e4ad1bdfd446155ff5bb8a9b2" category="section-title">架构图</block>
  <block id="b831e128b8fd177e9c80396ed741b7c1" category="section-title">硬件和软件要求</block>
  <block id="a623a8d0366bf079411aa30be45b2d10" category="section-title">计算</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">硬件</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">型号</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">数量</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">软件</block>
  <block id="261addf78c7b2c961032b3dd08ba0b1f" category="cell">目的</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">version</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="cell">虚拟化</block>
  <block id="c73bbd3786350b0a8d3577d82afdf489" category="cell">Red Hat Enterprise Linux</block>
  <block id="80e910f35b12e9c61335fa88de36edd0" category="cell">Red Hat 虚拟化</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="section-title">存储</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4.</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2.</block>
  <block id="fcda5b98e8c212807dc088477e802757" category="cell">NetApp Element</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="3a3a5cd068731551120f43f37950768b" category="cell">ONTAP Select</block>
  <block id="f82f50748d06cc9643330a4a8297ba43" category="cell">9.7</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="section-title">网络</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3.</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">从何处查找追加信息</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">要了解有关本文档中所述信息的更多信息，请查看以下文档和 / 或网站：</block>
  <block id="8887a9a417a1629326acdb917d224337" category="list-text">VMware vSphere</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="list-text">NetApp 互操作性表工具</block>
  <block id="930dd6e7cbd550494f96b487d9d38ec8" category="section-title">硬件要求</block>
  <block id="9d273bd32c1fceb91b7d6a4d40e98bdd" category="section-title">软件要求</block>
  <block id="d9ae1ecd6158beb6acd24c9f59d0498e" category="paragraph">下表列出了实施解决方案所需的软件组件。在任何解决方案实施中使用的软件组件可能会因客户要求而异。</block>
  <block id="0cdff7d38ef496f6b5510c5034fedf15" category="list-text">具有性能保证的多租户</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="section-title">技术概述</block>
  <block id="16600c3602f9acbaa2286f34135f6bb8" category="paragraph">通过 NetApp Element 软件集群，可以按卷动态配置 QoS 。您可以使用每个卷的 QoS 设置根据定义的 SLA 控制存储性能。以下三个可配置参数用于定义 QoS ：</block>
  <block id="d91a826908d0c27cf5d21d2152292ab0" category="list-text">* 最小 IOPS* 。 NetApp Element 软件集群为卷提供的最小可持续 IOPS 数。为卷配置的最小 IOPS 是卷的性能保证级别。每个卷的性能不会低于此级别。</block>
  <block id="827b5871d6ce8f2203a567ef3024f072" category="list-text">* 突发 IOPS 。 * 在短时突发情形下允许的最大 IOPS 数。突发持续时间设置是可配置的，默认值为 1 分钟。如果卷运行的 IOPS 低于最大 IOPS 级别，则会累积突发额度。如果性能级别变得非常高并不断推送，则允许卷上的 IOPS 短时突发超过最大 IOPS 。</block>
  <block id="e95bb6f1e85d1ffe0eb983fd5e0fbde8" category="section-title">多租户</block>
  <block id="086d1eacd91102f734387f0266326344" category="paragraph">可通过以下功能实现安全多租户：</block>
  <block id="78712bd6b2d8e5531e122b5e849fb842" category="paragraph">NetApp Element 软件集群可提高整体存储效率和性能。以下功能是实时执行的，始终开启的，无需用户手动配置：</block>
  <block id="7adf04762320f012179ffe68fb0aeb9f" category="paragraph">RHV 具有以下功能：</block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">摘要</block>
  <block id="87495e311a3944910e3cc0c7bee3d754" category="cell">VLAN</block>
  <block id="b7dff125c9fce628900142990708436f" category="cell">带外管理网络</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16.</block>
  <block id="7b9993fac4b9a60605aa2884eb40f4a3" category="cell">带内管理网络</block>
  <block id="36a1694bce9815b7e38a9dad05ad42e0" category="cell">1172.</block>
  <block id="cd3718e8610b820344c9a0284fe84f90" category="cell">存储网络</block>
  <block id="21c5bba1dd6aed9ab48c2b34c1a0adde" category="cell">3343</block>
  <block id="3de18ffc25309bd0755d8543a30ded78" category="cell">迁移网络</block>
  <block id="38a77aa456fc813af07bb428f2363c8d" category="cell">3345</block>
  <block id="9335616a8b7dc0e6f94fd0c6aa720efe" category="list-text">至少一个 DNS 服务器，提供可从带内管理网络和 VM 网络访问的完整主机名解析。</block>
  <block id="905a394004d9055ec4708e53880cac66" category="list-text">至少可从带内管理网络和 VM 网络访问一个 NTP 服务器。</block>
  <block id="729d72c073b607d370c067152cc53a10" category="doc">验证结果</block>
  <block id="1b21b0d71706897b69f108572c444d40" category="cell">虚拟机管理程序</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">不适用</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="doc">概述</block>
  <block id="1ddf333c6654f7f89c739dddfb4cc429" category="section-title">应用程序</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">前提条件</block>
  <block id="794df3791a8c800841516007427a2aa3" category="section-title">许可证</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="section-title">部署</block>
  <block id="65cd53ff19e601ea00bf9688be4dd86a" category="summary">借助 NetApp ONTAP 实现 Red Hat OpenShift 虚拟化</block>
  <block id="ad3a2e9007d848afd0c15ffc402781bb" category="doc">工作流：使用 NetApp ONTAP 实现 Red Hat OpenShift 虚拟化</block>
  <block id="55c7e45b50d0b012faf4bce31b6ad05d" category="section-title">从 Snapshot 创建 VM</block>
  <block id="f991e1a54e399d272c7d968dcdfdb690" category="paragraph">对于 OpenShift 中的 Snapshot 操作，必须定义资源 VolumeSnapshotClass ， VolumeSnapshot 和 VolumeSnapshotContent 。</block>
  <block id="0e2d1628ef03c4400cd293c3143cabb3" category="list-text">VolumeSnapshotContent 是从集群中的卷生成的实际快照。它是一种集群范围的资源，类似于用于存储的 PersistentVolume 。</block>
  <block id="8ca4876558d3675f7a3e2c452c62a215" category="list-text">VolumeSnapshot 是指创建卷快照的请求。它类似于 PersistentVolumeClaim 。</block>
  <block id="7f9fbed02a61699d31f7d9a0eb11bc81" category="list-text">管理员可以使用 VolumeSnapshotClass 为 VolumeSnapshot 指定不同的属性。通过此选项，您可以为从同一卷创建的不同快照设置不同的属性。</block>
  <block id="7f7858938c48bb9f08341c0e41c9162d" category="image-alt">Snapshot 架构中的 VM</block>
  <block id="99bf6e1ad41f7875d5b7ec9f857c4f0f" category="paragraph">要创建虚拟机的 Snapshot ，请完成以下步骤：</block>
  <block id="52f0977d1e65469f01e2f290e637a8f1" category="list-text">输入 Snapshot 类的名称，输入驱动程序的 csi.trident.netapp.io ，然后单击创建。</block>
  <block id="508073b07367d898823f1841627451d4" category="image-alt">创建 Snapshot 类</block>
  <block id="2bde7e02152796551174ea391bda0b60" category="list-text">确定连接到源 VM 的 PVC ，然后创建该 PVC 的 Snapshot 。导航到 `Storage &gt; VolumeSnapshots` ，然后单击 Create VolumeSnapshots 。</block>
  <block id="b9513caba1fba7b4291a9e22bc512de5" category="list-text">选择要为其创建 Snapshot 的 PVC ，输入 Snapshot 的名称或接受默认值，然后选择相应的 VolumeSnapshotClass 。然后单击创建。</block>
  <block id="a7a384e6f13cae2ef877b4dd78fd48ad" category="image-alt">创建快照</block>
  <block id="d8ae3e40f0f0dba0b7c7ba5b8eea845a" category="list-text">此时将创建 PVC 的快照。</block>
  <block id="e9b3b34ca8f917d1968a106e682f1a97" category="section-title">从快照创建新虚拟机</block>
  <block id="5160cd070df38f982551c5fea6f1c844" category="list-text">输入新 PVC 的详细信息，然后单击还原。这样就会创建一个新的 PVC 。</block>
  <block id="0d695454ca10516a832452b6123c5bb5" category="image-alt">将 Snapshot 还原到新的 PVC</block>
  <block id="75b0d3500d81c7799a5b84eca57d6d04" category="list-text">单击创建以创建新虚拟机。</block>
  <block id="57dc3c96f32e4895e89eab4a248088f5" category="list-text">成功创建虚拟机后，访问并验证新虚拟机的状态是否与创建快照时使用 PVC 创建快照的虚拟机的状态相同。</block>
  <block id="a4957cf974ce20219897bbbf5b131cb8" category="paragraph">管理员可以根据项目需求和存储系统型号配置多个存储后端，以实现高级存储功能，包括数据压缩，特定磁盘类型或 QoS 级别，以保证一定水平的性能。定义后，开发人员可以在其项目中使用这些后端创建永久性卷声明（ PVC ），并按需将永久性存储附加到容器。</block>
  <block id="ecfb2402c181e98da49a5d763378b116" category="paragraph"><block ref="ecfb2402c181e98da49a5d763378b116" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b62bb4786ef52ad76706950add6991dd" category="paragraph">从 20.04 版开始， Trident 设置由 Trident 操作员执行。操作员可以简化大规模部署，并为在 Trident 安装过程中部署的 Pod 提供额外的支持，包括自我修复。</block>
  <block id="4a85fdd5a26454abc330a5ec2a46a326" category="paragraph">在 21.01 版中，我们提供了一个 Helm 图表，用于简化 Trident 操作员的安装。</block>
  <block id="f95d0437e813349fa018b7f0e68e9a7d" category="paragraph">要在已部署的用户集群上安装 Trident 并配置永久性卷，请完成以下步骤：</block>
  <block id="422269f9bb560b76869cbd586b8370d5" category="list-text">从下载的软件包中提取 Trident 安装。</block>
  <block id="52d012c119e8e080d08f6a1592f8f9ec" category="section-title">使用 Helm 安装 Trident 操作员</block>
  <block id="68602d0447fae81afa9d0528ef0c6420" category="list-text">首先将用户集群的 `kubeconfig` 文件的位置设置为环境变量，以便您不必引用该文件，因为 Trident 没有传递此文件的选项。</block>
  <block id="449774824d889f1d6ebc0bbcc4920493" category="list-text">在用户集群中创建 Trident 命名空间时，运行 Helm 命令从 Helm 目录中的 tarball 安装 Trident 操作员。</block>
  <block id="64e437a845e5de3c8e50925ebdfce295" category="list-text">您可以通过检查命名空间中运行的 Pod 或使用 tridentctl 二进制文件检查已安装的版本来验证 Trident 是否已成功安装。</block>
  <block id="3ce67d5de6974f67e0048e6fdbf89498" category="admonition">在某些情况下，客户环境可能需要自定义 Trident 部署。在这种情况下，还可以手动安装 Trident 操作员并更新所包含的清单以自定义部署。</block>
  <block id="8bd534d3b6bc8d2541df052e053ed65d" category="section-title">手动安装 Trident 操作员</block>
  <block id="1315b42a551dafb715ab654d8eb5af40" category="list-text">首先，将用户集群的 `kubeconfig` 文件的位置设置为环境变量，以便您不必引用该文件，因为 Trident 没有传递此文件的选项。</block>
  <block id="5d710ec7d521df428edd75c1885ee89b" category="list-text">`trident 安装程序` 目录包含用于定义所有所需资源的清单。使用适当的清单创建 `TridentOrchestrator` 自定义资源定义。</block>
  <block id="0ac11186fb38b2e9d4acd38d03f61b5c" category="list-text">如果不存在 Trident 命名空间，请使用提供的清单在集群中创建一个 Trident 命名空间。</block>
  <block id="004c51fe71b5c654f88a31270ec6c8e9" category="list-text">为 Trident 操作员部署创建所需的资源，例如为操作员创建 `ServiceAccount` ，为 `SClusterRole` 和 `ClusterRoleBinding` ，为` erviceAccount `，专用` PodSecurityPolicy `或操作员本身创建。</block>
  <block id="f7b9c678b684e969a3ee5ac971514f48" category="list-text">您可以使用以下命令在操作员部署后检查其状态：</block>
  <block id="b34dd67c198ad4cf0088bd29c7ef4658" category="list-text">部署操作员后，我们现在可以使用它来安装 Trident 。这需要创建 `TridentOrchestrator` 。</block>
  <block id="e32d70a13ba1767d9a373fe9a0535531" category="section-title">准备工作节点以进行存储</block>
  <block id="4b4d60be85b0c53c72ae4b8a05deacef" category="paragraph">大多数 Kubernetes 分发软件包和实用程序都会随附用于挂载默认安装的 NFS 后端的软件包和实用程序，包括 Red Hat OpenShift 。</block>
  <block id="693642fbb464db49c22715a536e99c3f" category="paragraph">要使工作节点做好准备，以便能够通过 iSCSI 协议映射块存储卷，您必须安装支持此功能所需的软件包。</block>
  <block id="cccb85b5e6a9a19187087f71254d1fb2" category="paragraph">在 Red Hat OpenShift 中，可通过在部署集群后将 MCO （计算机配置操作员）应用于集群来实现此目的。</block>
  <block id="7b8e6ef8272a81ebcc108ee3fcf4eac8" category="list-text">登录到 OCP Web 控制台并导航到 Compute &gt; Machine Configs 。单击 Create Machine Config 。复制并粘贴 YAML 文件，然后单击创建。</block>
  <block id="c25282bfd8c140d1f79c25362637f744" category="paragraph">不使用多路径时：</block>
  <block id="541c76e8762c84e3e0488f91c8062e08" category="paragraph">使用多路径时：</block>
  <block id="d9f036d3b9f84b626f8a777480066cab" category="list-text">创建配置后，将此配置应用于工作节点并重新加载它们大约需要 20 到 30 分钟。使用 `oc get MCP` 验证是否应用了计算机配置，并确保已更新员工的计算机配置池。您还可以登录到工作节点，以确认 iscsid 服务正在运行（如果使用多路径，则 multipathd 服务正在运行）。</block>
  <block id="6e16409ed6038c106c7fa1dfbfb9da0f" category="admonition">此外，还可以通过使用适当的标志运行 `oc debug` 命令来确认 MachineConfig 已成功应用且服务已按预期启动。</block>
  <block id="b09d268106fd9cbfffd1dc848382a150" category="section-title">创建存储系统后端</block>
  <block id="615767b52353571ac174e22f1a984aa3" category="inline-link-macro">NetApp ONTAP NFS</block>
  <block id="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="list-text"><block ref="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="inline-link-macro-rx"></block></block>
  <block id="c93e7ef2934826b1393251e9f7d9e331" category="inline-link-macro">NetApp ONTAP iSCSI</block>
  <block id="d7b539d4bc16fbdf1477adddfda6c802" category="list-text"><block ref="d7b539d4bc16fbdf1477adddfda6c802" category="inline-link-macro-rx"></block></block>
  <block id="d0e0904111acb167badbf5f196ad1205" category="inline-link-macro">NetApp Element iSCSI</block>
  <block id="2e5d36490241211379006b7f6934bf06" category="list-text"><block ref="2e5d36490241211379006b7f6934bf06" category="inline-link-macro-rx"></block></block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">解决方案概述</block>
  <block id="13a74472f5a5018f40319d30a728d03e" category="paragraph">NetApp ONTAP 是一款功能强大的存储软件工具，具有直观的图形用户界面，具有自动化集成功能的 REST API ，基于 AI 的预测性分析和更正操作，无中断硬件升级和跨存储导入等功能。</block>
  <block id="3716516b242be48f15f8cbce6557a296" category="paragraph">ONTAP 提供以下功能：</block>
  <block id="3e23168685787e9deffccb3bdb29d98a" category="list-text">一个统一存储系统，可同时访问和管理 NFS ， CIFS ， iSCSI ， FC ， FCoE ， 和 FC-NVMe 协议。</block>
  <block id="11927aa24f71bc959d85115c8dd8c3a9" category="list-text">不同的部署模式包括内部全闪存，混合和全 HDD 硬件配置；基于 VM 的存储平台位于受支持的虚拟机管理程序（如 ONTAP Select ）上；云端为 Cloud Volumes ONTAP 。</block>
  <block id="65c42edcb28a34e276f92dd9b2172613" category="list-text">通过支持自动数据分层，实时数据压缩，重复数据删除和数据缩减，提高 ONTAP 系统的数据存储效率。</block>
  <block id="f0a8a62c8d7ea4d12a7f1c95b40d3cb3" category="list-text">基于工作负载，由 QoS 控制的存储。</block>
  <block id="1e16ebc829d46d68a51d55ac22293b1e" category="list-text">与公有云无缝集成，实现数据分层和保护。ONTAP 还提供强大的数据保护功能，使其在任何环境中脱颖而出：</block>
  <block id="613db5a747bd15eeccbcbedce5bd8888" category="list-text">* NetApp Snapshot 副本。 * 使用最少的磁盘空间对数据进行快速时间点备份，而不会产生额外的性能开销。</block>
  <block id="8f666d296151faf9c472110831227243" category="list-text">* NetApp SnapMirror 。 * 将数据的 Snapshot 副本从一个存储系统镜像到另一个存储系统。ONTAP 还支持将数据镜像到其他物理平台和云原生服务。</block>
  <block id="5685b3f13393b751231ff096f77e6747" category="list-text">* NetApp SnapLock 。 * 将不可重写数据写入指定时间段内无法覆盖或擦除的特殊卷，从而高效管理这些数据。</block>
  <block id="dff1063d1e007396b7fb75f266dd48b7" category="list-text">* NetApp Snapshot.* 可将多个存储系统中的数据备份到一个中央 SnapVault 副本中，该副本可用作所有指定系统的备份。</block>
  <block id="779cb4084f09228e9562ca3bedc5555c" category="list-text">* NetApp SyncMirror 。 * 可将数据实时镜像到物理连接到同一控制器的两个不同磁盘丛中。</block>
  <block id="929a0581ca4b2982313e21e51effbc10" category="list-text">* NetApp SnapRestore 。 * 可根据需要从 Snapshot 副本快速还原备份的数据。</block>
  <block id="774a065cb3548cc61fb0ec3bc1494fbe" category="inline-link">ONTAP 9 文档中心</block>
  <block id="c389369b80a8ce8ead607b4c7088682e" category="paragraph">NetApp ONTAP 可在内部部署，虚拟化或云中使用。</block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="section-title">NetApp Trident</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="ea2625d89edeb5ba9cb41ca58df54e93" category="paragraph">Anthos 提供以下功能：</block>
  <block id="c10e0a21a04a29dfca9609b3ec4bab76" category="list-text">* Anthos 配置管理。 * 自动执行混合 Kubernetes 部署的策略和安全性。</block>
  <block id="e8c4d5cbaf3932ffa3fa7a097bff923e" category="list-text">* Anthos Service mesh 。 * 利用 Istio 支持的服务网格增强应用程序的可观察性，安全性和控制力。</block>
  <block id="aa69ca65720dd2e4eef99ebfb7816268" category="section-title">裸机上的 Anthos</block>
  <block id="844236b21d302f8c93eda00636abfff8" category="list-text">* 安全要求。 * 安全问题日益增加或无法存储在公有云中的敏感数据集的客户可以从自己的数据中心的安全环境中运行其应用程序，从而满足组织的要求。</block>
  <block id="3f4b17e041e63192875c654812122484" category="paragraph">NetApp 公司 Alan Cowles 和 Nikhil M Kulkarni</block>
  <block id="eed1ab12478f3384bfca66e2b382aefc" category="doc">使用 NetApp ONTAP 部署 Red Hat OpenShift 虚拟化</block>
  <block id="7dc3a10e876dbab2b177f35c0b436f3a" category="list-text">Red Hat OpenShift 集群（ 4.6 版之后的版本），安装在具有 RHCOS 工作节点的裸机基础架构上</block>
  <block id="b5762731ee8c7a3d9a7ce9abe3804cf0" category="list-text">OpenShift 集群必须通过安装程序配置的基础架构（ IPI ）进行安装</block>
  <block id="7ed0bc09bfa62b64806b6b5c2f4378c7" category="list-text">部署计算机运行状况检查以保持虚拟机的 HA</block>
  <block id="43b1ab0e04b8f87e603cc790967d2886" category="list-text">NetApp ONTAP 集群</block>
  <block id="d4c321b9edd8d817bdc7ca442e71e3af" category="list-text">在 ONTAP 集群上配置了 SVM 的 Trident 后端</block>
  <block id="cfcf3a62902e36f3d966271cc090b65c" category="list-text">对 Red Hat OpenShift 集群的集群管理员访问</block>
  <block id="af91af16b4791d61bb2e9206807a658d" category="list-text">对 NetApp ONTAP 集群的管理员访问权限</block>
  <block id="e281839ef9ef6cb1eadcc2aa7d6d63be" category="list-text">安装了 tridentctl 和 oc 工具并将其添加到 $path 中的管理工作站</block>
  <block id="314f04ff1024e623d43e0cda9a9df410" category="paragraph">由于 OpenShift 虚拟化由 OpenShift 集群上安装的操作员管理，因此会增加内存， CPU 和存储的开销，在规划集群的硬件要求时必须考虑这些开销。请参见文档<block ref="f9421eaa4175c3e9f421a9acaf6f00d6" category="inline-link-rx"></block> 有关详细信息：</block>
  <block id="be51a7d8687b0a6254a274c1e0100052" category="paragraph">或者，您也可以通过配置节点放置规则来指定一组 OpenShift 集群节点，以托管 OpenShift 虚拟化操作员，控制器和 VM 。要为 OpenShift 虚拟化配置节点放置规则，请按照文档进行操作<block ref="325820076f9012df5bb7261c397a527f" category="inline-link-rx"></block>。</block>
  <block id="a805b74dbb589c916a1ebf0e08601665" category="paragraph">对于支持 OpenShift 虚拟化的存储， NetApp 建议使用一个专用 StorageClass ，以便从特定 Trident 后端请求存储，而该后端又由专用 SVM 提供支持。这样就可以在 OpenShift 集群上为基于 VM 的工作负载提供的数据方面保持多租户级别。</block>
  <block id="4c37a5afd480a0042f69d7628cadd57d" category="summary">借助 NetApp 在 Red Hat OpenShift 上为 Kubernetes 提供高级集群管理</block>
  <block id="43288d8129021b1fe8b4bc6784e65b32" category="doc">功能：借助 NetApp 在 Red Hat OpenShift 上为 Kubernetes 提供高级集群管理</block>
  <block id="d10b633b8bd8d022c66a52d93e0ed6ce" category="section-title">集群生命周期管理</block>
  <block id="8b9449bdfc859a900fc4da7c79420145" category="paragraph">要管理不同的 OpenShift 集群，您可以创建这些集群或将其导入到高级集群管理中。</block>
  <block id="0becde0fcfda03aec9c722d042326324" category="list-text">要创建新的 OpenShift 集群，请完成以下步骤：</block>
  <block id="50dfc508091b37338da8357e63e6a405" category="image-alt">添加提供程序连接</block>
  <block id="2984cab36bd51d5446963e671e808f5d" category="image-alt">添加集群</block>
  <block id="e6d9a6b38dd36fd9870260249ba5fc1f" category="list-text">要导入现有集群，请完成以下步骤：</block>
  <block id="9a618414b83afe67c19abcf935be6dbd" category="image-alt">导入现有集群</block>
  <block id="c812d1382d834648706b3bf1e6848135" category="list-text">创建并导入多个集群后，您可以从一个控制台监控和管理这些集群。</block>
  <block id="3605e05aa598ff405b5edffc1bf474f1" category="summary">在使用 NetApp 的 Red Hat OpenShift 上配置多租户</block>
  <block id="13148717f8faa9037f37d28971dfc219" category="doc">验证</block>
  <block id="286c0d2f200233e63709210881b700c4" category="paragraph">要验证在上述步骤中配置的多租户架构，请完成以下步骤：</block>
  <block id="f4da6475fc7e97756adf2751840e077d" category="list-text">以项目 1 中的 OCP-project-1-user 和开发人员身份登录。</block>
  <block id="2d7fbbcee3114769610fea6ef6f4cdf0" category="list-text">检查访问权限以创建新项目。</block>
  <block id="12cdc5f68c3a0ca10544c0a57e866249" category="list-text">使用分配给 project-1 的 storageclass 在 project-1 中创建 PVC 。</block>
  <block id="145d2249af633a497182f76e714d1f2e" category="list-text">检查与 PVC 关联的 PV 。</block>
  <block id="d424ec829e7a6f56de4d74835b97103a" category="list-text">验证 PV 及其卷是否已在 NetApp ONTAP 上专用于 project-1 的 SVM 中创建。</block>
  <block id="a345b6be662b316a3b3e3cfbc7566b31" category="list-text">在 project-1 中创建 POD ，然后挂载上一步创建的 PVC 。</block>
  <block id="7b929f9e235c85c6b73ed2ee867c5514" category="list-text">检查 POD 是否正在运行以及是否已挂载卷。</block>
  <block id="8e27501b578972bd7b65468deaa482ca" category="list-text">使用分配给 project-2 的 storageclass 在 project-1 中创建 PVC 。</block>
  <block id="71bc5a6f1f0141981e0034b388233917" category="list-text">在 project-2 中创建 PVC 。</block>
  <block id="1149bf04288dfa82d0e3b713a6e66aa1" category="list-text">请确保未创建 PVC `test-vpa-project-1-sc-2` 和 `test-vpa-project-2-sc-1` 。</block>
  <block id="0d843e91c3b8f62457e19b2d32ecace3" category="list-text">在 project-2 中创建 POD 。</block>
  <block id="43700888cdcd166f379f95bd1751ae63" category="list-text">检查访问权限以创建新项目。</block>
  <block id="32579947c29f341292c3ce775140178b" category="list-text">验证对查看项目的访问权限。</block>
  <block id="9e97a1398bb4a0499bb69bf1c9e67d6a" category="list-text">检查用户是否可以在 project-1 中查看或编辑 ResourceQuotas 。</block>
  <block id="17a658c4329ed475a82d2e02c0406118" category="list-text">验证用户是否有权查看存储器。</block>
  <block id="aa177e49bfc4cc0182f57218ce6bdd4d" category="list-text">检查访问权限以描述存储器。</block>
  <block id="997cef2cfb8ccc12d8739c63e69794f3" category="list-text">验证用户的访问权限以编辑存储器库。</block>
  <block id="8921c6e9843ba7487c77f4dce1467111" category="summary">NetApp Element 软件可提供模块化的可扩展性能，每个存储节点均可为环境提供有保障的容量和吞吐量。NetApp Element 系统可以在一个集群中从 4 个节点扩展到 100 个节点，并提供多种高级存储管理功能。</block>
  <block id="5d77fe4a6bb4c5e88c5c18510b3c4749" category="doc">NetApp Element ：采用 NetApp 技术的 Red Hat OpenShift</block>
  <block id="22f48c519a73ce4759edffb196331422" category="paragraph"><block ref="22f48c519a73ce4759edffb196331422" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27765508a97a89684590658c3465fb70" category="inline-link">NetApp SolidFire 网站</block>
  <block id="d37eaafbb6dfb29673d63ff988ff4f41" category="paragraph">有关 NetApp Element 存储系统的详细信息，请访问<block ref="0d1d77e6774527457304fa15f73899a1" category="inline-link-rx"></block>。</block>
  <block id="bd4ffcaabbe4a4f83fbfaaa2e34dc8a3" category="section-title">iSCSI 登录重定向和自我修复功能</block>
  <block id="dbafa7c074ef7efc3c778b69c0ad31b5" category="paragraph">NetApp Element 软件利用 iSCSI 存储协议，这是在传统 TCP/IP 网络上封装 SCSI 命令的标准方式。当 SCSI 标准发生变化或以太网网络的性能提高时， iSCSI 存储协议就会受益，而无需进行任何更改。</block>
  <block id="23e6b910b28346537f5696478fffe779" category="paragraph">尽管所有存储节点都有一个管理 IP 和一个存储 IP ，但 NetApp Element 软件会为集群中的所有存储流量公布一个存储虚拟 IP 地址（ SVIP 地址）。在 iSCSI 登录过程中，存储可以响应目标卷已移至其他地址，因此无法继续协商过程。然后，主机将在不需要主机端重新配置的过程中向新地址重新发出登录请求。此过程称为 iSCSI 登录重定向。</block>
  <block id="b8603f3d585261d0005c7c5e51108d19" category="paragraph">iSCSI 登录重定向是 NetApp Element 软件集群的一个关键部分。收到主机登录请求后，节点将根据 IOPS 和卷的容量要求确定集群中应由哪个成员处理流量。卷分布在 NetApp Element 软件集群中，如果单个节点处理的卷流量过多或添加了新节点，则会重新分配这些卷。给定卷的多个副本会在阵列中分配。</block>
  <block id="772db62cf9ecb837ed4f0a91a5963492" category="paragraph">这样，如果节点发生故障后又发生卷重新分布，则除了注销和登录并重定向到新位置之外，对主机连接不会产生任何影响。通过 iSCSI 登录重定向， NetApp Element 软件集群是一种自我修复型横向扩展架构，能够无中断升级和操作。</block>
  <block id="5c8e89de2b8e6e2f103d858b59e5aca0" category="section-title">NetApp Element 软件集群 QoS</block>
  <block id="f8cd3dfe225577e230dc2699ebbbfe34" category="list-text">* 最大 IOPS* 。 NetApp Element 软件集群为特定卷提供的最大可持续 IOPS 数。</block>
  <block id="97bee3e8d0db89b2cd19eba861763e7a" category="list-text">* 安全身份验证。 * 质询握手身份验证协议（ Challenge-Handshake Authentication Protocol ， CHAP ）用于安全卷访问。轻量级目录访问协议（ Lightweight Directory Access Protocol ， LDAP ）用于安全访问集群以进行管理和报告。</block>
  <block id="3918507b16aa3cc38274c29da446d90f" category="list-text">* 卷访问组（ VAG ）。 * 也可以使用 VAG 代替身份验证，将任意数量的 iSCSI 启动程序专用 iSCSI 限定名称（ IQN ）映射到一个或多个卷。要访问 VAG 中的卷，启动程序的 IQN 必须位于该卷组允许的 IQN 列表中。</block>
  <block id="28328e0db9c18c9ada207997f806124f" category="list-text">* 租户虚拟 LAN （ VLAN ）。 * 在网络级别，使用 VLAN 可提高 iSCSI 启动程序与 NetApp Element 软件集群之间的端到端网络安全性。对于为隔离工作负载或租户而创建的任何 VLAN ， NetApp Element 软件会创建一个单独的 iSCSI 目标 SVIP 地址，该地址只能通过特定 VLAN 进行访问。</block>
  <block id="5fec85270e969240cc769f429b9c8cdc" category="list-text">启用了 VRF 的 VLAN 。 * 为了进一步支持数据中心的安全性和可扩展性，您可以使用 NetApp Element 软件为任何租户 VLAN 启用类似 VRF 的功能。此功能增加了以下两项关键功能：</block>
  <block id="fca8436836d48525b8d98babbfd68518" category="list-text">通过 * L3 路由到租户 SVIP 地址。 * 此功能，您可以将 iSCSI 启动程序置于与 NetApp Element 软件集群不同的网络或 VLAN 上。</block>
  <block id="eaea554ececf5b64515f0833c56b3de4" category="list-text">* IP 子网重叠或重复。 * 此功能可用于向租户环境添加模板，从而可以从同一 IP 子网为每个租户 VLAN 分配 IP 地址。此功能对于扩展和保留 IP 空间非常重要的服务提供商环境非常有用。</block>
  <block id="c08531651ee4977d5020da1b84003631" category="section-title">企业级存储效率</block>
  <block id="6893566c26b28e197cebdefdcc6af3ae" category="list-text">* 重复数据删除。 * 系统仅存储唯一的 4 K 块。任何重复的 4K 块都会自动与已存储的数据版本关联。数据位于块驱动器上，并使用 NetApp Element 软件 Helix 数据保护进行镜像。此系统可显著减少系统中的容量消耗和写入操作。</block>
  <block id="2e5dd3a69ccb3f04d7814fc742318204" category="list-text">* 压缩。 * 数据写入 NVRAM 之前，会实时执行数据压缩。数据会进行压缩，以 4 k 块的形式存储，并在系统中保持压缩状态。这种压缩可显著减少集群中的容量消耗，写入操作和带宽消耗。</block>
  <block id="215de8162cb5ac909005881f92812fb0" category="list-text">* 精简配置。 * 此功能可在需要时提供适当数量的存储，从而消除因过度配置卷或未充分利用卷而导致的容量消耗。</block>
  <block id="95f1b89c8e9c330fcfdc8ec84633bfe6" category="list-text">* Helix.* 单个卷的元数据存储在元数据驱动器上，并复制到二级元数据驱动器以实现冗余。</block>
  <block id="da9c9b2b4164632e569069fe1e7c53ee" category="admonition">Element 专为自动化而设计。所有存储功能均可通过 API 使用。这些 API 是 UI 用于控制系统的唯一方法。</block>
  <block id="ec22e01e7cd5087ef746b3db5852da6e" category="doc">扩展：添加更多项目</block>
  <block id="0e4136a9f4ad3204c07db26d3c28a546" category="paragraph">在多租户配置中，使用存储资源添加新项目需要进行额外配置，以确保不会违反多租户要求。要在多租户集群中添加更多项目，请完成以下步骤：</block>
  <block id="c8acb1fa89b1ec9d78799a2dd4aa8b59" category="list-text">以存储管理员身份登录到 NetApp ONTAP 集群。</block>
  <block id="d0ed0d7b81278233c852e4a0d8aa123b" category="list-text">导航到 `Storage -&gt; Storage VM` ，然后单击 `Add` 。创建一个专用于 project-3 的新 SVM 。此外，还可以创建 vsadmin 帐户来管理 SVM 及其资源。</block>
  <block id="5790e2b8b367726e78500054d959d6f7" category="image-alt">创建 SVM 以进行扩展</block>
  <block id="b0c67e9a89c7ece3169ab5849bb0e411" category="list-text">以集群管理员身份登录到 Red Hat OpenShift 集群。</block>
  <block id="c9e86337c7483c8d45e5e535829d2163" category="list-text">创建新项目。</block>
  <block id="46c82384780a492254c43d461363d9ac" category="list-text">为 project-3 创建开发人员角色。</block>
  <block id="21ac9e9bbb2cfc707143311f4601af1c" category="admonition">本节中提供的角色定义只是一个示例。必须根据最终用户要求定义开发人员角色。</block>
  <block id="8efa8222e644f71e636f98917439566d" category="list-text">在 project-3 中为开发人员创建 RoleBinding. 将开发人员项目 3 角色绑定到 project-3 中的相应组（ OCP-project-3 ）。</block>
  <block id="e1f01c3341da15c9079bf5996c059811" category="list-text">以存储管理员身份登录到 Red Hat OpenShift 集群</block>
  <block id="2ca2d57f42208b6e7e9026b491595f41" category="list-text">创建 Trident 后端并将其映射到专用于 project-3 的 SVM 。NetApp 建议使用 SVM 的 vsadmin 帐户将后端连接到 SVM ，而不是使用 ONTAP 集群管理员。</block>
  <block id="c4dcda95616fac9215b5dac3cde37220" category="admonition">在此示例中，我们使用的是 ontap-NAS 驱动程序。使用相应的驱动程序根据使用情形创建后端。</block>
  <block id="8628ed29313534f54f01e0da36e66ab7" category="admonition">我们假定 Trident 已安装在 Trident 项目中。</block>
  <block id="55da75937cfedfe97c220c1e9d556d84" category="list-text">为 project-3 创建存储类，并将其配置为使用专用于 project-3 的后端存储池。</block>
  <block id="6efdcf6ed405066371d23375541816a1" category="list-text">创建 ResourceQuota 以限制项目 3 中的资源，从而从专用于其他项目的存储库请求存储。</block>
  <block id="1dea1d57247580b530335ec2d484f8a5" category="list-text">在其他项目中修补 ResourceQuotas ，以限制这些项目中的资源从专用于项目 3 的存储库访问存储。</block>
  <block id="31fd0c2c8d388a4cd2c6459234743476" category="section-title">可观察性</block>
  <block id="7a6ccefec75a946583cffdd0a8a47e09" category="image-alt">可观察性主页</block>
  <block id="4a973ae1a908770e354f949d3c0592f8" category="image-alt">观察 Pod</block>
  <block id="8a373f777de729c082b5be2d80b7eca6" category="image-alt">观察节点</block>
  <block id="2ececa2c251a851a85e976daae558c81" category="image-alt">观察集群</block>
  <block id="4e42a1e911325b5048e50f7b5ea73d1f" category="section-title">VM 实时迁移</block>
  <block id="09e113cd46b4487f140ee07899ea3359" category="image-alt">VM 实时迁移架构</block>
  <block id="660b7fa756d01df7c4338afb9050abb1" category="paragraph">要创建绑定到具有共享 ReadWriteMany 访问权限的 PVC 的 VM ，请执行以下操作：</block>
  <block id="416d6e9d0df33a74dd38603be60453c1" category="list-text">选择所需的操作系统，然后单击下一步。假设选定操作系统已配置了启动源。</block>
  <block id="e1b595d3037639bdea165dde4b1f3906" category="list-text">在 Review and Create 窗格中，选择要在其中创建 VM 的项目并提供 VM 详细信息。确保选择了要克隆的启动源，并使用为选定操作系统分配的相应 PVC 从 CD-ROM 启动。</block>
  <block id="998a8df469c318f9cd606b44664cea5d" category="list-text">单击自定义虚拟机，然后单击存储。</block>
  <block id="ef44ba6bf4a3e677b41b361628554b88" category="image-alt">使磁盘 rwx 可访问</block>
  <block id="2ae6b586f76075c7d71faff7ba9d2a41" category="list-text">单击 Review 并确认，然后单击 Create Virtual Machine 。</block>
  <block id="18c830e61a7a92c60804118ef362933c" category="paragraph">要手动将虚拟机迁移到 OpenShift 集群中的另一个节点，请完成以下步骤。</block>
  <block id="cc58a226305ad2362de0317c1fd8261b" category="list-text">对于要迁移的虚拟机，单击省略号，然后单击迁移虚拟机。</block>
  <block id="b5839595a4132807edfc858d9f6d90ad" category="list-text">当消息弹出时，单击迁移进行确认。</block>
  <block id="d0f501bd9588700bc91fe10b7d3f761a" category="admonition">如果 evictionStrategy 设置为 LiveMigrate ，则在将原始节点置于维护模式时， OpenShift 集群中的 VM 实例会自动迁移到另一节点。</block>
  <block id="122aacda8785e42ca8fd7bd6ebce84f8" category="summary">VMware vSphere 是一个虚拟化平台，用于集中管理 ESXi 虚拟机管理程序上运行的大量虚拟化服务器和网络。</block>
  <block id="68bc8529d7c57946fe13e6b3399ee287" category="inline-link">VMware vSphere 网站</block>
  <block id="80888e73d00a224bebfc22e8e4539b6d" category="paragraph">有关 VMware vSphere 的详细信息，请参见<block ref="8e822bbeb5824c0a05189bf9ff98da5c" category="inline-link-rx"></block>。</block>
  <block id="cb4d59b9004b7c584811a3d656f78bc5" category="paragraph">VMware vSphere 可提供以下功能：</block>
  <block id="cfb123c76f1c7a506310e1162d7ae235" category="paragraph"><block ref="cfb123c76f1c7a506310e1162d7ae235" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">网络设计</block>
  <block id="f1744781b12c15ad3b748bea44d9582b" category="section-title">VLAN 要求</block>
  <block id="e75b582a8823d532f6022b43ac209538" category="paragraph">VMware vSphere 上的 Red Hat OpenShift 旨在通过使用虚拟局域网（ VLAN ）在逻辑上隔离不同用途的网络流量。此配置可以进行扩展，以满足客户需求，或者为特定网络服务提供进一步隔离。下表列出了在 NetApp 验证解决方案时实施解决方案所需的 VLAN 。</block>
  <block id="05808f0e86c04c2a062c2e041f9e0827" category="cell">VLAN ID</block>
  <block id="3c8c5d8387f173924ffeb2bf88084dba" category="cell">管理物理节点和 IPMI</block>
  <block id="c61d980d5248923d65a5dfe7f8818011" category="cell">VM 网络</block>
  <block id="fc221309746013ac554571fbd180e1c8" category="cell">181</block>
  <block id="c846a1f843522d592b784a66368abed3" category="cell">ONTAP NFS 的存储网络</block>
  <block id="6cdd60ea0045eb7a6ec44c54d29ed402" category="cell">184</block>
  <block id="5e6094f6f2176409f469ee445fcf3f50" category="cell">适用于 ONTAP iSCSI 的存储网络</block>
  <block id="eecca5b6365d9607ee5a9d336962c534" category="cell">185.</block>
  <block id="45cf0331a91fdc3679a78fdd8f7c60a7" category="cell">管理 ESXi 节点， vCenter Server ， ONTAP Select</block>
  <block id="e8e0dd181e4ee545195120626098bfba" category="cell">3480</block>
  <block id="11967d5f57969ea4713204eace8fbf4e" category="cell">适用于 NetApp Element iSCSI 的存储网络</block>
  <block id="3fb04953d95a94367bb133f862402bce" category="cell">3481</block>
  <block id="c87f7de78a1912f53050e58df90e1445" category="cell">用于虚拟子系统迁移的网络</block>
  <block id="b7fede84c2be02ccb9c77107956560eb" category="cell">3482</block>
  <block id="35b5078b5953437a59ffd4f77c464800" category="section-title">网络基础架构支持资源</block>
  <block id="0bad9231e1bf61bc343a986739f155c1" category="paragraph">在部署 OpenShift 容器平台之前，应具备以下基础架构：</block>
  <block id="447cb4a01965e3df01476db3576e0399" category="list-text">（可选）带内管理网络和 VM 网络的出站 Internet 连接。</block>
  <block id="a181412a291a7d0ae8a71300abf746b8" category="section-title">生产部署的最佳实践</block>
  <block id="0f19aa91cffca51fd061e34dee1e5c79" category="paragraph">本节列出了企业在将此解决方案部署到生产环境之前应考虑的几个最佳实践。</block>
  <block id="bd690c49b77b8274786240fa94d9d880" category="section-title">将 OpenShift 部署到至少包含三个节点的 ESXi 集群</block>
  <block id="9dc31e1598f94b9476a025632cee3e19" category="section-title">配置虚拟机和主机关联性</block>
  <block id="9934283c0bf98610b4be1803b9ad3430" category="inline-link">vSphere 6.7 文档：使用 DRS 关联性规则</block>
  <block id="ed3ecd4254cc054c70ddee702d7ed519" category="section-title">使用自定义安装文件进行 OpenShift 部署</block>
  <block id="7b65abec68958867d7dd5f43b3b06e08" category="inline-link">Red Hat OpenShift 通过自定义在 vSphere 上安装集群</block>
  <block id="a0e01d06503f271c1de7acc0acd01733" category="doc">NVA-1160 ：采用 NetApp 技术的 Red Hat OpenShift</block>
  <block id="4711a0fd2fa3c3625080f399e5261ecd" category="paragraph">采用 NetApp 解决方案的 Red Hat OpenShift 旨在为客户提供卓越的价值，其使用情形如下：</block>
  <block id="44815e873492015d6a8ab6362de8da6c" category="list-text">使用 IPI （安装程序配置的基础架构）在裸机上， Red Hat OpenStack Platform ， Red Hat 虚拟化和 VMware vSphere 上轻松部署和管理 Red Hat OpenShift 。</block>
  <block id="03bb323d052d033ea0b5b2cab17f1219" category="list-text">将企业级容器和虚拟化工作负载的强大功能与 Red Hat OpenShift 相结合， Red Hat OpenShift 可虚拟部署在 OSP ， RHV 或 vSphere 上，也可通过 OpenShift 虚拟化部署在裸机上。</block>
  <block id="932ba7da1da9b241bfc5ddbb10e49da2" category="paragraph">企业越来越多地采用 DevOps 实践来创建新产品，缩短发布周期并快速添加新功能。由于容器和微服务本身的灵活性，它们在支持 DevOps 实践方面发挥着至关重要的作用。但是，在企业环境中以生产规模实施 DevOps 会带来自身的挑战，并对底层基础架构提出一些要求，例如：</block>
  <block id="43ee156205e7f74e32a02d556537fe90" category="list-text">堆栈中所有层的高可用性</block>
  <block id="b59807af538b77fee1fb3d1d3c81f9a8" category="list-text">易于部署过程</block>
  <block id="2748d7182409b378e23f62724be778fd" category="list-text">无中断运行和升级</block>
  <block id="1a4af279491c72d7c36b4c9767ae712f" category="list-text">API 驱动的可编程基础架构，可跟上微服务灵活性的步伐</block>
  <block id="8ca11bfd783c730b04c0c77fc7574406" category="list-text">能够同时运行虚拟化和容器化工作负载</block>
  <block id="0111977afdb7fa380f806edbe8438163" category="list-text">能够根据工作负载需求独立扩展基础架构</block>
  <block id="42c487483a8feee3cc0365881a4cc265" category="paragraph">Red Hat OpenShift with NetApp 认可这些挑战，并提供了一个解决方案，通过在客户选择的数据中心环境中实施完全自动化的 RedHat OpenShift IPI 部署，帮助解决每个问题。</block>
  <block id="fd89bb4228981d3b22187eb451421cd6" category="section-title">Red Hat OpenShift 容器平台</block>
  <block id="70240bc0debcb080aa08dbd9e7b9a525" category="paragraph">有关详细信息，请访问 OpenShift 网站<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>。</block>
  <block id="aa4193984de53d2a6d8fcc2d77c09bda" category="paragraph">有关详细信息，请访问 NetApp 网站<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>。</block>
  <block id="e7e767d7c0e58b16e57d3ab16150db80" category="cell">技术</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="cell">NetApp ONTAP</block>
  <block id="601712ded7a71b0842984ad41b6aad39" category="cell">12.3</block>
  <block id="765bb3744268ca0de607208bfdc8a37a" category="cell">存储编排</block>
  <block id="b175d08ac03101cd40f077848d436e1f" category="cell">Red Hat OpenShift</block>
  <block id="7cf4fea896dee61293d729d9985621d7" category="cell">容器编排</block>
  <block id="2454407b9991c6c5f417a2feb8ea7970" category="cell">4.6 EUS ， 4.7</block>
  <block id="9c4e78a1b7e7b4981aced1e10d037c6d" category="cell">Red Hat OpenStack 平台</block>
  <block id="de45aa336111dfa1825c54726464307c" category="cell">私有云基础架构</block>
  <block id="3c5825a0d4bdb85c67182ef89bc9c7eb" category="cell">16.1</block>
  <block id="f9a97ed4e88eeab44f2693afa0eb2089" category="cell">4.4</block>
  <block id="9c295b8302ac546bb93a346b68089f50" category="cell">6.7U3.</block>
  <block id="1be465260df7c846768e06c988594a6a" category="paragraph">要了解有关本文档中所述信息的更多信息，请查看以下网站：</block>
  <block id="e690fa655ec589e6d0abb58164d5ccfd" category="doc">追加信息：采用 NetApp 技术的 Red Hat OpenShift</block>
  <block id="6f4e4d9fbe846fd8bf7decf7dcffbd63" category="list-text">NetApp 文档</block>
  <block id="1497398039e94eb756be9a3cff5649c7" category="inline-link"><block ref="1497398039e94eb756be9a3cff5649c7" category="inline-link-rx"></block></block>
  <block id="f2d3084aa0f70da5e15757ee3292cda7" category="paragraph"><block ref="f2d3084aa0f70da5e15757ee3292cda7" category="inline-link-rx"></block></block>
  <block id="21b11dbf6ab3c6d36a76f280fe8ec75d" category="list-text">Red Hat OpenShift 文档</block>
  <block id="74201863479cf5c9b89330c920283301" category="inline-link"><block ref="74201863479cf5c9b89330c920283301" category="inline-link-rx"></block></block>
  <block id="3e10ed3875c45f9dc9064324660fc2b1" category="paragraph"><block ref="3e10ed3875c45f9dc9064324660fc2b1" category="inline-link-rx"></block></block>
  <block id="06fd33ae9f869a89e860634ec94b9793" category="list-text">Red Hat OpenStack Platform 文档</block>
  <block id="647d438a62673b6a6c9830682f6bc128" category="inline-link"><block ref="647d438a62673b6a6c9830682f6bc128" category="inline-link-rx"></block></block>
  <block id="705a39bc1a12c50103a847633c3f7493" category="paragraph"><block ref="705a39bc1a12c50103a847633c3f7493" category="inline-link-rx"></block></block>
  <block id="8d79e9650a1f62f89d77743225e203c0" category="list-text">Red Hat 虚拟化文档</block>
  <block id="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link"><block ref="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link-rx"></block></block>
  <block id="6d6038842b529e3d97aa9a8a9d81d866" category="paragraph"><block ref="6d6038842b529e3d97aa9a8a9d81d866" category="inline-link-rx"></block></block>
  <block id="4666fc2f640685636f115f8b2b6b8ce0" category="list-text">VMware vSphere 文档</block>
  <block id="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link"><block ref="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link-rx"></block></block>
  <block id="71aa41fc980571d5a324adedae614f9c" category="paragraph"><block ref="71aa41fc980571d5a324adedae614f9c" category="inline-link-rx"></block></block>
  <block id="639813d9aa126816c3f9e9de2a45ce17" category="paragraph">OSP 是一种基础架构即服务（ Infrastructure-as-a-Service ， IaaS ）云，由一组控制服务实施，用于管理计算，存储和网络资源。环境可通过基于 Web 的界面进行管理，管理员和用户可以控制，配置和自动化 OpenStack 资源。此外，还通过广泛的命令行界面和 API 为 OpenStack 基础架构提供便利，为管理员和最终用户提供全面的自动化功能。</block>
  <block id="737c38dd225185612ac8fa148ae9583e" category="inline-link">Red Hat OpenStack Platform 网站</block>
  <block id="e2ab8aafc6151adfa655ffd5d2425e7d" category="section-title">OpenStack 服务</block>
  <block id="f5fdcf6d68d437c59942a35d79b8c7b1" category="paragraph"><block ref="f5fdcf6d68d437c59942a35d79b8c7b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2ba7e785c49050f48da9aacc45c2b85" category="cell">服务</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">Description</block>
  <block id="2938c7f7e560ed972f8a4f68e80ff834" category="cell">信息板</block>
  <block id="85fb7708d989f936cb51ef53a8af080f" category="cell">Horizon</block>
  <block id="d5a9efab6df20a9e132b774795775dde" category="cell">基于 Web 浏览器的信息板，用于管理 OpenStack 服务。</block>
  <block id="c9c5c65fb4af9cf90eb99b3b84424189" category="cell">身份</block>
  <block id="1ce2096c300f78bbb8389ca2603e6dd9" category="cell">Keystone</block>
  <block id="91c68681aadba9c0e8308f7d0b3cc416" category="cell">用于身份验证和授权 OpenStack 服务以及管理用户，项目和角色的集中式服务。</block>
  <block id="88fac409baf592beb25e285d8663edcb" category="cell">中子</block>
  <block id="0283e46fd80198d441eb742b88cf96f1" category="cell">在 OpenStack 服务的接口之间提供连接。</block>
  <block id="a7173cc5cdd0e31df00cd34f058b1d33" category="cell">Cinder</block>
  <block id="597dab3a2b3c74e3c266b2f65ec28619" category="cell">管理虚拟机（ VM ）的永久性块存储卷。</block>
  <block id="6e747c4965495f2e26bf17e647aa0083" category="cell">Nova</block>
  <block id="f13c04e9c49274cd31bd8092c8f50304" category="cell">管理和配置计算节点上运行的 VM 。</block>
  <block id="be53a0541a6d36f6ecb879fa2c584b08" category="cell">图像</block>
  <block id="10ec3a0506fab7073649337ca7be7979" category="cell">概览</block>
  <block id="d9ff71ddcb6bbbe8ad48ae8b678369d4" category="cell">用于存储 VM 映像和卷快照等资源的注册表服务。</block>
  <block id="ae832e9b5bda2699db45f3fa6aa8c556" category="cell">Swift</block>
  <block id="41c380458dfcdc118ef573a2d98c6acb" category="cell">允许用户存储和检索文件和任意数据。</block>
  <block id="aa96a21412def0d916f43b639424f8e4" category="cell">遥测</block>
  <block id="8fb4b5e28f192236eaa9e4972f810dbd" category="cell">Ceilmeter</block>
  <block id="ed622b9c64858cc66a01c58893b5d39d" category="cell">提供对云资源使用情况的衡量指标。</block>
  <block id="d9cc1f843ea62c12a3e59afbbdc2f9ce" category="cell">流程编排</block>
  <block id="7d486371bb65b0633535ceba4189d8ed" category="cell">热</block>
  <block id="abaa6ebae60b74638c54a43f3341db8e" category="cell">基于模板的流程编排引擎，支持自动创建资源堆栈。</block>
  <block id="5ddbd3cec63b14995bf6a5823b692de7" category="paragraph">采用 NetApp 解决方案的 Red Hat OpenShift 使用两个数据交换机以 25 Gbps 的速度提供主数据连接。它还使用两个额外的管理交换机，这些交换机以 1 Gbps 的速度提供连接，用于存储节点的带内管理以及 IPMI 功能的带外管理。</block>
  <block id="c546b983b02d8654c5b245147d99dcf0" category="paragraph">采用 NetApp 的 Red Hat OpenShift 旨在通过使用虚拟局域网（ VLAN ）在逻辑上隔离不同用途的网络流量。此配置可以进行扩展，以满足客户需求，或者为特定网络服务提供进一步隔离。下表列出了在 NetApp 验证解决方案时实施解决方案所需的 VLAN 。</block>
  <block id="414b4843c124e72b43bccf2948a53a41" category="cell">用于管理物理节点和 IPMI 服务的网络具有讽刺意味。</block>
  <block id="e8cbca2d71bd2aeff622a07b4ffad6c2" category="cell">用于控制器节点直接映射卷以支持 Swift 等基础架构服务的网络。</block>
  <block id="757b505cfd34c64c85ca5b5690ee5293" category="cell">201</block>
  <block id="e103375dfc18f23e4fc072903e894fe9" category="cell">存储 Cinder</block>
  <block id="0bdfa6389eb47674a02f6049f342785d" category="cell">用于将块卷直接映射和附加到环境中部署的虚拟实例的网络。</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="772d9a23b79ccb504fa0590644934c3b" category="cell">内部 API</block>
  <block id="e44f5f63400b0975b884dc2980ee3a61" category="cell">用于通过 API 通信， RPC 消息和数据库通信在 OpenStack 服务之间进行通信的网络。</block>
  <block id="34ed066df378efacc9b924ec161e7639" category="cell">301.</block>
  <block id="6252d0571760e3d285e2e41a2b1e7743" category="cell">租户</block>
  <block id="577bcc914f9e55d5e4e4f82f9f00e7d4" category="cell">302.</block>
  <block id="cdc529b5e11a981e4597195c5f1c53b5" category="cell">OpenStack 对象存储（ Swift ）使用此网络在参与的副本节点之间同步数据对象。代理服务充当用户请求与底层存储层之间的中间接口。代理接收传入请求并找到所需的副本以检索请求的数据。</block>
  <block id="11b9842e0a271ff252c1903e7132cd68" category="cell">303.</block>
  <block id="5214f1e2490f3878e307fd6f81f9f77f" category="cell">PXE</block>
  <block id="16d856c79e739181f35adfe5b791c650" category="cell">OpenStack Director 在具有讽刺意味的裸机配置服务中提供 PXE 启动，用于编排 OSP Overcloud 的安装。</block>
  <block id="966b6dfb6b0819cc10644bea3115cf20" category="cell">3484</block>
  <block id="b206a1b4ea1097761f78e8876f6da779" category="cell">外部</block>
  <block id="dfeb9598fbfb97cc6bbcc0aff2c785d6" category="cell">3485</block>
  <block id="32223320445c4cf46444e40ebde18b7e" category="cell">提供对系统管理功能的访问，例如 SSH 访问， DNS 流量和网络时间协议（ NTP ）流量。此网络还充当非控制器节点的网关。</block>
  <block id="ab4f2b5fd96ca65349119909c1eada2d" category="cell">3486</block>
  <block id="f2260a90424f1d412334d1b3467abd22" category="list-text">至少一个 DNS 服务器，可提供完整的主机名解析。</block>
  <block id="d70672769aa84f2a999291a645e67355" category="list-text">至少三个 NTP 服务器，这些服务器可以使解决方案中的服务器保持时间同步。</block>
  <block id="478a3526bd6097c6b7a330fd6aae410e" category="list-text">（可选） OpenShift 环境的出站 Internet 连接。</block>
  <block id="9a14258452ea5da50d562e08e5b9291c" category="section-title">将 OpenShift 部署到至少包含三个计算节点的 OSP 私有云</block>
  <block id="7a595c63e0ebc069af3da46e3d1c8fee" category="section-title">配置虚拟机 / 主机关联性</block>
  <block id="9c0af999b760fac2aa82d9d105fa7a7e" category="paragraph">默认情况下，服务器组最多可管理 10 个虚拟实例的放置。可以通过更新 Nova 的默认配额来修改此设置。</block>
  <block id="8aea038e418642b1735131358c24a866" category="inline-link">如何为 OpenStack 实例配置关联性和反关联性？</block>
  <block id="47a822101acb11c74a4877a3d0b77093" category="inline-link">Red Hat OpenShift 通过自定义在 OpenStack 上安装集群</block>
  <block id="e38be1dc20a2b358b917b60fe2677b39" category="doc">NetApp Element iSCSI 配置</block>
  <block id="27ef1192cd037c8978195be045fa054e" category="list-text">编辑 `endpoint` 行上的用户，密码和 MVIP 值。</block>
  <block id="d1b7418d19df7144a98dfde725db068c" category="list-text">编辑 `SVIP` 值。</block>
  <block id="dd7f72325e6f60ea7163b071e4d5e2cc" category="list-text">安装好此后端文件后，运行以下命令创建第一个后端。</block>
  <block id="d8f188eff4c16fa87dd87f51db847f73" category="list-text">创建后端后，您接下来必须创建一个存储类。与后端一样，可以在 sample-inputs 文件夹中为环境编辑一个示例存储类文件。将其复制到工作目录并进行必要的编辑，以反映所创建的后端。</block>
  <block id="eb22c0d536e50f388da6dfd91ba4c0b6" category="list-text">必须对此文件进行的唯一编辑是，为新创建的后端存储驱动程序的名称定义 `backendType` 值。另请注意 name-field 值，稍后必须引用该值。</block>
  <block id="3ae96676432caea17595a22525bd9660" category="admonition">此文件中定义了一个名为 `FSType` 的可选字段。在 iSCSI 后端，可以将此值设置为特定的 Linux 文件系统类型（ XFS ， ext4 等），也可以删除此值，以便 OpenShift 决定要使用的文件系统。</block>
  <block id="7183f006fd74d941c838f003380f3f46" category="list-text">运行 `oc` 命令以创建存储类。</block>
  <block id="71cb54ab06aa16af27a0ec2157972648" category="list-text">创建存储类后，您必须创建第一个永久性卷请求（ PVC ）。此外，还可以在 sample-inputs 中使用一个示例 `pva-basic 。 yaml` file 来执行此操作。</block>
  <block id="afc499f2f95809cedce5c8922067065f" category="list-text">必须对此文件进行的唯一编辑是，确保 `storageClassName` 字段与刚刚创建的字段匹配。可以根据要配置的工作负载的需要进一步自定义 PVC 定义。</block>
  <block id="02eb9c3824b0b8eae9723daa7a2912d1" category="list-text">发出 `oc` 命令创建 PVC 。根据所创建的后备卷的大小，创建可能需要一些时间，因此您可以在该过程完成后进行观察。</block>
  <block id="de59be6e44d20d9dd12412571b745c5f" category="section-title">应用程序生命周期管理</block>
  <block id="fa19c463235a810b3a93333d6ee51d6c" category="paragraph">要创建应用程序并在一组集群中对其进行管理，</block>
  <block id="6b41f909eb299f214abfb15580583456" category="image-alt">创建应用程序</block>
  <block id="bcb3e5b76f189a87ea350550f86de83f" category="list-text">安装应用程序组件后，此应用程序将显示在列表中。</block>
  <block id="d70fc022d09a33f4044c81cd670a71b6" category="image-alt">应用程序列表</block>
  <block id="672d326704c3be4bebf6c816a48495e7" category="list-text">现在，可以从控制台监控和管理此应用程序。</block>
  <block id="9d312703c40c2d87b835076063682d59" category="summary">NetApp ONTAP 是一款功能强大的存储软件工具，具有直观的图形用户界面，具有自动化集成功能的 REST API ，基于 AI 的预测性分析和更正操作，无中断硬件升级和跨存储导入等功能。</block>
  <block id="48235fec2427a785c4a09d7150fc11fc" category="inline-link">NetApp ONTAP 网站</block>
  <block id="e65027864c84a42fc0799d878ffa0005" category="paragraph">有关 NetApp ONTAP 存储系统的详细信息，请访问<block ref="be9464a7a83e639a645a801fff2791d9" category="inline-link-rx"></block>。</block>
  <block id="4e3f9a03501932f914205c4ad0e682ea" category="list-text">* NetApp FlexClone 。 * 可根据 Snapshot 副本即时配置 NetApp 卷的完全可读写副本。</block>
  <block id="96f474208f638efbbd85fac3a46a2ed4" category="paragraph">有关 ONTAP 的详细信息，请参见<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>。</block>
  <block id="81bf516f5b38ea41d503a2670a9dc144" category="paragraph"><block ref="81bf516f5b38ea41d503a2670a9dc144" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e80842c9211bc376ee42d583c70ae408" category="section-title">NetApp 平台</block>
  <block id="5a69e0f8303b40f9f4d56038d3d260c9" category="section-title">NetApp AFF/FAS</block>
  <block id="d4c312c600a949fb72436c2d10568a90" category="paragraph">这两个系统均由 NetApp ONTAP 数据管理软件提供支持。 NetApp 数据管理软件是业内最先进的数据管理软件，可提供高度可用的云集成简化存储管理，可提供您的 Data Fabric 所需的企业级速度，效率和安全性。</block>
  <block id="992c24be8f66e4259b38ce763c115251" category="paragraph">有关 NetApp AFF/FAS 平台的详细信息，请单击<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>。</block>
  <block id="b008e805d13d953ddb5cbb220d8ef9b6" category="paragraph">ONTAP Select 是 NetApp ONTAP 的软件定义部署，可以部署到您环境中的虚拟机管理程序上。它可以安装在 VMware vSphere 或 KVM 上，并提供基于硬件的 ONTAP 系统的完整功能和体验。</block>
  <block id="3f0bbee5abf3eed060d4147cb0d060b9" category="paragraph">有关 ONTAP Select 的详细信息，请单击<block ref="7c1424ed7be035c303f12b0763e38ece" category="inline-link-rx"></block>。</block>
  <block id="117bdbda976fe8b3212bc3b6327a0a1b" category="section-title">Cloud Volumes ONTAP</block>
  <block id="f0f4b6de2040d7dc57e7f4f6baee7ec3" category="paragraph">NetApp Cloud Volumes ONTAP 是 NetApp ONTAP 的云部署版本，可部署在多个公有云中，包括 Amazon AWS ， Microsoft Azure 和 Google Cloud 。</block>
  <block id="c7fa0d52c3955385f084d0e67c59f963" category="paragraph">有关 Cloud Volumes ONTAP 的详细信息，请单击<block ref="75c9b0075008bbe40ac851ad7f6dda6a" category="inline-link-rx"></block>。</block>
  <block id="14a9bacc4b197037f54eb0c4c7e1970c" category="paragraph">因此，企业需要寻找在这两种环境中都能获得最佳性能的解决方案，例如，允许他们在一个集群中运行所有工作负载，同时为每个工作负载提供专用集群的优势。</block>
  <block id="cde9f9f8fcae0cdc6624895868803d60" category="list-text">通过共享集群资源，降低资本支出和运营支出</block>
  <block id="943a49720e6c85fa9692af2a5ebd8829" category="list-text">降低运营和管理开销</block>
  <block id="f51a58b3ab19c778652fcff9dd39ca55" category="list-text">保护工作负载免受安全违规交叉影响</block>
  <block id="181cfddfdb055879df4d55323a14c473" category="list-text">保护工作负载，防止因资源争用而导致性能意外下降</block>
  <block id="06fdae3f02fee5cbe172f1574564c925" category="doc">适用于 Kubernetes 的高级集群管理：采用 NetApp 的 Red Hat OpenShift</block>
  <block id="30c15b5a84f4fb26cd25b38dc787b22d" category="paragraph">随着容器化应用程序从开发过渡到生产，许多组织需要使用多个 Red Hat OpenShift 集群来支持该应用程序的测试和部署。同时，企业通常会在 OpenShift 集群上托管多个应用程序或工作负载。因此，每个组织最终都会管理一组集群，因此 OpenShift 管理员必须面对在跨多个内部数据中心和公有云的一系列环境中管理和维护多个集群这一额外挑战。为了应对这些挑战， Red Hat 推出了适用于 Kubernetes 的高级集群管理。</block>
  <block id="a7516c278242a08b85090e24cbf67218" category="paragraph">Red Hat Advanced Cluster Management for Kubernetes 作为 Red Hat OpenShift 集群的附加组件进行安装，并使用此集群作为其所有操作的中央控制器。此集群称为集线器集群，它会为用户提供一个管理平面以连接到高级集群管理。通过高级集群管理控制台导入或创建的所有其他 OpenShift 集群均由集线器集群管理，称为受管集群。它会在受管集群上安装一个名为 Kluterlet 的代理，将其连接到中心集群，并处理与集群生命周期管理，应用程序生命周期管理，可观察性和安全合规性相关的不同活动请求。</block>
  <block id="b1000f23e43dfac19b53c74d7ebe66c8" category="image-alt">ACM 架构</block>
  <block id="a376445fd812a7fa27714e6b11bc6163" category="paragraph">有关详细信息，请参见文档<block ref="50c0dc50e188cf3a7847d9a813fd829e" category="inline-link-rx"></block>。</block>
  <block id="7c613b296892d4712b9041d3081282f8" category="summary">借助 NetApp 在 Red Hat OpenShift 上为 Kubernetes 提供高级集群管理。</block>
  <block id="78e1aefe2bbb2518f1156636e761e479" category="paragraph">要在 OpenShift 集群上安装适用于 Kubernetes 的高级集群管理，请完成以下步骤：</block>
  <block id="b17056cdbd9ec695d4348e1ad799ace4" category="list-text">选择一个 OpenShift 集群作为中心集群，并使用 cluster-admin 权限登录到该集群。</block>
  <block id="2e5d3941e033e96d5317cc2bbd1da914" category="image-alt">ACM 磁贴</block>
  <block id="cc5a9dd5971b8369354db684e5dbfe2b" category="image-alt">ACM 图块详细信息</block>
  <block id="72b342ddabad6a9ec11df82389c40b88" category="image-alt">安装 ACM 操作员磁贴</block>
  <block id="11458c333e4903e54ca46f822ba6a3b6" category="list-text">等待操作员安装完成。</block>
  <block id="64524f91c2fdfcd54b4bbcab35392908" category="image-alt">正在安装 ACM 操作员</block>
  <block id="e0d84ec6a5b8f92909a7a3bef11455c1" category="image-alt">ACM 操作员 MulticlusterHub</block>
  <block id="344f0cb43d1b2e7a719bea808fe7c5bf" category="image-alt">创建多集群中心屏幕</block>
  <block id="851548d1ad843a23609f325e8b54e72d" category="image-alt">安装了含 ACM 的操作员</block>
  <block id="c7aa79f0c31ac15d728ee47c7e6eaee2" category="image-alt">多集群集线器就绪</block>
  <block id="f761fad3f1c25e94d5f46ebd9e23a901" category="image-alt">ACM 控制台路由</block>
  <block id="e68e90b5707502c9f2fc1361ac071b3d" category="paragraph">Red Hat OpenShift 容器平台将开发和 IT 运营统一到一个平台上，以便在内部和混合云基础架构中一致地构建，部署和管理应用程序。Red Hat OpenShift 基于开源创新和行业标准构建，其中包括 Kubernetes 和 Red Hat Enterprise Linux CoreOS ，这是全球领先的企业级 Linux 版本，专为基于容器的工作负载而设计。OpenShift 是 Cloud 原生计算基金会（ CNCF ）认证 Kubernetes 计划的一部分，可为容器工作负载提供可移植性和互操作性。</block>
  <block id="b2b7104a419a54dcb2763bddc6a0a47c" category="section-title">Red Hat OpenShift 提供以下功能：</block>
  <block id="16c321ec2744799f0acef92ce84d06ca" category="paragraph"><block ref="16c321ec2744799f0acef92ce84d06ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe8c2f8039053e077a0ca678496b72aa" category="section-title">Red Hat OpenShift 的部署方法</block>
  <block id="ec55e5ffb2376dada4b2eb066c1fd9fd" category="section-title">Red Hat OpenShift 的 IPI 安装</block>
  <block id="a91a379e59fea6610134af1efa3dfe87" category="paragraph">OpenShift 的安装程序配置基础架构（ IPI ）部署涉及以下高级步骤：</block>
  <block id="d1befa03c79ca0b84ecc488dea96bc68" category="inline-link">网站</block>
  <block id="cc66c30273a9be504b88d3239e65516b" category="paragraph"><block ref="cc66c30273a9be504b88d3239e65516b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86b43786316d35748685c4f7abc4145b" category="paragraph"><block ref="86b43786316d35748685c4f7abc4145b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">安装说明</block>
  <block id="220887aee59c37fa79fc366cba7dad4e" category="section-title">经过 NetApp 验证的 OpenShift 部署</block>
  <block id="aa9095c5ba77e3549672e5c4fae1fedc" category="inline-link-macro">裸机上的 OpenShift</block>
  <block id="fecab6277bc7322982f127ce83dee308" category="list-text"><block ref="fecab6277bc7322982f127ce83dee308" category="inline-link-macro-rx"></block></block>
  <block id="5f6a8f3661e7319797d4eab6792350e6" category="inline-link-macro">基于 Red Hat OpenStack 平台的 OpenShift</block>
  <block id="ff3de63c4917b45d20525986d5b29962" category="list-text"><block ref="ff3de63c4917b45d20525986d5b29962" category="inline-link-macro-rx"></block></block>
  <block id="f88eb30a75027b557910958c7306cb4e" category="inline-link-macro">基于 Red Hat 虚拟化的 OpenShift</block>
  <block id="92fb5c16a9f212d49c0c5fb48ebc9144" category="list-text"><block ref="92fb5c16a9f212d49c0c5fb48ebc9144" category="inline-link-macro-rx"></block></block>
  <block id="2772c11e552b243e60a34490c4174ff9" category="inline-link-macro">VMware vSphere 上的 OpenShift</block>
  <block id="83fc4dbe543f82a9e50bc1bd4c74fb70" category="list-text"><block ref="83fc4dbe543f82a9e50bc1bd4c74fb70" category="inline-link-macro-rx"></block></block>
  <block id="943dbb8750d636d9918af903ac016c0e" category="summary">NetApp 拥有多个存储平台，这些平台符合 Trident Storage Orchestrator 的要求，可为 Red Hat OpenShift 上部署的应用程序配置存储。</block>
  <block id="0186ffea1bd2c7ff6458a3a619d01ea2" category="paragraph"><block ref="0186ffea1bd2c7ff6458a3a619d01ea2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cc957c67b836ddc993931d8d2253032" category="list-text">NetApp Cloud Volumes Service （ AWS/GCP ）和 Azure NetApp Files 可在云中提供基于文件的存储。</block>
  <block id="faad8e024544c328d584c28118fb4102" category="list-text">NetApp Element 存储系统可在高度可扩展的环境中提供基于块的（ iSCSI ）用例。</block>
  <block id="85a240011ba49404bf70606e37c41c96" category="paragraph">以下页面介绍了有关已在 Red Hat OpenShift with NetApp 解决方案中验证的 NetApp 存储系统的追加信息：</block>
  <block id="3a374bfcdd912b5071f863e2b9f0eefa" category="list-text"><block ref="3a374bfcdd912b5071f863e2b9f0eefa" category="inline-link-macro-rx"></block></block>
  <block id="70b44fe3d3567f3f2a5ccd67ff8ac852" category="list-text"><block ref="70b44fe3d3567f3f2a5ccd67ff8ac852" category="inline-link-macro-rx"></block></block>
  <block id="eeaa3ef2816f113fd1978b036eefc4a4" category="doc">解决方案验证和使用情形：采用 NetApp 的 Red Hat OpenShift</block>
  <block id="9e766e668731b912ea84be747f0d6b4b" category="paragraph">此页面上提供的示例包括解决方案验证以及采用 NetApp 的 Red Hat OpenShift 的用例。</block>
  <block id="6f60a8e202d6d4f297230695ffa9c1a6" category="inline-link-macro">部署具有永久性存储的 Jenkins CI/CD 管道</block>
  <block id="20b131c747c2ab8c4c617107b04dfe76" category="list-text"><block ref="20b131c747c2ab8c4c617107b04dfe76" category="inline-link-macro-rx"></block></block>
  <block id="e85b6a5686bf01c916e1c3b442e8db44" category="inline-link-macro">在使用 NetApp 的 Red Hat OpenShift 上配置多租户</block>
  <block id="29a3155f4e27ac61f0e6d1e00866c981" category="list-text"><block ref="29a3155f4e27ac61f0e6d1e00866c981" category="inline-link-macro-rx"></block></block>
  <block id="781cf19a6329e508987456098cde8c79" category="list-text"><block ref="781cf19a6329e508987456098cde8c79" category="inline-link-macro-rx"></block></block>
  <block id="ddb9608f0f25d56d00a539a63333efa0" category="list-text"><block ref="ddb9608f0f25d56d00a539a63333efa0" category="inline-link-macro-rx"></block></block>
  <block id="7cd95c816f8a04ff858a857e3e5a484d" category="cell">20.04</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">容器编排</block>
  <block id="9fc7e91d0cfa196bee652e5b3ab8991b" category="doc">解决方案验证</block>
  <block id="3a724344bfc1b086a678d66814f20dd7" category="summary">本节介绍了与 Jenkins 部署持续集成和持续交付或部署管道以验证解决方案运行的步骤。</block>
  <block id="b830a759b7bbee23da50f11979fb8f27" category="doc">部署采用永久性存储的 Jenkins CI/CD 管道：采用 NetApp 的 Red Hat OpenShift</block>
  <block id="ff587ce314d6f90660779e9d75cafe53" category="paragraph">本节介绍了与 Jenkins 部署持续集成 / 持续交付或部署（ CI/CD ）管道以验证解决方案运行的步骤。</block>
  <block id="9eb8af4dd2c3557a24b914601b6ae465" category="section-title">创建 Jenkins 部署所需的资源</block>
  <block id="93b3852e5c67975dd33b1769b24a4a85" category="paragraph">要创建部署 Jenkins 应用程序所需的资源，请完成以下步骤：</block>
  <block id="9fd493573e73cb0e5e55e97306249596" category="list-text">创建一个名为 Jenkins 的新项目。</block>
  <block id="5690195262fb589b6021733b4a5a4432" category="paragraph"><block ref="5690195262fb589b6021733b4a5a4432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9db9f308c8ed7f5d0ed0851d8d605cb" category="paragraph"><block ref="f9db9f308c8ed7f5d0ed0851d8d605cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9272f40a21ca3dad814c4e3886b40776" category="section-title">使用永久性存储部署 Jenkins</block>
  <block id="939a7b51bfb262627185af768c3c1024" category="paragraph">要使用永久性存储部署 Jenkins ，请完成以下步骤：</block>
  <block id="bc5512ef7a17a0cfb58cb1ede30a6137" category="paragraph"><block ref="bc5512ef7a17a0cfb58cb1ede30a6137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6baa4bd25992de2d17278ade0d3090ad" category="list-text">单击 `实例化模板` 。</block>
  <block id="949381804bf1e16ca04ba9ac5fabc6a4" category="paragraph"><block ref="949381804bf1e16ca04ba9ac5fabc6a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7b4a6da6ab2733552de61d67b38a39e" category="list-text">默认情况下，系统会填充 Jenkins 应用程序的详细信息。根据您的要求，修改参数并单击创建。此过程将创建支持 OpenShift 上的 Jenkins 所需的所有资源。</block>
  <block id="cc9a211dac876290bd6ed039cf1afdcf" category="paragraph"><block ref="cc9a211dac876290bd6ed039cf1afdcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="274c247b7612630006e3d87d5ed5d46f" category="paragraph"><block ref="274c247b7612630006e3d87d5ed5d46f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="paragraph"><block ref="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="paragraph"><block ref="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9359288fc248319fa9acef62e4686d1c" category="paragraph"><block ref="9359288fc248319fa9acef62e4686d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00713894c16827219fd5ab50c5fc3794" category="paragraph"><block ref="00713894c16827219fd5ab50c5fc3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24f99be3c7033ab08c3baec1cdf32702" category="paragraph"><block ref="24f99be3c7033ab08c3baec1cdf32702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b6fc174a3fad5c396413febe1d4ba50" category="list-text">在创建项目页面上，输入所选名称，选择管道，然后单击确定。</block>
  <block id="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="paragraph"><block ref="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dedbf53849830e8b275b69e9b98159ce" category="paragraph"><block ref="dedbf53849830e8b275b69e9b98159ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d11f84feef51515ab9fdaafb3f02f3a" category="paragraph"><block ref="1d11f84feef51515ab9fdaafb3f02f3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43d9a2fc4d89e82c869a466778811ab3" category="paragraph"><block ref="43d9a2fc4d89e82c869a466778811ab3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d256abce3dbdfed83e337956e42f60f" category="list-text">在此示例中，我们使用永久性存储部署了 Jenkins 。要支持 Jenkins 构建，请创建 PVC 。导航到 "Storage"&gt;"Persistent Volume Claim " ，然后单击 "Create Persistent Volume Claim " 。选择已创建的存储类，确保永久性卷声明名称是 Jenkins ，选择适当的大小和访问模式，然后单击创建。</block>
  <block id="da33835bff86a0b0c8be6c67dcf677bb" category="list-text">实例化 Pod 后，导航到 "Networking" （网络） &gt;"routes" （路由）。要打开 Jenkins 网页，请单击为 Jenkins 路由提供的 URL 。</block>
  <block id="0191ad3b841f8db403ec4749d571eb4b" category="list-text">单击 Build now ，在准备，构建和测试阶段触发开发。完成整个构建过程并显示构建结果可能需要几分钟的时间。</block>
  <block id="b04b355d9fc6a2e23965649ebdd0aa31" category="list-text">只要代码发生任何更改，就可以重新构建管道来修补新版本的软件，从而实现持续集成和持续交付。单击 Recent Changes 以跟踪与先前版本相比的更改。</block>
  <block id="f913f3c8b073438c23eb36c9cf8237ac" category="section-title">创建虚拟机</block>
  <block id="71dd19ec5a595517b0b57750ad1a6568" category="paragraph">VM 是有状态部署，需要使用卷来托管操作系统和数据。使用 CNV 时，由于 VM 作为 Pod 运行，因此 VM 由 NetApp ONTAP 上通过 Trident 托管的 PV 提供支持。这些卷作为磁盘连接并存储整个文件系统，包括虚拟机的启动源。</block>
  <block id="e01cb9126428f7417091e42362dcb6cb" category="image-alt">创建 VM 架构</block>
  <block id="51f24796fdd958a7a4ab9fb9a1086c9a" category="paragraph">要在 OpenShift 集群上创建虚拟机，请完成以下步骤：</block>
  <block id="9b992d4161d9af3e77a9c4e35f9d7652" category="image-alt">为 VM 创建启动源</block>
  <block id="fe46fcd3bb2eadd55896f6a4e9af5b05" category="list-text">如果选定操作系统已配置启动源，则可以跳过上一步。</block>
  <block id="c119644bb97e69cc47555d48ff5ead07" category="list-text">如果要自定义虚拟机，请单击 "Customize Virtual Machine" 并修改所需的参数。</block>
  <block id="8b2c60e63de0927cca5bd9401cdd4647" category="list-text">单击 Create Virtual Machine 以创建虚拟机；此操作将在后台生成相应的 Pod 。</block>
  <block id="ba7734e1db4ae3c0a25330f01ced054d" category="paragraph">从 URL 或注册表为模板或操作系统配置启动源时，它会在 `OpenShift-virtual-os-images` 项目中创建一个 PVC ，并将 KVM 子映像下载到 PVC 。您必须确保模板 PVC 具有足够的已配置空间，以容纳相应操作系统的 KVM 子映像。然后，使用任何项目中的相应模板创建这些 PVC 时，这些 PVC 会克隆并作为根磁盘附加到虚拟机中。</block>
  <block id="4d4480c77d84881f85763c51fb0a0ebb" category="doc">视频和演示：采用 NetApp 的 Red Hat OpenShift</block>
  <block id="762a14964ee1713d320b8beefaf55b17" category="inline-link-macro">视频：安装 OpenShift 虚拟化—采用 NetApp 的 Red Hat OpenShift</block>
  <block id="aad993afc3c78a3a38ae471fa2ae1060" category="inline-link-macro">视频：使用 OpenShift 虚拟化部署虚拟机—采用 NetApp 的 Red Hat OpenShift</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">从何处查找追加信息</block>
  <block id="92637d8d513510f7c1f5bfac6e1cce9b" category="paragraph">要启用 Trident 与 NetApp ONTAP 存储系统的集成，您必须创建一个后端，以便与存储系统进行通信。</block>
  <block id="3ca99f0e09d3b1ea097a113dd72c9317" category="list-text">下载的安装归档中提供了 `sample-input` folder 层次结构中的示例后端文件。对于提供 iSCSI 的 NetApp ONTAP 系统，将 `backend-ontap-san.json` 文件复制到您的工作目录并编辑该文件。</block>
  <block id="fa346018b8222fdc195d0b73016cf5a0" category="list-text">编辑此文件中的 managementLIF ， dataLIF ， SVM ，用户名和密码值。</block>
  <block id="38ace6c607c7db13cd4cc319f9b0225b" category="list-text">安装此后端文件后，运行以下命令以创建第一个后端。</block>
  <block id="8e0bd613649f232fe1f718134898ea21" category="paragraph">要启用 Trident 与 NetApp ONTAP 存储系统的集成，您必须创建一个后端，以便与存储系统进行通信。</block>
  <block id="89441fb0b16307f49090afa2b479b9fa" category="list-text">下载的安装归档中提供了 `sample-input` folder 层次结构中的示例后端文件。对于提供 NFS 的 NetApp ONTAP 系统，将 `backend-ontap-nas.json` 文件复制到您的工作目录并编辑该文件。</block>
  <block id="87f6ff6bf74013e1dfe6df49a1cf1986" category="list-text">编辑 backendName ， managementLIF ， dataLIF ， SVM ，用户名， 和密码值。</block>
  <block id="00d6947fd6a153943286b857dcd0f339" category="admonition">此文件中定义了一个名为 `FSType` 的可选字段。可以在 NFS 后端删除此行。</block>
  <block id="648bdcd0b9a0f83d7b068dbed3c21c07" category="doc">设计注意事项</block>
  <block id="254f642527b45bc260048e30704edb39" category="doc">Configuration</block>
  <block id="44b1200b793638d4a3aebd1bee591e12" category="paragraph">对于任何多租户解决方案，任何用户都无法访问比所需更多的集群资源。因此，要在多租户配置中配置的整个资源集将在集群管理员，存储管理员和处理每个项目的开发人员之间进行划分。</block>
  <block id="1ceba10f8902735a18e8c3bb3e8a3052" category="paragraph">下表概括了不同用户要执行的不同任务：</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">Role</block>
  <block id="ef615563c8e8ea902c7fcac3cd2c4246" category="cell">任务</block>
  <block id="064dceba374668ef0734be5f9e182682" category="cell">* 集群管理 *</block>
  <block id="e033ab3bea3b8a20afb5852070df0203" category="cell">为 storage-admin 创建 ClusterRoles 和 RoleBindings</block>
  <block id="293d08622718634a8518b6fcc6376617" category="cell">为分配对特定项目的访问权限的开发人员创建角色和角色绑定</block>
  <block id="3e97e469255cd3686174c371f50961f9" category="cell">[ 可选 ] 配置项目以在特定节点上计划 Pod</block>
  <block id="93ffd2b1215bc47cc78b020f89e922ef" category="cell">* 存储管理 *</block>
  <block id="043ab42cdcbdacc4691c26ee52ed8ccd" category="cell">在 NetApp ONTAP 上创建 SVM</block>
  <block id="be09a24f118a66330a40633e9d5ebfca" category="cell">创建 Trident 后端</block>
  <block id="55995e8c220e05b3e75252cccf5752be" category="cell">创建 StorageClasses</block>
  <block id="2a5eb41b2d7fd04d01836f89ab790852" category="cell">创建存储 ResourceQuotas</block>
  <block id="4e00898ecc4e6640083ccff8d85fbe87" category="cell">* 开发人员 *</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">硬件要求</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">软件要求</block>
  <block id="bfd15aa26ba0ced782240c4a8b7e517e" category="cell">存储管理</block>
  <block id="98f770b0af18ca763421bac22b4b6805" category="section-title">功能</block>
  <block id="2c65eb4e4300c763b9d8ffcdc45660fc" category="paragraph">要安装 OpenShift 虚拟化，请完成以下步骤：</block>
  <block id="bb761e1ed8ef4412cddb399e81488f83" category="list-text">使用 cluster-admin 访问权限登录到 Red Hat OpenShift 裸机集群。</block>
  <block id="3f4b86cf3e8a535371d3937bd126d789" category="list-text">从 "Perspective" 下拉列表中选择 "Administrator" 。</block>
  <block id="78146e6a44100deebbe276c19e6c437a" category="image-alt">OpenShift 操作员中心</block>
  <block id="016a229c1180d24870be44f7391c5678" category="list-text">选择 OpenShift 虚拟化磁贴，然后单击安装。</block>
  <block id="fe87c9ebb6d1db5af643c2101dd83c2d" category="image-alt">OpenShift 虚拟化操作员图块</block>
  <block id="d2770f20a312c7d906cf3d8a97d335a2" category="list-text">在 Install Operator 屏幕上，保留所有默认参数，然后单击 Install 。</block>
  <block id="66b5ae84d6c0a470bb131b7aeb63f734" category="image-alt">OpenShift 虚拟化操作员详细信息</block>
  <block id="5f27d84a5a158e75ab7ac4543ca7c1be" category="image-alt">OpenShift 虚拟化操作员安装</block>
  <block id="49598c5badb95e31a9894d5dc277f301" category="list-text">安装操作员后，单击 Create HyperConverged 。</block>
  <block id="f63ea68253a91a92e8afb2e42bf0fb36" category="image-alt">OpenShift 虚拟化操作员—创建超融合</block>
  <block id="0e4308133099865567bc6a19f0abcb88" category="list-text">在 Create HyperConverged 屏幕上，单击 Create ，接受所有默认参数。此步骤将开始安装 OpenShift 虚拟化。</block>
  <block id="c57b56755457ec355801b1e17915fc47" category="image-alt">OpenShift 虚拟化操作员—超融合详细信息</block>
  <block id="ee0ffac6ee8f4e224a044d95e68aa30d" category="list-text">在 OpenShift-cnv 命名空间中的所有 Pod 都变为 running 状态且 OpenShift 虚拟化操作员处于 succeeded 状态后，操作员便可随时使用了。现在，可以在 OpenShift 集群上创建 VM 。</block>
  <block id="423e88e20ace3dbca3f9d5bd3b109cef" category="image-alt">OpenShift 虚拟化操作员安装完成</block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">结论</block>
  <block id="86c2cc4630e619e2c08c32f54e844297" category="section-title">在多个集群上创建资源</block>
  <block id="24800112d59462f8ea9ff03f5dd456a7" category="image-alt">创建资源</block>
  <block id="67a3852a946bc539243cc1e5f8982d03" category="section-title">裸机上的 OpenShift 可提供以下功能：</block>
  <block id="096e71732ebcd1f43544a7159596cb17" category="paragraph"><block ref="096e71732ebcd1f43544a7159596cb17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb18861dc375756df1a31b7ed3c03f38" category="paragraph"><block ref="bb18861dc375756df1a31b7ed3c03f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5a0639a1bbc3695e0ebaf4c3affe363" category="paragraph">采用 NetApp 解决方案的 Red Hat OpenShift 可通过使用虚拟局域网（ VLAN ）在逻辑上隔离不同用途的网络流量。</block>
  <block id="3d9073c9e531118eb3aff0f20647c86f" category="cell">管理裸机节点和 IPMI</block>
  <block id="44a94f76baabd05ab407f76c946326c8" category="cell">集群可用后用于 OpenShift 服务的网络</block>
  <block id="846325c36d78e7582d8bfcab277ca67a" category="cell">通过 IPI 以 PXE 启动和安装裸机节点的网络</block>
  <block id="cb8e8e87ec9c630a0a27910fe29abceb" category="summary">RHV 是一个企业级虚拟数据中心平台，运行在 Red Hat Enterprise Linux （ RHEL ）上，并使用 KVM 虚拟机管理程序。</block>
  <block id="603bc85f6f6f4d9e5095745d9252f1d3" category="inline-link">Red Hat 虚拟化网站</block>
  <block id="01b0ee840ef208c283c3f4e959aa9427" category="paragraph"><block ref="01b0ee840ef208c283c3f4e959aa9427" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d7e48e226974692ed3f522a2baef6db" category="paragraph">RHV 上的 Red Hat OpenShift 旨在通过使用虚拟局域网（ VLAN ）在逻辑上隔离不同用途的网络流量。此配置可以进行扩展，以满足客户需求，或者为特定网络服务提供进一步隔离。下表列出了在 NetApp 验证解决方案时实施解决方案所需的 VLAN 。</block>
  <block id="3083202a936b7d0ef8b680d7ae73fa1a" category="cell">3344</block>
  <block id="7e4be32047fe5b09a23fd956cd4e82f0" category="section-title">将 OpenShift 部署到至少包含三个节点的 RHV 集群</block>
  <block id="de4e964e7be880b328384cfedd5873d9" category="paragraph">本文档中介绍的经验证的架构介绍了适用于 HA 操作的最低硬件部署，具体方法是部署两个 RHV-H 虚拟机管理程序节点，并确保采用容错配置，两个主机均可管理托管引擎，而已部署的虚拟机可在两个虚拟机管理程序之间迁移。</block>
  <block id="b98f17dd49fc6d1c2a9b58922fae2686" category="paragraph">您可以通过启用虚拟机 / 主机关联性在多个虚拟机管理程序节点之间分布 OpenShift 主节点。</block>
  <block id="df1b58247681ba5f974a572d530dbdf9" category="paragraph">关联性是一种为一组 VM 和 / 或主机定义规则的方法，用于确定这些 VM 是在组中的同一主机上运行还是在不同主机上运行。它通过创建由具有一组相同参数和条件的 VM 和 / 或主机组成的关联组来应用于 VM 。根据关联组中的 VM 是在组中的同一主机上运行，还是在不同主机上单独运行，此关联组的参数可以定义正关联性或负关联性。</block>
  <block id="5c00bc5cb1bdae240d18551e77806abd" category="inline-link">Red Hat 6.11 。关联性组文档</block>
  <block id="1050f3dc9e3ee559789e3b25f2e4f77e" category="inline-link">Red Hat OpenShift 通过自定义在 RHV 上安装集群</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">技术要求</block>
  <block id="ff94444190436ee7694d15be2dde0f29" category="list-text">NetApp ONTAP 存储集群</block>
  <block id="b645e117fe786bf56128cde2dec3971a" category="list-text">Red Hat OpenShift 集群</block>
  <block id="0d46ef98dfe52c8d01c0c5ace93d8165" category="section-title">Red Hat OpenShift —集群资源</block>
  <block id="c4ff2177ae2f8ed9c3e5353068cf2195" category="section-title">Red Hat OpenShift —存储资源</block>
  <block id="06dc93ff20817f0d5fb8a07f8e43d6cb" category="doc">部署摘要</block>
  <block id="7652dcfa1608f7891f4e5c9b462354be" category="paragraph">为了应对这一挑战， Red Hat 从 OpenShift 4.6 版开始引入了 OpenShift 虚拟化（以前称为容器原生虚拟化）。通过 OpenShift 虚拟化功能，您可以在同一 OpenShift 容器平台安装中运行和管理虚拟机以及容器，从而提供混合管理功能，通过操作员自动部署和管理 VM 。除了使用 OpenShift 虚拟化在 OpenShift 中创建 VM 之外， Red Hat 还支持从 VMware vSphere ， Red Hat 虚拟化和 Red Hat OpenStack Platform 部署导入 VM 。</block>
  <block id="269bac1ed5128eacc45c06318333642a" category="image-alt">OpenShift 虚拟化</block>
  <block id="8a5bcb32f7cb878beee68d6f84b3ada7" category="paragraph">要了解有关 Red Hat OpenShift 虚拟化的详细信息，请参见相关文档<block ref="3339eb5909b80aa35681f9f3f9478c17" category="inline-link-rx"></block>。</block>
  <block id="ad8905a47eb465223ebe7acf569732b1" category="doc">配置： cluster-admin 任务</block>
  <block id="552eab1d1ea09d0d1733b97dee6609a1" category="paragraph">Red Hat OpenShift cluster-admin 执行以下任务：</block>
  <block id="8a4ffd494b5e8af3ac1be2cd9ab254fb" category="list-text">以 cluster-admin 身份登录到 Red Hat OpenShift 集群。</block>
  <block id="7ccd4d72e4addf5c27c53bafaeb3fdbd" category="list-text">创建两个与不同项目对应的项目。</block>
  <block id="6c98bfb16f2e9bbebd943c1f8592306d" category="list-text">为 project-1 创建开发人员角色。</block>
  <block id="3c73122271c9219b54ca745b732adc28" category="list-text">同样，为 project-2 创建开发人员角色。</block>
  <block id="7428df2e0e503f4cabb43a4667bc1983" category="list-text">所有 OpenShift 和 NetApp 存储资源通常由存储管理员管理。存储管理员的访问由安装 Trident 时创建的 Trident 操作员角色控制。此外，存储管理员还需要访问 ResourceQuotas 来控制存储的使用方式。</block>
  <block id="36e36b60ddb8f46fe0b9b4e8f4dce56f" category="list-text">为存储管理员配置 ClusterRoleBindings 。</block>
  <block id="ced38b1f1c19446862c601754b82b94c" category="list-text">为开发人员创建 RoleBindings ，将开发人员项目 1 角色绑定到项目 1 中的相应组（ OCP-project-1 ）。</block>
  <block id="2aa292f2ff8b13fe141ca55c27bc29c2" category="list-text">同样，为开发人员创建 RoleBindings ，将开发人员角色绑定到 project-2 中的相应用户组。</block>
  <block id="d008c60ddb28c0bbad1dfabdd77327fc" category="doc">配置： storage-admin 任务</block>
  <block id="6c0ed744c737f30af364d229639c8288" category="paragraph">存储管理员必须配置以下资源：</block>
  <block id="64244866ddff81ded5e6aaa49055c6aa" category="list-text">以管理员身份登录到 NetApp ONTAP 集群。</block>
  <block id="3f8bc17bf8dd138aa2915235f0a9c0d3" category="image-alt">在 ONTAP 上创建 SVM</block>
  <block id="c9bd46366e9fb78552566f1e7a13633a" category="list-text">为 project-1 创建后端，并将其映射到专用于该项目的 SVM 。NetApp 建议使用 SVM 的 vsadmin 帐户将后端连接到 SVM ，而不是使用 ONTAP 集群管理员。</block>
  <block id="4a6c648106c1ff38316705bf986de601" category="list-text">同样，为 project-2 创建 Trident 后端，并将其映射到专用于 project-2 的 SVM 。</block>
  <block id="9a45d41277a2e8ce29709826a31fb482" category="list-text">接下来，创建存储类。为 project-1 创建存储类，并通过设置 storagePools 参数将其配置为使用后端专用于 project-1 的存储池。</block>
  <block id="4350d40426f8c94f6ca046609969adb2" category="list-text">同样，为 project-2 创建一个存储类，并将其配置为使用专用于 project-2 的后端存储池。</block>
  <block id="2ee847ebe129ae778860d6dd2da21cf6" category="list-text">创建 ResourceQuota 以限制 project-1 中的资源，从而从专用于其他项目的存储库请求存储。</block>
  <block id="c689ae18a0f5e47541dcec4afb6e187a" category="list-text">同样，也可以创建 ResourceQuota 来限制项目 2 中的资源，以便从专用于其他项目的存储库请求存储。</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="doc">解决方案组件</block>
  <block id="f41043c73a62a435944d8abfb45094cb" category="list-text">适用于受管集群的 Red Hat OpenShift 集群（高于 4.5.3 版）</block>
  <block id="374185e020d06ceed3f020af518a1c14" category="list-text">适用于 Kubernetes 的 Red Hat 高级集群管理订阅</block>
  <block id="9afcd045ce0197d71ba631e3fbe43095" category="paragraph">高级集群管理是 OpenShift 集群的一个附加功能，因此，根据在集线器和受管集群中使用的功能，硬件资源具有某些要求和限制。在对集群进行规模估算时，您需要考虑这些问题。请参见文档<block ref="a5d2b81b971715f092f7296621743e22" category="inline-link-rx"></block> 有关详细信息：</block>
  <block id="65a62318377ddbc5fe3f73548dc3d677" category="paragraph">或者，如果集线器集群具有专用节点来托管基础架构组件，并且您希望仅在这些节点上安装高级集群管理资源，则需要相应地为这些节点添加容错和选择器。有关详细信息，请参见文档<block ref="df4d7b25534e8f26e8ab3acc1c646101" category="inline-link-rx"></block>。</block>
  <block id="03cae7751c31cc76a90cf5e94e86eb3a" category="section-title">监管和风险</block>
  <block id="9d7264067197bc9ff368288f98750fd6" category="paragraph">通过此功能，您可以为不同的集群定义合规性策略，并确保集群遵循此策略。您可以对策略进行配置，以通知或修复任何规则偏差或违规行为。</block>
  <block id="f6262e5369e2b989638aaa9d4f333d91" category="image-alt">创建合规性策略</block>
  <block id="0a1575621f2b12d5216e6d1c95eed2e6" category="list-text">配置完所有必需的策略后，可以通过高级集群管理监控和修复任何策略或集群违规。</block>
  <block id="38c080ff2128a92954fb61942ea497c0" category="image-alt">策略监控</block>
  <block id="4b6826f4f20a8e7e7a3b42ccb81d514f" category="section-title">VM 克隆</block>
  <block id="0ea820e58acf3d0c3acac3f64518c517" category="image-alt">VM 克隆架构</block>
  <block id="a1dbf280b3b5da141010127710d68ba7" category="paragraph">要考虑 CSI 卷克隆的某些限制：</block>
  <block id="7f8cb9ac957166d3d134bf9df8861f5b" category="list-text">源 PVC 和目标 PVC 必须位于同一项目中。</block>
  <block id="058d8141e417cb514573ba1a70e2e0cd" category="list-text">在同一存储类中支持克隆。</block>
  <block id="611b1b227968093cc5c73e69f7ac0fda" category="list-text">只有当源卷和目标卷使用相同的卷模式设置时，才能执行克隆；例如，一个块卷只能克隆到另一个块卷。</block>
  <block id="557d036c1a69ab0889c0820deb1e88de" category="paragraph">可以通过两种方式克隆 OpenShift 集群中的 VM ：</block>
  <block id="e1230e5b1f51d793ea14fb31df500399" category="list-text">关闭源 VM</block>
  <block id="29ec5d7b455e19c4f8141df877a9af0a" category="list-text">使源 VM 保持活动状态</block>
  <block id="84d19f7437a8329c49099517eccd37dc" category="section-title">关闭源 VM</block>
  <block id="375000776ee4694734b1d066c46e7096" category="list-text">单击克隆虚拟机并提供新虚拟机的详细信息。</block>
  <block id="b22c43b0906ef8ba78f3fbb7d5b1ff20" category="image-alt">克隆虚拟机</block>
  <block id="cf702a835a3fd4b019603d29ec402106" category="list-text">单击克隆虚拟机；此操作将关闭源 VM 并启动克隆 VM 的创建。</block>
  <block id="82cfb538b52ee01d4a9901d4d2cfad4d" category="list-text">完成此步骤后，您可以访问并验证克隆的虚拟机的内容。</block>
  <block id="3c7aa222cd4c9ee079b31567a347c05f" category="paragraph">也可以通过克隆源 VM 的现有 PVC ，然后使用克隆的 PVC 创建新 VM 来克隆现有 VM 。此方法不需要关闭源 VM 。要克隆虚拟机而不关闭它，请完成以下步骤。</block>
  <block id="545ce69617c1c157be6073dcc63bfbae" category="list-text">单击克隆 PVC 并提供新 PVC 的详细信息。</block>
  <block id="e659422cf737778a2fb1cdd50cc8003e" category="image-alt">克隆 PVC</block>
  <block id="07c24ffdbaf9583216cca9f030058c11" category="list-text">然后单击克隆。这样就会为新虚拟机创建一个 PVC 。</block>
  <block id="19e005e0709674157e554800d5ea7ef9" category="list-text">成功创建 VM 后，访问并验证新 VM 是否为源 VM 的克隆。</block>
  <block id="b2f35a84b813ef160b585d350d2fcd58" category="summary">在裸机上使用 Anthos 与硬件无关的功能，您可以选择针对您的用例优化的计算平台。因此，您可以匹配现有基础架构并减少资本支出。</block>
  <block id="5f95fbda20eeb9ce0859afe2ac6f42fa" category="doc">解决方案要求</block>
  <block id="7d4009b9254a61f6afd71a2656a3a78f" category="section-title">计算：自带服务器</block>
  <block id="dee41946d9d6ca32131352cb4374f12b" category="paragraph">下表列出了实施此解决方案所需的最低计算硬件组件数量，尽管所使用的硬件型号可能因客户要求而异。</block>
  <block id="c64518704ce0c0d5501a45763f464276" category="cell">使用情况</block>
  <block id="602f72fff77475a16eff159759656261" category="cell">硬件和型号</block>
  <block id="06e9950a2c1bb489cf54d03d4547e913" category="cell">管理节点</block>
  <block id="b349dcffed4594674c8ce6c91e72e42f" category="cell">Cisco UCS B200</block>
  <block id="fcb81a84511da525a1581c4ccc00d0fb" category="cell">工作节点</block>
  <block id="4867cc2ab4385d91c3a36d6ace67a984" category="cell">HP ProLiant DL360</block>
  <block id="2c0b20f0fbc047d58ca10a50c6a32bc7" category="section-title">存储： NetApp ONTAP</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF</block>
  <block id="eb8440af98c502b8095408e970297e6b" category="cell">NetApp AFF A300</block>
  <block id="e8d610d6c2d243856beaade33b5aa123" category="cell">2 个（ 1 个 HA 对）</block>
  <block id="b6ce11f078022a4ab598b8016db52a13" category="paragraph">下表中标识的软件版本由 NetApp 和我们的合作伙伴使用，用于向 NetApp 验证解决方案，但所使用的软件组件可能因客户要求而异。</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="128b9c7509f09d8ff4b08e87def0ac74" category="cell">操作系统位于 3 个管理员上</block>
  <block id="836a05a21ac6df3b6bcf9838895b017e" category="cell">基于 Worker4 的操作系统</block>
  <block id="bbd243e896202aa0eb00ce19d8a7fea8" category="cell">基于 Worker3 的操作系统</block>
  <block id="4077fabc9a8b0e761cfd9bf752e03c8a" category="cell">18.04</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="aaad0494526f271ca02ebd06a79e7382" category="cell">基于 Worker2 的操作系统</block>
  <block id="2a568439f8e6ff92daa9925ce8a03adf" category="cell">8.2</block>
  <block id="7ac53708026d8515ce15cc154e95f46b" category="cell">基于 Worker1 的操作系统</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="ca9f0d77f73d954e88e6ab43539ac7cb" category="cell">1.6.0</block>
  <block id="ea704238343d48baa3a08f039015185f" category="cell">存储 OS</block>
  <block id="f33749dd101d316dcf2e6953732629f9" category="cell">9.7P8.</block>
  <block id="8fe1ffd8f7dcf339dd4f34aabb6e1c99" category="cell">容器存储管理</block>
  <block id="a84024ce06ef98519b3b51300b2c8fbf" category="cell">20.10</block>
  <block id="d94e09dc1956d9513e690f8d24852f05" category="inline-link">裸机文档上的 Anthos</block>
  <block id="ae6f5747bf29f889c1d28208afab2a1a" category="doc">部署应用程序</block>
  <block id="cef52206f11ced919c8d0dd4b2c791a4" category="paragraph">以下各节介绍了如何安装和部署应用程序。</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="doc">致谢</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">NetApp 技术营销工程师 Mike Oglesby</block>
  <block id="94a8512f59eafd68b470105fc3269fd4" category="list-text">NetApp 高级技术总监 Santosh Rao</block>
  <block id="bd3114e9e2000f42e265a067e98b0d25" category="doc">以履行引擎的形式连接到第三方 API</block>
  <block id="1aea646cd3c044dd0758af18e73cfef3" category="paragraph">我们将以下第三方 API 作为履行引擎连接到问题解答问题：</block>
  <block id="94c494471216991658782a32f1e3ef37" category="inline-link">WeatherStack API</block>
  <block id="f7eb24e530470f21243c27770bd2c549" category="list-text"><block ref="c8600f69e922164a09610e481537b92d" category="inline-link-rx"></block>：返回给定位置的天气，温度，雨和雪。</block>
  <block id="1c96228fa1453bf3f691d5081cbd6adb" category="inline-link">Yelp Fusion API</block>
  <block id="55a3b552be8202b066ea237b831186f4" category="list-text"><block ref="8af0de0530d799485b6d6a2d146ab784" category="inline-link-rx"></block>：返回给定位置中最接近的存储信息。</block>
  <block id="114e8180b93cb1b21cd00067e446e5f0" category="inline-link">eBay Python SDK</block>
  <block id="da6816adc86546982065d9aef78845e5" category="list-text"><block ref="3d046b40b6d382ee41dd02d3b6ab007c" category="inline-link-rx"></block>：返回给定项目的价格。</block>
  <block id="e88a70d67e9de42d391fd019f2d06484" category="summary">要了解有关本文档所述信息的更多信息，请查看以下文档和网站。</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="doc">追加信息</block>
  <block id="b49efd5b259d6a3bceda1ebb8e34064a" category="list-text">数据集： TuSimple</block>
  <block id="61554b11b65c50bf7a094a86d699c8d5" category="inline-link"><block ref="61554b11b65c50bf7a094a86d699c8d5" category="inline-link-rx"></block></block>
  <block id="b150fd9c1d7740c871626031a398c8a3" category="paragraph"><block ref="b150fd9c1d7740c871626031a398c8a3" category="inline-link-rx"></block></block>
  <block id="a3a3504f7b11916e352125a598e15797" category="list-text">深度学习网络架构：空间对流神经网络</block>
  <block id="6467a460cb421335f9f5b0523c38c9a6" category="inline-link"><block ref="6467a460cb421335f9f5b0523c38c9a6" category="inline-link-rx"></block></block>
  <block id="35527148b08f99f1d85797af833430dc" category="paragraph"><block ref="35527148b08f99f1d85797af833430dc" category="inline-link-rx"></block></block>
  <block id="cc1881adebe7ddf5b873966741a32ef1" category="list-text">分布式深度学习培训框架： Horovod</block>
  <block id="732f85d0d5eaa9222831dd5290518ff2" category="inline-link"><block ref="732f85d0d5eaa9222831dd5290518ff2" category="inline-link-rx"></block></block>
  <block id="655c281079d0281fcf4b8f2f08634c16" category="paragraph"><block ref="655c281079d0281fcf4b8f2f08634c16" category="inline-link-rx"></block></block>
  <block id="934b1fbd011b584c4878284f454f812e" category="list-text">运行： AI 容器编排解决方案：运行： AI 产品简介</block>
  <block id="64b899832bfcad18bb426fb355a0d03b" category="inline-link"><block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="b78ec84f003a4d277e318031a163e191" category="paragraph"><block ref="b78ec84f003a4d277e318031a163e191" category="inline-link-rx"></block></block>
  <block id="275dbaaa3169640f82917075918df905" category="list-text">运行： AI 安装文档</block>
  <block id="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link"><block ref="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link-rx"></block></block>
  <block id="517046a8acf2e7fa61798debc5b6e25e" category="inline-link"><block ref="517046a8acf2e7fa61798debc5b6e25e" category="inline-link-rx"></block></block>
  <block id="b8b2e04f115b148d49a8cb477ed86af9" category="paragraph"><block ref="f03e58e4917966d9b82995c8ce69643b" category="inline-link-rx"></block><block ref="3530112fad5ba376549c9e0750df83f3" category="inline-link-rx"></block></block>
  <block id="8787c0bfc5af7ce34db56c9a5739f788" category="list-text">在运行中提交作业： AI CLI</block>
  <block id="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link"><block ref="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link-rx"></block></block>
  <block id="ca4ef6cf830a9de78ea71279d0d5417c" category="paragraph"><block ref="ca4ef6cf830a9de78ea71279d0d5417c" category="inline-link-rx"></block></block>
  <block id="984fd97f526f8afe9d2472b0894b84c2" category="inline-link"><block ref="984fd97f526f8afe9d2472b0894b84c2" category="inline-link-rx"></block></block>
  <block id="65640a241681656a4410cd7184278c9b" category="paragraph"><block ref="65640a241681656a4410cd7184278c9b" category="inline-link-rx"></block></block>
  <block id="33a756969a35b0a9029bf2a2c10e6d67" category="list-text">Azure 云资源： Azure NetApp Files</block>
  <block id="99ac98f589f6b551211f31e86cb9a212" category="inline-link"><block ref="99ac98f589f6b551211f31e86cb9a212" category="inline-link-rx"></block></block>
  <block id="3085d4407b575d4a8938814c7db17d92" category="paragraph"><block ref="3085d4407b575d4a8938814c7db17d92" category="inline-link-rx"></block></block>
  <block id="f938809a358080d4c7a941e59abfca40" category="list-text">Azure Kubernetes Service</block>
  <block id="21d0acc34f6416d6ebd8074617c57439" category="inline-link"><block ref="21d0acc34f6416d6ebd8074617c57439" category="inline-link-rx"></block></block>
  <block id="91c4b230ded9b13564b447ba71304aeb" category="paragraph"><block ref="91c4b230ded9b13564b447ba71304aeb" category="inline-link-rx"></block></block>
  <block id="d9d650693b25d0540fbb606b1d1fbe4e" category="list-text">Azure VM SKUs</block>
  <block id="08318cbecd61665ab1824d118c1029a5" category="inline-link"><block ref="08318cbecd61665ab1824d118c1029a5" category="inline-link-rx"></block></block>
  <block id="3e05fd8f7e2e0ac6116dd746a8823eaa" category="paragraph"><block ref="3e05fd8f7e2e0ac6116dd746a8823eaa" category="inline-link-rx"></block></block>
  <block id="b9a1a7c8f2194407b24183f7826d2e44" category="list-text">采用 GPU SKU 的 Azure VM</block>
  <block id="6046df9266bb79e1d99f9c232c1835e3" category="inline-link"><block ref="6046df9266bb79e1d99f9c232c1835e3" category="inline-link-rx"></block></block>
  <block id="d0bf246853f6f35070f6a8231d468c87" category="paragraph"><block ref="d0bf246853f6f35070f6a8231d468c87" category="inline-link-rx"></block></block>
  <block id="43a545df8285ba2aba289a52824f250d" category="inline-link"><block ref="43a545df8285ba2aba289a52824f250d" category="inline-link-rx"></block></block>
  <block id="944823ac69152177e369bd5d9a61a02f" category="paragraph"><block ref="944823ac69152177e369bd5d9a61a02f" category="inline-link-rx"></block></block>
  <block id="a9359a0f51034e1b1972f7690fe03f71" category="list-text">由 NetApp 提供支持的 Data Fabric</block>
  <block id="781262103885a96ffc9275431a7ef132" category="inline-link"><block ref="781262103885a96ffc9275431a7ef132" category="inline-link-rx"></block></block>
  <block id="93e35e3e458c1d81846aa83c346e240e" category="paragraph"><block ref="93e35e3e458c1d81846aa83c346e240e" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">NetApp 产品文档</block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="37e875b843ef9539c02d09d3bbee6668" category="doc">第 4.8 节的测试详细信息</block>
  <block id="638c2d891d4e85bcfae409499fba817c" category="inline-link-macro">通过过度配额 GPU 分配实现高集群利用率</block>
  <block id="d9ed812c8dd9083f1fb345425b8ce100" category="paragraph">此部分包含此部分的测试详细信息 <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>。</block>
  <block id="f354c9a7a0a52e7a5a3514252ea5f8b7" category="paragraph">按以下顺序提交作业：</block>
  <block id="9e727fdd3aec8274f46685441900280d" category="cell">项目</block>
  <block id="b3428404a5be1cf95d4e53b2ddc8288a" category="cell">GPU 数量</block>
  <block id="96b0141273eabab320119c467cdcaf17" category="cell">总计</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">comment</block>
  <block id="9320270de4ff6824ae7a21f729fb7d44" category="cell">团队 A</block>
  <block id="c6e328a3639bc00374d81e681f89f609" category="cell">Jupyter</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1.</block>
  <block id="ff8bed43ac09b1148fc7648f5845f698" category="cell">1 ， 4</block>
  <block id="37ce74088416f28dc9bb04355c2e5a28" category="cell">–</block>
  <block id="cfaa375bf6c7f9fcc1bc04d4f30c9154" category="cell">NetApp</block>
  <block id="6408e079aefee9702aa00f77228dd941" category="cell">2 ， 4</block>
  <block id="00833fac70036c049bd75443869cacb5" category="cell">运行： AI</block>
  <block id="36d2df43ead992a1e3c86acd0cec69f9" category="cell">4.4</block>
  <block id="d2313e844e73fe4a8f63d93f4df355fc" category="cell">正在使用其所有配额</block>
  <block id="238ff8d9192e9c01e50a8d6d21f1607b" category="cell">团队 b</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="e4275e3860ed32f489dbb6a5d4a10f5f" category="cell">0.6/2</block>
  <block id="8457d97e0a0f74a5926d1dee27e53541" category="cell">GPU 百分比</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="975ca8804565c1a569450d61090b2743" category="cell">1.2</block>
  <block id="867c7d7d65c50ae3679fabce2eab87a3" category="cell">2/2</block>
  <block id="c3a4885d143dc5b306446fb380c6cfda" category="cell">4/2</block>
  <block id="411472b1216ec08457e653eac42d7bbd" category="cell">两个超过配额</block>
  <block id="3b40d1328b825dda4b761a8e534669b7" category="cell">团队 c</block>
  <block id="d310cb367d993fb6fb584b198a2fd72c" category="cell">0.5</block>
  <block id="76169512ef5ca1abe70b32c0993856af" category="cell">0.5/2</block>
  <block id="e85b79abfd76b7c13b1334d8d8c194a5" category="cell">0 ， 3.</block>
  <block id="5c2b079fc9750c2995852b8fb354aae3" category="cell">0.8/2</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="00fd1da21e8b4ef31d987665dc575099" category="cell">3/2</block>
  <block id="0375b76ff57435094e28e94015a5f052" category="cell">一个超过配额</block>
  <block id="ae7ccf7b1a6a1a023f611a294572a900" category="cell">团队</block>
  <block id="ecdb9acc2db02134680a9c49abe3e991" category="cell">4 ， 8.</block>
  <block id="30c006c71ada68e2273b128bc2e6831b" category="cell">正在使用配额的一半</block>
  <block id="36cf0dc9f04c54214fa577ec66ff53fc" category="paragraph">命令结构：</block>
  <block id="7b3a4ccf5e0cc7918cd458f7e46b9c8e" category="paragraph">测试中使用的实际命令顺序：</block>
  <block id="3bf38f884fd74f6e6f1ec3d80018edd8" category="paragraph">此时，您应处于以下状态：</block>
  <block id="e55f05703a3e04fbd9e10f76ae925cc9" category="cell">已分配 GPU</block>
  <block id="26cc9c6ccae01f319282379c339cd90b" category="cell">已排队的工作负载</block>
  <block id="478eb1c4e698b325048b6bccfb8974f6" category="cell">4/4 （软配额 / 实际分配）</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="cell">无</block>
  <block id="2df6f557cc57e6d4044b9611b1f56439" category="inline-link-macro">通过过度分配 GPU 实现高集群利用率</block>
  <block id="3667ebc7f28f59fc13bfcf314c67de05" category="paragraph">请参见一节 <block ref="dee5d16c649661a62d3a765af5b1a963" category="inline-link-macro-rx"></block> 用于讨论继续测试场景。</block>
  <block id="1e92efa8f46c28a3c3a1c03ababfa7be" category="doc">NetApp 零售助理演示</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">此链接。</block>
  <block id="088070f65f454d6b38e8e40e332e70a8" category="paragraph"><block ref="088070f65f454d6b38e8e40e332e70a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f7f6c0b1054487e622896990b1d6d55" category="doc">TR-4841 ：采用数据缓存的混合云 AI 操作系统</block>
  <block id="1b55e21d5b19a6ba57ae9bbd6f3a0630" category="paragraph">Rick Huang ， David Arnette ， NetApp Ychay Ettun ， cnvrg.io</block>
  <block id="28d9fd6fa10254fdcc59aa182ae32dc9" category="paragraph">数据的爆炸式增长以及 ML 和 AI 的指数级增长已经融合在一起，形成了一个具有独特开发和实施挑战的超字节经济。</block>
  <block id="eb35f773ff882afb6d6d67613a4701ee" category="paragraph">尽管众所周知， ML 模型需要大量数据，并且需要接近计算资源的高性能数据存储，但在实践中，实施这种模型并不是那么直接，尤其是在混合云和弹性计算实例中。大量数据通常存储在低成本数据湖中， GPU 等高性能 AI 计算资源无法高效访问这些数据。在混合云基础架构中，如果某些工作负载在云中运行，而某些工作负载完全位于内部或不同的 HPC 环境中，则此问题会更加严重。</block>
  <block id="2b8ab86ccf473cca225e50ddb8c47e25" category="paragraph">在本文档中，我们介绍了一款全新的解决方案， IT 专业人员和数据工程师可以利用可感知拓扑的数据中心创建一个真正的混合云 AI 平台，数据科学家可以利用该平台在计算资源附近即时自动创建数据集缓存。 无论它们位于何处。因此，不仅可以完成高性能模型培训，而且还可以带来更多优势，包括多名 AI 实践者的协作，他们可以立即访问数据集版本中心内的数据集缓存，版本和行。</block>
  <block id="a6214fe1ac9a6825ffe38f3b34489c9d" category="summary">NetApp Run AI 合作创建了本技术报告，展示了 Azure NetApp Files 与 Run AI 平台在简化 AI 工作负载流程方面的独特功能。</block>
  <block id="a55106260c16aab506cebfb58e07e030" category="paragraph">NetApp 与 Run ： AI 合作创建了本技术报告，展示了 Azure NetApp Files 的独特功能以及用于简化 AI 工作负载流程的 Run ： AI 平台。本技术报告提供了一个参考架构，用于简化分布式通道检测培训的数据管道和工作负载流程编排流程。</block>
  <block id="4e51614a389f3ad4fa17e2ce7ad984e7" category="paragraph">总之，对于大规模分布式培训（尤其是在公有云环境中），资源编排和存储组件是解决方案的重要组成部分。确保数据管理不会妨碍多个 GPU 处理，从而实现 GPU 周期的最佳利用率。这样，就可以使该系统尽可能地经济高效地用于大规模分布式培训。</block>
  <block id="269c35b1959d92e9ef6665bb4c60ad5d" category="paragraph">NetApp 提供的 Data Fabric 可以帮助数据科学家和数据工程师在内部和云中相互连接，以实现同步数据，而无需执行任何手动干预，从而克服了这一挑战。换言之， Data Fabric 可以平稳地管理分布在多个位置的 AI 工作流。此外，它还可以将数据贴近计算，并在需要时随时随地执行分析，培训和验证，从而促进基于需求的数据可用性。此功能不仅可以实现数据集成，还可以保护和保障整个数据管道的安全。</block>
  <block id="1d22ea3c852f35081a408a42b1caa719" category="doc">cnvrg.io 部署</block>
  <block id="e1d91df1cfd0e5839c45e06d0504c9d6" category="section-title">使用 Helm 部署 cnvrg 核心</block>
  <block id="7e9e2a4317009b27ebfc0b4cd222ba30" category="paragraph">使用任何集群，内部， MinikubE 或任何云集群（如 AKS ， EKS 和 GKE） ， Helm 是快速部署 cnvrg 的最简单方法。本节介绍如何在安装了 Kubernetes 的内部（ DGX-1 ）实例上安装 cnvrg 。</block>
  <block id="ea6de3fdf29035cd2d521949527c2a44" category="paragraph">在完成安装之前，您必须在本地计算机上安装并准备以下依赖项：</block>
  <block id="6f49e891fdb1bb11823492f4d315b2fd" category="list-text">Kubectl</block>
  <block id="5e6cef7c129d4703b20be420ac32145c" category="list-text">Helm 3.x</block>
  <block id="93fafc2be5db6c259030d6d8dc989752" category="list-text">Kubernetes 集群 1.15 及更高版本</block>
  <block id="116efea8faeef9714de76fe9f81d9b82" category="section-title">使用 Helm 部署</block>
  <block id="237800170a9b824a7de8c08766ea114e" category="list-text">要下载最新的 cnvrg Helm 图表，请运行以下命令：</block>
  <block id="9b821098b02043dada6b07b924f4ef5f" category="list-text">在部署 cnvrg 之前，您需要集群的外部 IP 地址以及要部署 cnvrg 的节点的名称。要在内部 Kubernetes 集群上部署 cnvrg ，请运行以下命令：</block>
  <block id="1d1eb4e0da8bac1b4eaa79c1f0be9e04" category="list-text">运行 `helm install` 命令。所有服务和系统都会自动安装在集群上。此过程可能需要长达 15 分钟。</block>
  <block id="e269e5751f8883222b6d2f55da7ed811" category="list-text">`helm install` 命令可能需要长达 10 分钟的时间。部署完成后，转到新部署的 cnvrg 的 URL 或将新集群添加为组织内部的资源。使用 `helm` 命令可向您告知正确的 URL 。</block>
  <block id="ac0cc75e8d4f0df818dd93a00041897a" category="list-text">当所有容器的状态为 running 或 complete 时，已成功部署 cnvrg 。它应类似于以下示例输出：</block>
  <block id="3e82668da957bceb0d0c7024273ab624" category="section-title">使用 ResNet50 和 Chest X 射线数据集的计算机视觉模型培训</block>
  <block id="c9c734dfca60f137a58e1a5cb9c89b62" category="inline-link">NIH 下载站点</block>
  <block id="0c7f26c15912f9f5d0e0473bb21cb9a2" category="paragraph">cnvrg.io AI 操作系统部署在 Kubernetes 设置中，并部署在由 NVIDIA DGX 系统提供支持的 NetApp ONTAP AI 架构上。为了进行验证，我们使用了 NIH Chest X ray 数据集，该数据集包含经去除身份识别的胸 x 射线图像。这些映像采用 PNG 格式。这些数据由 NIH 临床中心提供，可通过获取<block ref="4e3f11b94ad47864cbd9c6049036ac93" category="inline-link-rx"></block>。我们使用了一个 250 GB 的数据样本，其中包含 627 ， 615 个图像，分布在 15 个类别中。</block>
  <block id="de53b795a18176edb91a88632f621868" category="paragraph">数据集已上传到 cnvrg 平台，并在 NetApp AFF A800 存储系统的 NFS 导出中进行缓存。</block>
  <block id="ec948f075c372d4beb7d19a5266f22d5" category="section-title">设置计算资源</block>
  <block id="42af2f71dc8561eb9cfe43d45664ecb3" category="paragraph">借助 cnvrg 架构和元数据计划功能，工程师和 IT 专业人员可以将不同的计算资源连接到一个平台。在我们的设置中，我们使用了为运行深度学习工作负载而部署的相同集群 cnvrg 。如果需要连接其他集群，请使用 GUI ，如以下屏幕截图所示。</block>
  <block id="df25fca4c07e68ed339b0e1974a9d59f" category="paragraph"><block ref="df25fca4c07e68ed339b0e1974a9d59f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f541774a08fc687f6e2016c77a6ebca5" category="section-title">加载数据</block>
  <block id="564bfd33ed32c02158989dfcee59ae89" category="paragraph">要将数据上传到 cnvrg 平台，您可以使用 GUI 或 cnvrg CLI 。对于大型数据集， NetApp 建议使用 CLI ，因为它是一款强大，可扩展且可靠的工具，可以处理大量文件。</block>
  <block id="41ad6001e0d3c17bd4a7957e18bd8bab" category="paragraph">要上传数据，请完成以下步骤：</block>
  <block id="192b006166881688d04f398db712aaeb" category="inline-link">cnvrg 命令行界面</block>
  <block id="8e9fbcfb57e26d7a14f0292c11fae122" category="list-text">下载<block ref="d3ae4cf97b77cb5805c16205cd459ce4" category="inline-link-rx"></block>。</block>
  <block id="5cea56fcf2481a021f3d93843a22c319" category="list-text">导航到 x-ray 目录。</block>
  <block id="1c5a650f398227a4f97ed81accfbbb4b" category="list-text">使用 `cnvrg data init` 命令初始化平台中的数据集。</block>
  <block id="5c48f13a3d988e0d618145098a829e3a" category="list-text">使用 `cnvrg data sync` 命令将目录的所有内容上传到中央数据湖。将数据上传到中央对象存储（ StorageGRID ， S3 或其他）后，您可以使用 GUI 进行浏览。下图显示了一个已加载的胸 X 射线纤维化影像 PNG 文件。此外， cnvrg 会对数据进行版本控制，以便您构建的任何模型都可以复制到数据版本。</block>
  <block id="935b6e25167b65d839bc1487ebb2fa6e" category="paragraph"><block ref="935b6e25167b65d839bc1487ebb2fa6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="308e9394a715dc64aa4e48e0054775ed" category="section-title">Cach 数据</block>
  <block id="556cde11a66a789acb7e62b934c1a88c" category="paragraph">为了加快训练速度并避免为每个模型训练和实验下载 60 万多个文件，在数据最初上传到中央数据湖对象存储之后，我们使用了数据缓存功能。</block>
  <block id="3d163413cac9b6cc4726a9c83d37fed3" category="paragraph"><block ref="3d163413cac9b6cc4726a9c83d37fed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d006c100d76e7d21d64055ce3cfe6a24" category="paragraph">用户单击缓存后， cnvrg 将从远程对象存储下载其特定提交中的数据，并将其缓存到 ONTAP NFS 卷上。完成后，可以使用这些数据进行即时培训。此外，如果数据在几天内未使用（例如用于模型训练或探索），则 cnvrg 会自动清除缓存。</block>
  <block id="53ad459d9bb7a65de3d1cc839b75c19f" category="section-title">使用缓存数据构建 ML 管道</block>
  <block id="db226c80bcb6098ce2f47dd3982cca26" category="paragraph">借助 cnvrg 流，您可以轻松构建生产 ML 管道。流非常灵活，可用于任何类型的 ML 用例，并可通过 GUI 或代码创建。一个流中的每个组件都可以使用不同的 Docker 映像在不同的计算资源上运行，从而可以构建混合云和优化的 ML 管道。</block>
  <block id="6b0eae96748d48b032362774a6467411" category="paragraph"><block ref="6b0eae96748d48b032362774a6467411" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1f18dfff2566b35d7d0e528565c43aa" category="section-title">构建箱内 X 射线流：设置数据</block>
  <block id="adec555cb8cd4de3f288baed510d1163" category="paragraph">我们已将数据集添加到新创建的流中。添加数据集时，您可以选择特定版本（提交）并指示是否需要缓存版本。在此示例中，我们选择了缓存的提交。</block>
  <block id="6dd780034ed574b328dbc16a6b485b79" category="paragraph"><block ref="6dd780034ed574b328dbc16a6b485b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13e0789c536fc18ddcdc32b4ca598b58" category="section-title">构建箱内 X 射线流：设置训练模型： ResNet50</block>
  <block id="fa3c48d58d8e9fd17365fd986906dd52" category="paragraph">在管道中，您可以添加所需的任何类型的自定义代码。在 cnvrg 中，还提供了 AI 库，这是一个可重复使用的 ML 组件集合。在 AI 库中，有算法，脚本，数据源以及其他解决方案可用于任何 ML 或深度学习流。在此示例中，我们选择了预构建的 ResNet50 模块。我们使用的是默认参数，例如 batch_size ： 128 ， epodchs ： 10 等。可以在 AI 库文档中查看这些参数。以下屏幕截图显示了将 X 线数据集连接到 ResNet50 的新流。</block>
  <block id="defe5cc08faaa501eeb5fc5500664d29" category="paragraph"><block ref="defe5cc08faaa501eeb5fc5500664d29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf9bb479506589dfd719446fe3e054c7" category="section-title">为 ResNet50 定义计算资源</block>
  <block id="943cb3f5c7789c68e811b0accdb6c5d9" category="paragraph">cnvrg 流中的每个算法或组件都可以使用不同的 Docker 映像在不同的计算实例上运行。在我们的设置中，我们希望使用 NetApp ONTAP AI 架构在 NVIDIA DGX 系统上运行训练算法。在下图中，我们选择了 `GPU Real` ，这是我们内部集群的计算模板和规范。我们还创建了一个模板队列并选择了多个模板。这样，如果无法分配 `GPU-Real` 资源（例如，如果其他数据科学家正在使用该资源），则可以通过添加云提供商模板来启用自动云突发功能。以下屏幕截图显示了如何使用 GPU Real 作为 ResNet50 的计算节点。</block>
  <block id="27c8450e6f62877ec794262ae4c5a713" category="paragraph"><block ref="27c8450e6f62877ec794262ae4c5a713" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bee38713f37ae72239f6bda08384dfbb" category="section-title">跟踪和监控结果</block>
  <block id="546b7da7049f1d7fdf35cdb57fa96c7c" category="paragraph">执行流量后， cnvrg 将触发跟踪和监控引擎。每次运行流程都会自动记录并实时更新。超参数，指标，资源使用情况（ GPU 利用率等），代码版本，项目，日志， 实验部分会自动提供，如以下两个屏幕截图所示。</block>
  <block id="8fabeb8b8d143d509bb92087cbbf953c" category="paragraph"><block ref="8fabeb8b8d143d509bb92087cbbf953c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdbd22304f732000189e44de22498da1" category="paragraph"><block ref="fdbd22304f732000189e44de22498da1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c83553858a60514501e9751c0747dea0" category="doc">基本资源分配公平</block>
  <block id="dc12a1ce34c0a7a264de91bc9b933a62" category="paragraph">在本节中，我们会显示，当 `team-d` 请求更多 GPU （它们低于其配额）时，系统会暂停 `team-b` 和 `team-c` 的工作负载，并以公平的方式将其移至待定状态。</block>
  <block id="ccc33823c0dc5e9ee0838a5eaa86f076" category="inline-link-macro">第 4.9 节的测试详细信息</block>
  <block id="86bbd55ea7850716c0c192b19c86176a" category="paragraph">有关提交作业，使用的容器映像以及执行的命令序列等详细信息，请参见一节 <block ref="94d73a1896276f719be59227f0e93a14" category="inline-link-macro-rx"></block>。</block>
  <block id="b6ea2a2f48a443e7d027bd652ac84762" category="paragraph">下图显示了由于自动负载平衡和预先计划而产生的集群利用率，每个组分配的 GPU 以及待处理作业。我们可以观察到，当所有团队工作负载请求的 GPU 总数超过集群中可用的 GPU 总数时， Run ： AI 的内部公平算法会分别为 `team-b` 和 `team-c` 暂停一个作业，因为它们已达到项目配额。这样可以提供整体较高的集群利用率，而数据科学团队仍在管理员设置的资源限制下工作。</block>
  <block id="d1a54cf8cb2a06c0715d2f042fbf44bd" category="paragraph"><block ref="d1a54cf8cb2a06c0715d2f042fbf44bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d52816ece2166f7a2e0eadf58d617df9" category="paragraph">此测试场景的结果显示以下内容：</block>
  <block id="bce83ec0a92a5b10380007a1643b2fd0" category="list-text">* 自动负载平衡。 * 系统会自动平衡 GPU 的配额，使每个团队现在都在使用其配额。暂停的工作负载属于超过其配额的团队。</block>
  <block id="f8be0d1ca354f8cb4aaa4c8aadcea80b" category="list-text">* 公平共享暂停。 * 系统会选择停止超过配额的一个组的工作负载，然后停止另一个组的工作负载。Run ： AI 具有内部公平算法。</block>
  <block id="4ac9fa791a6d1c7c97bbae134dd22586" category="paragraph">一个真正的人工智能对话系统可以进行类似于人类的对话，了解相关背景并提供智能响应。此类 AI 模型通常非常庞大且非常复杂。借助 NVIDIA GPU 和 NetApp 存储，可以对大规模的一流语言模型进行培训和优化，以快速运行推理。这是一个重大的进步，旨在结束快速 AI 模型与大型复杂 AI 模型之间的权衡。GPU 优化的语言理解模式可以集成到医疗保健，零售和金融服务等行业的 AI 应用程序中，为智能扬声器和客户服务线中的高级数字语音助理提供支持。通过这些高质量的对话式 AI 系统，各个垂直行业的企业可以在与客户接洽时提供以前无法实现的个性化服务。</block>
  <block id="4c2588a1e3dbf6824a4f05095df75f83" category="paragraph">尽管当今所有应用程序都不是人工智能驱动的，但它们正在不断发展的功能，使其能够获得人工智能的巨大优势。为了支持采用 AI ，应用程序需要一个基础架构，以便为其提供最佳运行级别所需的资源，并支持其持续发展。</block>
  <block id="31965de7c735983bb41a0b7e70361db2" category="paragraph">对于 AI 驱动的应用程序，边缘位置是主要的数据源。如果在一段时间内从多个边缘位置收集可用数据以构成培训数据集，则可以将这些数据用于培训。然后，可以将经过培训的模型部署回收集数据的边缘位置，从而加快推理速度，而无需将生产数据重复传输到专用推理平台。</block>
  <block id="9e53c147a93fed13d4349cba2a35e36b" category="paragraph">NetApp HCI AI 推理解决方案由采用 NVIDIA T4 GPU 和 NetApp 云连接存储系统的 NetApp H615c 计算节点提供支持，由 NetApp 和 NVIDIA 开发并验证。NetApp HCI 通过解决不确定性问题，消除设计复杂性和结束猜测，简化了在边缘数据中心部署 AI 推理解决方案的过程。此解决方案为 IT 组织提供了一个规范化的架构，可以：</block>
  <block id="9c4a53996590c74a0de3bba81f878254" category="list-text">在边缘数据中心启用 AI 推理</block>
  <block id="20c3f996d396cc8c92788bb3585a6e86" category="list-text">优化 GPU 资源的使用</block>
  <block id="06e81c54cb9157aa59541289f1163daf" category="list-text">提供基于 Kubernetes 的推理平台，以提高灵活性和可扩展性</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">消除设计复杂性</block>
  <block id="ba37c372c4a9119e45c7f525f4743cfc" category="paragraph">边缘数据中心在非常接近生成点的位置管理和处理数据。这种接近性可提高处理数据时的效率并减少相关延迟。许多垂直市场已经实现了边缘数据中心的优势，并在很大程度上采用这种分布式数据处理方法。</block>
  <block id="b501a0f0a3e7d559cecfad08c330227e" category="paragraph">下表列出了边缘垂直市场和应用程序。</block>
  <block id="06ce2a25e5d12c166a36f654dbea6012" category="cell">垂直</block>
  <block id="077262cc53a1fb1b5f651d31b6bf81ba" category="cell">医疗</block>
  <block id="9da98fbc1c3d290fefb743a2df8914b4" category="cell">计算机辅助诊断可帮助医务人员进行早期疾病检测</block>
  <block id="fa0a7aa1622ad105e9cdf5a706058333" category="cell">石油和天然气</block>
  <block id="55dae4e2e7f267e43e5768e66c7c3771" category="cell">对远程生产设施，视频和图像分析进行自主检查</block>
  <block id="252ddb15657f2c60bddc73633a7bf8c0" category="cell">航空</block>
  <block id="7a84f6faf76fd3533ae6ca65d28c53eb" category="cell">空中交通控制辅助和实时视频源分析</block>
  <block id="81ea9456adf225bcf11b668b427fd4f2" category="cell">媒体和娱乐</block>
  <block id="5015819e58d425b19f8acc93866e76fa" category="cell">音频 / 视频内容筛选功能，可提供适合家庭使用的内容</block>
  <block id="616e90f12cb95950bc1c75396902393a" category="cell">业务分析</block>
  <block id="3e4c06851690089d4952320e9df36dc2" category="cell">品牌认知度，用于分析在流式直播电视活动中的品牌表现</block>
  <block id="a9f7ecebb493e129aafb4cbfd73e85df" category="cell">电子商务</block>
  <block id="5df4fc692c9317012855d6935bf10310" category="cell">将供应商产品智能捆绑在一起，找到理想的商家和仓库组合</block>
  <block id="053e0bc8b9627b28e2ed8029a34b35bd" category="cell">零售</block>
  <block id="7cf7816e39e6e0c259a79dc29c5a5e7c" category="cell">自动结账，用于识别客户放入购物车的物品，并便于进行数字支付</block>
  <block id="165f5687ea9050fba239731810d0abe8" category="cell">智慧城市</block>
  <block id="a47b360ffbe39c5a39c7e12e2ae8fdf5" category="cell">改善交通，优化停车，增强人行和骑行者的安全</block>
  <block id="e86883c7cfc07afcf1e5ad8dffd7e1cc" category="cell">制造</block>
  <block id="f4d790a35097fa97c2687ac573b25338" category="cell">质量控制，装配线监控和缺陷识别</block>
  <block id="2273d1167a6212812d95dc8fadbae78e" category="cell">客户服务</block>
  <block id="bf4948e47ea0d77a86e639979879262d" category="cell">客户服务自动化，用于分析和鉴别咨询（电话，电子邮件和社交媒体）</block>
  <block id="8e54e9aa508ea37f7fe734e86ba9da27" category="cell">农业</block>
  <block id="7fb956270d49b22c3226bc1db2b0269f" category="cell">智能的农场运营和活动规划，可优化肥料和除草剂应用</block>
  <block id="3190a811a89bc9da4384152bc43d1b94" category="section-title">目标受众</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">解决方案的目标受众包括以下组：</block>
  <block id="134481f7bea652a34fa2ada120d250e5" category="list-text">数据科学家</block>
  <block id="8d26f0555c7ace3d4b297da8c12fb31b" category="list-text">IT 架构师</block>
  <block id="c114d2813b0041352b49187ebc28b62b" category="list-text">现场顾问</block>
  <block id="2d6d0cc18609f97853f883c1891397d2" category="list-text">专业服务</block>
  <block id="467f739adb5605167109d76676b44696" category="list-text">IT 经理</block>
  <block id="dcfa1c08d3b0126217af0b8690305c08" category="list-text">需要在边缘位置提供 IT 创新和强大数据和应用程序服务的基础架构的任何其他人</block>
  <block id="3bb420314fa4b29837c4b0528524000f" category="doc">NetApp ONTAP AI 和 AI 控制平台</block>
  <block id="1b85c0e7f381bd6f8c3150cafe56a9f0" category="paragraph">NetApp ONTAP AI 架构，由 NVIDIA DGX 系统和 NetApp 云连接存储系统提供支持。此参考架构为 IT 组织提供了以下优势：</block>
  <block id="5116c5071beb9f4f5b673c988c417c71" category="list-text">支持独立扩展计算和存储</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">支持客户从小规模入手，无缝扩展</block>
  <block id="bae698d3cdcc290d6a0048c7b786446c" category="list-text">为各种性能和成本点提供一系列存储选项 NetApp ONTAP AI 可将 DGX 系统和 NetApp AFF A800 存储系统与一流的网络紧密集成在一起。NetApp ONTAP AI 和 DGX 系统消除了设计复杂性和猜测性工作，从而简化了 AI 部署。客户可以从小规模入手，无中断地扩展系统，同时智能地管理从边缘到核心再到云再到云的数据。</block>
  <block id="c729dcbcad9e1c72ae15d4b823e9f311" category="paragraph">NetApp AI 控制平台是一个全堆栈 AI ， ML 和深度学习（ DL ）数据和实验管理解决方案，适用于数据科学家和数据工程师。随着企业越来越多地使用 AI ，他们面临着许多挑战，包括工作负载可扩展性和数据可用性。NetApp AI 控制平台可通过各种功能来应对这些挑战，例如像 Git repo一样 快速克隆数据命名空间，以及定义和实施 AI 培训工作流，这些工作流可近乎即时地创建数据和模型基线以实现版本控制和可追溯性。借助 NetApp AI 控制平台，您可以在站点和区域之间无缝复制数据，并快速配置 Jupyter 笔记本工作空间，以便访问海量数据集。</block>
  <block id="6b4330df9a37bcfef1faecd1e8973464" category="inline-link-macro">配额过度公平</block>
  <block id="5648f06cc2dff861e557e088190ccbe2" category="paragraph">在本节和各节中 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>，和 <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>，我们设计了高级测试方案，用于演示运行： AI 流程编排功能，以实现复杂的工作负载管理，自动抢占式计划和超配额 GPU 配置。我们这样做是为了在 ONTAP AI 环境中实现高集群资源利用率并优化企业级数据科学团队的工作效率。</block>
  <block id="fed09193953a2a2d15bfba4063981f8c" category="paragraph">对于这三个部分，请设置以下项目和配额：</block>
  <block id="d2d5c3e087f684e56b5b81d6212d7ccb" category="cell">配额</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8.</block>
  <block id="207b738b6cd0e1cf6ac4a405dc72102f" category="paragraph">此外，我们还会对这三个部分使用以下容器：</block>
  <block id="cc6f12794ea24a191cb4f699f1b95036" category="list-text">Jupyter 笔记本电脑： `jupyter/base-notebook`</block>
  <block id="b8d0bb7e356bfdd7e018a7c62f9343fa" category="list-text">Run ： AI Quickstart ： `gcr.io/run-ai-demo/Quickstart`</block>
  <block id="c9582d103b2fe8050364d3e629c4e80e" category="paragraph">我们为此测试场景设定了以下目标：</block>
  <block id="c2d51205301247cd0aa0eca284d3889b" category="list-text">展示资源配置的简便性以及如何从用户中提取资源</block>
  <block id="dfd4af458e74e30246827532e692dca7" category="list-text">展示用户如何轻松配置 GPU 的小部分和 GPU 的整数</block>
  <block id="d7bf7c7f0d7884bd8fe07da4f6a8aba3" category="list-text">展示如果集群中存在可用 GPU ，系统如何通过允许团队或用户超过其资源配额来消除计算瓶颈</block>
  <block id="f93609e9c7f7c826e6c83bb1f8416207" category="list-text">展示如何在运行计算密集型作业（例如 NetApp 容器）时使用 NetApp 解决方案消除数据管道瓶颈</block>
  <block id="8ac218f5a62c8021756a192ac737a7f2" category="list-text">显示如何使用系统运行多种类型的容器</block>
  <block id="802125395813e0bec35472d0403ab94e" category="list-text">Jupyter 笔记本电脑</block>
  <block id="91c4a4ef606f959264719f8d084aab0e" category="list-text">运行： AI 容器</block>
  <block id="23edbe937c996eb973ab4c69f9648893" category="list-text">集群已满时显示高利用率</block>
  <block id="815a27a2c38741e36d920cbea5587384" category="paragraph">有关在测试期间执行的实际命令序列的详细信息，请参见 <block ref="3a65193f11bb9f699d19b0e9a996cd93" category="inline-link-macro-rx"></block>。</block>
  <block id="9d020ce52f8e9ff0d2f2defe3942d660" category="paragraph">提交所有 13 个工作负载后，您可以看到一个容器名称和分配的 GPU 列表，如下图所示。我们有七个培训和六个互动作业，模拟四个数据科学团队，每个团队都有自己的模型运行或开发。对于交互式作业，各个开发人员都在使用 Jupyter 笔记本电脑编写或调试其代码。因此，它适合在不使用过多集群资源的情况下配置 GPU 分段。</block>
  <block id="5deafc9e56279ca519f1e3c351856aa8" category="paragraph"><block ref="5deafc9e56279ca519f1e3c351856aa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa04853a58b1b9ab0033c7e24b9d929" category="paragraph">此测试场景的结果如下：</block>
  <block id="dbaf41fcdcf0aa8cd93bfdf0e7f916f2" category="list-text">集群应已满：使用了 16/16 个 GPU 。</block>
  <block id="25421e793bda820f3023762c547a2495" category="list-text">集群利用率高。</block>
  <block id="fdf3de6e0502b5404d2e0b379421f759" category="list-text">由于分配百分比的影响，比 GPU 的实验更多。</block>
  <block id="68cf93a70e0f0fe62bc0428ce8a8b348" category="list-text">`team-d` 并未使用所有配额；因此， `team-b` 和 `team-c` 可以在其实验中使用额外的 GPU ，从而加快创新速度。</block>
  <block id="3642f282b12269091ab196a3aabf0858" category="summary">Trident 操作示例</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">本节包括您可能希望使用 Trident 执行的各种操作的示例。</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">导入现有卷</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">如果您的 NetApp 存储系统 / 平台上有要挂载到 Kubernetes 集群中的容器上但未与集群中的 PVC 绑定的现有卷，则必须导入这些卷。您可以使用 Trident 卷导入功能导入这些卷。</block>
  <block id="f363c1a10e150fdee0f4f310a06acb5e" category="inline-link-macro">ONTAP AI 部署的 Trident 后端示例</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">Kubernetes 官方文档</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link">Trident 文档</block>
  <block id="4330c34147b36030c50afe1d04ec2213" category="paragraph">以下示例命令显示了为在本节示例中创建的每个 Trident 后端导入相同卷 `PB_FG_ALL` 两次 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>，步骤 1 。通过以这种方式导入同一卷两次，您可以在不同 LIF 之间多次挂载此卷（现有 FlexGroup 卷），如一节所述 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>，步骤 1 。有关 PVCs 的详细信息，请参见<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。有关卷导入功能的详细信息，请参见<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">在示例 PVC 规范文件中指定了 `accessModes` 值 `ReadOnlyMany` 。有关 `accessMode` 字段的详细信息，请参见<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。</block>
  <block id="6631bf64346739a9880a9789a941a8d6" category="inline-link-macro">适用于 ONTAP AI 部署的 Kubernetes StorageClasses 示例</block>
  <block id="e6d82e60d43fe02e01930addfe670e8f" category="admonition">以下示例导入命令中指定的后端名称与在本节的示例中创建的后端相对应 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>，步骤 1 。以下示例 PVC 定义文件中指定的 StorageClass 名称与在本节的示例中创建的 StorageClasses 相对应 <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>，步骤 1 。</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">配置新卷</block>
  <block id="e149d2e1fdb31ad28f79dd3d2c7ee8ff" category="paragraph">您可以使用 Trident 在 NetApp 存储系统或平台上配置新卷。以下示例命令显示了新 FlexVol 卷的配置。在此示例中，使用在一节的示例中创建的 StorageClass 配置卷 <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>，步骤 2 。</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">在以下示例 PVC 定义文件中指定了 `accessModes` 值 `ReadWriteMany` 。有关 `accessMode` 字段的详细信息，请参见<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。</block>
  <block id="c701c7fe143bef79cc6eebc32606262e" category="paragraph">要了解有关本文档中所述信息的更多信息，请参见以下资源：</block>
  <block id="e40030fd64108859627c7a126638f0e6" category="list-text">NetApp AI 控制平台：</block>
  <block id="63178726ae501745b3914ec3aa50969e" category="list-text">NetApp AI 控制平面技术报告</block>
  <block id="3ce56c027572d1908d65b63056be024f" category="inline-link"><block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="445a4d3400bdde832e8898d8349696c0" category="paragraph"><block ref="445a4d3400bdde832e8898d8349696c0" category="inline-link-rx"></block></block>
  <block id="de1e4a3a0cae539a34678546eb6e91b3" category="list-text">适用于容器的 NetApp 持久存储：</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="193721fbb9ea3851cafcea43a4d95f73" category="list-text">ML 框架和工具：</block>
  <block id="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link"><block ref="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link-rx"></block></block>
  <block id="9a8ec45d909b996af4c042e44b5c5f29" category="list-text">TensorFlow ：适用于所有人的开源机器学习框架<block ref="db3465122fd83ad1dc4cff7e67d794df" category="inline-link-rx"></block></block>
  <block id="c5fd214cdd0d2b3b4272e73b022ba5c2" category="list-text">Docker</block>
  <block id="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link"><block ref="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link-rx"></block></block>
  <block id="60ea9e9ecbf839c413c5e977002eabf4" category="paragraph"><block ref="60ea9e9ecbf839c413c5e977002eabf4" category="inline-link-rx"></block></block>
  <block id="30136395f01879792198317c11831ea4" category="list-text">Kubernetes</block>
  <block id="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link"><block ref="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link-rx"></block></block>
  <block id="6bd14be39aedfe96ceacec2caaac0532" category="paragraph"><block ref="6bd14be39aedfe96ceacec2caaac0532" category="inline-link-rx"></block></block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="list-text">Kubeflow</block>
  <block id="a33d91971f7757996ab0eb8eb0362814" category="inline-link"><block ref="a33d91971f7757996ab0eb8eb0362814" category="inline-link-rx"></block></block>
  <block id="6771540ad76dbed724cb9025978b8510" category="paragraph"><block ref="6771540ad76dbed724cb9025978b8510" category="inline-link-rx"></block></block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="list-text">Jupyter 笔记本电脑服务器</block>
  <block id="c90a0598d42425e6ec2dfb3058534b35" category="inline-link"><block ref="c90a0598d42425e6ec2dfb3058534b35" category="inline-link-rx"></block></block>
  <block id="ef9e62eeb81c0987fbe61de48635886a" category="paragraph"><block ref="ef9e62eeb81c0987fbe61de48635886a" category="inline-link-rx"></block></block>
  <block id="3bc4d41311862190a8fd0d6c8f661971" category="list-text">Iguazio 数据科学平台</block>
  <block id="737d4d1e81ff236001338f46d1623aaa" category="list-text">Iguazio 数据科学平台文档</block>
  <block id="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link"><block ref="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link-rx"></block></block>
  <block id="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="paragraph"><block ref="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="inline-link-rx"></block></block>
  <block id="4f0f362becf6baf6e08f490115d76d98" category="list-text">Nercio 无服务器功能</block>
  <block id="89aa84cdf5db1bece2993801c78914de" category="inline-link"><block ref="89aa84cdf5db1bece2993801c78914de" category="inline-link-rx"></block></block>
  <block id="93eac034cc1c1aaedaf6ed41063825ee" category="paragraph"><block ref="93eac034cc1c1aaedaf6ed41063825ee" category="inline-link-rx"></block></block>
  <block id="b5266d58998338015b5e02ee7e84a833" category="list-text">MLRun 开源渠道业务流程框架</block>
  <block id="b96a861dccea968edc0b7a9ff96203e9" category="inline-link"><block ref="b96a861dccea968edc0b7a9ff96203e9" category="inline-link-rx"></block></block>
  <block id="70a8a001358e056f435199da7e17e427" category="paragraph"><block ref="70a8a001358e056f435199da7e17e427" category="inline-link-rx"></block></block>
  <block id="b3f90aaddad391963c2090db8f1b727e" category="list-text">NVIDIA DGX-1 系统</block>
  <block id="45a310b0e4b087b75cb073303044f6f9" category="inline-link"><block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="af828c56c03364ebbde4c582adeb8de3" category="paragraph"><block ref="af828c56c03364ebbde4c582adeb8de3" category="inline-link-rx"></block></block>
  <block id="d6a377b23d0f4dbe3f5bf91d5f6abf74" category="list-text">NVIDIA Tesla V100 Tensor 核心 GPU</block>
  <block id="fad8218d69ce01748faed5492aa5d3ef" category="inline-link"><block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="a724832176ce84a9d4be5c34e44891d3" category="paragraph"><block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="0df7621d860637a2e6e462c56322edab" category="list-text">NVIDIA GPU 云</block>
  <block id="5c75bfead88762783d54deaaa3d62735" category="inline-link"><block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="839d9b8469a8d9554891a7515a2b9be7" category="paragraph"><block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="list-text">NetApp AFF 系统</block>
  <block id="584122d1d5e8c2c4232e029a6896ba40" category="list-text">AFF 产品规格</block>
  <block id="9a84c14d2692222552174943486e7136" category="inline-link"><block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="0d9d8991a05834f0e52a99b37ce360b8" category="paragraph"><block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="5f662f6dc276dd5a2a83440d0fe63e9b" category="list-text">适用于 AFF 的 NetApp 闪存优势</block>
  <block id="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link"><block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="72cf25e9f1e13167cd0dde6f285552ea" category="paragraph"><block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="30df7f622635480ab538fb3016f9c36a" category="list-text">ONTAP 9.x 文档</block>
  <block id="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link"><block ref="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link-rx"></block></block>
  <block id="a5d59e86f09bafae4247836d5135b6a3" category="paragraph"><block ref="a5d59e86f09bafae4247836d5135b6a3" category="inline-link-rx"></block></block>
  <block id="35d8efcf211e40a836698bff14ed0ff6" category="list-text">NetApp FlexGroup 技术报告</block>
  <block id="1ab29fc7fde3319a82a477ec308cf820" category="inline-link"><block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="7a26d62dac2be507dcc3e5b9da0ed765" category="paragraph"><block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="list-text">NetApp ONTAP AI</block>
  <block id="47c991332229e0cbfe947beaa428ea61" category="list-text">采用 DGX-1 的 ONTAP AI 和 Cisco 网络设计指南</block>
  <block id="b141781260425e95eee945147e2f0d99" category="inline-link"><block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="9fbee18519e76388280bc1f8e3fd6c7e" category="paragraph"><block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="0be3b0697a0ffdfe9065df24ec1d3e16" category="list-text">《采用 DGX-1 的 ONTAP AI 和 Cisco 网络部署指南》</block>
  <block id="921f17c41dea89b0a711f380e9864e09" category="inline-link"><block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="aef3d0752148699921f8a251537d5ff3" category="paragraph"><block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="205a4f16a51f3acd6dbba76dbeb10818" category="list-text">采用 DGX-1 和 Mellanox 网络设计指南的 ONTAP AI</block>
  <block id="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link"><block ref="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link-rx"></block></block>
  <block id="0a9e1455c4a5a9965867a5efd6b8cc9b" category="paragraph"><block ref="0a9e1455c4a5a9965867a5efd6b8cc9b" category="inline-link-rx"></block></block>
  <block id="913c29df09bcb5715ed7a48c12f3a0da" category="list-text">ONTAP AI 网络</block>
  <block id="ae2703e9b1dff6da048c786142c2e7db" category="list-text">Cisco Nexus 3232C 系列交换机</block>
  <block id="bb31172f259c591005fd4cbcdbfadd11" category="inline-link"><block ref="bb31172f259c591005fd4cbcdbfadd11" category="inline-link-rx"></block></block>
  <block id="96eb8aa0e86d101fdf87284d7d6f1bc7" category="paragraph"><block ref="96eb8aa0e86d101fdf87284d7d6f1bc7" category="inline-link-rx"></block></block>
  <block id="8a27a2062df55e0aa73964ea8ec2ab55" category="list-text">Mellanox 横向扩展 SN2000 以太网交换机系列</block>
  <block id="87a849c2f3c412a491f97674d5e27ed1" category="inline-link"><block ref="fd77c1cd25d650110f7047fa02f8327d" category="inline-link-rx"></block></block>
  <block id="a6c16c720941d75800533dedd69929cc" category="paragraph"><block ref="ad90d1952f7d0f85370461937e4484b7" category="inline-link-rx"></block></block>
  <block id="7450cfde7058dc5e1f7909d0280fd7ae" category="list-text">Azure NetApp Files</block>
  <block id="142f782bb2b326679982208fe40cec31" category="section-title">NVIDIA DeepOps</block>
  <block id="337f05fad2de58e4a8b74cb25536b52d" category="doc">设置概述</block>
  <block id="666f45aef7a28ef5ba6e4bfb2f71bcee" category="section-title">安装 Iguazio</block>
  <block id="3b31e2e4387e938056251a113831e6da" category="inline-link">NVA-1121</block>
  <block id="8334797b9b3383d4f48d98178b8845ea" category="inline-link">此页面</block>
  <block id="ade8a7efee71036d2ca57676a54b31e3" category="paragraph">有关内部安装，请参见<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> 用于计算，网络和存储设置。Iguazio 的内部部署由 Iguazio 提供，客户无需支付额外费用。请参见<block ref="d273dd0a16e6003b56381a70823807f7" category="inline-link-rx"></block> DNS 和 SMTP 服务器配置。Provazio 安装页面如下所示。</block>
  <block id="8e72dced5918c4009ff80044ba6f44db" category="paragraph"><block ref="8e72dced5918c4009ff80044ba6f44db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">详细信息</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="cell">NFS</block>
  <block id="ed4a202c34987f40d5e245e76a65a243" category="paragraph">下图显示了建议的对话 AI 系统架构。您可以使用语音信号或文本输入与系统进行交互。如果检测到语音输入，则 JARVIS AI as-service （ AIaaS ）将执行 As1 ，以便为对话框管理器生成文本。对话框管理器会记住对话状态，将文本路由到相应的服务，并将命令传递到实施引擎。JARVIS NLP 服务会输入文本，识别意向和实体，并将这些意向和实体插槽输出回对话框管理器，然后由该对话框管理器向执行引擎发送操作。履行引擎由问题解答用户查询的第三方 API 或 SQL 数据库组成。从实施引擎收到结果后，对话管理器会将文本路由到 JarVis TTSAIaaS ，以便为最终用户生成音频响应。我们可以归档对话历史记录，为 Nemo 培训添加意向和插槽，以便随着更多用户与系统交互， NLP 服务得到改进。</block>
  <block id="308a0722262fbc3adde5d5d900ad0c36" category="paragraph"><block ref="308a0722262fbc3adde5d5d900ad0c36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="863eef2617ffc374c485389aabdd8a24" category="paragraph">此解决方案已通过一个 DGX 工作站和一个 AFF A220 存储系统的验证。JARVIS 需要使用 T4 或 V100 GPU 来执行深度神经网络计算。</block>
  <block id="6c4fbfa85e86ba1acd8a66b367a3b2c4" category="paragraph">下表列出了在测试中实施解决方案所需的硬件组件。</block>
  <block id="71c9e70899509bff35197ba9da10dafc" category="cell">T4 或 V100 GPU</block>
  <block id="8f452959667e7665cddf2484ddca1724" category="cell">NVIDIA DGX Station</block>
  <block id="f7a05af899e536cde0a9c8476c2da0a1" category="paragraph">下表列出了在测试中实施解决方案所需的软件组件。</block>
  <block id="5acec1d6c6e07042eb0c19bc926d2633" category="cell">版本或其他信息</block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="cell">NetApp ONTAP 数据管理软件</block>
  <block id="eaf2f97729e8d5e4d205672da8afc9a5" category="cell">9.6</block>
  <block id="efdec37786e687a58664ebd4ef6bdba4" category="cell">Cisco NX-OS 交换机固件</block>
  <block id="976d6c35e21478ef03ca2cec2a74dc71" category="cell">7.0 （ 3 ） I6 （ 1 ）</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">NVIDIA DGX 操作系统</block>
  <block id="4a5be8fea83a32ad5c7fc31b02ef1028" category="cell">4.0.4 — Ubuntu 18.04 LTS</block>
  <block id="0664d9eb73230b2a0b514b0facae8ade" category="cell">NVIDIA JarVis Framework</block>
  <block id="cc5f21cb121669006a19c9fde049f048" category="cell">EA v0.2</block>
  <block id="dfcc0491fc5a6e738ca8b5ef3a258093" category="cell">NVIDIA Nemo</block>
  <block id="317fe32bf712dffb43ddc0ee8dde8c3c" category="cell">nvcr.io/nvidia/nemo ： v0.10</block>
  <block id="44769dc982b2126503d2d014bcf7c15a" category="cell">Docker 容器平台</block>
  <block id="0cc9a8e76e0a79d0e0072e0a0d675fe5" category="cell">18.06.1-ce [e68fc7a]</block>
  <block id="9783bbad26249ed7f40d89e12ba42020" category="doc">运行：适用于 AI 工作负载编排的 AI 平台</block>
  <block id="cb39fb629a91fdf37928a15d38e05318" category="list-text">加快创新速度。通过将运行： AI 资源池化，排队和优先级划分机制与 NetApp 存储系统结合使用，研究人员可以消除基础架构管理方面的麻烦，并可以专注于数据科学。运行： AI 和 NetApp 客户可以根据需要运行任意数量的工作负载，而不会出现计算或数据管道瓶颈，从而提高工作效率。</block>
  <block id="8df86cf2931aab70fd9ad1f919f40449" category="list-text">提高团队工作效率。Run ： AI 公平算法可确保所有用户和团队都能获得他们应得的资源份额。可以预设优先级项目的策略，该平台支持将资源从一个用户团队动态分配到另一个用户团队，从而帮助用户及时访问所需的 GPU 资源。</block>
  <block id="c835378d4be1896f62ef5d2760340909" category="list-text">提高 GPU 利用率。通过 Run ： AI 计划程序，用户可以轻松地使用部分 GPU ，整数 GPU 和多个 GPU 节点在 Kubernetes 上进行分布式培训。这样， AI 工作负载就可以根据需求运行，而不是根据容量运行。数据科学团队可以在同一基础架构上运行更多 AI 实验。</block>
  <block id="fa752e98365b630341b8478c89a6757f" category="doc">正在配置 Kubernetes 集群</block>
  <block id="f12c340e651d989970371432778f9be2" category="paragraph">本节将分别分为两部分，分别用于云和内部部署。</block>
  <block id="ee06675a624f2ec74e8b71b5a57f8f9e" category="section-title">云部署 Kubernetes 配置</block>
  <block id="b513a0297a0d2efdebed8ce18e2f1715" category="paragraph">通过 NetApp Cloud Manager ，您可以定义与 Iguazio Kubernetes 集群的连接。要使卷可用， Trident 需要访问集群中的多个资源。</block>
  <block id="2d5bc331cc722113dd483838e908804c" category="list-text">要启用访问，请从一个 Iguazio 节点获取 Kubernetes 配置文件。该文件位于 ` /home/Iguazio/.Kube/config 下。` 将此文件下载到桌面。</block>
  <block id="17c6b0de5b91c5c06a0d8173c89110d8" category="list-text">转至 Discover Cluster 以进行配置。</block>
  <block id="df37cca51036f4c5b59db211df5354bc" category="paragraph"><block ref="df37cca51036f4c5b59db211df5354bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b848e07dc3f62b4307419421d844f123" category="list-text">上传 Kubernetes 配置文件。请参见下图。</block>
  <block id="5bcc42d0a2624f1586064488c3484529" category="paragraph"><block ref="5bcc42d0a2624f1586064488c3484529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63de24a45facebf9f65cb6578847f2b4" category="list-text">部署 Trident 并将卷与集群相关联。有关定义永久性卷并将其分配给 Iguazio 集群的信息，请参见下图。此过程将在 Iguazio 的 Kubernetes 集群中创建永久性卷（ PV ）。在使用它之前，您必须定义永久性卷声明（ PVC ）。</block>
  <block id="eee185b539f0e52d8b64916066463222" category="paragraph"><block ref="eee185b539f0e52d8b64916066463222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8b69025b2efa1b2ccb917bc911d30ccd" category="section-title">内部部署 Kubernetes 配置</block>
  <block id="31bbf80f0649d07d3e8340123f1a6963" category="inline-link">TR-4798</block>
  <block id="5be8900878997a404baf02b07ff271c6" category="paragraph">有关 NetApp Trident 的内部安装，请参见<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> 了解详细信息。配置 Kubernetes 集群并安装 NetApp Trident 后，您可以将 Trident 连接到 Iguazio 集群以启用 NetApp 数据管理功能，例如为数据和型号创建 Snapshot 副本。</block>
  <block id="677b450634b1a6a563206526cb4d9075" category="doc">TR-4858 ：《 NetApp Orchestration 解决方案与 Run ： AI 》</block>
  <block id="0959ee1db60e15d1e8e42d1206ca6a19" category="paragraph">Rick Huang ， David Arnette ， Sung-Han Lin ， NetApp Yaron Goldberg ， Run ： AI</block>
  <block id="c87cafeb37457343ef978bbf8cad88b5" category="paragraph">NetApp AFF 存储系统可提供极致性能和行业领先的混合云数据管理功能。NetApp 与 Run ： AI 合作展示了 NetApp ONTAP AI 解决方案在人工智能（ AI ）和机器学习（ ML ）工作负载方面的独特功能，这些功能可提供企业级性能，可靠性和支持。Run ： AI 工作负载的 AI 流程编排增加了一个基于 Kubernetes 的计划和资源利用率平台，可帮助研究人员管理和优化 GPU 利用率。NetApp ， NVIDIA 和 Run ： AI 的解决方案与 NVIDIA DGX 系统相结合，可提供一个专为企业 AI 工作负载构建的基础架构堆栈。本技术报告为客户构建对话式 AI 系统以支持各种用例和行业垂直市场提供了方向性指导。其中包括有关部署 Run ： AI 和 NetApp AFF A800 存储系统的信息，并可作为参考架构来快速成功地部署 AI 计划。</block>
  <block id="cae36004793b7131e0fc2323f598e7bb" category="list-text">为容器化微服务等基于 Kubernetes 的用例设计 AI 模型和软件开发解决方案的企业架构师</block>
  <block id="5d138e1f42e31fb645a3e3f5a8d37929" category="list-text">数据科学家正在寻找高效的方法，以便在具有多个团队和项目的集群环境中实现高效的模型开发目标</block>
  <block id="0d43a0c7aeec219a746e836746c0b208" category="list-text">负责维护和运行生产模型的数据工程师</block>
  <block id="00d764d2e91381a99d6f2c7b108e7c8e" category="list-text">希望打造最佳 Kubernetes 集群资源利用体验并通过 AI 计划缩短上市时间的高管和 IT 决策者和业务主管</block>
  <block id="01360221b637a04fa184dc6b9355fa46" category="summary">在创建此解决方案时，我们执行了简单的性能比较。我们使用 Kubernetes 执行了多个标准 NetApp 基准测试作业，并将基准测试结果与使用简单 Docker run 命令执行的执行情况进行了比较。</block>
  <block id="0e2f0f77407bfd956f621e13b8c1be34" category="doc">性能测试</block>
  <block id="467941822b3a557a8db7197e12285f14" category="paragraph">在创建此解决方案时，我们执行了简单的性能比较。我们使用 Kubernetes 执行了多个标准 NetApp AI 基准测试作业，并将基准测试结果与使用简单 Docker run 命令执行的执行情况进行了比较。我们没有发现任何明显的性能差异。因此，我们得出的结论是，使用 Kubernetes 编排容器化 AI 培训作业不会对性能产生负面影响。有关性能比较结果，请参见下表。</block>
  <block id="74575b23d5305310e904f87eb02ff980" category="cell">基准测试</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">数据集</block>
  <block id="c269688995d2959579fca276425898b8" category="cell">Docker 运行（映像 / 秒）</block>
  <block id="b3acbf223e2bb7a3a796e3b698a7748d" category="cell">Kubernetes （图像 / 秒）</block>
  <block id="6de4dbc350a60fb9d5ea80ac7854681d" category="cell">单节点 TensorFlow</block>
  <block id="2ec7cdace40d8a092e842288dfe854f7" category="cell">合成数据</block>
  <block id="a5ee9f5535788c17b947b7f2d8354351" category="cell">6,667.2475</block>
  <block id="b573d76a35b8d44de29524f11e873c60" category="cell">6,661.93125</block>
  <block id="b318879f822314efe94c2f096d06465c" category="cell">ImageNet</block>
  <block id="f9622443c76d58838af97acd4f0c12ed" category="cell">6,570.2025</block>
  <block id="f93ed9c22230ae6e2ed85323e8d3dff7" category="cell">6,530.59125</block>
  <block id="83817408eae44458daefc1a9516ad170" category="cell">同步分布式双节点 TensorFlow</block>
  <block id="d4b63997154f30598f823403bb4df7ba" category="cell">13,213.70625</block>
  <block id="a328a929a422e4b69be5bbe94694282e" category="cell">13,218.288125</block>
  <block id="209f721713f475a9a0f4ba2743b40853" category="cell">12,941.69125</block>
  <block id="1f07dab13107a813c6d35bb76648ec48" category="cell">12,881.33875</block>
  <block id="66bc9494be0116470b223f2e07873f77" category="summary">本页介绍部署 Kubernetes 集群以实施 NetApp AI 控制平面解决方案时必须完成的任务。如果您已有 Kubernetes 集群，则只要您运行的是 Kubernetes 和 NetApp Trident 支持的 Kubernetes 版本，就可以跳过本节。</block>
  <block id="2034cc978abb3057c4cf27e92b16ee74" category="doc">Kubernetes 部署</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">Kubeflow 官方文档</block>
  <block id="7c1ab988344d6a8d8cd9a30d6240955a" category="paragraph">本节介绍部署 Kubernetes 集群以实施 NetApp AI 控制平面解决方案时必须完成的任务。如果您已有 Kubernetes 集群，则只要您运行的是 Kubernetes 和 NetApp Trident 支持的 Kubernetes 版本，就可以跳过本节。有关 Kubeflow 支持的 Kubernetes 版本列表，请参见<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>。有关 Trident 支持的 Kubernetes 版本列表，请参见<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="ef8333b35fd982099a6ca0c7799b5618" category="paragraph">对于采用采用 NVIDIA GPU 的裸机节点的内部 Kubernetes 部署， NetApp 建议使用 NVIDIA 的 DeepOps Kubernetes 部署工具。本节概述了使用 DeepOps 部署 Kubernetes 集群的过程。</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">在执行本节所述的部署练习之前，我们假定您已执行以下任务：</block>
  <block id="612cba744b0eac9a7f153d2c4b8975da" category="list-text">您已按照标准配置说明配置任何裸机 Kubernetes 节点（例如，属于 ONTAP AI POD 的 NVIDIA DGX 系统）。</block>
  <block id="5a881e8e37e19924ac592136b5e7cfd3" category="inline-link">DeepOps GitHub 站点</block>
  <block id="452f5f6e8da4512f6cce223a76ae3558" category="list-text">您已在所有 Kubernetes 主节点和工作节点以及部署跳转主机上安装受支持的操作系统。有关 DeepOps 支持的操作系统列表，请参见<block ref="253a2cf380d7db7eaadb375aa91e2221" category="inline-link-rx"></block>。</block>
  <block id="a711e4ccced882d1762a8c653be8e921" category="section-title">使用 NVIDIA DeepOps 安装和配置 Kubernetes</block>
  <block id="47302a7393e0a038a150e679c9b3e80d" category="paragraph">要使用 NVIDIA DeepOps 部署和配置 Kubernetes 集群，请从部署跳转主机执行以下任务：</block>
  <block id="5c51dc3fcfdd9653809e90fa3948c2f4" category="inline-link">Getting Started 页面</block>
  <block id="0e91d2e60705ecb1730e9b96510019af" category="list-text">按照上的说明下载 NVIDIA DeepOps<block ref="6fb71807bf6999d2aec034d498e3ebf6" category="inline-link-rx"></block> 在 NVIDIA DeepOps GitHub 站点上。</block>
  <block id="2ed5978807d3da780c60a19b3f38a293" category="inline-link">Kubernetes 部署指南页面</block>
  <block id="5c18e4efa8c5cc9efb26e3f748b4e26d" category="list-text">按照上的说明在集群中部署 Kubernetes<block ref="b336a8bbad16f0e8d58bf87e261f51fa" category="inline-link-rx"></block> 在 NVIDIA DeepOps GitHub 站点上。</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">解决方案概述</block>
  <block id="bff183f31dd9706bece9767f4388a819" category="paragraph">由 NVIDIA DGX 系统和 NetApp 云连接存储系统提供支持的 NetApp ONTAP AI 架构由 NetApp 和 NVIDIA 开发并验证。此参考架构为 IT 组织提供了以下优势：</block>
  <block id="88acd7d612f76d7928b6b0448806e1ea" category="list-text">为各种性能和成本点提供一系列存储选项 NetApp ONTAP AI 可将 DGX 系统和 NetApp AFF A220 存储系统与一流的网络紧密集成在一起。NetApp ONTAP AI 和 DGX 系统消除了设计复杂性和猜测性工作，从而简化了 AI 部署。客户可以从小规模入手，无中断地扩展系统，同时智能地管理从边缘到核心再到云再到云的数据。</block>
  <block id="45f2cdf50f8bb89b245e814009b4244c" category="section-title">NVIDIA JarVis 多模式框架</block>
  <block id="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="paragraph"><block ref="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ad66827309f61fd22dc58cbbb2f8273" category="inline-link">NVIDIA JarVis</block>
  <block id="241d985aedf9124840f9adfa9496755d" category="paragraph"><block ref="9f89431954623c8e5c580e4350b427e7" category="inline-link-rx"></block> 是一个端到端框架，用于构建对话式 AI 服务。它包括以下经过 GPU 优化的服务：</block>
  <block id="bb3e7af8136880e3a92118c172aed302" category="list-text">自动语音识别（ Automatic Speech Recognition ， As1 ）</block>
  <block id="3c07089a439435a2998f14ea97f90825" category="list-text">自然语言理解（ NLF ）</block>
  <block id="8375cc1d63ce172363c4ed9c3cddd508" category="list-text">与域特定的履行服务集成</block>
  <block id="84fb561f92aa70d5e118f429e98ee99b" category="list-text">文本语音转换（ TTS- 语音转换）</block>
  <block id="9478a4e1be70e1be0fdd56f3929bbdc2" category="list-text">基于计算机视觉（ CV ） Jarvis 的服务使用最先进的深度学习模型来应对实时对话 AI 这一复杂且极具挑战性的任务。要与最终用户进行实时自然的交互，模型需要在 300 毫秒内完成计算。自然交互具有挑战性，需要多模式感知集成。模型管道也很复杂，需要在上述服务之间进行协调。</block>
  <block id="c29efa8b1d5c9d6d647a8ce72bef1b74" category="paragraph">JarVis 是一个完全加速的应用程序框架，用于构建使用端到端深度学习管道的多模式对话 AI 服务。JARVIS 框架包括经过预先培训的人工智能对话模型，工具以及针对语音，视觉和 NLU 任务优化的端到端服务。除了 AI 服务之外， JarVis 还支持您同时融合视觉，音频和其他传感器输入，以便在虚拟助手，多用户化和呼叫中心助理等应用程序中提供多用户，多上下文对话等功能。</block>
  <block id="dc3652fc64a2a6ea2a3cfd5c40443b16" category="paragraph"><block ref="4282ee73b9eecd67e90ed51f4f36b077" category="inline-link-rx"></block> 是一款开源 Python 工具包，用于使用易于使用的应用程序编程接口（ API ）构建，培训和微调 GPU 加速的一流对话 AI 模型。Nemo 使用 NVIDIA GPU 中的 Tensor 核心运行混合精度计算，并可轻松扩展到多个 GPU ，以提供尽可能高的训练性能。Nemo 用于为视频呼叫记录，智能视频助理以及医疗保健，金融，零售和电信等不同行业的自动呼叫中心支持等实时应用程序构建模型。</block>
  <block id="4e5ae683e2a399c166a1724b0aa6952e" category="paragraph">我们使用 Nemo 来训练模型，以便识别归档对话历史记录中用户问题的复杂意图。此培训将零售虚拟助手的功能扩展到了 Jarvis 所提供的功能之外。</block>
  <block id="053bc62e92a61e44afd338bcb27c422f" category="section-title">零售用例摘要</block>
  <block id="e1196fc000d661461f32bcaab7319c6a" category="inline-link">针对零售用例自定义状态和流程</block>
  <block id="8b6b761738b93e745ffa4f73dd233c08" category="paragraph">我们使用 NVIDIA Jarvis 构建了一个虚拟零售助理，可接受语音或文本输入并回答有关天气，关注点和库存定价的问题。对话式 AI 系统能够记住对话流，例如，如果用户未指定天气或感兴趣点的位置，可以询问跟进问题。系统还可以识别诸如 " 泰国食品 " 或 " 笔记本电脑内存 " 等复杂实体。 它了解自然语言问题，例如 " 下星期在洛杉矶会下雨吗？ " 有关零售虚拟助手的演示，请参见<block ref="0ba395e7fb59bace5ff35ab3c02ad737" category="inline-link-rx"></block>。</block>
  <block id="c755c33dca37a8aaffbf190bdf3f5fef" category="paragraph">此解决方案是在一个 NetApp AFF A800 系统，两个 DGX-1 服务器和两个 Cisco Nexus 3232C 100GbE 交换机上实施的。每个 DGX-1 服务器都通过四个 100GbE 连接连接连接到 Nexus 交换机，这些连接可通过使用基于融合以太网（ RoCE ）的远程直接内存访问（ RDMA ）进行 GPU 间通信。NFS 存储访问的传统 IP 通信也发生在这些链路上。每个存储控制器均使用四个 100GbE 链路连接到网络交换机。下图显示了本技术报告中用于所有测试场景的 ONTAP AI 解决方案架构。</block>
  <block id="782c9fdc3f29358987c2f5b99fe9e6b9" category="paragraph"><block ref="782c9fdc3f29358987c2f5b99fe9e6b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf8b135ff3c775c5b9bbba1b2f7a61ce" category="section-title">此解决方案中使用的硬件</block>
  <block id="a4ec49885c617f2b2500789af7e6eebf" category="paragraph">此解决方案已使用 ONTAP AI 参考架构两个 DGX-1 节点和一个 AFF A800 存储系统进行了验证。请参见<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> 有关此验证中使用的基础架构的更多详细信息。</block>
  <block id="fe59cdcdefd7c53625e1e745b9c5be09" category="cell">DGX-1 系统</block>
  <block id="53270fbfda62583949b287e08ae3d063" category="cell">AFF A800</block>
  <block id="6da64488bfb7f3216610e30ced34ff23" category="cell">Nexus 3232C 交换机</block>
  <block id="8e926487edd9348114ada5fa88a732df" category="paragraph">此解决方案已通过安装了 Run ： AI 操作员的基本 Kubernetes 部署进行验证。Kubernetes 是使用部署的<block ref="1c894f7463797b81796e78efc8345fb0" category="inline-link-rx"></block> 部署引擎，用于为生产就绪环境部署所有必需的组件。DeepOps 会自动部署<block ref="ca1c90879f9a0e8dc4ff805fb398f7ff" category="inline-link-rx"></block> 为了与 K8s 环境实现持久存储集成，我们创建了默认存储类，以便容器可以利用 AFF A800 存储系统中的存储。有关在 ONTAP AI 上使用 Kubernetes 进行 Trident 的详细信息，请参见<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block>。</block>
  <block id="a2525584dd9d2a9522ddea95841c06b3" category="cell">9.6 第 4 页</block>
  <block id="80afba45eb055fc9bdc48c90d1debd06" category="cell">Kubernetes 版本</block>
  <block id="4bbe90408850f459864a71c8054732f1" category="cell">1.17</block>
  <block id="f1112223b41fddc71fd6a626582dfb78" category="cell">Trident 版本</block>
  <block id="43d66966083b0e0feac8fb9be14ba5b8" category="cell">20.04.0</block>
  <block id="e993176eed424766bc6bd4758eaf2cb6" category="cell">运行： AI 命令行界面</block>
  <block id="5e6305186adf6e7dcf03f5cbfc802c49" category="cell">v2.1.13</block>
  <block id="f3eeed8e4b2791f80e2f123c4720aef5" category="cell">运行： AI Orchestration Kubernetes Operator 版本</block>
  <block id="bf8c2933a2f54ce25fe986f66d3bffa3" category="cell">1.0.39</block>
  <block id="076ca75e2fc5b6ea85d72b0a9adc8844" category="inline-link">运行： AI GPU 集群前提条件</block>
  <block id="eaec7f01752b17abf6125d8f29a8543c" category="paragraph">有关 Run ： AI 的其他软件要求，请参见<block ref="98bb21d82bcd499a183c82dcfc9b02f3" category="inline-link-rx"></block>。</block>
  <block id="dbb4dd9a11f48db13d63eedaae717fe5" category="doc">为数据科学团队创建项目并分配 GPU</block>
  <block id="22d09d229a06f294b0f45804f8e639d3" category="paragraph">研究人员可以通过 Run ： AI CLI ， Kubeflow 或类似流程提交工作负载。为了简化资源分配并创建优先级， Run ： AI 引入了项目概念。项目是指将项目名称与 GPU 分配和首选项关联的配额实体。这是一种管理多个数据科学团队的简单便捷的方式。</block>
  <block id="c0bd05e9d88cf015eac684873bfd14c7" category="paragraph">提交工作负载的研究人员必须将项目与工作负载请求相关联。运行： AI 计划程序会将请求与当前分配和项目进行比较，并确定是否可以为工作负载分配资源或是否应保持待定状态。</block>
  <block id="800f40fa67f69116bf6f38cd07456608" category="paragraph">作为系统管理员，您可以在 Run ： AI projects 选项卡中设置以下参数：</block>
  <block id="9c429f2284a95aaa299c7d85ccb16734" category="list-text">* 模拟项目。 * 为每个用户设置一个项目，为每个用户团队设置一个项目，并为每个实际组织项目设置一个项目。</block>
  <block id="b2f1422cf0d082a495bbf865b9a5621d" category="list-text">* 项目配额。 * 每个项目都与一个 GPU 配额相关联，可以同时为此项目分配 GPU 配额。这是一个有保障的配额，因为使用此项目的研究人员无论在集群中处于何种状态，都可以获得这一数量的 GPU 。通常，项目分配总和应等于集群中的 GPU 数量。除此之外，此项目的用户还可以收到超配额。只要未使用 GPU ，使用此项目的研究人员就可以获得更多 GPU 。我们在中演示了超额配额测试场景和公平考虑事项<block ref="9563fd9ab6978412dc97d80a70e51786" category="inline-link-rx"></block>，<block ref="a8ad108feafc827856baa28b0b9070ed" category="inline-link-rx"></block>，和<block ref="be867f64efefe193012b1dfc6c82f783" category="inline-link-rx"></block>。</block>
  <block id="20a3a45fbbd9502add12fd216350d569" category="list-text">创建新项目，更新现有项目并删除现有项目。</block>
  <block id="3bf13b237342258b6ddb3f167d679a3b" category="inline-link">运行： AI 文档</block>
  <block id="77332641abf52ec5dc1af8b23b2339f3" category="list-text">* 限制作业在特定节点组上运行 * 。您可以分配仅在特定节点上运行的特定项目。如果项目团队需要专用硬件，例如具有足够内存的硬件，则此功能非常有用。或者，项目团队也可能是特定硬件的所有者，这些硬件是通过专门预算获得的，或者您可能需要直接构建或交互式工作负载来处理较弱的硬件，并将较长的培训或无人看管的工作负载定向到较快的节点。有关对节点进行分组并为特定项目设置相关性的命令，请参见 <block ref="eae60ce89b8727160634b52e7654bf73" category="inline-link-rx"></block>。</block>
  <block id="2bd802cca9bf193b441123437f5d39ca" category="list-text">* 限制交互作业的持续时间 * 。研究人员经常忘记关闭交互式作业。这可能会导致资源浪费。一些组织倾向于限制交互式作业的持续时间并自动关闭这些作业。</block>
  <block id="10c2495ded559d79de96be22751712dc" category="paragraph">下图显示了已创建四个团队的 " 项目 " 视图。每个团队分配不同数量的 GPU 来处理不同的工作负载， GPU 总数等于由两个 DGX-1 组成的集群中可用 GPU 总数。</block>
  <block id="9ba047faa1d241a6153be986be27097f" category="paragraph"><block ref="9ba047faa1d241a6153be986be27097f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e40fd8f5f0e113c758dfa63adc1221d" category="summary">Kubeflow 能够快速配置新的 Jupyter 笔记本电脑服务器，以充当数据科学家工作空间。要使用 Kubeflow 配置新的 Jupyter 笔记本电脑服务器，请执行此页面上列出的任务。</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">为数据科学家或开发人员配置 Jupyter 笔记本电脑工作空间</block>
  <block id="52d84951381eb0ab7a285dd32b31702c" category="paragraph">Kubeflow 能够快速配置新的 Jupyter 笔记本电脑服务器，以充当数据科学家工作空间。要使用 Kubeflow 配置新的 Jupyter 笔记本电脑服务器，请执行以下任务。有关 Kubeflow 上下文中 Jupyter 笔记本电脑的详细信息，请参见<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block>。</block>
  <block id="5e82e4aa94a53b3b50acf347914be197" category="list-text">从 Kubeflow 中央信息板中，单击主菜单中的 Notebook Servers 以导航到 Jupyter 笔记本电脑服务器管理页面。</block>
  <block id="358d18b5a42ec1d80b04e767298ea372" category="paragraph"><block ref="358d18b5a42ec1d80b04e767298ea372" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208feb7a4d57f0afc49e53fe1fe8b978" category="list-text">单击新服务器以配置新的 Jupyter 笔记本电脑服务器。</block>
  <block id="3541a3b25823fa3b302c686b6fe2a212" category="paragraph"><block ref="3541a3b25823fa3b302c686b6fe2a212" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f95069a2e81949b101427e1fa4afddf" category="list-text">为新服务器指定一个名称，选择希望服务器基于的 Docker 映像，并指定服务器要预留的 CPU 和 RAM 量。如果命名空间字段为空，请使用页面标题中的选择命名空间菜单选择命名空间。然后， Namespace 字段将自动填充所选命名空间。</block>
  <block id="4fbbbc4aaa49d653f486738eed12357a" category="paragraph">在以下示例中，选择了 `kubeflow-anonymous` 命名空间。此外，还接受 Docker 映像， CPU 和 RAM 的默认值。</block>
  <block id="69bc8b3ae7667985c27ce3ef5de0e6ca" category="paragraph"><block ref="69bc8b3ae7667985c27ce3ef5de0e6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Kubeflow 部署</block>
  <block id="095efbb867f01094d56c633d3337a412" category="list-text">指定工作空间卷详细信息。如果选择创建新卷，则会使用默认 StorageClass 配置该卷或 PVC 。因为在部分中，使用 Trident 的 StorageClass 被指定为默认 StorageClass <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>，卷或 PVC 配置有 Trident 。此卷会自动挂载为 Jupyter 笔记本电脑服务器容器中的默认工作空间。用户在服务器上创建但未保存到单独数据卷的任何笔记本电脑将自动保存到此工作空间卷。因此，这些笔记本电脑在重新启动后会持久存在。</block>
  <block id="c44927b0124469511a724e179c80bfb5" category="paragraph"><block ref="c44927b0124469511a724e179c80bfb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="555e44b3745904843417371073338d08" category="list-text">添加数据卷。以下示例指定了一个名为 "pt-fg-all" 的现有 PVC 并接受默认挂载点。</block>
  <block id="0c73069b282d8e99ecbd8feb39164d40" category="paragraph"><block ref="0c73069b282d8e99ecbd8feb39164d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b120f9006af3d27ef70eb256c99c6617" category="list-text">* 可选： * 请求将所需数量的 GPU 分配给您的笔记本服务器。在以下示例中，请求一个 GPU 。</block>
  <block id="c969e6364e4561a959d1ce20f7187723" category="paragraph"><block ref="c969e6364e4561a959d1ce20f7187723" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8da2142543d647576288d71dddabb01" category="list-text">单击启动以配置新的笔记本电脑服务器。</block>
  <block id="37a742c47c216725dd178d8c3c7a3f31" category="list-text">等待笔记本电脑服务器完全配置完毕。如果您从未使用您指定的 Docker 映像配置服务器，则可能需要几分钟的时间，因为需要下载此映像。服务器配置完成后， Jupyter 笔记本电脑服务器管理页面上的状态列会显示一个绿色复选标记。</block>
  <block id="417a2eafac6842560d3900cf9d12b5bb" category="paragraph"><block ref="417a2eafac6842560d3900cf9d12b5bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0463a63e8059055e703ecd9ffa72e106" category="list-text">单击连接以连接到新的服务器 Web 界面。</block>
  <block id="4fbf21602f4888216386998d62f1defd" category="list-text">确认步骤 6 中指定的数据集卷已挂载到服务器上。请注意，默认情况下，此卷会挂载在默认工作空间中。从用户的角度来看，这只是工作空间中的另一个文件夹。用户可能是数据科学家，而不是基础架构专家，因此使用此卷无需具备任何存储专业知识。</block>
  <block id="c4b6acc44505864a5dccae2571b74f6a" category="paragraph"><block ref="c4b6acc44505864a5dccae2571b74f6a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7d375154397ce9358d2234ec578ff7e" category="paragraph"><block ref="a7d375154397ce9358d2234ec578ff7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="479d03862d87da58784e60e5cfcec977" category="list-text">打开一个终端，假设步骤 5 中请求了一个新卷，请执行 `df -h` 以确认已挂载新的 Trident 配置的永久性卷作为默认工作空间。</block>
  <block id="68f39a4f77e618e6617c3830fb47de7c" category="paragraph">默认工作空间目录是首次访问服务器的 Web 界面时显示的基目录。因此，使用 Web 界面创建的任何项目都会存储在此 Trident 配置的永久性卷上。</block>
  <block id="d3e91c75db0cb717734224e6eb72e201" category="paragraph"><block ref="d3e91c75db0cb717734224e6eb72e201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d739fe0e421e9cb4d6315f0021cc5eb" category="paragraph"><block ref="1d739fe0e421e9cb4d6315f0021cc5eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8c20de15cf5efa2297f9d40d899450e" category="list-text">使用终端运行 `nvidia-smi` 以确认为笔记本电脑服务器分配了正确数量的 GPU 。在以下示例中，已按照步骤 7 中的请求为笔记本电脑服务器分配一个 GPU 。</block>
  <block id="ed4e7225349e5c6cd33dfd15ad878438" category="paragraph"><block ref="ed4e7225349e5c6cd33dfd15ad878438" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a37acabf89826767b5a5fcb8dacffa3" category="summary">此页面介绍了在 Kubernetes 集群中部署 Kubeflow 必须完成的任务。</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">本节介绍在 Kubernetes 集群中部署 Kubeflow 必须完成的任务。</block>
  <block id="f48269a81318d4bd2dd9e57a8239fe56" category="list-text">您已有一个有效的 Kubernetes 集群，并且正在运行 Kubernetes 支持的版本。有关支持的版本列表，请参见<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>。</block>
  <block id="3429b7e0331de8d2f8d377b034ca6855" category="inline-link-macro">Trident 部署和配置</block>
  <block id="9fc644d78f21555decceeddf5b691fa4" category="list-text">您已在 Kubernetes 集群中安装和配置 NetApp Trident ，如中所述 <block ref="ec7700e2b8d95edf2f2700b590eab273" category="inline-link-macro-rx"></block>。</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">设置默认 Kubernetes StorageClass</block>
  <block id="e1be30d98edccc10974d5d339832197c" category="paragraph">在部署 Kubeflow 之前，您必须在 Kubernetes 集群中指定一个默认 StorageClass 。Kubeflow 部署过程会尝试使用默认 StorageClass 配置新的永久性卷。如果未将任何 StorageClass 指定为默认 StorageClass ，则部署将失败。要在集群中指定默认 StorageClass ，请从部署跳转主机执行以下任务。如果已在集群中指定默认 StorageClass ，则可以跳过此步骤。</block>
  <block id="e3e4fbe325df2b20670ca04ad0c2a517" category="list-text">将现有 StorageClasses 之一指定为默认 StorageClass 。以下示例命令显示了名为 `ontap-ai- FlexVols-Retain` 的 StorageClass 的默认 StorageClass 。</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">`ontap-nas-flexgroup` Trident 后端类型的最小 PVC 大小相当大。默认情况下， KubeFlow 会尝试配置大小只有少数几 GB 的 PVC 。因此，在部署 Kubeflow 时，不应将利用 `ontap-nas-flexgroup` 后端类型的 StorageClass 指定为默认 StorageClass 。</block>
  <block id="f12aad36b1ab9194dd8bc67542366bff" category="section-title">使用 NVIDIA DeepOps 部署 Kubeflow</block>
  <block id="3e1922d78dd7bdb1e8d7e7bd8f5aa92c" category="paragraph">NetApp 建议使用 NVIDIA DeepOps 提供的 Kubeflow 部署工具。要使用 DeepOps 部署工具在 Kubernetes 集群中部署 Kubeflow ，请从部署跳转主机执行以下任务。</block>
  <block id="3ede8bc1f55c95b9a16b2429e0b9bbcc" category="admonition">或者，您也可以按照手动方式部署 Kubeflow<block ref="c75d7e23bc80ca81cea11fe427173cb3" category="inline-link-rx"></block> 在 Kubeflow 官方文档中</block>
  <block id="a73d6d865f72179145299c720c53d39c" category="inline-link">Kubeflow 部署说明</block>
  <block id="04e3c704baa1b4c23cd48a18c10fcf39" category="list-text">按照中的说明在集群中部署 Kubeflow<block ref="5e7f04c1dfa70dd058d2720be031c44b" category="inline-link-rx"></block> 在 NVIDIA DeepOps GitHub 站点上。</block>
  <block id="2efdbab31c5d41a149e5092f4b8d7e48" category="list-text">记下 DeepOps Kubeflow 部署工具输出的 Kubeflow 信息板 URL 。</block>
  <block id="b714a06d49f16f8b7f988d95734d177f" category="list-text">确认在 Kubeflow 命名空间中部署的所有 Pod 均显示 `Ststatus` of `running` ，并确认命名空间中部署的任何组件均未处于错误状态。可能需要几分钟时间，才能启动所有 Pod 。</block>
  <block id="d6049afd6b1943d1e98ca6347dd907c5" category="list-text">在 Web 浏览器中，通过导航到步骤 2 中记下的 URL 来访问 Kubeflow 中央信息板。</block>
  <block id="64f559cf2e77f73aca6bd3dc9649f62c" category="paragraph">默认用户名为 `admin@kubeflow.org` ，默认密码为 `1231234` 。要创建其他用户，请按照中的说明进行操作<block ref="f529217f090b2c9cc3764f14abdec5f7" category="inline-link-rx"></block>。</block>
  <block id="2d84920115f9dc91fe2d35c4dc07eaf0" category="paragraph"><block ref="2d84920115f9dc91fe2d35c4dc07eaf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48c4dc7fbfa1197490124f13eb565bd2" category="doc">ONTAP AI 部署</block>
  <block id="70d5c23ad68d59b2546133efdd1c3267" category="inline-link">NVA-1121-Deploy ：由 NVIDIA 提供支持的 NetApp ONTAP AI</block>
  <block id="b393f072bc6b17085b75486a2abbcf97" category="paragraph">部署 ONTAP AI 需要安装和配置网络，计算和存储硬件。本文档不会介绍有关部署 ONTAP AI 基础架构的具体说明。有关详细的部署信息，请参见<block ref="8c03c9c25bc6aba17e86c510148a3423" category="inline-link-rx"></block>。</block>
  <block id="03e335ae74b1356b294af55e07eb6b70" category="paragraph">在此解决方案验证中，创建了一个卷并将其挂载到 DGX-1 系统。然后，该挂载点会挂载到容器中，以使数据可供训练访问。对于大规模部署， NetApp Trident 可自动创建和挂载卷，以消除管理开销并支持最终用户管理资源。</block>
  <block id="7a879e305f90568b91e8623ce5f9ee39" category="summary">自 2019 年 5 月起， Microsoft 推出了 Azure 原生，这是基于 NetApp ONTAP 技术的第一方门户服务，适用于企业级 NFS 和 SMB 文件服务。</block>
  <block id="0bf51d984b6a6d3fddc0e24f62eb1a14" category="doc">TR-4896 ： Azure 中的分布式培训：通道检测—解决方案设计</block>
  <block id="0ab5aa2896d8eed7732e69be5e5782b4" category="paragraph">NetApp Ronen Dar 的 Mameer Ahmad 和 Verron Martina ， Run ： AI</block>
  <block id="a89ade32996e322edf837476febbc9bd" category="paragraph">自 2019 年 5 月起， Microsoft 推出了 Azure 原生，这是基于 NetApp ONTAP 技术的第一方门户服务，适用于企业级 NFS 和 SMB 文件服务。这一发展由 Microsoft 和 NetApp 之间的战略合作伙伴关系推动，进一步将世界级 ONTAP 数据服务的覆盖范围扩展到 Azure 。</block>
  <block id="d6312cb01ee08559dbaa35c308e72268" category="paragraph">作为领先的云数据服务提供商， NetApp 与 Run ： AI 合作，这是一家对 AI 基础架构进行虚拟化的公司，可以利用全 GPU 利用率加快 AI 实验速度。通过这种合作关系，团队可以并行运行多项实验，快速访问数据并利用无限计算资源，从而加快 AI 的运行速度。运行： AI 通过自动分配资源来充分利用 GPU ，而经验证的 Azure NetApp Files 架构可以消除数据管道障碍，让每个实验都能以最高速度运行。</block>
  <block id="5234f8ee670afed8c398940a707f25df" category="paragraph">NetApp 和 Run ： AI 联手为客户在 Azure 中的人工智能之旅提供一个适应未来需求的平台。从分析和高性能计算（ HPC ）到自主决策（客户只需在需要时为所需的资源付费，即可优化 IT 投资）， NetApp 与 Run 之间的联合： AI 在 Azure Cloud 中提供统一的体验。</block>
  <block id="74c071ff3c1d6d6fc39b72d617aefdf8" category="doc">解决方案部署和验证详细信息</block>
  <block id="b122830b8b8edd9e76690ea23b0c4cbd" category="paragraph">以下各节将讨论解决方案部署和验证的详细信息。</block>
  <block id="d052a88935efadcc9eebf94684d52e19" category="doc">实现高集群利用率</block>
  <block id="27d597678185c0988ffb2dbb0c1b941d" category="inline-link-macro">使用 ImageNet 数据集的 RESNET-50 基准测试摘要</block>
  <block id="8d46742dbd21a217f738a9ca6a31f634" category="paragraph">在本节中，我们模拟了一个实际场景，其中四个数据科学团队各自提交自己的工作负载，以展示 Run ： AI Orchestration 解决方案，它可以在保持 GPU 资源优先级和平衡的同时实现高集群利用率。我们首先使用一节中所述的 RESNET-50 基准测试 <block ref="5872a8c23866a6bf186843724ee58ad7" category="inline-link-macro-rx"></block>：</block>
  <block id="14f48338822299bdf82bb4528d3c9e07" category="paragraph">我们运行的 RESNET-50 基准测试与中相同<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block>。对于不驻留在公有 Docker 存储库中的容器，我们使用了标志 ` -local-image` 。我们将主机 DGX-1 节点上的目录 ` /mnt` 和 ` /tm` 分别挂载到 ` /mnt` 和 ` /tm` 。该数据集位于 NetApp AFFA800 上，并且 `dataset_dir` 参数指向目录。` -num_devices=1` 和 ` -g 1` 表示我们为此作业分配一个 GPU 。前者是 `run.py` 脚本的参数，而后者是 `runai Submit` 命令的标志。</block>
  <block id="bccb844975c2eec86eb25c0d8e2a989b" category="paragraph">下图显示了一个系统概述信息板，其中 GPU 利用率为 97% ，所有十六个可用 GPU 均已分配。您可以在 GPU/ 项目条形图中轻松查看为每个团队分配的 GPU 数量。" 正在运行的作业 " 窗格显示当前正在运行的作业名称，项目，用户，类型，节点， GPU 已用，运行时间，进度和利用率详细信息。队列中的工作负载列表及其等待时间显示在 "Pending" 作业中。最后，节点框将提供集群中各个 DGX-1 节点的 GPU 编号和利用率。</block>
  <block id="1acc627e7c9d8002628b2e12c91ac683" category="paragraph"><block ref="1acc627e7c9d8002628b2e12c91ac683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ff1a758f526c5ceb434059efe27020a" category="summary">Apache 气流工作流示例</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">适用于 Kubernetes 的 NetApp 数据科学工具包</block>
  <block id="c5da96d7204df28dd9fdc33139c8a776" category="paragraph">。<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> 可与气流结合使用。通过将 NetApp 数据科学工具包与 Airflow 结合使用，您可以将 NetApp 数据管理操作整合到由 Airflow 协调的自动化工作流中。</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">气流示例</block>
  <block id="9fc322b3a5bb56d2d6ac18c15773d1c2" category="paragraph">请参见<block ref="c50bba54faf39c027cd571674d44a9c0" category="inline-link-rx"></block> 有关在 Airflow 中使用工具包的详细信息，请参见 NetApp Data Science Toolkit GitHub 存储库中的一节。</block>
  <block id="fbe29309a183681bc26203d4c65853a2" category="paragraph">本节将介绍传统数据科学管道及其缺点。此外，还介绍了建议的数据集缓存解决方案的架构。</block>
  <block id="1f14aecc1193f646e0005e27fbc6e63d" category="section-title">传统数据科学管道和缺点</block>
  <block id="17fb7d0ba5495199d3e18fe23dff7b59" category="paragraph">ML 模型开发和部署的典型顺序涉及以下迭代步骤：</block>
  <block id="63e1ded7e3ae73253b5c287bc9bdef02" category="list-text">正在载入数据</block>
  <block id="52e028dc7ac82e9d4b7b1ae588fecc9a" category="list-text">数据预处理（创建多个版本的数据集）</block>
  <block id="33cd0fcdd9ee7e650043133b12516155" category="list-text">运行多个涉及超参数优化，不同型号等的实验</block>
  <block id="b85c416c94e0c5314a1e6fcc21d4139e" category="list-text">Monitoringcnvrg.io 开发了一个全面的平台，可以自动执行从研究到部署的所有任务。下图显示了与管道相关的一小部分信息板屏幕截图。</block>
  <block id="5a5ade85e7f7478bcba59e8c3891c914" category="paragraph"><block ref="5a5ade85e7f7478bcba59e8c3891c914" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26d6a4638ffd0b7779f1353f5fe54f0d" category="paragraph">从公有存储库和私有数据中使用多个数据集非常常见。此外，每个数据集可能具有多个版本，这些版本是由数据集清理或功能工程产生的。需要一个信息板来提供数据集中心和版本中心，以确保团队可以使用协作和一致性工具，如下图所示。</block>
  <block id="e884d73b6a4214bea010ec3bbfdad8b6" category="paragraph"><block ref="e884d73b6a4214bea010ec3bbfdad8b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93661dde7027bf31b3d007740a3d4648" category="paragraph">管道的下一步是培训，这需要多个并行的培训模型实例，每个实例都与一个数据集和一个特定计算实例相关联。将数据集绑定到使用特定计算实例的特定实验是一项挑战，因为某些实验可能由 Amazon Web Services （ AWS ）中的 GPU 实例执行，而其他实验则由内部 DGX-1 或 DGX-2 实例执行。可能会在 GCP 的 CPU 服务器中执行其他实验，但数据集位置与执行培训的计算资源不是很近。如果距离合理，则从数据集存储到计算实例的连接将达到全 10GbE 或更高的低延迟。</block>
  <block id="ba4f5ee1b0d01d3416723cfc3ec296ec" category="paragraph">数据科学家通常会将数据集下载到执行培训和实验的计算实例中。但是，此方法可能会出现以下几个问题：</block>
  <block id="90b6a1c5b483f6c6b399bc17c5e1af9a" category="list-text">当数据科学家将数据集下载到计算实例时，无法保证集成计算存储具有高性能（高性能系统的一个示例是 ONTAP AFF A800 NVMe 解决方案）。</block>
  <block id="5713a88504bb65e3808faac627a6a0fc" category="list-text">如果下载的数据集驻留在一个计算节点中，则在多个节点上执行分布式模型时，存储可能会成为瓶颈（与 NetApp ONTAP 高性能分布式存储不同）。</block>
  <block id="299b9ae5439d32ed932f51f3b3aa92d6" category="list-text">由于队列冲突或优先级问题，下次迭代训练实验可能会在不同的计算实例中执行，这再次导致从数据集到计算位置的网络距离过长。</block>
  <block id="30e37003024e85518a26760a7ab58f4e" category="list-text">在同一计算集群上执行训练实验的其他团队成员不能共享此数据集；每个团队成员都从任意位置执行数据集（昂贵的）下载。</block>
  <block id="9e5d53150336efb0446a063309805f01" category="list-text">如果后续培训作业需要使用同一数据集的其他数据集或版本，则数据科学家必须再次将数据集（昂贵）下载到执行 training.NetApp 的计算实例中，而 cnvrg.io 已创建一个新的数据集缓存解决方案来消除这些障碍。解决方案通过在 ONTAP 高性能存储系统上缓存热数据集，加快了 ML 管道的执行速度。使用 ONTAP NFS 时，数据集会在由 NetApp 提供支持的数据网络结构（例如 AFF A800 ）中缓存一次（并且只缓存一次），该数据网络结构与计算搭配使用。由于 NetApp ONTAP NFS 高速存储可以为多个 ML 计算节点提供服务，因此培训模型的性能得到了优化，从而为企业节省了成本，提高了工作效率并提高了运营效率。</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">解决方案架构</block>
  <block id="a63af1f206939a3c956a2e8b6ab53103" category="paragraph">NetApp 和 cnvrg.io 提供的此解决方案可提供数据集缓存，如下图所示。通过数据集缓存，数据科学家可以选择所需的数据集或数据集版本，并将其移动到靠近 ML 计算集群的 ONTAP NFS 缓存中。现在，数据科学家可以运行多个实验，而不会造成延迟或下载。此外，所有协作工程师都可以将同一数据集与连接的计算集群结合使用（并可自由选择任何节点），而无需从数据湖中进行额外下载。数据科学家可以获得一个信息板，用于跟踪和监控所有数据集和版本，并查看缓存的数据集。</block>
  <block id="612eaee91b23ecc385c1b402d44c081f" category="paragraph">cnvrg.io 平台会自动检测某个时间内未使用的过期数据集，并从缓存中将其转出，从而为更常用的数据集保留可用的 NFS 缓存空间。需要注意的是，使用 ONTAP 的数据集缓存可在云端和内部环境中运行，从而提供最大的灵活性。</block>
  <block id="0cb5e14601fcf39745352a9556939aa3" category="paragraph"><block ref="0cb5e14601fcf39745352a9556939aa3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb1290be14b9bc3c64a2c3c9ace6c065" category="doc">用例概述和问题陈述</block>
  <block id="aa04a8198c7c60df7adcd6cd49bec6f8" category="paragraph">数据集和数据集版本通常位于数据湖中，例如 NetApp StorageGRID 基于对象的存储，这样可以降低成本并获得其他运营优势。数据科学家利用这些数据集，通过多个步骤对其进行设计，使其为使用特定模型进行培训做好准备，通常会在整个过程中创建多个版本。下一步，数据科学家必须选择经过优化的计算资源（ GPU ，高端 CPU 实例，内部集群等）来运行此模型。下图显示了 ML 计算环境中数据集不接近的情况。</block>
  <block id="cc054601488581e80cc1d19c227126f6" category="paragraph"><block ref="cc054601488581e80cc1d19c227126f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88515fca547c502286d6f2a9081fc734" category="paragraph">但是，多个训练实验必须在不同的计算环境中并行运行，每个实验都需要从数据湖中下载数据集，这是一个昂贵且耗时的过程。无法保证数据集与计算环境（尤其是混合云）的距离。此外，使用同一数据集运行自己实验的其他团队成员也必须经历同样艰巨的过程。除了明显缓慢的数据访问之外，还存在一些挑战，包括跟踪数据集版本，数据集共享，协作和可重现性方面的困难。</block>
  <block id="30b64502c0cb2f8a9bf951993e0abbac" category="section-title">客户要求</block>
  <block id="5243f720d7e440d7746f03df97ef885f" category="paragraph">为了在高效利用资源的同时实现高性能 ML 运行，客户要求可能有所不同；例如，客户可能需要满足以下要求：</block>
  <block id="1735cf11ce0034dbb80c297fb204bc21" category="list-text">从执行训练模型的每个计算实例快速访问数据集，而不会导致昂贵的下载和复杂的数据访问</block>
  <block id="80085a846f90523080cf086e66561d52" category="list-text">在云或内部环境中使用任何计算实例（ GPU 或 CPU ），而无需考虑数据集的位置</block>
  <block id="de79912b1ab8764406a232888aab85e5" category="list-text">通过在同一数据集中与不同计算资源并行运行多个训练实验，而不会出现不必要的延迟和数据延迟，提高了效率和工作效率</block>
  <block id="5211203793a223f02322b88b2e698a82" category="list-text">最大限度地降低计算实例成本</block>
  <block id="6a6fcee71b4e22ac6a4afdfdb5940b67" category="list-text">利用工具来保留数据集，其沿袭，版本和其他元数据详细信息的记录，从而提高了可重现性</block>
  <block id="930d18875813298018f8364069441eee" category="list-text">增强了共享和协作功能，使团队中的任何授权成员都可以访问数据集并运行实验</block>
  <block id="5f700d00ad72470694a5aa06cd515c8b" category="paragraph">要使用 NetApp ONTAP 数据管理软件实施数据集缓存，客户必须执行以下任务：</block>
  <block id="41fac0272180c0141b5cd7ad6ad85a44" category="list-text">配置和设置最接近计算资源的 NFS 存储。</block>
  <block id="25a3a7ee3cfbb4afc291cd5b94dec000" category="list-text">确定要缓存的数据集和版本。</block>
  <block id="dbffd2a20c35c06fbb6ba0cd17e54ef6" category="list-text">监控提交到缓存数据集的总内存以及可用于其他缓存提交的 NFS 存储容量（例如缓存管理）。</block>
  <block id="61d5e7050cbe037ad5adeaf246e6be19" category="list-text">如果数据集在特定时间未使用，则会使其过期。默认值为一天；其他配置选项可用。</block>
  <block id="0a1bc6b4024485ff9b55c99c1237e175" category="doc">使用 Run ： AI 优化集群和 GPU 利用率</block>
  <block id="b8b025dc1895637326d2420e912751e0" category="summary">在使用 Trident 在 Kubernetes 集群中动态配置存储资源之前，必须先创建一个或多个 Trident 后端。此页面上的示例展示了在 ONTAP AI POD 上部署 NetApp AI 控制平面解决方案时可能需要创建的不同类型的后端。</block>
  <block id="c0fe00dd01499e23426b850b65782c77" category="paragraph">在使用 Trident 在 Kubernetes 集群中动态配置存储资源之前，必须先创建一个或多个 Trident 后端。以下示例展示了在 ONTAP AI POD 上部署 NetApp AI 控制平台解决方案时可能需要创建的不同类型的后端。有关后端的详细信息，请参见<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="1e698f68960fb964df99e73068c9377c" category="list-text">NetApp 建议为要在 NetApp AFF 系统上使用的每个数据 LIF （提供数据访问的逻辑网络接口）创建一个启用了 FlexGroup 的 Trident 后端。这样，您可以在 LIF 之间平衡卷挂载</block>
  <block id="327a3876126e4773cfcc5e30649c9483" category="paragraph">以下示例命令显示了为与同一 ONTAP Storage Virtual Machine （ SVM ）关联的两个不同数据 LIF 创建两个启用了 FlexGroup 的 Trident 后端。这些后端使用 `ontap-nas-flexgroup` 存储驱动程序。ONTAP 支持两种主要数据卷类型： FlexVol 和 FlexGroup 。FlexVol 卷具有大小限制（截至本文撰写时，最大大小取决于特定部署）。另一方面， FlexGroup 卷可以线性扩展到高达 20 PB 和 4000 亿个文件，从而提供一个可显著简化数据管理的命名空间。因此， FlexGroup 卷最适合依赖大量数据的 AI 和 ML 工作负载。</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">如果您使用的是少量数据，并且希望使用 FlexVol 卷而不是 FlexGroup 卷，则可以创建使用 `ontap-NAS` 存储驱动程序而不是 `ontap-nas-flexgroup` 存储驱动程序的 Trident 后端。</block>
  <block id="d04adbc45ec06c05c1826745b8f4ddf2" category="list-text">NetApp 还建议创建一个或多个启用了 FlexVol 的 Trident 后端。如果您使用 FlexGroup 卷来训练数据集存储，则可能需要使用 FlexVol 卷来存储结果，输出，调试信息等。如果要使用 FlexVol 卷，必须创建一个或多个启用了 FlexVol 的 Trident 后端。下面的示例命令显示了如何创建一个使用单个数据 LIF 且已启用 FlexVol 的 Trident 后端。</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">设置</block>
  <block id="9dc7cfc5bd8fb85bad9fdab5cdded288" category="doc">运行： AI 安装</block>
  <block id="c1b7d088e01f6ec6ec89bf69437e4bb1" category="paragraph">要安装 Run ： AI ，请完成以下步骤：</block>
  <block id="7ad0483bc07dbde29ffd404af83f8305" category="list-text">使用 DeepOps 安装 Kubernetes 集群并配置 NetApp 默认存储类。</block>
  <block id="16d20d34f759cd25fd7486bbc4046a50" category="list-text">准备 GPU 节点：</block>
  <block id="d3eff3861b26ba61222bacaa41bc0fa7" category="list-text">验证是否已在 GPU 节点上安装 NVIDIA 驱动程序。</block>
  <block id="3683aa7fe695a205b8e40e9589c94a2e" category="list-text">验证是否已安装 `nvidia-Docker` 并将其配置为默认 Docker 运行时。</block>
  <block id="cef990020518a58fb1e70a90b5df80fe" category="list-text">安装运行： AI ：</block>
  <block id="e2d6778a342979b567501f951e36118a" category="inline-link">运行： AI 管理员 UI</block>
  <block id="6fc7ea9b01c6028f691aac2aeac528f1" category="list-text">登录到<block ref="668d940d94d02be49a88c4cfd2736fa9" category="inline-link-rx"></block> 以创建集群。</block>
  <block id="fe8f08cfda6726e2dcc5d0b85ed2c67d" category="list-text">下载创建的 `runai-operator-&lt;clustername&gt;.yaml` 文件。</block>
  <block id="b428155da5c27d208abd6c179c7669d3" category="list-text">将操作员配置应用于 Kubernetes 集群。</block>
  <block id="fac4447e0ea2e4cd1a2d9e2fefeab694" category="list-text">验证安装。</block>
  <block id="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link"><block ref="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link-rx"></block></block>
  <block id="2d14c64dc5dfa79a68cd6965fbf9e4b7" category="list-text">转至<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>。</block>
  <block id="feb48a27d95fc7a7e0c6db496c54d2fa" category="list-text">转到 " 概述 " 信息板。</block>
  <block id="09fa3891e2b39bb62217c6d097310577" category="inline-link">在内部 Kubernetes 集群上安装 Run ： AI</block>
  <block id="45d7be937e1eddf966adaf68562966d4" category="inline-link">安装 Run ： AI 命令行界面</block>
  <block id="728f8fd776de1dc47f318473052286db" category="list-text">验证右上角的 GPU 数量是否反映了预期的 GPU 数量，并且 GPU 节点均位于服务器列表中。有关 Run ： AI 部署的详细信息，请参见<block ref="089aa48f8d7b3b135b035765dd1e17ba" category="inline-link-rx"></block> 和<block ref="f2f48a2074c9edc0c2dea174863a4f6e" category="inline-link-rx"></block>。</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">NetApp 概述</block>
  <block id="d30aa8861afaf98888c2367f107a8bc6" category="paragraph">NetApp 是混合云数据管理领域的权威企业。NetApp 提供全套混合云数据服务，可简化云和内部环境中的应用程序和数据管理，加速数字化转型。NetApp 与我们的合作伙伴携手，赋予全球企业充分释放数据的全部潜能，以扩大客户接触点，促进更大的创新并优化运营的能力。</block>
  <block id="ee86473f0dbd191846077276ce455778" category="paragraph">NetApp ONTAP AI 由 NVIDIA DGX 系统和 NetApp 云互联全闪存存储提供支持，可可靠地简化数据流，并加快从边缘到核心再到云的数据网络结构的分析，培训和推理速度。它为 IT 组织提供了一个架构，可提供以下优势：</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">支持独立扩展计算和存储</block>
  <block id="6cb062d50ca0d4a2bfa0caec33fea16f" category="list-text">为各种性能和成本点提供一系列存储选项 NetApp ONTAP AI 提供融合基础架构堆栈，其中包括 NVIDIA DGX-1 ，一个 petaflop 级 AI 系统和 NVIDIA Mellanox 高性能以太网交换机，可统一 AI 工作负载，简化部署并加快 ROI 。在本技术报告中，我们将 ONTAP AI 与一个 DGX-1 和一个 NetApp AFF A800 存储系统结合使用。下图显示了此验证中使用的 DGX-1 系统的 ONTAP AI 拓扑。</block>
  <block id="3eedc2d7451e7ff0440f17c9e61227dc" category="paragraph"><block ref="3eedc2d7451e7ff0440f17c9e61227dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="section-title">NetApp AI 控制平台</block>
  <block id="e1fc355cf7f97dbf25407695f8852241" category="paragraph">借助 NetApp AI 控制平台，您可以借助解决方案充分发挥 AI 和 ML 的潜能，该平台可提供极高的可扩展性，简化的部署以及无中断的数据可用性。AI 控制平面解决方案将 Kubernetes 和 Kubeflow 与 NetApp 支持的数据网络结构相集成。Kubernetes 是适用于云原生部署的行业标准容器编排平台，可实现工作负载的可扩展性和可移动性。Kubeflow 是一款开源机器学习平台，可简化管理和部署，使开发人员能够在更短的时间内完成更多的数据科学工作。NetApp 支持的 Data Fabric 可提供无与伦比的数据可用性和可移植性，确保您的数据可通过管道从边缘到核心再到云进行访问。本技术报告在 MLRun 管道中使用 NetApp AI 控制平台。下图显示了 Kubernetes 集群管理页面，您可以在其中为每个集群设置不同的端点。我们将 NFS 永久性卷连接到 Kubernetes 集群，下图显示了连接到集群的永久性卷，其中<block ref="33155b45dbdad2f412212744fbe6f8dc" category="inline-link-rx"></block> 提供持久存储支持和数据管理功能。</block>
  <block id="b058638c35435549e77a90b91abd3305" category="paragraph"><block ref="b058638c35435549e77a90b91abd3305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d371ade9f9702601a7e2f8f57c8b013" category="paragraph"><block ref="7d371ade9f9702601a7e2f8f57c8b013" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1dc271f7d3ae88e2a019314b7e4fd8e" category="section-title">Iguazio 概述</block>
  <block id="0c9fe13fe6a660070e99a54151edd7c3" category="paragraph">Iguazio 数据科学平台是一个完全集成且安全的数据科学平台即服务（ PaaS ），可简化开发，加快性能，促进协作并解决运营难题。此平台包含以下组件， Iguazio 数据科学平台如下图所示：</block>
  <block id="2137518d79f0a3dfe335e8c02312cf96" category="list-text">数据科学工作台，包括 Jupyter 笔记本电脑，集成分析引擎和 Python 软件包</block>
  <block id="68ed19bfa85e4c4677e50979864e169b" category="list-text">通过试验跟踪和自动化管道功能进行模型管理</block>
  <block id="37a28d84cd653345f1f2c036cb732f2d" category="list-text">通过可扩展的 Kubernetes 集群管理数据和 ML 服务</block>
  <block id="77fdda1a79199ac02cde44b4249cb509" category="list-text">Nutrio ，一种实时无服务器功能框架</block>
  <block id="96a6f4a99a7526e82a294d44ed005701" category="list-text">一个速度极快且安全的数据层，支持 SQL ， NoSQL ，时间序列数据库，文件（简单对象）和流式传输</block>
  <block id="00a48f02675717eaf6082c4ba536a366" category="list-text">与 NetApp ， Amazon S3 ， HDFS ， SQL 数据库以及流式传输或消息传送协议等第三方数据源集成</block>
  <block id="901630ad39a688431a68dc119f5378a3" category="list-text">基于 Grafana 的实时信息板</block>
  <block id="887fce38ef8ddd8546748bb746ed7e5a" category="paragraph"><block ref="887fce38ef8ddd8546748bb746ed7e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a905494ad30a6d54678a2122c04bfd54" category="summary">Jupyter 笔记本电脑和 Kubeflow 管道示例</block>
  <block id="80e94617849fe0b057f3edcc76a6ac72" category="doc">示例笔记本电脑和管道</block>
  <block id="3da57858cd6a76521b38784effc6a06f" category="paragraph">。<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> 可与 Kubeflow 结合使用。将 NetApp 数据科学工具包与 Kubeflow 结合使用具有以下优势：</block>
  <block id="624a53dc5871ce49612a285ee2bf367e" category="list-text">数据科学家可以直接在 Jupyter 笔记本电脑中执行高级 NetApp 数据管理操作。</block>
  <block id="1c7d37cb415e8b7777b071784911a77a" category="list-text">可以使用 Kubeflow 管道框架将高级 NetApp 数据管理操作整合到自动化工作流中。</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Kubeflow 示例</block>
  <block id="987823970c7b662272fb9e0058bf5ff1" category="paragraph">请参见<block ref="3eb5d4ffd5360858e22dfb9799f211d7" category="inline-link-rx"></block> 有关将工具包与 Kubeflow 结合使用的详细信息，请参见 NetApp Data Science Toolkit GitHub 存储库中的一节。</block>
  <block id="7c0ea3e86521674f72e056d148d4f2ce" category="paragraph">NetApp 和 Run ： AI 已在本技术报告中展开合作，展示了 NetApp ONTAP AI 解决方案与 Run ： AI 平台在简化 AI 工作负载流程方面的独特功能。上述步骤提供了一个参考架构，用于简化深度学习的数据管道和工作负载流程。建议希望实施这些解决方案的客户联系 NetApp 和 Run ： AI 了解更多信息。</block>
  <block id="8383a1cf96c028a0986b7371049c8495" category="doc">网络设备故障预测用例摘要</block>
  <block id="dea416ff04e558b0d76cce896b618880" category="paragraph">本用例基于亚洲电信领域的 Iguazio 客户。每年有 10 万个企业客户和 125 万个网络中断事件，因此迫切需要预测并采取主动行动，防止网络故障影响客户。此解决方案为他们提供了以下优势：</block>
  <block id="feb68271e6d14db0b1ff524f3eb47a27" category="list-text">对网络故障进行预测性分析</block>
  <block id="70e00676492bea584fb8e7d551515eb5" category="list-text">与票证系统集成</block>
  <block id="6de8d1444549249c0161228a7b7c1d27" category="list-text">通过主动采取措施，防止因实施 Iguazio 而导致网络故障， 60% 的故障都是主动预防的。</block>
  <block id="8fcbbd73e86fa0b56d72d6127c318c85" category="paragraph">数据的爆炸式增长以及机器学习（ ML ）和人工智能（ AI ）的指数级增长已经融合在一起，形成了一个具有独特开发和实施挑战的新经济。大量数据通常存储在低成本的数据湖中， GPU 等高性能 AI 计算资源无法高效地访问它。在本报告中，我们介绍了一款全新的解决方案，数据科学实践者可以在其中实施数据中心，只需单击一下，即可在数据集的计算资源附近创建一个数据集缓存，无论这些数据集位于何处。因此，借助新的数据集版本中心所支持的增强协作， AI 实践者可以更轻松地执行高性能模型培训。</block>
  <block id="321cf11d6ad313e01614cfa7817893fb" category="doc">JarVis 部署</block>
  <block id="24a0684c018bf0ed5e7001773d8df2c5" category="inline-link">JARVIS 早期访问计划</block>
  <block id="55ce258288b89404cc493de8c839e20a" category="paragraph">您可以注册<block ref="de4a7b23900edb1996cbcb27f4a65904" category="inline-link-rx"></block> 访问 NVIDIA GPU Cloud （ NGC ）上的 JarVis 容器。从 NVIDIA 收到凭据后，您可以使用以下步骤部署 JarVis ：</block>
  <block id="e5a6dabbbe3f9144d9f6e72b568893cd" category="list-text">登录到 NGC 。</block>
  <block id="a668e3da095eca41ef93e0c494a6ebad" category="list-text">在 NGC 上设置您的组织： `ea-2-JarVis` 。</block>
  <block id="f3b0315f8d213517a6076eb7aff49cb6" category="list-text">找到 JarVis EA v0.2 资产： JarVis containers are in `Private Registry` &gt; `Organization Containers` 。</block>
  <block id="6db8e9899d42bcac6aeb824da5e952ef" category="list-text">选择 JarVis ：导航到 `Model Scripts` ，然后单击 `JarVis Quick Start`</block>
  <block id="737af365257800065a6412e56d652acc" category="list-text">验证所有资产是否均正常工作。</block>
  <block id="8a5fd124171d01a74b1af73e73ab7761" category="list-text">查找用于构建您自己的应用程序的文档： PDF 可在 `Model Scripts` &gt; `JarVis Documentation` &gt; `File Browser` 中找到。</block>
  <block id="f68b67869778246b8f0d8a98ed043512" category="paragraph">本节详细介绍了虚拟零售助理的实施。</block>
  <block id="1703cadf8e847114fb353feaaf03beb9" category="summary">本节包括在 ONTAP AI POD 上部署 Kubernetes 时可以执行的各种高性能作业的示例。</block>
  <block id="639ce1b23959b4470d67802f0e5e412a" category="doc">ONTAP AI 部署的高性能作业示例</block>
  <block id="e7446d382d8184be0a342a2fc45d4394" category="doc">WP-7328 ：使用 NVIDIA JarVis 的 NetApp 对话 AI</block>
  <block id="5dabc617366db74ce2a9fa3915f6af5a" category="paragraph">Rick Huang ， Sung-Han Lin ， NetApp ， NVIDIA 公司的 Dide Onofino</block>
  <block id="018aacc6ea95e20996bf57b319fd037a" category="paragraph">NVIDIA DGX 系统系列由全球首款基于人工智能（ AI ）的集成系统组成，这些系统专为企业 AI 而构建。NetApp AFF 存储系统可提供极致性能和行业领先的混合云数据管理功能。NetApp 和 NVIDIA 合作创建了 NetApp ONTAP AI 参考架构，这是一款适用于人工智能和机器学习（ ML ）的统包解决方案工作负载，可提供企业级性能，可靠性和支持。</block>
  <block id="1a76c739ce37834495a22c5db663d24b" category="paragraph">本白皮书为客户构建对话式 AI 系统提供了方向性指导，以支持各个行业的不同使用情形。其中包括有关使用 NVIDIA JarVis 部署系统的信息。这些测试是使用 NVIDIA DGX 工作站和 NetApp AFF A220 存储系统执行的。</block>
  <block id="f813bd56d696cb8de386a53a37eed6f6" category="list-text">企业架构师，负责设计用于开发人工智能模型和软件的解决方案，用于虚拟零售助理等人工智能对话用例</block>
  <block id="0497dfe9ff978e87977c978d3443e206" category="list-text">寻求高效方式实现语言建模开发目标的数据科学家</block>
  <block id="e84c345e30f668aa19a041e2e12bc9fe" category="list-text">负责维护和处理客户问题和对话记录等文本数据的数据工程师</block>
  <block id="00101e6b2bf526b1ee79d39389f461fa" category="list-text">有兴趣转变对话式 AI 体验并加快 AI 计划上市速度的高管和 IT 决策者以及业务主管</block>
  <block id="b682eee68510f6de72c9f48b832fba3c" category="inline-link"><block ref="b682eee68510f6de72c9f48b832fba3c" category="inline-link-rx"></block></block>
  <block id="3e5d8230d86c09995fcd8e9ccf335813" category="list-text">cnvrg-io （<block ref="0691e14f48847a7f13eaf800c0f5813a" category="inline-link-rx"></block>）：</block>
  <block id="6536b07bf755c64528073e655a567c32" category="list-text">cnvrg 核心（免费 ML 平台）</block>
  <block id="0a16af2994c8e10c6c5976d774430a92" category="paragraph"><block ref="0a16af2994c8e10c6c5976d774430a92" category="inline-link-rx"></block></block>
  <block id="1b21ae34f592a7f2ca92d4a44122475d" category="list-text">Cnvrg 文档</block>
  <block id="0730c44e9dc233c7fce5d95816294f52" category="inline-link"><block ref="0730c44e9dc233c7fce5d95816294f52" category="inline-link-rx"></block></block>
  <block id="f3a2f110576ed38849e70a6bb9794ae8" category="paragraph"><block ref="f3a2f110576ed38849e70a6bb9794ae8" category="inline-link-rx"></block></block>
  <block id="c7c082299876892b4274ecfb3c3f7bcd" category="list-text">NVIDIA DGX-1 服务器：</block>
  <block id="d2647f7d8e79758eea27c6cdcf636638" category="list-text">NVIDIA DGX-1 服务器</block>
  <block id="65d1be94e9f29dc4af77bef169d5be14" category="list-text">NVIDIA Tesla V100 Tensor 核心 GPU</block>
  <block id="9052758d35faeab8995feefc50d729ed" category="list-text">NVIDIA GPU Cloud （ NGC ）</block>
  <block id="64ba1593b4427fb62b53b007d4a1c26e" category="list-text">NetApp AFF 系统：</block>
  <block id="092940c9deac7c0f10a0ed36613c28c2" category="paragraph"><block ref="092940c9deac7c0f10a0ed36613c28c2" category="inline-link-rx"></block></block>
  <block id="b4199ce9c494dec10c6ee051ddb413e2" category="list-text">适用于 AFF 的 NetApp FlashAdvantage</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="paragraph"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="1cb9a8619999ebc0a2d9c07624d76166" category="list-text">NetApp 互操作性表</block>
  <block id="d51c982ce98a1e197c234ea0b9a5e7d9" category="paragraph"><block ref="d51c982ce98a1e197c234ea0b9a5e7d9" category="inline-link-rx"></block></block>
  <block id="7a211d267d46c5b44662098f9234fcd0" category="list-text">ONTAP AI 网络：</block>
  <block id="b8a60c56690ddfc62bd735d0b212c396" category="list-text">Cisco Nexus 3232C 交换机</block>
  <block id="926dc08a3a3a3946402bb1beab6545cc" category="list-text">Mellanox Spectrum 2000 系列交换机</block>
  <block id="492f548658890a1d2495b8af5cebef8c" category="paragraph"><block ref="11ff6f8fb3928ea5c0863401e5e79d17" category="inline-link-rx"></block></block>
  <block id="edb7d6728a9813b505cb306367d453e3" category="list-text">DALI</block>
  <block id="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="paragraph"><block ref="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="inline-link-rx"></block></block>
  <block id="1b2766572fa1896116e3c218eb697113" category="list-text">TensorFlow ：适用于所有人的开源机器学习框架</block>
  <block id="26909d0380bdba02e2fcf7f7157cd78b" category="list-text">Horovod ： Uber 的 TensorFlow 开源分布式深度学习框架</block>
  <block id="3ffa9619031400d374ed5c0860d434ab" category="paragraph"><block ref="3ffa9619031400d374ed5c0860d434ab" category="inline-link-rx"></block></block>
  <block id="c9cbaff7c173f4b7bc923573ca753577" category="list-text">在容器运行时生态系统中启用 GPU</block>
  <block id="b3a776c1e64d267ebe62a7bf45c6c1b7" category="paragraph"><block ref="b3a776c1e64d267ebe62a7bf45c6c1b7" category="inline-link-rx"></block></block>
  <block id="ccd09fd9430cf2df88a137dbec97676b" category="paragraph"><block ref="ccd09fd9430cf2df88a137dbec97676b" category="inline-link-rx"></block></block>
  <block id="22d149e351657eac5bd1db4934498bbe" category="list-text">数据集和基准测试：</block>
  <block id="717108fd0999828c4a6d8290d419733b" category="list-text">NIH Chest X 射线数据集</block>
  <block id="4eb7427d14327fa86230f324870dc6b8" category="paragraph"><block ref="4eb7427d14327fa86230f324870dc6b8" category="inline-link-rx"></block></block>
  <block id="f249b6ce18772b83efb8a6e58ac09d47" category="list-text">王晓松，彭义文，卢乐，陆志勇，莫哈马达迪 · 巴格里， Ronald Summers ， ChestX-ray8 ：《医院级胸 X 射线数据库和常见胸病的弱监督分类和本地化基准》， IEEE CVPR ，第页3462-3471 ， 2017TR-4841-0620</block>
  <block id="1e3ecab57c1572b4a25412b1e395562a" category="paragraph">您可以针对特定使用情形自定义对话框管理器的状态和流。在我们的零售示例中，我们提供了以下四个 YAML 文件，用于根据不同意向指导对话。</block>
  <block id="608f6d7dfd7bc98630446f0c601cc730" category="paragraph">查看以下文件名列表以及每个文件的问题描述：</block>
  <block id="77d10e2958e3d21f89adae8647e8d0d2" category="list-text">`main_flow.yml` ：定义主要对话流和状态，并在必要时将此流定向到其他三个 YAML 文件。</block>
  <block id="96b445ea5c6b049dfc1250466b6bdf2e" category="list-text">`retail _flow.yml` ：包含与零售或感兴趣点问题相关的状态。系统会提供最近商店的信息或给定商品的价格。</block>
  <block id="17a0ea5055e6be908d7e2f6f983aa471" category="list-text">`weather flow.yml` ：包含与天气问题相关的状态。如果无法确定位置，系统会询问一个跟进问题以进行澄清。</block>
  <block id="ade7d8cc2b23f24add45c4096dd41795" category="list-text">`error_flow.yml` ：处理用户意向不属于上述三个 YAML 文件的情况。显示错误消息后，系统会重新路由到接受用户问题。以下各节包含这些 YAML 文件的详细定义。</block>
  <block id="ef7c28f5093b59a07761555c8914df26" category="section-title">main_flow.yml</block>
  <block id="dfc9a806326d590aa4ccf49aa6909cda" category="section-title">Retail ， flow.yml</block>
  <block id="6e08d9d65c68d5f447f4fd239052c12e" category="section-title">weather flow.yml</block>
  <block id="b7dc1d2ced2caa9352158983c5ffeda1" category="section-title">error_flow.yml</block>
  <block id="39cf3ca3e5dbe56d6eade7cbe3cc40e6" category="doc">Kubeflow 操作和任务示例</block>
  <block id="368c8f521d74a015b7a3e1a46c8847b1" category="paragraph">本节包括您可能希望使用 Kubeflow 执行的各种操作和任务的示例。</block>
  <block id="33204bfa9ee287508f03782fd7ad512e" category="summary">在使用 Trident 在 Kubernetes 集群中动态配置存储资源之前，必须创建一个或多个 Kubernetes StorageClasses 。此页面上的示例展示了在 ONTAP AI POD 上部署 NetApp AI 控制平面解决方案时可能需要创建的不同类型的 StorageClasses 。</block>
  <block id="d9206a5144976221af82df78ad3d7977" category="paragraph">在使用 Trident 在 Kubernetes 集群中动态配置存储资源之前，必须创建一个或多个 Kubernetes StorageClasses 。以下示例展示了在 ONTAP AI POD 上部署 NetApp AI 控制平面解决方案时可能需要创建的不同类型的 StorageClasses 。有关 StorageClasses 的详细信息，请参见<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="993143e7434e63409a07cf3e8c422505" category="list-text">NetApp 建议为在一节中创建的每个启用了 FlexGroup 的 Trident 后端创建一个单独的 StorageClass <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>，步骤 1 。通过这些粒度级 StorageClasses ，您可以将与特定 LIF （创建 Trident 后端时指定的 LIF ）相对应的 NFS 挂载添加为 StorageClass 规范文件中指定的特定后端。下面的示例命令显示了两个 StorageClasses 的创建过程，这两个 StorageClasses 对应于在部分中创建的两个示例后端 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>，步骤 1 。有关 StorageClasses 的详细信息，请参见<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Kubernetes 文档</block>
  <block id="a596fcc71d1c43e3ba86b1557ac7af81" category="paragraph">为了在删除相应的 PersistentVolumeClaim （ PVC ）时不删除永久性卷，以下示例使用了 `reClaimPolicy` 值 `Retain` 。有关 `re"claimPolicy` " 字段的详细信息，请参见相关官员<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block>。</block>
  <block id="f053cb3a491d2bc48d41230b10a9b164" category="list-text">NetApp 还建议创建一个与您在部分中创建的启用了 FlexVol 的 Trident 后端对应的 StorageClass <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>，步骤 2 。下面的示例命令显示了为 FlexVol 卷创建一个 StorageClass 的过程。</block>
  <block id="99608a01905f0e69895bbb864a0deba3" category="paragraph">在以下示例中，未在 StorageClass 定义文件中指定特定后端，因为仅创建了一个启用了 FlexVol 的 Trident 后端。使用 Kubernetes 管理使用此 StorageClass 的卷时， Trident 会尝试使用使用 `ontap-NAS` 驱动程序的任何可用后端。</block>
  <block id="ee1d27a4ae3e30ff30ef72e305b029e7" category="list-text">NetApp 还建议为 FlexGroup 卷创建通用存储类。以下示例命令显示了如何为 FlexGroup 卷创建一个通用 StorageClass 。</block>
  <block id="d4a43a35c5d5a5ce3aefe77ceaa73a5c" category="paragraph">请注意， StorageClass 定义文件中未指定特定后端。因此，在使用 Kubernetes 管理使用此 StorageClass 的卷时， Trident 会尝试使用使用 `ontap-nas-flexgroup` 驱动程序的任何可用后端。</block>
  <block id="2732cb29fe3befd83c06e7c220b5456d" category="doc">第 4.10 节的测试详细信息</block>
  <block id="273936fc522fd7dbe4473de8a0b2a985" category="paragraph">此部分包含此部分的测试详细信息 <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>。</block>
  <block id="cf46f9264bb33ef7576cf671194a0275" category="paragraph">按以下顺序提交 `team-A` ， `team-b` 和 `team-c` 的作业：</block>
  <block id="fac80c1054e849e1ec88244c017978e7" category="cell">1 个工作负载已排队</block>
  <block id="eefc99cd833e14811fb22b758cbc62e5" category="cell">已排队 2 个工作负载</block>
  <block id="be46ffa9e65cb964fc3236de02c41e4e" category="paragraph">请参见以下已执行的命令序列：</block>
  <block id="001f9003205f670658ffc60b1e4d62d8" category="cell">两个工作负载要求每个 GPU 两个</block>
  <block id="f0f10ddbe8f00433aad17626c8d96a73" category="cell">两个工作负载，每个工作负载需要两个 GPU</block>
  <block id="f82056dbbe3376b10ac622b0bdaae914" category="cell">8/8.</block>
  <block id="61b8291124bff8ee36a1c799e35395e9" category="paragraph">接下来，删除 `team-d` 的所有工作负载：</block>
  <block id="ed9cf33d84548b5953f8b042c72faef4" category="paragraph">请参见一节 <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>，用于讨论后续测试场景。</block>
  <block id="5b7a8a379330d9d43907b47a6d7ee306" category="doc">使用 Nemo 培训扩展意向模型</block>
  <block id="a7fbadb37067070a61a3da62b548ba3c" category="paragraph">NVIDIA Nemo 是由 NVIDIA 构建的一个工具包，用于创建对话式 AI 应用程序。该工具包包含一系列针对 ASL ， NLP 和 TTS- 的预培训模块，使研究人员和数据科学家能够轻松构建复杂的神经网络架构，并更加专注于设计自己的应用程序。</block>
  <block id="1a56a4858eeec63d31bc890d38325b84" category="paragraph">如上例所示， Nara 只能处理有限类型的问题。这是因为经过预先培训的 NLP 模型只会对这些类型的问题进行训练。如果我们希望 Nara 能够处理更广泛的问题，我们需要使用自己的数据集对其进行重新训练。因此，我们将在此演示如何使用 Nemo 扩展 NLP 模型以满足要求。我们首先将从 Nara 收集的日志转换为 Nemo 的格式，然后训练数据集以增强 NLP 模型。</block>
  <block id="4e19d1e300ea3cd63472939c24caf65d" category="paragraph">我们的目标是使 Nara 能够根据用户首选项对项目进行排序。例如，我们可能会要求 Nara 推荐排名最高的寿司店，也可能希望 Nara 寻找价格最低的 jeans 。为此，我们使用 Nemo 中提供的意向检测和插槽填充模型作为我们的培训模型。通过此模型， Nara 可以了解搜索首选项的意图。</block>
  <block id="5cb83e5ef3cd25eb53fa55d635a7758f" category="section-title">数据准备</block>
  <block id="807cace7b07fcded06b9d106c4dd4d2d" category="paragraph">为了训练模型，我们会收集此类问题的数据集，并将其转换为 Nemo 格式。我们在此处列出了用于训练模型的文件。</block>
  <block id="dc1d3747ed1059f234cbe4a104700abd" category="section-title">dict.intents.csv</block>
  <block id="e803005a5c3a99889733e9c8e8bba406" category="paragraph">此文件列出了我们希望 Nemo 了解的所有意向。此处，我们有两个主要意向，一个意图仅用于对不符合任何主要意向的问题进行分类。</block>
  <block id="ce2440c5074ba6a1e30fa2ec906dafb4" category="section-title">dict.slots.csv</block>
  <block id="a3fc542c51797c85b30365ba9b2d12c5" category="paragraph">此文件列出了我们可以在培训问题上标记的所有插槽。</block>
  <block id="795cab38744084526a62914e47789fbe" category="section-title">Traine.tsv</block>
  <block id="8a5ae45ea3762f79d1a520bcf61275d5" category="paragraph">这是主要的培训数据集。每行都以文件 dict.intent.csv 中列出的意图类别后面的问题开头。此标签将从零开始枚举。</block>
  <block id="db487d8daea13e36203f660d46b3cdfc" category="section-title">Train_slots.tsv</block>
  <block id="73ade6fc5004174d2abe822c85cdfbef" category="section-title">训练模型</block>
  <block id="c764142480a5daa39ac98125503352e8" category="paragraph">然后，我们将使用以下命令启动此容器。在此命令中，我们会将容器限制为使用单个 GPU （ GPU ID = 1 ），因为这是一项轻型训练练习。此外，我们还会将本地工作空间 /workstore/nemo/ 映射到容器 /nemo 中的文件夹。</block>
  <block id="a712c52af847db1e143ca43fdd44bd39" category="paragraph">在容器中，如果要从最初的预先培训的 Bert 模型开始，我们可以使用以下命令启动培训操作步骤。data_dir 是用于设置训练数据路径的参数。work_dir 用于配置检查点文件的存储位置。</block>
  <block id="9e654b2215e90d20951b3ddd67a15bc6" category="paragraph">如果我们有新的培训数据集并希望改进先前的模型，则可以使用以下命令从停止的位置继续操作。checkpoint_dir 获取上一个检查点文件夹的路径。</block>
  <block id="87eea49f703666c49da2d7987ba093b2" category="section-title">推理模型</block>
  <block id="484c4e9e4a0a20bf41551f65663fa9d2" category="paragraph">我们需要在经过一定次数的时间之后验证经过训练的模型的性能。使用以下命令，我们可以逐个测试查询。例如，在此命令中，我们希望检查我们的模型是否能够正确识别查询的目的 `在哪里可以获得最好的意大利面` 。</block>
  <block id="de558a28e6333ac9f453a42631f44c12" category="paragraph">然后，以下是推理的输出。在输出中，我们可以看到经过培训的模型可以正确预测 DETAINT_the_store 的意向，并返回我们感兴趣的关键字。通过这些关键字，我们可以使 Nara 搜索用户所需内容并进行更精确的搜索。</block>
  <block id="84860cc77161e23e44eccd05430c00ea" category="doc">在 Run ： AI 命令行界面中提交作业</block>
  <block id="68c9d249f35c91dfcc4a11e209ccbdba" category="paragraph">本节详细介绍了可用于运行任何 Kubernetes 作业的基本 Run ： AI 命令。它会根据工作负载类型分为三部分。AI/ML/DL 工作负载可分为两种通用类型：</block>
  <block id="754edd5bae16b4a2ed8e6673821d3339" category="list-text">* 无人参与的培训课程 * 。对于这些类型的工作负载，数据科学家会准备一个自运行的工作负载并将其发送给执行。执行期间，客户可以检查结果。此类工作负载通常用于生产或模型开发阶段，无需人工干预。</block>
  <block id="fdfda155b7c1021ae5e73d2ab01c0129" category="list-text">* 交互式构建会话 * 。对于这些类型的工作负载，数据科学家将与 Bash ， Jupyter Notebook ，远程 PyCharm 或类似的 IDE 打开交互式会话，并直接访问 GPU 资源。我们还提供了第三种使用连接的端口运行交互式工作负载的方案，以便向容器用户显示内部端口。</block>
  <block id="6ec08732676824c58d76b0ecdc2aed24" category="section-title">无人参与的培训工作负载</block>
  <block id="18cb2734d0533ff093ddcb1b3005e216" category="paragraph">设置项目并分配 GPU 后，您可以在命令行中使用以下命令运行任何 Kubernetes 工作负载：</block>
  <block id="68e667063c4711033bbf6b7f8b312e1f" category="paragraph">此命令将为团队 A 启动无人参与的培训作业，并分配一个 GPU 。此作业基于示例 Docker 映像 `gcr.io/run-ai-demo/Quickstart` 。我们将作业命名为 `hyper1` 。然后，您可以运行以下命令来监控作业的进度：</block>
  <block id="cbae10285b6d282e740369a59fd25aaf" category="paragraph">下图显示了 `runai list` 命令的结果。您可能看到的典型状态包括：</block>
  <block id="e749e4e3bf7ed6d5368f336ba6ceeead" category="list-text">`容器创建` 。正在从云存储库下载 Docker 容器。</block>
  <block id="f5231f23820da3ad520bb16a9dfe97a7" category="list-text">`待定` 。作业正在等待计划。</block>
  <block id="411497b40a902afd2813d3c7af137ffb" category="list-text">`运行` 。作业正在运行。</block>
  <block id="c0801feb8216aa6b36a769e14c3bc138" category="paragraph"><block ref="c0801feb8216aa6b36a769e14c3bc138" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4f5f0c8fb5ec5bccf18cfd167b1d3bc5" category="paragraph">要获取作业的其他状态，请运行以下命令：</block>
  <block id="db0b192c9c9b9885b435e466b9ac861c" category="paragraph">要查看作业日志，请运行 `runai logs &lt;job-name&gt;` 命令：</block>
  <block id="280782f59c990a941b600c998427a52c" category="paragraph">在此示例中，您应看到正在运行的 DL 会话的日志，包括当前训练时间， ETA ，损失函数值，准确性以及每个步骤所用时间。</block>
  <block id="848ad760ae00e3eca33445cd09cfdf34" category="paragraph">您可以在运行： AI UI 上查看集群状态，网址为<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>。在 Dashboards &gt; Overview 下，您可以监控 GPU 利用率。</block>
  <block id="f899123d07ffe99c3d97952ae96017ed" category="paragraph">要停止此工作负载，请运行以下命令：</block>
  <block id="1f979b6140776c287d458036805ad8aa" category="inline-link">启动无人参与的培训工作负载</block>
  <block id="637552715214e8c0c87022bac459e824" category="paragraph">此命令将停止训练工作负载。您可以再次运行 `runai list` 来验证此操作。有关详细信息，请参见<block ref="e5fbbc266c1fd3a9a029581f5747622d" category="inline-link-rx"></block>。</block>
  <block id="7afece97948db40e546138d81dd343e1" category="section-title">交互式构建工作负载</block>
  <block id="30330792601ba24e9ad5f4f5ee0d5151" category="paragraph">设置项目并分配 GPU 后，您可以在命令行中使用以下命令运行交互式构建工作负载：</block>
  <block id="ca57038d87e3f48eb98329e6fd449824" category="paragraph">此作业基于示例 Docker 映像 python 。我们将作业 BUILD1 命名为。</block>
  <block id="39fd96ce47a2aa757eb5cc98cd910730" category="admonition">` - 交互式` 标志表示作业没有开始或结束研究人员有责任完成此项工作。管理员可以为交互式作业定义一个时间限制，在该时间限制之后，系统会终止这些作业。</block>
  <block id="d39d9c693980c2af510d4a58be6f2620" category="paragraph">` -g 1` 标志可为此作业分配一个 GPU 。提供的命令和参数为 ` —命令休眠— args infinity` 。您必须提供命令，否则容器将立即启动并退出。</block>
  <block id="aedc6bf8e3cb52af4a660584c69353ca" category="paragraph">以下命令的工作方式与中所述的命令类似 <block ref="a09c3ced87a580a4004dfa2429aba9c7" category="inline-xref-macro-rx"></block>：</block>
  <block id="1d2bac5ee25c12c0ee793df98c1b4d49" category="list-text">`runai list` ：显示名称，状态，期限，节点，映像， 用于作业的项目，用户和 GPU 。</block>
  <block id="6b5b5fdb13c8b8af02a41b296af91a2e" category="list-text">`runai get build1` ：显示作业 build1 的其他状态。</block>
  <block id="9c1e129aa488b11d05275f016f42dda5" category="list-text">`runai delete build1` ：停止交互式工作负载 BUILD1.To get a bash shell to the container ， the following command ：</block>
  <block id="ac97b61bdc50cfc22ffd507de190d00c" category="paragraph">这样就可以直接将 shell 连接到计算机。然后，数据科学家可以在容器中开发或微调其模型。</block>
  <block id="5051a9eb1fad38f876a260ba0a4850af" category="inline-link"><block ref="5051a9eb1fad38f876a260ba0a4850af" category="inline-link-rx"></block></block>
  <block id="c7fdd5fcf033fb9395c27ecbf2e54fc9" category="inline-link">启动和使用交互式构建工作负载</block>
  <block id="ff53dc42327d97c7410a6ac241222ffe" category="paragraph">您可以在运行： AI UI 上查看集群状态，网址为<block ref="29f2b88109b12c4db8e875d3f5ba7aae" category="inline-link-rx"></block>。有关详细信息，请参见<block ref="f3d6ab8050b43c83f452779c7622ab1d" category="inline-link-rx"></block>。</block>
  <block id="1028c65994f7201e0f43b3bf5d3c6b41" category="section-title">使用已连接端口的交互式工作负载</block>
  <block id="7d05c708b92b4809bfe9bf66edf8f765" category="inline-link">传入</block>
  <block id="34274fcc13408f06acfe43c4065c3f3b" category="paragraph">作为交互式构建工作负载的扩展，在使用 Run ： AI CLI 启动容器时，您可以向容器用户显示内部端口。这对于云环境，使用 Jupyter 笔记本电脑或连接到其他微服务非常有用。<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> 允许从 Kubernetes 集群外部访问 Kubernetes 服务。您可以通过创建一组规则来配置访问，这些规则定义哪些入站连接访问哪些服务。</block>
  <block id="e7f72a2c9a0cb7337eb00a3093f846da" category="paragraph">为了更好地管理对集群中服务的外部访问，我们建议集群管理员安装<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> 并配置负载平衡器。</block>
  <block id="16d79943625573d5b80809fe2a7ddbdd" category="paragraph">要使用传入作为服务类型，请在提交工作负载时运行以下命令以设置方法类型和端口：</block>
  <block id="79fcc0299f1a85ebab053926e2222bca" category="paragraph">容器成功启动后，执行 `runai list` 以查看用于访问 Jupyter 笔记本电脑的 `S服务 URL （ S ）` 。此 URL 由入口端点，作业名称和端口组成。例如，请参见<block ref="0309fbe8f364c8f6dfe6f383da8c46c2" category="inline-link-rx"></block>。</block>
  <block id="451b08ed1bf6f7f0a8931cff52c4c45e" category="inline-link">使用连接的端口启动交互式构建工作负载</block>
  <block id="b524842923f8cb1e38064fadc680893f" category="paragraph">有关详细信息，请参见<block ref="414875add8a18a03ddddfb14fb1c47f4" category="inline-link-rx"></block>。</block>
  <block id="86608a0b346f307c76f8ae00c9f6bcb9" category="summary">此报告介绍如何快速克隆数据命名空间。它演示了如何定义和实施 AI 培训工作流，这些工作流可以近乎即时地创建数据和模型基线，以实现可追溯性和版本控制。同时，还介绍了如何在站点和区域之间无缝复制数据，以及如何快速配置 Jupyter 笔记本电脑工作空间，以便访问海量数据集。</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">NetApp 公司 Mike Oglesby</block>
  <block id="27114500e25aba7a27847b772d396575" category="paragraph">各行各业各种规模的企业和组织都在转向人工智能（ AI ），机器学习（ ML ）和深度学习（ DL ），以解决实际问题，提供创新产品和服务，并在竞争日益激烈的市场中占据优势。随着企业越来越多地使用 AI ， ML 和 DL ，他们面临着许多挑战，包括工作负载可扩展性和数据可用性。本文档演示了如何使用 NetApp AI 控制平台来应对这些挑战， NetApp AI 控制平台是一种将 NetApp 数据管理功能与常见开源工具和框架配对的解决方案。</block>
  <block id="98300151efa6f504dee4866e49cf2078" category="paragraph">此报告介绍如何快速克隆数据命名空间。此外，还将向您展示如何在站点和区域之间无缝复制数据，以创建统一的统一 AI/ML/DL 数据管道。此外，它还会指导您完成 AI ， ML 和 DL 培训工作流的定义和实施，这些工作流可近乎即时地创建数据和模型基线，以实现可追溯性和版本控制。使用此解决方案，您可以跟踪每个模型训练返回到用于训练和 / 或验证模型的确切数据集。最后，本文档将向您介绍如何快速配置 Jupyter 笔记本电脑工作空间，以便访问海量数据集。</block>
  <block id="3a8a3991c7ef251983bda0fd052b9b10" category="inline-link-macro">TR-4890</block>
  <block id="3cbee33bcafaf0315e821a3331b91eb5" category="inline-link-macro">NetApp 完全支持的并行文件系统解决方案 BeeGFS</block>
  <block id="63de7cb3a054a3754335c60a0c8ba878" category="paragraph">注意：对于涉及大量需要共享访问同一数据集的 GPU 服务器的 HPC 模式大规模分布式培训，或者如果您需要 / 更喜欢并行文件系统，请查看 <block ref="f82f3a4db7a848244fd5070f378c86fb" category="inline-link-macro-rx"></block>。本技术报告介绍了如何包括 <block ref="99c493838dffa23aa6d1149e33e3edf0" category="inline-link-macro-rx"></block> 作为 NetApp AI 控制平台的一部分。此解决方案可从少数 NVIDIA DGX A100 系统扩展到全闪满的 140 节点 SuperPOD 。</block>
  <block id="9f1cc947f3e0236f8d5bc32d8d33509a" category="inline-link">cloud.netapp.com</block>
  <block id="9d50c340b35848862ab6ecbdadc401ed" category="paragraph">NetApp AI 控制平台面向数据科学家和数据工程师，因此只需极少的 NetApp 或 NetApp ONTAP ® 专业知识即可。借助此解决方案，可以使用简单熟悉的工具和界面来执行数据管理功能。如果您的环境中已有 NetApp 存储，您可以立即测试运行 NetApp AI Control 平台。如果您要测试解决方案驱动器，但尚未安装 NetApp 存储，请访问<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>，您只需几分钟即可使用基于云的 NetApp 存储解决方案启动并运行。下图显示了解决方案的可视化视图。</block>
  <block id="1f39acb56ba2a8669371819a64348c74" category="paragraph"><block ref="1f39acb56ba2a8669371819a64348c74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed8e4613850a4014b0e6ef830982caf2" category="paragraph">此部分包含此部分的测试详细信息 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>。</block>
  <block id="17b3673d5c28fb72e7cc48549f489dd4" category="cell">6/8</block>
  <block id="ffe090618e54b7916fa47cf8881019b1" category="cell">team-b/c 工作负载暂停并移至 `pending` 。</block>
  <block id="bccfe4ac65004fb31c146d17003d00e8" category="cell">其他团队（ b/c ）工作负载暂停并移至 `pending` 。</block>
  <block id="3b099141b6a7e4e8804c3fda5ed4f440" category="paragraph">请参见一节 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block> 有关继续测试场景的讨论。</block>
  <block id="aa364e0963e38930007df2b60bdba067" category="doc">将数据保存到 Trident 配置的 PersistentVolume</block>
  <block id="ef1fb51957f2aa894de5476a9a0112a2" category="paragraph">NetApp Trident 是一个完全受支持的开源项目，旨在帮助您满足容器化应用程序的复杂持久性需求。您可以将数据读写到 Trident 配置的 Kubernetes PersistentVolume （ PV ）中，并通过 NetApp ONTAP 数据管理软件提供数据分层，加密， NetApp Snapshot 技术，合规性和高性能优势。</block>
  <block id="a821f368daf439d909bfed3c8e95d4b9" category="section-title">重复使用现有命名空间中的 PVC</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link">NetApp Trident 文档</block>
  <block id="15040fc521e7fa5e8ef42694ca89e53d" category="paragraph">对于规模较大的 AI 项目，不同容器向同一个 Kubernetes PV 读取和写入数据可能会更高效。要重复使用 Kubernetes 永久性卷声明（ PVC ），用户必须已创建 PVC 。请参见<block ref="5b6274adc29653ed1820027957bdb4e2" category="inline-link-rx"></block> 有关创建 PVC 的详细信息。以下是重复使用现有 PVC 的示例：</block>
  <block id="743520c366f0d11ca817811dda85fcf1" category="paragraph">运行以下命令查看项目 `team-A` 的作业 `pvc 测试` 的状态：</block>
  <block id="7d4c508442c775f946e3d9318b75b1a0" category="paragraph">您应看到 PV /tmp/pvc1mount 挂载到 `team-A` job `vc-test` 。这样，多个容器就可以从同一个卷读取数据，这在开发或生产环境中存在多个竞争模式时非常有用。数据科学家可以构建一系列模型，然后通过多数投票或其他技术将预测结果结合起来。</block>
  <block id="dae81aa45b8ce281aabbd1402afe277b" category="paragraph">使用以下命令访问容器 Shell ：</block>
  <block id="bc63da8fa87210da818596598e359427" category="paragraph">然后，您可以检查已挂载的卷并访问容器中的数据。</block>
  <block id="fc180b17e3fccb2beb46854f71d31406" category="paragraph">这种重复使用 PVC 的功能可与 NetApp FlexVol 卷和 NetApp ONTAP FlexGroup 卷配合使用，从而使数据工程师可以使用更灵活，更强大的数据管理选项来利用由 NetApp 提供支持的数据网络结构。</block>
  <block id="52c7321ea4e3d5b264fdc8639a65e280" category="doc">部署 Grafana 信息板</block>
  <block id="c843fc0ceca9c58b409cab519799c125" category="paragraph">部署完所有内容后，我们会对新数据运行推断。这些型号可预测网络设备故障。预测结果存储在 Iguazio 时间序列表中。您可以在与 Iguazio 的安全和数据访问策略集成的平台中使用 Grafana 来查看结果。</block>
  <block id="ae93e86067cc1d0e7bb1ec8fdca6fbc3" category="paragraph">您可以通过将提供的 JSON 文件导入到集群中的 Grafana 接口来部署信息板。</block>
  <block id="213977705fe35a4cb0cfc9365088fc87" category="list-text">要验证 Grafana 服务是否正在运行，请查看服务下的。</block>
  <block id="b426c25dbb35de6b9c6bff0b10b8bef9" category="paragraph"><block ref="b426c25dbb35de6b9c6bff0b10b8bef9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b6e0cc0a098260878a0e8fa4eb7766" category="list-text">如果不存在此实例，请从服务部分部署此实例：</block>
  <block id="cd40a7a2e0a86f4a0283af5999a050db" category="list-text">单击新建服务。</block>
  <block id="59c4bcb990174489660974167376a50a" category="list-text">从列表中选择 Grafana 。</block>
  <block id="7e280ecf88737f34a1972ac94f9ae2a1" category="list-text">接受默认值。</block>
  <block id="9e47b36567e5001dea59ffee81456737" category="list-text">单击下一步。</block>
  <block id="4fa350b43dd079673b6fca4852841147" category="list-text">输入您的用户 ID 。</block>
  <block id="af81385be6cef15b54f8c8c126c0eab0" category="list-text">单击 Save Service 。</block>
  <block id="568c8b6f668936384414e470f9ddd939" category="list-text">单击顶部的 Apply Changes 。</block>
  <block id="b5be50b376063d6c3ffaa3be10d4a9d3" category="list-text">要部署信息板，请通过 Jupyter 界面下载文件 `NetopsPredictions-Dashboard.json` 。</block>
  <block id="587b311a501585c3a1d9260d4f147990" category="paragraph"><block ref="587b311a501585c3a1d9260d4f147990" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ad16c6527a3abd13b6864b8b078586b" category="list-text">从服务部分打开 Grafana 并导入信息板。</block>
  <block id="0b78dd574d02d72071845d040fdde57c" category="paragraph"><block ref="0b78dd574d02d72071845d040fdde57c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3ce0bca8ff75db7ff2bbc3e76532b2" category="list-text">单击 Upload ` * 。 json` File ，然后选择先前下载的文件（`NetopsPredictions-Dashboard.json` ）。上传完成后，将显示信息板。</block>
  <block id="7cd4d06091771aa3f16d2759a067e18c" category="paragraph"><block ref="7cd4d06091771aa3f16d2759a067e18c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0258dc4515b0e18ecd4b55651e27671" category="section-title">部署清理功能</block>
  <block id="ff4bdefb3ddd7532393d08c8df14d786" category="paragraph">当您生成大量数据时，保持数据干净有序非常重要。为此，请使用 `cleanup.ipynb` 笔记本部署清理功能。</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="section-title">优势</block>
  <block id="6d0f7ccc9b17bcabb743cabdfb56e0da" category="paragraph">NetApp 和 Iguazio 通过构建 Kubeflow ， Apache Spark 和 TensorFlow 等基本框架以及 Docker 和 Kubernetes 等业务流程工具，加快并简化 AI 和 ML 应用程序的部署。通过统一端到端数据管道， NetApp 和 Iguazio 可以减少许多高级计算工作负载固有的延迟和复杂性，从而有效地缩小开发和运营之间的差距。在培训阶段，数据科学家可以对大型数据集运行查询，并与授权用户安全地共享数据和算法模型。容器化模型准备好投入生产后，您可以轻松地将其从开发环境迁移到操作环境。</block>
  <block id="612edeb05f6d237e20f3d843d6e7eba4" category="paragraph">以下各节详细介绍了运行： AI 安装，测试场景以及在此验证中执行的结果。</block>
  <block id="2df14da3d7db15550e8eafc892e89d8e" category="paragraph">我们使用行业标准基准测试工具（包括 TensorFlow 基准测试）验证了此系统的运行和性能。ImageNet 数据集用于训练 RESNET-50 ，它是一种著名的神经网络（ Convolutional Neural Network ， CNN ） DL 图像分类模型。RESNET-50 可提供准确的训练结果，并缩短处理时间，从而使我们能够对存储产生足够的需求。</block>
  <block id="afee48a46dd68b9618cec81a8ee5ba86" category="paragraph">本节介绍 ONTAP AI 解决方案的技术要求。</block>
  <block id="e96b7604f8b75ae786c6c0e1016e46fd" category="inline-link">ONTAP AI 网站</block>
  <block id="929f5f13d86d1be55b96dba26e773c6f" category="paragraph">虽然硬件要求取决于特定的客户工作负载，但 ONTAP AI 可以在任何规模部署，用于数据工程，模型培训和生产推理，从单个 GPU 到机架级配置，用于大规模 ML/DL 操作。有关 ONTAP AI 的详细信息，请参见<block ref="7ec9b089c41da1b986bad97e1099df1c" category="inline-link-rx"></block>。</block>
  <block id="41e840b508d9e839f95d16dd582af8d6" category="paragraph">此解决方案已通过使用 DGX-1 系统进行计算，使用 NetApp AFF A800 存储系统和使用 Cisco Nexus 3232C 进行网络连接的验证。在此验证中使用的 AFF A800 可支持多达 10 个 DGX-1 系统，用于大多数 ML/DL 工作负载。下图显示了此验证中用于模型培训的 ONTAP AI 拓扑。</block>
  <block id="bc2eb92d1e1797a759b677c38f619a8f" category="paragraph"><block ref="bc2eb92d1e1797a759b677c38f619a8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d98e5c43e7b3be89fe8a9076f89f1e99" category="paragraph">要将此解决方案扩展到公有云，可以将 Cloud Volumes ONTAP 与云 GPU 计算资源一起部署，并集成到混合云数据网络结构中，使客户能够使用适合任何给定工作负载的任何资源。</block>
  <block id="4dc70b997a39a64b2def3ef74a96fdb4" category="paragraph">下表显示了此解决方案验证中使用的特定软件版本。</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">组件</block>
  <block id="d173e10eb6a0fc7969fe540c987e0c7d" category="cell">18.04.4 LTS</block>
  <block id="9b4bffa460105781f82b1d463bde8200" category="cell">4.4.0</block>
  <block id="3c1d47ba5c1ada327abd4532ff9f4437" category="cell">20.02.1</block>
  <block id="0083e57a258edd18b949d3afbf6cfc2a" category="cell">1.15</block>
  <block id="152090ff5e9a05ea7e1cf0c248449638" category="cell">掌舵</block>
  <block id="232de5556d4148d75b55012e1230616c" category="cell">3.1.0</block>
  <block id="e5e8ab661917b89b4161959c7dc28442" category="cell">cnvrg.io</block>
  <block id="272f0a04b740763e0a29316bc4af89a4" category="cell">3.0.0</block>
  <block id="d8a31094f88724af6834c47a6697dc56" category="cell">9.6P4</block>
  <block id="9909115a4f9fe32731077286c367501c" category="paragraph">在此解决方案验证中， Kubernetes 会在 DGX-1 系统上部署为单节点集群。对于大规模部署，应部署独立的 Kubernetes 主节点，以提供高可用性的管理服务，并为 ML 和 DL 工作负载预留有价值的 DGX 资源。</block>
  <block id="ecb81ab37e1d2a7ed6dfce3807622e3d" category="summary">本节详细介绍了如何使用 Run AI Orchestrator 设置平台，以便大规模执行车道检测分布式培训。</block>
  <block id="0714a752696f8feed939bbf52a6214f7" category="doc">车道检测—使用 Run ： AI 进行分布式培训</block>
  <block id="dbf10b854b8b7fc90297279e7ad0f745" category="paragraph">本节详细介绍了如何设置平台，以便使用 run ： AI orchator 大规模执行车道检测分布式培训。我们将讨论所有解决方案要素的安装以及在所述平台上运行分布式培训作业的问题。可以使用 NetApp SnapshotTM 并将其与 run ： AI 实验相链接来完成 ML 版本控制，以实现数据和模型可重现性。在跟踪模型，团队成员之间共享工作，结果的可重现性，将新型号版本投入生产以及数据来源方面， ML 版本控制起着至关重要的作用。NetApp ML 版本控制（ Snapshot ）可以捕获与每个实验相关的数据，经过培训的模型和日志的时间点版本。它具有丰富的 API 支持，可以轻松地与运行： AI 平台集成；您只需根据训练状态触发事件即可。此外，您还必须捕获整个实验的状态，而不更改 Kubernetes （ K8 ）上运行的代码或容器中的任何内容。</block>
  <block id="25d19977e35c6d286c5b051982ae3f3c" category="paragraph">最后，本技术报告将对 AKS 中多个启用了 GPU 的节点进行性能评估。</block>
  <block id="1987a7039dccb848f2e8ce693ba3faff" category="section-title">针对使用 TuSimple 数据集的通道检测用例的分布式培训</block>
  <block id="f75a7cb3d80e7be148c1ce86a4347011" category="paragraph">在本技术报告中，对 TuSimple 数据集进行了分布式培训，用于检测通道。在本培训代码中， Horovod 用于通过 AKS 在 Kubernetes 集群中的多个 GPU 节点上同时执行数据分布式培训。代码作为容器映像打包，以供 TuSimple 数据下载和处理。处理后的数据存储在 NetApp Trident 插件分配的永久性卷上。在培训中，还会创建一个容器映像，并使用在下载数据期间创建的永久性卷上存储的数据。</block>
  <block id="58b4798157820b4e4415d8136cf60fe9" category="paragraph">要提交数据和培训作业，请使用 run ： ai 编排资源分配和管理。Run ： AI 允许您执行 Horovod 所需的消息传递接口（ Message Passing Interface ， MPI ）操作。此布局允许多个 GPU 节点彼此通信，以便在每次训练迷你批处理后更新训练权重。此外，它还可以通过 UI 和 CLI 监控训练，从而轻松监控实验进度。</block>
  <block id="ecbeff08f5ec15c6952355b518d4ae02" category="paragraph">NetApp Snapshot 集成在培训代码中，可捕获每个实验的数据状态和经过培训的模型。通过此功能，您可以跟踪所用数据和代码的版本以及生成的相关培训模型。</block>
  <block id="63addc90b28c066bd235c900fed65314" category="section-title">AK 设置和安装</block>
  <block id="50f7d8213ee52350926ec407074e68f1" category="inline-link">创建 AKS 集群</block>
  <block id="55b295c729173e8c0c745bb036b03270" category="paragraph">要设置和安装 AKS 集群，请转至<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block>。然后，按照以下一系列步骤进行操作：</block>
  <block id="8f9d847fad9782b080de76b0161b1c45" category="list-text">选择节点类型（无论是系统（ CPU ）节点还是辅助（ GPU ）节点）时，请选择以下项：</block>
  <block id="957d1a35f975177c3fd161490f3e2d83" category="list-text">以 `Standard_DS2_v2` 大小添加名为 `agentpool` 的主系统节点。使用默认的三个节点。</block>
  <block id="8853a13db2e2a03cb5b2f1186fbcd0a6" category="list-text">添加工作节点 `gpupool` 并使用 `Standard_Nc6s_v3` 池大小。至少为 GPU 节点使用三个节点。</block>
  <block id="5085043d6dea89934a2e516fc46f891a" category="paragraph"><block ref="5085043d6dea89934a2e516fc46f891a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633b880bff72a9f1c1114df31dec55bf" category="admonition">部署需要 5 – 10 分钟。</block>
  <block id="f55bb34768c41f91318fb57b85c1def9" category="inline-link">安装工具</block>
  <block id="6369fc9d36c9d56cbebefdeccda5fbff" category="list-text">部署完成后，单击 Connect to Cluster 。要连接到新创建的 AKS 集群，请从本地环境（笔记本电脑 /PC ）安装 Kubernetes 命令行工具。请访问<block ref="bcd577f96ff7023ec6fd5c904f040896" category="inline-link-rx"></block> 以根据您的操作系统进行安装。</block>
  <block id="811c47e56617f97db3579bc32a9085c9" category="inline-link">在本地环境中安装 Azure CLI</block>
  <block id="ea5d45554a3e9cb9cbc0ddea4c228b28" category="list-text"><block ref="2db79c584144175dd0bb69b6c7045fc9" category="inline-link-rx"></block>。</block>
  <block id="825ca3bff78c42ec87920dfbce105fae" category="list-text">要从终端访问 AKS 集群，请先输入 `az login` 并输入凭据。</block>
  <block id="3394029cd334ed00686c86c088d73c24" category="list-text">运行以下两个命令：</block>
  <block id="193937b265ce655417f00a79334d3937" category="list-text">在 Azure 命令行界面中输入此命令：</block>
  <block id="cbf78d8bb0be543834c56e61560773b0" category="admonition">如果所有六个节点均按此处所示启动并运行，则 AKS 集群已准备就绪并连接到本地环境。</block>
  <block id="e8085ec7505cfe6f3cfbe2c2628386dc" category="paragraph"><block ref="e8085ec7505cfe6f3cfbe2c2628386dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0143a2caee1b9ab090de587206b65fe6" category="section-title">为 Azure NetApp Files 创建委派子网</block>
  <block id="450cf7e7f8262fdaa3454c2e11aad687" category="paragraph">要为 Azure NetApp Files 创建委派子网，请执行以下一系列步骤：</block>
  <block id="0ca30ab1eb5e523356720465eb7439c8" category="list-text">导航到 Azure 门户中的虚拟网络。查找新创建的虚拟网络。它应具有前面板，如 AK vnet ，如此处所示。单击虚拟网络的名称。</block>
  <block id="ce0c628aca3577055043c7f8364600d9" category="paragraph"><block ref="ce0c628aca3577055043c7f8364600d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25157709e5a253560f5ec68b8262563c" category="list-text">单击子网，然后从顶部工具栏中选择 +Subnet 。</block>
  <block id="d9bf5876b80dbf558587f06630e3915c" category="paragraph"><block ref="d9bf5876b80dbf558587f06630e3915c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a07ef5dbc59d5ba150de82d519fb4f8" category="list-text">为子网提供名称，例如 `ANF.SN` ，然后在 Subnet delegation 标题下选择 Microsoft.NetApp/volumes 。请勿更改任何其他内容。单击确定。</block>
  <block id="a8ccea52e17d54aea1295a99ab4d5c2e" category="paragraph"><block ref="a8ccea52e17d54aea1295a99ab4d5c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d182b62071ada1a29e4f9c26487c1121" category="paragraph">Azure NetApp Files 卷将分配给应用程序集群，并在 Kubernetes 中用作永久性卷声明（ Persistent Volume Claim ， PVC ）。反过来，这种分配也为我们提供了将卷映射到不同服务的灵活性，包括 Jupyter 笔记本电脑，无服务器功能等</block>
  <block id="a74ff852d3b3b8447b0306018a76c4f1" category="paragraph">服务用户可以通过多种方式使用平台中的存储。Azure NetApp Files 的主要优势包括：</block>
  <block id="a7c5a83cc4ccf14374e496bcbb4363f5" category="list-text">使用户能够使用快照。</block>
  <block id="ea437fe76a4bba5bf335daccbbd24b50" category="list-text">允许用户在 Azure NetApp Files 卷上存储大量数据。</block>
  <block id="cedebf66380d43f58c07dfb1d4d686a6" category="list-text">在一组大型文件上运行 Azure NetApp Files 卷的型号时，可以获得这些卷的性能优势。</block>
  <block id="75ab13308585f62c3cd57a246d0e0c64" category="section-title">Azure NetApp Files 设置</block>
  <block id="8c060d9ae24c7bc4518e54cd5ed13098" category="inline-link">快速入门：设置 Azure NetApp Files 并创建 NFS 卷</block>
  <block id="fd01c32c80d631ed4bebff78fa83b23e" category="paragraph">要完成 Azure NetApp Files 的设置，必须先按照中所述对其进行配置<block ref="2f4e63e538c7dd311b18db058621cef8" category="inline-link-rx"></block>。</block>
  <block id="e26f032bd6f7f5636860d6b94ac84859" category="paragraph">但是，您可以省略为 Azure NetApp Files 创建 NFS 卷的步骤，因为您将通过 Trident 创建卷。在继续操作之前，请确保您已：</block>
  <block id="e953b5e281d40c5db3cc047889eec4f2" category="inline-link">注册 Azure NetApp Files 和 NetApp 资源提供商（通过 Azure Cloud Shell ）</block>
  <block id="3b46d13fb20fe6a92456f742b5732774" category="list-text"><block ref="527fb205c939c551ed93f597562513fb" category="inline-link-rx"></block>。</block>
  <block id="d0652e942d3d4b469179248d72ccaa5c" category="inline-link">已在 Azure NetApp Files 中创建帐户</block>
  <block id="82a51bbfec23ca7366c216813caeacc8" category="list-text"><block ref="874637dbfce24ba5a63adadd91968dc9" category="inline-link-rx"></block>。</block>
  <block id="02209b9e3a221b39bf0ce87641e7afc6" category="inline-link">设置容量池</block>
  <block id="7b4cb99ad8c150ff95b1a65d0f0524cc" category="list-text"><block ref="0fa33cef09dfad4c8795f42dd9dd5248" category="inline-link-rx"></block> （最低 4 TiB 标准版或高级版，具体取决于您的需求）。</block>
  <block id="1c7c9057bf4f7aee40c5a117c160c0fd" category="section-title">建立 AKS 虚拟网络和 Azure NetApp Files 虚拟网络对等关系</block>
  <block id="998069ab494c49ade2cc77591c02d9fa" category="paragraph">接下来，按照以下步骤将 AKS 虚拟网络（ vNet ）与 Azure NetApp Files vNet 建立对等关系：</block>
  <block id="bf12dce8dcc6febfeddec5ed2570e7d7" category="list-text">在 Azure 门户顶部的搜索框中，键入虚拟网络。</block>
  <block id="3f961f79effdf0aa37042e1733ee53ef" category="list-text">单击 vNet AK - vnet-name ，然后在搜索字段中输入 Peeids 。</block>
  <block id="0249aa06ef3e10e8754106189b542be4" category="list-text">单击 +Add ，然后输入下表中提供的信息：</block>
  <block id="6f16a5f8ff5d75ab84c018adacdfcbb7" category="cell">字段</block>
  <block id="88645c17102d75583e93db9aa716b012" category="cell">值或问题描述</block>
  <block id="f80824cb9ab9f704542dec0c71c5f38b" category="cell">对等链路名称</block>
  <block id="5d43607a5a0ebb50f3ea9348485daa15" category="cell">aps-vnet-name_to_anf</block>
  <block id="62912b52e584278e26870d9e5092e723" category="cell">subscriptionId</block>
  <block id="7d97336a164d9ce685e88a121141b189" category="cell">订阅要与之建立对等关系的 Azure NetApp Files vNet</block>
  <block id="82a60e720574cf435dda0a03976e8323" category="cell">vNet 对等配对节点</block>
  <block id="d2ade9376eb8b87db099330d20c4f180" category="cell">Azure NetApp Files vNet</block>
  <block id="5b92ad691782a9e4cc701e479c90997f" category="admonition">保留所有非星号部分的默认设置</block>
  <block id="0e5883528161213f3edc02dd718e1693" category="list-text">单击添加或确定将对等添加到虚拟网络。</block>
  <block id="12eee9bf8836d675f26602260016f7da" category="inline-link">创建，更改或删除虚拟网络对等关系</block>
  <block id="fa1f15d2aebd0592f338ea9f49e06377" category="paragraph">有关详细信息，请访问<block ref="610fa6db13a2eefe4a391b16732fbbf0" category="inline-link-rx"></block>。</block>
  <block id="91d2f55da5f23abbcf1a0656897d101b" category="paragraph">Trident 是 NetApp 为应用程序容器永久性存储维护的一个开源项目。Trident 已作为外部配置程序控制器实施，该控制器本身作为 POD 运行，可监控卷并完全自动化配置过程。</block>
  <block id="4088b2a65b2a3182209479dced5e78c5" category="paragraph">NetApp Trident 通过创建和附加永久性卷来存储培训数据集和经过培训的模型，可以与 K8 平稳集成。借助此功能，数据科学家和数据工程师可以更轻松地使用 K8 ，而无需手动存储和管理数据集。Trident 还可以通过逻辑 API 集成将数据管理相关任务集成在一起，因此数据科学家无需学习管理新的数据平台。</block>
  <block id="b8b9eab8c1ed7b79387652490f5724ec" category="section-title">安装 Trident</block>
  <block id="77dc68d199719a4b8f5eba742ecb7056" category="paragraph">要安装 Trident 软件，请完成以下步骤：</block>
  <block id="2f2e9ef9449e2f31756b1d3683a207b3" category="inline-link">首先安装 Helm</block>
  <block id="089f0e488d4e2b1a4b02d6d6b638c9d3" category="list-text"><block ref="b3c10ddb3b7f0e3e121ce123f60cc497" category="inline-link-rx"></block>。</block>
  <block id="e12559703ec38e80de7b94fecc84a043" category="list-text">下载并解压缩 Trident 21.01.1 安装程序。</block>
  <block id="7ee913d1a8b01e1a461f9eb99b0bba74" category="list-text">将目录更改为 `trident 安装程序` 。</block>
  <block id="8ad5650fb94bff45b328581838d836fd" category="list-text">将 `tridentctl` 复制到系统中的目录 ` $path.`</block>
  <block id="6da8d48465deb31425595b33a9172acf" category="list-text">使用 Helm 在 K8s 集群上安装 Trident ：</block>
  <block id="7b09729551ddb1a7445f559eb1186978" category="list-text">将目录更改为 helm 目录。</block>
  <block id="27b4c36cae8d1c4fd515d289942c87cc" category="list-text">安装 Trident 。</block>
  <block id="cea04f1ceb2ba2472ec50de3a03a689c" category="list-text">按照通常的 K8s 方式检查 Trident Pod 的状态：</block>
  <block id="6ac3c5fc780260af91dd10523188e6fd" category="list-text">如果所有 Pod 均已启动且正在运行，则会安装 Trident ，您可以继续操作。</block>
  <block id="7862dabe13bf66a99fcfd3a6b1af4d94" category="section-title">设置 Azure NetApp Files 后端和存储类</block>
  <block id="7e98dce86779e84763b71398d851f7bb" category="paragraph">要设置 Azure NetApp Files 后端和存储类，请完成以下步骤：</block>
  <block id="dadab4bead78e450739c0f56bad40cda" category="list-text">切换回主目录。</block>
  <block id="65b8f7db2e9a3793e76d2ec3787f71fa" category="inline-link">项目存储库</block>
  <block id="03636accad716972f761628ea21e43f6" category="list-text">克隆<block ref="2b240ffa21ddbdc99d1706dee4302f7e" category="inline-link-rx"></block> `lan-detect-scnan-horovod` 。</block>
  <block id="0ea725833b806058fe7810e6be91f9c0" category="list-text">转至 `trident — config` 目录。</block>
  <block id="c51fa2034e7d5d97ec8c31248fc18e98" category="list-text">创建 Azure 服务原则（服务原则是 Trident 如何与 Azure 通信以访问 Azure NetApp Files 资源）。</block>
  <block id="7c794fc1e683a6843753158bb92cab75" category="paragraph">输出应类似于以下示例：</block>
  <block id="203565dfd87ac32927ce5a828d45babd" category="list-text">创建 Trident `backend json` 文件。</block>
  <block id="d7e47f31bf1c921dd5e28ee7e6f5cd34" category="list-text">使用您的首选文本编辑器，填写 `anf-backend.json` 文件中下表中的以下字段。</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">价值</block>
  <block id="8c443e170595ba0feac007ffb92cb49a" category="cell">subscriptionId</block>
  <block id="deb6a9aaa10be6bb24feea6a3540128c" category="cell">您的 Azure 订阅 ID</block>
  <block id="bc54592d6183695b841c6d1880ec0bf8" category="cell">tenantId</block>
  <block id="b147f00fa948b22faa89aa8044904495" category="cell">您的 Azure 租户 ID （上一步 AZ AD sp 的输出）</block>
  <block id="93c5bebdea9c94a0740fe6fd9bb250f0" category="cell">clientId</block>
  <block id="5760e6800c58c7dc9ee68efdc6db38de" category="cell">您的应用程序 ID （来自上一步 AZ AD sp 的输出）</block>
  <block id="2b53761249254ce6b502f521e5cc0683" category="cell">客户端机密</block>
  <block id="0571f76a94493cb2020d6c3b7453a367" category="cell">您的密码（上一步 AZ AD sp 的输出）</block>
  <block id="25e6b7ea847b31b4f88b60acd65052db" category="paragraph">此文件应类似于以下示例：</block>
  <block id="49356331b94221561b7751ae1f5343a9" category="list-text">指示 Trident 在 `trident` 命名空间中创建 Azure NetApp Files 后端，使用 `anf-backend.json` 作为配置文件，如下所示：</block>
  <block id="bd9c5e9bd5f130a6fbdbcaeb04656652" category="list-text">创建存储类：</block>
  <block id="a9fa0a3d8bf1bce76ef654f0a047b8fe" category="list-text">K8 用户使用按名称指定存储类的 PVC 配置卷。指示 K8s 使用以下命令创建一个存储类 `azurenetappfiles` ，该存储类将引用上一步中创建的 Azure NetApp Files 后端：</block>
  <block id="5e121b263b32950e629eaf774c12da78" category="list-text">使用以下命令检查是否已创建存储类：</block>
  <block id="202ed88f7ec48eda708f6c062786f474" category="paragraph"><block ref="202ed88f7ec48eda708f6c062786f474" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72611a189b0331f709788d99912a1bd7" category="section-title">在 AKS 上部署和设置卷快照组件</block>
  <block id="3ea90db69187da57e9739e033add6801" category="paragraph">如果集群未预安装正确的卷快照组件，则可以通过运行以下步骤手动安装这些组件：</block>
  <block id="c3987ca9f11aad20ef5d2ae0dd30f9cb" category="admonition">AK 1.18.14 没有预安装的 Snapshot 控制器。</block>
  <block id="312e34d756f6ef39f0bd74e2f844773f" category="list-text">使用以下命令安装 Snapshot 测试版 CRD ：</block>
  <block id="529616f838a47cade6e5fac6f879ce5a" category="list-text">使用 GitHub 中的以下文档安装 Snapshot 控制器：</block>
  <block id="90a2427d3a3145723cd2a130c5372865" category="inline-link">卷快照类</block>
  <block id="8f2838f14b6a64dd466dc23bcf7e3c01" category="list-text">设置 K8s `volumesnapshotclass` ：创建卷快照之前，请先执行<block ref="cba124de563550c68e57cf9a6641a5d1" category="inline-link-rx"></block> 必须已设置。为 Azure NetApp Files 创建卷快照类，并使用它通过 NetApp Snapshot 技术实现 ML 版本控制。create `volumesnapshotclass netapp-csI-snapclass` 并将其设置为 default `volumesnapshotclass `，如下所例：</block>
  <block id="adc3a39a071327998da9cc6708ef4fe8" category="paragraph"><block ref="adc3a39a071327998da9cc6708ef4fe8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="770bec683fa99c1a917babb074d95e66" category="list-text">使用以下命令检查是否已创建卷 Snapshot 副本类：</block>
  <block id="99b5a364457d91999df6ca6488b800f2" category="paragraph"><block ref="99b5a364457d91999df6ca6488b800f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d9a6cca62c9095cbae70692ef82741c" category="section-title">运行： AI 安装</block>
  <block id="d1d2b81816d977b7a9d3480a495beda5" category="paragraph">要安装 run ： ai ，请完成以下步骤：</block>
  <block id="7899a1a12ecf76a5676a6d5ddb64842f" category="inline-link">在 AKS 上安装 run ： ai 集群</block>
  <block id="54437101a8cdfe297499d517331ced60" category="list-text"><block ref="400679f1b873ae4a832f018613d486cc" category="inline-link-rx"></block>。</block>
  <block id="5f854e827ba37f66f45f8e47643e23ea" category="list-text">转至 app.runai.ai ，单击创建新项目，然后将其命名为 LAN-detection 。它将在 K8s 集群上创建一个命名空间，其开头为 `runai` - ，后跟项目名称。在这种情况下，创建的命名空间将为 runai-lane 检测。</block>
  <block id="e699d582d1b58a9a23ebd74cab11d5bc" category="paragraph"><block ref="e699d582d1b58a9a23ebd74cab11d5bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="546524b2c8ed6fd083c9286159ebd55a" category="inline-link">安装 run ： ai 命令行界面</block>
  <block id="f3a9807f54199fd5dbad651af2ea853a" category="list-text"><block ref="6291ffcd5a23a3d0b996bc90930ef0b3" category="inline-link-rx"></block>。</block>
  <block id="08d1d73b27232763a82ef46a413779ce" category="list-text">在您的终端上，使用以下命令将通道检测设置为默认运行： AI project ：</block>
  <block id="0ca589f93fd9565aa5fc097fd66437ae" category="paragraph"><block ref="0ca589f93fd9565aa5fc097fd66437ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cd1a85dd18a7a0b8f1d07b4240fafcf" category="list-text">为项目命名空间创建 ClusterRole 和 ClusterRoleBinding （例如， `LANE-detection ）` 因此，属于 `runai-lan-detection` namespace 的默认服务帐户有权在作业执行期间执行 `volumesnapshot` 操作：</block>
  <block id="351495b134e625df33dfb5230d6eab7b" category="list-text">使用以下命令列出命名空间以检查 `runai-lan-detection` 是否存在：</block>
  <block id="bd546162071f28fd50f8c977ac61149e" category="paragraph">输出应类似于以下示例：</block>
  <block id="8c33c9910dfecb6260489cd05f43b275" category="paragraph"><block ref="8c33c9910dfecb6260489cd05f43b275" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f23930532ba19f8970c6dcb4b6ad778f" category="list-text">使用以下命令创建 ClusterRole `netappsnapshot` 和 ClusterRoleBinding`netappsnapshot` ：</block>
  <block id="7e3ec6f763cd8a13380162aba60c47e0" category="section-title">下载并将 TuSimple 数据集作为 run ： ai 作业处理</block>
  <block id="c0cc307d9f63d0a096f8d6e3193cd561" category="paragraph">下载并处理运行时的 TuSimple 数据集的过程： AI 作业是可选的。其中包括以下步骤：</block>
  <block id="52eeaf7bac6d3e2111d129a11d0bafed" category="list-text">构建并推送 Docker 映像，或者如果要使用现有 Docker 映像（例如， `muneer7589/download-tusimple ： 1.0 ）` ，则省略此步骤</block>
  <block id="0d5647db76048e129c1146a822abbdd8" category="list-text">切换到主目录：</block>
  <block id="02c403c221afbdccdc4f7182e2eb5cb7" category="list-text">转到项目的数据目录 `lan-detect-scnan-horovod` ：</block>
  <block id="eed104c2f8af7c3526ec55b8cc69dde7" category="list-text">修改 `build_image.sh` shell 脚本并将 Docker 存储库更改为您的。例如，将 `muneer7589` 替换为 Docker 存储库名称。您还可以更改 Docker 映像名称和标记（例如 `download-tusimple` 和 `1.0` ）：</block>
  <block id="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="paragraph"><block ref="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed49e04589e6c9071bbd1af307f83a0" category="list-text">运行脚本以构建 Docker 映像，并使用以下命令将其推送到 Docker 存储库：</block>
  <block id="8ebf5e70d0ed304519c7c9b525d80af1" category="list-text">提交运行： AI 作业，以下载，提取，预处理并将 Tubple 通道检测数据集存储在一个 `PVC` 中，该 PVC 由 NetApp Trident 动态创建：</block>
  <block id="050d58b165aef32cad86839521b721b2" category="list-text">使用以下命令提交运行： AI 作业：</block>
  <block id="83b4fb868b7505e293871c3e5accc98c" category="list-text">输入下表中的信息以提交运行： AI 作业：</block>
  <block id="e50d72d773874b2be58530daec43900c" category="cell">name</block>
  <block id="37e9bb74490b0ac510effff5a546f11d" category="cell">作业的名称</block>
  <block id="5503ed8f71ae365eb6f5e8221562a0eb" category="cell">-pvc</block>
  <block id="626299ff067d1e6a178beced1631ab43" category="cell">PVC 格式为 [StorageClassName] ： size ： ContainerMountPath 在上述作业提交中，您正在使用具有存储类 azurenetappfiles 的 Trident 根据需要创建 PVC 。此处的永久性卷容量为 100Gi ，并挂载在路径 /mnt 处。</block>
  <block id="0247d7fb481075907b9eb467cfe90e3a" category="cell">图像</block>
  <block id="b30f1ca8b35fd6ccab829a959f414a51" category="cell">创建此作业的容器时要使用的 Docker 映像</block>
  <block id="22a55ba6c8590fa98f1b3234141f2848" category="paragraph"><block ref="22a55ba6c8590fa98f1b3234141f2848" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af270e479cd849e4a9cb6d17b76585ef" category="list-text">列出已提交的运行： AI 作业。</block>
  <block id="f740410b6ea33d3ffc740140cc23a0e2" category="paragraph"><block ref="f740410b6ea33d3ffc740140cc23a0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51869a860c4af748ec2815d406929a17" category="list-text">检查提交的作业日志。</block>
  <block id="ab353387b0e5276e03aecae4cc95d150" category="paragraph"><block ref="ab353387b0e5276e03aecae4cc95d150" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84dd51baa0cf15db0a639dbb6d5d8ee" category="list-text">列出已创建的 `PVC` 。在下一步中使用此 `PVC` 命令进行培训。</block>
  <block id="cc2e05fe54a847aee415a2deb0b7f13e" category="paragraph"><block ref="cc2e05fe54a847aee415a2deb0b7f13e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b20e4749f78095f0b9adf5c3cad36f81" category="list-text">在 run ： ai UI （或 `app.run.ai` ）中检查作业。</block>
  <block id="ced39410c19f3968638fc81e16743f32" category="paragraph"><block ref="ced39410c19f3968638fc81e16743f32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3dee54cb181d3bfde644600fb15bbac4" category="section-title">使用 Horovod 执行分布式通道检测培训</block>
  <block id="645e2c981858a720c673c6a782efd9ea" category="paragraph">使用 Horovod 执行分布式通道检测培训是一个可选过程。但是，需要执行以下步骤：</block>
  <block id="04e568eec6dda4a0cfb1fc6680509d35" category="list-text">构建并推送 Docker 映像，或者如果要使用现有 Docker 映像（例如， `muneer7589/dist-lan-detection ： 3.1 ），请跳过此步骤：`</block>
  <block id="b01fdc5088b4a04549ed5e7cc71f898b" category="list-text">切换到主目录。</block>
  <block id="14e21ef8495bc1dd543db0aebbe06c5b" category="list-text">转到项目目录 `lan-detect-scnan-horovod.`</block>
  <block id="0a27aa824e245e7b31f5f8d990636ead" category="list-text">修改 `build_image.sh` shell 脚本并将 Docker 存储库更改为您的（例如，将 `muneer7589` 替换为您的 Docker 存储库名称）。您也可以更改 Docker 映像名称和标记（例如， `dist-lan-detection` 和 `3.1 ）` 。</block>
  <block id="c9ce95c3d4cf96d5e894e4a834754cb6" category="paragraph"><block ref="c9ce95c3d4cf96d5e894e4a834754cb6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2776d43d1e635424496622f14cfd745c" category="list-text">运行脚本以构建 Docker 映像并推送到 Docker 存储库。</block>
  <block id="b9bcfd06c5cdfc67a00ffe8a0c846318" category="list-text">提交 Run ： AI 作业以执行分布式培训（ MPI ）：</block>
  <block id="f3b76b64a9761cfb85f0ddc37d910fef" category="list-text">使用提交运行： AI 在上一步中自动创建 PVC （用于下载数据）仅允许您访问 RW ，这样不允许多个 Pod 或节点在分布式培训中访问同一 PVC 。将访问模式更新为 ReadWriteMany ，然后使用 Kubernetes 修补程序执行此操作。</block>
  <block id="2874172b683ddc4047fd63f29baf543d" category="list-text">首先，运行以下命令以获取 PVC 的卷名称：</block>
  <block id="bcc0952c2970bfd6c85cd65050e00533" category="paragraph"><block ref="bcc0952c2970bfd6c85cd65050e00533" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64ac0e4e6343f4593e210b98f9c91de" category="list-text">修补卷并将访问模式更新为 ReadWriteMany （在以下命令中将卷名称替换为您的）：</block>
  <block id="7a9d347cf2f324e82478a9cf243448f7" category="list-text">使用下表中的信息提交运行： AI MPI 作业以执行分布式培训` 作业：</block>
  <block id="b068931cc450442b63f5b3d276ea4297" category="cell">name</block>
  <block id="e4580c1854231c935f0cf2eb4609d97a" category="cell">分布式培训作业的名称</block>
  <block id="384dd16a327b7f16278642f008c27fab" category="cell">大型 shm</block>
  <block id="fc9fed4d0a3cb207102499ba041f2603" category="cell">挂载大型 /dev/shm 设备这是一个挂载在 RAM 上的共享文件系统，可为多个 CPU 工作人员提供足够大的共享内存来处理批处理并将其加载到 CPU RAM 中。</block>
  <block id="530968b205d33b3869aa32e2933fbfad" category="cell">流程</block>
  <block id="403e4aa48fedb1c5777ee913b2f2bedb" category="cell">分布式培训流程的数量</block>
  <block id="0aa0be2a866411d9ff03515227454947" category="cell">GPU</block>
  <block id="031492a2d708ca774bd08c099eb4dd79" category="cell">要为此作业中的作业分配的 GPU/ 进程数，有三个 GPU 工作进程（ -processes=3 ），每个进程都分配有一个 GPU （ -GPU 1 ）</block>
  <block id="642542e40351edbd731ebad352b31317" category="cell">PVC</block>
  <block id="c50723a53a74a682495f8c3810ce4a65" category="cell">使用由先前作业（ download-tusimple 数据）创建并挂载到路径 /mnt 的现有永久性卷（ vpvc 下载 -tusimple 数据 0 ）</block>
  <block id="78805a221a988e79ef3f42d7c5bfd418" category="cell">图像</block>
  <block id="8c236f63f205a50942b609a6d45734a7" category="cell">定义要在容器中设置的环境变量</block>
  <block id="61dcf83940f915d0c5fe5b985eed7be8" category="cell">use_works.</block>
  <block id="f84e120605e14d9755a1ed2e8e03cea6" category="cell">如果将参数设置为 true ，则会启用多进程数据加载</block>
  <block id="90b186f5d2a6890e77373c8aa60461e7" category="cell">num_works.</block>
  <block id="a10574eb8e119b847fb5ab95b788e723" category="cell">数据加载程序工作进程的数量</block>
  <block id="61c67ea819106ff81c08249014791d3b" category="cell">batch_size</block>
  <block id="243f7fe32e2dbb7748c1a018fe60016e" category="cell">训练批大小</block>
  <block id="d07f4474a5e5996da9b6e57abb250331" category="cell">使用 VAL</block>
  <block id="919bc92a851c1d3e2c467e844398b751" category="cell">如果将参数设置为 true ，则可以进行验证</block>
  <block id="c4407b612c3b5e2c00c1b5522c686c84" category="cell">Val_batch_size</block>
  <block id="597765782da042e86019b4c919a86248" category="cell">验证批处理大小</block>
  <block id="18e0d33045db50bb37e6f2fcd5c0b842" category="cell">enable_snapshot</block>
  <block id="67c5deea68dff022b0f807ffb3bf56e2" category="cell">如果将参数设置为 true ，则可以为 ML 版本控制创建数据和经过培训的模型快照</block>
  <block id="cdd7dd1603420ef6c3efe7b264205137" category="cell">PVC_NAME</block>
  <block id="d95926771c9100db9ba3e3247c86a192" category="cell">要为其创建快照的 PVC 的名称。在提交的上述作业中，您将创建由数据集和经过培训的模型组成的 PVC-download-tusimple data-0 的快照</block>
  <block id="b302d66ab7f3f0c94236ff26c8ead4d9" category="inline-image-macro">错误：缺少图形映像</block>
  <block id="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="paragraph"><block ref="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3299ed00d03beff0cc2ebaf178a91786" category="list-text">列出已提交的作业。</block>
  <block id="2e593aa2ccf62807184e56a543d23e97" category="paragraph"><block ref="2e593aa2ccf62807184e56a543d23e97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82abe908a319245230ef0f3ec84c263f" category="list-text">已提交作业日志：</block>
  <block id="dab56217fc48a1919fee48434a7c7204" category="paragraph"><block ref="dab56217fc48a1919fee48434a7c7204" category="inline-image-macro-rx" type="image"></block></block>
  <block id="981528b0e4cd4a19c56310c6b9c915ce" category="list-text">查看 Run 中的培训作业： AI GUI （或 app.runai.ai): run ： AI Dashboard ，如下图所示。第一个图详细介绍了为分布在 AKS 三个节点上的分布式培训作业分配的三个 GPU ，以及第二个运行： AI 作业：</block>
  <block id="d8cbd4299e4baf5de5572bf6af32dd52" category="paragraph"><block ref="d8cbd4299e4baf5de5572bf6af32dd52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90fdc4068f0b660d1d6b102946986bd1" category="paragraph"><block ref="90fdc4068f0b660d1d6b102946986bd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e8bb0b427c33dd6cf63d1a3a37c7022" category="list-text">完成培训后，请检查创建的 NetApp Snapshot 副本，并将其与 run ： ai 作业链接在一起。</block>
  <block id="6c94f812a836696605e3e2b6bd5ca768" category="paragraph"><block ref="6c94f812a836696605e3e2b6bd5ca768" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4c0a1395081fc81855e465c493f4967" category="section-title">从 NetApp Snapshot 副本还原数据</block>
  <block id="ec8de1dcfce51c9d877901e2f6f5971e" category="paragraph">要从 NetApp Snapshot 副本还原数据，请完成以下步骤：</block>
  <block id="5adc4d7860e7ad0f78ada0bb1f0eaca6" category="list-text">转到项目目录 `lan-detect-scnan-horovod` 。</block>
  <block id="6344772f26907403fed713060f33b8f4" category="list-text">修改 `restore-snaphot-vc.yaml` 并将 `dataSource` `name` 字段更新到要从中还原数据的 Snapshot 副本。您也可以更改要将数据还原到的 PVC 名称，在此示例中为其 `restored-tusimple` 。</block>
  <block id="b3b5448c329ac882bc890a1be1a1b369" category="paragraph"><block ref="b3b5448c329ac882bc890a1be1a1b369" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f8efb3d1b86c88cfab193291776b6ad" category="list-text">使用 `restore-snapshot-vc.yaml` 创建新的 PVC 。</block>
  <block id="34c7c2e95019754701182fe2ab194499" category="paragraph"><block ref="34c7c2e95019754701182fe2ab194499" category="inline-image-macro-rx" type="image"></block></block>
  <block id="070856555a817dbf9a4061542b2098ca" category="list-text">如果您要使用刚刚还原的数据进行培训，则作业提交将保持不变；在提交培训作业时，只需将 `vc_name` 替换为已还原的 `vc_name` ，如以下命令所示：</block>
  <block id="e945ddc4d35a9c49a17bd00c53db05a6" category="section-title">性能评估</block>
  <block id="3451b157ef07ae84bfaba5fb6639c1ba" category="paragraph">为了显示解决方案的线性可扩展性，我们对以下两种情形进行了性能测试：一个 GPU 和三个 GPU 。在有关 TuSimple 通道检测数据集的培训中，我们捕获了 GPU 分配， GPU 和内存利用率，不同的单节点和三节点指标。为了分析培训过程中的资源利用率，数据增加了五倍。</block>
  <block id="b8077d533d2f9918c47d330cbac4392d" category="inline-link-macro">Azure NetApp Files 服务级别</block>
  <block id="da9b7dc2993c3c848d5d9a9a15806d8c" category="paragraph">借助解决方案，客户可以从一个小型数据集和几个 GPU 入手。当数据量和 GPU 需求增加时，客户可以动态地横向扩展标准层中的 TB ，并快速扩展到高级层，从而在不移动任何数据的情况下获得每 TB 吞吐量的四倍。本节将进一步介绍此过程。 <block ref="bdbab4daa7de478307acc7147c869853" category="inline-link-macro-rx"></block>。</block>
  <block id="090a231c840a0cb23aa29c8d1afc7832" category="paragraph">一个 GPU 的处理时间为 12 小时 45 分钟。三个节点上的三个 GPU 的处理时间约为 4 小时 30 分钟。</block>
  <block id="49eca64b9f03702167beb48ebd38587b" category="paragraph">本文档其余部分中显示的图说明了根据各个业务需求提供的性能和可扩展性示例。</block>
  <block id="abfc10c2bc00a990735e6d27797295a8" category="paragraph">下图显示了 1 个 GPU 分配和内存利用率。</block>
  <block id="8d7e3abab70510c3f4636ff7bf953250" category="paragraph"><block ref="8d7e3abab70510c3f4636ff7bf953250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31a3d2def4927574922946c38f043c0b" category="paragraph">下图显示了单节点 GPU 利用率。</block>
  <block id="58cf0f270760f08ac96254402d0696dc" category="paragraph"><block ref="58cf0f270760f08ac96254402d0696dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dcca9cfd87d9f2087d720ef187655cea" category="paragraph">下图显示了单节点内存大小（ 16 GB ）。</block>
  <block id="e22d39f2830d0f3e3944644d0f605d41" category="paragraph"><block ref="e22d39f2830d0f3e3944644d0f605d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="576c0843e21d5ee884a067aa7b6a1a40" category="paragraph">下图显示了单节点 GPU 计数（ 1 ）。</block>
  <block id="ef855771be83c072ebaafc60d2d1933f" category="paragraph"><block ref="ef855771be83c072ebaafc60d2d1933f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2c50f1b8fc86c36cc0df94dd14b46b9" category="paragraph">下图显示了单节点 GPU 分配（ % ）。</block>
  <block id="e295f84458327d01315b814d8deb2aea" category="paragraph"><block ref="e295f84458327d01315b814d8deb2aea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b2b7f256373eac14419bfec5b84b21" category="paragraph">下图显示了三个节点上的三个 GPU — GPU 分配和内存。</block>
  <block id="e763ef0e4b7cb9d022bf6db49319c570" category="paragraph"><block ref="e763ef0e4b7cb9d022bf6db49319c570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94ab4242b167972f7a9f0513ca772555" category="paragraph">下图显示了三个节点的三个 GPU 利用率（ % ）。</block>
  <block id="d786146ae56597413fa5be548126cda9" category="paragraph"><block ref="d786146ae56597413fa5be548126cda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c31ecb239228cac5e96860d42f9a4d" category="paragraph">下图显示了三个节点的三个 GPU 内存利用率（ % ）。</block>
  <block id="2224958fd5113068ac8a3b55a336661b" category="paragraph"><block ref="2224958fd5113068ac8a3b55a336661b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79f05e8f99917560625d1cf3f2d4fc5d" category="inline-link">服务级别</block>
  <block id="07c1fda2408980b5d53ea06ad3cc5ed1" category="paragraph">您可以通过将现有卷移动到使用的另一个容量池来更改此卷的服务级别<block ref="bc9fbd5fd43d884f02abe6a6f9b51339" category="inline-link-rx"></block> 所需的卷。此卷的现有服务级别更改不需要迁移数据。它也不会影响对卷的访问。</block>
  <block id="5e2ff0b5dc3206032a81aa3aecb7c462" category="section-title">动态更改卷的服务级别</block>
  <block id="58e691ddc6184f73e5d6b513ca5a3c49" category="paragraph">要更改卷的服务级别，请执行以下步骤：</block>
  <block id="3f19b438418ed162387a3050b304c89b" category="list-text">在卷页面上，右键单击要更改其服务级别的卷。选择更改池。</block>
  <block id="5acf521dbc5099b2ec33a64efac89595" category="paragraph"><block ref="5acf521dbc5099b2ec33a64efac89595" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6533c4186062235d8b7f47e232e92597" category="list-text">在更改池窗口中，选择要将卷移动到的容量池。然后，单击确定。</block>
  <block id="3f0874d07ce6ae728a6dcdda7903f9cd" category="paragraph"><block ref="3f0874d07ce6ae728a6dcdda7903f9cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb935c59f24539e0966b7ab5c761e862" category="section-title">自动执行服务级别更改</block>
  <block id="1391028ed384c93fd59fd5a0097f9181" category="paragraph">动态服务级别更改当前仍在公有预览中，但默认情况下不会启用。要在 Azure 订阅上启用此功能，请按照文档 " 中提供的步骤进行操作<block ref="5c3671452d40598396b030d5c9c6dc27" category="inline-link-rx"></block>。 "</block>
  <block id="407443b5508c517acd825fbcddb7ab4c" category="inline-link">AZ netappfiles volume ：管理 Azure NetApp Files （ ANF ）卷资源</block>
  <block id="1d3afb31c5d2a81fca940ae760671a1c" category="list-text">您还可以对 Azure 使用以下命令： CLI 。有关更改 Azure NetApp Files 的池大小的详细信息，请访问<block ref="8b45caafcc8d758d5c37edb19f8a2761" category="inline-link-rx"></block>。</block>
  <block id="ebd5b070cb8457b94f1916baa92c3c7d" category="inline-link">更改 Azure NetApp Files 卷的池</block>
  <block id="d5460fd5fbfbf643b9a4bc1d1de279d0" category="list-text">此处显示的 `set- aznetappfilesvolumepool` cmdlet 可更改 Azure NetApp Files 卷的池。有关更改卷池大小和 Azure PowerShell 的详细信息，请访问<block ref="70c8d95cde8b63eae0d37a8b81a31482" category="inline-link-rx"></block>。</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">追加信息</block>
  <block id="7661400c51b9fc184bdec46eb5577ff9" category="doc">从 GitHub 获取代码</block>
  <block id="1a3652d661d6b73b6aa57aff1fa5e4d4" category="paragraph">既然 NetApp Cloud Volume 或 NetApp Trident 卷可供 Iguazio 集群和开发人员环境使用，您就可以开始查看该应用程序了。</block>
  <block id="ae53ae826cc9a587fbaee0e834dd75ca" category="paragraph">用户拥有自己的工作空间（目录）。在每个笔记本电脑上，用户目录的路径为 ` /User` 。Iguazio 平台负责管理目录。如果按照上述说明进行操作，则可以在 ` /NetApp` 目录中找到 NetApp Cloud 卷。</block>
  <block id="754e85a9ea7f4fbb718080a73790abdb" category="paragraph">使用 Jupyter 终端从 GitHub 获取代码。</block>
  <block id="1d706cc291efb1d79274befd6f9dd64c" category="paragraph"><block ref="1d706cc291efb1d79274befd6f9dd64c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12d0e4b8ba8db4e6a7aa1dda942a1ed4" category="paragraph">在 Jupyter 终端提示符处，克隆项目。</block>
  <block id="d4095d9e0ab52b6d683ace00b5cbea55" category="paragraph">现在，您应在 Jupyter 工作空间的文件树中看到 `NetOps" - "NetApp` " 文件夹。</block>
  <block id="2e52c56d063752bbfeda9c8f9d2fee41" category="summary">此页面介绍了在 Kubernetes 集群中安装和配置 NetApp Trident 时必须完成的任务。</block>
  <block id="7c4090c7fa7a91e8c7fed182401dbf6b" category="doc">NetApp Trident 部署和配置</block>
  <block id="e539ec743b02403b5ba74b884d117a5a" category="paragraph">本节介绍在 Kubernetes 集群中安装和配置 NetApp Trident 时必须完成的任务。</block>
  <block id="14ede02439184c7c75e53410ffa40370" category="list-text">您已有一个可正常工作的 NetApp 存储设备，软件定义的实例或云存储服务， Trident 支持此服务。</block>
  <block id="984b69562391cb8032fd50ded03a29a6" category="paragraph">要在 Kubernetes 集群中安装和配置 NetApp Trident ，请从部署跳转主机执行以下任务：</block>
  <block id="07d8795f785e6495307106596d07402e" category="list-text">使用以下方法之一部署 Trident ：</block>
  <block id="040d3466a6f1c45ca2e523c9354dfdc7" category="inline-link">Trident 部署说明</block>
  <block id="bb6989644edf59b8c5e0de0c25b6f8b6" category="list-text">如果您使用 NVIDIA DeepOps 部署 Kubernetes 集群，则也可以使用 NVIDIA DeepOps 在 Kubernetes 集群中部署 Trident 。要使用 DeepOps 部署 Trident ，请按照<block ref="77e542aaaac8c5d2482c94ca2d79c997" category="inline-link-rx"></block> 在 NVIDIA DeepOps GitHub 站点上。</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">部署说明</block>
  <block id="7cfdcb466d040b6c8f9c85e9981b9652" category="inline-link-macro">适用于 ONTAP AI 部署的 Kubernetes Storageclasses 示例</block>
  <block id="180b707bbdd9c2fc8001a966c6c7d029" category="admonition">如果要在 ONTAP AI POD 上部署 NetApp AI 控制平台解决方案，请参见 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block> 有关您可能希望创建和的不同 Trident 后端的一些示例，请参见 <block ref="d495c2f5a68f6923824470c0096419c8" category="inline-link-macro-rx"></block> 有关可能要创建的不同 Kubernetes StorageClasses 的一些示例，请参见。</block>
  <block id="13e8f52d7e19f83d3e64003c58ea220b" category="doc">使用 NDE 在 NetApp HCI 上部署 VMware 虚拟基础架构（自动化部署）</block>
  <block id="2635318d9bf1ea76c73bfab7f3eeafb7" category="section-title">NDE 部署前提条件</block>
  <block id="f6ec2c1aa5118cb19e89af5a10ecb65c" category="inline-link">NetApp HCI 前提条件检查清单</block>
  <block id="2187fc20798cda55150d8c067fac10be" category="paragraph">请参见<block ref="c760383d1767df51ab118e6ffc289894" category="inline-link-rx"></block> 在开始部署之前查看 NetApp HCI 的要求和建议。</block>
  <block id="cd02d0868a7414dd1e76924b30b82b52" category="list-text">网络和交换机要求和配置</block>
  <block id="1d8b6c167080876dff9ad2e74e70fecf" category="list-text">准备所需的 VLAN ID</block>
  <block id="17cec09f14c225b5f27dc73542e9077a" category="list-text">交换机配置</block>
  <block id="4d40082ed807aa2fb7e1d2f03921e4d4" category="list-text">NetApp HCI 和 VMware 的 IP 地址要求</block>
  <block id="2e8e4792043f43cb4b34a84b8dcd909b" category="list-text">DNS 和保留时间要求</block>
  <block id="829710d6ec2a8e59e7a69fb3537ec494" category="list-text">最后准备工作</block>
  <block id="fb720b4ad7c03710e0e5771c9fb58b44" category="section-title">NDE 执行</block>
  <block id="cf50c81e30d1d64fcb4992a9792abedb" category="paragraph">在执行 NDE 之前，您必须完成所有组件的机架和堆栈，网络交换机的配置以及所有前提条件的验证。如果您计划允许 NDE 自动配置所有地址，则可以通过连接到单个存储节点的管理地址来执行 NDE 。</block>
  <block id="130c61c344b6fbf262b6f63818eab7e4" category="paragraph">NDE 执行以下任务以使 HCI 系统联机：</block>
  <block id="d89f68a2ec388fe5d72fb6fe024a0176" category="list-text">至少在两个存储节点上安装存储节点（ NetApp Element 软件）。</block>
  <block id="f6f86c1086573c7daeb1f48535041576" category="list-text">至少在两个计算节点上安装 VMware 虚拟机管理程序。</block>
  <block id="0718265bec3e2ee6fc9d5e0773b5ff60" category="list-text">安装 VMware vCenter 以管理整个 NetApp HCI 堆栈。</block>
  <block id="e09575b9713329ebe2480dbf404b2b1b" category="list-text">安装和配置 NetApp 存储管理节点（ mNode ）和 NetApp 监控代理。</block>
  <block id="dddc28f734d0bcb367638f51ef8b4dfa" category="admonition">此验证使用 NDE 自动配置所有地址。您也可以在环境中设置 DHCP ，或者为每个存储节点和计算节点手动分配 IP 地址。本指南不会介绍这些步骤。</block>
  <block id="dd9cd526f5753b79bda6de19f1a66fe9" category="paragraph">如前所述，此验证对计算节点使用双缆线配置。</block>
  <block id="32691d86c49e682187776e0262b732d7" category="paragraph">本文档不介绍 NDE 的详细步骤。</block>
  <block id="968a3687be335c74374e73712c63e2e4" category="inline-link">部署指南</block>
  <block id="8b6e1a3a9d21ff63520793416432cd56" category="paragraph">有关完成基础 NetApp HCI 平台部署的分步指导，请参见<block ref="7742239770a3accee30f01673a1a43a5" category="inline-link-rx"></block>。</block>
  <block id="61ef02ded53524d506cd714c5821cd86" category="list-text">完成 NDE 后，登录到 vCenter 并创建一个分布式端口组 `NetApp HCI VDS 01-NFS_Network` ，以供 ONTAP Select 和应用程序使用。</block>
  <block id="bd9091c7320e4b1069eed28f04839354" category="paragraph">在构建自己的 AI/ML 管道时，配置架构中组件的集成，管理，安全性和可访问性是一项极具挑战性的任务。让开发人员访问和控制其环境也带来了另一组挑战。</block>
  <block id="820423ca1ad0e872ef04cbb366b6e3de" category="paragraph">NetApp 与 Iguazio 的结合将这些技术作为托管服务整合在一起，加快了技术采用速度，并缩短了新 AI/ML 应用程序的上市时间。</block>
  <block id="2fb227f90ebf269423fe0cf1a15b8111" category="doc">定义永久性卷声明</block>
  <block id="8f5da11015f2baf835f0e8b421c1cfe9" category="list-text">将以下 YAML 保存到文件中，以创建类型为 Basic 的 PVC 。</block>
  <block id="04c58cdb1d0c073dd558caf87f2b8ed1" category="list-text">将 YAML 文件应用于您的 Iguazio Kubernetes 集群。</block>
  <block id="f685fdfcc5aedb3ccc237a4020b69cd8" category="section-title">将 NetApp 卷附加到 Jupyter 笔记本电脑</block>
  <block id="dc4b8e255a77b2c73f89b702dbb7acc5" category="inline-link">Iguazio 应用程序服务和工具概述</block>
  <block id="11eb1e24a14c1d15ee5e287b4338b764" category="paragraph">Iguazio 提供多种托管服务，为数据科学家提供完整的端到端堆栈，用于开发和部署 AI/ML 应用程序。有关这些组件的详细信息，请参见<block ref="2cf4dcc22fda31f66959754df93d6196" category="inline-link-rx"></block>。</block>
  <block id="3591be3d07a4f8a37d218b9e92bea432" category="paragraph">其中一项托管服务是 Jupyter Notebook 。每个开发人员都可以使用开发所需的资源自行部署一个笔记本容器。要授予他们对 NetApp Cloud Volume 的访问权限，您可以将卷分配给容器，并在下图中显示了永久性卷声明的正在运行的用户和环境变量设置。</block>
  <block id="e0d870d503aeb797f7626b14c9acb4ae" category="paragraph">对于内部配置，您可以参见<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> 在 Trident 设置中启用 NetApp ONTAP 数据管理功能，例如为数据或模型创建 Snapshot 副本以进行版本控制。在 Trident 后端配置文件中添加以下行，以使 Snapshot 目录可见：</block>
  <block id="12ce9751e0e6d2a7d593d46e19211984" category="inline-link">Trident 命令</block>
  <block id="71f8fa2d01d0c5a2d9af72f90f65e379" category="paragraph">您必须以 JSON 格式创建 Trident 后端配置文件，然后运行以下命令<block ref="1dce3ee9e9ff2b59caf27104be259d37" category="inline-link-rx"></block> 要参考此指南：</block>
  <block id="2842c07cfacaf614e63dc1f2afef93b2" category="paragraph"><block ref="2842c07cfacaf614e63dc1f2afef93b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="34d54070f7d06f04159ffbc3d9a3e082" category="doc">配置工作环境</block>
  <block id="8302b607de31151e5500de556070d9b9" category="paragraph">将 `Notebook` `set_env-example.ipynb` 复制为 `set_env.ipynb` 。打开并编辑 `set_env.ipynb` 。此笔记本电脑可为凭据，文件位置和执行驱动程序设置变量。</block>
  <block id="3dc3cffc26096b89061a452cc7d16b6a" category="paragraph">如果按照上述说明进行操作，则只需执行以下步骤即可：</block>
  <block id="26448fec50e405fb230427686eeb11f4" category="list-text">从 Iguazio 服务信息板获取此值： `docker_regRegistry`</block>
  <block id="837784ac15c5cac463a4d016bac63db1" category="paragraph">示例： `docker-registry.default-tenant.app.clusterq.iguaziodev.com:80`</block>
  <block id="04dca9f72f7dfc6f87034c574f821a12" category="list-text">将 `admin` 更改为您的 Iguazio 用户名：</block>
  <block id="b2dea33f1195135f6905b7dd0ee58713" category="paragraph">`IGZ_container_path = "/" 用户 /admin"`</block>
  <block id="0ddaf8f981ee966dc3533de490c7ee4e" category="paragraph">下面是 ONTAP 系统连接详细信息。包括安装 Trident 时生成的卷名称。以下设置适用于内部 ONTAP 集群：</block>
  <block id="dada97be0cb81e6518d92aa7112fa356" category="paragraph">以下设置适用于 Cloud Volumes ONTAP ：</block>
  <block id="586d20125924bc57624aaacc07973d5a" category="section-title">创建基本 Docker 映像</block>
  <block id="0ab24923db4855b821917446711104c9" category="paragraph">构建 ML 管道所需的一切都包含在 Iguazio 平台中。开发人员可以定义运行管道和从 Jupyter Notebook 执行映像创建所需的 Docker 映像的规格。打开笔记本 `creation- images.ipynb` 并运行所有单元格。</block>
  <block id="3dc4e8abb0e99c6cf29451a16a891524" category="paragraph">此笔记本可创建两个我们在管道中使用的映像。</block>
  <block id="5446cc82e4c165e2700af830f8428d63" category="list-text">`igiio/NetApp.` 用于处理 ML 任务。</block>
  <block id="61145f9d17e187b69bc41525b10aafe6" category="paragraph"><block ref="61145f9d17e187b69bc41525b10aafe6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62e9956426227f62abc9692954a5ad39" category="list-text">`NetApp/ 渠道` 。包含用于处理 NetApp Snapshot 副本的实用程序。</block>
  <block id="4050f795a12d7f83a545999c8a0d1905" category="paragraph"><block ref="4050f795a12d7f83a545999c8a0d1905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6677daf583d4c0cf5860927a024f278d" category="section-title">查看各个 Jupyter 笔记本电脑</block>
  <block id="6414e1c23e017075a375d3a531eab90c" category="paragraph">下表列出了我们用于构建此任务的库和框架。所有这些组件均已与 Iguazio 基于角色的访问和安全控制完全集成。</block>
  <block id="da292beca00e0b352eade7a070855fd3" category="cell">库 / 框架</block>
  <block id="124d604ba0d3fd8e3d31c821b2a332f5" category="cell">MLRun</block>
  <block id="1c1491d01d96c08951ae2ac55fadf443" category="cell">由 Iguazio 管理的，用于组装，执行和监控 ML/AI 管道。</block>
  <block id="a2580bd6e044f86f4e39be2f59ee91da" category="cell">Nutriio</block>
  <block id="2d753cbb7762fe25d15a2cda2ff84790" category="cell">与 Iguazio 集成的无服务器功能框架。也可作为由 Iguazio 管理的开源项目提供。</block>
  <block id="0bbee378f2697a1d0c184e76d2b206c6" category="cell">基于 Kubernetes 的框架，用于部署管道。这也是一个开源项目， Iguazio 为此做出了贡献。它与 Iguazio 集成，可提高安全性，并与基础架构的其余部分集成。</block>
  <block id="849efb47ec760eb7c3c6b5848e740c3b" category="cell">Docker 注册表作为服务在 Iguazio 平台中运行。您也可以更改此设置以连接到注册表。</block>
  <block id="a38f73277b7341a709cf0cb57ebc4434" category="cell">NetApp Cloud Volumes</block>
  <block id="7279bb663993b77e219b4ca813326d77" category="cell">通过在 AWS 上运行的 Cloud Volumes ，我们可以访问大量数据，并可以创建 Snapshot 副本来版本用于培训的数据集。</block>
  <block id="9953e13b783f3ad45d99187c955cb9f9" category="cell">Trident 是一个由 NetApp 管理的开源项目。它有助于与 Kubernetes 中的存储和计算资源集成。</block>
  <block id="5fa4506d691373039fd2834939e582b3" category="paragraph">我们使用多台笔记本电脑来构建 ML 管道。在将每台笔记本电脑整合到管道中之前，可以对其进行单独测试。我们将按照此演示应用程序的部署流程分别介绍每台笔记本电脑。</block>
  <block id="06a86c2506db8ef5fdac675c1352e3cf" category="paragraph">理想的结果是，通过管道根据数据的 Snapshot 副本训练模型，并部署模型进行推理。下图显示了已完成的 MLRun 管道的结构图。</block>
  <block id="1d79eb753e06f2122a118408a14d6c51" category="paragraph"><block ref="1d79eb753e06f2122a118408a14d6c51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51b666fe429f998144ea4f2ce818cd60" category="section-title">部署数据生成功能</block>
  <block id="034015442bf8bf34c0e7e8149d35dae6" category="paragraph">本节介绍如何使用 Nutrio 无服务器功能生成网络设备数据。此用例是从部署了管道并使用 Iguazio 服务监控和预测网络设备故障的 Iguazio 客户端改编而来的。</block>
  <block id="2d024dd4dc0601ff2e4d0b81fcaec60a" category="inline-link">Nutrio 网站</block>
  <block id="59009d367371847f2042c59338282f4b" category="paragraph">我们模拟了来自网络设备的数据。执行 Jupyter 笔记本 `data-generator.ipynb` 可创建一个每 10 分钟运行一次的无服务器功能，并使用新数据生成一个 Parquet 文件。要部署此功能，请运行此笔记本中的所有单元。请参见<block ref="a9d48e85369982160b96d90770d878d1" category="inline-link-rx"></block> 查看此笔记本中任何不熟悉的组件。</block>
  <block id="fa0c06ebcd647f13ce81472307615ee3" category="paragraph">生成函数时，将忽略包含以下注释的单元格。假设笔记本电脑中的每个单元都属于该功能的一部分。导入 Nuclio 模块以启用 ` %nuclio 幻影` 。</block>
  <block id="c2b253a6bc491b37027772dba5f0b4e7" category="paragraph">在函数规范中，我们定义了函数的执行环境，触发方式以及使用的资源。</block>
  <block id="95b0eb5f892f7b0bcb3ec7dbb9058c02" category="paragraph">初始化 `init_context` 函数时， Noclio 框架会调用该函数。</block>
  <block id="1aab9637db54631d95ec5901bfda0947" category="paragraph">在函数初始化时，将调用不在函数中的任何代码。调用该命令时，系统将执行处理程序功能。您可以更改处理程序的名称并在函数规范中指定它。</block>
  <block id="94be7a657ecb54ef7337030d9dd78b70" category="paragraph">您可以在部署之前从笔记本电脑测试此功能。</block>
  <block id="01237c05459839293bfcd5a3beb1364f" category="paragraph">该功能可以从笔记本电脑部署，也可以从 CI/CD 管道部署（修改此代码）。</block>
  <block id="c697561ec27606d29683f7fc5fb3846d" category="section-title">渠道笔记本电脑</block>
  <block id="83041c5547fb0ad965936febfc41508d" category="paragraph">这些笔记本电脑不能单独执行此设置。这只是对每台笔记本电脑的回顾。我们在管道中调用了这些命令。要分别执行这些操作，请查看 MLRun 文档，将其作为 Kubernetes 作业执行。</block>
  <block id="c16b208e4ffb938f4008373dea5fb4ec" category="section-title">Snap_CV.ipynb</block>
  <block id="eeb06194a969eee5616e56b449a99306" category="paragraph">此笔记本电脑在管道开始时处理 Cloud Volume Snapshot 副本。它会将卷的名称传递到管道环境。此笔记本会调用 shell 脚本来处理 Snapshot 副本。在管道中运行时，执行上下文包含可帮助查找执行所需的所有文件的变量。编写此代码时，开发人员不必担心执行此代码的容器中的文件位置。如后面所述，此应用程序会随其所有依赖项一起部署，而是通过管道参数的定义来提供执行上下文。</block>
  <block id="dc82b570ec10aa261c20bf4828af24c1" category="paragraph">创建的 Snapshot 副本位置将放置在 MLRun 上下文中，供管道中的步骤使用。</block>
  <block id="7f609b3599e86a8f1b83bde97709ba37" category="paragraph">接下来的三台笔记本电脑将并行运行。</block>
  <block id="d1839287f93e09936af234173d03d6b7" category="section-title">data-prep.ipynb</block>
  <block id="dbe6ca7c47e3dc8cbd3a4956e684b761" category="paragraph">必须将原始指标转换为功能，才能进行模型培训。此笔记本电脑可从 Snapshot 目录读取原始指标，并将模型培训的功能写入 NetApp 卷。</block>
  <block id="dab65fbdf0ed5ce626558d99e83c618f" category="paragraph">在管道环境中运行时，输入 `DATA_DIR` 包含 Snapshot 副本位置。</block>
  <block id="4636df8c7ba383c5f135c7ae8f2ef772" category="section-title">描述 .ipynb</block>
  <block id="43099d46867c7c0cc922fdd3e026d029" category="paragraph">为了直观显示传入指标，我们部署了一个管道步骤，该步骤可提供通过 Kubeflow 和 MLRun UI 提供的图解和图形。每个执行都有自己版本的此可视化工具。</block>
  <block id="7fd47125b80c0e6241052a47dcb41b98" category="section-title">deploy-feature-feature.ipynb</block>
  <block id="684eb641c7a322c328f8ea91cd482b0d" category="paragraph">我们会持续监控指标以查找异常。此笔记本电脑可创建一个无服务器功能，用于生成对传入指标运行预测所需的功能。此笔记本电脑将调用函数的创建。功能代码位于笔记本电脑 `data-prep.ipynb` 中。请注意，我们使用同一笔记本电脑作为管道中的一个步骤。</block>
  <block id="1c475141d16ada0e53ddb14047963024" category="section-title">训练 .ipynb</block>
  <block id="43b6984a9b2a7863061833c96be2b851" category="paragraph">创建功能后，我们将触发模型培训。此步骤的输出为要用于推理的模型。我们还会收集统计信息，以跟踪每个执行情况（实验）。</block>
  <block id="a6858cae929a8eed6e9c9d6cfa9befac" category="paragraph">例如，以下命令会将准确性得分输入到该实验的上下文中。此值在 Kubeflow 和 MLRun 中可见。</block>
  <block id="9d1126b5d7690c0eb46dd7713822680e" category="section-title">deploy-inftion-Function.ipynb</block>
  <block id="827ebf8bb3ee1798b5394ecd2a8bb3ae" category="paragraph">管道中的最后一步是将模型部署为无服务器功能，以实现持续推理。此笔记本电脑将调用在 `nuclio-inference - Function .ipynb` 中定义的无服务器功能的创建过程。</block>
  <block id="4d2c908b5247626d682903dc9527bd05" category="section-title">审核和构建管道</block>
  <block id="6c8673acfb6249793bed69954ca16a9b" category="paragraph">通过将所有笔记本电脑整合到一个管道中，可以持续运行实验，根据新指标重新评估模型的准确性。首先，打开 `pipeline.ipynb` 笔记本电脑。我们将详细介绍 NetApp 和 Iguazio 如何简化此 ML 管道的部署。</block>
  <block id="50d4decae4f0f08e83a1bd8342bd6ef1" category="paragraph">我们使用 MLRun 为管道的每个步骤提供上下文并处理资源分配。MLRun API 服务在 Iguazio 平台中运行，是与 Kubernetes 资源交互的点。每个开发人员都不能直接请求资源； API 负责处理这些请求并启用访问控制。</block>
  <block id="c7c5ccf69a87e301b134dcfdf46ab307" category="paragraph">此管道可以与 NetApp Cloud Volumes 和内部卷配合使用。我们构建此演示的目的是使用 Cloud Volumes ，但您可以在代码中看到在内部运行的选项。</block>
  <block id="ce16d064e13fffda0ff2a07c50276f33" category="paragraph">将 Jupyter 笔记本电脑转变为 Kubeflow 步骤所需的第一个操作是将代码转换为函数。功能具有运行该笔记本电脑所需的所有规格。向下滚动笔记本电脑时，您可以看到我们为管道中的每个步骤定义了一个函数。</block>
  <block id="8bbbd384e919f705f071525a96cdfaec" category="cell">属于笔记本电脑</block>
  <block id="5d75cd50687084d681964f5c6ee8a73a" category="cell">&lt;code_to_Function&gt; （ MLRun 模块的一部分）</block>
  <block id="eef456f018469b2d403742d05e33a5dd" category="cell">函数名称： project name 。用于组织所有项目项目项目。此信息会显示在 MLRun UI 中。好的。在这种情况下，是 Kubernetes 作业。这可以是 dask ， MPI ， spark8s 等。有关详细信息，请参见 MLRun 文档。文件笔记本的名称。此位置也可以是 Git （ HTTP ）中的一个位置。</block>
  <block id="d0161cbbc56081c803c919679b76b846" category="cell">我们在此步骤中使用的 Docker 映像的名称。我们先前使用 create-image.ipynb 笔记本创建了此版本。</block>
  <block id="28bb8862d962b462f621d9098de311cd" category="cell">volume_mounts 和 volumes</block>
  <block id="a6841da965bfb59838d367b9fdc30a8c" category="cell">有关在运行时挂载 NetApp Cloud Volume 的详细信息。</block>
  <block id="5d9261bc63dfeef8d26c807e36a9daa4" category="paragraph">我们还定义了步骤的参数。</block>
  <block id="fcd242cd0d87d4de3be34f843180bdb0" category="paragraph">在为所有步骤定义了函数之后，您可以构建管道。我们使用 `kfp` 模块来定义此定义。使用 MLRun 与自行构建之间的区别在于编码的简化和缩短。</block>
  <block id="f02b57d2fbd61d7629e76438ba68f7a1" category="paragraph">我们定义的函数将使用 MLRun 的 `as_step` 函数转换为步骤组件。</block>
  <block id="8859e75c5bfd3a8ea5a783296d71b795" category="section-title">Snapshot 步骤定义</block>
  <block id="dabb827ac33da3a8d8a2384874221aab" category="paragraph">启动 Snapshot 功能，输出并将 v3io 作为源进行挂载：</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">Parameters</block>
  <block id="422ac26927e8ad3d6b30617226e26c2a" category="cell">newtask</block>
  <block id="b954691c9a06ef7281bf4c836e7684f1" category="cell">newtask 是函数 run 的定义。</block>
  <block id="7871261404e7a8d93339696184b243b9" category="cell">（ MLRun 模块）</block>
  <block id="4522319a8fbbe0a85c82e604047dfe6c" category="cell">处理程序。要调用的 Python 函数的名称。我们在笔记本中使用了名称处理程序，但这不是必需的。参数。我们传递给执行的参数。在代码中，我们使用 context.get_param （‘parameter ｝ ）来获取值。</block>
  <block id="6cebb60f71d9de65143ade7a8388e27a" category="cell">as_step</block>
  <block id="070faabab806ce863279f5bd38452cc4" category="cell">NameKubeflow 管道步骤的名称。输出。这些值是步骤在完成时添加到词典中的值。查看 snap_CV.ipynb 笔记本电脑。mount_v3io （）。此操作将为执行管道的用户配置挂载 /User 的步骤。</block>
  <block id="a8aff967e1649a1c82ea607c881e8091" category="cell">输入</block>
  <block id="6f1ba99c8ee685047e0fa3c32349a01f" category="cell">您可以将上一步的输出传递到步骤。在这种情况下， snap.outputs"snapVolumeDetails" 是我们在快照步骤中创建的 Snapshot 副本的名称。</block>
  <block id="a399d9e54dd5dc35c6b455d995702175" category="cell">输出路径</block>
  <block id="026446ea82508e4c9f41609b3484b4cb" category="cell">一个位置，用于放置使用 MLRun 模块 log_tools. 生成的项目。</block>
  <block id="2fe8889e7fb9545ea383ff3c0451cabf" category="paragraph">您可以从上至下运行 `pipvip.ipynb` 。然后，您可以转到 Iguazio 信息板中的管道选项卡来监控进度，如 Iguazio 信息板管道选项卡中所示。</block>
  <block id="74dec5a93e3c1ccb06f26ebc6f9401fb" category="paragraph"><block ref="74dec5a93e3c1ccb06f26ebc6f9401fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f47db69a9e60b47a1c8f7800753f6b57" category="paragraph">由于我们在每次运行中都记录了训练步骤的准确性，因此我们在每个实验中都有一个准确性记录，如训练准确性记录所示。</block>
  <block id="5bb7a1a5b810ce843cd4d41a7137ce26" category="paragraph"><block ref="5bb7a1a5b810ce843cd4d41a7137ce26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9ebd260b4ed60a239b8228fe68b2dbc" category="paragraph">如果选择 Snapshot 步骤，则可以看到用于运行此实验的 Snapshot 副本的名称。</block>
  <block id="1d231b2e1da6122607105ce52f87a763" category="paragraph"><block ref="1d231b2e1da6122607105ce52f87a763" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc578a2d3b019d646da18c9172282dc" category="paragraph">所述步骤具有可视化项目，可用于浏览我们使用的指标。您可以展开以查看完整图，如下图所示。</block>
  <block id="ffb599ed438d33d337e7cca9a1fbaf07" category="paragraph"><block ref="ffb599ed438d33d337e7cca9a1fbaf07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89238f00748675db057567546f67c2c5" category="paragraph">此外， MLRun API 数据库还会跟踪按项目组织的每个运行的输入，输出和项目。下图显示了每个运行的输入，输出和项目示例。</block>
  <block id="a8baa83f88edfb0fceafeda75819cb5f" category="paragraph"><block ref="a8baa83f88edfb0fceafeda75819cb5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c6050fe85d7b5528bc8356c88eab725" category="paragraph">对于每个作业，我们会存储更多详细信息。</block>
  <block id="8683624a37c6626765321b5cc2f60954" category="paragraph"><block ref="8683624a37c6626765321b5cc2f60954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f02f72c9470e67a8b3c5f9054b0a32c" category="inline-link">MLRun GitHub 站点</block>
  <block id="01661b1e0825da7434573266df1672e0" category="paragraph">有关 MLRun 的信息比本文档中介绍的信息更多。可以将 AL 项目（包括步骤和功能的定义）保存到 API 数据库中，并进行版本控制，也可以单独调用或作为完整项目调用。此外，还可以保存项目并将其推送到 Git 以供日后使用。我们建议您在中了解更多信息<block ref="92ae596fd8e402850e22f59a73ed3a44" category="inline-link-rx"></block>。</block>
  <block id="10dedd24e41d2fa9b5a5e681dd5b4882" category="summary">此页面提供了了解 NetApp 如何推进 AI 项目的背景信息，包括有关容器， Kubernetes ， NetApp Trident 等的信息。</block>
  <block id="0b7e964d1176d21b9ba3eceec8ed95ac" category="doc">概念和组件</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">人工智能</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">AI 是一门计算机科学学科，其中计算机经过训练，可以模拟人类思维的认知功能。AI 开发人员培训计算机，以便以类似于甚至优于人类的方式学习和解决问题。深度学习和机器学习是 AI 的子领域。企业越来越多地采用 AI ， ML 和 DL 来满足其关键业务需求。以下是一些示例：</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">分析大量数据以挖掘以前未知的业务洞察力</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">使用自然语言处理直接与客户互动</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">自动化执行各种业务流程和功能</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">现代 AI 训练和推理工作负载需要大规模并行计算功能。因此， GPU 越来越多地用于执行 AI 操作，因为 GPU 的并行处理功能远远优于通用 CPU 。</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="section-title">容器</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">容器是在共享主机操作系统内核上运行的隔离用户空间实例。容器的采用率正在快速增长。容器可提供许多与虚拟机（ VM ）相同的应用程序沙盒优势。但是，由于虚拟机所依赖的虚拟机管理程序和子操作系统层已被消除，因此容器的重量要轻得多。下图展示了虚拟机与容器的可视化情况。</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Docker 网站</block>
  <block id="da28cd415837c7f3d1d6221ff490b84b" category="paragraph">此外，还可以通过容器直接将应用程序依赖关系，运行时间等内容高效地打包到应用程序中。最常用的容器打包格式是 Docker 容器。已采用 Docker 容器格式进行容器化的应用程序可以在可以运行 Docker 容器的任何计算机上执行。即使计算机上不存在应用程序的依赖关系，也是如此，因为所有依赖关系都打包在容器中。有关详细信息，请访问<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block>。</block>
  <block id="9c3d617029ed075512781527983e01e4" category="paragraph"><block ref="9c3d617029ed075512781527983e01e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Kubernetes 网站</block>
  <block id="7a1446916a360f9c8ae3b94a97ad8c86" category="paragraph">Kubernetes 是一款开源分布式容器编排平台，最初由 Google 设计，现在由 Cloud 原生计算基金会（ CNCF ）维护。Kubernetes 可以为容器化应用程序实现部署，管理和扩展功能的自动化。近年来， Kubernetes 已成为主导容器业务流程平台。虽然支持其他容器打包格式和运行时间，但 Kubernetes 最常用作 Docker 容器的业务流程系统。有关详细信息，请访问<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block>。</block>
  <block id="6ea70a0ecace7daa9dfbbc8ff3282de1" category="inline-link">Trident 网站</block>
  <block id="f9b736ec48694a34e744a1a0309602bd" category="paragraph">Trident 是一款由 NetApp 开发和维护的开源存储编排程序，可大大简化 Kubernetes 工作负载的永久性存储的创建，管理和使用。Trident 本身是 Kubernetes 本机应用程序，直接在 Kubernetes 集群中运行。借助 Trident ， Kubernetes 用户（开发人员，数据科学家， Kubernetes 管理员等）可以采用他们已熟悉的标准 Kubernetes 格式创建，管理永久性存储卷并与其交互。同时，他们还可以利用 NetApp 的高级数据管理功能以及由 NetApp 技术提供支持的数据网络结构。Trident 可将持久存储的复杂性抽象化，并使其易于使用。有关详细信息，请访问<block ref="ad5406ed69f3fe0de810f757310402c9" category="inline-link-rx"></block>。</block>
  <block id="47bbe104ad41e6af2ee0dba5dc76d74d" category="inline-link">DeepOps 网站</block>
  <block id="b1c5aef0d1e7ec0339ca5caa48c1b3e3" category="paragraph">DeepOps 是 NVIDIA 的一个开源项目，通过使用 Ansible ，可以根据最佳实践自动部署 GPU 服务器集群。DeepOps 采用模块化设计，可用于执行各种部署任务。在本文档及其所述的验证练习中， DeepOps 用于部署一个由 GPU 服务器辅助节点组成的 Kubernetes 集群。有关详细信息，请访问<block ref="640792bfd91bad987ba8fd5d776a2824" category="inline-link-rx"></block>。</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Kubeflow 网站</block>
  <block id="ea77b50ef31a778a66411b993d6cb7d1" category="paragraph">Kubeflow 是一款适用于 Kubernetes 的开源 AI 和 ML 工具包，最初由 Google 开发。通过 Kubeflow 项目，可以在 Kubernetes 上轻松，便携且可扩展地部署 AI 和 ML 工作流。Kubeflow 将 Kubernetes 的错综复杂之处抽象出来，让数据科学家能够专注于他们最了解的―数据科学。有关可视化效果，请参见下图。随着企业 IT 部门越来越多地在 Kubernetes 上实现标准化， Kubeflow 的吸引力也越来越大。有关详细信息，请访问<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block>。</block>
  <block id="a2b0a43dcae6386929654b652393e691" category="paragraph"><block ref="a2b0a43dcae6386929654b652393e691" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">KubeFlow 管道</block>
  <block id="384873a621d99250018cd7ce1768f8af" category="paragraph">Kubeflow 管道是 Kubeflow 的一个关键组件。Kubeflow 管道是一个平台和标准，用于定义和部署可移植且可扩展的 AI 和 ML 工作流。有关详细信息，请参见<block ref="6de5a235a0c43df48d05588e1b69b959" category="inline-link-rx"></block>。</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Jupyter 网站</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="section-title">Apache 气流</block>
  <block id="c01fb6f699235f8c5d36bdda9e155c77" category="paragraph">Apache Airflow 是一个开源工作流管理平台，支持对复杂的企业工作流进行编程创作，计划和监控。它通常用于自动执行 ETL 和数据管道工作流，但不限于这些类型的工作流。气流项目由 Airbnb 发起，但此后在业内备受欢迎，现在由 Apache 软件基金会赞助。气流采用 Python 编写，气流工作流通过 Python 脚本创建，气流是按照 " 配置即代码 " 原则设计的。 现在，许多企业级气流用户都在 Kubernetes 上运行 Airflow 。</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">定向循环图（ DAG ）</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">在气流模式下，工作流称为定向环比图（ DAG ）。DAG 由按顺序，并行或两者的组合执行的任务组成，具体取决于 DAG 定义。气流计划程序会根据 DAG 定义中指定的任务级别依赖关系对一组工作负载执行各个任务。DAG 是通过 Python 脚本定义和创建的。</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9.</block>
  <block id="0b83cba78e13ee67f3ada794b1e8edb8" category="paragraph">NetApp ONTAP 9 是 NetApp 推出的最新一代存储管理软件，可帮助像您这样的企业打造现代化的基础架构并过渡到云就绪数据中心。借助行业领先的数据管理功能，无论数据位于何处， ONTAP 都可以通过一组工具来管理和保护数据。您还可以将数据自由移动到任何需要的位置：边缘，核心或云。ONTAP 9 包含许多功能，可简化数据管理，加快和保护关键数据，并在混合云架构中打造适应未来需求的基础架构。</block>
  <block id="849f9e6e3176f7bb2abaf1dfdda6f4de" category="section-title">简化数据管理</block>
  <block id="5d0a72b50313f5f3615263a7d19ee676" category="paragraph">数据管理对于企业 IT 运营至关重要，这样您就可以为应用程序和数据集使用适当的资源。ONTAP 包括以下功能，可简化运营并降低总运营成本：</block>
  <block id="30490e1b1bd18c329c3b28df91914ffe" category="list-text">* 实时数据缩减和扩展的重复数据删除。 * 数据缩减可减少存储块中浪费的空间，重复数据删除可显著提高有效容量。</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">* 最低，最高和自适应服务质量（ QoS ）。 * 细粒度 QoS 控制有助于在高度共享的环境中保持关键应用程序的性能水平。</block>
  <block id="d9a5709ce7afa0856dd86539f75c8087" category="list-text">* ONTAP FabricPool 。 * 此功能可将冷数据自动分层到公有和私有云存储选项，包括 Amazon Web Services （ AWS ）， Azure 和 NetApp StorageGRID 基于对象的存储。</block>
  <block id="ddb2f8d78c57d5743fdee9e17ae053c9" category="section-title">加速和保护数据</block>
  <block id="4994fe58be1734616de0863809040200" category="paragraph">ONTAP 可提供卓越的性能和数据保护，并通过以下功能扩展这些功能：</block>
  <block id="b109ecc7b4570bf3dbb9f8d082595075" category="list-text">* 高性能和低延迟。 * ONTAP 以尽可能低的延迟提供最高的吞吐量。</block>
  <block id="9e184f7b8847a390232c0163d45ab461" category="list-text">* NetApp ONTAP FlexGroup 技术 * 。 FlexGroup 卷是一种高性能数据容器，可线性扩展到高达 20 PB 和 4000 亿个文件，从而提供一个可简化数据管理的命名空间。</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">* 数据保护。 * ONTAP 提供内置数据保护功能，并在所有平台之间进行通用管理。</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* NetApp 卷加密。 * ONTAP 提供原生卷级加密，并支持板载和外部密钥管理。</block>
  <block id="0950833529b7822458a242631cce3b3b" category="section-title">Future-Proof 基础架构</block>
  <block id="ba5b61620e18b71a8644dbc382c0c4f1" category="paragraph">ONTAP 9 可帮助您满足不断变化的苛刻业务需求：</block>
  <block id="d9d73747d25ab5e9c5de8f1f61c9ec7c" category="list-text">* 无缝扩展和无中断运行。 * ONTAP 支持向现有控制器和横向扩展集群无中断添加容量。您可以升级到 NVMe 和 32 Gb FC 等最新技术，而无需进行昂贵的数据迁移或中断。</block>
  <block id="512a65c054e8b5d06216e0eae55abedb" category="list-text">* 云连接。 * ONTAP 是云连接最广泛的存储管理软件之一，可在所有公有云中选择软件定义的存储（ ONTAP Select ）和云原生实例（ NetApp Cloud Volumes Service ）。</block>
  <block id="5ca60f373401802dfa44501cfa4f5cc7" category="list-text">* 与新兴应用程序集成。 * 通过使用支持现有企业级应用程序的相同基础架构， ONTAP 可为 OpenStack ， Hadoop 和 MongoDB 等下一代平台和应用程序提供企业级数据服务。</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">NetApp Snapshot 副本</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">NetApp Snapshot 副本是卷的只读时间点映像。该映像占用的存储空间极少，并且性能开销极低，因为它仅记录自创建上次 Snapshot 副本以来创建的文件所做的更改，如下图所示。</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Snapshot 副本的效率归功于核心 ONTAP 存储虚拟化技术—任意位置写入文件布局（ Write Anywhere File Layout ， WAFL ）。与数据库一样， WAFL 使用元数据指向磁盘上的实际数据块。但是，与数据库不同， WAFL 不会覆盖现有块。它会将更新后的数据写入新块并更改元数据。这是因为 ONTAP 在创建 Snapshot 副本时引用元数据，而不是复制数据块，因此 Snapshot 副本的效率非常高。这样做可以避免其他系统在查找要复制的块时花费寻道时间，并避免创建副本本身的成本。</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">您可以使用 Snapshot 副本恢复单个文件或 LUN ，或者还原卷的整个内容。ONTAP 会将 Snapshot 副本中的指针信息与磁盘上的数据进行比较，以重建缺少或损坏的对象，而不会造成停机或高昂的性能成本。</block>
  <block id="9787a3a5983c64cfaf3029a721aab4f0" category="paragraph"><block ref="9787a3a5983c64cfaf3029a721aab4f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">NetApp FlexClone 技术</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">NetApp FlexClone 技术会引用 Snapshot 元数据来创建卷的可写时间点副本。副本与其父级共享数据块，在将更改写入副本之前，除了元数据所需的存储外，不会占用任何其他存储，如下图所示。传统副本可能需要几分钟甚至几小时才能创建，而 FlexClone 软件可以让您几乎即时复制最大的数据集。因此，如果您需要相同数据集的多个副本（例如，开发工作空间）或数据集的临时副本（针对生产数据集测试应用程序），则这种情况是理想之选。</block>
  <block id="423c2edb645c178257ba9d79bd9ac684" category="paragraph"><block ref="423c2edb645c178257ba9d79bd9ac684" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">NetApp SnapMirror 数据复制技术</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">NetApp SnapMirror 软件是一款经济高效且易于使用的统一复制解决方案，可跨数据网络结构实现。它可以通过 LAN 或 WAN 高速复制数据。它可以为各种类型的应用程序提供高数据可用性和快速数据复制，包括虚拟和传统环境中的业务关键型应用程序。在将数据复制到一个或多个 NetApp 存储系统并持续更新二级数据时，您的数据将保持最新，并可随时使用。不需要外部复制服务器。有关利用 SnapMirror 技术的架构示例，请参见下图。</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">SnapMirror 软件通过仅通过网络发送更改的块来利用 NetApp ONTAP 的存储效率。SnapMirror 软件还可使用内置网络压缩来加快数据传输速度，并将网络带宽利用率降低多达 70% 。借助 SnapMirror 技术，您可以利用一个精简复制数据流创建一个存储库，同时维护活动镜像和先前的时间点副本，从而将网络流量减少多达 50% 。</block>
  <block id="423eee692f81241addaf586841d0c66a" category="paragraph"><block ref="423eee692f81241addaf586841d0c66a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="0e4fcaf78d0d4feda27a31ecb6944b58" category="paragraph">NetApp XCP 是一款基于客户端的软件，可用于任意到 NetApp 以及 NetApp 到 NetApp 的数据迁移和文件系统洞察。XCP 旨在通过利用所有可用系统资源来处理大容量数据集和高性能迁移来实现扩展和最大性能。XCP 可通过生成报告的选项帮助您全面了解文件系统。</block>
  <block id="9a3914e340e4b09762f8231f9fd0ddaa" category="paragraph">NetApp XCP 可通过一个软件包提供，该软件包支持 NFS 和 SMB 协议。XCP 包括一个适用于 NFS 数据集的 Linux 二进制文件和一个适用于 SMB 数据集的 Windows 可执行文件。</block>
  <block id="adc911d4d2f4e0008e765523cff39824" category="paragraph">NetApp XCP 文件分析是一款基于主机的软件，可检测文件共享，对文件系统运行扫描并提供用于文件分析的信息板。XCP 文件分析与 NetApp 和非 NetApp 系统兼容，并可在 Linux 或 Windows 主机上运行，以便为 NFS 和 SMB 导出的文件系统提供分析。</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroup 卷</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">培训数据集可以是一组可能包含数十亿个文件的集合。文件可以包括文本，音频，视频以及其他形式的非结构化数据，这些数据必须进行存储和处理才能并行读取。存储系统必须存储大量小文件，并且必须并行读取这些文件，以便执行顺序和随机 I/O</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">FlexGroup 卷是一个包含多个成分卷的命名空间，如下图所示。从存储管理员的角度来看， FlexGroup 卷是一个受管卷，其作用类似于 NetApp FlexVol 卷。FlexGroup 卷中的文件将分配给各个成员卷，并且不会在卷或节点之间进行条带化。它们支持以下功能：</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">FlexGroup 卷可为高元数据工作负载提供多 PB 的容量和可预测的低延迟。</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">它们在同一命名空间中最多支持 4000 亿个文件。</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">它们支持在 CPU ，节点，聚合和成分卷之间的 NAS 工作负载中执行并行操作 FlexVol 。</block>
  <block id="07e40bce6e02494c0af7b6a5f2aeaad8" category="paragraph"><block ref="07e40bce6e02494c0af7b6a5f2aeaad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28b9eb1a9ba550cf23239eb33610203e" category="doc">软件和硬件要求</block>
  <block id="dce011ea921230b4e3061bb70569c598" category="section-title">网络配置：</block>
  <block id="5c56d5a342310a4d1ead67adc85adcab" category="paragraph">以下是在云中设置的网络配置要求：</block>
  <block id="df97d4ea35e2febbb06b9bd1ba29b50e" category="list-text">Iguazio 集群和 NetApp Cloud Volumes 必须位于同一个虚拟私有云中。</block>
  <block id="a8f3c1a7fc956bcddef483bc8797e742" category="list-text">云管理器必须有权访问 Iguazio 应用程序节点上的端口 6443 。</block>
  <block id="0d1562d43d3c0d4c52eef4a841896eba" category="list-text">我们在本技术报告中使用了 Amazon Web Services 。但是，用户可以选择在任何云提供商中部署解决方案。为了便于在采用 NVIDIA DGX-1 的 ONTAP AI 中进行内部测试，我们使用了 Iguazio 托管的 DNS 服务。</block>
  <block id="820de5e74a90f4dbc17e37b78258c35b" category="paragraph">客户端必须能够访问动态创建的 DNS 域。如果需要，客户可以使用自己的 DNS 。</block>
  <block id="43ad77bf4f253415b4e90ea4aa41a2d7" category="paragraph">您可以在自己的集群中安装 Iguazio 内部部署。我们已使用 NVIDIA DGX-1 系统验证了 NetApp ONTAP AI 中的解决方案。下表列出了用于测试此解决方案的硬件。</block>
  <block id="7b6f2acc1b4489fd971965be635ea987" category="cell">NetApp AFF A800 系统</block>
  <block id="55552614d2dd18f2d6c40759f2de9e22" category="cell">1 个高可用性（ HA ）对，包括 2 个控制器和 48 个 NVMe SSD （ 3.8 TB 或更高）</block>
  <block id="413400218c4c262991ad8483b3be0a04" category="cell">Cisco Nexus 3232C 网络交换机</block>
  <block id="72f23e74ab545a9064f74aca4d904bf4" category="paragraph">下表列出了内部测试所需的软件组件：</block>
  <block id="751601035b4077a9c6f7280ab1d3369c" category="cell">4.4 — Ubuntu 18.04 LTS</block>
  <block id="bb3121464976ef0c6b6b2b81fc75f3c5" category="cell">19.03.5</block>
  <block id="2a820a07d05055e147221622557f34b9" category="cell">容器版本</block>
  <block id="6f3d0f773f6be20d70e6bbbafca93de9" category="cell">20.01-tF1-py2.</block>
  <block id="46b6cc5d90605df4689002387db99128" category="cell">机器学习框架</block>
  <block id="f060e908e90b13cff9447e18fbb6bb20" category="cell">TensorFlow 1.15.0</block>
  <block id="4ec1f03a0b910370451392d8af8cd05a" category="cell">Iguazio</block>
  <block id="80b1aaf85493db4117fca57135bec077" category="cell">版本 2.8+</block>
  <block id="20de768bd6142b858c4e99c64e19f37b" category="cell">ESX 服务器</block>
  <block id="f884cc5c56f9c9a8d4d61568ff64db9c" category="cell">6.5</block>
  <block id="95b4a53c1023a65c982b077b13be4b96" category="paragraph">此解决方案已通过 Iguazio 2.5 版和适用于 AWS 的 NetApp Cloud Volumes ONTAP 的全面测试。Iguazio 集群和 NetApp 软件均在 AWS 上运行。</block>
  <block id="efbef76fea5d52b17e66f66b7fbdb1be" category="cell">版本或类型</block>
  <block id="1f2c90c0f9931b94eab6d9d2d3a640c9" category="cell">应用程序节点</block>
  <block id="8f33b30dd333b320c87f038f61e17523" category="cell">m5.4xlarge</block>
  <block id="b8f3b98512c841c7f30ce704570ac0b6" category="cell">数据节点</block>
  <block id="ea93f0324aaeaa177497ea41b52cb9ff" category="cell">I3.4 x 大型</block>
  <block id="232abf87aa3028a990e94f6bb51fe8bd" category="summary">要在 Kubernetes 集群中执行单节点 AI 和 ML 作业，请从部署跳转主机执行此页面上的任务。</block>
  <block id="46300fa439cc237919f854816fc89fc2" category="doc">执行单节点 AI 工作负载</block>
  <block id="ebbcd572ece7625ba24f2c3ecda6d5b5" category="paragraph">要在 Kubernetes 集群中执行单节点 AI 和 ML 作业，请从部署跳转主机执行以下任务。借助 Trident ，您可以快速轻松地使可能包含数 PB 数据的数据卷可供 Kubernetes 工作负载访问。要使此类数据卷可从 Kubernetes Pod 中访问，只需在 Pod 定义中指定 PVC 即可。此步骤是 Kubernetes 本机操作；不需要 NetApp 专业知识。</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">本节假定您已将尝试在 Kubernetes 集群中执行的特定 AI 和 ML 工作负载容器化（采用 Docker 容器格式）。</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">ImageNet 网站</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">以下示例命令显示了如何为使用 ImageNet 数据集的 TensorFlow 基准工作负载创建 Kubernetes 作业。有关 ImageNet 数据集的详细信息，请参见<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block>。</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">此示例作业请求八个 GPU ，因此可以在具有八个或更多 GPU 的单个 GPU 工作节点上运行。此示例作业可以在集群中提交，其中包含八个或更多 GPU 的工作节点不存在或当前占用另一个工作负载。如果是，则此作业将保持待定状态，直到此类辅助节点变为可用为止。</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">此外，为了最大程度地提高存储带宽，包含所需训练数据的卷会在该作业创建的 POD 中挂载两次。此外，还会在 Pod 中挂载另一个卷。第二个卷将用于存储结果和指标。这些卷在作业定义中使用 PVC 的名称进行引用。有关 Kubernetes 作业的详细信息，请参见<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block>。</block>
  <block id="225e66547943a27f429558dce4e639e2" category="paragraph">在本示例作业创建的 Pod 中， `edium` 值为 `Memory` 的` emtyDir `m卷将挂载到 ` /dev/shm` 。Docker 容器运行时自动创建的 ` /dev/shm` 虚拟卷的默认大小有时可能不足以满足 TensorFlow 的需求。按以下示例所示挂载 `emptyDir` 卷可提供足够大的 ` /dev/shm` 虚拟卷。有关 `emptyDir` 卷的详细信息，请参见<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block>。</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">在此示例作业定义中指定的单个容器将获得 `securityContext &gt; privileged` 值 `true` 。此值表示容器在主机上具有有效的 root 访问权限。在这种情况下使用此标注是因为要执行的特定工作负载需要 root 访问权限。具体而言，工作负载执行的清除缓存操作需要 root 访问权限。是否需要此 `特权： true` 标注取决于您要执行的特定工作负载的要求。</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">确认您在步骤 1 中创建的作业正在正确运行。以下示例命令确认已按照作业定义中的指定为此作业创建了一个 POD ，并且此 POD 当前正在其中一个 GPU 工作节点上运行。</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">确认您在步骤 1 中创建的作业已成功完成。以下示例命令确认作业已成功完成。</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">* 可选： * 清理作业项目。以下示例命令显示了在步骤 1 中创建的作业对象的删除情况。</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">删除作业对象时， Kubernetes 会自动删除任何关联的 Pod 。</block>
  <block id="65f63f96295566cd4278775eef1b4c8c" category="doc">为要求较低的工作负载或交互式工作负载分配的 GPU 百分比</block>
  <block id="1b3d285072ee60a98cde2f66b6e47fde" category="paragraph">当研究人员和开发人员在开发，超参数调整或调试阶段使用其模型时，此类工作负载通常所需的计算资源更少。因此，配置百分比 GPU 和内存的效率更高，以便可以将同一 GPU 同时分配给其他工作负载。Run ： AI 的业务流程解决方案为 Kubernetes 上的容器化工作负载提供了一个百分比 GPU 共享系统。该系统支持运行 CUDA 程序的工作负载，尤其适用于推理和模型构建等轻型 AI 任务。部分 GPU 系统可以透明地为数据科学和 AI 工程团队提供在一个 GPU 上同时运行多个工作负载的能力。这样，企业就可以在同一硬件上运行更多的工作负载，例如计算机视觉，语音识别和自然语言处理，从而降低成本。</block>
  <block id="5db1fcd5bb529fa2475aaf893414d2e4" category="paragraph">Run ： AI 的百分比 GPU 系统可利用自身的内存和计算空间有效地创建虚拟化逻辑 GPU ，容器可以使用和访问这些 GPU ，就像它们是独立的处理器一样。这样，多个工作负载便可在同一 GPU 上的容器中并排运行，而不会相互干扰。解决方案是透明，简单且可移植的，不需要对容器本身进行更改。</block>
  <block id="71cdf780e37cc9571b5fcd0bf89958b1" category="paragraph">一个典型的使用情形可能会看到在同一个 GPU 上运行两到八个作业，这意味着您可以使用同一个硬件执行八倍的工作。</block>
  <block id="0a1f69603a47f75f701f92ad7d94e3c5" category="paragraph">对于下图中的作业 `frac05` 属于项目 `team-d` ，我们可以看到分配的 GPU 数量为 0.5 。这一点可通过 `nvidia-smi` 命令进一步验证，该命令显示容器可用的 GPU 内存为 16 ， 255 MB ： DGX-1 节点中每个 V100 GPU 32 GB 的一半。</block>
  <block id="e6d9743072cdc6867ea2980c7db7e7fd" category="paragraph"><block ref="e6d9743072cdc6867ea2980c7db7e7fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff9caff469d56a572a569942ca24c8b4" category="list-text">NVIDIA DGX 系统</block>
  <block id="b69073c22b4269568fd577ea090ce638" category="list-text">NVIDIA DGX-1 系统<block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="fe287c518b9b1345defadacdc6a9ecbf" category="list-text">NVIDIA V100 Tensor 核心 GPU<block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="d6a8716635a5681cde357a465953bc72" category="list-text">NVIDIA NGC<block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="11bdb18e1c5e7d1e4362c9d2f6956fc8" category="list-text">运行： AI 容器编排解决方案</block>
  <block id="5afc85c81e76f427a293dd861e0109a3" category="list-text">Run ： AI 产品简介<block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="9acfbb098f0d9b45b5897b44ae347ee9" category="list-text">运行： AI 安装文档<block ref="cb05a776556ca5a25aec417185ef6863" category="inline-link-rx"></block>
<block ref="b2e8533fae57aa9047d7731db51b6dfe" category="inline-link-rx"></block></block>
  <block id="b0d8a6d0eebdc42ac243c16f9137118d" category="list-text">在 Run ： AI 命令行界面中提交作业<block ref="97ec6c214f99d7e6a39194a167aeecc8" category="inline-link-rx"></block>
<block ref="d75350381b5fda5cc9c9a1ce34c24299" category="inline-link-rx"></block></block>
  <block id="9bd35f4f3f6faa9e9330c54fd2086967" category="list-text">在 Run ： AI 命令行界面中分配 GPU 分数<block ref="e343516de5fb56c6a0d652bcdfceaab7" category="inline-link-rx"></block></block>
  <block id="ddb27cb97146c8f5964eaf368feb4ce0" category="list-text">技术报告<block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="2273cd603e277bb35f96881a557b0608" category="list-text">简短演示<block ref="61e3673018126d9a106032d9ff691322" category="inline-link-rx"></block></block>
  <block id="45f26b752dfae88ec8c7def446162521" category="list-text">GitHub 存储库<block ref="f9a4909739179bedfa8ba1d225598979" category="inline-link-rx"></block></block>
  <block id="c36e36ff8b7edf8dd17781148ed57337" category="list-text">NetApp AFF A 系列产品规格<block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="ffc4c8e8bc10afc438d9c590f44e3b51" category="list-text">适用于全闪存 FAS 的 NetApp 闪存优势<block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="7843ce52c43038d88c2f54d85f3f764d" category="list-text">ONTAP 9 信息库<block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="5f1b8a708e16776ca4372c71dc377653" category="list-text">NetApp ONTAP FlexGroup Volumes 技术报告<block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="062d7e5979c653f33e03cb0aaeaec6e9" category="list-text">采用 DGX-1 的 ONTAP AI 和 Cisco 网络设计指南<block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="59086e50189644b7c19947dfa68f8395" category="list-text">《采用 DGX-1 的 ONTAP AI 和 Cisco 网络部署指南》<block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="062afad089226e62b53e77ba2af24574" category="list-text">采用 DGX-1 和 Mellanox 网络设计指南的 ONTAP AI<block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="e6b737f0513721f0a8024f538058333e" category="list-text">采用 DGX-2 的 ONTAP AI 设计指南<block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="1f9a7430deed674d394796eaea14138f" category="paragraph">本技术报告为拥有小型到大型数据科学 / 工程团队的客户提供了一些准则，可通过使用运行： AI 命令行界面和 NetApp ONTAP AI 上的系统信息板来优化 Kubernetes 集群和 GPU 的使用。此外，它还包括运行： AI 平台安装信息，测试场景以及适用于经验证的测试用例的详细命令。Run ： AI Orchestration 解决方案与 NetApp AI 控制平面相结合，可通过优化资源利用率提高开发人员的工作效率，从而加快创新速度。</block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="summary">本节介绍在 Kubernetes 集群中部署气流时必须完成的任务。</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Apache Airflow 部署</block>
  <block id="f23c532f744716d23270b963c3eca570" category="paragraph">NetApp 建议在 Kubernetes 顶部运行 Apache Airflow 。本节介绍在 Kubernetes 集群中部署气流时必须完成的任务。</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">可以在 Kubernetes 以外的平台上部署 Airflow 。在 Kubernetes 以外的平台上部署气流不在此解决方案的范围内。</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">您已有一个工作正常的 Kubernetes 集群。</block>
  <block id="e59b39fd5c122dde3747561247eb2888" category="list-text">您已按照《 NetApp Trident 部署和配置》一节中所述在 Kubernetes 集群中安装和配置 NetApp Trident 。</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">安装 Helm</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Airflow 可使用 Kubernetes 常用的软件包管理器 Helm 进行部署。在部署气流之前，必须在部署跳转主机上安装 Helm 。要在部署跳转主机上安装 Helm ，请按照<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> 在官方 Helm 文档中。</block>
  <block id="678c0949a1824bf54eba73ab0a2609d8" category="paragraph">在部署 Airflow 之前，您必须在 Kubernetes 集群中指定一个默认 StorageClass 。气流部署过程会尝试使用默认 StorageClass 配置新的永久性卷。如果未将任何 StorageClass 指定为默认 StorageClass ，则部署将失败。要在集群中指定默认 StorageClass ，请按照一节中所述的说明进行操作 <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>。如果已在集群中指定默认 StorageClass ，则可以跳过此步骤。</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">使用 Helm 部署气流</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">要使用 Helm 在 Kubernetes 集群中部署气流，请从部署跳转主机执行以下任务：</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">按照说明使用 Helm 部署气流<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> 用于 Artifact Hub 上的官方气流图表。下面的示例命令显示了如何使用 Helm 部署气流。根据您的环境和所需配置，根据需要修改，添加和 / 或删除 `custom- values.yaml` 文件中的值。</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">确认所有气流 Pod 均已启动且正在运行。所有 POD 可能需要几分钟的时间才能启动。</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">按照步骤 1 中使用 Helm 部署 Airflow 时控制台上印有的说明获取 Airflow Web 服务 URL 。</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">确认您可以访问 Airflow Web 服务。</block>
  <block id="6a8e19652a540e359304ba812d39ea8e" category="paragraph"><block ref="6a8e19652a540e359304ba812d39ea8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e60c4461b2b4dcf3aa8535e3aab780b3" category="paragraph"><block ref="e60c4461b2b4dcf3aa8535e3aab780b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4e7b8572218b2c9421122c7ab76be25" category="paragraph">NetApp 和 cnvrg.io 合作为客户提供了一个完整的数据管理解决方案，用于 ML 和 DL 软件开发。ONTAP AI 可为任何规模的运营提供高性能计算和存储，而 cnvrg.io 软件可简化数据科学工作流并提高资源利用率。</block>
  <block id="8537de5688b6b855ec8b5465eca4e8f6" category="list-text">NVIDIA DGX Station ， V100 GPU ， GPU Cloud</block>
  <block id="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link"><block ref="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link-rx"></block></block>
  <block id="432a0462f3a215c89d6067d01ac9fee8" category="list-text">NVIDIA DGX Station<block ref="00e84bc2760804fd15a292583676639b" category="inline-link-rx"></block></block>
  <block id="a8135dcfdfd9c1074b55895b8d51f9be" category="list-text">NVIDIA V100 Tensor 核心 GPU<block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="f3e44b157fa7ead37042e8a6f3b14071" category="list-text">NVIDIA NGC<block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="944c1fe2317541350506cecb6131b857" category="inline-link"><block ref="944c1fe2317541350506cecb6131b857" category="inline-link-rx"></block></block>
  <block id="d3ceb6166da1ada512f22bc7832ec047" category="list-text">NVIDIA JarVis<block ref="34ae4389dc7afcada801d63c08e322b9" category="inline-link-rx"></block></block>
  <block id="21ce987b6ba4d344f1427dc72d497669" category="inline-link"><block ref="21ce987b6ba4d344f1427dc72d497669" category="inline-link-rx"></block></block>
  <block id="7bf7a8db8c3809766aa2579c2eadf37d" category="list-text">NVIDIA JarVis Early Access<block ref="2daee9604c6a07f74e6776847d2ee61e" category="inline-link-rx"></block></block>
  <block id="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link"><block ref="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link-rx"></block></block>
  <block id="852c7bf0a8f3b30a5a001dbf642dbebe" category="list-text">NVIDIA Nemo<block ref="fa9e246f0ef36a285adacc70507ae974" category="inline-link-rx"></block></block>
  <block id="299a4717590cda2cfe1db321802b4995" category="inline-link"><block ref="299a4717590cda2cfe1db321802b4995" category="inline-link-rx"></block></block>
  <block id="dfc2ce4fd02d20052bebaa2e6b8cd029" category="list-text">开发人员指南<block ref="9940ba67713949ce4f2fc05d3a37bd8c" category="inline-link-rx"></block></block>
  <block id="5467c9d1c07a7d1786936650b3c2d52a" category="list-text">NetApp AFF A 系列产品规格<block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="6bb399f406fc5ac4150ad21c6aa05ab2" category="list-text">适用于全闪存 FAS 的 NetApp 闪存优势<block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="9415aef2732728cc097fbbc9ab96b2fe" category="list-text">ONTAP 9 信息库<block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="d106dc348953acc0500f03a25379282e" category="list-text">NetApp ONTAP FlexGroup Volumes 技术报告<block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="05dbc5885d3bec70d2317a4b51526d96" category="list-text">采用 DGX-1 的 ONTAP AI 和 Cisco 网络设计指南<block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="af5797305db370f4f59d77bf7c73160b" category="list-text">《采用 DGX-1 的 ONTAP AI 和 Cisco 网络部署指南》<block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="f2345b2674d3976c091d4af042c36a8f" category="inline-link"><block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="f63c45f352478237d0d0fe7c5a26d6bf" category="list-text">采用 DGX-1 和 Mellanox 网络设计指南的 ONTAP AI<block ref="459df3a4bfb1f89f6920196001257745" category="inline-link-rx"></block></block>
  <block id="b38db7c217c396412f601b87dfc58a8c" category="inline-link"><block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="da8009e462fd2ec5eeb41b4cf3721f7a" category="list-text">采用 DGX-2 的 ONTAP AI 设计指南<block ref="86d70269673ee41c37a2673f7d3655ce" category="inline-link-rx"></block></block>
  <block id="ca6d5ad374e3cf268dec341c0c398442" category="summary">在此架构中，重点关注 AI 或机器学习（ ML ）分布式车道检测训练流程中计算最密集的部分。</block>
  <block id="8cb13336dc020a2fb7bca9d4e940cc64" category="paragraph">在此架构中，重点关注 AI 或机器学习（ ML ）分布式车道检测训练流程中计算最密集的部分。车道检测是自动驾驶中最重要的任务之一，它有助于通过对车道标记进行定位来引导车辆。车道标记等静态组件可引导车辆以交互方式安全地在高速公路上驾驶。</block>
  <block id="0721542454dcaa77c97cd9c545d9063f" category="paragraph">基于卷积神经网络（ CNN ）的方法将场景理解和分段提升到了一个新的水平。虽然对于结构较长的对象以及可能被堵塞的区域（例如，极柱，车道上的阴影等）来说，这种方法并不能很好地发挥作用。空间对流神经网络（ SCNN ）将 CNN 概括为丰富的空间级别。它可以在同一层的神经元之间传播信息，从而最适合结构化对象，例如通道，极或带有 occlusi 的叉车。这种兼容性是因为空间信息可以得到增强，并且可以保持平稳性和连续性。</block>
  <block id="df38a65c87631c9530cc3a6832ea7a7d" category="paragraph">需要在系统中注入数千个场景图像，以便模型能够学习和区分数据集中的各个组件。这些图像包括天气，日间或夜间，多层公路以及其他交通状况。</block>
  <block id="f7759f002b4a60b5c837abb7f8936037" category="paragraph">对于培训，需要高质量和高数量的数据。单个 GPU 或多个 GPU 可能需要数天到数周才能完成培训。数据分布式培训可通过使用多个和多节点 GPU 来加快此过程。Horovod 就是这样一个框架，它可以提供分布式培训，但在 GPU 集群之间读取数据可能会成为一种障碍。Azure NetApp Files 提供超快，高吞吐量和持续低延迟，可提供横向扩展 / 纵向扩展功能，从而充分利用 GPU 的计算容量。我们的实验证实，集群中的所有 GPU 平均使用 96% 以上的 GPU 来使用 SCNN 进行通道检测训练。</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="section-title">目标受众</block>
  <block id="0ca450eccdc7141b5e85e9e691a7f16b" category="paragraph">数据科学在 IT 和业务领域整合了多个学科，因此我们的目标受众中包含多个角色：</block>
  <block id="8acb1f50d0ada4e1149c01a5aa15b9ce" category="list-text">数据科学家需要灵活地使用自己选择的工具和库。</block>
  <block id="d0ba3808090644db73caeb23fcc2b17c" category="list-text">数据工程师需要了解数据的流动方式及其所在位置。</block>
  <block id="22a8c99419dee54a28ed1e2355a6706b" category="list-text">自主驾驶用例专家。</block>
  <block id="18f66c4bad233033dabddf6ff1289eeb" category="list-text">云管理员和架构师设置和管理云（ Azure ）资源。</block>
  <block id="4c9b6067f04f945e9247ecd00c22e328" category="list-text">开发运营工程师需要使用工具将新的 AI/ML 应用程序集成到持续集成和持续部署（ CI/CD ）管道中。</block>
  <block id="53720cf6403ac6b8a2402cce66c79d4f" category="list-text">业务用户希望能够访问 AI/ML 应用程序。</block>
  <block id="68dcdc6243e54c14b4c41c129d574c43" category="paragraph">在本文档中，我们将介绍 Azure NetApp Files ， Run ： AI 和 Microsoft Azure 如何帮助这些角色为业务带来价值。</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="section-title">解决方案技术</block>
  <block id="8017303b9b2c96742151083f089fc51f" category="paragraph">本节介绍了在 Azure 云中全面运行的大规模分布式训练解决方案的通道检测用例的技术要求。下图概述了解决方案架构。</block>
  <block id="f17291da16ed3dd7b705548f16706120" category="paragraph">此解决方案中使用的元素包括：</block>
  <block id="f28c5620810ae2a6961a1811277a7ff8" category="list-text">Azure Kubernetes Service （ AKS ）</block>
  <block id="03023f4a63d3d8f8ff86ff8246f75b9a" category="list-text">采用 NVIDIA GPU 的 Azure 计算 SKU</block>
  <block id="ae5ba69294a1b9feb03e6dd75395092c" category="list-text">运行： AI</block>
  <block id="951370659c41a55ac9f80ff19c2f4b26" category="paragraph">中列出了指向此处提及的所有要素的链接 <block ref="c8b73068ae16e202922904f7ed452f8e" category="inline-link-macro-rx"></block> 部分。</block>
  <block id="00d9279819736707d2b224ec427a8aae" category="paragraph"><block ref="00d9279819736707d2b224ec427a8aae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6a2faff353ad4e74bf3ee92e5d8b9c6" category="section-title">云资源和服务要求</block>
  <block id="5b691a1a00c6c03be70e559f55ae4fef" category="paragraph">下表列出了实施解决方案所需的硬件组件。在任何解决方案实施中使用的云组件可能会因客户要求而异。</block>
  <block id="c8e2277ecfb1427838c488c217f99466" category="cell">云</block>
  <block id="5f3bc5eb45e6b472bf3345d1036945e9" category="cell">AK</block>
  <block id="55b8660903ebaaed924e945432fe269e" category="cell">至少三个系统节点和三个 GPU 工作节点</block>
  <block id="3580a6b3e7ba0d55af17daee07244cbd" category="cell">虚拟机（ VM ） SKU 系统节点</block>
  <block id="8f75b0af54b5e672a660f4f1f1557f18" category="cell">三个 Standard_DS2_v2</block>
  <block id="a6066b29e1c4603af2c5c46cf549f764" category="cell">VM SKU GPU 工作节点</block>
  <block id="6aa4bab72f83c0b68587ee208f2c9ab0" category="cell">三个 Standard_NC6s_v3</block>
  <block id="3468e131592d70a22139936f3fb21403" category="cell">4 TB 标准层</block>
  <block id="cb251883efe045266871b7dd15229644" category="cell">版本或其他信息</block>
  <block id="bb451ae1fa5a629a0307949d38a60e2d" category="cell">AK — Kubernetes 版本</block>
  <block id="f2d1dd8f39098da402272f7606fd2638" category="cell">1.18.14</block>
  <block id="13c5eaa211a3778d391d5c8f65b80234" category="cell">运行： AI 命令行界面</block>
  <block id="89633b9d6f401377b6ece0682b92530a" category="cell">v2.2.25</block>
  <block id="4b138e2d1492b1e550d42348c65cbf82" category="cell">运行： AI Orchestration Kubernetes Operator 版本</block>
  <block id="6db851ff24c4b893a85242e63bbea119" category="cell">1.0.109</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">Horovod</block>
  <block id="4a7724061c17f8cf5be61a8adf4c170f" category="cell">0.21.2.</block>
  <block id="44adee2c140fc723412bae93732e5993" category="cell">20.01.1</block>
  <block id="1a7fa7cc4c79d5163f691ff60e6fc34d" category="doc">运行： AI 信息板和视图</block>
  <block id="3473dab452c5446b1a01a923e9879461" category="paragraph">在 Kubernetes 集群上安装 Run ： AI 并正确配置容器后，您将看到以下信息板和视图<block ref="2af90fde6f4d8ae5947b005d1208e742" category="inline-link-rx"></block> 在浏览器中，如下图所示。</block>
  <block id="f977554b7762214959db36c20484c697" category="paragraph"><block ref="f977554b7762214959db36c20484c697" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dfd99441ce89d4be896e4fc9757f7d2" category="paragraph">集群中共有 16 个 GPU ，由两个 DGX-1 节点提供。您可以查看节点数，可用 GPU 总数，分配给工作负载的已分配 GPU ，正在运行的作业总数，待定作业以及闲置已分配 GPU 。右侧的条形图显示每个项目的 GPU ，其中总结了不同团队如何使用集群资源。中间是当前正在运行的作业列表，其中包含作业详细信息，包括作业名称，项目，用户，作业类型， 每个作业正在运行的节点，为此作业分配的 GPU 数量，作业的当前运行时间，作业进度百分比以及该作业的 GPU 利用率。请注意，集群利用率不足（ GPU 利用率为 23% ），因为一个团队只提交了三个正在运行的作业（`team-A` ）。</block>
  <block id="67545e2efac33412706ff883eff2e1c4" category="paragraph">在下一节中，我们将介绍如何在 " 项目 " 选项卡中创建多个团队，并为每个团队分配 GPU ，以便在每个集群有大量用户时最大限度地提高集群利用率并管理资源。这些测试场景模拟了在训练，推理和交互式工作负载之间共享内存和 GPU 资源的企业环境。</block>
  <block id="efbb4ade01a09771413f4c09880e800a" category="paragraph">在本节中，我们将扩展多个团队提交工作负载并超过其配额的情形。通过这种方式，我们将展示 Run ： AI 的公平性算法如何根据预设配额比率分配集群资源。</block>
  <block id="3bd5af2e3a75651c4b9c45d26400fbaa" category="paragraph">此测试场景的目标：</block>
  <block id="cc9e23eb4fe1626d97a5dfeab7cf0d25" category="list-text">显示多个团队请求超过其配额的 GPU 时的排队机制。</block>
  <block id="050060785f2852b203c9e82254f2946a" category="list-text">显示系统如何根据配额之间的比率在超过配额的多个组之间分配公平的集群份额，以便具有较大配额的组获得较大的备用容量份额。</block>
  <block id="9e06f625a31670e60f0a8a09917c3ba0" category="paragraph">结束时 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>，有两个工作负载排队：一个用于 `team-b` ，一个用于 `team-c` 。在本节中，我们将对其他工作负载进行排队。</block>
  <block id="286cda6cf9e9438a2cff2827773cfe7a" category="inline-link-macro">第 4.10 节的测试详细信息</block>
  <block id="0e7a9992269080ceaf2b90c188cbb861" category="paragraph">有关提交作业，使用的容器映像以及执行的命令序列等详细信息，请参见 <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>。</block>
  <block id="b1df8ade330dd8e3c0962d87a58c1ba9" category="paragraph">根据部分提交所有作业时 <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>系统信息板显示 `team-A` ， `team-b` 和 `team-c` 所有 GPU 都超过其预设配额。与预设的软配额（ 4 个）相比， `team-A` 占用的 GPU 更多，而 `team-b` 和 `team-c` 每个占用的 GPU 都比其软配额（ 2 个）多两个。分配的过度配额 GPU 的比率等于其预设配额的比率。这是因为系统使用预设配额作为优先级的参考，并在多个团队请求更多 GPU ，超过其配额时相应地进行配置。当企业数据科学团队积极参与 AI 模型的开发和生产时，这种自动负载平衡可以实现公平和优先级划分。</block>
  <block id="6effcb49094093af4699b050b9994a58" category="paragraph"><block ref="6effcb49094093af4699b050b9994a58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3be1869ca88e0b5881bc6d1da583426" category="list-text">系统开始将其他团队的工作负载取消队列。</block>
  <block id="d2325970b5cec6b47eb2c10267e3a599" category="list-text">除队顺序根据公平算法来确定，这样 `team-b` 和 `team-c` 会获得相同数量的超配额 GPU （因为它们具有类似的配额）， 而 `team-A` 获得的 GPU 数量是原来的两倍，因为他们的配额是 `team-b` 和 `team-c` 的两倍。</block>
  <block id="e2cc28c61aaa6ca7e38bd7ed9de398f1" category="list-text">所有分配都将自动完成。</block>
  <block id="c21d5f3e7c1336258c406bddcde6e0f8" category="paragraph">因此，系统应在以下状态下保持稳定：</block>
  <block id="8f2185cd998019e76038f11669cfbfb0" category="cell">已分配 GPU</block>
  <block id="3b55c08436be9e1008bb19488c139c88" category="cell">8/4.</block>
  <block id="f532ced5959572a93091758c821d7ff1" category="cell">超过配额的四个 GPU 。空队列。</block>
  <block id="b0713292a73176f9754bd528cecde2d1" category="cell">超过配额的两个 GPU 。一个工作负载已排队。</block>
  <block id="1f0189591d8d7dc1d3db367398fb49c5" category="cell">0/8</block>
  <block id="7c0de9de98eb6577a96694238e533915" category="cell">根本不使用 GPU ，没有已排队的工作负载。</block>
  <block id="948c32bf5f56f7dd6f3b2baab5f6d89d" category="paragraph">下图显示了各个部分的 Run ： AI Analytics 信息板中每个项目在一段时间内的 GPU 分配情况 <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>， <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>，和 <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>。图中的每一行表示在任何时间为给定数据科学团队配置的 GPU 数量。我们可以看到，系统会根据提交的工作负载动态分配 GPU 。这样，当集群中存在可用 GPU 时，团队可以超过配额，然后根据公平原则抢占作业，最后达到所有四个团队的稳定状态。</block>
  <block id="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="paragraph"><block ref="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c97b4929008c9f4091a8070f570ccd4" category="paragraph">我们使用行业标准基准工具 TensorFlow 基准测试对该系统的运行和性能进行了验证。ImageNet 数据集用于训练 RESNET-50 ，它是一种著名的用于图像分类的 Convolutional Neural Network （ CNN ） DL 模型。RESNET-50 可提供准确的训练结果，并缩短处理时间，从而使我们能够对存储产生足够的需求。</block>
  <block id="56dfbb2acffcc994819cbad5ec450617" category="paragraph">本节介绍与 ML 工作流中的数据缓存相关的概念和组件。</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="section-title">机器学习</block>
  <block id="d3f18dede1775f82df24232095090253" category="paragraph">对于全球许多企业和组织来说， ML 正迅速变得至关重要。因此， IT 和 DevOps 团队现在面临着标准化 ML 工作负载以及配置云，内部和混合计算资源的挑战，这些资源支持 ML 作业和管道所需的动态密集型工作流。</block>
  <block id="f71dfff263d05c18171dcf4b8c538ebf" category="section-title">基于容器的机器学习和 Kubernetes</block>
  <block id="002f314c3c41ffb741f8c91d2274af9a" category="paragraph">容器是在共享主机操作系统内核上运行的隔离用户空间实例。容器的采用率正在快速增长。容器可提供许多与虚拟机（ VM ）相同的应用程序沙盒优势。但是，由于虚拟机所依赖的虚拟机管理程序和子操作系统层已被消除，因此容器的重量要轻得多。</block>
  <block id="ce8bb3a31abf8bfcdcdacb34d96b010a" category="paragraph">此外，还可以通过容器直接将应用程序依赖关系，运行时间等内容高效地打包到应用程序中。最常用的容器打包格式是 Docker 容器。已采用 Docker 容器格式进行容器化的应用程序可以在可以运行 Docker 容器的任何计算机上执行。即使计算机上不存在应用程序的依赖关系，也是如此，因为所有依赖关系都打包在容器中。有关详细信息，请访问<block ref="5b5112034c22f544bc19c7a568afbfcb" category="inline-link-rx"></block>。</block>
  <block id="cfbe31a3e8ac3348240670510232ed8f" category="paragraph">Kubernetes 是一款广受欢迎的容器编排程序，可帮助数据科学家启动基于容器的灵活作业和管道。它还支持基础架构团队在一个受管云原生环境中管理和监控 ML 工作负载。有关详细信息，请访问<block ref="45556eaecf73275e38fa694031a104a3" category="inline-link-rx"></block>。</block>
  <block id="371ac536e4099ad82f6080b713ce9647" category="paragraph">cnvrg.io 是一款 AI 操作系统，可将企业管理，扩展和加速 AI 和数据科学开发的方式从研究转变为生产。代码优先平台由数据科学家为数据科学家构建，可灵活地在内部或云中运行。借助模型管理， MLOps 和持续的 ML 解决方案， cnvrg.io 为数据科学团队带来了一流的技术，因此他们可以减少在开发运营上花费的时间，专注于真正的魔力—算法。自使用 cnvrg.io 以来，各个行业的团队已获得更多生产模式，从而增加了业务价值。</block>
  <block id="ffb1d184fa3790eda48f1fc2d9c2f821" category="section-title">cnvrg.io 元数据计划程序</block>
  <block id="55fdc117823776b1ebb2170b4adfadf6" category="paragraph">cnvrg 。IO 具有一个独特的架构，允许 IT 和工程师将不同的计算资源连接到同一控制平面，并使 cnvrg-io 管理所有资源中的 ML 作业。这意味着它可以连接多个内部 Kubernetes 集群， VM 服务器和云帐户，并在所有资源上运行 ML 工作负载，如下图所示。</block>
  <block id="3c7fcf7e73eda18d7277b14914857f38" category="paragraph"><block ref="3c7fcf7e73eda18d7277b14914857f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cfff0196a077e92a8fe9326f97cb7fc5" category="section-title">cnvrg.io 数据缓存</block>
  <block id="ad693e5ee82f0e0486a136821d0a0779" category="paragraph">借助 cnvrg.io ，数据科学家可以利用其数据缓存技术定义热数据集和冷数据集版本。默认情况下，数据集存储在集中式对象存储数据库中。然后，数据科学家可以在选定计算资源上缓存特定数据版本，以节省下载时间，从而提高 ML 开发和工作效率。已缓存且在几天内未使用的数据集将自动从选定 NFS 中清除。只需单击一下鼠标即可执行缓存和清除操作；无需进行编码， IT 或 DevOps 工作。</block>
  <block id="42cf1b27f88752e1e98918981aa76e41" category="section-title">cnvrg.io 流和 ML 管道</block>
  <block id="1bc2ab6c98ec5b23a8a384861da1c6ca" category="paragraph">cnvrg.io 流是一种用于构建生产 ML 管道的工具。流中的每个组件都是一个脚本 / 代码，在选定计算上运行，并具有一个基本 Docker 映像。这种设计使数据科学家和工程师能够构建一个可同时在内部和云中运行的管道。cnvrg.io 可确保数据，参数和项目在不同组件之间移动。此外，还会对每个流进行监控和跟踪，以实现 100% 可重现的数据科学。</block>
  <block id="87cd11047488d3aa87eb2829eeb02305" category="section-title">cnvrg.io 核心</block>
  <block id="526c8ebff3057ce85f47160f32e15556" category="paragraph">cnvrg.io 核心是数据科学社区的一个免费平台，可帮助数据科学家更加专注于数据科学，而不是专注于开发运营。核心灵活的基础架构使数据科学家能够控制使用任何语言， AI 框架或计算环境，无论是内部环境还是云环境，以便他们能够做到最擅长的事情，构建算法。在任何 Kubernetes 集群上，只需一个命令即可轻松安装 cnvrg-io 核心。</block>
  <block id="f92894a2a2633c488de71d74ace474d7" category="paragraph">ONTAP AI 是一款适用于 ML 和深度学习（ DL ）工作负载的数据中心参考架构，它使用 NetApp AFF 存储系统和采用 Tesla V100 GPU 的 NVIDIA DGX 系统。ONTAP AI 基于基于 100 Gb 以太网的行业标准 NFS 文件协议，可为客户提供高性能 ML/DL 基础架构，该基础架构使用标准数据中心技术来降低实施和管理开销。通过使用标准化网络和协议， ONTAP AI 可以集成到混合云环境中，同时保持操作的一致性和精简性。作为一款经过预先验证的基础架构解决方案， ONTAP AI 可减少部署时间和风险，并显著降低管理开销，从而使客户能够更快地实现价值。</block>
  <block id="c2148c4c14a795b271b67f662900da4e" category="paragraph">Trident 是一款由 NetApp 开发和维护的开源存储编排程序，可大大简化 Kubernetes 工作负载的永久性存储的创建，管理和使用。Trident 本身是 Kubernetes 的本机应用程序，它直接在 Kubernetes 集群中运行。借助 Trident ， Kubernetes 用户（开发人员，数据科学家， Kubernetes 管理员等）可以采用他们已熟悉的标准 Kubernetes 格式创建，管理永久性存储卷并与其交互。同时，他们还可以利用 NetApp 的高级数据管理功能以及由 NetApp 技术提供支持的数据网络结构。Trident 可将持久存储的复杂性抽象化，并使其易于使用。有关详细信息，请访问<block ref="c98bfcab9052a99136f8752a5ac8ed0b" category="inline-link-rx"></block>。</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetApp StorageGRID</block>
  <block id="ecfefbd82f34239e668be7aac3762226" category="paragraph">NetApp StorageGRID 是一款软件定义的对象存储平台，旨在通过提供简单的类似于云的存储来满足这些需求，用户可以使用 S3 协议访问这些存储。StorageGRID 是一种横向扩展系统，旨在支持互联网连接站点之间的多个节点，而不管距离如何。借助 StorageGRID 的智能策略引擎，用户可以选择跨站点的纠删编码对象，以便在远程站点之间实现地理故障恢复能力或对象复制，从而最大程度地减少 WAN 访问延迟。StorageGRID 在此解决方案中提供了一个出色的私有云主对象存储数据湖。</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="section-title">NetApp Cloud Volumes ONTAP</block>
  <block id="c060a6548f860aa739b76c0178ac7c5c" category="paragraph">NetApp Cloud Volumes ONTAP 数据管理软件可以灵活地为用户数据提供控制，保护和效率，同时还可以灵活地使用 AWS ， Google 云平台和 Microsoft Azure 等公有云提供商。Cloud Volumes ONTAP 是一款基于 NetApp ONTAP 存储软件构建的云原生数据管理软件，可为用户提供出色的通用存储平台来满足其云数据需求。在云端和内部部署中使用相同的存储软件，可以为用户提供 Data Fabric 的价值，而无需培训 IT 员工掌握全新的数据管理方法。</block>
  <block id="e16f1943a363dfa46a958bd450c2ecf8" category="paragraph">对于对混合云部署模式感兴趣的客户， Cloud Volumes ONTAP 可以在大多数公有云中提供相同的功能和同类领先的性能，以便在任何环境中提供一致，无缝的用户体验。</block>
  <block id="d993b502abe38cef7c7256291e3ffa8e" category="paragraph">下表列出了实施解决方案所需的硬件组件。在任何特定解决方案实施中使用的硬件组件可能会因客户要求而异。</block>
  <block id="48fe531f68f98f9f6afcf79da6d3b1b3" category="doc">TR-4834 ：《 NetApp 和 Iguazio for MLRun 管道》</block>
  <block id="a0e5bba9c75f65c1d58c6a238316bd2b" category="paragraph">Rick Huang ， David Arnette ， NetApp Marcelo LitovskY ， Iguazio</block>
  <block id="dd9508a891c15cc4bb34f03dc870ab6c" category="paragraph">本文档介绍了使用 NetApp ONTAP AI ， NetApp AI 控制平台， NetApp Cloud Volumes 软件和 Iguazio 数据科学平台的 MLRun 管道的详细信息。我们使用的是 Nercio 无服务器功能， Kubernetes 永久性卷， NetApp Cloud Volumes ， NetApp Snapshot 副本， Grafana 信息板， 以及 Iguazio 平台上的其他服务，用于构建端到端数据管道，以模拟网络故障检测。我们集成了 Iguazio 和 NetApp 技术，可在内部和云端实现快速的模型部署，数据复制和生产监控功能。</block>
  <block id="d431a0ad3e0e99cf99c08fda529884bd" category="paragraph">数据科学家的工作重点应放在机器学习（ ML ）和人工智能（ AI ）模型的培训和调整上。但是，根据 Google 的研究，数据科学家花费了 ~80% 的时间来研究如何使其模型能够与企业应用程序结合使用并大规模运行，如以下描述 AI/ML 工作流中模型开发的图像所示。</block>
  <block id="f08b641e59dba6d999dc1bc2085bcd2c" category="paragraph"><block ref="f08b641e59dba6d999dc1bc2085bcd2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eec0363d19df86d30ecefc2e44170fa" category="paragraph">要管理端到端 AI/ML 项目，需要更广泛地了解企业组件。虽然 DevOps 已接管这些类型的组件的定义，集成和部署，但机器学习操作的目标是类似的流程，其中包括 AI/ML 项目。要了解端到端 AI/ML 管道在企业中涉及的内容，请参见以下所需组件列表：</block>
  <block id="ea2ef9b0d095bf991f4973633b485340" category="list-text">数据库</block>
  <block id="3b18b13f059019d19211f8a9f36f7e4e" category="list-text">文件系统</block>
  <block id="d6c823008f20bbfce5f39b30ec9fa918" category="list-text">持续集成和持续部署（ CI/CD ）管道</block>
  <block id="52681719ec1296447ae0e357c4781415" category="list-text">开发集成开发环境（ IDE ）</block>
  <block id="2fae32629d4ef4fc6341f1751b405e45" category="list-text">安全性</block>
  <block id="bd0992d43bb2d0ca676184502e14754e" category="list-text">数据访问策略</block>
  <block id="a9353b1bd1eeedb788a74090b5f8d0bc" category="list-text">数据科学工具集和库</block>
  <block id="2f0ff7df4fd6fa99bbf249af2ea4c3a5" category="paragraph">在本白皮书中，我们展示了 NetApp 与 Iguazio 之间的合作关系如何显著简化端到端 AI/ML 管道的开发。这种简化可以加快所有 AI/ML 应用程序的上市速度。</block>
  <block id="253411380ba9cde08bcfafbd516ad585" category="paragraph">数据科学领域涉及信息技术和业务领域的多个学科。</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">数据科学家需要灵活地使用自己选择的工具和库。</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">数据工程师需要了解数据的流动方式及其所在位置。</block>
  <block id="c12281f5ea7b17e370414efbf3f26c30" category="list-text">DevOps 工程师需要使用工具将新的 AI/ML 应用程序集成到其 CI/CD 管道中。</block>
  <block id="f1a4e0eca545ebe9e3c32f1fde407410" category="list-text">业务用户希望能够访问 AI/ML 应用程序。我们介绍了 NetApp 和 Iguazio 如何帮助这些角色为我们的平台带来业务价值。</block>
  <block id="00cc9e5c959e62a9132baca479060db3" category="paragraph">此解决方案遵循 AI/ML 应用程序的生命周期。我们从数据科学家的工作开始，定义准备数据以及训练和部署模型所需的不同步骤。接下来，我们将完成创建完整管道所需的工作，该管道能够跟踪项目，试验执行并部署到 Kubeflow 。为了完成整个周期，我们将管道与 NetApp Cloud Volumes 集成，以启用数据版本控制，如下图所示。</block>
  <block id="ddd4a11ec23c52d3f0831809bc4d7c8f" category="paragraph"><block ref="ddd4a11ec23c52d3f0831809bc4d7c8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0de039e647bc53dcce6e7bceb8605cbf" category="paragraph">各行各业各种规模的企业和组织都在转向人工智能（ AI ），机器学习（ ML ）和深度学习（ DL ），以解决实际问题，提供创新产品和服务，并在竞争日益激烈的市场中占据优势。随着企业越来越多地使用 AI ， ML 和 DL ，他们面临着许多挑战，包括工作负载可扩展性和数据可用性。可以通过使用 NetApp AI 控制平台解决方案来应对这些挑战。</block>
  <block id="cae02473f4798da0fdd40f4f598b1d96" category="paragraph">通过此解决方案，您可以快速克隆数据命名空间。此外，您还可以定义和实施 AI ， ML 和 DL 培训工作流，这些工作流可近乎即时地创建数据和模型基线，以实现可追溯性和版本控制。使用此解决方案，您可以跟踪每个模型训练返回到模型经过训练和 / 或验证的确切数据集。最后，借助此解决方案，您可以快速配置 Jupyter 笔记本电脑工作空间，以访问海量数据集。</block>
  <block id="696dba9a093d4ac7b67234745dd57835" category="paragraph">由于此解决方案面向数据科学家和数据工程师，因此只需极少的 NetApp 或 NetApp ONTAP 专业知识即可。借助此解决方案，可以使用简单熟悉的工具和界面来执行数据管理功能。此外，此解决方案还利用完全开源和免费的组件。因此，如果您的环境中已有 NetApp 存储，则可以立即实施此解决方案。如果您要测试此解决方案的驱动器，但尚未安装 NetApp 存储，请访问<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>，您可以随时使用基于云的 NetApp 存储解决方案启动和运行。</block>
  <block id="3a607d0e3fa64fd7558e11352f751dd0" category="summary">NetApp AI 控制平面解决方案不依赖于此特定硬件。</block>
  <block id="976cf3edd8adeff2e75cd7a9dd0dae21" category="paragraph">NetApp AI 控制平面解决方案不依赖于此特定硬件。解决方案与 Trident 支持的任何 NetApp 物理存储设备，软件定义的实例或云服务兼容。例如， NetApp AFF 存储系统， Azure NetApp Files ， NetApp Cloud Volumes Service ， NetApp ONTAP Select 软件定义的存储实例或 NetApp Cloud Volumes ONTAP 实例。此外，只要 Kubernetes 和 NetApp Trident 支持所使用的 Kubernetes 版本，即可在任何 Kubernetes 集群上实施解决方案。有关 Kubeflow 支持的 Kubernetes 版本列表，请参见<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>。有关 Trident 支持的 Kubernetes 版本列表，请参见<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。有关用于验证解决方案的环境的详细信息，请参见下表。</block>
  <block id="2e4fd4a404800f52299c132a3403dc72" category="cell">基础架构组件</block>
  <block id="64d354dc5879cf570ce7b4ef676e75bd" category="cell">操作系统</block>
  <block id="4152ac69f367cb5f64dfbc247dd41db0" category="cell">部署跳转主机</block>
  <block id="583a65df9db4119165f5ea0abaa50281" category="cell">虚拟机</block>
  <block id="204dd0a482d284a7fb87c908f713f9bd" category="cell">Ubuntu 20.04.2 LTS</block>
  <block id="f341fd2fe180518e152be2d6fb4ec20b" category="cell">Kubernetes 主节点</block>
  <block id="a89c263b82f7c7f61c9b6c93080f8425" category="cell">Kubernetes 工作节点</block>
  <block id="76a7e6383604f84ace970ce86ba76a9f" category="cell">Kubernetes GPU 工作节点</block>
  <block id="f89b34b046a8d6e3137c95861fa3cf8a" category="cell">NVIDIA DGX-1 （裸机）</block>
  <block id="eba551f3f972830c55b1c9bef15b5f26" category="cell">NVIDIA DGX OS 4.0.5 （基于 Ubuntu 18.04.2 LTS ）</block>
  <block id="0911ffdbb76c891f964e39a07eb6b697" category="cell">1 个 HA 对</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="cell">NetApp AFF A220</block>
  <block id="d1d73cf191d1afbd40e85644467cae8b" category="cell">NetApp ONTAP 9.7 P6</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">软件组件</block>
  <block id="47354877541923135499c38a6606138a" category="cell">2.0.1</block>
  <block id="9ba69bd971d430b368ce3f0286c8e77c" category="cell">Apache 气流 Helm 图表</block>
  <block id="ecfa741d55b7b1a85bd61a2307877c8c" category="cell">8.0.8</block>
  <block id="fd99a7ef225418315b041ad631a5674c" category="cell">19.03.12</block>
  <block id="56765472680401499c79732468ba4340" category="cell">1.2</block>
  <block id="48d02190984e4f8526f99f9cd9550e08" category="cell">1.18.9</block>
  <block id="d58d49f83f534f5d71b20750bb7927c7" category="cell">21.01.2</block>
  <block id="7a04e1f765218bcbfc633ef331b312b8" category="inline-link-macro">61898cdfda</block>
  <block id="7855beff2fafbce2cf0df4d67f8dfed7" category="cell">提交时主分支的 Trident 部署功能 <block ref="686ead03155c78694e1a59db0970fc1a" category="inline-link-macro-rx"></block>；从 21.03 版开始提供所有其他功能</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">支持</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">请联系 NetApp</block>
  <block id="a1773dfa99aa26853e90886d55e0d05a" category="paragraph">NetApp 不为 Apache Airflow ， Docker ， Kubeflow ， Kubernetes 或 NVIDIA DeepOps 提供企业级支持。如果您对具有与 NetApp AI 控制平台解决方案类似的功能的完全受支持的解决方案感兴趣， <block ref="103a4ac9affe57bb7edb7796bfdeb684" category="inline-link-macro-rx"></block> 关于 NetApp 与合作伙伴共同提供的完全受支持的 AI/ML 解决方案。</block>
  <block id="3cfbc3bac23f6bb9e7ebdc6deefeaf1d" category="paragraph">由 NetApp 和 NVIDIA 开发并验证的 NetApp ONTAP AI 架构由 NVIDIA DGX 系统和 NetApp 云连接存储系统提供支持。此参考架构为 IT 组织提供了以下优势：</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">为各种性能和成本点提供了一系列存储选项</block>
  <block id="6fa0f6cc1d5d12069641e73217a17be2" category="paragraph">NetApp ONTAP AI 将 DGX 系统和 NetApp AFF A800 存储系统与一流的网络紧密集成在一起。NetApp ONTAP AI 和 DGX 系统消除了设计复杂性和猜测性工作，从而简化了 AI 部署。客户可以从小规模入手，无中断地扩展系统，同时智能地管理从边缘到核心再到云再到云的数据。</block>
  <block id="bdc094a519f73076386a8bf2948832a6" category="paragraph">NetApp AI 控制平台是一个全堆栈 AI ， ML 和深度学习（ DL ）数据和实验管理解决方案，适用于数据科学家和数据工程师。随着企业越来越多地使用 AI ，他们面临着许多挑战，包括工作负载可扩展性和数据可用性。NetApp AI 控制平台可通过多种功能来应对这些挑战，例如像 Git repo一样 快速克隆数据命名空间，以及定义和实施 AI 培训工作流，这些工作流可以近乎即时地创建数据和模型基线，以实现可追溯性和版本控制。借助 NetApp AI 控制平台，您可以在站点和区域之间无缝复制数据，并快速配置 Jupyter 笔记本工作空间，以便访问海量数据集。</block>
  <block id="22101b8498dea1c2e2e35bd4868847a4" category="paragraph">运行： AI 为 AI 基础架构构建了全球首款业务流程和虚拟化平台。通过将工作负载从底层硬件中抽象出来， Run ： AI 可创建一个可动态配置的 GPU 资源共享池，从而高效地编排 AI 工作负载并优化 GPU 的使用。数据科学家可以无缝地使用大量 GPU 功能来改进和加快研究速度，同时 IT 团队可以对资源配置，队列和利用率保持集中的跨站点控制和实时可见性。Run ： AI 平台基于 Kubernetes 构建，可与现有 IT 和数据科学工作流轻松集成。</block>
  <block id="ae00256db8d45ecdaf9c364a96821417" category="paragraph">Run ： AI 平台具有以下优势：</block>
  <block id="d472807c15e94ef6053e95521ff7e838" category="list-text">* 加快创新速度。 * 通过将 Run ： AI 资源池，队列和优先级划分机制与 NetApp 存储系统结合使用，研究人员可以从基础架构管理的麻烦中消除，并可以专注于数据科学。运行： AI 和 NetApp 客户可以根据需要运行任意数量的工作负载，而不会出现计算或数据管道瓶颈，从而提高工作效率。</block>
  <block id="2707d068deb9b46967615c70c806e0d8" category="list-text">* 提高团队工作效率。 * 运行： AI 公平算法可确保所有用户和团队都能获得公平的资源份额。可以预设优先级项目的策略，该平台支持将资源从一个用户或团队动态分配给另一个用户或团队，从而帮助用户及时访问所需的 GPU 资源。</block>
  <block id="faa5854c7e84507b88cba1c0ec1a9aaf" category="list-text">* 提高了 GPU 利用率。 * 运行： AI 计划程序使用户能够轻松地使用百分比 GPU ，整数 GPU 和多个 GPU 节点在 Kubernetes 上进行分布式培训。这样， AI 工作负载就可以根据您的需求运行，而不是根据容量运行。数据科学团队可以在同一基础架构上运行更多 AI 实验。</block>
  <block id="9abac747d764180a5fe55920e00e887d" category="section-title">客户价值</block>
  <block id="45ce76bfe721ca13d37ca15fdbebd391" category="paragraph">作者衷心感谢我们尊敬的 NVIDIA 同事：达维德 · 奥诺弗罗， Alex Qi ， Sicong Ji ， Marty Jain 和 Robert Sohigian 为本白皮书所做的贡献。作者还想感谢 NetApp 团队的主要成员所做的贡献： Santosh Rao ， David Arnette ， Michael Oglesby ， Brent Davis ， Andy Sayare ， Erik Minder 和 Mike McNamara 。</block>
  <block id="81fbc4247f2c3a990b090cef6b9ebe03" category="paragraph">我们衷心感谢所有这些人士，他们提供了洞察力和专业知识，为本白皮书的编写提供了极大的帮助。</block>
  <block id="25edd21a28cb2fca00ab6f30e47c6d79" category="paragraph">要运行示例推理请求，请完成以下步骤：</block>
  <block id="cb11a85322b32a7615367d2523718b49" category="list-text">获取客户端容器 /Pod 的 Shell 。</block>
  <block id="b489ec265fd981ff7aa78a7721bd3101" category="list-text">运行示例推理请求。</block>
  <block id="15c5e1ffe753f0365f39e7b508ce5ae0" category="paragraph"><block ref="15c5e1ffe753f0365f39e7b508ce5ae0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5bf2ae3a2d0d1dd1e0740744c9ebb1b" category="paragraph">此推理请求调用用于图像识别的 `resnet50_netdef` 模型。其他客户端也可以通过类似的方法并调用相应的模型来同时发送推理请求。</block>
  <block id="21f937997adb0cac073e2458491f2c2f" category="list-text">按照上的说明下载 NVIDIA DeepOps<block ref="a94c3c17b923443c927cfa8fe7a2482a" category="inline-link-rx"></block> 在 NVIDIA DeepOps GitHub 站点上。</block>
  <block id="76ada3ea43b0e44772967793fe69b1bd" category="inline-link">《 Kubernetes 部署指南》</block>
  <block id="03628142cdc704dd6ffe5d7d13573999" category="list-text">按照上的说明在集群中部署 Kubernetes<block ref="cdf0a6d71dcbe898357c0e37010d30de" category="inline-link-rx"></block> 在 NVIDIA DeepOps GitHub 站点上。</block>
  <block id="2dfe8bb84d94f23030d91e315d7899bc" category="admonition">要使 DeepOps Kubernetes 部署正常工作，所有 Kubernetes 主节点和工作节点上必须存在相同的用户。</block>
  <block id="c6fff1434177c1b95244b5300314f730" category="paragraph">如果部署失败，请在 `deepops/config/group_vars/K8s-cluster.yml` 中将 `kubectl_localhost` 的值更改为 false ，然后重复步骤 2 。`Copy kubectl binary to Ansible host` 任务仅在 `kubectl_localhost` 值为 true 时执行，它依赖于 Fetch Ansible 模块，该模块存在已知的内存使用问题。这些内存使用问题有时可能会使任务发生原因失败。如果任务因内存问题描述而失败，则部署操作的其余部分将无法成功完成。</block>
  <block id="24e1fa4c913dcdc975e022f921d4d603" category="paragraph">如果在将 `kubectl_localhost` 的值更改为 `false` 后部署成功完成，则必须手动将 `kubectl 二进制文件` 从 Kubernetes 主节点复制到部署跳转主机。您可以通过直接在特定主节点上运行 `which kubectl` 命令来查找 `kubectl 二进制文件` 在该节点上的位置。</block>
  <block id="d7cd7846436814deb26b0df06d7a4b2a" category="summary">要在 Kubernetes 集群中执行同步多节点 AI 和 ML 作业，请在部署跳转主机上执行此页面上列出的任务。通过此过程，您可以利用存储在 NetApp 卷上的数据，并使用单个工作节点所能提供的 GPU 。</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">执行同步分布式 AI 工作负载</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">要在 Kubernetes 集群中执行同步多节点 AI 和 ML 作业，请在部署跳转主机上执行以下任务。通过此过程，您可以利用存储在 NetApp 卷上的数据，并使用单个工作节点所能提供的 GPU 。有关同步分布式 AI 作业的描述，请参见下图。</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">与异步分布式作业相比，同步分布式作业有助于提高性能和训练准确性。本文档不会讨论同步作业与异步作业的利弊。</block>
  <block id="262523fcbe6eb0ec96ea58299e58f65c" category="paragraph"><block ref="262523fcbe6eb0ec96ea58299e58f65c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a9af10e4883efa64de927027b5b0ffa" category="list-text">以下示例命令显示了创建一名员工参与同步分布式执行本节中示例中在单个节点上执行的同一 TensorFlow 基准测试作业的过程 <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>。在此特定示例中，仅部署一个员工，因为此作业会在两个员工节点上执行。</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">此示例员工部署请求八个 GPU ，因此可以在一个 GPU 工作节点上运行，该节点具有八个或更多 GPU 。如果您的 GPU 工作节点具有八个以上的 GPU ，则为了最大限度地提高性能，您可能需要增加此数量，使其等于您的工作节点所具有的 GPU 数量。有关 Kubernetes 部署的详细信息，请参见<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block>。</block>
  <block id="bfe89db11adc9a38165e670f3062d398" category="paragraph">在此示例中创建了 Kubernetes 部署，因为此特定容器化员工永远不会自行完成。因此，使用 Kubernetes 作业构造来部署它毫无意义。如果员工的设计或编写是为了自己完成，则可以使用此作业构建来部署员工。</block>
  <block id="05bdf5435b916b7b205f448788324f2b" category="paragraph">在此示例部署规范中指定的 Pod 的值为 `hostNetwork` 值 `true` 。此值表示 Pod 使用主机工作节点的网络堆栈，而不是 Kubernetes 通常为每个 Pod 创建的虚拟网络堆栈。在这种情况下使用此标注是因为特定工作负载依靠 Open MPI ， NCCL 和 Horovod 以同步分布式方式执行工作负载。因此，它需要访问主机网络堆栈。有关 Open MPI ， NCCL 和 Horovod 的讨论不在本文档的讨论范围之内。是否需要此 `hostNetwork ： true` 标注取决于要执行的特定工作负载的要求。有关 `hostNetwork` 字段的详细信息，请参见<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block>。</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">确认您在第 1 步中创建的员工部署已成功启动。以下示例命令确认已为部署创建了一个辅助 POD ，如部署定义所示，并且此 POD 当前正在其中一个 GPU 辅助节点上运行。</block>
  <block id="3ba975f6a7389af18602f0e938bcc37b" category="list-text">为启动，参与并跟踪同步多节点作业执行的主节点创建 Kubernetes 作业。以下示例命令创建一个主节点，用于启动，参与和跟踪在一节中的示例中对单个节点执行的相同 TensorFlow 基准测试作业的同步分布式执行 <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>。</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">此示例主作业请求八个 GPU ，因此可以在具有八个或更多 GPU 的单个 GPU 工作节点上运行。如果您的 GPU 工作节点具有八个以上的 GPU ，则为了最大限度地提高性能，您可能需要增加此数量，使其等于您的工作节点所具有的 GPU 数量。</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">在本示例作业定义中指定的主 Pod 的值为 `hostNetwork` 值为 `true` ，就像在步骤 1 中为工作 Pod 提供了 `hostNetwork` 值 `true` 一样。有关为何需要此值的详细信息，请参见第 1 步。</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">确认您在步骤 3 中创建的主作业正在正确运行。以下示例命令确认已为作业创建了一个主 Pod ，如作业定义所示，并且此 Pod 当前正在其中一个 GPU 工作节点上运行。您还应看到，您最初在步骤 1 中看到的辅助 POD 仍在运行，并且主节点和辅助节点正在不同的节点上运行。</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">确认您在步骤 3 中创建的主作业已成功完成。以下示例命令确认作业已成功完成。</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">如果您不再需要此员工部署，请将其删除。以下示例命令显示了删除在步骤 1 中创建的工作部署对象的过程。</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">删除 worker 部署对象时， Kubernetes 会自动删除任何关联的 worker Pod 。</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">* 可选： * 清理主作业项目。以下示例命令显示了删除在步骤 3 中创建的主作业对象的过程。</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">删除主作业对象时， Kubernetes 会自动删除任何关联的主 Pod 。</block>
  <block id="46b8f9361fae73f13467cd1aaff186ba" category="summary">记录 NetApp 解决方案资料的最新变更</block>
  <block id="679ce0aa9d3d54bfddd37e1b78b802de" category="doc">NetApp 解决方案变更日志</block>
  <block id="aceacf14369d872e8cb00f62613f52c6" category="paragraph">NetApp 解决方案资料的最新变更。首先列出最新的更改。</block>
  <block id="fcf140abed196b8eba71c45f21312bce" category="cell">NetApp 解决方案</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="cell">Oracle 数据库</block>
  <block id="4549cdf15178a5f0535be7f0f86cdb4d" category="cell">企业数据库</block>
  <block id="b0ac6120dada9135114784db22a59940" category="cell">现代数据分析</block>
  <block id="408649df4ac74ae19e47eef7d060c5cb" category="cell">解决方案自动化</block>
  <block id="14c4dbb7c61081eee1c499c4cf138c96" category="inline-link-macro">FlexPod 数据中心上的 Oracle 19c RAC 数据库，采用 Cisco UCS 和基于 FC 的 NetApp AFF A800</block>
  <block id="e9dcec3e531a3cec5ee733f23baab91d" category="inline-link-macro">在 NFS 上自动部署适用于 ONTAP 的 Oracle 19c</block>
  <block id="760b7d532df381143dc946fd59bf0b62" category="inline-link-macro">Azure NetApp Files 上的 SQL Server</block>
  <block id="d4c96dcd516adf0c5bde093b0b7b7255" category="summary">此页面介绍了在 NetApp ONTAP 存储上部署 Oracle19c 的自动化方法。</block>
  <block id="cb59b87e00d11222bfd9159d0d23836f" category="doc">入门</block>
  <block id="def8ebf26c2dec5f6af5a00893fae037" category="paragraph">此解决方案可以在 AWX/Tower 环境中运行，也可以通过命令行界面在 Ansible 控制主机上运行。</block>
  <block id="008ba800d97cb969def651e93f0d93fb" category="section-title">AWX/ 塔式</block>
  <block id="a481f1841043d60245f18522a86731b1" category="paragraph">对于 AWX/Tower 环境，系统将引导您创建 ONTAP 集群管理和 Oracle 服务器（ IP 和主机名）清单，创建凭据，配置从 NetApp Automation Github 提取 Ansible 代码的项目以及启动自动化的作业模板。</block>
  <block id="5055de7b9d28f88e537f99f34959c80c" category="list-text">填写特定于您的环境的变量，然后将其复制并粘贴到作业模板中的额外 VAR 字段中。</block>
  <block id="d116f375db402ba471f519c0a4df15dc" category="list-text">将额外的变量添加到作业模板后，您可以启动自动化。</block>
  <block id="8ca0a52cf9938328875e0a8803ae71dd" category="list-text">通过为 ontap_config ， linux_config 和 oracle_config 指定标记，作业模板将分三个阶段运行。</block>
  <block id="da3d0d670ace8a327170aa25ee29f272" category="section-title">通过 Ansible 控制主机执行 CLI</block>
  <block id="28e934ddab7714830f8afe8d3b641dc9" category="list-text">配置 Ansible 控制主机后，您可以克隆 Ansible Automation 存储库。</block>
  <block id="f667be8dac02593d217a02ac5bfb18de" category="list-text">使用 ONTAP 集群管理的 IP 和 / 或主机名以及 Oracle 服务器的管理 IP 编辑 hosts 文件。</block>
  <block id="95bd15e6b4a109de659c54c331c06284" category="list-text">填写特定于您的环境的变量，然后将其复制并粘贴到 `vars.yml` 文件中。</block>
  <block id="ca548be3e5f238d32286d43dc4c89f7b" category="list-text">每个 Oracle 主机都有一个可变文件，该文件由其主机名标识，其中包含主机专用变量。</block>
  <block id="87192ebbcab92216d25fd694a282971d" category="list-text">完成所有可变文件后，您可以通过为 `ontap_config` ， `linux_config` 和 `oracle_config` 指定标记来分三个阶段运行此攻略手册。</block>
  <block id="5a2ebfb8baa378cfcfcba58bbb1380c2" category="section-title">要求</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">environment</block>
  <block id="9d5cfca4ad04b54536e5ad15210f7dc2" category="cell">* 可逆环境 *</block>
  <block id="eebc1357e7d1e88ed4e4908d5ae86c0b" category="cell">AWX/Tower 或 Linux 主机作为 Ansible 控制主机</block>
  <block id="3f0733e14ebf265f0abf4b32371043ac" category="cell">Ansible v.10 及更高版本</block>
  <block id="3c91a74236fab100f024452f6df13b5e" category="cell">Python 3.</block>
  <block id="215b38d177939de20bbb7b7913ce32c1" category="cell">Python 库— netapp-lib — xmltodict — jMespath</block>
  <block id="d911b17f4f4cdcca62a04ad77aa9403d" category="cell">* ONTAP *</block>
  <block id="0a928fe81d89083ed303ea3d9f1af8c9" category="cell">ONTAP 版本 9.3 - 9.7</block>
  <block id="10aadda84b1b1da26c3757dfdb59379d" category="cell">两个数据聚合</block>
  <block id="9f998f9668ffe69c62d78760d1c531f0" category="cell">已创建 NFS VLAN 和 ifgrp</block>
  <block id="ba5f343281b90f0408008806c66bce86" category="cell">* Oracle 服务器 *</block>
  <block id="6f1de5f0d7966ebf5f8d255fe28ebffe" category="cell">RHEL 7/8</block>
  <block id="aa596da3b79631d86c0d35e1c4b03aac" category="cell">Oracle Linux 7/8</block>
  <block id="814e8f57514db6134b6ffcd7a4ce20a6" category="cell">NFS ，公有和可选管理的网络接口</block>
  <block id="515f291f3ecc550c5d13cf31fadba91d" category="cell">Oracle 服务器上的 Oracle 安装文件</block>
  <block id="ae9205dab0c26cca7762be5149a93923" category="section-title">自动化详细信息</block>
  <block id="ba0676e7ae183e2c0bbd54261818154f" category="paragraph">此自动化部署采用一本 Ansible 攻略手册设计，该攻略手册包含三个不同的角色。这些角色适用于 ONTAP ， Linux 和 Oracle 配置。下表介绍了正在自动执行的任务。</block>
  <block id="9bb642814808cd0cab510ddfb9e5969c" category="cell">* ontap_config*</block>
  <block id="c0563eda0fb9d63778efe04a13a5d744" category="cell">预检查 ONTAP 环境</block>
  <block id="79b814c8267c6b7822e78ab4624db8e0" category="cell">为 Oracle 创建基于 NFS 的 SVM</block>
  <block id="0c981d6164da0d8e69cdb199966316b0" category="cell">创建导出策略</block>
  <block id="99179ac01bbb0236fc540871377c55c4" category="cell">为 Oracle 创建卷</block>
  <block id="db738705829d97db1e287ad8ea9e5400" category="cell">创建 NFS LIF</block>
  <block id="089c4c184b079d771501d8ceb0f3bb05" category="cell">* Linux 配置 *</block>
  <block id="3ea572544d30a39d236496578f980d13" category="cell">创建挂载点并挂载 NFS 卷</block>
  <block id="db6c0f994cc39fbf66d58eea6c627e6a" category="cell">验证 NFS 挂载</block>
  <block id="6a882e7966e7869ab1d2112a0b1c0074" category="cell">特定于操作系统的配置</block>
  <block id="6e6d41d1398fafd8809de20e831c9ce3" category="cell">创建 Oracle 目录</block>
  <block id="6f965a5d44e1653dac9825f465f71c84" category="cell">配置页面</block>
  <block id="be577868fe0712b7bbb6d5cb5eae613c" category="cell">禁用 SELinux 和防火墙守护进程</block>
  <block id="bb6f16330211bf24baa83db38b11e4a9" category="cell">启用并启动 chronyd 服务</block>
  <block id="e9e5cefa281d2c696aac82ef9c756f51" category="cell">增加文件描述符硬限制</block>
  <block id="a4acc779f882208c081f943aedfeab5c" category="cell">创建 pam 会话文件</block>
  <block id="d03021f9e02b9fa9ebac591ad4bfea08" category="cell">* ORACLE_CONFIG *</block>
  <block id="5e706781d4bf141c80e249a244179235" category="cell">Oracle 软件安装</block>
  <block id="1a98fce6d77de1126bf3cb8247747621" category="cell">创建 Oracle 侦听器</block>
  <block id="841df7bfbef212936073c6d261d4dba9" category="cell">创建 Oracle 数据库</block>
  <block id="845a6e024025bb13aafdc167511e5e7d" category="cell">Oracle 环境配置</block>
  <block id="666113957f940ba4319b4f0d9c3e86c0" category="cell">保存 PDB 状态</block>
  <block id="264bca6ddd5a16346460d9c21e8f926d" category="cell">启用实例归档模式</block>
  <block id="620ca5ae835411d2031ca0fdbbbe61a1" category="cell">启用 DNFS 客户端</block>
  <block id="4d7e6c9b84f6f86cf4817262ad424eeb" category="cell">在操作系统重新启动之间启用数据库自动启动和关闭</block>
  <block id="bf60025632dd0c4a2cf35e8b33e80619" category="section-title">默认参数</block>
  <block id="ebda2606845855cc07ce0ce15ecf8a00" category="paragraph">为了简化自动化，我们已使用默认值预设了许多必需的 Oracle 部署参数。通常，无需更改大多数部署的默认参数。更高级的用户可以谨慎地更改默认参数。默认参数位于每个角色文件夹的默认目录下。</block>
  <block id="452eff11ca6d680a279a3e81b8dc8974" category="section-title">部署说明</block>
  <block id="1cf7ad9cd74067dd3f4aee3c1690ea32" category="paragraph">开始之前，请下载以下 Oracle 安装和修补程序文件，并将其放置在 ` /tmp/archive` 目录中，以便每个要部署的数据库服务器上的所有用户都能进行读取，写入和执行访问。自动化任务会在该特定目录中查找命名的安装文件，以便进行 Oracle 安装和配置。</block>
  <block id="19adadc497199e16f07f9744d43b2899" category="paragraph">您应按照 Github 存储库中的说明读取许可证信息。访问，下载，安装或使用此存储库中的内容即表示您同意所规定的许可证条款 <block ref="07d15b3b85718d883b437fb3739e59a7" category="inline-link-macro-rx"></block>。</block>
  <block id="87d624bc8a7f555a711e7214ee002eec" category="paragraph">请注意，在生成和 / 或共享任何派生作品时，此存储库中的内容存在一定的限制。请务必阅读的条款 <block ref="49480c711afcff6aca610d8294731030" category="inline-link-macro-rx"></block> 在使用内容之前。如果您不同意所有条款，请勿访问，下载或使用此存储库中的内容。</block>
  <block id="5abe869dd828ac1e4527f07db79841a8" category="inline-link-macro">此处可查看 AWX/ 塔式部署的详细步骤</block>
  <block id="c3bcf861ccc9247a7c0a9b4749747e4e" category="inline-link-macro">此处用于命令行界面部署</block>
  <block id="f867ea86471dd6849f2c840cf13d1536" category="paragraph">准备就绪后，单击 <block ref="0ecf76284fbf596cdd030af085c16a3b" category="inline-link-macro-rx"></block> 或 <block ref="42cd9508ebf775e8df0efba80be76af7" category="inline-link-macro-rx"></block>。</block>
  <block id="9b64a6dfae1f3fa326b750c2790c79fe" category="summary">本节介绍如何在使用 Azure NetApp Files SMB 卷的 AOAG 配置中实时部署 SQL 数据库资产。</block>
  <block id="5ca1071c67ab704b04ed27747f213551" category="doc">实时，高级别的参考设计</block>
  <block id="bb0357d1c0b3b8ebd31a43c9b30f3745" category="list-text">节点数： 4</block>
  <block id="7f4f30d96e1d0a820a6962ad6ac994ee" category="list-text">数据库数量： 21</block>
  <block id="f28735e3e5e57049aa575b3f0ec83c61" category="list-text">可用性组数： 4</block>
  <block id="96fb94ba9fad0b4452c212b21df61eab" category="list-text">备份保留： 7 天</block>
  <block id="a8d1485807d36562316fb8b2254bca57" category="list-text">备份归档： 365 天</block>
  <block id="4afa49afd4ebc3638f3e000d65825370" category="admonition">在具有 Azure NetApp Files 共享的 Azure 虚拟机上使用 SQL Server 部署 FCI 可提供一个具有单个数据副本的经济高效模式。如果文件路径与二级副本不同，则此解决方案可以防止出现添加文件操作问题。</block>
  <block id="ab030ea777250278c4f110a497eeef88" category="paragraph"><block ref="ab030ea777250278c4f110a497eeef88" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4822d9597460a9166778308da312709c" category="paragraph">下图显示了 AOAG 中分布在各个节点上的数据库。</block>
  <block id="af316199cc8e77dcbb6fb560cbc4c44c" category="paragraph"><block ref="af316199cc8e77dcbb6fb560cbc4c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">数据布局</block>
  <block id="35c33dd0c5565dbdba04dc2b313d7a2e" category="paragraph">用户数据库文件（ .mdf ）和用户数据库事务日志文件（ .ldf ）以及 tempdb 存储在同一个卷上。服务级别为 " 超 " 。</block>
  <block id="9b7d6479a15395afefc6d7f9e38a4f17" category="paragraph">此配置由四个节点和四个 AGS 组成。所有 21 个数据库（动态 AX ， SharePoint ， RDS 连接代理和索引服务的一部分）都存储在 Azure NetApp Files 卷上。数据库在 AOAG 节点之间进行平衡，以便有效地使用节点上的资源。WSFC 中添加了四个 D32 v3 实例，该实例参与了 AOAG 配置。这四个节点在 Azure 虚拟网络中进行配置，不会从内部迁移。</block>
  <block id="fcbd19b726fdd6160dfe2ab43f285a55" category="paragraph">* 注： *</block>
  <block id="09a10f0ab048cde1d7b704392ba05d9a" category="list-text">如果日志需要更高的性能和吞吐量，具体取决于应用程序的性质以及执行的查询，则可以将数据库文件置于高级服务级别，并将日志存储在超服务级别。</block>
  <block id="51368a236b969e288242f0b0b615cf74" category="list-text">如果 tempdb 文件已放置在 Azure NetApp Files 上，则 Azure NetApp Files 卷应与用户数据库文件分隔开。下面是在 AOAG 中分发数据库文件的示例。</block>
  <block id="2e66f3d288799e6f4235b883bb2f693c" category="list-text">为了保留基于 Snapshot 副本的数据保护的优势， NetApp 建议不要将数据和日志数据组合到同一个卷中。</block>
  <block id="1452bcdb4aeb229a2c2e503f9bbba753" category="list-text">如果二级数据库的文件路径与相应主数据库的路径不同，则对主副本执行的添加文件操作可能会在二级数据库上失败。如果主节点和二级节点上的共享路径不同（由于计算机帐户不同），则可能会发生这种情况。此故障可能会暂停二级数据库的发生原因。如果无法预测增长或性能模式，并且计划稍后添加文件，则使用 Azure NetApp Files 的 SQL Server 故障转移集群是可接受的解决方案。对于大多数部署， Azure NetApp Files 均可满足性能要求。</block>
  <block id="19f59b74448f6a27519db281a44e4b12" category="section-title">migration</block>
  <block id="cd6b4503e07d15cebc0842bb8da7b765" category="paragraph">可以通过多种方法将内部 SQL Server 用户数据库迁移到 Azure 虚拟机中的 SQL Server 。迁移可以联机或脱机。选择的选项取决于组织内定义的 SQL Server 版本，业务要求和 SLA 。为了最大限度地减少数据库迁移过程中的停机时间， NetApp 建议使用 AlwaysOn 选项或事务复制选项。如果无法使用这些方法，您可以手动迁移数据库。</block>
  <block id="2d4221f1ee93c102ca047daac1fba4a7" category="paragraph">在计算机之间移动数据库时，最简单且经过最彻底测试的方法是备份和还原。通常，您可以先从数据库备份开始，然后再将数据库备份副本复制到 Azure 中。然后，您可以还原数据库。为了获得最佳数据传输性能，请使用压缩的备份文件将数据库文件迁移到 Azure 虚拟机。本文档中引用的高级设计采用 Azure 文件同步 Azure 文件存储的备份方法，然后还原到 Azure NetApp Files 。</block>
  <block id="623f8382f97ee8df2d7af54439833812" category="admonition">Azure Migrate 可用于发现，评估和迁移 SQL Server 工作负载。</block>
  <block id="fbc25f1c70f1a9c133715cac6d66b21b" category="paragraph">要执行迁移，请完成以下高级步骤：</block>
  <block id="d807caa187d2fea33bab50ed1e1c79bb" category="list-text">根据您的要求设置连接。</block>
  <block id="59f59f1aebe4fc18ab054480b3a1098a" category="list-text">将完整数据库备份到内部文件共享位置。</block>
  <block id="4891d727582d5df766ee6737fe7fb761" category="list-text">使用 Azure 文件同步将备份文件复制到 Azure 文件共享。</block>
  <block id="135899cc34886eb6ce9baf7211d4adb5" category="list-text">使用所需版本的 SQL Server 配置 VM 。</block>
  <block id="fbef0b11b7ee9e0d709d3d1c6efbd4d4" category="list-text">在命令提示符处使用 `copy` 命令将备份文件复制到虚拟机。</block>
  <block id="b9786aca69df61c5165147929b4ced89" category="list-text">将完整数据库还原到 Azure 虚拟机上的 SQL Server 。</block>
  <block id="e937691d64dcb1188cbbcbcd83d87d2f" category="admonition">要还原 21 个数据库，大约需要 9 小时。此方法是针对此情形的。但是，可以根据您的情况和要求使用下面列出的其他迁移技术。</block>
  <block id="2b9d85faa379ef985ae3851810db1403" category="paragraph">用于将数据从内部 SQL Server 移动到 Azure NetApp Files 的其他迁移选项包括：</block>
  <block id="90248308f9c24bd3bf817ee129838603" category="list-text">断开数据和日志文件，将其复制到 Azure Blob 存储，然后将其附加到 Azure 虚拟机中的 SQL Server ，并使用从 URL 挂载的 ANF 文件共享。</block>
  <block id="82ce70205698ed956d1fce48af1360c0" category="inline-link">添加 Azure 副本向导</block>
  <block id="e5e07f1ff84f0082089e4fec71ed43a4" category="list-text">如果您使用的是内部部署的始终可用性组，请使用<block ref="aea558e3371e9956f5e03828309464a0" category="inline-link-rx"></block> 在 Azure 中创建副本，然后执行故障转移。</block>
  <block id="eedc53c13a9992999dba36bda1b62255" category="inline-link">事务复制</block>
  <block id="47a43d904457c52da2918f290a0ae5cb" category="list-text">使用 SQL Server<block ref="21bf5f41b40b598aae9dd55aa9dcb960" category="inline-link-rx"></block> 要将 Azure SQL Server 实例配置为订阅者，请禁用复制并将用户指向 Azure 数据库实例。</block>
  <block id="bf4614882fd1000329cfcb76f98f6c17" category="list-text">使用 Windows 导入 / 导出服务运送硬盘。</block>
  <block id="be062cdcabbb3055334e8f19b4bdf378" category="section-title">备份和恢复</block>
  <block id="b855582b6472c4fbe2a5f606191e66d6" category="paragraph">备份和恢复是任何 SQL Server 部署的一个重要方面。必须具有适当的安全网，以便与 AOAG 等高可用性解决方案结合使用，从各种数据故障和丢失情形中快速恢复。可以使用 SQL Server 数据库静默工具， Azure 备份（流式）或任何第三方备份工具（例如 Commvault ）对数据库执行应用程序一致的备份，</block>
  <block id="3896e1102f68b0bc974f324bb134f6e6" category="inline-link">SCSQLAPI 工具</block>
  <block id="e372173044ccba12657b2e3dbff1879b" category="paragraph">借助 Azure NetApp Files Snapshot 技术，您可以轻松创建用户数据库的时间点（ PIT ）副本，而不会影响性能或网络利用率。通过此技术，您还可以使用还原卷功能将 Snapshot 副本还原到新卷，或者将受影响的卷快速还原到创建 Snapshot 副本时的状态。与 Azure 备份提供的流式备份不同， Azure NetApp Files 快照过程非常快速高效，可以进行多个每日备份。如果在给定日期内可以创建多个 Snapshot 副本，则 RPO 和 RTO 时间可以显著缩短。要添加应用程序一致性，以便在创建 Snapshot 副本之前数据完好无损并正确地转储到磁盘，请使用 SQL Server 数据库暂停工具 <block ref="b800e9e09a17fc5b41967404ec8e47ac" category="inline-link-rx"></block>；访问此链接需要 NetApp SSO 登录凭据）。此工具可从 PowerShell 中执行，此工具会暂停 SQL Server 数据库，进而生成应用程序一致的存储 Snapshot 副本进行备份。</block>
  <block id="04666a337d02195d17089298f5773f4c" category="paragraph">* 注： *</block>
  <block id="a4d5ac6087b7ce119cfe6b7ad4d77ee5" category="list-text">SCSQLAPI 工具仅支持 2016 和 2017 版本的 SQL Server 。</block>
  <block id="fdcb10d4c2db07cf930247a4f9898ec5" category="list-text">SCSQLAPI 工具一次只能使用一个数据库。</block>
  <block id="2f65ae42dc3aa8b735406a2d56ceb6fb" category="list-text">通过将文件放置在单独的 Azure NetApp Files 卷上，将其与每个数据库隔离。</block>
  <block id="879351e17b2cd6d740ac0974e9ff8a5a" category="inline-link">Azure 备份</block>
  <block id="794b24c8957eec03a1402459d32f6810" category="paragraph">由于 SCSQL API 的巨大限制，<block ref="10a72c6743c3c6714e03b5537ec15603" category="inline-link-rx"></block> 用于数据保护，以满足 SLA 要求。它可以为 Azure 虚拟机和 Azure NetApp Files 中运行的 SQL Server 提供基于流的备份。Azure Backup 支持 15 分钟的 RPO ，并可频繁进行日志备份和长达一秒的 PIT 恢复。</block>
  <block id="423e555c5ec3885f2bb5d9d2d6627f63" category="section-title">监控</block>
  <block id="fe58430a0bb00057a08eed382c5d82b2" category="paragraph">Azure NetApp Files 与 Azure 监控器集成，可提供时间序列数据，并提供有关已分配存储，实际存储使用情况，卷 IOPS ，吞吐量，磁盘读取字节 / 秒的指标。 磁盘写入字节 / 秒，磁盘读取 / 秒和磁盘写入 / 秒以及相关延迟。此数据可用于确定警报瓶颈，并执行运行状况检查，以验证 SQL Server 部署是否在最佳配置下运行。</block>
  <block id="48419e90c914ae5fa935283404de8a2a" category="paragraph">在此 HLD中 ， ScienceLogic 用于通过使用适当的服务主体公开指标来监控 Azure NetApp Files 。下图显示了 Azure NetApp Files Metric 选项的示例。</block>
  <block id="2bede5da6907dcdcebc6a8f407f07467" category="paragraph"><block ref="2bede5da6907dcdcebc6a8f407f07467" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fe292df6373534e554d5a7938bc3c3b" category="section-title">使用厚克隆的 DevTest</block>
  <block id="652f67778e6d02c7b5bfe46a3e579f7f" category="paragraph">借助 Azure NetApp Files ，您可以创建即时数据库副本，以测试应用程序开发周期内应使用当前数据库结构和内容实施的功能，并在填充数据仓库时使用数据提取和操作工具。 或者甚至恢复错误删除或更改的数据。此过程不涉及从 Azure Blob 容器复制数据，因此效率非常高。还原卷后，可以将其用于读 / 写操作，从而显著缩短验证时间和上市时间。为了确保应用程序一致性，需要将此功能与 SCSQLAPI 结合使用。这种方法提供了另一种持续成本优化技术，同时 Azure NetApp Files 还利用了 " 还原到新卷 " 选项。</block>
  <block id="e4665dd99280634e4b44ff82666fbb9f" category="list-text">使用还原新卷选项从 Snapshot 副本创建的卷会占用容量池中的容量。</block>
  <block id="0031911d8ba66a79d06b9819afd4f082" category="list-text">您可以使用 REST 或 Azure 命令行界面删除克隆的卷，以避免额外成本（如果必须增加容量池）。</block>
  <block id="cb4d46fdcb0881652013c495d90ae732" category="section-title">混合存储选项</block>
  <block id="e6a1767911a937e11cc1750fcc4256c3" category="paragraph">虽然 NetApp 建议对 SQL Server 可用性组中的所有节点使用相同的存储，但在某些情况下，可以使用多个存储选项。在 Azure NetApp Files 中， AOAG 中的一个节点与 Azure NetApp Files SMB 文件共享连接，而第二个节点与 Azure 高级磁盘连接时，可能会出现这种情况。在这些情况下，请确保 Azure NetApp Files SMB 共享包含用户数据库的主副本，并且高级磁盘用作二级副本。</block>
  <block id="009d3d51226fdccd09052934b65100db" category="list-text">在这种部署中，为了避免任何故障转移问题，请确保在 SMB 卷上启用持续可用性。如果没有持续可用的属性，则在存储层进行任何后台维护时，数据库可能会失败。</block>
  <block id="918e9d895272e6a326c6585e05ae4c08" category="list-text">将数据库的主副本保留在 Azure NetApp Files SMB 文件共享上。</block>
  <block id="1a5c3601eda1cd38072323e418968743" category="section-title">业务连续性</block>
  <block id="064ea84d2e6072b28bfd7a8b36aed3db" category="paragraph">在任何部署中，灾难恢复通常都是事后考虑的。但是，必须在初始设计和部署阶段解决灾难恢复问题，以避免对您的业务造成任何影响。借助 Azure NetApp Files ，可以使用跨区域复制（ CRR ）功能将块级别的卷数据复制到配对区域，以处理任何意外的区域中断。启用了 CRR 的目标卷可用于读取操作，因此它是灾难恢复模拟的理想候选卷。此外，可以为 CRR 目标分配最低的服务级别（例如标准），以降低总 TCO 。发生故障转移时，复制可能会中断，从而使相应的卷具有读 / 写能力。此外，还可以使用动态服务级别功能更改卷的服务级别，从而显著降低灾难恢复成本。这是 Azure NetApp Files 在 Azure 中进行块复制的另一项独特功能。</block>
  <block id="86258094262f66b30d10068d1d9c29d4" category="section-title">长期 Snapshot 副本归档</block>
  <block id="65bd92a3b5fcfea7efeb973a0a2483d8" category="inline-link">AzCopy</block>
  <block id="e6bf440e9e7e787ce92e6f8661daf9e9" category="paragraph">许多组织都必须长期保留数据库文件中的快照数据，这是强制性合规性要求。虽然此 HLD" 不会使用此过程，但可以使用简单的批处理脚本轻松完成此过程<block ref="f326c7b047cd071718d141dba06c550f" category="inline-link-rx"></block> 将 Snapshot 目录复制到 Azure Blob 容器。可以使用已计划的任务根据特定计划触发批处理脚本。此过程非常简单，包括以下步骤：</block>
  <block id="dfdc6514d824f948d82ee2ac6515603f" category="list-text">下载 AzCopy V10 可执行文件。没有要安装的内容，因为它是一个 `exe` 文件。</block>
  <block id="5434519f37049a19d388fb3edabd08f7" category="list-text">在容器级别使用具有适当权限的 SAS 令牌来授权 AzCopy 。</block>
  <block id="73facdc1e77927e1c0d4c2f66c6fedf9" category="list-text">授权 AzCopy 后，数据传输开始。</block>
  <block id="a2c31034ac77c6ad0ce6dae2a7882d73" category="list-text">在批处理文件中，请确保转义 SAS 令牌中显示的 % 字符。为此，可以在 SAS 令牌字符串中的现有 % 字符旁边添加一个额外的 % 字符。</block>
  <block id="0eed577952fd376af1fa48aa241e3df7" category="inline-link">需要安全传输</block>
  <block id="b2f731ca364e7df30cd69650bdc19d46" category="list-text">。<block ref="7e9be5c7f255e20f7f3a81046108dcad" category="inline-link-rx"></block> 存储帐户的设置可确定与存储帐户的连接是否使用传输层安全（ Transport Layer Security ， TLS ）进行保护。默认情况下，此设置处于启用状态。以下批处理脚本示例以递归方式将数据从 Snapshot 副本目录复制到指定的 Blob 容器：</block>
  <block id="f2c225fb316953652d9040f71e76717c" category="paragraph">在 PowerShell 中执行以下示例 cmd ：</block>
  <block id="e7cc24e4ddff469c6304653aea869597" category="list-text">Azure NetApp Files 不久将提供类似的长期保留备份功能。</block>
  <block id="03930ecbc2c505278298d571631e23bb" category="list-text">在任何需要将数据复制到任何区域的 Blob 容器的情况下，均可使用此批处理脚本。</block>
  <block id="a39ae09f8be4327fc176cfeb76a0e366" category="section-title">成本优化</block>
  <block id="07ecdeff0f5a70968e882eb4ace6f576" category="paragraph">随着对数据库完全透明的卷重新调整和动态服务级别更改， Azure NetApp Files 可以在 Azure 中实现持续成本优化。此 HLDC 广泛使用此功能，以避免过度配置额外存储来处理工作负载高峰。</block>
  <block id="bf511e8b678dd2ecee162930e6c8c9e6" category="paragraph">通过结合 Azure 警报日志创建 Azure 功能，可以轻松调整卷大小。</block>
  <block id="13d13fda6fbfbd83ab30f9a5bee17b08" category="section-title">在 NFS 上自动部署适用于 ONTAP 的 Oracle19c</block>
  <block id="9ce6d30135c2644ff34390c65af4061b" category="paragraph">企业正在对其环境进行自动化，以提高效率，加快部署速度并减少手动操作。Ansible 等配置管理工具正在用于简化企业数据库操作。在此解决方案中，我们将演示如何使用 Ansible 通过 NetApp ONTAP 自动配置和配置 Oracle 19c 。通过使存储管理员，系统管理员和 DBA 能够一致快速地部署新存储，配置数据库服务器并安装 Oracle 19c 软件，您可以获得以下优势：</block>
  <block id="5291cb8e681983247b899ce2364188f2" category="list-text">消除设计复杂性和人为错误，并实施可重复的一致部署和最佳实践</block>
  <block id="a90516bf4597e04e1a97bd9cb37087d8" category="list-text">缩短配置存储，配置数据库主机和安装 Oracle 的时间</block>
  <block id="a54e59b6b063d8a2bf18acffab877d09" category="list-text">提高数据库管理员，系统和存储管理员的工作效率</block>
  <block id="d18d76441366273feb36bde890ad5e1c" category="list-text">轻松扩展存储和数据库</block>
  <block id="7d85c5a5f016aefeda6b89687f1307bb" category="paragraph">NetApp 为客户提供经过验证的 Ansible 模块和角色，以加快 Oracle 数据库环境的部署，配置和生命周期管理。此解决方案提供了相关说明和 Ansible 攻略手册代码，可帮助您：</block>
  <block id="547b893b7cd300d6a8335f5b179ad12e" category="list-text">为 Oracle 数据库创建和配置 ONTAP NFS 存储</block>
  <block id="36bb01ec9f02292fb44b9f10f57ceae7" category="list-text">在 RedHat Enterprise Linux 7/8 或 Oracle Linux 7/8 上安装 Oracle 19c</block>
  <block id="548bf87c41c9d3bb76981decbd599c90" category="list-text">在 ONTAP NFS 存储上配置 Oracle 19c</block>
  <block id="950496934d91d07bb089d6ed0999b5a9" category="paragraph">有关更多详细信息或要开始，请参见下面的概述视频。</block>
  <block id="b923f56ad2a53fa1a3ca1160e48f141e" category="section-title">AWX/ 塔式部署</block>
  <block id="cf7bbd18f18fdc73ee49ffea888126c7" category="list-text">第 2 部分：变量和运行攻略手册</block>
  <block id="f5e227cfa54c5693c512c6adf41a3772" category="section-title">CLI 部署</block>
  <block id="0b8a09b5974336d1f5e510d18205c03c" category="list-text">第 1 部分：入门，要求，自动化详细信息和可变控制主机设置</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">是的。</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">否</block>
  <block id="0dd197c8abd1f3c3607887dbc615148f" category="doc">验证 Oracle 安装</block>
  <block id="f673434da0f39c1b4366cbc45f67da8a" category="admonition">如果安装按预期完成且 Oracle 数据库已启动，则此列表将列出 Oracle 进程</block>
  <block id="52320018ddc230fda7bdeccfda8b9f0a" category="section-title">如何获取帮助？</block>
  <block id="1b6a5f8b328d3175066895d7ff5ea576" category="inline-link-macro">NetApp 解决方案自动化社区支持 Slack 通道</block>
  <block id="12f178498803c606c23e7166dcefb0cb" category="paragraph">如果您需要有关该工具包的帮助，请加入 <block ref="f1bb21e2ce6888d898ae31a2098245a1" category="inline-link-macro-rx"></block> 并寻找解决方案自动化渠道来发布您的问题或询问。</block>
  <block id="75b7d47e2aa19968e092ab7ddb108a3f" category="summary">无论您是针对采用延伸型数据库的全云云还是混合云， Azure NetApp Files 都可以提供出色的选项来部署和管理数据库工作负载，同时通过将数据需求无缝迁移到应用程序层来降低 TCO 。</block>
  <block id="d8d2e6021f496c4e4a31a3d5d51c0a97" category="paragraph">本文档介绍了有关使用 Azure NetApp Files 规划，设计，优化和扩展 Microsoft SQL Server 部署的建议，这些建议可能因实施方式而异。正确的解决方案取决于实施的技术细节以及推动项目的业务需求。</block>
  <block id="56925354251a536c23de1174d3001595" category="section-title">要点总结</block>
  <block id="033e6e43f2148e187e072dc7e6585802" category="paragraph">本文档的要点包括：</block>
  <block id="b2b363e230905b04f6e9c7263aa93f42" category="list-text">现在，您可以使用 Azure NetApp Files 托管 SQL Server 集群的数据库和文件共享见证。</block>
  <block id="4d6ec76303888bc681d543d1f4593c55" category="list-text">您可以缩短应用程序响应时间并提供 99.9999% 的可用性，以便在需要时随时随地访问 SQL Server 数据。</block>
  <block id="408e4b7fbec4ba85e097b9393d2b27a7" category="list-text">您可以简化 SQL Server 部署和持续管理（例如 RAID 条带化）的整体复杂性，并即时调整大小。</block>
  <block id="41642b38214243168d907d92759dde36" category="list-text">您可以借助智能操作功能在几分钟内部署 SQL Server 数据库，并加快开发周期。</block>
  <block id="61a32d891a5f7bca599a014bc56eec61" category="list-text">如果 Azure Cloud 是目标，则 Azure NetApp Files 是最适合优化部署的存储解决方案。</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="section-title">存储效率</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">存储配置</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="4db58285a0e634acd6843c40f7a6f4e0" category="paragraph">要了解有关本文档中所述信息的更多信息，请访问以下网站链接：</block>
  <block id="d53a72004974ee8431ee292856c0bba3" category="list-text">使用 Azure NetApp Files 的解决方案架构</block>
  <block id="653ba0610595f0695c3ceb2c59afed59" category="inline-link"><block ref="653ba0610595f0695c3ceb2c59afed59" category="inline-link-rx"></block></block>
  <block id="d5ec9321fb49816034de6b296ef6baa2" category="paragraph"><block ref="d5ec9321fb49816034de6b296ef6baa2" category="inline-link-rx"></block></block>
  <block id="ba110408cece764b57b56f1129b3ba2e" category="list-text">使用 Azure NetApp Files for SQL Server 部署的优势</block>
  <block id="62b5dbc436fc2540c46476bd8e484c11" category="inline-link"><block ref="62b5dbc436fc2540c46476bd8e484c11" category="inline-link-rx"></block></block>
  <block id="44594562b4f528fe8d864bd3f48ddff6" category="paragraph"><block ref="44594562b4f528fe8d864bd3f48ddff6" category="inline-link-rx"></block></block>
  <block id="7aa91f5f0414f1488ce2f5324e63d12e" category="list-text">《使用 Azure NetApp Files 的 Azure 上的 SQL Server 部署指南》</block>
  <block id="9021ea474df74856b145a78c58c35e05" category="inline-link"><block ref="9021ea474df74856b145a78c58c35e05" category="inline-link-rx"></block></block>
  <block id="52a5313d9aca117b5d167e6be79c5bc7" category="paragraph"><block ref="52a5313d9aca117b5d167e6be79c5bc7" category="inline-link-rx"></block></block>
  <block id="49217b0d4a68c88899c93d24203a34b4" category="list-text">借助 Azure NetApp Files 实现容错，高可用性和故障恢复能力</block>
  <block id="9e5e063336d276080a054861016aadd8" category="inline-link"><block ref="9e5e063336d276080a054861016aadd8" category="inline-link-rx"></block></block>
  <block id="7ff89d0ad939652d37cbab9b6f420f65" category="paragraph"><block ref="7ff89d0ad939652d37cbab9b6f420f65" category="inline-link-rx"></block></block>
  <block id="05807e454c19f244770adae059b3c330" category="section-title">高可用性</block>
  <block id="6551468cb4811e7add616eea103efea9" category="doc">分步部署操作步骤</block>
  <block id="0e6b1c16527d2792d391c578bbf12efe" category="section-title">CLI 部署 Oracle 19c 数据库</block>
  <block id="57daddd847cdbab22b7363630de48a2f" category="inline-link-macro">入门和要求部分</block>
  <block id="82ba94e85d91493ea6c88423c0b34605" category="paragraph">本节介绍使用 CLI 准备和部署 Oracle19c 数据库所需的步骤。确保您已查看 <block ref="598ea103507880273a5a1840cac102d8" category="inline-link-macro-rx"></block> 并相应地准备好您的环境。</block>
  <block id="0f2d7675188dbfc7b9df587588bff71b" category="section-title">下载 Oracle19c repo</block>
  <block id="4e2b619426350db7e7d5b09c96b8010b" category="section-title">编辑 hosts 文件</block>
  <block id="b183e47af1fa85c93e4a4368205c3249" category="paragraph">在部署之前完成以下操作：</block>
  <block id="c4ab1530ffd8a3306d47c804ca88240c" category="list-text">编辑 hosts 文件 na_oracle19c_deploy 目录。</block>
  <block id="bc1dd0e50a3c20e78cc2d680eaf32378" category="list-text">在 ONTAP 下，将 IP 地址更改为集群管理 IP 。</block>
  <block id="6475f51ce7ff0a21a5635ea50b1f1a86" category="list-text">在 Oracle 组下，添加 Oracle 主机名称。主机名必须通过 DNS 或 hosts 文件解析为其 IP 地址，或者必须在主机中指定。</block>
  <block id="5c3f5e9dc815ca28c7cf1ff64cdc61a2" category="list-text">完成这些步骤后，请保存所做的任何更改。</block>
  <block id="b27994a7bba852ac9a8f1a262413e68b" category="paragraph">以下示例说明了一个主机文件：</block>
  <block id="1caa2eee0ed6a6c5c6edcbc0320e8671" category="paragraph">此示例将执行该攻略手册，并在两个 Oracle DB 服务器上同时部署 Oracle 19c 。您也可以仅使用一个数据库服务器进行测试。在这种情况下，您只需要配置一个主机变量文件。</block>
  <block id="d11927d6f93a4edaa78dc52c6e34fd5f" category="admonition">无论您部署多少 Oracle 主机和数据库，本攻略手册的执行方式都是相同的。</block>
  <block id="030c98564d5fbd7c8672a76e2a593b21" category="section-title">编辑 host_vars 下的 host_name.yml 文件</block>
  <block id="86c40bb4891f3e6b34a2eece7bb19532" category="paragraph">每个 Oracle 主机都有其主机变量文件，该文件由包含主机专用变量的主机名标识。您可以为主机指定任何名称。从 Host VARS Config 部分编辑并复制 `host_vars` ，然后将其粘贴到所需的 `host_name.yml` 文件中。</block>
  <block id="93be2ec6954884b83ac9df8117967949" category="admonition">必须根据您的环境更改蓝色项。</block>
  <block id="5bbe8264b4d6c6787657c66d4017c183" category="section-title">主机 VARS 配置</block>
  <block id="44505c1007599884b05c0148599ad1b0" category="section-title">编辑 vars.yml 文件</block>
  <block id="41cdd95196e2753968e0d69375c41825" category="paragraph">`vars.yml` 文件整合了所有环境特定的变量（ ONTAP ， Linux 或 Oracle ），用于 Oracle 部署。</block>
  <block id="271f9ccf9c8189bb1888d25c7f0e025b" category="list-text">编辑并复制 VARS 部分中的变量，然后将这些变量粘贴到 `vars.yml` 文件中。</block>
  <block id="78d77851709e21512097cee585c59d0c" category="section-title">运行攻略手册</block>
  <block id="8f42d9f703ada5b4f1374ca96a4f1cec" category="paragraph">完成所需的环境前提条件并将变量复制到 `vars.yml` 和 `yor_host.yml` 中后，您便可部署攻略手册了。</block>
  <block id="6226590ec5d4a109e4b93317425994c1" category="admonition">必须根据您的环境更改 &lt; 用户名 &gt; 。</block>
  <block id="24b2767982b51deb19947fb3e94279c6" category="section-title">在同一 Oracle 主机上部署其他数据库</block>
  <block id="5cc75d1029461de7ddcd02bbc784af26" category="paragraph">此攻略手册的 Oracle 部分会每次在 Oracle 服务器上创建一个 Oracle 容器数据库。要在同一服务器上创建其他容器数据库，请完成以下步骤：</block>
  <block id="b4a35a2d5c3a4f3efb7c77f6bcd2a905" category="list-text">修改 host_vars 变量。</block>
  <block id="5641cb71d4e10abef15918c2dd828917" category="list-text">返回到步骤 3 - 编辑 `host_vars` 下的 `host_name.yml` 文件。</block>
  <block id="ffcc6e6df9c3839334c063a9223c65b3" category="list-text">将 Oracle SID 更改为其他命名字符串。</block>
  <block id="a936a5fabc881eb3591658385409dfb8" category="list-text">将侦听器端口更改为其他编号。</block>
  <block id="24f0029973c35b16fc49847b27215915" category="list-text">如果已安装 EM Express ，请将 EM Express 端口更改为其他编号。</block>
  <block id="365c64de6adc281d7f484029d1356855" category="list-text">将修订后的主机变量复制并粘贴到 `host_vars` 下的 Oracle 主机变量文件中。</block>
  <block id="b64219fd8290ac8a154f733df0825dbb" category="list-text">使用 `ORACLE_CONFIG` 标记执行攻略手册，如中所示 <block ref="1c892654e23ff69bf71caefc702aa8b4" category="inline-xref-macro-rx"></block>。</block>
  <block id="c150393fd3b1bd9d801cbd062234f73d" category="section-title">AWX/Tower 部署 Oracle 19c 数据库</block>
  <block id="32003b051ef9368756d1e9cd79796719" category="section-title">1. 为您的环境创建清单，组，主机和凭据</block>
  <block id="2c8b94d570dd5a63a27d112e32a1c799" category="paragraph">本节介绍如何在 AWX/Ansible 塔中设置清单，组，主机和访问凭据，以便为使用 NetApp 自动化解决方案的环境做好准备。</block>
  <block id="134d501fee5367069f0746f15302ce1f" category="list-text">配置清单。</block>
  <block id="af2c7dd4ecef5e42e9bc8f88213d51d9" category="list-text">导航到资源→清单→添加，然后单击添加清单。</block>
  <block id="56fc26ef1c8ae54dced3529eec65fa26" category="list-text">提供名称和组织详细信息，然后单击保存。</block>
  <block id="fe0981da08a8d2f4fed2006bafd9fb30" category="list-text">在清单页面上，单击已创建的清单。</block>
  <block id="3fa16e80574aff03c27de1253474a20f" category="list-text">如果存在任何清单变量，请将其粘贴到变量字段中。</block>
  <block id="65d119ae335d9e7c9c798b3e6db1b2d0" category="list-text">导航到组子菜单，然后单击添加。</block>
  <block id="396641e01a7451ca821b5d7d1377b0c7" category="list-text">提供 ONTAP 的组名称，粘贴组变量（如果有），然后单击保存。</block>
  <block id="a4f13b6e4100f2d5db093eb54a3ffe0c" category="list-text">对 Oracle 的另一个组重复此过程。</block>
  <block id="6f29f21d5f3e40494291fb357b9f4f73" category="list-text">选择已创建的 ONTAP 组，转到主机子菜单，然后单击添加新主机。</block>
  <block id="8d92ffd9d0d2b033d05731ec4af50af8" category="list-text">提供 ONTAP 集群管理 IP 的 IP 地址，粘贴主机变量（如果有），然后单击保存。</block>
  <block id="f1254ecbe57ff98d850d541b8a1ab988" category="list-text">必须对 Oracle 组和 Oracle 主机管理 IP/ 主机名重复此过程。</block>
  <block id="f11c5853bdca384314b28c9c59f2d6d0" category="list-text">创建凭据类型。对于涉及 ONTAP 的解决方案，您必须配置凭据类型以匹配用户名和密码条目。</block>
  <block id="c87e3da0a9f8d5eeacea4eac9bef80ea" category="list-text">导航到管理→凭据类型，然后单击添加。</block>
  <block id="e6bf632438290fdf98265b2b18943118" category="list-text">提供名称和问题描述。</block>
  <block id="5f5a0974b600f86bd4e77595282fcf70" category="list-text">将以下内容粘贴到输入配置中：</block>
  <block id="1616edbabbc3bbfd22afe144d1929386" category="list-text">将以下内容粘贴到注射器配置中：</block>
  <block id="c4053f20c3fe50fe899484a64367439e" category="list-text">配置凭据。</block>
  <block id="41dcc8a8aaaa79a511ba0ab4e6bde225" category="list-text">导航到资源→凭据，然后单击添加。</block>
  <block id="cc865c923bcb1c61acf9985311675b93" category="list-text">输入 ONTAP 的名称和组织详细信息。</block>
  <block id="ea314f484653e7f9f25144ea61d34888" category="list-text">选择为 ONTAP 创建的自定义凭据类型。</block>
  <block id="179cae6336461d9f165e8fa87146362a" category="list-text">在 Type Details 下，输入用户名，密码和 vsadmin_password 。</block>
  <block id="659fb4c811f1a73cf40492056e6d3c3f" category="list-text">单击 Back to Credential ，然后单击 Add 。</block>
  <block id="3b9c90c4bf202563a3cdeda5ec78fac2" category="list-text">输入 Oracle 的名称和组织详细信息。</block>
  <block id="9ef3fcc446a5f500717f9b5e9291bce4" category="list-text">选择计算机凭据类型。</block>
  <block id="9fadc5c4eed350a8a1423628227dad59" category="list-text">在 Type Details 下，输入 Oracle 主机的 Username 和 Password 。</block>
  <block id="b4ca3125325138b1dbfc309e6bd67b80" category="list-text">选择正确的权限升级方法，然后输入用户名和密码。</block>
  <block id="51b04d83367483575e89740841d94262" category="section-title">2. 创建项目</block>
  <block id="e56fa1e2655db1bc7664a00295bd62a2" category="list-text">转至 "Resources" → "projects" ，然后单击 "Add" 。</block>
  <block id="9c78f8d8687776e79018ded982e14c25" category="list-text">输入名称和组织详细信息。</block>
  <block id="4096a1870a258e9d46585f08d4906f21" category="list-text">在源控制凭据类型字段中选择 Git 。</block>
  <block id="784148c4a03cf22250dddc5756684e39" category="list-text">输入 ... <block ref="4509731a8f0f86cf7d8a010739dfd7c5" category="inline-link-rx"></block> 作为源控制 URL 。</block>
  <block id="7557bd62e953fb4d48f07977151ea94f" category="list-text">单击保存。</block>
  <block id="99bc2ea435ea8ae0ed38ef3051a4350a" category="list-text">当源代码发生更改时，项目可能偶尔需要同步。</block>
  <block id="14e017f358e18dd612a468713206093f" category="section-title">3. 配置 Oracle host_vars</block>
  <block id="05557c38b20e42173356b53f42c92152" category="paragraph">本节中定义的变量将应用于每个 Oracle 服务器和数据库。</block>
  <block id="ac886b852fd1b481e9c7e68c217b5e21" category="list-text">以以下嵌入式 Oracle hosts 变量或 host_vars 形式输入环境特定的参数。</block>
  <block id="e1847b1a99378b07a0df71cf2baac5da" category="list-text">填写蓝色字段中的所有变量。</block>
  <block id="741c92ab2429ff59927918c7a07ad9a5" category="list-text">完成变量输入后，单击表单上的复制按钮以复制要传输到 AWX 或塔式的所有变量。</block>
  <block id="1e1ea51549ac2a644a3e965113c1d370" category="list-text">导航回 AWX 或塔式，然后转到资源→主机，选择并打开 Oracle 服务器配置页面。</block>
  <block id="0d630b14098a793ac4586173286d0805" category="list-text">在详细信息选项卡下，单击编辑并将从步骤 1 复制的变量粘贴到 YAML 选项卡下的变量字段。</block>
  <block id="c6dca9e669d097298fc6059b27f96e09" category="list-text">对系统中的任何其他 Oracle 服务器重复此过程。</block>
  <block id="7890327bd98d1ec932e453254511754d" category="section-title">4. 配置全局变量</block>
  <block id="e5cac740ce6bd43e6ff83881e150d0f3" category="paragraph">本节中定义的变量适用于所有 Oracle 主机，数据库和 ONTAP 集群。</block>
  <block id="87b55102ec2889891b0258253b739244" category="list-text">在以下嵌入式全局变量或变量表单中输入环境特定的参数。</block>
  <block id="7d2a3c2ad9ee2eeb7547d205d30b9335" category="list-text">在蓝色字段中填写所有变量。</block>
  <block id="099f04b51539ed973890f1d1af2d5063" category="list-text">完成变量输入后，单击表单上的复制按钮，将要传输到 AWX 或塔式的所有变量复制到以下作业模板中。</block>
  <block id="c807b1735c1915c52547b9f7e917b55d" category="section-title">5. 配置并启动作业模板。</block>
  <block id="b1171f0b44b8d9b11ac555972ebc8c3b" category="list-text">创建作业模板。</block>
  <block id="0fd181172a82ebe5219e9a30e5d97c0d" category="list-text">导航到资源→模板→添加，然后单击添加作业模板。</block>
  <block id="c7fa74fb4cbaab9d336a8e55bf164684" category="list-text">输入名称和问题描述</block>
  <block id="3dcca032e3328f54206079a87830aa27" category="list-text">选择作业类型；运行将根据攻略手册配置系统，而检查将在不实际配置系统的情况下执行攻略手册的试运行。</block>
  <block id="daefcb84cec2b58089094a64cefb845f" category="list-text">为攻略手册选择相应的清单，项目，攻略手册和凭据。</block>
  <block id="b01c6189ccdc531874f3442803680525" category="list-text">选择 all_playbook.yml 作为要执行的默认攻略手册。</block>
  <block id="ce150ce9cfe145db199958e7cd2ecce0" category="list-text">将从步骤 4 复制的全局变量粘贴到 YAML 选项卡下的模板变量字段中。</block>
  <block id="e8f0426d97d09775fb78bdeb793b0b3e" category="list-text">选中作业标记字段中的启动时提示框。</block>
  <block id="31e2568c13fbdaaad088eb3b665dea9d" category="list-text">启动作业模板。</block>
  <block id="3624b34cb634949984bcb28c79fd327f" category="list-text">导航到资源→模板。</block>
  <block id="56ae7378358ba2b1c55c47283f544991" category="list-text">单击所需模板，然后单击启动。</block>
  <block id="ad7ad1bbc416fda1f9518ff4004d891c" category="list-text">在启动作业标记时系统提示时，键入 requirements_config 。您可能需要单击 requirements_config 下方的 Create Job Tag 行以输入作业标记。</block>
  <block id="b9ef793a3db3f07ed7dc808f4709c6ca" category="admonition">requirements_config 可确保您有正确的库来运行其他角色。</block>
  <block id="6ac039e55dcf8a249f5122b1fdbbf60e" category="list-text">单击下一步，然后单击启动以启动作业。</block>
  <block id="06f392c8dfb4783859e67f16fed69bc7" category="list-text">单击查看→作业以监控作业输出和进度。</block>
  <block id="7f6a02c24592bd309f31b5a72a0f8d6d" category="list-text">在启动作业标记时，系统提示您键入 ontap_config 。您可能需要单击 ontap_config 下方的 Create "Job Tag （创建作业标记） " 行以输入作业标记。</block>
  <block id="18c003af9ed29d295877baabf7b42ce1" category="list-text">单击查看→作业以监控作业输出和进度</block>
  <block id="c0029d5cdcaae1ceef3bed244b3ab3c6" category="list-text">完成 ontap_config 角色后，对 linux_config 再次运行此过程。</block>
  <block id="fc71758268fe1c3aba4b75df3ee0560f" category="list-text">选择所需模板，然后单击启动。</block>
  <block id="bbe073bafc2875db8b48e59284636931" category="list-text">在 Linux_config 中启动作业标记类型时，系统提示您选择 Linux_config 下方的创建 " 作业标记 " 行以输入作业标记。</block>
  <block id="bc43b7acafead2cdee67de733ae10b13" category="list-text">选择 View → Jobs 以监控作业输出和进度。</block>
  <block id="e73718535637e07111f6a4925685c0bd" category="list-text">完成 Linux_config 角色后，对 ORACLE_CONFIG 再次运行此过程。</block>
  <block id="574f8726a5cc088da32ab84269c8e0f8" category="list-text">转至资源→模板。</block>
  <block id="252b85bc679cb8ecdccbcd127c65b795" category="list-text">在启动作业标记时，系统提示您键入 ORACLE_CONFIG 。您可能需要选择 ORACLE_CONFIG 下方的 "Create Job Tag （创建作业标记） " 行以输入作业标记。</block>
  <block id="6757805f64ddba2566927ece0d9f30e1" category="section-title">6. 在同一 Oracle 主机上部署其他数据库</block>
  <block id="4edc1d4492ab93edbbb0a67c0c265b84" category="paragraph">此攻略手册的 Oracle 部分会每次在 Oracle 服务器上创建一个 Oracle 容器数据库。要在同一服务器上创建其他容器数据库，请完成以下步骤。</block>
  <block id="a12a0fa7fe728658376da87df04fa7c2" category="list-text">修改 host_vars 变量。</block>
  <block id="ba52bf2d165115d60675d61a4b84b0c6" category="list-text">返回到步骤 2 —配置 Oracle host_vars 。</block>
  <block id="d9fa63a6f267402d4cf6068165e04a38" category="list-text">如果要安装 EM Express ，请将 EM Express 端口更改为其他编号。</block>
  <block id="23f5c9b4f57b3075f9890f1bc1896ebe" category="list-text">将修订后的主机变量复制并粘贴到主机配置详细信息选项卡中的 Oracle 主机变量字段中。</block>
  <block id="4d4426a703dd8227727fef5758b680d8" category="list-text">启动仅包含 ORACLE_CONFIG 标记的部署作业模板。</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">简介</block>
  <block id="a2810b66f557bf43f1c602ecfe7f52b1" category="summary">本文档介绍如何利用 Azure 虚拟机在 Azure NetApp Files 上实时部署 SQL Server 始终可用性组（ AOAG ）。</block>
  <block id="0ecccb1d48727b6da357728efe7b6375" category="doc">TR-4897 ： Azure NetApp Files 上的 SQL Server — Real Deployment 视图</block>
  <block id="4eae423bbc6520b4a8fa4d0d4de28b8a" category="paragraph">NetApp 公司 Niyaz Mohamed</block>
  <block id="8ae2b9aab28b6c00df7581f99f9211ef" category="paragraph">IT 组织面临着不断变化的问题。据 Gartner 报告，到 2022 年，所有数据库中有近 75% 的数据库将需要基于云的存储。作为领先的关系数据库管理系统（ Relational Database Management System ， RDBMS ）， Microsoft SQL Server 是 Windows 平台设计的应用程序和组织的首选，这些应用程序和组织依靠 SQL Server 来实现从企业资源规划（ Enterprise Resource Planning ， ERP ）到分析再到内容管理的所有功能。SQL Server 帮助企业彻底改变了管理海量数据集的方式，并为其应用程序提供支持，以满足架构和查询性能需求。</block>
  <block id="eae371fd2d593d80849fab02c4e8b90b" category="paragraph">大多数 IT 组织都采用云优先的方法。处于转型阶段的客户会评估其当前的 IT 环境，然后根据评估和发现练习将其数据库工作负载迁移到云。促使客户迁移到云的一些因素包括弹性 / 突发，数据中心退出，数据中心整合，寿命终结情形，合并， 采集等。迁移的原因可能因组织及其各自的业务优先级而异。迁移到云时，要充分发挥 SQL Server 数据库云部署的潜能，选择合适的云存储非常重要。</block>
  <block id="f9468c81b3d59ac0030570c4f58e95f1" category="section-title">用例</block>
  <block id="cf8b0bda1e058c1f8383f434c4da9b71" category="paragraph">将 SQL Server 资产迁移到 Azure ，并将 SQL Server 与 Azure Data Factory ， Azure IoT Hub 和 Azure Machine Learning 等 Azure 的大量平台即服务（ Platform-as-a-Service ， PaaS ）功能相集成，为支持数字化转型创造了巨大的业务价值。与依赖资本支出模式或传统私有云模式相比，采用云还可以使相应的业务部门专注于工作效率并更快地交付新功能和增强功能（ DevTest 用例）。本文档介绍如何利用 Azure 虚拟机在 Azure NetApp Files 上实时部署 SQL Server 始终可用性组（ AOAG ）。</block>
  <block id="239a02aaaf9289a3093f682835f65f88" category="paragraph">Azure NetApp Files 提供具有持续可用文件共享的企业级存储。SMB 文件共享上的 SQL Server 生产数据库需要持续可用的共享，以确保节点始终能够访问数据库存储，包括在控制器升级或故障等中断情形下。持续可用的文件共享不再需要在存储节点之间复制数据。Azure NetApp Files 使用 SMB 3.0 横向扩展，持久句柄和透明故障转移来支持在发生计划内和计划外停机事件（包括许多管理任务）时执行无中断操作（ NDO ）。</block>
  <block id="f47a858d79de9725a0d6881541748e9b" category="paragraph">在规划云迁移时，您应始终评估最佳使用方法。应用程序迁移最常见且最简单的方法是重新托管（也称为提升和移动）。本文档中提供的示例方案使用重新托管方法。使用采用 Azure NetApp Files 的 Azure 虚拟机上的 SQL Server ，您可以在云中使用完整版本的 SQL Server ，而无需管理内部硬件。SQL Server 虚拟机（ VM ）还可以在按需购买的情况下简化许可成本，并为开发，测试和资产更新情形提供弹性和突发功能。</block>
  <block id="64899c745691f41e5b1dc01d3a4487d2" category="summary">本节介绍在云中使用 Azure NetApp Files 和 SQL Server 时应考虑的不同问题。</block>
  <block id="bb4695a70b92668f0a7927d04580db60" category="doc">需要考虑的因素</block>
  <block id="4dd91c7652639dacea041fe6033e2627" category="section-title">虚拟机性能</block>
  <block id="e6ac657ee6eac68b739c5cc437863922" category="inline-link">内存优化</block>
  <block id="68e5d4a238cdfe033afa141123484499" category="paragraph">选择合适的 VM 大小对于公有云中关系数据库的最佳性能非常重要。Microsoft 建议您继续使用适用于内部服务器环境中 SQL Server 的相同数据库性能调整选项。使用 ...<block ref="187f54af8632f4f6696d6052e8b74aec" category="inline-link-rx"></block> VM 大小可实现 SQL Server 工作负载的最佳性能。收集现有部署的性能数据，以确定 RAM 和 CPU 利用率，同时选择合适的实例。大多数部署可选择 D ， E 或 M 系列。</block>
  <block id="8b2db846b8ed65b2919d93a68b819a43" category="list-text">要获得最佳的 SQL Server 工作负载性能，请使用内存优化的 VM 大小。</block>
  <block id="32a3b4d7b7e6cf1ecde48636119e0288" category="list-text">NetApp 和 Microsoft 建议您先确定存储性能要求，然后再选择具有适当内存到 VCORE 比率的实例类型。这还有助于选择具有适当网络带宽的较低实例类型，以克服 VM 的存储吞吐量限制。</block>
  <block id="0abdff1d9e33eca61c14ccafe8012cd5" category="section-title">VM 冗余</block>
  <block id="9fecd525b2d9ad39ac38bbfc4d05ee17" category="inline-link">可用性集</block>
  <block id="26075dbb6cfad683e0d9bd0d29c570b8" category="inline-link">可用性区域</block>
  <block id="e936e004eab3eccfc1e7f46a3187dfd1" category="paragraph">要提高冗余和高可用性， SQL Server VM 应处于同一状态<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> 或其他<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>。创建 Azure VM 时，您必须在配置可用性集与可用性区域之间进行选择； Azure VM 不能同时参与这两者。</block>
  <block id="94eeeae1e60f97a446e8c4f69d6d6f43" category="paragraph">为了实现高可用性，最好配置 SQL Server AOAG 或始终在故障转移集群实例（ FCI ）上。对于 AOAG ，这涉及到一个虚拟网络中 Azure 虚拟机上的多个 SQL Server 实例。如果数据库级别需要高可用性，请考虑配置 SQL Server 可用性组。</block>
  <block id="fa32aac4116ce1980c311f004157a133" category="paragraph">Microsoft SQL Server 可以使用 SMB 文件共享作为存储选项进行部署。从 SQL Server 2012 开始，系统数据库（主数据库，型号数据库， msdb 或 tempdb ）， 用户数据库可以作为存储选项与服务器消息块（ Server Message Block ， SMB ）文件服务器一起安装。此适用场景既适用于 SQL Server 独立服务器，也适用于 SQL Server FCI 。</block>
  <block id="250548ef00796e6a203215b1d550bb0d" category="admonition">SQL Server 数据库的文件共享存储应支持持续可用的属性。这样可以无中断地访问文件共享数据。</block>
  <block id="45a6af9c92529e3da9ccdbeae9d692ac" category="paragraph">Azure NetApp Files 可提供高性能文件存储来满足任何苛刻的工作负载要求，与块存储解决方案相比，它可以降低 SQL Server 的 TCO 。对于块存储， VM 会对磁盘操作的 I/O 和带宽施加限制；仅对 Azure NetApp Files 应用网络带宽限制即可。换言之，不会对 Azure NetApp Files 应用 VM 级别的 I/O 限制。如果没有这些 I/O 限制，在连接到 Azure NetApp Files 的较小 VM 上运行的 SQL Server 以及在较大 VM 上运行的 SQL Server 就可以正常运行。Azure NetApp Files 可降低计算和软件许可成本，从而降低 SQL Server 部署成本。有关使用 Azure NetApp Files for SQL Server 部署的详细成本分析和性能优势，请参见<block ref="458fda910151e8d66385b2aabb6cd60e" category="inline-link-rx"></block>。</block>
  <block id="9d2b7eb8bc76e60b0d9cd237d67a34fb" category="paragraph">使用 Azure NetApp Files for SQL Server 的优势包括：</block>
  <block id="8ee22743237d82e9adc18a596977a138" category="list-text">使用 Azure NetApp Files 可以使用较小的实例，从而降低计算成本。</block>
  <block id="3de639403ea86ae87a5883d359deb4ab" category="list-text">Azure NetApp Files 还可以降低软件许可成本，从而降低总体 TCO 。</block>
  <block id="46790c8fe72176f6262b4b5531482ee5" category="list-text">卷重新调整和动态服务级别功能可针对稳定状态的工作负载进行规模估算并避免过度配置，从而优化成本。</block>
  <block id="860d93b2ef30525111fa6440bf4d5bd7" category="list-text">要提高冗余和高可用性， SQL Server VM 应处于同一状态<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> 或不同的<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>。如果需要用户定义的数据文件，请考虑文件路径要求；在这种情况下，请选择 SQL FCI over SQL AOAG 。</block>
  <block id="c6fbfcd868e29e37e88eaeff82a7f430" category="inline-link">\\ANFSMB-b4ca.anf.test\SQLDB 和 \\ANFSMB-b4ca.anf.test\SQLDB\</block>
  <block id="e2bed4e218692d056237b3ae3d24293c" category="list-text">支持以下 UNC 路径：<block ref="cb8cdd6ee3ebeed12086142f1a66cc3e" category="inline-link-rx"></block>。</block>
  <block id="0b4d3828f5dae91cd27e48bffa786d91" category="list-text">不支持环回 UNC 路径。</block>
  <block id="db3d2f4f54b992af225801eb51ea7387" category="list-text">要进行规模估算，请使用内部环境中的历史数据。对于 OLTP 工作负载，使用平均和高峰时间的工作负载以及磁盘读取 / 秒和磁盘写入 / 秒性能计数器将目标 IOPS 与性能要求进行匹配。对于数据仓库和报告工作负载，请使用工作负载在平均和峰值时间以及磁盘读取字节 / 秒和磁盘写入字节 / 秒匹配目标吞吐量平均值可与卷重新调整功能结合使用。</block>
  <block id="da3259c6aa3dafdc8ca15c687022a5cd" category="section-title">创建持续可用的共享</block>
  <block id="f7ee3eee4fa679986e37911272d13a29" category="inline-link">创建持续可用的共享</block>
  <block id="de7d92d6f4ac1f140ac05886ec017f09" category="paragraph">使用 Azure 门户或 Azure 命令行界面创建持续可用的共享。在门户中，选择启用持续可用性属性选项。对于 Azure 命令行界面，使用 `az netappfiles volume create 并将 smb-continuoused-avl` 选项设置为 ` $True` 来将共享指定为持续可用的共享。要了解有关创建启用了持续可用性的新卷的详细信息，请参见<block ref="86e4b436e8054cc83fccec640f98e218" category="inline-link-rx"></block>。</block>
  <block id="9a3932b7bdfdbb892087fd595ec7acb9" category="list-text">为 SMB 卷启用持续可用性，如下图所示。</block>
  <block id="c012fe8c05a3d9875a4f87cee09d1ca9" category="list-text">如果使用的是非管理员域帐户，请确保已为该帐户分配所需的安全权限。</block>
  <block id="762783478495f0889d01a59db256f92c" category="list-text">在共享级别设置适当的权限，并设置适当的文件级别权限。</block>
  <block id="bfb74db6a55528f52e8ecb83a507a043" category="inline-link">将现有 SMB 卷转换为使用持续可用性</block>
  <block id="3cad4a4fcd378074292bfc2ff45fd4ca" category="list-text">无法在现有 SMB 卷上启用持续可用属性。要将现有卷转换为使用持续可用的共享，请使用 NetApp Snapshot 技术。有关详细信息，请参见<block ref="25dc0603f84029cfd15a97a37903a54c" category="inline-link-rx"></block>。</block>
  <block id="015dd90c833178044ff327aee63f72ec" category="paragraph"><block ref="015dd90c833178044ff327aee63f72ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">性能</block>
  <block id="ee38206503545cf54ad072dee7f8ab1a" category="paragraph">Azure NetApp Files 支持三种服务级别：标准（每 TB 16 MBps ），高级（每 TB 64 MBps ）和超级（每 TB 128 MBps ）。配置适当的卷大小对于优化数据库工作负载性能非常重要。使用 Azure NetApp Files 时，卷性能和吞吐量限制取决于以下因素的组合：</block>
  <block id="b87f5218989e854f2889f939a4e2ec06" category="list-text">卷所属容量池的服务级别</block>
  <block id="9320cce40e9ab4d677bfcc78eddc64d5" category="list-text">分配给卷的配额</block>
  <block id="2d98af90367bed299b95066a85be0a17" category="list-text">容量池的服务质量（ QoS ）类型（自动或手动）</block>
  <block id="a6f08c2897faaf4d449d71d87f473ff1" category="inline-link">Azure NetApp Files 的服务级别</block>
  <block id="ac56170d8576092b90989d467f2d383e" category="paragraph">有关详细信息，请参见<block ref="1e8ed0f384e427209ce2e9dfbaed249d" category="inline-link-rx"></block>。</block>
  <block id="79bcc7c0be7625b4b6b95ac8189ec45e" category="paragraph"><block ref="79bcc7c0be7625b4b6b95ac8189ec45e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">性能验证</block>
  <block id="af3948d0fe6860f3a865cd04abebc009" category="inline-link">SQL Server 存储基准测试（ Storage Benchmark ， SB ）工具</block>
  <block id="01384acc34d886b9383610a7494ca75a" category="paragraph">与任何部署一样，测试虚拟机和存储也至关重要。对于存储验证，可使用 HammerDB ， Apploader ，等工具<block ref="df8d6ca8d2831e94c0812b2b971f8958" category="inline-link-rx"></block>或任何具有适当读 / 写混合的自定义脚本或 FIO 。但请注意，大多数 SQL Server 工作负载，甚至繁忙的 OLTP 工作负载，读取率接近 80% – 90% ，写入率接近 10% – 20% 。</block>
  <block id="10fde396dd4a669ec17689dd7cf8b599" category="paragraph">为了展示性能，我们对使用高级服务级别的卷执行了快速测试。在此测试中，卷大小从 100 GB 实时增加到 2 TB ，而不会中断应用程序访问和零数据迁移。</block>
  <block id="6fab14b7b6a90422e865a3b09497edaa" category="paragraph"><block ref="6fab14b7b6a90422e865a3b09497edaa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eedfe317eed7692e9d95ba36177a80e9" category="paragraph">下面是使用 HammerDB 对本白皮书所述的部署执行实时性能测试的另一个示例。在此测试中，我们使用了一个小型实例，其中包含八个 vCPU ，一个 500 GB 高级 SSD 和一个 500 GB SMB Azure NetApp Files 卷。HammerDB 配置了 80 个仓库和 8 个用户。</block>
  <block id="c365893719ad3de45f14fa9c19408eca" category="paragraph">下图显示，使用大小相当的卷（ 500 GB ）时， Azure NetApp Files 能够以 4 倍的延迟提供每分钟事务数的 2.6 倍。</block>
  <block id="d50d666921da97fdc14e35f752474e41" category="paragraph">另一项测试是，将大小调整为使用 32 个 vCPU 和 16 TB Azure NetApp Files 卷的较大实例。每分钟事务数显著增加，延迟始终保持在 1 毫秒。在此测试中， HammerDB 配置了 80 个仓库和 64 个用户。</block>
  <block id="3b38e0407e747349840c72259c5da930" category="paragraph"><block ref="3b38e0407e747349840c72259c5da930" category="inline-image-macro-rx" type="image"></block></block>
  <block id="892725223bbd64ebec595545eeaf8c28" category="paragraph">通过 Azure NetApp Files ，可以无中断，透明地调整卷大小，并且可以在不发生停机且不影响应用程序的情况下更改服务级别。这是一项独特的功能，可实现动态成本管理，避免使用峰值指标执行数据库规模估算。而是可以使用稳定状态的工作负载，从而避免前期成本。通过卷重新调整和动态服务级别更改，您可以几乎瞬时按需调整 Azure NetApp Files 卷的带宽和服务级别，而无需暂停 I/O ，同时保留数据访问。</block>
  <block id="44aaafbc17f2a4fcbd6d52e1c8ee0cae" category="paragraph">可以使用 LogicApp 或功能等 Azure PaaS 产品根据特定的 webhook 或警报规则触发器轻松调整卷大小，以满足工作负载需求，同时动态处理成本。</block>
  <block id="d613d5e1ef7a7f52eed191ef1066a08a" category="paragraph">例如，假设数据库需要 250 MBps 才能实现稳定状态操作；但是，它也需要 400 MBps 的峰值吞吐量。在这种情况下，应使用高级服务级别内的 4 TB 卷执行部署，以满足稳定状态的性能要求。要处理高峰工作负载，请在该特定时间段内使用 Azure 功能将卷大小增加到 7 TB ，然后减小卷大小以使部署经济高效。此配置可避免过度配置存储。</block>
  <block id="3d45b043c5518eca1e47fb4ba8a813da" category="inline-link-macro">为 RHEL/CentOS 上的 CLI 部署设置 Ansible 控制节点</block>
  <block id="2afb5cc3404c6c8162722fd41895c2de" category="inline-link-macro">为 Ubuntu / Debian 上的 CLI 部署设置 Ansible 控制节点</block>
  <block id="6b8c64be0bad88fb867c6576ac777b25" category="inline-link-macro">为塔式 /AWX 部署设置 Ansible 塔式或 AWX</block>
  <block id="b278438874f41a76068d02368e65aa3e" category="doc">关于此存储库</block>
  <block id="404af48e0cb5f84306fbd93fac2ff8be" category="paragraph">NetApp 解决方案存储库简介—从何处查找特定解决方案以及如何使用此存储库。</block>
  <block id="45ac6b09a3b8f5ea07ca656ca8dea987" category="section-title">存储库导航</block>
  <block id="c28e40ef527e43509a0fcd3b114ff824" category="paragraph">存储库的导航由主边栏管理，主边栏显示在页面左侧。解决方案分为更高级别的技术领域，这些技术领域被定义为 NetApp 解决方案的 " 技术塔 " 。</block>
  <block id="e9982e506e30915713c7485a2e77633b" category="section-title">Technology Towers 概述</block>
  <block id="d67372be0bd12a2ddbcf795ccfacc7de" category="cell">* 第节 *</block>
  <block id="f14c276c07197ebef1394a5a219087a1" category="cell">* 问题描述 *</block>
  <block id="f27edcc7a209983dc37cbcdb0df49ce7" category="cell">虚拟桌面</block>
  <block id="d83d094e8e3ce7450bf099061814d148" category="cell">使用 Red Hat Ansible 开始使用解决方案自动化概述。</block>
  <block id="6174d88cc7c0409df3e035a5c9d089cb" category="section-title">更改日志</block>
  <block id="a0067ab2420cbaebc335efc5c2433c45" category="inline-link-macro">更改日志</block>
  <block id="bea4c2c8eb82d05891ddd71584881b56" category="section-title">反馈</block>
  <block id="fb6b632cdd61e02434568081cbbf0fae" category="paragraph">请使用 <block ref="a5f81f398e43efd62a061a201309bfa7" category="inline-link-macro-rx"></block> 请求对内容进行更改或提供有关内容的反馈。请尽可能具体地确保您的反馈得到适当处理。</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="inline-link-macro">NetApp AI 解决方案</block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps</block>
  <block id="c8d20ce0b6bb23d912f3368f706d5794" category="summary">NetApp 解决方案是一套战略和技术功能，旨在强调 NetApp 产品和服务组合，以满足客户最关键的业务需求。</block>
  <block id="c6aaad7e04b9605d83a2a2aa661fc1b4" category="summary">借助 NetApp VDS ，管理员可以将任务委派给其他人。他们可以连接到已部署的服务器以进行故障排除，查看日志和运行审核报告。在帮助客户时，帮助台或 3 级技术人员可以根据需要对用户会话进行影子管理，查看进程列表并终止进程。</block>
  <block id="3a1e041969ddc2d8e0e399260d9159a7" category="doc">使用 Login VSI 进行单服务器负载测试</block>
  <block id="12d80b6f529069c8b2bc8d45947a0379" category="paragraph">NetApp 虚拟桌面服务使用 Microsoft 远程桌面协议来访问虚拟桌面会话和应用程序，而 Login VSI 工具可确定可在特定服务器型号上托管的最大用户数。Login VSI 可按特定时间间隔模拟用户登录，并执行用户操作，例如打开文档，阅读和撰写邮件，使用 Excel 和 PowerPoint ，打印文档，压缩文件以及随机中断。然后，它会测量响应时间。如果服务器利用率较低，则用户响应时间较短；如果添加了更多用户会话，则用户响应时间会增加。Login VSI 会根据初始用户登录会话确定基线，当用户响应超过基线 2 秒时，它会报告最大用户会话。</block>
  <block id="4be1d7a9b1a8d85ed7d1cf5c72b23928" category="paragraph">NetApp 虚拟桌面服务利用 Microsoft 远程桌面协议访问虚拟桌面会话和应用程序。为了确定可在特定服务器型号上托管的最大用户数，我们使用了 Login VSI 工具。Login VSI 可按特定时间间隔模拟用户登录，并执行用户操作，例如打开文档，阅读和撰写邮件，使用 Excel 和 PowerPoint ，打印文档，压缩文件，随机中断等。它还可测量响应时间。如果服务器利用率较低，则用户响应时间较短；如果添加了更多用户会话，则用户响应时间会增加。Login VSI 会根据初始用户登录会话确定基线，当用户响应超过基线 2 秒时，它会报告最大用户会话数。</block>
  <block id="481e9968651d6bd0d36d67a776a0f32a" category="paragraph">下表包含用于此验证的硬件。</block>
  <block id="e93f994f01c537c4e2f7d8528c3eb5e9" category="cell">计数</block>
  <block id="8417ade953d75aa6fa3c64813e005e17" category="cell">NetApp HCI H610C</block>
  <block id="ec1d568aa57f1e1231acef5759640fc6" category="cell">一个集群中有三个用于启动程序， AD ， DHCP 等。一台服务器用于负载测试。</block>
  <block id="5b68b81817d64cfa84c65e2e185efe97" category="cell">NetApp HCI H615C</block>
  <block id="c36af9ab64be0b8bd4d5097f58b8a5ba" category="cell">2 个 24C Intel Xeon Gold 6282 @2.1 GHz 。1.5 TB RAM 。</block>
  <block id="825c03a9f78635bec804883dde1bd6bf" category="paragraph">下表包含用于此验证的软件。</block>
  <block id="f80ee94fe4a9c10f8d85e442e7521687" category="cell">NetApp VDS 5.4</block>
  <block id="bb15f84d3b96a9b33719b8a71bc62207" category="cell">VM 模板 Windows 2019 1809</block>
  <block id="f6a3c0d463e2ae697b02a9893e2062a3" category="cell">适用于 RDSH 的服务器操作系统</block>
  <block id="5a264c4e5b7b75d4ead67bf3ff7988bc" category="cell">登录 VSI</block>
  <block id="5227da0541209a94c7dc0a07cf3e0740" category="cell">4.1.32.1</block>
  <block id="123995603a5e237810bf85a8e3c73f2e" category="cell">VMware vSphere 6.7 Update 3</block>
  <block id="2752fcc90cb7cc7439b827d762e89166" category="cell">VMware vCenter 6.7 Update 3f</block>
  <block id="436bc441be68b676a199df5c1ea02263" category="cell">VMware 管理工具</block>
  <block id="9ad541af6dac1be0c6655522128a386c" category="paragraph">Login VSI 测试结果如下：</block>
  <block id="17126aef3e415713552604218f448967" category="cell">VM 配置</block>
  <block id="084abcce930cefa047af15fc0836639a" category="cell">Login VSI 基线</block>
  <block id="8bb9799dff9f679e2305879f7dc1a9f0" category="cell">Login VSI 最大值</block>
  <block id="e49775052ecbe49b489c84d0b09e916e" category="cell">H610C</block>
  <block id="a9cc7da7b66d8162a44a176bb1109440" category="cell">8 个 vCPU ， 48 GB RAM ， 75 GB 磁盘， 8 Q vGPU 配置文件</block>
  <block id="28267ab848bcf807b2ed53c3a8f8fc8a" category="cell">799</block>
  <block id="8f85517967795eeef66c225f7883bdcb" category="cell">178.</block>
  <block id="bd40934d28717a37aa4087f1622d8f0b" category="cell">H615C</block>
  <block id="4052d2c7017812dc33333a4dc7e83dc9" category="cell">12 个 vCPU ， 128 GB RAM ， 75 GB 磁盘</block>
  <block id="eefc9e10ebdc4a2333b42b2dbb8f27b6" category="cell">763</block>
  <block id="7a614fd06c325499f1680b9896beedeb" category="cell">272</block>
  <block id="71c62dd6d64bb960471819c829a777fd" category="paragraph">考虑到子 NUMA 边界和超线程，选择用于 VM 测试和配置的八个 VM 取决于主机上可用的核心。</block>
  <block id="0f57e9c52f3aa2d44da0de48ac87443a" category="paragraph">我们在 H610C 上使用了 10 个启动器 VM ，这些 VM 使用 RDP 协议连接到用户会话。下图显示了 Login VSI 连接信息。</block>
  <block id="ad1351ac01d5fe0ac5546c8a2fd2d170" category="paragraph"><block ref="ad1351ac01d5fe0ac5546c8a2fd2d170" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dba4e8b5ffc06c0ccce673fd6f48159" category="paragraph">下图显示了 H610C 的 Login VSI 响应时间与活动会话的对比情况。</block>
  <block id="8d58d21e6be9e4be37d3c42935a380b5" category="paragraph"><block ref="8d58d21e6be9e4be37d3c42935a380b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65f671ed80b2c6f0cc371ab295230a3a" category="paragraph">下图显示了 H615C 的登录 VSI 响应时间与活动会话的对比情况。</block>
  <block id="72cce33d21386089f9a521f893c14d41" category="paragraph"><block ref="72cce33d21386089f9a521f893c14d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c29ae1e9123280c1975dbc407f3eca3" category="paragraph">下图显示了在对 vSphere 主机和 VM 执行 H615C 登录 VSI 测试期间 Cloud Insights 的性能指标。</block>
  <block id="d64755ae2a4094876fbaf88a161ddec2" category="paragraph"><block ref="d64755ae2a4094876fbaf88a161ddec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ccea8702c360d2d159b0e8477fe81d6" category="summary">使用 H610C 或 H615C 时， GPU 的许可证必须从有权转售许可证的 NVIDIA 合作伙伴处购买。</block>
  <block id="1f26c520bd4eba393348dedea38da7b7" category="doc">NVIDIA 许可</block>
  <block id="b548ee560d6fa4ee980d777df0300d09" category="inline-link">配对节点定位器</block>
  <block id="72d760f4e8266e660fa7126e42f63bbe" category="paragraph">使用 H610C 或 H615C 时， GPU 的许可证必须从有权转售许可证的 NVIDIA 合作伙伴处购买。您可以找到 NVIDIA 与的合作伙伴<block ref="32da44153625c96a28e5bf10161bbc42" category="inline-link-rx"></block>。搜索虚拟 GPU （ vGPU ）或 Tesla 等能力。</block>
  <block id="7709fb92e99b3458d440c5212792a0de" category="paragraph">NVIDIA vGPU 软件有四个版本：</block>
  <block id="31473f257c4cfabfcba0c506fefcf4ca" category="list-text">NVIDIA GRID 虚拟 PC （ GRID vPC ）</block>
  <block id="75cc5be2167cc23ca9d32aa78a164907" category="list-text">NVIDIA GRID 虚拟应用程序（ GRID vApp ）</block>
  <block id="53b933a69a5adecaa6c8c8817d2d87a5" category="list-text">NVIDIA Quadro 虚拟数据中心工作站（ Quadro vDWS ）</block>
  <block id="2d655109b3aad5a539482617b4aa3b6b" category="list-text">NVIDIA Virtual ComputeServer （ vComputeServer ）</block>
  <block id="38f26d9fb2d58dd577140e84010a059d" category="section-title">网格虚拟 PC</block>
  <block id="e43876de331b666ca7fd1c7bbb8a844d" category="paragraph">此产品非常适合希望使用虚拟桌面为 Microsoft Windows 应用程序，浏览器，高清视频和多显示器支持提供卓越用户体验的用户。NVIDIA GRID 虚拟 PC 可在虚拟环境中提供原生体验，让您可以以全性能运行所有 PC 应用程序。</block>
  <block id="06a4851adc711a27ef53d0577d69e210" category="section-title">网格虚拟应用程序</block>
  <block id="2c20bf668630521a8f76995b0c04c398" category="paragraph">网格 vApp 适用于部署远程桌面会话主机（ RDSH ）或其他应用程序流式或基于会话的解决方案的组织。网格 vApp 还支持 Windows Server 托管的 RDSH 桌面，旨在以全性能交付 Microsoft Windows 应用程序。</block>
  <block id="5de115addc6579e1d30075a2a92c9ae7" category="section-title">Quadro 虚拟数据中心工作站</block>
  <block id="74fec534073fb87750193748093ada5a" category="paragraph">本版本非常适合使用功能强大的 3D 内容创建应用程序的主流和高端设计人员，例如，达索 CATIA ， SOLIDWORKS ， 3dexcite ， Siemens NX ， PTC 克里奥， Schlumberg器 Petrel 或 Autodesk Maya 。通过 NVIDIA Quadro vDWS ，用户可以在任何设备上访问具有全部功能和性能的专业图形应用程序。</block>
  <block id="fb5cc5533386fd1b00e6b986dec8cba1" category="section-title">NVIDIA Virtual ComputeServer</block>
  <block id="087877c8284ea313c79d65cb22d48329" category="paragraph">许多组织都运行计算密集型服务器工作负载，例如人工智能（ AI ），深度学习（ DL ）和数据科学。对于这些使用情形， NVIDIA vComputeServer 软件可虚拟化 NVIDIA GPU ，从而通过错误更正代码，页面停用，通过 NVLink 对等和多 vGPU 等功能加快计算密集型服务器工作负载的速度。</block>
  <block id="e1f54ed77362f191ac08c4db8d9c44cd" category="admonition">使用 Quadro vDWS 许可证，您可以使用网格 vPC 和 NVIDIA vComputeServer 。</block>
  <block id="56b4cb3c337694fdafc2164dddad87fa" category="summary">GPU 通常用于通过执行重复性计算实现图形可视化（渲染）。这种重复计算功能通常用于人工智能和深度学习用例。</block>
  <block id="ca32c5a534baaf5f6dc3e6e6fed62450" category="doc">GPU 注意事项</block>
  <block id="ceeb28ce3b9ce753f02856fffb7ba66c" category="paragraph">对于图形密集型应用程序， Microsoft Azure 提供基于 NVIDIA Tesla M60 卡的 NV 系列，每个 VM 具有一到四个 GPU 。每个 NVIDIA Tesla M60 卡都包含两个基于 Maxwell 的 GPU ，每个 GPU 具有 8 GB 的 GDDR5 内存，总共 16 GB 。</block>
  <block id="cb433c3099845f0ac8f3ba53d162db7b" category="admonition">NV 系列附带 NVIDIA 许可证。</block>
  <block id="0f0c98cc175dc7cda319a35afcd199e5" category="paragraph"><block ref="0f0c98cc175dc7cda319a35afcd199e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ead26a90008a32871b53cb37bbe8431a" category="paragraph">使用 NetApp HCI 时， H615C GPU 包含三个 NVIDIA Tesla T4 卡。每个 NVIDIA Tesla T4 卡都具有一个基于旅行的 GPU ，其中包含 16 GB 的 GDDR6 内存。在 VMware vSphere 环境中使用时，虚拟机可以共享 GPU ，每个 VM 都具有专用的帧缓冲区内存。NetApp HCI H615C 上的 GPU 提供了光线跟踪功能，可以生成逼真的图像，包括光照。请注意，您需要具有一个 NVIDIA 许可证服务器，并获得 GPU 功能的许可证。</block>
  <block id="148811d448421f6a42c549400b7201c0" category="paragraph"><block ref="148811d448421f6a42c549400b7201c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc6992cca0b3d14a85c456d0890f3e37" category="paragraph">要使用 GPU ，您必须安装相应的驱动程序，此驱动程序可从 NVIDIA 许可证门户下载。在 Azure 环境中， NVIDIA 驱动程序可作为 GPU 驱动程序扩展使用。接下来，必须更新以下屏幕截图中的组策略，以便将 GPU 硬件用于远程桌面服务会话。您应确定 H.264 图形模式的优先级并启用编码器功能。</block>
  <block id="5b0ff68b017720dd46aa6d1923fdfa95" category="paragraph"><block ref="5b0ff68b017720dd46aa6d1923fdfa95" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7d3d3d6dd94c69620cd3edfb005691c" category="paragraph">使用任务管理器或在运行 WebGL 示例时使用 nvidia-smi 命令行界面验证 GPU 性能监控。确保 GPU ，内存和编码器资源已被占用。</block>
  <block id="d13ca37d387c1bb473c0343278d0477d" category="paragraph"><block ref="d13ca37d387c1bb473c0343278d0477d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f2b53ac98ef55a900849ead654ca636" category="paragraph">为了确保虚拟机部署到采用虚拟桌面服务的 NetApp HCI H615C 中，请使用包含 H615C 主机的 vCenter 集群资源定义一个站点。VM 模板必须附加所需的 vGPU 配置文件。</block>
  <block id="818fad61fba48977b2293819f37e950a" category="paragraph">对于共享多会话环境，请考虑分配多个同构 vGPU 配置文件。但是，对于高端专业图形应用程序，最好将每个 VM 专用于一个用户，以使 VM 保持隔离。</block>
  <block id="a2db30df8af33b0e661aaed00ce2c1d3" category="paragraph">GPU 处理器可以通过 QoS 策略进行控制，每个 vGPU 配置文件都可以具有专用的帧缓冲区。但是，每个卡都共享编码器和解码器。vGPU 配置文件在 GPU 卡上的放置由 vSphere 主机 GPU 分配策略控制，该策略可以强调性能（分布式 VM ）或整合（组 VM ）。</block>
  <block id="53cf9d36e61cc97b118ae4cc9589bac3" category="summary">通过 NetApp VDS Cloud Workspace Management Suite 门户，可以集中管理各种 VDS 部署，包括为内部部署，管理用户，应用程序目录和脚本化事件定义了站点的 VDS 部署。管理用户还可以使用此门户根据需要手动配置应用程序，并连接到任何计算机进行故障排除。</block>
  <block id="e68a6dedaba6faaba6e7afd9197edc4f" category="doc">管理门户</block>
  <block id="76368893e7696218fc60d77f96235f35" category="paragraph">NetApp VDS Cloud Workspace Management Suite 门户现已推出<block ref="1640f4040bca8395064a2ee51cb5f0ae" category="inline-link-rx"></block> 即将推出的版本<block ref="b6375c31f2253ef964d998b5762ba440" category="inline-link-rx"></block>。</block>
  <block id="02655da204b103696191f5d52c33427f" category="paragraph">通过该门户，可以集中管理各种 VDS 部署，包括为内部部署，管理用户，应用程序目录和脚本化事件定义了站点的 VDS 部署。管理用户还可以使用此门户根据需要手动配置应用程序，并连接到任何计算机进行故障排除。</block>
  <block id="0499b0532cd51452b57a028f3973d9fa" category="paragraph">服务提供商可以使用此门户添加自己的渠道合作伙伴，并允许他们管理自己的客户端。</block>
  <block id="aaca2e6fe88c6861582a8d1a20acfd4f" category="summary">适用于虚拟桌面服务的 ONTAP 功能。</block>
  <block id="bc9c47c8423d4537fdbf118b09a80084" category="doc">适用于虚拟桌面服务的 ONTAP 功能</block>
  <block id="472986236003195075a1428fe6103f4c" category="paragraph">以下 ONTAP 功能使其成为与虚拟桌面服务结合使用的极具吸引力的选择。</block>
  <block id="6128a47ce6baa55dbad9293234f2f65c" category="list-text">* 横向扩展文件系统。 * ONTAP FlexGroup 卷的大小可以增长到 20 PB 以上，并且可以在一个命名空间中包含 4000 亿个以上的文件。此集群最多可包含 24 个存储节点，每个节点都具有一个灵活的网络接口卡数量，具体取决于使用的型号。</block>
  <block id="960f11687b64143d44db7f4ffcb33ef2" category="paragraph">用户的虚拟桌面，主文件夹，用户配置文件容器，共享数据等可以按需增长，而无需考虑文件系统限制。</block>
  <block id="ab7ad572d2251b9b27fa0213fde8531f" category="list-text">* 文件系统分析。 * 您可以使用 XCP 工具深入了解共享数据。借助 ONTAP 9.8+ 和 ActiveIQ Unified Manager ，您可以轻松查询和检索文件元数据信息并识别冷数据。</block>
  <block id="885f3e34ca03dc8ff35c0bac51b384f7" category="list-text">* 云分层。 * 您可以将冷数据迁移到云中的对象存储或数据中心中任何与 S3 兼容的存储。</block>
  <block id="fb38ee94b865e67571a08316a3baac38" category="list-text">* 文件版本。 * 用户可以恢复受 NetApp ONTAP Snapshot 副本保护的文件。ONTAP Snapshot 副本非常节省空间，因为它们仅记录更改的块。</block>
  <block id="9b7db1dd6f422e5f07ded1d3b7b04d90" category="list-text">* 全局命名空间。 * ONTAP FlexCache 技术支持文件存储远程缓存，便于在包含 ONTAP 存储系统的各个位置之间管理共享数据。</block>
  <block id="827aa7cb1ad6ddbf99e040efe34725a8" category="list-text">* 安全多租户支持。 * 一个物理存储集群可以呈现为多个虚拟存储阵列，每个阵列都有自己的卷，存储协议，逻辑网络接口，身份和身份验证域，管理用户等。因此，您可以在多个业务单位或环境之间共享存储阵列，例如测试，开发和生产。</block>
  <block id="6c36afe01468d888b334a4432dcac4b2" category="paragraph">为了保证性能，您可以使用自适应 QoS 根据已用空间或已分配空间设置性能级别，并且可以使用配额控制存储容量。</block>
  <block id="b1a678f5f86de8ff8a5b9b1c4b3772b8" category="list-text">* VMware 集成。 * 适用于 VMware vSphere 的 ONTAP 工具提供了一个 vCenter 插件，用于配置数据存储库，实施 vSphere 主机最佳实践以及监控 ONTAP 资源。</block>
  <block id="9b12997ae1d332c9003c444a6ff8918a" category="paragraph">ONTAP 支持 vStorage APIs for Array Integration （ VAAI ）将 SCSI/ 文件操作卸载到存储阵列。ONTAP 还支持用于存储感知的 vStorage API （ VASA ），并支持对块和文件协议使用虚拟卷。</block>
  <block id="025e05e390f2d7ef7708bb42d81e1eeb" category="paragraph">适用于 VMware vSphere 的 SnapCenter 插件可通过存储阵列上的 Snapshot 功能轻松备份和还原虚拟机。</block>
  <block id="3452f822915108b5d640f3288959e7fd" category="paragraph">ActiveIQ Unified Manager 可在 vSphere 环境中提供端到端存储网络可见性。管理员可以轻松识别 ONTAP 上托管的虚拟桌面环境中可能发生的任何延迟问题。</block>
  <block id="c9559fb9abb51cf76cc973d06c7e730c" category="list-text">* 安全合规性。 * 借助 ActiveIQ Unified Manager ，您可以通过警报监控多个 ONTAP 系统，以发现任何策略违规。</block>
  <block id="875c0a88cb08e888c642bbcc19cb33a2" category="list-text">* 多协议支持。 * ONTAP 支持块（ iSCSI ， FC ， FCoE 和 NVMe/FC ），文件（ NFSv3 ， NFSv4.1 ， SMB2.x 和 SMB3.x ）以及对象（ S3 ）存储协议。</block>
  <block id="4ac79aa8e1431a96a08ba58c1e17a104" category="list-text">* 自动化支持。 * ONTAP 提供 REST API ， Ansible 和 PowerShell 模块，可通过 VDS 管理门户自动执行任务。</block>
  <block id="b5ed404fa434aeee227f550cddf89892" category="inline-link">NetApp 云</block>
  <block id="d823edbaf98641c5959f3a596de3df66" category="list-text"><block ref="d823edbaf98641c5959f3a596de3df66" category="inline-link-rx"></block></block>
  <block id="b1eb0510d1bc6ffab71faa53637ecde2" category="inline-link">NetApp VDS 产品文档</block>
  <block id="c5b41ed257411dffc1cc80a4c00cf17c" category="list-text"><block ref="c5b41ed257411dffc1cc80a4c00cf17c" category="inline-link-rx"></block></block>
  <block id="272427e7f4e6650df3749f83086acde6" category="inline-link">使用 VPN 网关将内部网络连接到 Azure</block>
  <block id="c460b4e40e6d4709ed15a2e8dba39833" category="list-text"><block ref="c460b4e40e6d4709ed15a2e8dba39833" category="inline-link-rx"></block></block>
  <block id="440e11297e8634c052b1bfd29a90309c" category="inline-link">Azure 门户</block>
  <block id="8284aff5fcde6ba43a0ca21712739cae" category="list-text"><block ref="8284aff5fcde6ba43a0ca21712739cae" category="inline-link-rx"></block></block>
  <block id="8867b143d669949d3948e3816324ec75" category="inline-link">Microsoft Windows 虚拟桌面</block>
  <block id="0db816b3393ed224b26131285b4e3dff" category="list-text"><block ref="0db816b3393ed224b26131285b4e3dff" category="inline-link-rx"></block></block>
  <block id="7c033f9cfba6e06ff2ee6cb852ce10f4" category="inline-link">Azure NetApp Files 注册</block>
  <block id="aff481c4855a001492901fbefcab7d17" category="list-text"><block ref="aff481c4855a001492901fbefcab7d17" category="inline-link-rx"></block></block>
  <block id="4725a4744390b735ea1bb4e3fc99b686" category="section-title">存储节点</block>
  <block id="0f66538edca95cf4d42667cfa5d6a362" category="section-title">计算节点</block>
  <block id="60ece3fee8421729100872ec44f1cda9" category="summary">在部署过程中，您可以选择文件服务方法来托管用户配置文件，共享数据和主驱动器文件夹。可用选项包括文件服务器， Azure 文件或 Azure NetApp Files 。但是，在部署后，您可以使用命令中心工具修改此选项，使其指向任何 SMB 共享。使用 NetApp ONTAP 托管具有多种优势。</block>
  <block id="568483e9bd85504f3c9dcef24ecd3235" category="doc">数据管理</block>
  <block id="1b8c33cc721641b8b0555f2d7b5c2773" category="inline-link-macro">使用 NetApp ONTAP 托管具有多种优势</block>
  <block id="ef9fd867f3eaed93e0806bd027825218" category="inline-link">更改数据层</block>
  <block id="698e77d7e678617a2ae27ca2525bfbf7" category="paragraph">在部署过程中，您可以选择文件服务方法来托管用户配置文件，共享数据和主驱动器文件夹。可用选项包括文件服务器， Azure 文件或 Azure NetApp Files 。但是，在部署后，您可以使用命令中心工具修改此选项，使其指向任何 SMB 共享。 <block ref="50056d02f0a90e2e837160c093f1b22b" category="inline-link-macro-rx"></block>。要了解如何更改 SMB 共享，请参见<block ref="336429df384a16f14c12cbc8dba62525" category="inline-link-rx"></block>。</block>
  <block id="24e6e2f6171b43a847fe194a9a9b5cd0" category="section-title">全局文件缓存</block>
  <block id="ce29b83c61cdf6a56b49dbde9a4d57e0" category="paragraph">如果用户分布在全局命名空间的多个站点上，则全局文件缓存有助于减少频繁访问的数据的延迟。可以使用配置收集和脚本化事件自动部署全局文件缓存。全局文件缓存可在本地处理读写缓存，并在不同位置保持文件锁定。全局文件缓存可用于任何 SMB 文件服务器，包括 Azure NetApp Files 。</block>
  <block id="87db7a122a37ab4a28f2223fa123a5be" category="paragraph"><block ref="87db7a122a37ab4a28f2223fa123a5be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d726de6a27bb533c6c8c44ea508dffa8" category="paragraph">全局文件缓存需要满足以下要求：</block>
  <block id="2f28046ff208122796d51bafd8d4bc9c" category="list-text">管理服务器（许可证管理服务器）</block>
  <block id="83168e6cb289d732cc78427b51f93153" category="list-text">核心</block>
  <block id="e7704357fe6a312ecafae725be93b8c2" category="list-text">具有足够磁盘容量以缓存数据的边缘</block>
  <block id="d70c88e6a13ca1af40b966d8d7d831c4" category="inline-link">GFC 文档</block>
  <block id="154c48fd725e7207d36baa74bba5fd7a" category="paragraph">要下载软件并计算 Edge 的磁盘缓存容量，请参见<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>。</block>
  <block id="1afc494dd7d35016d9524e06b68dbf2a" category="paragraph">为了进行验证，我们在 Azure 的同一个虚拟机上部署了核心资源和管理资源，并在 NetApp HCI 上部署了边缘资源。请注意，核心是需要进行大量数据访问的位置，边缘是核心的一部分。安装软件后，您必须激活已激活的许可证，然后才能使用。为此，请完成以下步骤：</block>
  <block id="70366038f1d44fef6c71f615b677b9cf" category="list-text">在 License Configuration 部分下，使用链接 Click here 完成许可证激活。然后注册核心。</block>
  <block id="a51a182b58a11b12770fbd2bd9643852" category="paragraph"><block ref="a51a182b58a11b12770fbd2bd9643852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d666527802938c89b9f895300aea220b" category="list-text">提供用于全局文件缓存的服务帐户。有关此帐户所需的权限，请参见<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>。</block>
  <block id="ab698dd081619e8f6dc264df6c99b73e" category="paragraph"><block ref="ab698dd081619e8f6dc264df6c99b73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b1486d5cfb9e0c5394a50e2515b53c" category="list-text">添加新的后端文件服务器并提供文件服务器名称或 IP 。</block>
  <block id="ffeac1f6b14ca75f608539cb6c673f37" category="paragraph"><block ref="ffeac1f6b14ca75f608539cb6c673f37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="643c94b6eb5664ed3cca98d31d7dbd39" category="list-text">在边缘上，缓存驱动器必须具有驱动器盘符 D如果不是，请使用 diskpart.exe 选择卷并更改驱动器号。以边缘身份向许可证服务器注册。</block>
  <block id="e9b41aa1ac49113064748a9c6e0f48a9" category="paragraph"><block ref="e9b41aa1ac49113064748a9c6e0f48a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="156666d997fd17a94bed67fe95334273" category="paragraph">如果启用了核心自动配置，则会自动从许可证管理服务器检索核心信息。</block>
  <block id="891d862f33aaeafcd8ecc43e102febd3" category="paragraph"><block ref="891d862f33aaeafcd8ecc43e102febd3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2184b1f206fd35eeb448e9937bdabe7" category="paragraph">在任何客户端计算机上，用于访问文件服务器上共享的管理员都可以使用 UNC 路径 ` \\&lt; 边缘服务器名称 &gt;\FASTDATA\&lt; 核心服务器名称 &gt;\&lt; 后端文件服务器名称 &gt;\&lt; 共享名称 &gt;` 使用 GFC 边缘访问该共享。管理员可以将此路径包含在用户登录脚本或 GPO 中，以便在边缘位置映射用户驱动器。</block>
  <block id="a08e5ca253097ac5ad7741e20d9dd090" category="paragraph">为了为全球用户提供透明的访问权限，管理员可以设置 Microsoft 分布式文件系统（ DFS ），使其链接指向文件服务器共享和边缘位置。</block>
  <block id="0c9f570b7b5b34f0fbdab873e122d432" category="paragraph"><block ref="0c9f570b7b5b34f0fbdab873e122d432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9e8ad2bf50c8da3a637a8858d3a1391" category="paragraph">当用户根据与站点关联的子网使用 Active Directory 凭据登录时， DFS 客户端将使用相应的链接来访问数据。</block>
  <block id="6a6b2107f2b5daadfd13df04f769a587" category="paragraph"><block ref="6a6b2107f2b5daadfd13df04f769a587" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8aabec6a7d3f54b83478824808357c91" category="paragraph">文件图标会根据文件是否已缓存而变化；未缓存的文件在图标的左下角显示灰色 X 。边缘位置的用户访问某个文件后，该文件将被缓存，并且图标将发生变化。</block>
  <block id="1014b6d5d432758e9041c845e4da7830" category="paragraph"><block ref="1014b6d5d432758e9041c845e4da7830" category="inline-image-macro-rx" type="image"></block></block>
  <block id="610eee89db61eda57b4b6da39d799845" category="paragraph">如果某个文件已打开，而另一个用户正在尝试从边缘位置打开同一文件，则系统会提示用户选择以下内容：</block>
  <block id="5a31b6c180e91d3c3d3c1053bbab642c" category="paragraph"><block ref="5a31b6c180e91d3c3d3c1053bbab642c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c6f3b21447f91b42ceee404afc53720" category="paragraph">如果用户选择在原始副本可用时接收通知的选项，则系统会按如下所示通知用户：</block>
  <block id="922c6f30fa0f74f32df2fac11a3bf378" category="paragraph"><block ref="922c6f30fa0f74f32df2fac11a3bf378" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b9bc3a03a8ae9cef2c5a66238e5ab25" category="inline-link">有关 Talon 和 Azure NetApp Files 部署的视频</block>
  <block id="e725329a19c23f541a0bdbead9c9b1e7" category="paragraph">有关详细信息，请参见此<block ref="92818ea025c5b78ace999366164c2c46" category="inline-link-rx"></block>。</block>
  <block id="fc95bd8bc19564339fe05c7bad1b7662" category="section-title">SaaS 备份</block>
  <block id="482cadbeebfa6f9c4f062c1f2724d546" category="paragraph">NetApp VDS 可为 Salesforce 和 Microsoft Office 365 （包括 Exchange ， SharePoint 和 Microsoft OneDrive ）提供数据保护。下图显示了 NetApp VDS 如何为这些数据服务提供 SaaS Backup 。</block>
  <block id="0e3aff181138166393e5e5e698c994d2" category="paragraph"><block ref="0e3aff181138166393e5e5e698c994d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="201e09e85ad81db8a19ef9f20c05d1a5" category="inline-link">此视频</block>
  <block id="4cde65566156674196c087d89ded5c3b" category="paragraph">有关 Microsoft Office 365 数据保护的演示，请参见<block ref="158107d7e819a2ef8c2e8f24519fc9a9" category="inline-link-rx"></block>。</block>
  <block id="a067b7082c28e7dbf856ab55b29d1acb" category="paragraph">有关 Salesforce 数据保护的演示，请参见<block ref="dd6e5767407887626a36af7b68defda9" category="inline-link-rx"></block>。</block>
  <block id="7b0f97bc4856c6b0645650d13b53acb5" category="summary">如果内部资源与云资源之间存在连接，则可以将 NetApp 虚拟桌面服务扩展到内部环境。企业可以使用 Express Route 或站点间 IPsec VPN 连接建立与 Microsoft Azure 的链接。您也可以使用专用链路或使用 IPsec VPN 通道以类似方式创建指向其他云的链接。</block>
  <block id="995d0ae58fc48c0007c3a45046221736" category="doc">混合云环境</block>
  <block id="610e3513c7222cae8d2a7c450741211a" category="paragraph">在解决方案验证中，我们使用了下图所示的环境。</block>
  <block id="0d9e9a129d4eb3389af12248eb017ef1" category="paragraph"><block ref="0d9e9a129d4eb3389af12248eb017ef1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60ca94382604fd3deb8a198feed31f1b" category="paragraph">在内部环境中，我们有多个 VLAN 用于管理，远程桌面会话主机等。它们位于 172.21.146-150.0/24 子网中，并使用 Microsoft 远程路由访问服务路由到公司网络。我们还执行了以下任务：</block>
  <block id="b613a58cb27d96b09550b74a616e43d8" category="list-text">我们注意到了 Microsoft 路由和远程访问服务器（ RRAS ；标识为 IPchicken.com ）的公有 IP 。</block>
  <block id="b0aa9d967a62cfeb9427c31c3968fb31" category="list-text">我们在 Azure 订阅上创建了虚拟网络网关资源（基于路由的 VPN ）。</block>
  <block id="2db3e884a3b1d82162c06df081b8e8f0" category="list-text">我们创建了一个连接，用于为 Microsoft RRAS 服务器的公有 IP 提供本地网络网关地址。</block>
  <block id="ac7b5e31749488bdca809cc69e83bcec" category="list-text">我们在 RRAS 上完成了 VPN 配置，以便使用创建 VPN 网关时提供的预共享身份验证创建虚拟接口。如果配置正确，则 VPN 应处于已连接状态。您还可以使用 pfsense 或其他相关工具创建站点到站点的 IPsec VPN 通道，而不是 Microsoft RRAS 。由于此通道基于路由，因此会根据配置的特定子网重定向流量。</block>
  <block id="064b2713bd54ad7c04715d629ea8d77e" category="paragraph">Microsoft Azure Active Directory 基于 OAuth 提供身份身份验证。企业客户端身份验证通常需要 NTLM 或基于 Kerberos 的身份验证。Microsoft Azure Active Directory 域服务使用 ADConnect 在 Azure Active Directory 和内部域控制器之间执行密码哈希同步。</block>
  <block id="c9ced395d02e614104c13dc687b8d960" category="paragraph">对于此混合 VDS 解决方案验证，我们最初会部署到 Microsoft Azure ，并使用 vSphere 添加了一个额外的站点。此方法的优势在于，平台服务已部署到 Microsoft Azure ，然后可以使用该门户随时进行备份。这样，即使站点 - 站点 VPN 链路已关闭，也可以从任意位置轻松访问服务。</block>
  <block id="759e5787427ba679d146727a04400c46" category="paragraph">要添加其他站点，我们使用了一个名为 DCConfig 的工具。该应用程序的快捷方式可在 Cloud Workspace Manager （ CWMgr ） VM 的桌面上找到。启动此应用程序后，导航到 "DataCenter 站点 " 选项卡，添加新的数据中心站点并填写所需信息，如下所示。此 URL 指向 vCenter IP 。在添加配置之前，请确保 CWMgr 虚拟机可以与 vCenter 进行通信。</block>
  <block id="ae5bd963078c278284e2aabaefb99232" category="admonition">确保在 CloudWorkspace Manager 上安装 vSphere PowerCLI 5.1 ，以便能够与 VMware vSphere 环境进行通信。</block>
  <block id="e0072a2f037098ba3ee9ec9e1113f1ee" category="paragraph">下图显示了内部数据中心站点配置。</block>
  <block id="30efb5f8dd999c0f737bf30327346d6f" category="paragraph"><block ref="30efb5f8dd999c0f737bf30327346d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f823fddfaa31c0b2b910c651849fe1e0" category="paragraph">请注意，可以根据特定集群，主机名或可用 RAM 空间为计算资源提供筛选选项。存储资源的筛选选项包括数据存储库上的最小可用空间或每个数据存储库的最大 VM 数。可以使用正则表达式排除数据存储库。单击保存按钮以保存配置。</block>
  <block id="40cf95c01dfbdb8adc110507697330bf" category="paragraph">要验证配置，请单击测试按钮或单击加载虚拟机管理程序，然后选中 vSphere 部分下的任何下拉列表。应使用适当的值填充它。对于默认配置站点，最好将主虚拟机管理程序设置为 yes 。</block>
  <block id="b081b97ab471a870119bb85e196c0d63" category="paragraph">在 VMware vSphere 上创建的 VM 模板将用作 VDS 上的配置集合。配置集合有两种形式：共享和 VDI 。共享配置收集类型用于远程桌面服务，对于这些服务，所有服务器都应用一个资源策略。VDI 类型用于单独分配资源策略的 WVD 实例。可以为配置集合中的服务器分配以下三个角色之一：</block>
  <block id="9a0b479d2d7eaed435c14e20818841d9" category="list-text">终端服务和数据服务器角色的 * TSDATA.* 组合。</block>
  <block id="286b69ba39f77189135fbf4c39786e12" category="list-text">* 终端服务 * （会话主机）。</block>
  <block id="0b39ab3df8d28606b4bb8f5891022692" category="list-text">* 数据。 * 文件服务器或数据库服务器。定义服务器角色时，必须选择 VM 模板和存储（数据存储库）。选择的数据存储库可以限制为特定的数据存储库，也可以使用 " 使用最少 " 选项，在该选项中，系统会根据数据使用情况选择数据存储库。</block>
  <block id="fb89cc64fafb0e1626269bc00c07ae73" category="paragraph">每个部署都根据 Active Users ， Fixed ， Server Load 或 User Count 为云资源分配设置了 VM 资源默认值。</block>
  <block id="18dbdef148da0fb68861cf1b6aeeeb40" category="summary">通过采用 NetApp VDS 的混合 VDI ，服务提供商和企业虚拟桌面管理员可以轻松地将资源扩展到其他云环境，而不会影响其用户。在 NetApp HCI 上部署内部资源可以更好地控制 GPU 资源，并允许您根据需要扩展计算或存储节点。</block>
  <block id="0fe8a299bf61a0d1bbca5d975dc94fcc" category="paragraph">通过采用 NetApp VDS 的混合 VDI ，服务提供商和企业虚拟桌面管理员可以轻松地将资源扩展到其他云环境，而不会影响其用户。拥有内部资源可以更好地控制资源，并提供多种选择（计算， GPU ，存储和网络）来满足需求。</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">此解决方案适用场景的使用情形如下：</block>
  <block id="f9bfa55b1c8ab8884a1452fa3c9cb975" category="list-text">突发到云中，以应对对远程桌面和应用程序的需求激增</block>
  <block id="6b53dc409ecc50a533e93345ddf1f2ee" category="list-text">通过在内部使用闪存存储和 GPU 资源托管远程桌面和应用程序，降低长期运行的 TCO</block>
  <block id="f1de7e15d0b0c3caaafa1a47204338c7" category="list-text">跨云环境轻松管理远程桌面和应用程序</block>
  <block id="f9ce5b54f5428c82364a39f17156cc4f" category="list-text">使用软件即服务模式和内部资源体验远程桌面和应用程序</block>
  <block id="675ee473db5bbe3911c19a4e43f8ec3f" category="list-text">希望了解混合 VDS 要求的 EUC /VDI 架构师</block>
  <block id="a7f381741a2ff77b61bc4b7bc2e3d04f" category="list-text">希望帮助客户满足远程桌面和应用程序需求的 NetApp 合作伙伴</block>
  <block id="efa648658230830c2b9ac1a0647002d7" category="list-text">希望满足远程桌面和应用程序需求的现有 NetApp HCI 客户</block>
  <block id="b4f83b03956523a39e8bbbd0895f0f29" category="section-title">Cloud Insights</block>
  <block id="52f9ec21735243ad9917cda3ca077d32" category="section-title">GPU</block>
  <block id="3d564c1c20cf4265a5094ead9dc937f6" category="paragraph">NetApp 公司 Suresh ThopPay</block>
  <block id="64241e0b33fb869cb12ff8e1ec74f806" category="summary">NetApp VDS 使用 Azure Active Directory 进行身份验证，使用 Azure Active Directory 域服务进行 NTLM/Kerberos 身份验证。ADConnect 工具可用于将内部 Active Directory 域与 Azure Active Directory 同步。</block>
  <block id="92726ab5faeb2cb9208eaac9af0346bd" category="doc">用户管理</block>
  <block id="c758de7e1477d6707c6709441d41a5e9" category="paragraph">可以从门户添加新用户，也可以为现有用户启用云工作空间。工作空间和应用程序服务的权限可以由单个用户或组控制。从管理门户中，可以定义管理用户来控制门户，工作空间等的权限。</block>
  <block id="b1bb3db86aec5efef6f7cc0d0d7c6331" category="paragraph">下图显示了 NetApp VDS 中的用户管理。</block>
  <block id="ed5018356119de97fa1ab09c0eeab65a" category="paragraph"><block ref="ed5018356119de97fa1ab09c0eeab65a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1350c851c78a6cdb31c6fe46ddb499c2" category="paragraph">每个工作空间都位于云工作空间 OU 下自己的 Active Directory 组织单位（ OU ）中，如下图所示。</block>
  <block id="a5484d6de39aa020af1aa382d6d52c5e" category="paragraph"><block ref="a5484d6de39aa020af1aa382d6d52c5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3fad2f68853fae9ef870ed5535896790" category="paragraph">有关详细信息，请参见<block ref="b5d59c719b42a4e7d2b711482aa2f54d" category="inline-link-rx"></block> 有关 NetApp VDS 中的用户权限和用户管理的信息。</block>
  <block id="48a8649f1ce9d97848d70480ce7fea9c" category="paragraph">如果使用数据中心的 API 调用将 Active Directory 组定义为 CRAUserGroup ，则该组中的所有用户都将导入到 CloudWorkspace 中，以便使用 UI 进行管理。为用户启用云工作空间后， VDS 将创建用户主文件夹，设置权限，用户属性更新等。</block>
  <block id="9e30d1bf5e5278a123ad0ddab43066b7" category="paragraph">如果选中 VDI User Enabled ，则 VDS 将创建一个专用于该用户的单会话 RDS 计算机。它会提示您配置模板和数据存储库。</block>
  <block id="093d2ddf98cacaf853b6f986ca9bd647" category="paragraph"><block ref="093d2ddf98cacaf853b6f986ca9bd647" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57eae0e26c1c0bbaec9110d010f68f7a" category="summary">NetApp HCI 是一种混合云基础架构，由多个存储节点和计算节点组成。根据型号的不同，它可以是双机架单元或单机架单元。部署 VM 所需的安装和配置通过 NetApp 部署引擎（ NDE ）自动完成。计算集群通过 VMware vCenter 进行管理，存储集群通过使用 NDE 部署的 vCenter 插件进行管理。</block>
  <block id="855faa205a8f23993f1a0fe1ac2cde2f" category="doc">NetApp HCI 概述</block>
  <block id="95404d16cb98456e438a61d79a0a31d9" category="paragraph">NetApp HCI 是一种混合云基础架构，由多个存储节点和计算节点组成。根据型号的不同，它可以是双机架单元或单机架单元。部署 VM 所需的安装和配置通过 NetApp 部署引擎（ NDE ）自动完成。计算集群通过 VMware vCenter 进行管理，存储集群通过使用 NDE 部署的 vCenter 插件进行管理。名为 mNode 的管理 VM 会作为 NDE 的一部分进行部署。</block>
  <block id="b6ab683d50d83f639ae697569117a54b" category="paragraph">NetApp HCI 可处理以下功能：</block>
  <block id="d15278d453245d004f8fd55cff421171" category="list-text">版本升级</block>
  <block id="b783caf332f2c3190dcb6ced64290f5a" category="list-text">将事件推送到 vCenter</block>
  <block id="79adeb760f6909dd746e1e7adae6cd58" category="list-text">vCenter 插件管理</block>
  <block id="a45e04274259a13dff2a10641a0fd97f" category="list-text">用于支持的 VPN 通道</block>
  <block id="227590ca6f7ff3f3cc72e49cf277625f" category="list-text">NetApp Active IQ 收集器</block>
  <block id="b0088ee645cccd0951013eb53d0b3816" category="list-text">将 NetApp 云服务扩展到内部环境，实现混合云基础架构。下图显示了 HCI 组件。</block>
  <block id="1a811712e3bea62b6f5bd1851b149fc3" category="paragraph"><block ref="1a811712e3bea62b6f5bd1851b149fc3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65f0d96af236e344bd739fd20df1fa5d" category="paragraph">存储节点可用作半宽或全宽机架单元。首先至少需要四个存储节点，一个集群最多可扩展到 40 个节点。一个存储集群可以在多个计算集群之间共享。所有存储节点都包含一个缓存控制器，用于提高写入性能。单个节点可提供 50 ， 000 或 100 ， 000 IOPS ，块大小为 4 k 。</block>
  <block id="d31f04e865057f7055f2d8287b92ba2d" category="paragraph">NetApp HCI 存储节点运行 NetApp Element 软件，该软件可提供最小，最大和突发 QoS 限制。存储集群支持混合使用多个存储节点，但一个存储节点不能超过总容量的三分之一。</block>
  <block id="449aaf51a6dfa9c0e17423ae5938d674" category="inline-link">《 VMware 兼容性指南》</block>
  <block id="1046a3e2377d26c40f75eb2cd2f268da" category="admonition">NetApp 支持将其存储连接到中列出的任何计算服务器<block ref="72cc7e3e2b2d7f777e05aa309ef5f733" category="inline-link-rx"></block>。</block>
  <block id="bc1a52314ab38efacf0a83e9df0b01cc" category="paragraph">计算节点提供半宽，全宽和两种机架单元大小。NetApp HCI H410C 和 H610C 基于可扩展的 Intel Skylake 处理器。H615C 基于第二代可扩展 Intel 级联湖处理器。有两种计算型号包含 GPU ： H610C 包含两个 NVIDIA M10 卡， H615C 包含三个 NVIDIA T4 卡。</block>
  <block id="683876986e8fe1045fa768b4a8675ea9" category="paragraph"><block ref="683876986e8fe1045fa768b4a8675ea9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9667ae1b4be7e4c088e175844fd675e6" category="paragraph">NVIDIA T4 具有 40 个 RT 核心，可提供实时光线跟踪所需的计算能力。现在，设计师和工程师使用的相同服务器模式也可供艺术家用来创建照片级的图像，使表面的光像实际生活中的光弹出一样。这种支持 RTX 的 GPU 可实现高达每秒 5 GB 的实时光线跟踪性能。NVIDIA T4 与 Quadro 虚拟数据中心工作站（ Quadro vDWS ）软件相结合，可帮助艺术家从任何位置在任何设备上创建具有准确阴影，镜像和折光效果的照片级设计。</block>
  <block id="bee5034948808ff859affdc8ba03b52c" category="paragraph">利用 Tensor 核心，您可以运行深度学习推理工作负载。在运行这些工作负载时，采用 Quadro vDWS 的 NVIDIA T4 的性能比纯 CPU 服务器驱动的虚拟机快多达 25 倍。NetApp H615C 在一个机架单元中具有三个 NVIDIA T4 卡，是图形和计算密集型工作负载的理想解决方案。</block>
  <block id="1f99f286804bf2f5a91a1cdd1733decf" category="paragraph">下图列出了 NVIDIA GPU 卡并对其功能进行了比较。</block>
  <block id="67c0c3f98979352a9ed10f0de3d551f3" category="paragraph"><block ref="67c0c3f98979352a9ed10f0de3d551f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b4fc2931642829391b479ea5fb1e9d" category="paragraph">对于知识型员工使用情形， M10 GPU 仍然是最佳的 TCO 解决方案。但是，如果要在 GPU 上进行标准化，而 GPU 可用于多种使用情形，例如虚拟工作站，图形性能，实时交互式渲染和推理，则 T4 是一个很好的替代方案。借助 T4 ， IT 可以利用相同的 GPU 资源来运行混合工作负载―例如，在白天运行 VDI ，并将资源重新用于在夜间运行计算工作负载。</block>
  <block id="bdced20c33601e0149aecb44114cfdc5" category="paragraph">H610C 计算节点的大小为两个机架单元； H615C 的大小为一个机架单元，耗电较少。H615C 支持 H.264 和 H.265 （高效视频编码（ High Efficiency Video Coding ， HEVC ） 4 ： 4 ： 4 编码和解码。此外，它还支持越来越主流的 VP9 解码器；即使 YouTube 提供的 Web 容器软件包也会使用 VP9 编解码器来处理视频。</block>
  <block id="fe046fc197d12a64da1ea78423a2a809" category="paragraph">计算集群中的节点数由 VMware 决定；目前，使用 VMware vSphere 7.0 Update 1 时为 96 个。启用增强型 vMotion 兼容性（ EVC ）后，支持在集群中混用不同型号的计算节点。</block>
  <block id="868ab86f19065016e9a2f077c5ec1ede" category="summary">任务工作人员可以从可供其使用的应用程序列表中快速启动应用程序。应用程序服务从远程桌面服务会话主机发布应用程序。借助 WVD ，应用程序组可从多会话 Windows 10 主机池提供类似的功能。</block>
  <block id="aa08bd8b0522ea3a5e9ace598db7162c" category="doc">应用程序管理</block>
  <block id="f83a66a518ff3f3f44725a09d9666710" category="paragraph">对于为用户提供支持的办公室员工，可以使用服务板手动配置所需的应用程序，也可以使用 NetApp VDS 中的脚本化事件功能自动配置这些应用程序。</block>
  <block id="546d3f7d3bb8a664a6ba4a3fb2f68c30" category="inline-link">NetApp 应用程序授权页面</block>
  <block id="175ba74f5b7d0ecd3f531c5fce21a240" category="paragraph">有关详细信息，请参见<block ref="03e02ecfc967e94041a86f599e14ac44" category="inline-link-rx"></block>。</block>
  <block id="91af64270656f51ceebeabc4b79ecb07" category="summary">NetApp VDS 可以使用根据所需代码库提供的设置应用程序部署到 Microsoft Azure 。</block>
  <block id="29707848401dd26f02baed07b9a416c1" category="paragraph">NetApp VDS 可以使用根据所需代码库提供的设置应用程序部署到 Microsoft Azure 。当前版本可用<block ref="deb5bc0c1293f06a53a77d04b921abbd" category="inline-link-rx"></block> 即将推出的产品的预览版现已发布<block ref="b5073644bfe6db36c388c6bdbca64b49" category="inline-link-rx"></block>。</block>
  <block id="c4e1987e3c1416cefd772fd61f28dfb4" category="paragraph">请参见<block ref="f8270911b627accef36841f0608bc58d" category="inline-link-rx"></block> 有关部署说明，请参见。</block>
  <block id="bf6d8e47240024519d1dbb6f5582ce66" category="summary">图形工作站通常用于制造业，医疗保健，能源，媒体和娱乐，教育， 架构等。对于图形密集型应用程序，移动性往往受到限制。</block>
  <block id="942cd85feff07ce32d619d2f724254a8" category="doc">行业解决方案</block>
  <block id="fb987436787e4263bfee440b93703026" category="paragraph">为了解决移动性问题描述问题，虚拟桌面服务可以使用云中的硬件资源或 NetApp HCI 为从任务员工到专家用户的所有类型的员工提供桌面环境，包括灵活的 GPU 配置选项。VDS 支持用户使用笔记本电脑，平板电脑和其他移动设备从任意位置访问工作环境。</block>
  <block id="68ae3286d2356ff8dd51c2a397ca20eb" category="paragraph">要使用 ANSYS Fluent ， ANSYS MechanIC ， AutoDESCad ， AutoDESCIGAN ， AutoDESCUTE VENIGAN ， AutoDESCKS Max 等软件运行制造工作负载， ｛ \f4 ｝ ｛ \f4 ｝ ｛ \f4 ｝ ｛ \f4 ｝ ｛ Systèmes \f4 ｝ ｛ \f4 ｝ ｛ \f4 ｝ ｛ \f4 ｝ ｛ \f4 ｝ ｛ \f4 ｝ ｛ Systèmes 下表列出了各种云（截至 2021 年 1 月）上可用的 GPU 。</block>
  <block id="f5168df5bb95078acdfb440f5975a601" category="cell">GPU 型号</block>
  <block id="1668ca1bd914c1d847f23b491319ac91" category="cell">Microsoft Azure</block>
  <block id="b314ebdba178173db01ffda8d3a5af67" category="cell">Google 计算（ GCP ）</block>
  <block id="943ca3782b28d89aff2f86a50b332b3c" category="cell">Amazon Web Services （ AWS ）</block>
  <block id="8df8a98ff17d4d77329f5da80da051e8" category="cell">内部部署（ NetApp HCI ）</block>
  <block id="aaba9e920b39aa997c69800a9e589cd4" category="cell">NVIDIA M60</block>
  <block id="e095ad80d900786110d53ecd5cbd3e3e" category="cell">NVIDIA T4</block>
  <block id="c909ed1507c6d5537f0cc0966e83d3f1" category="cell">NVIDIA P100</block>
  <block id="c015c1cc95335d3b867c145c056df10b" category="cell">NVIDIA P4</block>
  <block id="e8130bb14c9382769c22861fb54683b3" category="paragraph">此外，还提供与其他用户的共享桌面会话以及专用个人桌面。虚拟桌面可以具有一到四个 GPU ，也可以在 NetApp HCI 中使用部分 GPU 。NVIDIA T4 是一款多功能 GPU 卡，可满足各种用户工作负载的需求。NetApp HCI H615C 上的每个 GPU 卡都有 16 GB 的帧缓冲区内存，每个服务器有三个卡。可以托管在一个 H615C 服务器上的用户数量取决于用户工作负载。</block>
  <block id="4d8b78a5288c49df59136421211718c9" category="cell">用户 / 服务器</block>
  <block id="704316eb872cbca84a8b30d74c2708a4" category="cell">轻型（ 4 GB ）</block>
  <block id="6f3a945a32dd8eba9f2fae42715f7246" category="cell">中型（ 8 GB ）</block>
  <block id="adb5e5b63d256f3854fc7276b3e8d14a" category="cell">重磅（ 16 GB ）</block>
  <block id="8938ba807f25f2cd88559b9f84bbc3de" category="paragraph">要确定用户类型，请在用户使用执行典型任务的应用程序时运行 GPU 配置程序工具。GPU 配置程序可捕获内存需求，显示数量以及用户所需的分辨率。然后，您可以选择满足您要求的 vGPU 配置文件。</block>
  <block id="1b014a2b6e4c329b9696aae7afac88db" category="paragraph">使用 GPU 的虚拟桌面可支持高达 8K 的显示分辨率，而实用程序 nView 可将一个监控器拆分为多个区域，以便使用不同的数据集。</block>
  <block id="30f1a84c728d67b9606115a1531aa9c3" category="paragraph">借助 ONTAP 文件存储，您可以实现以下优势：</block>
  <block id="826f3d14d0c34cd0f8ced37e07a1537d" category="list-text">一个命名空间，可通过 4000 亿个文件增长到 20 PB 的存储空间，而无需大量管理输入</block>
  <block id="1d7ab3c9a162bc81b216bdc0948094f2" category="list-text">一种可通过全局文件缓存跨越全球的命名空间</block>
  <block id="2d4169e0cb52db60fd11576990b38a54" category="list-text">利用受管 NetApp 存储实现安全多租户</block>
  <block id="a44c13ec320997e84b87b0fef150c39f" category="list-text">使用 NetApp FabricPool 将冷数据迁移到对象存储</block>
  <block id="3749fba0ca78e5e5c70f899da89be2c3" category="list-text">通过文件系统分析快速提供文件统计信息</block>
  <block id="63d0ec819ea12b4e83e0ef4a1cd2bb1c" category="list-text">将存储集群扩展到多达 24 个节点，以提高容量和性能</block>
  <block id="818a13118ddb0908ba00c1b7ca18dc2c" category="list-text">能够使用配额控制存储空间，并具有 QoS 限制的性能保障</block>
  <block id="ef94cd0a62341c72316393b1044582f8" category="list-text">通过加密保护数据安全</block>
  <block id="c1e36bb7dca3b0da98164eb5956e3f0f" category="list-text">满足广泛的数据保护和合规性要求</block>
  <block id="6a632279908ad5d56ab46a826de6c9f2" category="list-text">提供灵活的业务连续性选项</block>
  <block id="0581202e42d61d6dfe4875c70d00cdac" category="summary">NetApp 虚拟桌面服务可提供一个易于使用的虚拟桌面和应用程序环境，并重点关注业务挑战。通过使用 NetApp HCI 扩展 VDS ，您可以在 VDS 环境中使用强大的 NetApp 功能，包括实时重复数据删除，数据缩减，精简配置和数据压缩。</block>
  <block id="33491606222aecbfbdfa3fc8f13ffded" category="paragraph">NetApp 虚拟桌面服务可提供一个易于使用的虚拟桌面和应用程序环境，并重点关注业务挑战。通过在内部 ONTAP 环境中扩展 VDS ，您可以在 VDS 环境中使用强大的 NetApp 功能，包括快速克隆，实时重复数据删除，数据缩减，精简配置， 和数据压缩。这些功能可以节省存储成本并提高全闪存存储的性能。借助 VMware vSphere 虚拟机管理程序，可通过使用虚拟卷和 vSphere API 实现阵列集成，最大限度地缩短服务器配置时间。利用混合云，客户可以选择适合其苛刻工作负载的环境，并节省资金。内部运行的桌面会话可以根据策略访问云资源。</block>
  <block id="a3af49b9146a6a36e8bea4c525797782" category="summary">此页面将讨论 DCConfig 工具， TestV 直流工具和日志文件。</block>
  <block id="d56ee3058d1c4ab634cd3e1e606f2064" category="doc">工具和日志</block>
  <block id="626b1761e15913fc6f955e1d76a0ac10" category="section-title">DCConfig 工具</block>
  <block id="65bbb1c25836b86f699bd2141a545958" category="paragraph">DCCconfig 工具支持以下虚拟机管理程序选项来添加站点：</block>
  <block id="2c76e52255da65e5fcf88143f91aa431" category="paragraph"><block ref="2c76e52255da65e5fcf88143f91aa431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da2595b668536baaea606e674ade5181" category="paragraph"><block ref="da2595b668536baaea606e674ade5181" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2eb34c5311117b56d2c8eb33494052a3" category="paragraph">可以使用 GPO 处理共享数据的特定工作空间驱动器号映射。专业服务或支持团队可以使用高级选项卡自定义 Active Directory OU 名称，启用或禁用 FSLogix 部署的选项，各种超时值等设置。</block>
  <block id="8688a5dde644921ea673f5bc2dde55c3" category="paragraph"><block ref="8688a5dde644921ea673f5bc2dde55c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6c93f3609bb3be799ed32b6a601d5fc" category="section-title">命令中心（以前称为 TestV 直流工具）</block>
  <block id="46433f623976c5af8ebdc7ab92816a48" category="inline-link-macro">命令中心概述</block>
  <block id="bf69b43c185864d35a461d8f1c3ea56e" category="paragraph">要启动 Command Center 和所需角色，请参见 <block ref="d7ce3bd63a8a34b9b1630abb82acb951" category="inline-link-macro-rx"></block>。</block>
  <block id="b425cca2998cc4a7041a0baf7681e912" category="paragraph">您可以执行以下操作：</block>
  <block id="b462233b13790bce7e4c6449d02cf930" category="list-text">更改工作空间的 SMB 路径。</block>
  <block id="ee347a7998de9774369e6853f1ed7bcc" category="paragraph"><block ref="ee347a7998de9774369e6853f1ed7bcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c524c01ee30f2f1597bb3e90c721dd8c" category="list-text">更改用于配置收集的站点。</block>
  <block id="ccb9931a262a0b169576103526fa2ab2" category="paragraph"><block ref="ccb9931a262a0b169576103526fa2ab2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af6ba12de0b8c93d5f768c83143c7d99" category="section-title">日志文件</block>
  <block id="017b9aa293da801da252c728736f02db" category="inline-link-macro">自动化日志</block>
  <block id="580acc766c3f0e464b462d271028dc32" category="paragraph"><block ref="5f6615a18cd0f2f0bcfb7578db5d1c9e" category="inline-image-macro-rx" type="image"></block>检查 <block ref="11597d7347faee3da56e0e01d5ba1de2" category="inline-link-macro-rx"></block> 了解更多信息。</block>
  <block id="21a1e68164f738b8be1dae11d5a694b3" category="section-title">数据保护</block>
  <block id="d1c59e5cbf684efb4f69f300e72a4ac9" category="doc">操作管理</block>
  <block id="787e198d8fa4e242ef62df0a63fc0f5d" category="inline-link">对 VDA 操作失败页面进行故障排除</block>
  <block id="8086a7a818fcf045c7b05845b97629ed" category="paragraph">有关 VDS 日志文件的信息，请参见<block ref="0ecc734e7dc5f9a5685babbaab9faaa5" category="inline-link-rx"></block>。</block>
  <block id="88a80237ffcd0c20f5f4d4e7f9eda875" category="inline-link">VDA 组件和权限页面</block>
  <block id="000ea3efdd5a83f774a0c189fa2dcdc3" category="paragraph">有关所需最低权限的详细信息，请参见<block ref="573c5bde2dc73c6cb4f63bbc5571c0e2" category="inline-link-rx"></block>。</block>
  <block id="81bb80b99b1ba5d80f9ba049cbd0c42f" category="inline-link">克隆虚拟机页面</block>
  <block id="91aa73f3df8edb27ce6b20c984ff5d3e" category="paragraph">如果要手动克隆服务器，请参见<block ref="837d5521d53fff809b7ef3ad6b17ecfa" category="inline-link-rx"></block>。</block>
  <block id="7d71ba8ea6767ea10d7cd61cbd787f89" category="inline-link">自动增加磁盘空间功能页面</block>
  <block id="abf872062b9eb23bdf6d671c27508d96" category="paragraph">要自动增加 VM 磁盘大小，请参见<block ref="627eb07506141f4255cfbedd7fe89646" category="inline-link-rx"></block>。</block>
  <block id="cc6d8546c611bac5ab11fa1a5948ac1d" category="inline-link">最终用户要求页面</block>
  <block id="efb9afc2e01262d41bf1fa60ddc36414" category="paragraph">NetApp Cloud Insights 是一款基于 Web 的监控工具，可让您全面了解在 NetApp 和其他第三方基础架构组件上运行的基础架构和应用程序。Cloud Insights 支持私有云和公有云来监控，故障排除和优化资源。</block>
  <block id="4894eb73d4d2ad7eaebb0968e871cb70" category="paragraph">只有采集单元 VM （可以是 Windows 或 Linux ）必须安装在私有云上，才能从数据收集器收集指标，而无需代理。通过基于代理的数据收集器，您可以从 Windows 性能监控器或 Telegraf 支持的任何输入代理中提取自定义指标。</block>
  <block id="32e49e2645f559763ede8e346bbcb816" category="paragraph">下图显示了 Cloud Insights VDS 信息板。</block>
  <block id="cb9ecf4f0010c9ec12b73a00e06a9237" category="paragraph"><block ref="cb9ecf4f0010c9ec12b73a00e06a9237" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3bd1406c323c740b5b2f2a7615ad62ca" category="paragraph">有关 NetApp Cloud Insights 的详细信息，请参见<block ref="5fdb6e8524eb99916602753c65f2f24e" category="inline-link-rx"></block>。</block>
  <block id="48a2bc9c10adbea95074594015793272" category="summary">工作空间由一个桌面环境组成，该环境可以是在内部或任何支持云环境上托管的共享远程桌面会话。借助 Microsoft Azure ，桌面环境可以在 Windows Virtual Desktop 中持久存在。每个工作空间都与特定组织或客户端相关联。</block>
  <block id="1da2374b50f497e208c8dab11e6b2c98" category="doc">工作空间管理</block>
  <block id="fb67e63246489555a7e8929a138ced4c" category="paragraph">工作空间由桌面环境组成；可以是在内部或任何受支持的云环境上托管的共享远程桌面会话。借助 Microsoft Azure ，桌面环境可以在 Windows Virtual Desktop 中持久存在。每个工作空间都与特定组织或客户端相关联。下图显示了创建新工作空间时可用的选项。</block>
  <block id="42a6c6312ce8b92836d9e74d89998e89" category="paragraph"><block ref="42a6c6312ce8b92836d9e74d89998e89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d49083c2604eac2881e01b4acea428e" category="admonition">每个工作空间都与特定部署相关联。</block>
  <block id="2a1fdca12b05c0f5292a8670b24cb478" category="paragraph">工作空间包含关联的应用程序和应用程序服务，共享数据文件夹，服务器和 WVD 实例。每个工作空间都可以控制各种安全选项，例如强制实施密码复杂性，多因素身份验证，文件审核等。</block>
  <block id="f29490b04a344e19674ee8d1db337d14" category="paragraph">工作空间可以控制工作负载计划以启动额外的服务器，限制每个服务器的用户数或为给定时间段内可用的资源设置计划（始终打开 / 关闭）。还可以配置资源以按需启动。</block>
  <block id="421b47ffd946ca083b65cd668c6b17e6" category="inline-link">视频</block>
  <block id="5a70681d968007936b9d092ba1a93313" category="paragraph">如果需要，此工作空间可以覆盖部署 VM 资源的默认值。对于 WVD ，也可以从云工作空间管理套件门户管理 WVD 主机池（其中包含会话主机和应用程序组）和 WVD 工作空间。有关 WVD 主机池的详细信息，请参见此部分<block ref="283c24f69dac0d05b60b041138870b19" category="inline-link-rx"></block>。</block>
  <block id="7d37fde7375502ef1013412159477502" category="summary">NetApp 提供许多云服务，包括使用 WVD 或远程应用程序快速配置虚拟桌面，包括与 Azure NetApp Files 快速集成。</block>
  <block id="28850fd0c108cc5f990fc4b4b52ab60d" category="doc">NetApp 虚拟桌面服务概述</block>
  <block id="c70675dc3857ae45ab2475f60c0f1f85" category="paragraph">NetApp 提供许多云服务，包括使用 WVD 或远程应用程序快速配置虚拟桌面以及与 Azure NetApp Files 快速集成。</block>
  <block id="8b32dee3fc7d9223248420cb828c5527" category="paragraph">传统上，为客户配置和交付远程桌面服务需要数周时间。除了配置之外，管理应用程序，用户配置文件，共享数据和组策略对象以强制实施策略可能会很困难。防火墙规则可能会增加复杂性，并需要单独的技能和工具。</block>
  <block id="0276a1f5f692f2e9635f3733b371cf70" category="paragraph">借助 Microsoft Azure Windows 虚拟桌面服务， Microsoft 负责维护远程桌面服务组件，使客户能够专注于在云中配置工作空间。客户必须配置和管理整个堆栈，这需要具备管理 VDI 环境的特殊技能。</block>
  <block id="51db16f7b26a08952beb43836ad3f31d" category="paragraph">借助 NetApp VDS ，客户可以快速部署虚拟桌面，而无需担心在何处安装架构组件，例如代理，网关，代理等。需要完全控制其环境的客户可以与专业服务团队合作来实现其目标。客户使用 VDS 即服务，因此可以专注于关键业务挑战。</block>
  <block id="139562ef7df2deed82d586ebe297a082" category="paragraph">NetApp VDS 是一款软件即服务产品，用于集中管理 AWS ， Azure ， GCP 或私有云环境中的多个部署。Microsoft Windows 虚拟桌面仅在 Microsoft Azure 上可用。NetApp VDS 可在其他环境中编排 Microsoft 远程桌面服务。</block>
  <block id="fd9a0083b0a0e084ce6fb8d2ca64272f" category="paragraph">Microsoft 在 Windows 10 上提供多会话功能，专用于 Azure 上的 Windows 虚拟桌面环境。身份验证和身份由虚拟桌面技术处理； WVD 要求将 Azure Active Directory （使用 AD Connect ）同步到 Active Directory ，并将会话 VM 加入 Active Directory 。RDS 需要使用 Active Directory 进行用户身份和身份验证以及 VM 域加入和管理。</block>
  <block id="416feb9f77def2ffedaab40a538d47e5" category="paragraph">下图显示了一个部署拓扑示例。</block>
  <block id="e377917f3505cdb9fc72b74164df5928" category="paragraph"><block ref="e377917f3505cdb9fc72b74164df5928" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d271ca257d56879fcc9ed95d82aabaa7" category="paragraph">每个部署都与一个 Active Directory 域关联，并为客户端提供一个访问工作空间和应用程序的入口点。具有多个 Active Directory 域的服务提供商或企业通常部署更多。一个跨多个区域的 Active Directory 域通常具有一个包含多个站点的部署。</block>
  <block id="9ea3c4f34057d91531ae286e3efe62c3" category="paragraph">对于 Azure 中的 WVD ， Microsoft 提供了一种由 NetApp VDS 使用的平台即服务。对于其他环境， NetApp VDS 会协调 Microsoft 远程桌面服务的部署和配置。NetApp VDS 既支持 WVD Classic ，也支持 WVD arm ，并且还可用于升级现有版本。</block>
  <block id="3e8cd47ad0ab71d0b3891f85212ccdbc" category="paragraph">每个部署都有自己的平台服务，其中包括 Cloud Workspace Manager （ REST API 端点）， HTML 5 网关（从 VDS 管理门户连接到 VM ）， RDS 网关（客户端访问点）和域控制器。下图展示了用于 RDS 实施的 VDS 控制平台架构。</block>
  <block id="38606818aeffd06d174e51013afc23a1" category="paragraph"><block ref="38606818aeffd06d174e51013afc23a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58cad6a2c8c8ff1a585bf8d6ca94560" category="paragraph">对于 RDS 实施，可以使用客户端软件从 Windows 和浏览器轻松访问 NetApp VDS ，该软件可以进行自定义以包含客户标识和映像。根据用户凭据，用户可以访问已批准的工作空间和应用程序。无需配置网关详细信息。</block>
  <block id="c2dcf4d443be38a737d1e580fb4b86ec" category="paragraph">下图显示了 NetApp VDS 客户端。</block>
  <block id="8e7d56f1d99fdc8080a747bf8b1eda75" category="paragraph"><block ref="8e7d56f1d99fdc8080a747bf8b1eda75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71110c8ffc8b198bc951f6e587fbcddf" category="paragraph">在 Azure WVD 实施中， Microsoft 负责处理客户端的访问入口点，并可供各种操作系统本机使用的 Microsoft WVD 客户端使用。也可以从基于 Web 的门户访问它。客户端软件的配置必须由组策略对象（ GPO ）或客户首选的其他方式处理。</block>
  <block id="9e4318c1c6ae62544ba67e7c0fe55649" category="paragraph">下图展示了适用于 Azure WVD 实施的 VDS 控制平面架构。</block>
  <block id="ba9e4c82a95db68279bffa8ca8a8803f" category="paragraph"><block ref="ba9e4c82a95db68279bffa8ca8a8803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d648a5d4acf66674fb86cc7be05bd5e" category="paragraph">除了部署和配置所需组件之外， NetApp VDS 还负责处理用户管理，应用程序管理，资源扩展和优化。</block>
  <block id="3ea30729e0e7f0d666400ccc1a6f7bc3" category="paragraph">NetApp VDS 可以创建用户或授予现有用户帐户对云工作空间或应用程序服务的访问权限。该门户还可用于重置密码和委派管理部分组件。帮助台管理员或 3 级技术人员可以对用户会话进行影子管理，以便进行故障排除或从门户中连接到服务器。</block>
  <block id="061d5215d4dd8b8e2b7d9f2498a4a8c3" category="paragraph">NetApp VDS 可以使用您创建的映像模板，也可以使用市场上现有的映像模板进行基于云的配置。要减少要管理的映像数量，您可以使用基础映像，并且可以使用提供的框架配置所需的任何其他应用程序，以包括任何命令行工具，例如 chocolatey ， MSIX 应用程序连接， PowerShell 等。即使自定义脚本也可以用作计算机生命周期事件的一部分。</block>
  <block id="2cdacde3c74a59c779ff64324954b86f" category="summary">NetApp 虚拟桌面服务（ Virtual Desktop Service ， VDS ）可在主要公有云以及私有云中编排远程桌面服务（ Remote Desktop Services ， RDS ）。VDS 在 Microsoft Azure 上支持 Windows 虚拟桌面（ WVD ）。VDS 可自动执行许多在部署 WVD 或 RDS 后必须执行的任务，包括设置 SMB 文件共享（用于用户配置文件，共享数据和用户主驱动器），启用 Windows 功能，安装应用程序和代理，防火墙和策略等。</block>
  <block id="acb7add6e3cf0ca01c52e60466c321ca" category="doc">TR-4861 ：《采用虚拟桌面服务的混合云 VDI 》</block>
  <block id="bb6a5b934db24610665e58e743983ae4" category="paragraph">对于专用桌面，共享桌面和远程应用程序，用户会使用 VDS 。VDS 提供了脚本化事件，用于自动管理桌面的应用程序，并减少了要管理的映像数量。</block>
  <block id="38e3c8e108e8e361d0712cdfe23e0b38" category="paragraph">VDS 提供了一个管理门户，用于在公有和私有云环境中处理部署。</block>
  <block id="07d07e20c1ad9bd1a3e99e2303879ff9" category="paragraph">2020 年远程员工人数激增，改变了对业务连续性的要求。IT 部门在快速配置虚拟桌面方面面临着新的挑战，因此需要配置灵活性，远程管理以及混合云的 TCO 优势，以便于轻松配置内部和云资源。他们需要混合云解决方案：</block>
  <block id="44ff202cbab5f506b48c6021b19c4b1c" category="list-text">解决了 COVID 后的工作空间现实，支持具有全局动态的灵活工作模式</block>
  <block id="53f994926861d0a62f2893b66d8b2025" category="list-text">通过简化和加快从任务员工到高级用户的所有员工的工作环境部署，实现工作转型</block>
  <block id="831955bd9eabf6724f4e4b01acbb833c" category="list-text">通过提供丰富，安全的 VDI 资源来调动您的员工，而无论其位于何处</block>
  <block id="ab02aa4712e65c237e92874eeef51ecd" category="list-text">简化混合云部署</block>
  <block id="074890ea8810b95d9b381027ff9baef2" category="list-text">自动化并简化风险降低管理</block>
  <block id="49fc376ed35249f3841846ede4dab884" category="inline-link">NetApp Cloud Central</block>
  <block id="b1c770f25b823d4453567c0ff9d7cf67" category="summary">此页面提供了在 VMware vSphere 环境中部署 NetApp ONTAP NFS 版本 3 数据存储库的步骤。</block>
  <block id="168dbfe414d4d4089585360152953a57" category="doc">vSphere NFS 数据存储库—使用 ONTAP 的版本 3</block>
  <block id="bbe48fb854ea022537208eeeff822f91" category="section-title">关于此任务</block>
  <block id="2be27a78c84ba5629cd9f2c22983240a" category="paragraph">使用 ONTAP NAS 存储创建 NFS 版本 3 数据存储库。</block>
  <block id="1563a554e82b055714efd37bc6d1fdd6" category="paragraph">对于自动配置，请使用以下脚本之一： <block ref="a45ba722ee80832fb205d0588df91e01" category="inline-xref-macro-rx"></block>， <block ref="d9559d06f0afa5b213d78afb48b783e7" category="inline-xref-macro-rx"></block>或 <block ref="e5e7d2f44064f3bfeddfdbea251f7835" category="inline-xref-macro-rx"></block>。</block>
  <block id="6ac65708de8f04eeb173ca99f3eb19fa" category="section-title">您需要的内容</block>
  <block id="106a118b8a267220cb2c40a4bb68b684" category="list-text">管理 vSphere 环境和 ONTAP 所需的基本技能。</block>
  <block id="00c46d0ea9cdf9a5a37b8af04896741f" category="list-text">运行 ONTAP 9.8 或更高版本的 ONTAP 存储系统（ FAS/AFF/CVO/ONTAP Select/Cloud Volume Service/Azure NetApp Files ）</block>
  <block id="d5ba6255ccf331629f7b1b4598223d33" category="list-text">ONTAP 凭据（ SVM 名称，用户 ID ，密码）</block>
  <block id="190ba592a6988abfd7566be9b5c8217a" category="list-text">NFS 的 ONTAP 网络端口， SVM 和 LUN 信息</block>
  <block id="d5cb637f6500cfa77d4190ebdfd8cce0" category="inline-link-macro">完整的 NFS 配置工作表</block>
  <block id="915142cb27ebec8265b54739a95840b5" category="list-text"><block ref="915142cb27ebec8265b54739a95840b5" category="inline-link-macro-rx"></block></block>
  <block id="24c066a87410cc7b08ad4b5ca45565d7" category="list-text">vCenter Server 凭据</block>
  <block id="a9ab6317871b5547fc7bf0dd22151f00" category="list-text">vSphere 7.0 或更高版本的 vSphere 主机信息</block>
  <block id="d7850596008b347e3797ad7dcb7252e5" category="list-text">NFS VMKernel 适配器 IP 信息</block>
  <block id="9068992a529de63b07b7c2250be12f87" category="list-text">网络交换机</block>
  <block id="0675fa9a38b420775f29ec7a62d9a8a0" category="list-text">使用 ONTAP 系统网络数据端口并连接 vSphere 主机</block>
  <block id="a7fb6a7233e9c40554334921be362af1" category="list-text">为 NFS 配置的 VLAN</block>
  <block id="44786c36009327ad04469602f3f96832" category="list-text">（可选）为 ONTAP 网络数据端口配置的链路聚合</block>
  <block id="503023bddb3bd1c7803b35b4ace6aa7a" category="list-text">适用于 VMware vSphere 的 ONTAP 工具已部署，配置并可随时使用</block>
  <block id="f3a29486bed19a90f2da6d007818b427" category="section-title">步骤</block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">互操作性表工具（ IMT ）</block>
  <block id="4b18348d39655902cd0e183596a82856" category="list-text">检查与的兼容性<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="bc295a5edde99316e021476fd74118c6" category="inline-link-macro">验证是否支持 NFS 配置。</block>
  <block id="564210524eadeca61542a5680bf0afca" category="list-text"><block ref="564210524eadeca61542a5680bf0afca" category="inline-link-macro-rx"></block></block>
  <block id="e103d9cdc55ef0be25a4fd8054bc28bc" category="list-text">完成以下 ONTAP 和 vSphere 任务。</block>
  <block id="cfa5eceb5ac37d5ebd3af6f265d9ce4c" category="section-title">ONTAP 任务</block>
  <block id="c54d1c547e26987b98af73634278c77a" category="inline-link-macro">验证 NFS 的 ONTAP 许可证。</block>
  <block id="8174503ab9e5dc2fe2f74068f651770d" category="list-text"><block ref="8174503ab9e5dc2fe2f74068f651770d" category="inline-link-macro-rx"></block></block>
  <block id="5d3f3e14f3096740cb085fa81836d595" category="list-text">使用 `ssystem license show` 命令检查是否已列出 NFS 。</block>
  <block id="8b3434ec0db76b4d537ae9c645aa913c" category="list-text">使用 `license add -license-code &lt; 许可证代码 &gt;` 添加许可证。</block>
  <block id="135850bb72d05ca77b8b8f846429fe71" category="inline-link-macro">按照 NFS 配置工作流进行操作。</block>
  <block id="01a85c06aae02abe9083e7e02d90661f" category="list-text"><block ref="01a85c06aae02abe9083e7e02d90661f" category="inline-link-macro-rx"></block></block>
  <block id="722a3f8fc9c281f41b6ca7a69ca15ec0" category="section-title">VMware vSphere 任务</block>
  <block id="2281b9d958567868b171298a8df5cdee" category="inline-link-macro">按照适用于 vSphere 的 NFS 客户端配置工作流进行操作。</block>
  <block id="c80c5160cfe2127b3ab167103b20488c" category="paragraph"><block ref="c80c5160cfe2127b3ab167103b20488c" category="inline-link-macro-rx"></block></block>
  <block id="63d5049791d9d79d86e9a108b0a999ca" category="section-title">参考</block>
  <block id="883a5adf98ba177c28c5bc7d95e28763" category="paragraph">完成这些任务后， NFS 数据存储库便可用于配置虚拟机。</block>
  <block id="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link"><block ref="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link-rx"></block></block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">false</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">enabled</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">卷保证</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">grow_shrink</block>
  <block id="01a7d7174ccc6593753679eefec17d49" category="summary">本页介绍在 VMware vSphere 环境中自动执行基本 ONTAP 功能的优势。</block>
  <block id="1406aa071af210d31c6a2951fe66ddcc" category="doc">ONTAP 和 vSphere 自动化简介</block>
  <block id="8e2b0503a0ad76f57c96738d7f0a3b0d" category="section-title">VMware 自动化</block>
  <block id="b5845209cb81dad561de4abe6e4481c4" category="paragraph">自 VMware ESX 推出以来，自动化已成为管理 VMware 环境不可或缺的一部分。能够将基础架构作为代码进行部署，并将实践扩展到私有云操作，有助于缓解对规模，灵活性，自行配置和效率的顾虑。</block>
  <block id="f7c9a2e2ec395a7e4b605bb3df40abf8" category="paragraph">自动化可以分为以下几类：</block>
  <block id="cba6f5a209d4f2ac1839f1c1e0a10051" category="list-text">* 虚拟基础架构部署 *</block>
  <block id="f41d0733c4edc0bf273a3d0587efb21e" category="list-text">* 来宾计算机操作 *</block>
  <block id="7f2a4b0fa787b1f058accb56cc377af8" category="list-text">* 云操作 *</block>
  <block id="290a03d97ea4e48144d20f313e0a0826" category="paragraph">管理员可以选择多种方法来实现基础架构自动化。无论是通过将虚拟机的主机配置文件或自定义规范等原生 vSphere 功能用于 VMware 软件组件，操作系统和 NetApp 存储系统上的可用 API ，均可获得大量文档和指导。</block>
  <block id="217dd73ccc3bd89b5d4e35d0bf50ea6c" category="paragraph">如果 ESX 主机运行的是 ESX 4.1 或更高版本，则 Data ONTAP 8.0.1 及更高版本支持某些 VMware vSphere API for Array Integration （ VAAI ）功能。VAAI 是一组 API ，用于在 VMware vSphere ESXi 主机和存储设备之间进行通信。这些功能有助于将操作从 ESX 主机卸载到存储系统，并提高网络吞吐量。ESX 主机会在正确的环境中自动启用这些功能。您可以通过检查 VAAI 计数器中的统计信息来确定系统使用 VAAI 功能的程度。</block>
  <block id="16123583d64fd438c5d7f5b61a1c1d2f" category="paragraph">自动部署 VMware 环境的最常见起点是配置基于块或文件的数据存储库。在开发相应的自动化之前，必须确定实际任务的要求。</block>
  <block id="a78bd4dd1db96affe0c2889376cccf53" category="paragraph">有关 VMware 环境自动化的详细信息，请参见以下资源：</block>
  <block id="ebd98e15bf07fe37dfdc879f9d0d1f48" category="inline-link">NetApp Pub</block>
  <block id="6123648b7dec055b609781b4d47c1b26" category="list-text"><block ref="6c65ff4f1dfb7aa26df896b1c9c849eb" category="inline-link-rx"></block>。NetApp 配置管理和自动化。</block>
  <block id="7c4272bef0cc405b65fc74e3791664bc" category="inline-link">适用于 VMware 的 Ansible GALAXY 社区</block>
  <block id="59fb42204e71850f7fd7024e5e6a1058" category="list-text"><block ref="c471bcaf7efa6fb129f37edaa7c41a56" category="inline-link-rx"></block>。一组适用于 VMware 的 Ansible 资源。</block>
  <block id="1ec695bd70399ce37180f1d84a33d151" category="inline-link">VMware ｛ code ｝ 资源</block>
  <block id="489c5322cef99651507b070e2240b6a8" category="list-text"><block ref="77e0562f07512a7a248241b7170b6944" category="inline-link-rx"></block>。为软件定义的数据中心设计解决方案所需的资源，包括论坛，设计标准，示例代码和开发人员工具。</block>
  <block id="5a44477fe5ac4beac2dc6574097cf079" category="summary">此页面提供了在 VMware vSphere 环境中部署 NetApp ONTAP 存储 iSCSI VMFS 数据存储库的步骤。</block>
  <block id="6d5f52fb3cf097647a57da8b55e5b08f" category="doc">使用 ONTAP 配置 vSphere 传统块存储</block>
  <block id="7c2d57185437da757ecede58f5a842d4" category="paragraph">VMware vSphere 支持以下 VMFS 数据存储库选项，并指定了 ONTAP SAN 协议支持。</block>
  <block id="c90881491d716de5c0ed7f9f4b09a3ad" category="cell">VMFS 数据存储库选项</block>
  <block id="a9181ef164a32ec0949c2cf63315ca31" category="cell">ONTAP SAN 协议支持</block>
  <block id="5903a917b575023b60264c602c220771" category="inline-link-macro">光纤通道（ FC ）</block>
  <block id="a4bce6d7794ee38a14e6a6d3785039f9" category="cell"><block ref="a4bce6d7794ee38a14e6a6d3785039f9" category="inline-link-macro-rx"></block></block>
  <block id="a6105c0a611b41b08f1209506350279e" category="cell">是的。</block>
  <block id="8da5577a58a95e2ebe9c6dd4f19f6c11" category="inline-link-macro">以太网光纤通道（ FCoE ）</block>
  <block id="40b814244a055d57c1af5fd02e4a8747" category="cell"><block ref="40b814244a055d57c1af5fd02e4a8747" category="inline-link-macro-rx"></block></block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="inline-link-macro">iSCSI</block>
  <block id="b26caac6068e09e5f849cfcb3e8c0c90" category="cell"><block ref="b26caac6068e09e5f849cfcb3e8c0c90" category="inline-link-macro-rx"></block></block>
  <block id="c38e870d503879d110dbddd5bf388ab2" category="cell">适用于 RDMA 的 iSCSI 扩展（ iSER ）</block>
  <block id="7fa3b767c460b54a2be4d49030b349c7" category="cell">否</block>
  <block id="de5a656362f0d785d2cc7d3097a507ef" category="inline-link-macro">采用 FC 的基于网络结构的 NVMe （ NVMe/FC ）</block>
  <block id="71a94ffc9bd97f314990ee2cd7a87154" category="cell"><block ref="71a94ffc9bd97f314990ee2cd7a87154" category="inline-link-macro-rx"></block></block>
  <block id="16d2954ba1640e32b21c312695337233" category="cell">采用基于融合以太网的 RDMA 的基于网络结构的 NVMe （ NVMe/RoCE ）</block>
  <block id="344567ba51767dd5805c908c602fb10e" category="admonition">如果需要 iSER 或 NVMe/RoCE VMFS ，请检查基于 SANtricity 的存储系统。</block>
  <block id="0f0b69f9725d17d0a8d3ceebcf33f72f" category="inline-link">适用于 VMware 的 NetApp ONTAP 工具</block>
  <block id="8ce83a5c4c3183c4e25f0d8d7b657ffc" category="summary">此页面可在 VMware vSphere 环境中提供 NFS 数据存储库支持。</block>
  <block id="3769193a46f06731838a6d904cf1da37" category="doc">使用 ONTAP 配置 vSphere 传统文件存储</block>
  <block id="8d3005420a2cb4cc915402d9c5604538" category="paragraph">VMware vSphere 支持以下 NFS 协议，这两种协议均支持 ONTAP 。</block>
  <block id="78aa97ac78d1291969b5893edcfe448a" category="inline-link-macro">NFS 版本 3</block>
  <block id="fb110cc4ad992a0846c0eaea7fbf2d94" category="list-text"><block ref="fb110cc4ad992a0846c0eaea7fbf2d94" category="inline-link-macro-rx"></block></block>
  <block id="2d6affbd5ec6eb1f6009383ca5ba9b2b" category="inline-link-macro">NFS 版本 4.1</block>
  <block id="3f65d9416139ab7c1ff75966bccf6f7d" category="list-text"><block ref="3f65d9416139ab7c1ff75966bccf6f7d" category="inline-link-macro-rx"></block></block>
  <block id="fc5929c224818a87a89047d2813dd2c5" category="inline-link-macro">此 NFS 客户端版本比较</block>
  <block id="ce51dd3c15b8a6638d0c212b990ae643" category="paragraph">如果在为 vSphere 选择正确的 NFS 版本时需要帮助，请检查 <block ref="8055fbd4933fc4c8b583fa212ff14ff2" category="inline-link-macro-rx"></block>。</block>
  <block id="e69b470437a857bf2d9517ce4ef8d2c1" category="summary">此页面提供了在 VMware vSphere 环境中部署 NetApp ONTAP 存储 FC VMFS 数据存储库的步骤。</block>
  <block id="91d9498cf61618ef81368a106318efd2" category="doc">vSphere VMFS 数据存储库—采用 ONTAP 的光纤通道存储后端</block>
  <block id="b6e52e53cc59b8620dcdc05f2b812be4" category="paragraph">本节介绍如何使用 ONTAP 光纤通道（ FC ）存储创建 VMFS 数据存储库。</block>
  <block id="6b70d8f91894fa50b3c04af804f090b6" category="list-text">管理 vSphere 环境和 ONTAP 所需的基本技能</block>
  <block id="fdb8f60c37b623874df816146436f56b" category="list-text">ONTAP 凭据（ SVM 名称，用户 ID 和密码）</block>
  <block id="f2a03b032017931383878c3ef48cdb0a" category="list-text">主机，目标以及 SVM 和 LUN 信息的 ONTAP WWPN</block>
  <block id="d0a36a0dcdef62d026caa08afbaa4a42" category="inline-link-macro">已完成的 FC 配置工作表</block>
  <block id="5c42144bb611ba366591a823d4c2955e" category="list-text"><block ref="5c42144bb611ba366591a823d4c2955e" category="inline-link-macro-rx"></block></block>
  <block id="c7f58b1f94665d7ebf6f107970d1b91b" category="list-text">vSphere 主机信息</block>
  <block id="63fc76a195a29345d466bc86f293ca14" category="list-text">光纤交换机</block>
  <block id="6c2e28f86b2049d110f0e73e9bb78709" category="list-text">连接了 ONTAP FC 数据端口和 vSphere 主机</block>
  <block id="52dd4b667b031cd80a33b9d176e43827" category="list-text">启用 N_port ID 虚拟化（ NPIV ）功能</block>
  <block id="46fdd1539543376bfbbf2cc6da976539" category="list-text">创建单个启动程序单个目标分区。</block>
  <block id="df7f994fb0c494b66708667a64b2c406" category="list-text">为每个启动程序创建一个分区（单个启动程序分区）。</block>
  <block id="5a1cb943a687396a356750829002d982" category="list-text">对于每个分区，包括一个目标，该目标是 SVM 的 ONTAP FC 逻辑接口（ WWPN ）。每个 SVM 的每个节点至少应有两个逻辑接口。请勿使用物理端口的 WWPN 。</block>
  <block id="acd7065eaa19f6ad949216b6dcca52b6" category="list-text">适用于 VMware vSphere 的 ONTAP 工具已部署，配置并可随时使用。</block>
  <block id="d13dd15101d292f5b2c56e5be828fec8" category="section-title">配置 VMFS 数据存储库</block>
  <block id="95877ca095b0f0a0a981f8a12d234ad5" category="paragraph">要配置 VMFS 数据存储库，请完成以下步骤：</block>
  <block id="94dafc85e46c3bc0d374c052b1075890" category="list-text">使用检查兼容性<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="195e1a47999aff0fbaa4eb8d97be6c40" category="inline-link-macro">支持 FCP 配置</block>
  <block id="e1b87801d0d31fd947fb52aa411c2815" category="list-text">验证是否已 <block ref="a0240d867f430aa7cc80ec129fc2bdb1" category="inline-link-macro-rx"></block>。</block>
  <block id="0b3f75b021ef6bdc0a532e2d9b2a9d74" category="inline-link-macro">验证您是否具有 FCP 的 ONTAP 许可证。</block>
  <block id="3c56f50608e95955ed2e1a3fb8b1dad1" category="list-text"><block ref="3c56f50608e95955ed2e1a3fb8b1dad1" category="inline-link-macro-rx"></block></block>
  <block id="e7dc6b39e7e5bd6df8fa93e90a426161" category="list-text">使用 `ssystem license show` 命令检查是否列出了 FCP 。</block>
  <block id="f8aa00b1a94d3290ba6ac653b792dd8a" category="list-text">使用 `liconen se add -license-code &lt; 许可证代码 &gt;` 添加许可证。</block>
  <block id="86a53381cefd41dcca81850274f0203a" category="list-text">确保已在 SVM 上启用 FCP 协议。</block>
  <block id="169e237a691059b9ac1933f0e7be8f56" category="inline-link-macro">验证现有 SVM 上的 FCP 。</block>
  <block id="5bb60b756067a0334c310be1e2260c3b" category="list-text"><block ref="5bb60b756067a0334c310be1e2260c3b" category="inline-link-macro-rx"></block></block>
  <block id="fab6621b43b19a018afc1860a5b85c21" category="inline-link-macro">在现有 SVM 上配置 FCP 。</block>
  <block id="7d4ca3fa89beb77990d305e17ed9ba64" category="list-text"><block ref="7d4ca3fa89beb77990d305e17ed9ba64" category="inline-link-macro-rx"></block></block>
  <block id="0d195904efc6cfb176bbc04e93c2947d" category="inline-link-macro">使用 FCP 创建新的 SVM 。</block>
  <block id="df062a6cafa16aee5f7ea64ea6991776" category="list-text"><block ref="df062a6cafa16aee5f7ea64ea6991776" category="inline-link-macro-rx"></block></block>
  <block id="5aab5d056538757626dd0562a563471a" category="list-text">确保 FCP 逻辑接口在 SVM 上可用。</block>
  <block id="aa01379022dd5b86e18f436c76f651f5" category="list-text">使用 `Network Interface show` 验证 FCP 适配器。</block>
  <block id="f89eac3d097d3dae5c0159f0da84b1c7" category="list-text">使用 GUI 创建 SVM 时，逻辑接口是该过程的一部分。</block>
  <block id="946b60eb8bd4945ad82b28fd9ccd3c63" category="list-text">要重命名网络接口，请使用 `Network Interface modify` 。</block>
  <block id="52fa81ab62bea2599ed516f01925678d" category="inline-link-macro">创建并映射 LUN 。</block>
  <block id="c8ecf540bebb63423545ecd3d02c6ca0" category="list-text"><block ref="a2b18e9ce335dd856363e6613d961c1a" category="inline-link-macro-rx"></block> 如果您使用适用于 VMware vSphere 的 ONTAP 工具，请跳过此步骤。</block>
  <block id="e4f7ebeb9544fb23a73028ab714ca87c" category="section-title">VMware vSphere 任务</block>
  <block id="7407e0a15262132133381a890e36e47a" category="inline-link-macro">存储适配器信息</block>
  <block id="25d85157bcfdbb601bbda056cd3a5bc6" category="list-text">确认已安装 HBA 驱动程序。VMware 支持的 HBA 已开箱即用部署驱动程序，应在中显示这些驱动程序 <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block>。</block>
  <block id="c57f32bc5ce6f95f5f9bec8260ecdb08" category="inline-link-macro">使用 ONTAP 工具配置 VMFS 数据存储库</block>
  <block id="b3a5f140339b1ca0940c5875b2a76d0b" category="list-text"><block ref="89ebfed741bd060c10a4a1472581f4e2" category="inline-link-macro-rx"></block>。</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="section-title">数据保护</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise Plus</block>
  <block id="e61ead4102c89a9758572df81301a1d2" category="inline-image-macro">混合云</block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">故障恢复</block>
  <block id="bbaff12800505b22a853e8b7f4eb6a22" category="inline-link-macro">联系方式</block>
  <block id="d3db539e5d56da6e251021138c5fe53f" category="section-title">了解 NetApp 和 VMware 解决方案</block>
  <block id="09f93ac387258fa68c085baba3c8fc44" category="inline-link-macro">NetApp 和 amp ； VMware ：携手合作更好</block>
  <block id="fb758bbc93c23b25607ef41f302d4eef" category="list-text"><block ref="35ef54e3b8ad8ec505bab4b973f86177" category="inline-link-macro-rx"></block></block>
  <block id="b6741313b8f46ab1018ebd6a361c22a4" category="inline-link-macro">ONTAP 9.8 VMware 的最新功能概述</block>
  <block id="d393be6d50183d7362f0adb8bc92ae08" category="list-text"><block ref="d393be6d50183d7362f0adb8bc92ae08" category="inline-link-macro-rx"></block></block>
  <block id="b25a3522acbb33341ccacac99424fcce" category="inline-link-macro">利用适用于 VMware vSphere 的 SnapCenter 插件</block>
  <block id="a65898b7011ddfb663cdba62f90581c6" category="list-text"><block ref="a65898b7011ddfb663cdba62f90581c6" category="inline-link-macro-rx"></block></block>
  <block id="60b0390f50a5ad13d613d49cfe1bce0b" category="inline-link-macro">使用 NetApp 和 NVMe 重新定义 VMware 性能</block>
  <block id="f6dde7f191b6b8f8351902b139ec8672" category="list-text"><block ref="f6dde7f191b6b8f8351902b139ec8672" category="inline-link-macro-rx"></block></block>
  <block id="c576371db342dc9cb166c73b0e157fb5" category="inline-link-macro">基于 AWS 的 VMware Cloud 的低成本高性能环境</block>
  <block id="89487ceb1ada10e49befbbaed3b714ec" category="list-text"><block ref="89487ceb1ada10e49befbbaed3b714ec" category="inline-link-macro-rx"></block></block>
  <block id="92061b0dd7904e2299ac65ed9bc2d6af" category="inline-link-macro">在 NetApp 中推出 VMware Tanzu</block>
  <block id="ae7c9beb8e4adca6da75607ee83e2403" category="list-text"><block ref="ae7c9beb8e4adca6da75607ee83e2403" category="inline-link-macro-rx"></block></block>
  <block id="a88a91878fb958db59873117d16ad078" category="inline-link-macro">Virtual Desktop Infrastructure (VDI) ：按需提供员工工作站</block>
  <block id="9467ff6388811a059199513a0a484f0b" category="list-text"><block ref="9467ff6388811a059199513a0a484f0b" category="inline-link-macro-rx"></block></block>
  <block id="d5e64137a19403f8c1c89f50546b82c5" category="inline-link-macro">VMware on AWS ：架构和服务选项</block>
  <block id="6cb2c8a80e576f132097e4d28cec24cd" category="list-text"><block ref="6cb2c8a80e576f132097e4d28cec24cd" category="inline-link-macro-rx"></block></block>
  <block id="cd4efd0ada1938b240dd48aa08010f04" category="inline-link-macro">使用 NetApp Cloud Volumes Service API 进行编程以优化 AWS 体验</block>
  <block id="f61369e9428a21eb1090be340ef36f16" category="list-text"><block ref="f61369e9428a21eb1090be340ef36f16" category="inline-link-macro-rx"></block></block>
  <block id="6d14f3ca0f5be54f01fd579906dd80bb" category="inline-link-macro">Kubernetes ：在 vSphere 和 Tanzu 上运行 K8s</block>
  <block id="ef8e103737164442c629df5b5d98769d" category="list-text"><block ref="ef8e103737164442c629df5b5d98769d" category="inline-link-macro-rx"></block></block>
  <block id="7e0caac7f6d493fab662f4f4d65ae213" category="section-title">构建虚拟化 Data Fabric</block>
  <block id="f1f4041236ed90e2a5e65e9a3c858875" category="section-title">查看适用于 VMware 的最新 NetApp 解决方案</block>
  <block id="0e8dd76bc961a90df87833953de6d067" category="inline-link-macro">采用 ONTAP 的 VMware vSphere ： NetApp 解决方案</block>
  <block id="b761cb4d962320708880627e8e2fe971" category="inline-link-macro">采用 ONTAP 的 VMware vSphere 虚拟卷</block>
  <block id="5b90454e2bf0f381c8f7fc928ef6fb9e" category="list-text"><block ref="5b90454e2bf0f381c8f7fc928ef6fb9e" category="inline-link-macro-rx"></block></block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="inline-link-macro">适用于 VMware vSphere 的 SnapCenter 插件</block>
  <block id="730c2cf92bbe409c31ef1f39cf25377a" category="list-text"><block ref="730c2cf92bbe409c31ef1f39cf25377a" category="inline-link-macro-rx"></block></block>
  <block id="c375e5bb7184da46adef700a9a36d674" category="inline-link-macro">NetApp 现代 NVMeoF VMware vSphere 工作负载设计和放大；验证</block>
  <block id="b54be27467e63a98d65e6b17a914e373" category="list-text"><block ref="902dd483e9192a0b4645b4c8be7acbff" category="inline-link-macro-rx"></block></block>
  <block id="b860a89f6215a92f2320f0afe4e0ee05" category="inline-link-macro">适用于 VMware 和和 SQL Server 的 NetApp 现代 NVmeoF 云连接 Flash 解决方案</block>
  <block id="0ebff16085636352cc1aa1e5b0003bdb" category="list-text"><block ref="ac70b8666634dd9095602966c4c61093" category="inline-link-macro-rx"></block></block>
  <block id="eccda9b55035b56259299545d5781136" category="inline-link-macro">借助 VMware Tanzu 和 amp ； ONTAP 加快 Kubernetes 之旅</block>
  <block id="bb79e474557eb86fc30118354eef0039" category="list-text"><block ref="5dd92e330c2d45255a2025ee1eedd52d" category="inline-link-macro-rx"></block></block>
  <block id="7f8cf1c43494d40e935f5e99e38ce659" category="inline-link-macro">降低在 AWS 上运行 VMware Cloud 的成本</block>
  <block id="f0d8a1b084d604c4db4319a2c5bbd522" category="list-text"><block ref="f0d8a1b084d604c4db4319a2c5bbd522" category="inline-link-macro-rx"></block></block>
  <block id="5ab6c918ee903c74a7d7c97b2432ebaf" category="section-title">观看最新 VMware 解决方案的视频演示</block>
  <block id="7128c22bfdae1fe8be75c9a9ee56eca9" category="inline-link-macro">VMware vSphere 和 NetApp ONTAP 的最佳实践</block>
  <block id="d2fa143a4aaef3477f2edb0d92676341" category="inline-link-macro">您的 VMware 环境—让我们使用 ONTAP 在 NVMe-oF 上运行它</block>
  <block id="207681662de4971035cc8d5c9347c986" category="list-text"><block ref="207681662de4971035cc8d5c9347c986" category="inline-link-macro-rx"></block></block>
  <block id="e9c2b8b8a9962013c07f83742ca35f0e" category="inline-link-macro">使用 ONTAP 工具和 VMware SRM 进行 VVOL 灾难恢复</block>
  <block id="8ca7386c3cb63b01ffc6387ba41427ae" category="list-text"><block ref="8ca7386c3cb63b01ffc6387ba41427ae" category="inline-link-macro-rx"></block></block>
  <block id="e308c2a1dacddb5bc6ffa093081111e4" category="inline-link-macro">适用于 Data Fabric 的 VMware 备份和恢复</block>
  <block id="9934e59457fa5f31d39a58f1d55ac5d5" category="list-text"><block ref="9934e59457fa5f31d39a58f1d55ac5d5" category="inline-link-macro-rx"></block></block>
  <block id="c10a86f3b9530baf3bed3b02aaaf873f" category="section-title">为 VMware 部署灵活的混合云和现代化应用程序基础架构</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="section-title">视频</block>
  <block id="f20368920280b50131814db2f83fda66" category="inline-link-macro">基于 NetApp 全闪存 FAS 构建 VMware 数据存储库</block>
  <block id="8ff6498eeabd53b4271d75f543dc3bc4" category="list-text"><block ref="8ff6498eeabd53b4271d75f543dc3bc4" category="inline-link-macro-rx"></block></block>
  <block id="f1c2408ffc6e67ac6b34eb8da2b3039c" category="list-text"><block ref="f1c2408ffc6e67ac6b34eb8da2b3039c" category="inline-link-macro-rx"></block></block>
  <block id="253d309203cf1f2c1bb57255bd0a5bdc" category="inline-link-macro">将 VMware VM 迁移到 Google Cloud</block>
  <block id="7518aab5e189037f632ee46ea9e3cf07" category="video-title">《部署适用于 VMware Tanzu 的动态持久 NetApp 存储》，第 1 部分</block>
  <block id="f86bf601d6e42c44cf076ea1772ae13c" category="video-title">《部署适用于 VMware Tanzu 的动态持久 NetApp 存储》，第 2 部分</block>
  <block id="bf5c12d4eed319d2dc2b2b7279944f71" category="video-title">《部署适用于 VMware Tanzu 的动态持久 NetApp 存储》，第 3 部分</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="section-title">博客</block>
  <block id="a398d57165e21c951dd9c9def41598a9" category="inline-link-macro">VMware Cloud on AWS ： Fujitsu 如何使用 CVO 节省数百万美元</block>
  <block id="d750d47d5e87a6c526e7b40e12eab95b" category="list-text"><block ref="d750d47d5e87a6c526e7b40e12eab95b" category="inline-link-macro-rx"></block></block>
  <block id="3ca2b14e719d79aed66780282e879db4" category="section-title">请联系 NetApp 和 VMware 专家</block>
  <block id="20475522c77401af1c203f23942ffda5" category="inline-link-macro">加入 VMware 解决方案论坛</block>
  <block id="1dccc60a61431b3ef3f48709a0f68de7" category="list-text"><block ref="1dccc60a61431b3ef3f48709a0f68de7" category="inline-link-macro-rx"></block></block>
  <block id="a5810200dda7a3f37fc7eae5378cc8f3" category="inline-link-macro">请联系 NetApp 全球服务团队开始使用</block>
  <block id="efb954cbfdbe0c54f04c904a2719b98a" category="list-text"><block ref="efb954cbfdbe0c54f04c904a2719b98a" category="inline-link-macro-rx"></block></block>
  <block id="6fe85aae6e8fa231a1f417edfeef3759" category="doc">vSphere VMFS 数据存储库—具有 ONTAP 的 iSCSI 存储后端</block>
  <block id="4f6f7882fc7b858bc0eb3e3a41991494" category="paragraph">本节介绍如何使用 ONTAP iSCSI 存储创建 VMFS 数据存储库。</block>
  <block id="383b1f30f341cb0eff11db96d70e9f50" category="list-text">管理 vSphere 环境和 ONTAP 所需的基本技能。</block>
  <block id="47c341511ad626bfba98caeaa0762774" category="list-text">iSCSI 的 ONTAP 网络端口， SVM 和 LUN 信息</block>
  <block id="f76f5dc5c6861d7938aa8d60b08976c8" category="inline-link-macro">一份完整的 iSCSI 配置工作表</block>
  <block id="275e54409e966e03b62ee630e4856daa" category="list-text"><block ref="275e54409e966e03b62ee630e4856daa" category="inline-link-macro-rx"></block></block>
  <block id="980e76f4fd03b06bfe740133284e92a9" category="list-text">使用 ONTAP 系统网络数据端口并连接 vSphere 主机</block>
  <block id="3a6f48cf422509b67592ce2a0b4dd558" category="list-text">为 iSCSI 配置的 VLAN</block>
  <block id="a9df884192a193f56d8208439b4d1fca" category="list-text">检查与的兼容性<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block>。</block>
  <block id="881de4e9f9e9dba55f3d9f09d3fc8eac" category="inline-link-macro">验证是否支持 iSCSI 配置。</block>
  <block id="6a2fb6d042919f5807315156f926ab10" category="list-text"><block ref="6a2fb6d042919f5807315156f926ab10" category="inline-link-macro-rx"></block></block>
  <block id="f04a1b9690234d25ff072d6719666947" category="inline-link-macro">验证 iSCSI 的 ONTAP 许可证</block>
  <block id="41bf6980693d9ba9f5e7a797fe2f4417" category="list-text"><block ref="0767ceac1f7ac130ade75fb7fae3fc53" category="inline-link-macro-rx"></block>。</block>
  <block id="3ffc628bd3f213f0998146fb5262f366" category="list-text">使用 `ssystem license show` 命令检查是否列出了 iSCSI 。</block>
  <block id="d1b0a5732b3cb229ef0f788fbb095f05" category="list-text">使用 `license add -license-code &lt; 许可证代码 &gt;` 添加许可证。</block>
  <block id="97035bc2443de65f877c3fddd838c6ae" category="inline-link-macro">验证是否已在 SVM 上启用 iSCSI 协议。</block>
  <block id="3807dbdaab3b890b6a293c99c7b46f63" category="list-text"><block ref="3807dbdaab3b890b6a293c99c7b46f63" category="inline-link-macro-rx"></block></block>
  <block id="cb66a92bc9fa6195f8b2914bcf868664" category="list-text">验证 iSCSI 网络逻辑接口在 SVM 上是否可用。</block>
  <block id="da91d0d17d1f671a0af23e7ebb96ec92" category="admonition">使用 GUI 创建 SVM 时，还会创建 iSCSI 网络接口。</block>
  <block id="da6a83da2309e8dbd81bb5b55c7c9602" category="list-text">使用 `Network interface` 命令查看或更改网络接口。</block>
  <block id="53fd22677faa2085c1fc51f1d116faff" category="admonition">建议每个节点使用两个 iSCSI 网络接口。</block>
  <block id="69fea75e454b43e67ba176dddb604159" category="inline-link-macro">创建 iSCSI 网络接口。</block>
  <block id="1bc0e04873be7c6291aef492ff2785cc" category="list-text"><block ref="d503e168b9096ac416caa1c8f13ab28a" category="inline-link-macro-rx"></block> 您可以使用 default-data-blocks 服务策略。</block>
  <block id="bd494b2c15d88a1dfa29c308b39e8f6e" category="inline-link-macro">验证 data-iscsi 服务是否包含在服务策略中。</block>
  <block id="c436a9a899f5e1cfacf8828c90931ca9" category="list-text"><block ref="24788d985e181b3194881517c2ec7650" category="inline-link-macro-rx"></block> 您可以使用 `network interface service-policy show` 进行验证。</block>
  <block id="c0e1d066d0482fc5cc1554edaa3f36b2" category="inline-link-macro">验证是否已启用巨型帧。</block>
  <block id="a355e4512cfabb746ee4c05a87a61107" category="list-text"><block ref="a355e4512cfabb746ee4c05a87a61107" category="inline-link-macro-rx"></block></block>
  <block id="5ccd820a879b8d1daef5e44125431184" category="inline-link-macro">创建并映射 LUN 。</block>
  <block id="c49b54ab60508b16176724eeb8118049" category="list-text"><block ref="3a73ce9b9237c3e09863bf7b049ce423" category="inline-link-macro-rx"></block> 如果您使用适用于 VMware vSphere 的 ONTAP 工具，请跳过此步骤。对每个 LUN 重复此步骤。</block>
  <block id="5c9b297b088335a8562568dc59549c7d" category="list-text">验证 iSCSI VLAN 是否至少有一个可用 NIC 。为了提高性能和容错能力，最好使用两个 NIC 。</block>
  <block id="fe9e58c95c20042a4032ef737d6e8400" category="inline-link-macro">确定 vSphere 主机上可用的物理 NIC 的数量。</block>
  <block id="96cf3cacac94299a7630f48f5cf5b7e3" category="list-text"><block ref="96cf3cacac94299a7630f48f5cf5b7e3" category="inline-link-macro-rx"></block></block>
  <block id="87d3329dab6e8f24601b6f45d40614ea" category="inline-link-macro">配置 iSCSI 启动程序。</block>
  <block id="536d7ac288972152b209e6f004917285" category="list-text"><block ref="95a6e2e5fae04247474cdc6a729342fc" category="inline-link-macro-rx"></block> 典型的使用情形是软件 iSCSI 启动程序。</block>
  <block id="fd823eb37045485458bb3d5d52ddc46f" category="inline-link-macro">验证 iSCSI 的 TCPIP 堆栈是否可用</block>
  <block id="875d65383afa504aad11a619d920adc7" category="list-text"><block ref="025b4ff12eca60b6c5b5be76597b5e95" category="inline-link-macro-rx"></block>。</block>
  <block id="e45f6655250b094b5a8370ff511869c3" category="inline-link-macro">验证 iSCSI 端口组是否可用</block>
  <block id="4c93429599cf15be2af5aa0f59131c17" category="list-text"><block ref="5e67546a702454fa060946b3e582d0e9" category="inline-link-macro-rx"></block>。</block>
  <block id="b7b554d373b5992838a126134a03ba0d" category="list-text">我们通常使用具有多个上行链路端口的单个虚拟交换机。</block>
  <block id="879d70f2184599f483fd94f0f274163f" category="list-text">使用 1 ： 1 适配器映射。</block>
  <block id="9f60e3586ab900b8f879404be003b539" category="list-text">验证是否已启用 iSCSI VMKernel 适配器以匹配 NIC 数量，以及是否已分配 IP 。</block>
  <block id="3e6e09b1cda3200c7407173a3473a103" category="inline-link-macro">将 iSCSI 软件适配器绑定到 iSCSI VMKernel 适配器。</block>
  <block id="70d687ef257c5d00e0d85844c0101c77" category="list-text"><block ref="70d687ef257c5d00e0d85844c0101c77" category="inline-link-macro-rx"></block></block>
  <block id="187fbd973609969af8f47e857f8579c4" category="inline-link-macro">使用 ONTAP 工具配置 VMFS 数据存储库</block>
  <block id="1e9df60603ff2a9fe2495b189aecc647" category="list-text"><block ref="efecd5d76f6fc92c9c9a8111cf809724" category="inline-link-macro-rx"></block>。对所有数据存储库重复此步骤。</block>
  <block id="5f4723c28ea2b13a27b86c1116720a8a" category="inline-link-macro">验证硬件加速支持。</block>
  <block id="aa0cfa24dd578f0629299a21b453583c" category="list-text"><block ref="aa0cfa24dd578f0629299a21b453583c" category="inline-link-macro-rx"></block></block>
  <block id="1d3fa7ee382266d716ba7a360f30f188" category="paragraph">完成这些任务后， VMFS 数据存储库便可用于配置虚拟机。</block>
  <block id="53001b412ce4896686a413a19f6dcc5f" category="listing-title">Ansible 攻略手册</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">VMotion</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="section-title">适用于 VMware vSphere 的 ONTAP 工具</block>
  <block id="54452390cac5f65f3bcec580ba079531" category="section-title">FlexGroup</block>
  <block id="2abfff2974f589f7a217325f304e0ec5" category="list-text">ONTAP 9.8</block>
  <block id="fa7b524ea902bff51145e4279b653d84" category="summary">此页面提供了视频和教程的简介。</block>
  <block id="4267881eb271396086a3cc1387da9a3a" category="section-title">NetApp 与 VMware Tanzu</block>
  <block id="2dd739333b022cfeccd93e19c8c39d83" category="paragraph">借助 VMware Tanzu ，客户可以通过 vSphere 或 VMware Cloud Foundation 部署，管理和管理 Kubernetes 环境。通过 VMware 的这一产品组合，客户可以选择最适合其需求的 VMware Tanzu 版本，从一个控制平台管理所有相关的 Kubernetes 集群。</block>
  <block id="f8d0723a562ed498a977795477b75cb0" category="inline-link">VMware Tanzu 概述</block>
  <block id="2d3e9ef8ae693e8ff80c4d6e70f0a876" category="paragraph">有关 VMware Tanzu 的详细信息，请参见<block ref="1951d4038519ab642a1c0f8898cecfe0" category="inline-link-rx"></block>。此审核涵盖使用情形，可用添加内容以及有关 VMware Tanzu 的更多信息。</block>
  <block id="2426b725f5be26f50931584ae804c2eb" category="inline-link">Red Hat OpenShift 概述</block>
  <block id="02d4482d332e1aef3437cd61c9bcc624" category="doc">请联系我们</block>
  <block id="93ac3f76e97265952e309b2cbb980030" category="summary">此页面提供了在 VMware vSphere 环境中部署 NetApp ONTAP NFS 版本 4 数据存储库的步骤。</block>
  <block id="11bbb95c80fd3935828f1472bade3ae4" category="doc">vSphere NFS 数据存储库—使用 ONTAP 的 4.1 版</block>
  <block id="0a339846bb9d45c2252cf84f27f8390e" category="paragraph">本节介绍如何使用 ONTAP NAS 存储创建 NFS 4.1 版数据存储库。</block>
  <block id="d5ffdd3b223c5bb3d1d66e5756977564" category="list-text">管理 vSphere 环境和 ONTAP 所需的基本技能</block>
  <block id="7d0a7cdd836d94b19d4ecbce81ba2c1e" category="list-text">连接了 ONTAP 系统网络数据端口， vSphere 主机和</block>
  <block id="d4e890b3139e840bac898dc24d2330a3" category="list-text">适用于 VMware vSphere 的 ONTAP 工具已部署，配置并可随时使用</block>
  <block id="f2f6f93a63f235f63bf8a14ad398ddd0" category="inline-link">互操作性表工具（ IMT ）</block>
  <block id="2c364f266e330209041f2cf854afab91" category="list-text">使用检查兼容性<block ref="975c7893d48b02c6727b59b0582d74bc" category="inline-link-rx"></block></block>
  <block id="863feef43abaa752e441459bd37722c3" category="list-text">完成下面提供的 ONTAP 和 vSphere 任务。</block>
  <block id="1b2d2406823c016e35ebeddf0ec29c66" category="inline-link-macro">验证 NFS 的 ONTAP 许可证</block>
  <block id="7209cd833425a764d216b4e565ac65c6" category="list-text"><block ref="7209cd833425a764d216b4e565ac65c6" category="inline-link-macro-rx"></block></block>
  <block id="55d2948d4abb6ad9ea1e2b6a5b73460b" category="list-text">使用 `ssystem license show` 命令检查是否列出了 NFS 。</block>
  <block id="0a5e80a3066e5036387d5026a58fe582" category="inline-link-macro">按照 NFS 配置工作流进行操作</block>
  <block id="4b9e38c0f910614d9be47f85cf0f07bc" category="list-text"><block ref="4b9e38c0f910614d9be47f85cf0f07bc" category="inline-link-macro-rx"></block></block>
  <block id="4344c7f5d714fb1797033b7d9cca43fd" category="inline-link-macro">按照适用于 vSphere 的 NFS 客户端配置工作流进行操作。</block>
  <block id="c9fb47d82da1089992044972b4b65103" category="paragraph"><block ref="c9fb47d82da1089992044972b4b65103" category="inline-link-macro-rx"></block></block>
  <block id="a7ba4bd9aa10b0456b8f13ef40a2d1d5" category="summary">此页面提供了在 VMware vSphere 环境中部署 NetApp ONTAP 存储 FCoE VMFS 数据存储库的步骤。</block>
  <block id="1937a4bfde18bb02682d378132d0b6a9" category="doc">vSphere VMFS 数据存储库—采用 ONTAP 的以太网光纤通道存储协议</block>
  <block id="66439ac6171413528646918952bff23e" category="paragraph">本节介绍如何使用以太网光纤通道（ FCoE ）传输协议创建与 ONTAP 存储的 VMFS 数据存储库。</block>
  <block id="d9da372e69584852a9808bfa9fcc99a9" category="inline-link-macro">支持的 FCoE 组合</block>
  <block id="b61947ecee08267d1f6930ccbd646d52" category="list-text"><block ref="b61947ecee08267d1f6930ccbd646d52" category="inline-link-macro-rx"></block></block>
  <block id="08b42ec45ef1147093b9161cc743b0a0" category="inline-link-macro">完成的配置工作表</block>
  <block id="bcf78e9148ebbc12ed4a54d2149cc2bc" category="list-text"><block ref="bcf78e9148ebbc12ed4a54d2149cc2bc" category="inline-link-macro-rx"></block></block>
  <block id="80ba2a0b5b5ae31742a18c682e724b6e" category="list-text">连接了 ONTAP FC 数据端口或 vSphere 主机</block>
  <block id="d7b3fbe677a7bffd7e387a3578d6b481" category="inline-link-macro">已配置 FC/FCoE 分区</block>
  <block id="434da439fcd2a7729ac67cef537d6651" category="list-text"><block ref="434da439fcd2a7729ac67cef537d6651" category="inline-link-macro-rx"></block></block>
  <block id="5d914ccaef7b5404838cb47cff27fa11" category="list-text">支持 FCoE</block>
  <block id="b74438cda33fca6618da9e30ef5fee5d" category="list-text">支持 DCB</block>
  <block id="69b788fe29f78e1fb439efd1bec08ab6" category="inline-link-macro">FCoE 的巨型帧</block>
  <block id="e92f4c11834e879e94fa441894d8e9c9" category="list-text"><block ref="e92f4c11834e879e94fa441894d8e9c9" category="inline-link-macro-rx"></block></block>
  <block id="42cdbee955a0e208306a321b74a948b1" category="section-title">配置 VMFS 数据存储库</block>
  <block id="f067d14dc86c5c0ec984803b3485a7a6" category="inline-link-macro">验证是否支持 FCoE 配置</block>
  <block id="79d164739c1e0aaf7f56e13c2a4c66ac" category="list-text"><block ref="4201ef99768aac8f72883e5cb6ec656f" category="inline-link-macro-rx"></block>。</block>
  <block id="1a04100ec801e5e2d1708d89eb1159b6" category="inline-link-macro">验证 FCP 的 ONTAP 许可证。</block>
  <block id="7fcd357d480b8eaa4a38cdbbddfd6c97" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block></block>
  <block id="f2a0a9000f5ff3910235e570c0ac5e44" category="list-text">使用 `ssystem license show` 命令验证是否已列出 FCP 。</block>
  <block id="e5b8ca3e9ff580bcc9315fabcb34312e" category="list-text">验证是否已在 SVM 上启用 FCP 协议。</block>
  <block id="015c565181667d59b83b7761e35682d1" category="inline-link-macro">使用 FCP 创建新的 SVM 。</block>
  <block id="de4606f963140e2d2d0a3df251ffd646" category="list-text"><block ref="de4606f963140e2d2d0a3df251ffd646" category="inline-link-macro-rx"></block></block>
  <block id="2d6fd01ea0767b50e214a74ff1fcfae0" category="list-text">验证 SVM 上的 FCP 逻辑接口是否可用。</block>
  <block id="46f04290f169589dff914e050d1a987b" category="list-text">使用图形用户界面创建 SVM 时，逻辑接口就是该过程的一部分。</block>
  <block id="ee7f4720a3fc60686c4a9f7429a60cbc" category="list-text">要重命名网络接口，请使用 `Network Interface modify` 。</block>
  <block id="6e67c7d604ae439f60ceb51480fdbb1c" category="inline-link-macro">创建并映射 LUN</block>
  <block id="e4eeb9421963195597743339d2f38ff6" category="list-text"><block ref="96e32c32f267ac1d65d603f36f017a41" category="inline-link-macro-rx"></block>；如果您使用适用于 VMware vSphere 的 ONTAP 工具，请跳过此步骤。</block>
  <block id="f6c0391a150cfd40a68682285c56e835" category="inline-link-macro">存储适配器信息</block>
  <block id="60f05805eb8189d665c19856d5388e3c" category="list-text">验证是否已安装 HBA 驱动程序。VMware 支持的 HBA 已开箱即用部署驱动程序，应在中显示这些驱动程序 <block ref="c5f1cce809af8cfecf09908d33f4c097" category="inline-link-macro-rx"></block>。</block>
  <block id="d4f43ea12f3f521c93fb3dd4d93c428d" category="summary">此页面介绍了在 VMware vSphere 环境中为 VMFS 数据存储库部署 NetApp ONTAP NVMe/FC 存储的步骤。</block>
  <block id="9e433440cdaf3b61716784200e8abf6d" category="doc">vSphere VMFS 数据存储库—采用 ONTAP 的 NVMe/FC</block>
  <block id="9367f3df6c8d54eba1da3cd9c5fa2776" category="paragraph">本节介绍如何使用 NVMe/FC 使用 ONTAP 存储创建 VMFS 数据存储库。</block>
  <block id="6af0e7a38739ed6e2658342101a7b51e" category="list-text">管理 vSphere 环境和 ONTAP 所需的基本技能。</block>
  <block id="7890464cdce93f078097395e27132775" category="inline-link-macro">基本了解 NVMe/FC</block>
  <block id="c6e7cd589502f52a9398e779ede56d14" category="list-text"><block ref="62a43aa3bd2eb01e27a6091d3017311c" category="inline-link-macro-rx"></block>。</block>
  <block id="2ec64af43682ffa45eeaf33a86950347" category="list-text">主机，目标和 SVM 以及 LUN 信息的 ONTAP WWPN</block>
  <block id="62eadfe081f86e1f9a72988a4feb7bfc" category="inline-link-macro">填写完整的 FC 配置工作表</block>
  <block id="f186921a73873df63dc496b515bc2099" category="list-text"><block ref="f186921a73873df63dc496b515bc2099" category="inline-link-macro-rx"></block></block>
  <block id="c4436d4a190778b7ec1e9461f6454bdd" category="list-text">vCenter Server</block>
  <block id="60ce38e4967c52c316eff771b7a3c4ec" category="list-text">连接了 ONTAP FC 数据端口和 vSphere 主机。</block>
  <block id="32086766e64ae646fcadddc3e16b203b" category="list-text">启用 N_port ID 虚拟化（ NPIV ）功能。</block>
  <block id="b6e0bd021536c90aa87cfea18d73d453" category="list-text">创建一个启动程序目标分区。</block>
  <block id="f386e9f209710f55d41a97e9502d1c7c" category="list-text">对于每个分区，包括一个目标，该目标是 SVM 的 ONTAP FC 逻辑接口（ WWPN ）。每个 SVM 的每个节点至少应有两个逻辑接口。请勿使用物理端口的 WWPN 。</block>
  <block id="71d4977f0fd6be92644e1ff9f8096637" category="section-title">配置 VMFS 数据存储库</block>
  <block id="f42c50210dcc0a3a69c8258256e75e4b" category="inline-link-macro">验证是否支持 NVMe/FC 配置。</block>
  <block id="5312bcc81ee6d7bce6549b2089c9d1ac" category="list-text"><block ref="5312bcc81ee6d7bce6549b2089c9d1ac" category="inline-link-macro-rx"></block></block>
  <block id="9d17f91ad987b7e7cf2fa7249cd97343" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block>使用 `ssystem license show` 命令检查是否列出了 NVMe_oF 。使用 `license add -license-code &lt; 许可证代码 &gt;` 添加许可证。</block>
  <block id="7193bed15c5b4f7c80f1f19630b57e1e" category="list-text">验证是否已在 SVM 上启用 NVMe 协议。</block>
  <block id="5eabd2d7390fc49cb61f882324bdcac0" category="inline-link-macro">为 NVMe 配置 SVM 。</block>
  <block id="f2fd2de931ce484e947c89ae8207346a" category="list-text">验证 NVMe/FC 逻辑接口在 SVM 上是否可用。</block>
  <block id="978583cfbb47e2700c599c43b7949a53" category="list-text">使用图形用户界面创建 SVM 时，逻辑接口将作为该过程的一部分。</block>
  <block id="3866119a70b69102c1584c0baa386190" category="list-text">要重命名网络接口，请使用命令 `Network Interface modify` 。</block>
  <block id="6ad7e9002145710745843d16314895e3" category="inline-link-macro">创建 NVMe 命名空间和子系统</block>
  <block id="06badf30aa173febc3374aceef25c5ce" category="list-text"><block ref="06badf30aa173febc3374aceef25c5ce" category="inline-link-macro-rx"></block></block>
  <block id="c6613394adcc7526a48f6e92b61ee067" category="list-text">验证是否已安装 HBA 驱动程序。VMware 支持的 HBA 已开箱即用部署驱动程序，应可从查看这些驱动程序 <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block></block>
  <block id="9761a89a99469e468e71b7a0087be29d" category="inline-link-macro">执行 vSphere 主机 NVMe 驱动程序安装和验证任务</block>
  <block id="926e4d89379d3dde2510965ca53771af" category="list-text"><block ref="926e4d89379d3dde2510965ca53771af" category="inline-link-macro-rx"></block></block>
  <block id="e229fd9b7b8948ddebf276bda8a9145e" category="inline-link-macro">创建 VMFS 数据存储库</block>
  <block id="3dbbea9263919f89335d7ba053f09a39" category="list-text"><block ref="3dbbea9263919f89335d7ba053f09a39" category="inline-link-macro-rx"></block></block>
  <block id="a123daaac5749e4d0965aca160f0adfd" category="doc">NetApp 解决方案自动化</block>
  <block id="d1029167179320d8b6d70b11c3d01bd3" category="list-text">Ansible 控制节点的要求，：</block>
  <block id="9ced761647f5d80fe615526ffff63937" category="list-text">安装了以下软件包的 Ubuntu 或 Debian 计算机：</block>
  <block id="ca60b3698dd3d27a5f91e4dc0a1a2546" category="list-text">Python3.</block>
  <block id="4ce3ea126bb844d4f8c4ce1a65cbe3ae" category="list-text">Pip3.</block>
  <block id="881cbd1ce3fdb52f73a82f8674a2a364" category="list-text">Ansible （版本高于 2.10.0 ）</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="list-text">Git</block>
  <block id="6e3d8a0ff7934b777031953fe936bac8" category="paragraph">如果您的新 Ubuntu 或 Debian 计算机未安装上述要求，请按照以下步骤将该计算机设置为 Ansible 控制节点：</block>
  <block id="d82dd9b3245382b365106db0568113e8" category="summary">借助 NetApp 解决方案自动化，客户可以自动部署，配置和执行许多常见的基础架构和应用程序任务。</block>
  <block id="90305bb6fba97091f683e8b82f9bf805" category="summary">借助 NetApp 解决方案自动化，客户可以自动部署，配置和执行许多常见基础架构和应用程序任务。</block>
  <block id="5c263f30899f93ff7ccd457ad3eb956f" category="list-text">安装了以下软件包的 RHEL/CentOS 计算机：</block>
  <block id="7b643b0eef9cf1199195fa05b77fc3c8" category="paragraph">如果您的新 RHEL/CentOS 计算机未安装上述要求，请按照以下步骤将该计算机设置为 Ansible 控制节点：</block>
  <block id="d2052f202108defaf6afc7831ba59362" category="list-text">为 RHEL/8/RHEL/7 启用 Ansible 存储库</block>
  <block id="61fbc2f21db84f17551fda6893429d16" category="list-text">对于 RHEL/8 （以 root 用户身份运行以下命令）</block>
  <block id="77cd42f765e6b40764459a64a979f90c" category="list-text">对于 RHEL/7 （以 root 用户身份运行以下命令）</block>
  <block id="2aa17d37bd2483f97468ab7653396786" category="paragraph">本节介绍在 AWX/Ansible 塔中配置参数所需的步骤，这些参数可为使用 NetApp 自动化解决方案的环境做好准备。</block>
  <block id="0fb1db9928d7fc107d96c13f1918b639" category="list-text">导航到资源→清单→添加，然后单击添加清单。</block>
  <block id="2623b8eb8fcaecc009c3b78cc6e7d391" category="list-text">提供名称和组织详细信息，然后单击保存。</block>
  <block id="cc243ac3e015aef331656a4bff40241c" category="list-text">在清单页面中，单击刚刚创建的清单资源。</block>
  <block id="b0ddb214e9aa4a84bc80e6af8c6b2adf" category="list-text">如果存在任何清单变量，请将其粘贴到变量字段中。</block>
  <block id="5d7863780eab69b6b968cfc9dc6e66bc" category="list-text">转到组子菜单，然后单击添加。</block>
  <block id="ec51931bb91bc912d609f2099974dfd9" category="list-text">提供组的名称，复制组变量（如果需要），然后单击保存。</block>
  <block id="8f9cbdc13fdcb31ff345f10ba333ac59" category="list-text">单击创建的组，转到主机子菜单，然后单击添加新主机。</block>
  <block id="98e7a99b463b825a87899d25486e46ea" category="list-text">提供主机的主机名和 IP 地址，粘贴到主机变量中（如有必要），然后单击保存。</block>
  <block id="3caf9a56384a30eb8dee819e3abc14d6" category="list-text">创建凭据类型。对于涉及 ONTAP ， Element ， VMware 或任何其他基于 HTTPS 的传输连接的解决方案，您必须将凭据类型配置为与用户名和密码条目匹配。</block>
  <block id="615b6214c17105ae4915a8c8a632025b" category="list-text">导航到 Administration → Credential types ，然后单击 Add 。</block>
  <block id="846bb9303e5cc4395e96eba0d4c7d50a" category="list-text">将以下内容粘贴到输入配置中：</block>
  <block id="333a40c5632e0507a83f6a191f0b69b3" category="list-text">将以下内容粘贴到注射器配置中：</block>
  <block id="e31908e83a96aee8550446309c4ef7e0" category="list-text">配置凭据。</block>
  <block id="de06c7b54d4158f81a8c4d4a02b61eb0" category="list-text">导航到资源→凭据，然后单击添加。</block>
  <block id="e5b5f57b6910910a3f9a486e88088608" category="list-text">选择正确的凭据类型；如果要使用标准 SSH 登录，请选择类型 Machine 或选择您创建的自定义凭据类型。</block>
  <block id="9256ee926473942ba849050ef0450b7f" category="list-text">输入其他相应的详细信息，然后单击保存。</block>
  <block id="29d192f714134f2e257058cfcf763722" category="list-text">配置项目。</block>
  <block id="1b892b7661c6a3ae2b57cbf4233c3af5" category="list-text">导航到资源→项目，然后单击添加。</block>
  <block id="936784ca62c93ca666e77fd10733247c" category="list-text">为源控制凭据类型选择 Git 。</block>
  <block id="9f4fd9b4a4c75c02d1b469e8dd75d9fb" category="list-text">粘贴与特定解决方案对应的源控制 URL （或 git 克隆 URL ）。</block>
  <block id="95acbbc0424478165cdbe3a62849cbc3" category="list-text">或者，如果 Git URL 受访问控制，请在源控制凭据中创建并附加相应的凭据。</block>
  <block id="a934d780fa0cb0e8495a0a1cabd0f501" category="list-text">配置作业模板。</block>
  <block id="10c610c9225adcc92ca1b284b5bbb04b" category="list-text">输入名称和问题描述。</block>
  <block id="e33edf61d02fc69c2087dcc3c42177e1" category="list-text">选择作业类型； Run 会根据攻略手册配置系统， Check 会在不实际配置系统的情况下执行攻略手册的试运行。</block>
  <block id="57cf64ce7890d12e5a41d18b83979ffd" category="list-text">为攻略手册选择相应的清单，项目和凭据。</block>
  <block id="fc6b15b1dd73bb25477aed453b9a02f2" category="list-text">选择要在作业模板中运行的攻略手册。</block>
  <block id="9a7d90740af07bcdd2c628a6f6ae966c" category="list-text">通常，变量会在运行时粘贴。因此，要在运行时提示填充变量，请确保选中与 Variable 字段对应的 Launch 上的复选框提示。</block>
  <block id="3454f07e6f81a48099e0d144ca38ec7a" category="list-text">根据需要提供任何其他详细信息，然后单击保存。</block>
  <block id="0b55c84dbc04b54418b0d507f7b8f669" category="list-text">如果在启动时出现提示，请填写任何变量，然后再次单击启动。</block>
  <block id="dca91c3343cc0ad062506cdd14eb7d41" category="summary">混合云，桌面虚拟化和容器解决方案宣传材料的最新补充内容</block>
  <block id="07e257430bade6bc5bce1c2170c6fc0d" category="paragraph">概述最新的混合云，桌面虚拟化和容器解决方案和解决方案宣传材料。</block>
  <block id="c1e392a90896851b3319d6075402fd4d" category="cell">* 混合云 / 私有云 *</block>
  <block id="8ef4e9c7260e8d314760329e07c618ae" category="cell">* 虚拟化 *</block>
  <block id="2bdc87f51d413e6d2fa23dd26238501f" category="inline-link-macro">适用于 ONTAP 的 VMware vSphere</block>
  <block id="236122c6ab4c764632437a76fa95e5c0" category="cell">* 桌面虚拟化 *</block>
  <block id="4b47c65474ab7fae9b08ddf38d598971" category="inline-link-macro">采用 NetApp 虚拟桌面服务（ Virtual Desktop Service ， VDS ）的混合云 VDI</block>
  <block id="dea91bec9e85387a496bb2c228fc7dc3" category="cell"><block ref="dea91bec9e85387a496bb2c228fc7dc3" category="inline-link-macro-rx"></block></block>
  <block id="1ebfe0d8e53e3f7f2c37e8b3835c2adf" category="cell">* 容器 *</block>
  <block id="119ad672b0d69ab3f968877b6ec83dd3" category="cell"><block ref="119ad672b0d69ab3f968877b6ec83dd3" category="inline-link-macro-rx"></block></block>
  <block id="ad1cf94aab71c9962e22037ed60d41e9" category="cell"><block ref="ad1cf94aab71c9962e22037ed60d41e9" category="inline-link-macro-rx"></block></block>
  <block id="e6ba927c9d14295015e39be05cf54040" category="inline-link-macro">使用 NetApp ONTAP 在 Red Hat OpenShift 上使用多租户</block>
  <block id="ab439bcac737f2565970fe2612976b75" category="cell"><block ref="ab439bcac737f2565970fe2612976b75" category="inline-link-macro-rx"></block></block>
  <block id="ad95c47343e102dc30ec33fa6f1ccc55" category="inline-link-macro">NVA-1160 —采用 NetApp 技术的 Red Hat OpenShift</block>
  <block id="1043b5153afff839b84d714aa9127913" category="cell"><block ref="1043b5153afff839b84d714aa9127913" category="inline-link-macro-rx"></block></block>
  <block id="0fd00a19fb12bb899dfe7cefbcbbcb79" category="inline-link-macro">在 Red Hat OpenShift 上安装 NetApp Trident —如何解决 Docker 的 ‘所有请求 ' 问题描述！</block>
  <block id="43e5d9153d1fc4a35be5f57189605919" category="cell"><block ref="43e5d9153d1fc4a35be5f57189605919" category="inline-link-macro-rx"></block></block>
  <block id="da38226e07ff21f147182bb08be38f6f" category="inline-link-macro">采用 NetApp 技术的裸机 Anthos</block>
  <block id="ac1da2af455fc001ba8b58af0e62d151" category="cell"><block ref="ac1da2af455fc001ba8b58af0e62d151" category="inline-link-macro-rx"></block></block>
  <block id="ec7f98a3714557d87968dc6a898f7912" category="inline-link-macro">将 VMware Tanzu 与 ONTAP 结合使用，加快 Kubernetes 之旅</block>
  <block id="32e124b0349f41e06bf1e03f11950665" category="list-text"><block ref="32e124b0349f41e06bf1e03f11950665" category="inline-link-macro-rx"></block></block>
  <block id="e7f098b026755d10f2c3f16d0ff0b1db" category="inline-link-macro">设计指南</block>
  <block id="1027b152cc3e8165ce099ede9548be95" category="cell"><block ref="1027b152cc3e8165ce099ede9548be95" category="inline-link-macro-rx"></block></block>
  <block id="dfb1e9c5f4c5835e6e1a4173130a49c9" category="inline-link-macro">部署指南</block>
  <block id="983044e3ba861493c43c08b9285c3125" category="cell"><block ref="983044e3ba861493c43c08b9285c3125" category="inline-link-macro-rx"></block></block>
  <block id="d91f70a15d40fe5795af6ded9555e095" category="cell"><block ref="d91f70a15d40fe5795af6ded9555e095" category="inline-link-macro-rx"></block></block>
  <block id="8e9465b5d4318c8ef9039dfe684619d5" category="cell"><block ref="8e9465b5d4318c8ef9039dfe684619d5" category="inline-link-macro-rx"></block></block>
  <block id="4725a75839c620bb95363c5f7f2ee9bc" category="cell">VMware Horizon</block>
  <block id="9efcc0ad3c93b238cc0495e3c87b715f" category="inline-link-macro">借助 Ansible 在 FlexPod 上自动部署 Oracle 19c RAC</block>
  <block id="33be49f7ebc56eb7d336a201f7ac0df6" category="inline-link-macro">基于 Azure NetApp Files 的 SAP</block>
  <block id="e131204502a58630f2f72937238604c8" category="section-title">视频 / 演示</block>
  <block id="cf04feec36847ba9c9671b28661cd1fc" category="sidebar">NetApp 解决方案文档</block>
  <block id="38d9ffc674675d65fbb8aabd7e47acd3" category="sidebar">FlexPod 解决方案</block>
  <block id="3523ec156cfc8217bb64d1273e5663fa" category="sidebar">关于 NetApp 解决方案</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="sidebar">NetApp DataOps 工具包</block>
  <block id="17c3771ed0b6c1ae15740eff715e9922" category="sidebar">视频和演示</block>
  <block id="0333ddced253ee1c6929eda5612dea92" category="sidebar">请求自动化</block>
  <block id="9e2c62f406d88ad1ee253efd74f593df" category="sidebar">建议新的解决方案</block>
  <block id="7fd861566be88364067d817b54a44688" category="sidebar">提供解决方案反馈</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">适用于不同分析策略的不同解决方案解决方案简介</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">采用 Splunk SmartStore 的 NetApp StorageGRID</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E 系列 E5700 和 Splunk Enterprise</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">《使用 NetApp Storage 解决方案的 Apache Spark 工作负载》（部署指南）</block>
  <block id="cdc53c90644739ab9cb455ad8b663d7b" category="sidebar">Red Hat OpenShift 概述</block>
  <block id="d48e549b4fdcc889e0243c53bbb4dda0" category="sidebar">解决方案验证和使用情形</block>
  <block id="f99e4eb05e28c150680cb72ca8410d93" category="sidebar">使用 NetApp ONTAP 在 Red Hat OpenShift 上配置多租户</block>
  <block id="51a25aff8c490f11d9be543c7af23a0d" category="sidebar">集群管理员任务</block>
  <block id="244e9cd91466ef1240c125511568880a" category="sidebar">存储管理员任务</block>
  <block id="bc967dc2d57e6eff184a821bf7577a80" category="sidebar">扩展</block>
  <block id="d6bf2b10101446c7afd28ff94926fc44" category="sidebar">通过操作员部署</block>
  <block id="e6b088db24ebe67ed0e9567d309387ec" category="sidebar">工作流</block>
  <block id="88c506562ebadd679bb16d76a4558619" category="sidebar">VM 克隆</block>
  <block id="d313887d8fa4b2493a50d1e00bad440e" category="sidebar">应用程序生命周期管理</block>
  <block id="f55899cffbf639043209795d5a1af970" category="sidebar">创建资源</block>
  <block id="9a9891facf2fa1c878c0fc18c6638005" category="sidebar">AI 融合基础架构</block>
  <block id="12797522e94d75727dd0a05a4ed9f5ff" category="sidebar">采用 NVIDIA 的 ONTAP AI</block>
  <block id="687350c847aefbf978e16be26609d101" category="sidebar">采用 NVIDIA DGX A100 的 ONTAP AI 系统设计指南</block>
  <block id="4c7a8c5b878fcdf733694f638b393b6b" category="sidebar">采用 NVIDIA DGX A100 的 ONTAP AI 系统部署指南</block>
  <block id="74c684b866e5fcffcc9c5165a491d5b2" category="sidebar">采用 NVIDIA DGX A100 系统和 Mellanox 频谱以太网交换机的 ONTAP AI 设计指南</block>
  <block id="f8363659ae3ab117a0afa4163ca69fc7" category="sidebar">《采用 NVIDIA DGX A100 系统和 Mellanox 频谱以太网交换机的 ONTAP AI 部署指南》</block>
  <block id="0c3efd7c1aae12456ab9935ae5fd15e0" category="sidebar">采用 NVIDIA DGX A100 系统和 BeeGFS 的 EF 系列 AI</block>
  <block id="c70e778edabe427cd2db90132a56e456" category="sidebar">采用 NVIDIA DGX A100 系统和 BeeGFS 设计的 EF 系列 AI</block>
  <block id="06aa576b3e3e95c5df800228d146af65" category="sidebar">采用 NVIDIA DGX A100 系统和 BeeGFS 部署的 EF 系列 AI</block>
  <block id="2967ab4748573d0cb6f2c4084c4fd70f" category="sidebar">采用 NetApp E 系列参考架构的 BeeGFS</block>
  <block id="1db760587a86f5c1b9ab39aa8cf8cf3d" category="sidebar">使用 NetApp E 系列存储部署 IBM Spectrum Scale</block>
  <block id="e648dd2d4df65a903e9c1204d81abaed" category="sidebar">适用于 AI 和 ML 模型培训工作负载的 NetApp AFF A800 和 Fujitsu 服务器 PRIMERGY GX2570 M5</block>
  <block id="6a571fb799acb43b64f874729f838e2a" category="sidebar">数据管道，数据湖和管理</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">适用于自主驾驶工作负载的 NetApp StorageGRID 数据湖</block>
  <block id="fad62e8b886e655813cc4ce635152f62" category="sidebar">Trident 部署</block>
  <block id="70be05b3500f28affc2d048f81c4f7ab" category="sidebar">分布式 Azure 培训—通道检测</block>
  <block id="7767872606b9c99eb656c9568c1fdd83" category="sidebar">车道检测—使用 Run AI 进行分布式培训</block>
  <block id="ce3b746194cb1fb7d96dfe14187115e0" category="sidebar">采用数据缓存的混合云 AI 操作系统</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">将数据从大数据环境迁移到 AI 环境</block>
  <block id="f1e7c981dec3bcee348bda96c55363c4" category="sidebar">使用 NVIDIA 的对话 AI</block>
  <block id="d5c1931461d1e204a84a486796df2cca" category="sidebar">NetApp Orchestration 解决方案与 Run ： AI</block>
  <block id="c0a0f5bbb431dea70000d73b29e50249" category="sidebar">使用 Run AI 优化集群和 GPU 利用率</block>
  <block id="09c995632f33d1ee4a581eb951793f35" category="sidebar">运行 AI 安装</block>
  <block id="5c9e37e6d7e6f5e3a76854d8343d626b" category="sidebar">运行 AI 信息板和视图</block>
  <block id="29ebede332931243e314d8a3f333c1a7" category="sidebar">在 Run AI CLI 中提交作业</block>
  <block id="2943702718c42a5063e0c70598cebdc6" category="sidebar">适用于自主驱动工作负载的 NetApp ONTAP AI 解决方案设计</block>
  <block id="d11813566a7c636e892d384601baf2c3" category="sidebar">适用于医疗保健的 NetApp ONTAP AI 参考架构：诊断成像</block>
  <block id="ab8526a90cc9cc979ddd23c87fff57bd" category="sidebar">适用于金融服务工作负载的 NetApp ONTAP AI 参考架构</block>
  <block id="6efd886c994d37b6577e22359be2310e" category="sidebar">使用 NetApp E 系列和 BeeGFS 进行 AI 部署</block>
  <block id="3863e8a73e226ce0c0a6ad02b90ee75b" category="sidebar">《采用 NetApp E 系列系统的 Quantum StorNext 设计指南》</block>
  <block id="7891972f4586e6ee183ea541991ebe9f" category="sidebar">《采用 NetApp E 系列系统的 Quantum StorNext 部署指南》</block>
  <block id="89447eb7454239e11376250fa04a88f7" category="sidebar">SAP 与使用集群模式 Data ONTAP 的 Windows 上的 Microsoft SQL Server</block>
  <block id="54d2cdd3035ca1cdff5803c30f2ed2e1" category="sidebar">部署 Oracle 数据库</block>
  <block id="c880b35e02dbb5854452c86028138e2a" category="sidebar">在 NetApp ONTAP 上部署 Oracle 数据库</block>
  <block id="699700175d80778f1738d906ee9540d5" category="sidebar">入门和要求</block>
  <block id="210fdbe41d80b2e8690a970de86a7ffb" category="sidebar">自动部署 Oracle 19c AWX/ 塔式服务器</block>
  <block id="13cf6478a61a7904a3062d587248fb75" category="sidebar">自动部署 Oracle 19c CLI</block>
  <block id="bc113eb23aa0579a5e1d93e97ca13635" category="sidebar">基于 NetApp EF 系列的 Oracle 数据库</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server</block>
  <block id="61def2ac347af2f10fd60cd67052a311" category="sidebar">参考设计（实时高级别设计）</block>
  <block id="7c02456b91ace7501ea6f18d1657dcf7" category="sidebar">打造现代化的 Microsoft SQL Server</block>
  <block id="5c008a8422e884d74da1d4b50a7ada55" category="sidebar">《采用 NetApp EF 系列的 Microsoft SQL Server 最佳实践指南》</block>
  <block id="a87e5ca19422686ef96f1e6799e9111d" category="sidebar">虚拟桌面服务（ Virtual Desktop Services ， VDS ）</block>
  <block id="dede82866780d163734b443c5f4d484e" category="sidebar">采用 NetApp 虚拟桌面服务的混合云 VDI</block>
  <block id="b89c617ff394cc85df3935994baa194b" category="sidebar">使用 Login VSI 进行单服务器负载测试</block>
  <block id="6abbceca4793ffe4b329045f63b4d219" category="sidebar">操作管理</block>
  <block id="1b31ca8ddb749644af37aa10b42e6930" category="sidebar">GPU 注意事项</block>
  <block id="a1da2a2d050a6b61256020afd015a056" category="sidebar">行业解决方案</block>
  <block id="3acc5e85d752378c6f1b9154f379b475" category="sidebar">VMware 最终用户计算（设计指南）</block>
  <block id="87e25a8d0e462ac8d7158e587f376605" category="sidebar">采用 VMware 和 NVIDIA GPU 的最终用户计算（设计指南）</block>
  <block id="d840a196af6c9e07c3ac3b20b15fb724" category="sidebar">使用 VMware 和 NVIDIA GPU 的最终用户计算（部署指南）</block>
  <block id="f93781578174ca3309bd3ac126884af4" category="sidebar">借助 VMware 实现 3D 图形的最终用户计算</block>
  <block id="e2a1b52ebd707739003f77464bbcaa80" category="sidebar">FlexPod 桌面虚拟化解决方案</block>
  <block id="6c30682e8603121e14abe8bab7bd88f3" category="sidebar">适用于 ONTAP 的 VMware 虚拟化</block>
  <block id="c0bf5949fe87e1e5caf42e4746cd0080" category="sidebar">采用 ONTAP 的 VMware vSphere 最佳实践</block>
  <block id="1918f1bc0ea91d0e5d8e37878d5ab562" category="sidebar">采用 NetApp ONTAP 9 的 VMware Site Recovery Manager</block>
  <block id="c4f0254bef611d7217287539f6e00feb" category="sidebar">VMware vSphere 自动化</block>
  <block id="86fbb5b9292be9b680987addfa410586" category="sidebar">传统块存储配置</block>
  <block id="805a0828a65bce146a58e3556113b017" category="sidebar">VMFS —光纤通道</block>
  <block id="26e113624e0cc32cbe2a26e1cde1da24" category="sidebar">VMFS —以太网光纤通道</block>
  <block id="8237af9088e8905784b1cb373e3a080d" category="sidebar">VMFS — iSCSI</block>
  <block id="94cab344ef7124917167bd5415b137cf" category="sidebar">VMFS —基于网络结构的 NVMe</block>
  <block id="348ee034e8868e5211a6501c09d4b0f0" category="sidebar">传统文件存储配置</block>
  <block id="614b997c0fb5abcd68fda0ab9ca05d69" category="sidebar">NFS — v3</block>
  <block id="912655e9dd57ab01b86691021957e61e" category="sidebar">NFS — v4.1</block>
  <block id="ce006038ddc2a04747fe5a2c9c43b8f5" category="sidebar">演示和教程</block>
  <block id="645198fb2e03205a7f761aeaff8ef26f" category="sidebar">NetApp 解决方案自动化和 Ansible 入门</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">请求自动化</block>
  <block id="bdca592f24222e5064192bb9e2f9af6e" category="sidebar">FlexPod — NetApp Cisco 解决方案</block>
  <block id="0da8a1ebf94a3a1e650dbfbd01c69dd9" category="sidebar">FlexPod 解决方案技术内容</block>
  <block id="32591d046a055939af0d128133dc8606" category="sidebar">FlexPod 销售页面</block>
  <block id="9e5a59ca9aef030e74a725dab3fb6dcf" category="paragraph">借助 Astra Trident 和 Red Hat OpenShift ，用户可以在所配置的存储类上创建永久性卷的快照。通过此功能，用户可以创建卷的时间点副本，并使用该副本创建新卷或将同一卷还原到先前的状态。这样可以启用或支持从回滚到克隆再到数据还原等各种使用情形。</block>
  <block id="05cd0cf0962d29806df78d956f772deb" category="summary">Astra Trident 是一款开源且完全受支持的存储编排程序，适用于容器和 Kubernetes 分发版，包括 Red Hat OpenShift 。</block>
  <block id="0626021388a8dcc9b1e26b1209550b8d" category="paragraph">Astra Trident 具有快速的开发周期，就像 Kubernetes 一样，每年发布四次。</block>
  <block id="4281e618126caa3d322e78eafddba1b2" category="section-title">下载 Astra Trident</block>
  <block id="f71051465199267cbb540658a51e2957" category="paragraph">完成 Astra Trident 操作员安装后，您必须为所使用的特定 NetApp 存储平台配置后端。请访问以下链接继续设置和配置 Astra Trident 。</block>
  <block id="7eba670f1ea5a6e2fba9cff6b6399064" category="summary">此页面详细介绍了 MetalLB 负载平衡器的安装和配置说明。</block>
  <block id="79a2d2fa50d2b47d02c0e9dbdfadc07f" category="doc">安装 MetalLB 负载平衡器： Red Hat OpenShift 与 NetApp</block>
  <block id="0b2da9b5fe81e13e88c9a05981a95a9e" category="paragraph">此页面列出了 MetalLB 负载平衡器的安装和配置说明。</block>
  <block id="28a4ce0a0514d0f6a6596fc7a9c5e725" category="section-title">MetalLB 配置选项</block>
  <block id="04c22d763ca95631f9c8789eb2c6e68f" category="paragraph">根据 MetalLB 如何公布分配给 OpenShift 集群以外的负载平衡器服务的 IP 地址，它可在两种模式下运行：</block>
  <block id="92f98c10e5e0c86bcae2e9cb58b700e3" category="list-text">* 第 2 层模式。 * 在此模式下， OpenShift 集群中的一个节点将接管此服务的所有权，并对该 IP 的 ARP 请求做出响应，使其可在 OpenShift 集群之外访问。由于只有节点才公布 IP ，因此存在带宽瓶颈和较慢的故障转移限制。有关详细信息，请参见文档 <block ref="4a1d14cac7ed68a2326a050e0f1fed80" category="inline-link-macro-rx"></block>。</block>
  <block id="32333b5f74abf17bffedb6e7abeb7b5f" category="section-title">安装 MetalLB 负载平衡器</block>
  <block id="70bd399edc6825961c98dc29c2a49299" category="list-text">下载 MetalLB 资源。</block>
  <block id="d95ae9e4bae10f240e5577110ccbd7e6" category="list-text">编辑文件 `metallb.yaml` 并从控制器部署和主讲人 DemonSet 中删除 `spec.template.spec.securityContext` 。</block>
  <block id="39bb715a16a6f4c1ab16bc3ad3654f0b" category="paragraph">* 要删除的行： *</block>
  <block id="803519c541b237245faa09039c50dcaa" category="list-text">创建 `metallb-system` 命名空间。</block>
  <block id="980aff973ca30f65ec180530f40def06" category="list-text">创建 MetalLB CR 。</block>
  <block id="f87be5542b64a7f94a807699fd549479" category="list-text">在配置 MetalLB 扬声器之前，请授予扬声器 DemonSet 提升权限，使其能够执行使负载平衡器正常工作所需的网络配置。</block>
  <block id="53747915d8e79873876b08edb1ce3671" category="list-text">通过在 `metallb-system` 命名空间中创建 `ConfigMap` 来配置 MetalLB 。</block>
  <block id="2b1e829362de1a86eeb131cdc4619908" category="list-text">现在，在创建负载平衡器服务时， MetalLB 会为这些服务分配一个外部 IP ，并通过响应 ARP 请求来公布 IP 地址。</block>
  <block id="234ce2b9b198f2acf2193cbd06120ff2" category="admonition">如果要在 BGP 模式下配置 MetalLB ，请跳过上述步骤 6 并按照 MetalLB 文档中的操作步骤进行操作 <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>。</block>
  <block id="dc7ec0964c3d39892e26bbe1593a79e2" category="list-text">安装在 OpenShift 集群上的 Astra Trident</block>
  <block id="e909486a42368b2659780687c3b4a31b" category="list-text">一种在 OpenShift 集群上配置的存储类，其中使用 Astra Trident 作为配置程序</block>
  <block id="7df52e0f8b2cb2af1e107fde51d06945" category="paragraph">实时迁移是指在不停机的情况下将 VM 实例从 OpenShift 集群中的一个节点迁移到另一个节点的过程。要在 OpenShift 集群中执行实时迁移， VM 必须绑定到具有共享 ReadWriteMany 访问模式的 PVC 。在启用了 NFS 协议的 NetApp ONTAP 集群上配置了 SVM 的 Astra Trident 后端支持对 PVC 的共享 ReadWriteMany 访问。因此，对于从启用了 NFS 的 SVM 中由 Trident 配置的 StorageClasses 请求具有 PVC 的 VM ，可以在不停机的情况下进行迁移。</block>
  <block id="a0c55f3c40b8bb2d3e26f8d11ca73cbc" category="summary">本参考文档对通过安装程序配置的基础架构（ IPI ）在 NetApp 验证的多种不同数据中心环境中部署的 Red Hat OpenShift 解决方案进行了部署验证。同时，还详细介绍了如何利用 Astra Trident 存储编排程序来管理永久性存储，从而与 NetApp 存储系统实现存储集成。最后，我们还探讨并记录了许多解决方案验证和实际使用情形。</block>
  <block id="a2ac5b8f3de7c17418af38c828121a15" category="list-text">与 NetApp 存储和适用于 Kubernetes 的开源存储编排程序 Astra Trident 结合使用时，重点介绍 Red Hat OpenShift 的功能的实际配置和使用情形。</block>
  <block id="d3d8eb53a347d6ffc9fb157d9ac8398b" category="paragraph">采用 NetApp 解决方案的 Red Hat OpenShift 由以下主要组件组成：</block>
  <block id="2b8932b35916e8cecb6216546111322e" category="paragraph">Red Hat OpenShift 容器平台是一个完全受支持的企业 Kubernetes 平台。Red Hat 对开源 Kubernetes 进行了多项增强，可提供一个应用程序平台，其中包含所有组件，这些组件均已完全集成，可用于构建，部署和管理容器化应用程序。</block>
  <block id="9480fd8950471a46e6b29b165ba7ae41" category="paragraph">NetApp Astra 控制中心为有状态 Kubernetes 工作负载提供了一组丰富的存储和应用程序感知型数据管理服务，这些服务部署在内部环境中，并采用 NetApp 值得信赖的数据保护技术。</block>
  <block id="12c17259bf3f3b36e970c9e3abbc6b43" category="cell">NetApp Astra 控制中心</block>
  <block id="8d96276332b02a2ef892828c1d4fbab4" category="cell">应用程序感知型数据管理</block>
  <block id="8de59ec369b10820d0dd336b9765c79b" category="cell">NetApp Astra Trident</block>
  <block id="824bd84e05db30b27e73f839dae3b8e5" category="list-text">Astra Trident 文档</block>
  <block id="fe549ebd8a3f0fea1803cbaa947ef198" category="list-text">NetApp Astra 控制中心文档</block>
  <block id="ad837604b59ea6a89754d8e75f595c7b" category="inline-link"><block ref="ad837604b59ea6a89754d8e75f595c7b" category="inline-link-rx"></block></block>
  <block id="4af69e66dd3d513168080d177919dd21" category="paragraph"><block ref="4af69e66dd3d513168080d177919dd21" category="inline-link-rx"></block></block>
  <block id="3dbb1adfd571e8b44af1259f287d723f" category="paragraph">NetApp 拥有多个存储平台，这些平台符合我们的 Astra Trident Storage Orchestrator 标准，可为在 Red Hat OpenShift 上部署的应用程序配置存储。</block>
  <block id="0d1d64b47559f0c28c883e7e790b8363" category="summary">本节专门介绍实际用户在将此解决方案部署到生产环境中时可能需要执行的自定义设置，例如创建专用映像注册表或部署自定义负载平衡器实例。</block>
  <block id="2642cf401e87de575eae139953f87134" category="admonition">在本节中，我们介绍了一些高级配置选项，例如，使用第三方负载平衡器或创建专用注册表来托管自定义容器映像，这两个选项都是安装 NetApp Astra 控制中心的前提条件。</block>
  <block id="02b655f637212514780af2795fd74fc4" category="paragraph">以下页面介绍了有关在 Red Hat OpenShift with NetApp 解决方案中验证的高级配置选项的追加信息：</block>
  <block id="becc5334b7f3d2f4f57fc42cd287fd54" category="inline-link-macro">了解负载平衡器选项</block>
  <block id="22651dd64b4cd4c6d2742d1f8b126ae6" category="list-text"><block ref="22651dd64b4cd4c6d2742d1f8b126ae6" category="inline-link-macro-rx"></block></block>
  <block id="261bdcc1d2c24d15c43c5947e69ea9e6" category="inline-link-macro">配置私有映像注册表</block>
  <block id="c8db11b008075455562a8b598b31753c" category="list-text"><block ref="c8db11b008075455562a8b598b31753c" category="inline-link-macro-rx"></block></block>
  <block id="c4a7756da710a87248298a14bd0c21e6" category="paragraph"><block ref="c4a7756da710a87248298a14bd0c21e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7a6c3c568d213db46836511343c4965" category="list-text">运行 ONTAP 9.5 或更高版本的一个或多个 NetApp ONTAP 存储系统。</block>
  <block id="c927c560df09d5ca001f99cd07b14700" category="list-text">必须在每个 OpenShift 集群上配置一个 Trident 存储后端，其中包含一个由 ONTAP 集群提供支持的 SVM 。</block>
  <block id="67a56d728807272d2a01df50c6548f4f" category="list-text">在每个 OpenShift 集群上配置的默认 StorageClass ，其中使用 Astra Trident 作为存储配置程序。</block>
  <block id="dda5c1363ac68168c83f72fc2645f51f" category="list-text">必须在每个 OpenShift 集群上安装和配置负载平衡器，以实现负载平衡并公开 OpenShift 服务。</block>
  <block id="7dbcc72cc3a693b8f89b064e38ed7a23" category="list-text">必须配置私有映像注册表以托管 NetApp Astra Control Center 映像。</block>
  <block id="537f97bbcef0e2e67d6840aa5845aa65" category="list-text">您必须对 NetApp ONTAP 集群具有管理员访问权限。</block>
  <block id="0507b40de1fbd59b7a77b9054689e92b" category="list-text">一个管理工作站，其中安装了 Docker 或 podman ， tridentctl 以及 oc 或 kubectl 工具，并将其添加到 $path 中。</block>
  <block id="8c7c70cb991e0295e289054b79308c5d" category="section-title">安装 Astra 控制中心</block>
  <block id="ccab5cf8842d06d8d4e2f7f778657c4b" category="list-text">打开 tar ball 的包装并将工作目录更改为生成的文件夹。</block>
  <block id="abe31bcfb59f2265c2fb97dde407366c" category="open-title">podman</block>
  <block id="e83d8437c3befea11906e730883605bf" category="list-text">将 ‘re名称为组织 / 命名空间 / 项目的注册表 FQDN 导出为环境变量 "gregistry" 。</block>
  <block id="9acf317cba8637e151b8daae04e3e998" category="list-text">登录到注册表。</block>
  <block id="326c4e96ff06709dede5c03038f00e78" category="list-text">使文件可执行</block>
  <block id="ed85c18933b4b240788294af279f8624" category="list-text">执行 shell 脚本。</block>
  <block id="05b6053c41a2130afd6fc3b158bda4e6" category="open-title">Docker</block>
  <block id="a27cc132b2f3001f3e9df9c40dad4bfb" category="list-text">运行以下命令创建运算符。</block>
  <block id="685fe82295261a8902e709081b6c9599" category="list-text">创建一个专用命名空间以安装所有 Astra 控制中心资源。</block>
  <block id="d689979a6af0f5660231db187d212950" category="list-text">在为其创建的命名空间中创建 Astra 控制中心 CRD 。</block>
  <block id="9904a774f242f31a5ae37c8f75bda92b" category="list-text">检查 `Acc-operator-controller-manager` 日志以确保安装已完成。</block>
  <block id="cc2ba6bb5620162b64bafdca9f089718" category="inline-image-macro">Astra 控制中心登录</block>
  <block id="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="paragraph"><block ref="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90fbead2d113af1a2680805778908d98" category="inline-image-macro">Astra 控制中心强制更改密码</block>
  <block id="247e9fd0170ec4d9550de59ebd54787b" category="paragraph"><block ref="247e9fd0170ec4d9550de59ebd54787b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0dd5915bd7ca0f5d34df18bf7a183d50" category="inline-image-macro">Astra 控制中心创建用户</block>
  <block id="0ea309ed2f56bdc52dd6184b9043e683" category="paragraph"><block ref="0ea309ed2f56bdc52dd6184b9043e683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54936e9fda3da1e56a25c0056f054bce" category="inline-image-macro">Astra Control Center 添加许可证</block>
  <block id="02fd0244de299d20dfbaf9113b883030" category="paragraph"><block ref="02fd0244de299d20dfbaf9113b883030" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2044ecf5033cd4a7b9530b83075af99e" category="admonition">如果您在安装或配置 NetApp Astra 控制中心时遇到问题，可以参考已知问题的知识库<block ref="d775d2705bd260971e4d33c3d1094402" category="inline-link-rx"></block>。</block>
  <block id="8b14fb34f5313442bf2fdc4d80edc389" category="summary">本节专门介绍要使用 NetApp 自定义 Red Hat OpenShift 部署的用户的负载平衡器选项。</block>
  <block id="87beaa6eff6159cd7270b2a4e71c10a4" category="doc">了解负载平衡器选项： Red Hat OpenShift 与 NetApp</block>
  <block id="0aa971b4d33bdc82c500a35166e588c8" category="paragraph">但是，在某些情况下，应用程序需要部署和配置自定义负载平衡器才能公开相应的服务。其中一个示例是 NetApp Astra 控制中心。为了满足这一需求，我们评估了许多自定义负载平衡器选项。本节将介绍其安装和配置。</block>
  <block id="6914d9014ff3e2cb99cabff26b55a0bc" category="paragraph">以下页面提供了有关负载平衡器选项的追加信息，这些选项已在 Red Hat OpenShift with NetApp 解决方案中进行验证：</block>
  <block id="2b545f7c547a71eaeda9dcb451aea0c5" category="inline-link-macro">元 LB</block>
  <block id="eaefba36e93c0d0177c3de1143bd08dd" category="list-text"><block ref="eaefba36e93c0d0177c3de1143bd08dd" category="inline-link-macro-rx"></block></block>
  <block id="16dcf1808fc3c9a6f8342f97305d2ad6" category="doc">保护您的应用程序</block>
  <block id="58c0d00b6ee4c263f1fbe431b41eebf4" category="paragraph">在由 Astra 控制中心管理应用程序工作负载之后，您可以为这些工作负载配置保护设置。</block>
  <block id="59af79c7ab060b4cca322301a4729f0c" category="section-title">创建应用程序快照</block>
  <block id="c0cf3c0162d106c6ee24b7afa9b79575" category="paragraph">应用程序的快照会创建一个 ONTAP Snapshot 副本，该副本可用于根据该 Snapshot 副本将应用程序还原或克隆到特定时间点。</block>
  <block id="9101281f33d55e682b1a47a44251fa0e" category="list-text">要为应用程序创建快照，请导航到 "Apps" &gt; "Managed " 选项卡，然后单击要为其创建 Snapshot 副本的应用程序。单击应用程序名称旁边的下拉菜单，然后单击 Snapshot 。</block>
  <block id="c01290a8a623e36f9bcae85b910a3410" category="inline-image-macro">Astra 控制中心快照按钮</block>
  <block id="f40e241f10f15eb6887acbc81fec81b0" category="inline-image-macro">Astra 控制中心创建快照</block>
  <block id="1853746a915bea325b8b576237c24427" category="section-title">创建应用程序备份</block>
  <block id="91796648d42dbd448c6cbb2044cb92ba" category="paragraph">应用程序的备份可捕获应用程序的活动状态及其资源的配置，将其覆盖到文件中，并将其存储在远程对象存储分段中。</block>
  <block id="72e328bb06195897c7a644970c61d3a2" category="paragraph">要在 Astra 控制中心备份和还原受管应用程序，必须先为支持的 ONTAP 系统配置超级用户设置。为此，请输入以下命令。</block>
  <block id="6db82a24b17137378420e9fc7961d961" category="list-text">要在 Astra 控制中心创建受管应用程序的备份，请导航到应用程序 &gt; 受管选项卡，然后单击要备份的应用程序。单击应用程序名称旁边的下拉菜单，然后单击备份。</block>
  <block id="bc230776554b8a63af328cf9f01124e1" category="inline-image-macro">Astra 控制中心备份按钮</block>
  <block id="e10781941ccd98298d2856b437b3fb4b" category="inline-image-macro">Astra 控制中心创建备份</block>
  <block id="92955527b375720b2a586155a776c0ac" category="inline-image-macro">Astra Control Center 克隆按钮</block>
  <block id="c4293ef1955d52694e7d2288b637df1a" category="inline-image-macro">Astra 控制中心还原</block>
  <block id="c501040965cb5ca97cc675347e9ebfdf" category="list-text">当 Astra 控制中心在选定集群上创建应用程序时，新应用程序将进入 " 正在发现 " 状态。在 Astra 安装并检测到应用程序的所有资源后，该应用程序将进入可用状态。</block>
  <block id="9ff3c5458e4a8facc6e7c25656a3baf7" category="inline-image-macro">发现 Astra Control Center 新应用程序</block>
  <block id="d19de154f02438c6d6918a4e016c7c62" category="doc">选择要保护的应用程序</block>
  <block id="501195b19cb60bfec4c2e4899a2a460c" category="paragraph">注册 Red Hat OpenShift 集群后，您可以通过 Astra 控制中心发现已部署的应用程序并对其进行管理。</block>
  <block id="a022d74e2b8b62dd9f1caa37a51aa3f3" category="section-title">管理应用程序</block>
  <block id="d8c780951f3271e7d72b116e5f41d46b" category="list-text">在将 OpenShift 集群和 ONTAP 后端注册到 Astra 控制中心后，控制中心将自动开始发现所有命名空间中使用使用使用指定 ONTAP 后端配置的 storageclass 的应用程序。</block>
  <block id="3b5963749d054f288f27dfb2f20d0370" category="inline-image-macro">发现 Astra 控制中心应用程序</block>
  <block id="a78e618a70881e5c5dda311aaa61c250" category="paragraph"><block ref="a78e618a70881e5c5dda311aaa61c250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c46442de8c982973aeee99a9441b746" category="list-text">导航到应用程序 &gt; 已发现，然后单击要使用 Astra 管理的应用程序旁边的下拉菜单。然后单击管理。</block>
  <block id="22d84cdf10d4c1059d68b1ab7da5b375" category="inline-image-macro">Astra 控制中心管理应用程序</block>
  <block id="4afca1ab36db499d54b08ff38dff8a5c" category="paragraph"><block ref="4afca1ab36db499d54b08ff38dff8a5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d694cfe5907a4790ea939388a8cfd25" category="list-text">此应用程序将进入可用状态，并可在 "Apps" 部分的 "Managed " 选项卡下查看。</block>
  <block id="dc496d6799e0c6ab3bdfdbdc6a086b48" category="inline-image-macro">提供 Astra 控制中心应用程序</block>
  <block id="872adedc4ac847cec0aa8fb9299d32e5" category="paragraph"><block ref="872adedc4ac847cec0aa8fb9299d32e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="472d13eb415cd6107aeef3a1ae6cd705" category="summary">NetApp 提供了许多产品，可帮助客户在基于容器的环境中编排和管理持久数据，例如 Red Hat OpenShift 。</block>
  <block id="ebfc0e639726a366f8eb5ac86bb7cc43" category="paragraph"><block ref="ebfc0e639726a366f8eb5ac86bb7cc43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd351007d4a671a321b6881f730d0dc3" category="paragraph">以下页面介绍了有关已在 Red Hat OpenShift with NetApp 解决方案中针对应用程序和永久性存储管理进行验证的 NetApp 产品的追加信息：</block>
  <block id="810a039d1a8524388b75a0fe8d837afc" category="summary">要使 Astra 控制中心能够管理您的工作负载，您必须先注册 Red Hat OpenShift 集群。</block>
  <block id="3557f7a93216446476c40d54e0426c40" category="doc">将 Red Hat OpenShift 集群注册到 Astra 控制中心</block>
  <block id="349c99fe6f384da92e5b8289b828791c" category="section-title">注册 Red Hat OpenShift 集群</block>
  <block id="c179429ab818c9d0cca3d1db55f788bf" category="list-text">第一步是将 OpenShift 集群添加到 Astra 控制中心并对其进行管理。转至集群并单击添加集群，上传 OpenShift 集群的 kubeconfig 文件，然后单击选择存储。</block>
  <block id="8dfc7d6b819f8c17b51391e3b3159add" category="inline-image-macro">Astra 控制中心创建集群</block>
  <block id="7470624615914e8e3d5fdf4ea1aa31de" category="paragraph"><block ref="7470624615914e8e3d5fdf4ea1aa31de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7d9a690231a2d896f69e9b45c9ff4a1" category="admonition">可以生成 kubeconfig 文件，以便使用用户名和密码或令牌进行身份验证。令牌将在一段有限的时间后过期，并且可能会使注册的集群无法访问。NetApp 建议使用具有用户名和密码的 kubeconfig 文件将 OpenShift 集群注册到 Astra 控制中心。</block>
  <block id="cab7d2cb072914c0a5a89baab41d38e8" category="inline-image-macro">Astra 控制中心创建集群选择存储</block>
  <block id="68ac91074dd3b4e5514e5f56a6c9c756" category="paragraph"><block ref="68ac91074dd3b4e5514e5f56a6c9c756" category="inline-image-macro-rx" type="image"></block></block>
  <block id="420b9c40f78cc4825914319af51801b9" category="inline-image-macro">提供 Astra 控制中心集群</block>
  <block id="1b017a62213661e1ed3c5c581fcf74a2" category="paragraph"><block ref="1b017a62213661e1ed3c5c581fcf74a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d01de34ef9b9b934d18009a1e3273a9" category="list-text">将 ONTAP 集群作为存储资源导入，以便由 Astra 控制中心作为后端进行管理。将 OpenShift 集群添加到 Astra 并配置了 storageclass 后，它会自动发现并检查支持该 storageclass 的 ONTAP 集群，但不会将其导入到要管理的 Astra 控制中心中。</block>
  <block id="781ffd1df517a65b302412f53de974da" category="inline-image-macro">Astra 控制中心后端发现</block>
  <block id="1fcc7977dffdc8fd8fc53582c67da895" category="paragraph"><block ref="1fcc7977dffdc8fd8fc53582c67da895" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4da0c23c38cf0da34e1e6660ff74542b" category="inline-image-macro">Astra 控制中心创建后端</block>
  <block id="69dbaffc2661024ee0b5095bc3674f60" category="paragraph"><block ref="69dbaffc2661024ee0b5095bc3674f60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edb4425c04926a17b6ff9a4a2ecdc669" category="list-text">添加后端后，状态将更改为 Available 。现在，这些后端可提供有关 OpenShift 集群中的永久性卷以及 ONTAP 系统上的相应卷的信息。</block>
  <block id="92c130f9be24925c7dee36f7580ea347" category="inline-image-macro">提供 Astra 控制中心后端</block>
  <block id="e9f487b0aad6779edbf50c6092477bd5" category="paragraph"><block ref="e9f487b0aad6779edbf50c6092477bd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2d10d92dc9d83e3cf3514e8e883e5cb" category="list-text">要使用 Astra 控制中心在 OpenShift 集群之间进行备份和还原，您必须配置支持 S3 协议的对象存储分段。目前支持的选项包括 ONTAP S3 ， StorageGRID 和 AWS S3 。为此，我们将配置一个 AWS S3 存储分段。转到 " 分段 " ，单击 " 添加分段 " ，然后选择 " 通用 S3" 。输入有关 S3 存储分段和凭据的详细信息以访问它，单击复选框 " 将此存储分段设置为云的默认存储分段 " ，然后单击添加。</block>
  <block id="6910cb9051734be0129cb1e7dd84ce5c" category="inline-image-macro">Astra 控制中心创建存储分段</block>
  <block id="2786d0b632389f7cbd6c4e67fba0061f" category="paragraph"><block ref="2786d0b632389f7cbd6c4e67fba0061f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2ed5156911e542a4d3d64a6e160f6446" category="image-alt">Red Hat OpenShift 集群上的多租户，采用由 NetApp ONTAP 提供支持的 Astra Trident</block>
  <block id="086e6c16e3fe8e13c336612ef636aa02" category="list-text">Astra Trident</block>
  <block id="bf4e72937ad57bd2f780561c81d25d53" category="paragraph">在由 NetApp ONTAP 提供支持的 Astra Trident 的协助下， OpenShift 虚拟化还支持某些功能，例如实时 VM 迁移， VM 磁盘克隆， VM 快照等。这些工作流的示例将在本文档后面的相应章节中进行讨论。</block>
  <block id="d55adbfc40b7bcdb0606eb0bd4d88cae" category="summary">本节专门介绍如何创建和配置由 Astra Trident 提供的永久性存储提供支持的私有映像注册表。</block>
  <block id="9c864113b9e4202e111b818a53d4f506" category="inline-link">Quay.io</block>
  <block id="4b4141875f954447d204e6f73d93e2a0" category="inline-link">DockerHub</block>
  <block id="508888fd9f92f35e5edd97bd8083e289" category="paragraph">对于大多数 Red Hat OpenShift 部署，请使用等公有注册表<block ref="b9eeebbe4a68a648d570ea2173e5ef99" category="inline-link-rx"></block> 或<block ref="0252a6b70cc5017fa1445a78532155b6" category="inline-link-rx"></block> 满足大多数客户的需求。但是，有时客户可能希望托管自己的私有或自定义映像。</block>
  <block id="00a3f196d7f27a1f41f5d6a7f48759d0" category="paragraph">本操作步骤介绍了如何创建私有映像注册表，该注册表由 Astra Trident 和 NetApp ONTAP 提供的永久性卷提供支持。</block>
  <block id="d9d5e29b1b83dd9c215f5ea158ca2475" category="admonition">Astra 控制中心需要注册表来托管 Astra 容器所需的映像。以下部分介绍了在 Red Hat OpenShift 集群上设置专用注册表以及推送支持安装 Astra 控制中心所需的映像的步骤。</block>
  <block id="86e93d266c168d718105c402f43fc91e" category="list-text">然后，可以将此提取密钥修补到服务帐户或在相应的 POD 定义中引用。</block>
  <block id="18f8bf05a7a278e63d921de74d2a5966" category="list-text">将 TLS 证书添加到 Docker 客户端。</block>
  <block id="fe70522102670f75ed2fff361701d056" category="paragraph">本参考文档对通过安装程序配置的基础架构（ IPI ）在 NetApp 验证的多种不同数据中心环境中部署的 Red Hat OpenShift 解决方案进行了部署验证。同时，还详细介绍了如何利用 Astra Trident 存储编排程序管理永久性存储，以及利用 NetApp Astra 控制中心管理和保护有状态应用程序，从而实现与 NetApp 存储系统的存储集成。最后，我们还探讨并记录了许多解决方案验证和实际使用情形。</block>
  <block id="4a56de086437c8a56c22bccd4e7ed9ba" category="paragraph">通过支持 Astra Trident 的卷 CSI 克隆功能，可以在 OpenShift 中克隆现有虚拟机。通过 CSI 卷克隆，可以使用现有 PVC 作为数据源并通过复制其 PV 来创建新的 PVC 。创建新的 PVC 后，它将作为一个单独的实体运行，并且不会与源 PVC 建立任何链接或依赖关系。</block>
  <block id="9057e692817874e4c563dec1fa8c1700" category="paragraph">通过关闭虚拟机克隆现有虚拟机是一项原生 OpenShift 功能，该功能在 Astra Trident 的支持下实施。要克隆虚拟机，请完成以下步骤。</block>
  <block id="306a916d056a0d0a4b898b9dca9692ee" category="inline-link-macro">基于 Red Hat OpenShift 的 NetApp Astra 控制中心</block>
  <block id="20c49a9a4d903fa259d4f8820b3755d2" category="cell"><block ref="20c49a9a4d903fa259d4f8820b3755d2" category="inline-link-macro-rx"></block></block>
  <block id="82ebdc178ed6bd9adb7b66c2edfb70d0" category="sidebar">NetApp 存储系统概述</block>
  <block id="aef2d8db139dd41c9ae6c878ab92ae75" category="sidebar">NetApp 存储集成概述</block>
  <block id="5f6fc3deb668cb75e9e6c8932620df6a" category="sidebar">NetApp Astra 控制中心概述</block>
  <block id="846665f4ec19bffa9d9a8c3937c2f9fd" category="sidebar">注册 Red Hat OpenShift 集群</block>
  <block id="b1dbcb80c89b000949ef64c6d6d6c42b" category="sidebar">选择要保护的应用程序</block>
  <block id="2913361a2ab3fddb4242f1761d4a6e38" category="sidebar">保护您的应用程序</block>
  <block id="b066abadb76f5e6776aa1e7cfdf56b38" category="sidebar">NetApp Astra Trident 概述</block>
  <block id="938033783443233af5517c828deb6d1e" category="sidebar">OpenShift 的高级配置选项</block>
  <block id="8252479af4b1df9b77ceaf67fa8cd07d" category="sidebar">创建私有映像注册表</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="summary">法律声明提供对版权声明、商标、专利等的访问。</block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">法律声明</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">版权</block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">商标</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp 、 NetApp 徽标和 NetApp 商标页面上列出的标记是 NetApp 、 Inc. 的商标。其他公司和产品名称可能是其各自所有者的商标。</block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">专利</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">有关 NetApp 拥有的专利的最新列表，请访问：</block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">隐私政策</block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">开放源代码</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">通知文件提供有关 NetApp 软件中使用的第三方版权和许可证的信息。</block>
  <block id="d648f2a68a54fd1b3329efc3cf24d29c" category="sidebar">法律声明</block>
  <block id="5328ed3b5c6e4726166e04c16c2e5581" category="summary">本节介绍如何在熊猫中加载 Criteo Click Logs Day 15 以及如何训练一个 sc科学 学习随机林模型。在此示例中，我们使用 dask cuDF 执行了 DataFrame 加载，并在 dask cuML 中训练了一个随机林模型。</block>
  <block id="a0432b74d7d4d2ad68e93e947654c865" category="doc">在 dask 中加载第 15 天，训练一个 dask cuML 随机林模型</block>
  <block id="78dc33cd9d496e2466a0c1e2ba09ab3f" category="inline-link-macro">" 培训时间比较。 "</block>
  <block id="4a2764258721dd882c9ec28454963797" category="paragraph">按照与上一节类似的方式，在熊猫中加载 Criteo 单击 Logs Day 15 ，然后训练一个 cscit-Learn 随机林模型。在此示例中，我们使用 dask cuDF 执行了 DataFrame 加载，并在 dask cuML 中训练了一个随机林模型。我们比较了本节中培训时间和规模的差异 <block ref="8d6c01ed5b9db5301efeb6183c858b76" category="inline-link-macro-rx"></block></block>
  <block id="356d8553da3749641cb731d318c85b0c" category="section-title">Criteo_dask_rf.ipynb</block>
  <block id="2f4f1a139be92d2b17647025ff8630ab" category="paragraph">此笔记本电脑将导入 `NumPy` ， `累积` 和必要的 `dask` 库，如以下示例所示：</block>
  <block id="7b871613dade772ae668d694698383bf" category="paragraph">启动 dask 客户端（）。</block>
  <block id="3e9277d3d0f0519292426b933e52f232" category="paragraph">如果集群配置正确，您可以查看工作节点的状态。</block>
  <block id="d6b257c355ced1525e4967c96b62b83e" category="paragraph">在我们的 AKS 集群中，将显示以下状态：</block>
  <block id="d94a77691c281e8bf418635fea6ca580" category="paragraph"><block ref="d94a77691c281e8bf418635fea6ca580" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073b2194006d8da73b5f74f3d7224d76" category="paragraph">请注意， dask 采用了延迟执行模式： dask 不是即时执行处理代码，而是构建定向的环状图（ DAG ）执行。DAG 包含一组任务及其互动，每位员工都需要执行这些任务。此布局意味着，只有在用户指示 dask 以某种方式执行任务后，这些任务才会运行。使用 dask ，您有三个主要选项：</block>
  <block id="a40049c3d7270ce955d2023f8e2015dc" category="list-text">在 DataFrame 上调用 compute （）。 * 此调用将处理所有分区，然后将结果返回给计划程序，以便最终聚合和转换为 cuDF DataFrame 。除非计划程序节点内存不足，否则应谨慎使用此选项，并且仅在结果大幅减少时使用。</block>
  <block id="30e170dbe1dd223491e1a822605da52d" category="list-text">* 在 DataFrame 上调用 persiste（ ）。 * 此调用执行图形，但它不会将结果返回到计划程序节点，而是在整个集群的内存中保留这些结果，以便用户可以在管道中重复使用这些中间结果，而无需重新运行相同的处理。</block>
  <block id="ca013764f3f6faeab137d2d529dba598" category="list-text">* 在 DataFrame 上调用 head （）。 * 与 cuDF 一样，此调用会将 10 条记录返回到计划程序节点。此选项可用于快速检查 DataFrame 是否包含所需的输出格式，或者记录本身是否合理，具体取决于您的处理和计算结果。</block>
  <block id="7ac60f98a199ceae63010c7802a9aefa" category="paragraph">因此，除非用户调用其中任一操作，否则员工将处于闲置状态，等待计划程序启动处理。这种延迟执行模式在现代并行和分布式计算框架（如 Apache Spark ）中很常见。</block>
  <block id="d887d6a29f39f14cec0f83c5b02c42f8" category="paragraph">下一段使用 dask cuML 进行分布式 GPU 加速计算，以此训练随机林模型，并计算模型预测准确性。</block>
  <block id="27a5a0a02525fbb66788e119b829fe28" category="list-text">Azure NetApp Files</block>
  <block id="45bd81d391ee3bd9831a237bff32b2c1" category="list-text">Azure NetApp Files 的解决方案架构页面</block>
  <block id="57b815cb2da0c842a09d5ef586792c0a" category="inline-link"><block ref="57b815cb2da0c842a09d5ef586792c0a" category="inline-link-rx"></block></block>
  <block id="02508d077a7c6fbe1035568c37610d22" category="paragraph"><block ref="02508d077a7c6fbe1035568c37610d22" category="inline-link-rx"></block></block>
  <block id="f42fced7b7a9bfef49a209632add6f80" category="list-text">适用于容器的 Trident 持久存储：</block>
  <block id="158e66cfa121c58b072656402170ca60" category="list-text">Azure NetApp Files 和 Trident</block>
  <block id="d9fe72ef646d82c8372b45ff009726a2" category="inline-link"><block ref="d9fe72ef646d82c8372b45ff009726a2" category="inline-link-rx"></block></block>
  <block id="e3c781df174a80c19c70a938b96db93a" category="paragraph"><block ref="e3c781df174a80c19c70a938b96db93a" category="inline-link-rx"></block></block>
  <block id="145f2a04d99fdbd7a450ef83e82d471b" category="list-text">dask 和 rapids ：</block>
  <block id="df5eb1591e808e358e02221e1e0111e6" category="list-text">dask</block>
  <block id="7db6639777894f081a3d7c055b97900a" category="inline-link"><block ref="7db6639777894f081a3d7c055b97900a" category="inline-link-rx"></block></block>
  <block id="4846c68fb34aec3b1b7b7de96d27e71f" category="paragraph"><block ref="4846c68fb34aec3b1b7b7de96d27e71f" category="inline-link-rx"></block></block>
  <block id="41563f9620e92fbfd1e105e32ac297e4" category="list-text">安装 dask</block>
  <block id="8659b02378fc9b47aac4428f69411abc" category="inline-link"><block ref="8659b02378fc9b47aac4428f69411abc" category="inline-link-rx"></block></block>
  <block id="972dffc891589785367dd3581a5abcef" category="paragraph"><block ref="972dffc891589785367dd3581a5abcef" category="inline-link-rx"></block></block>
  <block id="3ba7abeba4fd0f5d5ca9072155319afd" category="list-text">Dask API</block>
  <block id="f7673aa4f6b36ba9952cef7c98115776" category="inline-link"><block ref="f7673aa4f6b36ba9952cef7c98115776" category="inline-link-rx"></block></block>
  <block id="d43a23bd530cae7ba37a2e0ed6513bad" category="paragraph"><block ref="d43a23bd530cae7ba37a2e0ed6513bad" category="inline-link-rx"></block></block>
  <block id="1bfabf7fb7bf05567331dfc3d20c4921" category="list-text">DASK 机器学习</block>
  <block id="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link"><block ref="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link-rx"></block></block>
  <block id="d05f63d77306100c615132f350f3fafe" category="paragraph"><block ref="d05f63d77306100c615132f350f3fafe" category="inline-link-rx"></block></block>
  <block id="90223e93e145939c9954970520e1767a" category="list-text">Dask 分布式诊断</block>
  <block id="e7252fe9d67234e05be7dc251c48cf74" category="inline-link"><block ref="e7252fe9d67234e05be7dc251c48cf74" category="inline-link-rx"></block></block>
  <block id="925c8b588cf5ae5fc486494a21fba8ac" category="paragraph"><block ref="925c8b588cf5ae5fc486494a21fba8ac" category="inline-link-rx"></block></block>
  <block id="d97adf46c9b097cad5eff54e3b65a21f" category="paragraph"><block ref="d97adf46c9b097cad5eff54e3b65a21f" category="inline-link-rx"></block></block>
  <block id="528d52adf23d34a248f0b9bf684c1832" category="paragraph"><block ref="528d52adf23d34a248f0b9bf684c1832" category="inline-link-rx"></block></block>
  <block id="7580f940c2b73a449943bf14cfdb743e" category="summary">此页面介绍了 Azure NetApp Files 云资源的配置。</block>
  <block id="9ab9ef31301ca94d2090a6ac7e5141f0" category="doc">云资源要求</block>
  <block id="00130c4c20e30be7264c0ff0d085261b" category="section-title">配置 Azure NetApp Files</block>
  <block id="d696f60435e09b1c41d1db77b458999b" category="inline-link">快速入门：设置 Azure NetApp Files 并创建 NFS 卷</block>
  <block id="b955f251da04c8c868b22cbe7663a4f5" category="paragraph">按照中所述配置 Azure NetApp Files<block ref="f8525997ced72f3cfd70e1aecf287af9" category="inline-link-rx"></block>。</block>
  <block id="4ee734214d7dd4e522f2aab3d8e3d349" category="paragraph">您可以继续阅读 " 为 Azure NetApp Files 创建 NFS 卷 " 一节，因为您要通过 Trident 创建卷。在继续之前，请完成以下步骤：</block>
  <block id="2a304a1348456ccd2234cd71a81bd338" category="inline-link">链接。</block>
  <block id="b1d13ce152415787185b9f596f9635e1" category="list-text">注册 Azure NetApp Files 和 NetApp 资源提供商（通过 Azure Shell ）（<block ref="7a85c4f09a460b2978e2b516b5474576" category="inline-link-rx"></block>）。</block>
  <block id="4c21364a09ae3c9dab758e383fcae62d" category="list-text">在 Azure NetApp Files 中创建帐户（<block ref="27e1abf4e17aeb1c0d418f5fee2f2b5f" category="inline-link-rx"></block>）。</block>
  <block id="97f203356061531d1acaf022df0d4c3c" category="list-text">设置容量池（至少 4 TB 标准版或高级版，具体取决于您的需要）（<block ref="16f1daa909eef5f1fe1f552d6b28d086" category="inline-link-rx"></block>）。下表列出了在云中设置的网络配置要求。dask 集群和 Azure NetApp Files 必须位于同一个 Azure 虚拟网络（ vNet ）或对等 vNet 中。</block>
  <block id="ddcf50c29294d4414f3f7c1bbc892cb5" category="cell">Resources</block>
  <block id="3e19b1ddc4033d0c6c439dad720f730d" category="cell">类型 / 版本</block>
  <block id="21b6b0c072968b7235d21d8ec72be5dc" category="cell">代理节点</block>
  <block id="e5262abb96ddec17ecbca3557e70ea26" category="cell">3 个 Standard_DS2_v2</block>
  <block id="c64f4eaffc33134095fd3105b3d63832" category="cell">GPU 节点</block>
  <block id="11fed615c3da90add7abe544e965fa14" category="cell">3 个 Standard_NC6s_v3</block>
  <block id="238f4027146f2469c7d1209e594471e4" category="cell">标准容量池</block>
  <block id="9163995275052e5abd777ae389b15dfd" category="cell">容量（以 TB 为单位）</block>
  <block id="999aa3cd55c654beafcfa7653b65d339" category="paragraph">要使用 Helm 安装 Trident ，请完成以下步骤：</block>
  <block id="36cd38f49b9afa08222c0dc9ebfe35eb" category="inline-link">source</block>
  <block id="9c5f8711af47a869d4ef82db9e55eda5" category="list-text">安装 Helm （有关安装说明，请访问<block ref="adf15389dc6d5fe4bd9024075437080f" category="inline-link-rx"></block>）。</block>
  <block id="f7c078ec85c617d77dfa95c309e4df1b" category="list-text">下载并解压缩 Trident 20.01.1 安装程序。</block>
  <block id="5729bb69ffc852a2e2757d743b7cb833" category="list-text">将 `tridentctl` 复制到系统中的目录 ` $path` 。</block>
  <block id="d7fc4d1537e4623fdcebe9b8ba333cbb" category="list-text">使用 Helm （<block ref="cbc920955683fc4acb62f9ea7099333f" category="inline-link-rx"></block>）：</block>
  <block id="f515d7de4d597c284ba8042f699a0eab" category="list-text">将目录更改为 `helm` 目录。</block>
  <block id="6ee4094e2c3617e3e298ec79f9dc2898" category="list-text">检查 Trident Pod 的状态。</block>
  <block id="30f93734da9765d3bc7d49ca89932736" category="paragraph">如果所有 Pod 均已启动且正在运行，则会安装 Trident ，您可以继续操作。</block>
  <block id="cde865911fa15995bc83db30d852300b" category="list-text">为 AKS 设置 Azure NetApp Files 后端和存储类。</block>
  <block id="476fdb61358f28988640245a33bd9199" category="list-text">创建 Azure 服务原则。</block>
  <block id="5cdfb88cd634d9d0eb47237e3251d4bd" category="paragraph">服务主体是 Trident 如何与 Azure 通信以操作 Azure NetApp Files 资源。</block>
  <block id="253a9ccb0f0696ed79c174b388867829" category="list-text">创建 Trident 后端 json 文件，示例名称 `anf-backend.json` 。</block>
  <block id="c17b83e07524acc467ac01e42fa0ebdb" category="list-text">使用首选文本编辑器，完成 `anf-backend.json` 文件中的以下字段：</block>
  <block id="1197f8dc56b70115d87008dd2ecd3fca" category="list-text">替换以下字段：</block>
  <block id="b0b2134849d44712e969d6872e7245e5" category="list-text">`ssubscriptionID` 。您的 Azure 订阅 ID</block>
  <block id="7b42dbe86adeab0d66f36221b33bb0f4" category="list-text">`租户 ID` 。上一步中 `az ad sp` 输出中的 Azure 租户 ID 。</block>
  <block id="5a8bb8e509b4a424a1df50ef0bb41d89" category="list-text">`客户端 ID` 。上一步中 `az ad sp` 输出中的 appID 。</block>
  <block id="6334b606a5807346a083767eaab3934f" category="list-text">`clientSecret` 。上一步中 `az ad sp` 输出中的密码。</block>
  <block id="12104fe8975b3ce95324ec3cab160ffc" category="list-text">指示 Trident 在 `trident` 命名空间中使用 `anf-backend.json` 作为配置文件创建 Azure NetApp Files 后端：</block>
  <block id="d6d34c355bcd6b2efe2795a2aeedd247" category="paragraph"><block ref="d6d34c355bcd6b2efe2795a2aeedd247" category="inline-image-macro-rx" type="image"></block></block>
  <block id="004530c3d3b3f442f56243625372db1d" category="list-text">创建存储类。Kubernetes 用户使用按名称指定存储类的 PVC 配置卷。指示 K8s 创建一个` azurenetappfiles `，该存储类引用上一步创建的 Trident 后端。</block>
  <block id="e777b114d6f12bc1190a60eaf8498e37" category="list-text">为存储类和副本创建 YAML （`anf-storage-class.yaml` ）文件。</block>
  <block id="01d45e8c6af153b1a477537e02466b5c" category="list-text">验证是否已创建存储类。</block>
  <block id="445895be8456b7de5e864fc09994551a" category="paragraph"><block ref="445895be8456b7de5e864fc09994551a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b737f96f31f513a87adcf43b83ec3a1" category="summary">此页面介绍设置 AKS 集群所需的步骤。</block>
  <block id="a81532d943508d42466c22d8d87bb4b8" category="doc">安装和设置 AKS 集群</block>
  <block id="40e1cc9f8d9321cbe9c1ef090f926a2b" category="paragraph">要安装和设置 AKS 集群，请参见网页<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block> 然后完成以下步骤：</block>
  <block id="ad4af0825dd4979b7f48ae5ba031b23a" category="list-text">选择节点类型（系统 CPU 或辅助 GPU 节点）时，请选择以下选项：</block>
  <block id="5a244a81080ee9fc08696fcbd45284e5" category="list-text">主系统节点应为标准 DS2v2 （`agentpool` 默认三个节点）。</block>
  <block id="f3449ebebbf547282aa0562015bd360d" category="list-text">然后，为名为 `gpupool` 的用户组（对于 GPU 节点）添加工作节点 Standard_Nc6s_v3 Pool （至少三个节点）。</block>
  <block id="d3d648c68589ef99efb6ad3ec15d1beb" category="paragraph"><block ref="d3d648c68589ef99efb6ad3ec15d1beb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2efc2b95642d4bcc76c710a3826225c" category="list-text">部署需要 5 到 10 分钟。完成后，单击 Connect to Cluster 。</block>
  <block id="31797d7013400422e5d589ae3d91c79a" category="list-text">要连接到新创建的 AKS 集群，请从本地环境（笔记本电脑 /PC ）安装以下内容：</block>
  <block id="87e009e80a344ecb598be4c4bbe01c79" category="inline-link">针对您的特定操作系统提供的说明</block>
  <block id="13a6d4f4230d0a1569b719c15884d447" category="list-text">使用的 Kubernetes 命令行工具<block ref="ad2337a31b7d16867fc954b03de661bd" category="inline-link-rx"></block></block>
  <block id="24a109d7bba4f8808eeb0bcf64d4357b" category="inline-link">安装 Azure 命令行界面</block>
  <block id="7feed8a8a6c680e7beeca052b9fc9ed0" category="list-text">文档中所述的 Azure 命令行界面，<block ref="8e2043d81b680dba324c5a2abbee7b3f" category="inline-link-rx"></block></block>
  <block id="d33a4b8acf4001a4b35a2186fd020432" category="list-text">要从终端访问 AKS 集群，请输入 `az login` 并输入凭据。</block>
  <block id="402ff6cff3671c1f49dc4af765835c14" category="list-text">输入 `Azure CLI ： kubectl get nodes` 。</block>
  <block id="4e5d89028ffbf65df6693ef1affd6573" category="list-text">如果所有六个节点均已启动且正在运行，如以下示例所示，则 AKS 集群已准备就绪并连接到本地环境</block>
  <block id="6b935f22371497abfe5378d4446df0da" category="paragraph"><block ref="6b935f22371497abfe5378d4446df0da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1490a61359279998443f8eab1c0483e" category="summary">本页总结了 Azure NetApp Files 在分布式或大规模培训方面的优势。</block>
  <block id="b0de8e85db65da6381bb71646929daa6" category="doc">点击率预测用例摘要</block>
  <block id="3f504d5ee520c44b83e5875afd3f2831" category="inline-link">TB 单击 Logs</block>
  <block id="ce2803fd5e9b90b62d0792d13e715d11" category="inline-link">Criteo AI 实验室</block>
  <block id="67ccf3c7c1e67c90000dfee83bab38ec" category="list-text">Azure NetApp Files 在分布式或大规模培训方面的优势</block>
  <block id="e15bc9f9b7a013d672cb689660ab9f9f" category="list-text">支持 CUDA 的数据处理（ cuDF ， cuPy 等）和 ML 算法（ cuML ）</block>
  <block id="17a9b27c376a8a5f5e184b2ebce41164" category="summary">部署完所有内容后，对新数据运行推断。这些模型可根据浏览活动预测用户是否单击某个广告。预测结果存储在 dask cuDF 中。您可以使用 Prometheus 监控结果，并在 Grafana 信息板中直观显示结果。</block>
  <block id="af4d0cbb3c6dcf4f3a5e831b08e40ace" category="doc">使用 Prometheus 和 Grafana 监控 dask 和快速流</block>
  <block id="23c1612202d19b502b3701f893fb2557" category="inline-link">RAPID AI 中型 POST</block>
  <block id="9fed5c9f0dab5b88ba96d45cf450079f" category="paragraph">有关详细信息，请参见此<block ref="47200b727ab2088d205d11a973529202" category="inline-link-rx"></block>。</block>
  <block id="adb2100439d02c2978c4a5670cda87b8" category="summary">此页面列出了用于构建此任务的库和框架。所有这些组件均已与 Azure 基于角色的访问和安全控制完全集成。</block>
  <block id="235ff38f40d20846e27b4c64e964ce28" category="doc">用于数据处理和模型培训的库</block>
  <block id="c4e831049faaa8b89e89eebd0a105dab" category="paragraph">下表列出了用于构建此任务的库和框架。所有这些组件均已与 Azure 基于角色的访问和安全控制完全集成。</block>
  <block id="faeae27c134f5193efb923d2492daa47" category="cell">库 / 框架</block>
  <block id="b540cdb28de9a6c72ef1a92504e69423" category="cell">dask cuML</block>
  <block id="1fc1b4b6567949aab2cb7e6fecb1e68f" category="inline-link">cuML 库</block>
  <block id="efe85bbaa5690074ea98a2bfef62d930" category="cell">要使 ML 在 GPU 上运行，请使用<block ref="514c908f6fc3f426a00e1dabdf37831f" category="inline-link-rx"></block> 可通过 dask 访问快速通道 cML 软件包。与基于 CPU 的方法相比，强强联合可以通过基于 GPU 的高性能实施实施常见的 ML 算法，包括集群，维度缩减和回归方法，提供高达 100 倍的速度。</block>
  <block id="ede0db3d6c9043439d0762ee99543654" category="cell">dask cudf</block>
  <block id="a9c380d6e09cc11f858b53d56cf69da4" category="inline-link">dask-cudf 库</block>
  <block id="13a7d0199f9797a3533ff335da46b446" category="cell">CUDF 包括支持 GPU 加速提取，转换，加载（ ETL ）的各种其他功能，例如数据子设置，转换，单热编码等。快速发展团队会维护<block ref="836818db4e43067816d31d2b73198787" category="inline-link-rx"></block> 其中包括使用 dask 和 cuDF 的帮助程序方法。</block>
  <block id="0c9c2e873df681f1ab5b13053be78af7" category="cell">Scikit 学习</block>
  <block id="cd1235fc9b090edba051d73dbc6f66bf" category="inline-link">估算器</block>
  <block id="1977c9daa1d67de51a4651abdb160c09" category="inline-link">适合</block>
  <block id="4f54da5a2c4a796e8215f20eb95fddcc" category="cell">Scikit Learning 提供了数十种内置机器学习算法和模型，称为评估器。每个<block ref="855747fa3f470c1754852d09071dd101" category="inline-link-rx"></block> 可以使用将其安装到某些数据中<block ref="e52e604a9dbe357e0fb9bc58f4b62add" category="inline-link-rx"></block> 方法</block>
  <block id="0dd4d530afb3c99ab869350770d7bebd" category="paragraph">我们使用两台笔记本电脑构建 ML 管道进行比较；一台是传统的熊猫科学学习方法，另一台是使用快速和快速的分布式培训。每台笔记本电脑均可单独进行测试，以查看时间和规模方面的性能。我们会分别介绍每台笔记本电脑，以展示使用快速流和 dask 进行分布式培训的优势。</block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="doc">版本历史记录</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">Date</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">文档版本历史记录</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">版本 1.0</block>
  <block id="248f830b158797f9c038ea35ea266b89" category="cell">2021年8月</block>
  <block id="ea9349a37bfee247df0f87cbcacca796" category="cell">初始版本。</block>
  <block id="8bffe528b31ee595be868b5a4af3d25a" category="paragraph">要为 Azure NetApp Files 创建委派子网，请完成以下步骤：</block>
  <block id="1aa0034de6393efa24703b8a479a5aa6" category="list-text">导航到 Azure 门户中的虚拟网络。查找新创建的虚拟网络。它应具有 `AK -vnet` 等前缀。</block>
  <block id="f1621549bc319674bb9e859babb2a671" category="list-text">单击 vNet 的名称。</block>
  <block id="c536871a8fac3a4390226f6e485cf662" category="paragraph"><block ref="c536871a8fac3a4390226f6e485cf662" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5025fbb3995af8640cab85f4f91126b" category="list-text">单击子网，然后单击顶部工具栏中的 +Subnet 。</block>
  <block id="22307856839205c5209cc8ce1f4ed0df" category="paragraph"><block ref="22307856839205c5209cc8ce1f4ed0df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e45b350630c9a3b31bf0c1a1f03dffb0" category="list-text">为子网提供名称，例如 `ANF.SN` ，然后在 Subnet delegation 标题下选择 `Microsoft.Netapp/volumes` 。请勿更改任何其他内容。单击确定。</block>
  <block id="3621b1bf0075cb659f152966504dfc0d" category="paragraph"><block ref="3621b1bf0075cb659f152966504dfc0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8034fc216ae23edc69bb75430f3de2f" category="paragraph">Azure NetApp Files 卷将分配给应用程序集群，并在 Kubernetes 中用作永久性卷声明（ Persistent Volume Claim ， PVC ）。反过来，通过此过程，您可以灵活地将其映射到不同的服务，例如 Jupyter 笔记本电脑，无服务器功能等。</block>
  <block id="ac3654eb11c3b0cfc94c6c1abdc6767a" category="paragraph">服务用户可以通过多种方式使用平台中的存储。在本技术报告讨论 NFS 时， Azure NetApp Files 的主要优势包括：</block>
  <block id="42ba8b77b788a422a7e4ba2d8bb2d45e" category="list-text">为用户提供使用 Snapshot 副本的功能。</block>
  <block id="a51448debe1bbe5bb229b849d4057e09" category="list-text">允许用户在 Azure NetApp Files 卷上存储大量数据。</block>
  <block id="b7c10d399d058ef3538882e444459ba5" category="list-text">在大型文件集上运行 Azure NetApp Files 卷的型号时，可以利用这些卷的性能优势。</block>
  <block id="74b3e84bf9817092a6f26ddf10a2f3f8" category="summary">此页面概述了此解决方案中使用的技术。</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">技术概述</block>
  <block id="4b2eedb67d8fb9da01af759e6e722a13" category="section-title">Microsoft 和 NetApp</block>
  <block id="09e4ef7b38fea4a7bdf4341b588176d6" category="paragraph">自 2019 年 5 月起， Microsoft 推出了 Azure 原生，这是基于 NetApp ONTAP 技术的第一方门户服务，适用于企业级 NFS 和 SMB 文件服务。这一发展由 Microsoft 和 NetApp 之间的战略合作伙伴关系推动，进一步将世界级 ONTAP 数据服务的覆盖范围扩展到 Azure 。</block>
  <block id="851e5baafa3bd23201e65e29f2fdf06a" category="paragraph">Azure NetApp Files 服务是一种企业级高性能计量文件存储服务。Azure NetApp Files 支持任何工作负载类型，默认情况下具有高可用性。您可以选择服务和性能级别，并通过服务设置 Snapshot 副本。Azure NetApp Files 是一项 Azure 第一方服务，用于在云中迁移和运行要求最严苛的企业文件工作负载，包括数据库， SAP 和高性能计算应用程序，并且不会更改代码。</block>
  <block id="f014a6e06480ef33e3f1ab027f7065ca" category="paragraph">此参考架构为 IT 组织提供了以下优势：</block>
  <block id="5e6e9a1ee378cf26b50e61d8bd46d54d" category="list-text">为各种性能和成本点提供一系列存储层</block>
  <block id="295f4f6daaf50c87d2639d407c47f357" category="section-title">Dask 和 NVIDIA 快速流概述</block>
  <block id="a9dcf931a9aad845de3c5b908d562955" category="paragraph">Dask 是一款开源并行计算工具，可在多台计算机上扩展 Python 库，并加快处理大量数据的速度。它提供的 API 类似于单线程传统 Python 库，例如熊猫， Numpy 和 sciKit 学习。因此，原生 Python 用户不必对其现有代码进行大量更改，即可在整个集群中使用资源。</block>
  <block id="955647f3573b932f8596ba04ed80b7b6" category="paragraph">NVIDIA RAID 是一套开源库，可以完全在 GPU 上运行端到端 ML 和数据分析工作流。通过与 dask 结合使用，您可以轻松地从 GPU 工作站（纵向扩展）扩展到多节点，多 GPU 集群（横向扩展）。</block>
  <block id="7a9ece70a2d60d73203e927718fd8454" category="paragraph">要在集群上部署 dask ，您可以使用 Kubernetes 进行资源编排。您还可以根据进程要求纵向或横向扩展工作节点，进而有助于优化集群资源消耗，如下图所示。</block>
  <block id="b3951b803e4010ed575c9238d2803949" category="paragraph"><block ref="b3951b803e4010ed575c9238d2803949" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0dff6955889d5634f0212efb574ef815" category="doc">单击查看速率预测数据处理和模型训练</block>
  <block id="19075a93ccd90f3ea7019f0572778b2a" category="summary">此页面列出了此解决方案所需的软件要求。</block>
  <block id="793d18702a236e0e3b768917638f0ba2" category="paragraph">下表列出了此解决方案所需的软件要求。</block>
  <block id="8ab697a4168b5fb33603a98d6bc9a436" category="cell">流和 dask 容器映像</block>
  <block id="9ab6289633c326d69a377cbb29bd81a3" category="cell">存储库： "rapidsai/rapidsai" 标记： 0.17-cuda11.0-runtime-ubuntu18.04</block>
  <block id="9e59f01034d2c132fac901b9c14a5d88" category="summary">适用于 Kubernetes 的 NetApp DataOps 工具包可将存储资源和 Kubernetes 工作负载抽象到数据科学工作空间级别。这些功能打包在一个简单易用的界面中，专为数据科学家和数据工程师设计。</block>
  <block id="7aee811c7e891ab94bb5be40b333faaf" category="doc">使用 NetApp DataOps 工具包对数据集和模型进行版本控制</block>
  <block id="fd2d048a9ec0f96d89493b98f72cbe34" category="paragraph">适用于 Kubernetes 的 NetApp DataOps 工具包可将存储资源和 Kubernetes 工作负载抽象到数据科学工作空间级别。这些功能打包在一个简单易用的界面中，专为数据科学家和数据工程师设计。该工具包采用熟悉的 Python 计划形式，可帮助数据科学家和工程师在几秒钟内配置和销毁 JupyterLab 工作空间。这些工作空间可以包含数 TB 甚至数 PB 的存储容量，从而使数据科学家能够将其所有培训数据集直接存储在其项目工作空间中。单独管理工作空间和数据卷的时代已经一去不返。</block>
  <block id="4a6c7893abd7ef92fb09d3359e17324d" category="inline-link">GitHub 存储库</block>
  <block id="eb0d40310a9cc0432fac66dc97652c39" category="paragraph">有关详细信息，请访问工具包<block ref="64134ca6239d4056f34489b42f2baeed" category="inline-link-rx"></block>。</block>
  <block id="cff4cbb413623685c446a2632974cf62" category="summary">此页面将使用传统熊猫的模型训练时间与 dask 进行比较。对于熊猫，由于处理时间较慢，我们加载的数据较少，以避免内存溢出。因此，我们对结果进行了插值计算，以便进行合理的比较。</block>
  <block id="014020acc8f97c1da58961d44b6301eb" category="doc">培训时间比较</block>
  <block id="c8ed0bb49061765f5f30ba006ea7c5c0" category="paragraph">本节将使用传统熊猫的模型训练时间与 dask 进行比较。对于熊猫，由于处理时间较慢，我们加载的数据较少，以避免内存溢出。因此，我们对结果进行了插值计算，以便进行合理的比较。</block>
  <block id="5b5214524edbd74fb721da08e61c8a41" category="paragraph">下表显示了当熊猫随机林模型（数据集每天 200 亿行中的 5000 万行）所使用的数据明显减少时的原始训练时间比较。 15此示例仅使用所有可用数据的 0.25% 以下。而对于 dask-cuML ，我们在所有 200 亿行可用的行上训练了随机林模型。这两种方法的训练时间相当。</block>
  <block id="40a68b5da4b9b224764558bb02ecd028" category="cell">方法</block>
  <block id="0e90ab0d7d04d2a878961f8d40071c83" category="cell">培训时间</block>
  <block id="24cc88af022e13431f8005b38f74e0fd" category="cell">Scikit 学习：在 15 天仅使用 50 米行作为训练数据</block>
  <block id="26e394f0b8009246698f4844db682015" category="cell">47 分 21 秒</block>
  <block id="ed536b2798ed9f16a79fb8f772601548" category="cell">rapids-dask ：使用第 15 天的所有 20 B 行作为训练数据</block>
  <block id="8809f6d1a4b5cbd872b52f83e378e527" category="cell">1 小时， 12 分钟和 11 秒</block>
  <block id="57093fade268287629c2720356ecac57" category="paragraph">如果我们按线性方式插值训练时间结果，如下表所示，则使用分布式训练和 dask 具有显著优势。传统的熊猫科学学习方法需要 13 天来处理和训练 45 GB 的数据，只需一天的单击日志，而使用快速 dask 方法处理相同数量的数据则要快 262.39 倍。</block>
  <block id="36ebc33745cb5ac06238c615c8aaebdc" category="cell">Scikit 学习：使用第 15 天的所有 20 B 行作为训练数据</block>
  <block id="b2ab615236e8c7812b0ab7dff59c552f" category="cell">13 天， 3 小时， 40 分钟和 11 秒</block>
  <block id="0d7cda3e89555f27bf26cf0c0c4f4fed" category="paragraph">在上表中，您可以看到，通过使用带和 dask 的快速处理功能在多个 GPU 实例之间分布数据处理和模型训练，与使用 scide-Learn 模型训练的传统熊猫 DataFrame 处理相比，运行时间要短得多。此框架支持在云端以及多节点多 GPU 集群内部进行纵向和横向扩展。</block>
  <block id="57a499fcdd85136edfd1ee55dedd9675" category="summary">此解决方案遵循 AI/ML 应用程序的生命周期。我们从数据科学家的工作入手，确定准备数据和训练模型所需的不同步骤。通过利用 dask 上的快速访问功能，我们可以在 Azure Kubernetes Service （ AKS ）集群中执行分布式培训，与传统的 Python 科学学习方法相比，可以大幅缩短培训时间。为了完成整个周期，我们将管道与 Azure NetApp Files 集成在一起。</block>
  <block id="e6fab630e7da86a500e1e3c51fa61a00" category="paragraph">Rick Huang ， Verron Martina ， Muncher ， NetApp</block>
  <block id="4c3816ce69205bc811aa89dbe9d09a1a" category="paragraph">数据科学家的工作重点应放在机器学习（ ML ）和人工智能（ AI ）模型的培训和调整上。但是，根据 Google 的研究，数据科学家花费大约 80% 的时间来研究如何使其模型能够与企业应用程序结合使用并大规模运行。</block>
  <block id="a1451f6988178ae140f8da836d63a157" category="paragraph">要管理端到端 AI/ML 项目，需要更广泛地了解企业组件。虽然 DevOps 已接管了这些类型的组件的定义，集成和部署，但 ML 操作的目标是类似的流程，其中包括 AI/ML 项目。要了解端到端 AI/ML 管道在企业中涉及的内容，请参见以下所需组件列表：</block>
  <block id="24bea3d677b34d6aea9ff01417fd9d06" category="list-text">集成开发环境（ IDE ）</block>
  <block id="e6a53478c3fc5682c6f851672b3e7bc9" category="paragraph">数据科学领域涉及 IT 和业务领域的多个领域：</block>
  <block id="9ca78187997ba2a23a73c094256ae63f" category="list-text">云管理员和架构师需要能够设置和管理 Azure 资源。</block>
  <block id="060bc2911862b1ab8f6b4b77542434a2" category="paragraph">在本技术报告中，我们将介绍 Azure NetApp Files ，快速 AI ， dask 和 Azure 如何帮助这些角色为业务带来价值。</block>
  <block id="ed8b6e047f5d4e844fe3e870c3fda4a3" category="paragraph">Azure NetApp Files 提供各种性能层。客户可以从标准层开始，无需移动任何数据即可无中断地横向扩展和纵向扩展到高性能层。数据科学家可以利用此功能大规模训练模型，而不会出现任何性能问题，从而避免集群中出现任何数据孤岛，如下图所示。</block>
  <block id="d4dc9019b6000fd12d9dc6b091fe3e26" category="paragraph"><block ref="d4dc9019b6000fd12d9dc6b091fe3e26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d577549f9b3a229c338e203a433489f6" category="summary">本节介绍如何将 AKS vNet 与 Azure NetApp Files vNet 建立对等关系。</block>
  <block id="e61e6d340ad05dc2e1ad0982f6857d7d" category="doc">对等 AKS vNet 和 Azure NetApp Files vNet</block>
  <block id="e6ef5f0946a89d073a8f360de1038061" category="paragraph">要将 AKS vNet 与 Azure NetApp Files vNet 建立对等关系，请完成以下步骤：</block>
  <block id="87c2d6c506d0bf65d2c5d773474f9c0f" category="list-text">在搜索字段中输入虚拟网络。</block>
  <block id="7680f3bc49a836c67a8b0e7d2d9ccb44" category="list-text">选择 `vnet AK -vnet-name 。` 单击它并在搜索字段中输入 "Peels" 。</block>
  <block id="fc3bb6a018a8f599cab21678959f92b0" category="list-text">单击 +Add 。</block>
  <block id="1991ef5bd8e165e42c56ccaefa2f640f" category="list-text">输入以下描述符：</block>
  <block id="51e5b9c0a583a9afbc2f998e622fd30d" category="list-text">对等链路名称是 `aps-vnet-name_to_anf` 。</block>
  <block id="14ac6521e2758ba95fe7be9ca6a82cd1" category="list-text">subscriptionID 和 Azure NetApp Files vNet 作为 vNet 对等配对节点。</block>
  <block id="70b58cb057d859d4da9f17e43ffd238c" category="list-text">保留所有非星号部分的默认值。</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">单击添加。</block>
  <block id="50e3209c871e4867931ef51a9344a921" category="paragraph">有关详细信息，请参见<block ref="f81943721c88f7efe9b8252470f9ea43" category="inline-link-rx"></block>。</block>
  <block id="dcfa517bb68d187d11e580baf2ecf588" category="summary">此页面介绍如何使用 Helm 在 AKS 上设置带快速部署的 dask 。</block>
  <block id="fd22fb1626b987fa7b72743fa9698ec6" category="doc">使用 Helm 在 AKS 上设置带快速部署的 dask</block>
  <block id="d81f517b6ad0d9702be81a8199a2246f" category="paragraph">要使用 Helm 在 AKS 上设置带快速部署的 dask ，请完成以下步骤：</block>
  <block id="549c839f491ec7099a895dd1cfea7534" category="list-text">创建一个命名空间以安装带有快速流的 dask 。</block>
  <block id="74d041e68ac2a21a636ab14ae78f279d" category="list-text">创建一个 PVC 以存储点击率数据集：</block>
  <block id="f5008aa6b27cdcaadbe27960383c8ff6" category="list-text">将以下 YAML 内容保存到文件中以创建 PVC 。</block>
  <block id="67d464c36bcc48173c964a780459dbfd" category="list-text">将 YAML 文件应用于 Kubernetes 集群。</block>
  <block id="be0ca76aafd92c18792693b8f05d01ce" category="inline-link"><block ref="be0ca76aafd92c18792693b8f05d01ce" category="inline-link-rx"></block></block>
  <block id="dc7ba914646428512334728c1f0ebd7d" category="list-text">克隆 `apidsai git` repository （<block ref="4f08c7c28c19e75f4d8607fc65d40067" category="inline-link-rx"></block>）。</block>
  <block id="50aef45ee39d958bc589f422bfb6d1bf" category="list-text">修改 `values.yaml` 并包括先前为员工和 Jupyter 工作空间创建的 PVC 。</block>
  <block id="06867e85b141bb9d17f8ed6b4b685c46" category="list-text">转至存储库的 `rapidsai` 目录。</block>
  <block id="1a985ac965074fab9cfcee28ef954755" category="list-text">更新 `values.yaml` 文件并使用 PVC 挂载卷。</block>
  <block id="52076eb1fec3929530258335052328b3" category="list-text">转到存储库的主目录，然后使用 Helm 在 AKS 上为三个辅助节点部署 dask 。</block>
  <block id="1a17b23dd49d997677e18c9b9fe29935" category="summary">此页面介绍如何使用原生任务流信息板监控 dask 。</block>
  <block id="3268570ddd540695f3e92ff79d8f4684" category="doc">使用原生任务流信息板监控 dask</block>
  <block id="9eeb55820f49a600fa229f23cfe9e5b5" category="inline-link">dask 分布式计划程序</block>
  <block id="99b248c7005783fe2682ad82217e9a24" category="paragraph">。<block ref="7df0d90bf997a373bfe85bbe10a2d2c8" category="inline-link-rx"></block> 以两种形式提供实时反馈：</block>
  <block id="d8516bf5d94a38a1fa1d7a8c3b92dee7" category="list-text">一个交互式信息板，其中包含许多图表和包含实时信息的表</block>
  <block id="d22ebe91c5dc1499387785da997fbe7d" category="list-text">一个适合在控制台或笔记本电脑中交互使用的进度条</block>
  <block id="6e35e4c1cc9332ebc8028df451bc4f06" category="paragraph">在我们的案例中，下图显示了如何监控任务进度，包括存储的字节数，详细细分流数量的任务流以及执行关联功能的任务名称的进度。在我们的案例中，由于我们有三个辅助节点，因此流有三个主要区块，而颜色代码表示每个流中的不同任务。</block>
  <block id="5743e70224503025dacaa77fae253c4f" category="paragraph"><block ref="5743e70224503025dacaa77fae253c4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a5c7a858f05434bf6637c3995959f49" category="paragraph">您可以选择分析单个任务并以毫秒为单位检查执行时间，或者确定任何障碍或障碍。例如，下图显示了随机林模型安装阶段的任务流。要执行的功能要多得多，包括用于 DataFrame 处理的唯一区块，用于安装随机林的 _construct_rf 等。由于 Criteo Click Logs 中一天的数据非常大（ 45 GB ），因此大部分时间都花在了 DataFrame 操作上。</block>
  <block id="816ff133aaa3d2f46ca0c7842f5fdaab" category="paragraph"><block ref="816ff133aaa3d2f46ca0c7842f5fdaab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d68d11ee3f69a45d681f78c744cae498" category="summary">您可以通过将现有卷移动到使用所需卷服务级别的另一个容量池来更改此卷的服务级别。借助此解决方案，客户可以从标准层中的小型数据集和少量 GPU 入手，并随着数据量和 GPU 的增加而横向扩展或纵向扩展到高级层。</block>
  <block id="2fe5665064f07acc8afc830f911c09a5" category="doc">Azure NetApp Files 性能层</block>
  <block id="de524ca3fc83ef426bc329e1a8b712ea" category="paragraph">您可以通过将现有卷移动到使用所需卷服务级别的另一个容量池来更改此卷的服务级别。借助此解决方案，客户可以从标准层中的小型数据集和少量 GPU 入手，并随着数据量和 GPU 的增加而横向扩展或纵向扩展到高级层。高级层提供的每 TB 吞吐量是标准层的四倍，并且可以执行纵向扩展，而无需移动任何数据即可更改卷的服务级别。</block>
  <block id="5f92df8a2ac38644ed8ba20e16791602" category="paragraph">要动态更改卷的服务级别，请完成以下步骤：</block>
  <block id="8c83c4957baac2f6fea18f9d77767e3a" category="paragraph"><block ref="8c83c4957baac2f6fea18f9d77767e3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21ec2eabbe87e02cad1b0d4279ea00a7" category="list-text">在更改池窗口中，选择要将卷移动到的容量池。</block>
  <block id="ef3a0105bad35ad4c385d92daf6496a6" category="paragraph"><block ref="ef3a0105bad35ad4c385d92daf6496a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">单击确定。</block>
  <block id="32ae33eea9c6b04002778d814c344fb5" category="section-title">自动执行性能层更改</block>
  <block id="1c9506694c5a6fe83d1a0389d1d24564" category="paragraph">以下选项可用于自动执行性能层更改：</block>
  <block id="54a3bcd89041e8f96766dcb598b15511" category="list-text">动态服务级别更改目前仍在公有预览中，默认情况下不会启用。要在 Azure 订阅上启用此功能，请参见本文档了解如何操作<block ref="773d4c9e90e7325c5fcf35857900af6e" category="inline-link-rx"></block>。</block>
  <block id="0b01c5f61940e864222c5b29615a7eeb" category="inline-link">卷池更改文档</block>
  <block id="265eed4df59633a830c9da49505786fc" category="list-text">中提供了 Azure CLI 卷池更改命令<block ref="db78b725076ccf0203288c6620e52eb9" category="inline-link-rx"></block> 在以下示例中：</block>
  <block id="4455e376dc005ca0a99be0491b917ce7" category="inline-link">Set-AzNetAppFilesVolumePool cmdlet</block>
  <block id="a5bce2f378011f6036711869a5e8073b" category="list-text">PowerShell ：<block ref="45dc9ea5ce8eabd60a14674d792889e0" category="inline-link-rx"></block> 更改 Azure NetApp Files 卷的池，如以下示例所示：</block>
  <block id="60f89129c6220bfb3de5a84b4f6471ca" category="summary">此页面介绍了我们如何使用熊猫和 dask DataFrames 从 Criteo TB 数据集中加载 Click Logs 数据。在广告交换的数字广告中，使用情形与此相关，它可以预测是否会点击广告，或者如果交换在自动管道中使用的模型不准确，从而构建用户的个人资料。</block>
  <block id="efdbc2f24f0a87c559175250c645b26b" category="doc">在熊猫中加载 Criteo 单击 Logs Day 15 ，然后训练一个 sc科学 学习随机林模型</block>
  <block id="f82859e215621220b9aae984f796ef24" category="paragraph">本节介绍如何使用熊猫和 dask DataFrames 从 Criteo TB 数据集中加载 Click Logs 数据。在广告交换的数字广告中，使用情形与此相关，它可以预测是否会点击广告，或者如果交换在自动管道中使用的模型不准确，从而构建用户的个人资料。</block>
  <block id="f08833dbbe310e84a1ba564838776db2" category="paragraph">我们从 Click Logs 数据集加载了第 15 天的数据，总计 45 GB 。在 Jupyter 笔记本电脑中运行以下单元 `CT-PandasRF-colled.ipynb` 创建一个包含前 5 ， 000 万行的熊猫 DataFrame ，并生成一个 scide-Learn 随机林模型。</block>
  <block id="f9964b2f8f54a1422ac46bab70fd1216" category="inline-link">官方科学知识工具包学习文档</block>
  <block id="5646953e1414498e1ddf2eb3ab488e27" category="paragraph">要使用经过培训的随机林模型执行预测，请在此笔记本电脑中运行以下段落。为了避免重复，我们采用了自第 15 天起的最后 100 万行作为测试集。该单元格还会计算预测准确性，其定义为模型准确预测用户是否单击 AD 。要查看此笔记本中任何不熟悉的组件，请参见<block ref="27e4d9ca2442a6439517a3ec2c7a4e73" category="inline-link-rx"></block>。</block>
  <block id="7f39827ac712fa5b76b27ff0b267373c" category="sidebar">使用 NetApp DataOps 工具包进行数据集和型号版本控制</block>
  <block id="6589da0279dd02b9b1d177e0ff5f457b" category="list-text">创建一个命名空间 `NetApp-Acc-operator` 以安装 Astra 控制中心操作员。</block>
  <block id="e3990b0b892faaf03261a0a1bcd00b9b" category="list-text">使用凭据创建一个密钥，以登录到 `NetApp-Acc-operator` 命名空间中的映像注册表。</block>
  <block id="8b6327b93d10679b1f412976af9d3bba" category="summary">Azure NetApp Files ，速写和 dask 可加快和简化大规模 ML 处理和培训的部署，并与 Docker 和 Kubernetes 等业务流程工具集成。通过统一端到端数据管道，此解决方案可降低许多高级计算工作负载固有的延迟和复杂性，从而有效地弥补开发和运营之间的差距。</block>
  <block id="5dc14d36063086387d2eb7cf012544aa" category="list-text">创建 VolumeSnapshotClass ，然后使用该类创建 VolumeSnapshot 。导航到 "Storage"&gt;"VolumeSnapshotClasss" ，然后单击 "Create VolumeSnapshotClass" 。</block>
  <block id="3ffbaa72c8e63f0ec3ced08d8ebf9f72" category="list-text">首先，将 Snapshot 还原到新的 PVC 中。导航到存储 &gt; 卷快照，单击要还原的快照旁边的省略号，然后单击还原为新 PVC 。</block>
  <block id="8a4d1acf8df9931b5c42b3253f943d79" category="list-text">接下来，使用此 PVC 创建一个新虚拟机。导航到工作负载 &gt; 虚拟化 &gt; 虚拟机，然后单击创建 &gt; 使用 YAML 。</block>
  <block id="91b9a57ab88a6942f692f9f393549f6e" category="list-text">在规范 &gt; 模板 &gt; 规范 &gt; 卷部分中，指定从 Snapshot 创建的新 PVC ，而不是从容器磁盘创建的新 PVC 。根据您的要求提供新虚拟机的所有其他详细信息。</block>
  <block id="78c43863df60a7808264e8659cfa6b54" category="paragraph">Astra Trident 是一款开源且完全受支持的存储编排程序，适用于容器和 Kubernetes 分发版，包括 Red Hat OpenShift 。Trident 可与包括 NetApp ONTAP 和 Element 存储系统在内的整个 NetApp 存储产品组合配合使用，并且还支持 NFS 和 iSCSI 连接。Trident 允许最终用户从其 NetApp 存储系统配置和管理存储，而无需存储管理员干预，从而加快了 DevOps 工作流的速度。</block>
  <block id="d719c733d0cd8753c048c8c3a025fd51" category="paragraph">MetalLB 是一种安装在 OpenShift 集群上的自托管网络负载平衡器，可用于在未在云提供程序上运行的集群中创建类型为负载平衡器的 OpenShift 服务。MetalLB 可协同工作以支持负载平衡器服务的两个主要功能是地址分配和外部公告。</block>
  <block id="13f78a1c753a58b3786e5664e7b01344" category="list-text">* BGP 模式。 * 在此模式下， OpenShift 集群中的所有节点都与路由器建立 BGP 对等会话，并公布路由以将流量转发到服务 IP 。前提条件是将 MetalLB 与该网络中的路由器集成在一起。由于 BGP 中采用哈希机制，因此在服务的 IP 到节点映射发生更改时，它具有一定的限制。有关详细信息，请参见文档 <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>。</block>
  <block id="5fe238de20fea7c5ec86dde0a98c5841" category="admonition">在本文档中，我们将在第 2 层模式下配置 MetalLB 。</block>
  <block id="0ef06ef8df800cf71fb95c66e0e08f1a" category="list-text">首先导航到 " 自动化基础架构 "&gt;" 集群 " 。</block>
  <block id="e056bb6efa17796fc810edad8410280d" category="list-text">创建提供程序连接：导航到 " 提供程序连接 " 并单击 " 添加连接 " ，提供与选定提供程序类型对应的所有详细信息，然后单击 " 添加 " 。</block>
  <block id="401b252566122602a82ff66bc7ed3e6c" category="list-text">要创建新集群，请导航到集群，然后单击添加集群 &gt; 创建集群。提供集群和相应提供程序的详细信息，然后单击创建。</block>
  <block id="2da6eeb34cf16de43ab8fa2f939d81c7" category="list-text">创建集群后，该集群将显示在集群列表中，状态为 Ready 。</block>
  <block id="f52ae06380cfd00cae7839562f550e87" category="list-text">导航到集群，然后单击添加集群 &gt; 导入现有集群。</block>
  <block id="63b7276dd1b569babc28304e786e2041" category="list-text">输入集群的名称，然后单击保存导入并生成代码。此时将显示一个用于添加现有集群的命令。</block>
  <block id="be87809a27ab2944f89ccaebd89b7596" category="list-text">单击 Copy Command ，然后对要添加到集线器集群的集群运行命令。此操作将在集群上启动所需代理的安装，完成此过程后，集群将显示在集群列表中，并显示状态为 Ready 。</block>
  <block id="627fd2c5e0310dc7409ea377e5d13045" category="section-title">验证在分配的项目中创建 PVC 或 Pod 的访问权限</block>
  <block id="8c9885c86a67cc4c47a30d7e8d14badb" category="section-title">验证在其他项目中创建 PVC 或 Pod 的访问权限，或者使用专用于另一项目的资源</block>
  <block id="83aa0a39007c30e71adde6fbf8180d9f" category="section-title">验证对查看和编辑项目， ResourceQuotas 和 StorageClasses 的访问权限</block>
  <block id="53c583e55a36ad49234df678a2dbcf45" category="paragraph">NetApp Element 软件可提供模块化的可扩展性能，每个存储节点均可为环境提供有保障的容量和吞吐量。NetApp Element 系统可以在一个集群中从 4 个节点扩展到 100 个节点，并提供多种高级存储管理功能。</block>
  <block id="1c01b62cc887329b006a88e9f959b5d4" category="list-text">确保已在 IdP 上为 project-3 创建用户组并与 OpenShift 集群同步。</block>
  <block id="e98511d60f9850de86f096614f447322" category="paragraph">适用于 Kubernetes 的高级集群管理提供了一种监控所有集群中的节点， Pod 以及应用程序和工作负载的方法。</block>
  <block id="36aff44ed429ca86d182dc7ee3dfdbb1" category="list-text">导航到 " 观察环境 "&gt;" 概述 " 。</block>
  <block id="c9904a9276a489fc238c999d2ddd633f" category="list-text">所有集群中的所有 Pod 和工作负载都会根据各种筛选器进行监控和排序。单击 Pod 以查看相应数据。</block>
  <block id="7cd1c61051d3647bc47d839e0efee222" category="list-text">集群中的所有节点都会根据各种数据点进行监控和分析。单击节点可更深入地了解相应的详细信息。</block>
  <block id="4e7f54a0ebc5cd69209a17181d477e4c" category="list-text">系统会根据不同的集群资源和参数监控和组织所有集群。单击集群可查看集群详细信息。</block>
  <block id="842f7d4793f116332f5b12b648dfd539" category="list-text">导航到工作负载 &gt; 虚拟化 &gt; 虚拟机，然后单击创建 &gt; 使用向导。</block>
  <block id="ae024d48dbfaaf4badad7bf9c812a98f" category="list-text">单击 rootdisk 旁边的省略号，并确保已选择使用 Trident 配置的 storageclass 。展开高级，然后为访问模式选择共享访问（ rwx ）。然后单击保存。</block>
  <block id="289f346dbeb0185de2648a24955ca887" category="list-text">导航到工作负载 &gt; 虚拟化 &gt; 虚拟机。</block>
  <block id="a542faac65568ba146d392d835d7fb33" category="list-text">* VMware vCenter Server* 。 VMware vCenter Server 可通过一个控制台统一管理所有主机和 VM ，并聚合对集群，主机和 VM 的性能监控。</block>
  <block id="46b35ead34118cb2c50327c71e4aa640" category="list-text">* 分布式资源计划程序（ DRS ）。 * 可以配置 VMware vSphere 集群，以便对其托管的 VM 的资源需求进行负载平衡。具有资源管理的 VM 可以热迁移到集群中的其他节点，以确保有足够的可用资源。</block>
  <block id="5c6371faa8d72dee8337811921707a4b" category="paragraph">NetApp 解决方案上的 Red Hat OpenShift 使用两个数据交换机提供 25 Gbps 的主数据连接。它还使用两个额外的管理交换机，这些交换机以 1 Gbps 的速度提供连接，用于存储节点的带内管理以及 IPMI 功能的带外管理。OCP 使用 VMware vSphere 上的 VM 逻辑网络进行集群管理。本节介绍解决方案中使用的每个虚拟网段的布局和用途，并概述了部署解决方案的前提条件。</block>
  <block id="f33bd5bca507f2b59fc0a43383ade71b" category="cell">虚拟子系统网络访问</block>
  <block id="3500f2194985ef1b586c649fbe519d8d" category="paragraph">本文档中介绍的经验证的架构介绍了适用于 HA 操作的最低硬件部署，具体方法是部署两个 ESXi 虚拟机管理程序节点，并通过启用 VMware vSphere HA 和 VMware vMotion 来确保容错配置。此配置允许部署的 VM 在两个虚拟机管理程序之间迁移，并在一个主机不可用时重新启动。</block>
  <block id="e79fa01ec6b411cfda4f8baad9f95cb0" category="paragraph">由于 Red Hat OpenShift 最初部署有三个主节点，因此在某些情况下，双节点配置中至少有两个主节点可以占用同一个节点，如果该特定节点不可用，可能会导致 OpenShift 中断。因此， Red Hat 的最佳实践是，必须至少部署三个 ESXi 虚拟机管理程序节点，以便可以均匀分布 OpenShift 主节点，从而提高容错能力。</block>
  <block id="f5428382aa8b44d7ef6ca71195afc8ca" category="paragraph">通过启用 VM 和主机关联性，可确保在多个虚拟机管理程序节点之间分布 OpenShift 主节点。</block>
  <block id="c23c2371397ad3490af42526283948a4" category="paragraph">关联性或反关联性是一种为一组 VM 和 / 或主机定义规则的方法，用于确定这些 VM 是在同一主机上运行还是在组中的主机上运行，还是在不同主机上运行。它通过创建由具有一组相同参数和条件的 VM 和 / 或主机组成的关联组来应用于 VM 。根据关联组中的 VM 是在组中的同一主机上运行，还是在不同主机上单独运行，此关联组的参数可以定义正关联性或负关联性。</block>
  <block id="5e059b05dcf86db414d6b8cdd66bcf0f" category="paragraph">IPI 可通过本文档前面讨论的交互式向导轻松部署 OpenShift 集群。但是，在集群部署过程中，您可能需要更改某些默认值。</block>
  <block id="2a3b399798aa16ecfbc1425cc560bfad" category="section-title">用例</block>
  <block id="f08561bbd831bfa1923e6acf045ef13a" category="section-title">业务价值</block>
  <block id="81f74b2a02db97d708bd7cbf08d2463a" category="section-title">NetApp 存储系统</block>
  <block id="660d073f0987fac312dc40bd5dc868bd" category="paragraph">NetApp 拥有多个存储系统，非常适合企业数据中心和混合云部署。NetApp 产品组合包括 NetApp ONTAP ， NetApp Element 和 NetApp E 系列存储系统，所有这些系统均可为容器化应用程序提供永久性存储。</block>
  <block id="069b087e8e1e69cc928f18a85f683523" category="section-title">NetApp 存储集成</block>
  <block id="b4186621511a622be24ad982b0a8ec32" category="paragraph">NetApp Astra 控制中心为有状态 Kubernetes 工作负载提供了一组丰富的存储和应用程序感知型数据管理服务，这些服务部署在内部环境中，并采用值得信赖的 NetApp 数据保护技术。</block>
  <block id="947496ade2e4a2c8e929d9aa9f00be04" category="paragraph">有关详细信息，请访问 NetApp Astra 网站<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>。</block>
  <block id="0bc570c518e7c4f356ebceb14fa8372f" category="section-title">高级配置选项</block>
  <block id="aa44798f04a58b33c3699abd02a59c57" category="paragraph">本节专门介绍实际用户在将此解决方案部署到生产环境中时可能需要执行的自定义设置，例如创建专用私有映像注册表或部署自定义负载平衡器实例。</block>
  <block id="382742bb5fff6a719c144a0a01cd17e3" category="section-title">已验证版本的当前支持列表</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">软件版本</block>
  <block id="e3024b13494086daa1b9813a799ba41a" category="cell">数据中心虚拟化</block>
  <block id="35be109b995061abd3392d1b01fd0e9a" category="summary">Red Hat OpenStack 平台为创建，部署和扩展安全可靠的私有 OpenStack 云提供了一个集成基础。</block>
  <block id="dc34aa9761794ceabad79dc29944976e" category="paragraph">OpenStack 项目是一个快速开发的社区项目，每六个月提供更新版本。最初， Red Hat OpenStack Platform 通过发布新版本以及每个上游版本并为每个第三个版本提供长期支持，跟上了此版本周期的步伐。最近，在 OSP 16.0 版（基于 OpenStack 训练）中， Red Hat 选择不跟上版本号的步伐，而是将新功能支持到子版本中。最新版本是 Red Hat OpenStack Platform 16.1 ，其中包括上游 Ussuri 和维多利亚版本的后台高级功能。</block>
  <block id="ffd7a6889e6ea6965969472250235082" category="paragraph">OpenStack 平台服务以容器的形式部署，可将服务彼此隔离，并可轻松进行升级。OpenStack 平台使用一组使用 Kolla 构建和管理的容器。可通过从 Red Hat 自定义门户中提取容器映像来部署服务。这些服务容器可使用 Podman 命令进行管理，并可使用 Red Hat OpenStack Director 进行部署，配置和维护。</block>
  <block id="7adea0d9c77aabccd8bb67ae0a832d59" category="cell">项目名称</block>
  <block id="e7a39f4cb0dd0ffaaffe8fb0319dec67" category="cell">OpenStack 网络</block>
  <block id="4f0550f066ae72bb8c24fc3f59c323bf" category="cell">块存储</block>
  <block id="670aaecb1a526fbed439dad3ec353a96" category="cell">对象存储</block>
  <block id="b81a67bf2ab52e16a62a9c71454c90ee" category="paragraph">Red Hat OpenStack Director 需要 IPMI 功能才能使用具有讽刺意味的裸机配置服务部署 Red Hat OpenStack Platform 。</block>
  <block id="567f5ee3e60ecdd5338b39cab0006510" category="cell">存储基础架构</block>
  <block id="ea414c629935302b115bf3dabf5f827c" category="cell">中子通过 VXLAN 的通道为每个租户提供自己的网络。网络流量在每个租户网络中隔离。每个租户网络都有一个关联的 IP 子网，而网络命名空间意味着多个租户网络可以使用相同的地址范围而不会导致冲突</block>
  <block id="f2feccaa3f5d086f0b16010ff463e369" category="cell">公共网络，用于托管用于图形管理的 OpenStack 信息板（ Horizon ），并允许公有 API 调用来管理 OpenStack 服务。</block>
  <block id="493fd05bc58266bcd8394072cbe81748" category="paragraph">本文档中介绍的经验证的架构通过部署三个 OSP 控制器节点和两个 OSP 计算节点提供了最适合 HA 操作的硬件部署。此架构可确保容错配置，其中两个计算节点均可启动虚拟实例，而已部署的 VM 则可在两个虚拟机管理程序之间迁移。</block>
  <block id="ebe803a768c48af52bca59e6ab7df9bf" category="paragraph">由于 Red Hat OpenShift 最初使用三个主节点进行部署，因此双节点配置可能会发生原因至少两个主节点占用同一节点，从而可能导致 OpenShift 在特定节点不可用时发生中断。因此， Red Hat 的最佳实践是至少部署三个 OSP 计算节点，以便 OpenShift 主节点可以均匀分布，并且解决方案可以获得更多的容错能力。</block>
  <block id="bbfdc160550acbcdb4791a961a165d5d" category="paragraph">通过启用虚拟机 / 主机关联性，可以在多个虚拟机管理程序节点之间分布 OpenShift 主节点。</block>
  <block id="cb346122cae28dfb1fcf0811f46296a2" category="paragraph">关联性是一种为一组 VM 和 / 或主机定义规则的方法，用于确定这些 VM 是在组中的同一主机上运行还是在不同主机上运行。它通过创建由具有一组相同参数和条件的 VM 和 / 或主机组成的关联组来应用于 VM 。根据关联组中的 VM 是在组中的同一主机上运行，还是在不同主机上单独运行，此关联组的参数可以定义正关联性或负关联性。在 Red Hat OpenStack 平台中，可以通过创建服务器组和配置筛选器来创建和实施主机关联性和反关联性规则，以便 Nova 在服务器组中部署的实例部署在不同的计算节点上。</block>
  <block id="de5bd213c3df23736df75636241f96de" category="admonition">OSP 服务器组具有特定的硬关联性 / 反关联性限制；如果没有足够的资源可在不同的节点上部署，或者没有足够的资源可用于共享节点，则 VM 将无法启动。</block>
  <block id="dc5fa659e0452a77d6006f5b72f8b334" category="paragraph">要启用 Trident 与 NetApp Element 存储系统的集成，您必须创建一个后端，以便使用 iSCSI 协议与存储系统进行通信。</block>
  <block id="05ca7295321cb9b417a251e75557c6c5" category="list-text">下载的安装归档中提供了 `sample-input` folder 层次结构中的示例后端文件。对于提供 iSCSI 服务的 NetApp Element 系统，将 `backend-solidfire.json` 文件复制到您的工作目录中，然后编辑该文件。</block>
  <block id="b73d05719d0ea2964c963f6f83a34d3d" category="admonition">此文件中定义了一个名为 `FSType` 的可选字段。在 iSCSI 后端，可以将此值设置为特定的 Linux 文件系统类型（ XFS ， ext4 等），也可以将其删除以允许 OpenShift 决定要使用的文件系统。</block>
  <block id="920db239cf01c8ded4b7f364194ab540" category="list-text">从边栏导航到管理应用程序，然后单击创建应用程序。提供要创建的应用程序的详细信息，然后单击保存。</block>
  <block id="f4fc33973424c12639f93790b1c6f370" category="paragraph">NetApp 提供强大的全闪存（ AFF ）和横向扩展混合（ FAS ）存储平台，这些平台专为低延迟性能，集成数据保护和多协议支持量身定制。</block>
  <block id="c48db988cd283c11f89d4dd85803ec0a" category="doc">在使用 NetApp 的 Red Hat OpenShift 上配置多租户</block>
  <block id="6d72da55d82cdd434045ba5df1a959b6" category="paragraph">许多在容器上运行多个应用程序或工作负载的组织往往会为每个应用程序或工作负载部署一个 Red Hat OpenShift 集群。这样，他们就可以对应用程序或工作负载实施严格的隔离，优化性能并减少安全漏洞。但是，为每个应用程序部署一个单独的 Red Hat OpenShift 集群会产生自己的一系列问题。它增加了单独监控和管理每个集群所需的运营开销，由于为不同应用程序配置了专用资源而增加了成本，并妨碍了高效的可扩展性。</block>
  <block id="332dcd535fa9ce865f462efb80829a35" category="paragraph">要解决这些问题，可以考虑在一个 Red Hat OpenShift 集群中运行所有应用程序或工作负载。但是，在这种架构中，资源隔离和应用程序安全漏洞是主要挑战之一。一个工作负载中的任何安全漏洞都可能自然溢出到另一个工作负载，从而增加影响区域。此外，一个应用程序的任何突然不受控制的资源利用率都会影响另一个应用程序的性能，因为默认情况下没有资源分配策略。</block>
  <block id="73c1b26ace2fc5fca6e6e78c00a61837" category="paragraph">其中一个有效的解决方案是在 Red Hat OpenShift 上配置多租户。多租户是一种架构，允许多个租户在同一集群上共存，并正确隔离资源，安全性等。在这种情况下，可以将租户视为集群资源的一部分，这些资源配置为供特定用户组专用使用。在 Red Hat OpenShift 集群上配置多租户具有以下优势：</block>
  <block id="f3ff3f5b3c67fb47bb8ec0f2f688b97d" category="paragraph">对于完全实现的多租户 OpenShift 集群，必须为属于不同资源分段的集群资源配置配额和限制：计算，存储，网络连接，安全性等。虽然我们会介绍此解决方案中所有资源分段的某些方面， 我们重点介绍最佳实践，通过在由 NetApp ONTAP 提供支持的 Astra Trident 动态分配的存储资源上配置多租户，隔离并保护同一 Red Hat OpenShift 集群上多个工作负载提供或使用的数据。</block>
  <block id="1cf7b9db4d7fe091bd1bbb685e5beea8" category="paragraph">使用 Red Hat Advanced Cluster Management for Kubernetes 可以执行以下任务：</block>
  <block id="808c579683377aa7bd89b8e4d76ba220" category="list-text">跨数据中心和公有云创建，导入和管理多个集群。</block>
  <block id="7fe0555145a586e3fb769f86902ccc72" category="list-text">从一个控制台在多个集群上部署和管理应用程序或工作负载。</block>
  <block id="416434625b0f2158d99a4af37f233805" category="list-text">监控和分析不同集群资源的运行状况和状态</block>
  <block id="fed6fdd49a1e6adda0ea12a93e74ea2d" category="list-text">监控并强制实施多个集群的安全合规性。</block>
  <block id="1630dbfdd4887ce201ea82c71cde3d11" category="doc">部署适用于 Kubernetes 的高级集群管理</block>
  <block id="bc2ab7a7550cebeb52a08cf830b5ecf6" category="list-text">导航到 Operators &gt; Operators Hub ，然后搜索适用于 Kubernetes 的高级集群管理。</block>
  <block id="c4ab802b80978ba1c5de3922d546bdb7" category="list-text">选择适用于 Kubernetes 的高级集群管理，然后单击安装。</block>
  <block id="c972585d6241c4f2ed2604bcc8706358" category="list-text">在 Install Operator 屏幕上，提供必要的详细信息（ NetApp 建议保留默认参数），然后单击 Install 。</block>
  <block id="7bf3d0678c48be5730f20005e6f88aa1" category="list-text">安装操作员后，单击创建多集群中心。</block>
  <block id="95f29f27e373a9759cf065e1fde23e28" category="list-text">在 "Create MultiClusterHub " 屏幕上，在提供详细信息后单击 "Create 。此操作将启动多集群集线器的安装。</block>
  <block id="a50aa5e8249109d6f4902945e968ad7d" category="list-text">在打开集群管理命名空间中的所有 Pod 均移至运行状态且操作员移至成功状态后，将安装适用于 Kubernetes 的高级集群管理。</block>
  <block id="391dd52c88201d377f1572062e22c43e" category="list-text">完成集线器安装需要一些时间，完成后，多集群集线器将变为运行状态。</block>
  <block id="eef36825efd5d2d40e4f833635cd19da" category="list-text">它会在开放式集群管理命名空间中创建路由。连接到路由中的 URL 以访问高级集群管理控制台。</block>
  <block id="f122078c68f20c36897fec8a7c4a23e8" category="doc">OpenShift 概述</block>
  <block id="9c2dd02f13d452b4422ac6c864933f01" category="paragraph">从 Red Hat OpenShift 4 开始， OpenShift 的部署方法包括使用用户配置基础架构（ User Provisioned Infrastructure ， UPI ）手动部署高度自定义的部署，或者使用安装程序配置的基础架构（ IPI ）完全自动化部署。</block>
  <block id="66f8ff89bd2c9146cb3273d416c60fd2" category="list-text">选择要将 Red Hat OpenShift 部署到的环境。</block>
  <block id="f5806bcee67fc8f13f0255068a186e42" category="list-text">在下一屏幕中，下载安装程序，唯一的拉取密钥以及用于管理的 CLI 工具。</block>
  <block id="d711fd24836980dd490f3c01dd3ee8de" category="paragraph">NetApp 已使用安装程序配置基础架构（ IPI ）部署方法在以下每个数据中心环境中测试和验证了 Red Hat OpenShift 在其实验室中的部署：</block>
  <block id="77caa49b32b4fc8ce3276158f57f9229" category="doc">NetApp 存储概述</block>
  <block id="50bc4bb14f0d89a22c593112574d0fb3" category="list-text">AFF 和 FAS 系统运行 NetApp ONTAP ，并为基于文件（ NFS ）和基于块（ iSCSI ）的使用情形提供存储。</block>
  <block id="bf3bfadca5040d5a50a8703c7dbb7ef1" category="list-text">Cloud Volumes ONTAP 和 ONTAP Select 在云和虚拟空间方面的优势各不相同。</block>
  <block id="cb050b8fb8c2102a0ab337119eb19f0f" category="admonition">NetApp 产品组合中的每个存储系统都可以简化内部站点和云之间的数据管理和移动，从而确保数据位于应用程序所在位置。</block>
  <block id="b432301f7ba469598e6ea2eb86e4859a" category="paragraph">通常，最易于部署的解决方案是最佳选择，但在某些情况下，需要进行高级自定义，以满足特定应用程序或要部署解决方案的环境的要求或规范。为此，采用 NetApp 解决方案的 Red Hat OpenShift 允许进行以下自定义以满足这些需求。</block>
  <block id="d31d340fd6b135cac2cfac7b04a34c10" category="list-text">在左上角，将角色从管理员更改为开发人员。单击 +Add ，然后从目录中选择。在 Filter by Keyword 栏中，搜索 Jenkins 。选择 Jenkins Service with Persistent Storage 。</block>
  <block id="fb86f2dea9912af1bb1677c9cf33e619" category="list-text">Jenkins Pod 大约需要 10 到 12 分钟才能进入就绪状态。</block>
  <block id="d59d1324dea050a2c0ffc376de411aa0" category="list-text">由于在创建 Jenkins 应用程序时使用了 OpenShift OAuth ，因此请单击使用 OpenShift 登录。</block>
  <block id="70a742210f3e3599821b3a11b682144c" category="list-text">授权 Jenkins 服务帐户访问 OpenShift 用户。</block>
  <block id="b07934b6023389a7e3e183b45e3b7448" category="list-text">此时将显示 Jenkins 欢迎页面。由于我们使用的是 Maven 内部版本，因此请先完成 Maven 安装。导航到 Manage Jenkins &gt; Global Tool Configuration ，然后在 Maven 子标题中单击 Add Maven 。输入您选择的名称，并确保已选中自动安装选项。单击保存。</block>
  <block id="8fd32305bf380bf893ef2407eae75f5d" category="list-text">现在，您可以创建一个管道来演示 CI/CD 工作流。在主页上，单击左侧菜单中的创建新作业或新建项目。</block>
  <block id="cd55d787cacfb25983e0a24b58ba6d48" category="list-text">选择管道选项卡。从试用样本管道下拉菜单中，选择 Github + Maven 。代码将自动填充。单击保存。</block>
  <block id="eaeef52618dbbd29ca52633c93abcbb4" category="list-text">选择所需的操作系统，然后单击下一步。</block>
  <block id="6befc3ce0d5cbd575434f0d5e1ec1125" category="list-text">如果选定操作系统未配置启动源，则必须对其进行配置。对于启动源，选择是要从 URL 还是从注册表导入操作系统映像，并提供相应的详细信息。展开高级并选择 Trident 支持的 StorageClass 。然后单击下一步。</block>
  <block id="3d210170d7f07fe3c907e8ac619f003a" category="doc">NetApp Astra 控制中心概述</block>
  <block id="9b0d9ae1197ded2c7d52147e5056475d" category="paragraph">NetApp Astra 控制中心为部署在内部环境中并采用 NetApp 数据保护技术的有状态 Kubernetes 工作负载提供丰富的存储和应用程序感知型数据管理服务。</block>
  <block id="f0358bd53d50b55aa0509189dd381ca9" category="paragraph">NetApp Astra 控制中心可以安装在 Red Hat OpenShift 集群上，该集群已部署 Astra Trident 存储编排程序并为其配置存储类和存储后端到 NetApp ONTAP 存储系统。</block>
  <block id="8cc4d72a7129322eb1f39ea9b9cfb2f6" category="inline-link-macro">本文档在此处提供</block>
  <block id="1c2ddd920580e1a7860afb96d7ac352e" category="paragraph">有关安装和配置 Astra Trident 以支持 Astra 控制中心的信息，请参见 <block ref="a581b27b235a239b8b186164c4dbebd1" category="inline-link-macro-rx"></block>。</block>
  <block id="876ae62d75901b9ef80277fd884aa5e9" category="paragraph">在云互联环境中， Astra 控制中心使用 Cloud Insights 提供高级监控和遥测功能。在没有 Cloud Insights 连接的情况下，可以使用有限的监控和遥测（ 7 天的指标），并通过开放式指标端点导出到 Kubernetes 原生监控工具（ Prometheus 和 Grafana ）。</block>
  <block id="54a5ba4de846d3c3ba8c0322f5139893" category="paragraph">Astra 控制中心完全集成到 NetApp AutoSupport 和 Active IQ 生态系统中，可为用户提供支持，协助进行故障排除以及显示使用情况统计信息。</block>
  <block id="34610c3089a79a0b0e58bcc24da4c16c" category="paragraph">除了已付费版本的 Astra 控制中心之外，还提供 90 天评估许可证。评估版可通过电子邮件和社区（ Slack 通道）获得支持。客户可以访问这些以及其他知识库文章以及产品支持信息板上提供的文档。</block>
  <block id="b3d5fa878980b3f5b771ced3fa94111a" category="inline-link-macro">Astra 网站</block>
  <block id="83d307afe7b187cee5d096f65402182f" category="paragraph">要开始使用 NetApp Astra 控制中心，请访问 <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>。</block>
  <block id="7f9648de128837be473a3b24e53ff823" category="section-title">安装 Astra 控制中心的前提条件</block>
  <block id="8ffc0d45ec909884b280603fd2556021" category="list-text">一个或多个 Red Hat OpenShift 集群。目前支持版本 4.6 EUS 和 4.7 。</block>
  <block id="526a5a0f546838d61791ded926113f71" category="list-text">必须已在每个 Red Hat OpenShift 集群上安装和配置 Astra Trident 。</block>
  <block id="7433dd0f15704f71764248a0ca105fad" category="admonition">最佳做法是，在站点上安装的每个 OpenShift 都要有一个专用的 SVM 来用于永久性存储。多站点部署需要额外的存储系统。</block>
  <block id="e32d2cb3312c2c7797ca52bd8d6ff26f" category="admonition">请参见链接 <block ref="0065297854ca0573913043e80b99a2d1" category="inline-link-macro-rx"></block> 有关已为此目的验证的负载平衡器的信息。</block>
  <block id="aa32c16385a1b749687956188e4f0d9a" category="admonition">请参见链接 <block ref="9d2000c3bba4885fe5f36ed192264583" category="inline-link-macro-rx"></block> 为此安装和配置 OpenShift 专用注册表。</block>
  <block id="121c2592ea226f655d357a8ecd8caf2e" category="inline-link">Astra 注册站点</block>
  <block id="ba6df9237a2774d7ca28cdf134cf9314" category="admonition">要开始获取 Astra Control 的试用许可证，请访问<block ref="dd61f8f3fbfa8ca8b0a268b985d55b0e" category="inline-link-rx"></block>。</block>
  <block id="29fc4f6574f437e623e4eb9d47136931" category="list-text">开始安装之前，请将 Astra Control Center 映像推送到映像注册表。</block>
  <block id="25b4e951c048e2ae39554f36af8824b9" category="admonition">您可以选择使用 Docker 或 Podman 执行此操作，此步骤将提供这两者的说明。</block>
  <block id="a53846d7be2355a59af69a47e2cf4637" category="list-text">创建 Shell 脚本文件并将以下内容粘贴到其中。</block>
  <block id="ad3318a786149147666e961c291c6875" category="admonition">如果您的注册表使用的是不可信的证书，请编辑 shell 脚本并对` podman 推送命令 ` `podman 推送 $registry/$ （ echo $astraImage^ s/^ ……………………………………………………………………………………………………………………………………………` …</block>
  <block id="f39d61476380fc033f45c2d744596b00" category="list-text">接下来，将映像注册表 TLS 证书上传到 OpenShift 节点。为此，请使用 TLS 证书在 OpenShift-config 命名空间中创建一个配置映射，并将其修补到集群映像配置中以使此证书可信。</block>
  <block id="508ca0ca5ae419c052d9a8487bb0b2d0" category="admonition">如果您使用的是包含传入操作员的默认 TLS 证书的 OpenShift 内部注册表和路由，则仍需要按照上一步将这些证书修补到路由主机名。要从 `运算符提取证书，您可以使用命令` oc extract secret/router -ca -keys=tls.crt -n OpenShift-Inuse-operator 。</block>
  <block id="6d71c41a686bcfc0b0866044afd43f2b" category="list-text">创建用于访问该命名空间中的映像注册表的密钥。</block>
  <block id="25eb68598d15a49d385089020950412c" category="list-text">编辑 Astra 控制中心 CRD 文件 `Astra_control_center_min.yaml` 并输入 FQDN ，映像注册表详细信息，管理员电子邮件地址和其他详细信息。</block>
  <block id="42b9bde28896d6478a324770641ac301" category="admonition">先前的文件 `Astra_control_center_min.yaml` 是 Astra 控制中心 CRD 的最低版本。如果要创建具有更多控制权的 CRD ，例如定义非默认创建 PVC 的 storageclass 或为邮件通知提供 SMTP 详细信息，则可以编辑文件 `Astra_control_center.YAML` ，输入所需详细信息，然后使用它创建 CRD 。</block>
  <block id="e3cd33ca69b8e508c973939783f528db" category="list-text">完成安装可能需要几分钟时间。验证 `NetApp-Astra-cc` 命名空间中的所有 Pod 和服务是否均已启动且正在运行。</block>
  <block id="c27deb19babf146e6377dce25b1e70e7" category="list-text">用于登录到 Astra 控制中心的用户名是 CRD 文件中提供的管理员电子邮件地址，密码是附加到 Astra 控制中心 UUID 的字符串 `Acc-` 。运行以下命令：</block>
  <block id="57a7aa2eaf00ddaa73ef6b49299ade6e" category="admonition">在此示例中，密码为 `Acc-345c55a5-bf2e-21f0-84b8-b6f2bce5e95f` 。</block>
  <block id="19bae630567610f1955167595b8daae3" category="list-text">首次使用 CRD 中提供的管理员电子邮件地址登录到 Astra 控制中心图形用户界面时，您需要更改密码。</block>
  <block id="0c62383e1115b208212b5a634214ae37" category="list-text">如果要将用户添加到 Astra 控制中心，请导航到 Account &gt; Users ，单击 Add ，输入用户的详细信息，然后单击 Add 。</block>
  <block id="60423d24e49c8db4836be0abd09fb78d" category="doc">NetApp ONTAP iSCSI 配置</block>
  <block id="cbaa3aa588b8aa5c85dca443c15a0195" category="doc">NetApp ONTAP NFS 配置</block>
  <block id="f897eefba2c59919d6493db4825e2db2" category="admonition">最佳做法是，将自定义 backendName 值定义为 storageDriverName 和为 NFS 提供服务的 dataLIF 的组合，以便于识别。</block>
  <block id="a802e9436bb9bcbfa2b88bb549e28503" category="paragraph">在大多数情况下， Red Hat OpenShift 会通过路由向外部世界提供应用程序。通过为服务提供一个可从外部访问的主机名来公开该服务。OpenShift 路由器可以使用定义的路由及其服务标识的端点，以便为外部客户端提供此命名连接。</block>
  <block id="445b72f2cbecd97022bb6636eda3cbc7" category="cell">为不同的应用程序或工作负载创建项目</block>
  <block id="bfc5fb8ef5464441bc8b3ca7eda2892d" category="cell">验证对已分配项目中的 PVC 或 Pod 的创建或修补访问权限</block>
  <block id="9e95c94350b2b7b51176ad958deb1388" category="cell">验证对在其他项目中创建或修补 PVC 或 Pod 的访问权限</block>
  <block id="8c0b7954d326b4bcf2f42a57ef00eead" category="cell">验证对查看或编辑项目， ResourceQuotas 和 StorageClasses 的访问权限</block>
  <block id="bbb49986c10d9b599ce8b72ea09d5261" category="list-text">导航到 Operators &gt; OperatorHub 并搜索 OpenShift 虚拟化。</block>
  <block id="2515fbef39d57544723402c683215c64" category="doc">NetApp 存储集成概述</block>
  <block id="689ca76b61ed9331405d36eb5ded709d" category="paragraph">NetApp 提供了许多产品，可帮助您在基于容器的环境中编排和管理永久性数据，例如 Red Hat OpenShift 。</block>
  <block id="bc2397695676d1a63e489d4c80c8cd91" category="paragraph">通过适用于 Kubernetes 的高级集群管理功能，用户可以从控制台同时在一个或多个受管集群上创建资源。例如，如果您的 OpenShift 集群位于不同站点，并由不同的 NetApp ONTAP 集群提供支持，并且希望在两个站点上配置 PVC ，则可以单击顶部栏上的（ + ）符号。然后，选择要创建 PVC 的集群，粘贴资源 YAML ，然后单击创建。</block>
  <block id="2fb91f8695d5dc9db4bf5a7ef710ec73" category="list-text">Astra 控制中心会检测符合条件的存储类。现在，选择使用 NetApp ONTAP 上由 SVM 支持的 Trident 配置卷的 storageclass 方式，然后单击查看。在下一个窗格中，验证详细信息，然后单击 Add Cluster 。</block>
  <block id="3edb3c83eb1bede6778cc1960a651973" category="list-text">按照步骤 1 中所述注册两个 OpenShift 集群。添加后，集群将变为 " 正在发现 " 状态，而 Astra 控制中心将对其进行检查并安装必要的代理。成功注册后，集群状态将更改为 " 正在运行 " 。</block>
  <block id="ed5c1a60b8165b8bc691cbdf1b0d122c" category="admonition">在受管集群上安装的代理从该注册表中提取映像时，由 Astra 控制中心管理的所有 Red Hat OpenShift 集群都应有权访问用于安装的映像注册表。</block>
  <block id="feab1371530d1ef069d928e811bcb08b" category="list-text">要导入 ONTAP 集群，请转到后端，单击下拉列表，然后选择要管理的 ONTAP 集群旁边的管理。输入 ONTAP 集群凭据，单击查看信息，然后单击导入存储后端。</block>
  <block id="a62e902f0d244d960eddf2f14d3afa6f" category="paragraph">基于裸机的 OpenShift 可在商用服务器上自动部署 OpenShift 容器平台。</block>
  <block id="0e05c6235b67ae8e5b743c9ca77358fa" category="paragraph">基于裸机的 OpenShift 类似于 OpenShift 的虚拟部署，它可以轻松部署，快速配置和扩展 OpenShift 集群，同时还可以为尚未准备好进行容器化的应用程序提供虚拟化工作负载支持。通过在裸机上部署，除了 OpenShift 环境之外，您无需额外的开销即可管理主机虚拟机管理程序环境。通过直接在裸机服务器上部署，您还可以减少主机和 OpenShift 环境之间共享资源的物理开销限制。</block>
  <block id="6bc136fcf409560a1029f6f323619bbf" category="paragraph">NetApp 解决方案上的 Red Hat OpenShift 使用两个数据交换机提供 25 Gbps 的主数据连接。它还使用两个管理交换机，这些交换机以 1 Gbps 的速度提供连接，用于存储节点的带内管理以及 IPMI 功能的带外管理。</block>
  <block id="17fea9675576fc9c72deb9501a5fd16a" category="paragraph">对于 OpenShift 裸机 IPI 部署，您必须创建一个配置程序节点，即必须将网络接口连接到不同网络的 Red Hat Enterprise Linux 8 计算机。</block>
  <block id="7633522f66aaba6bc4bb2c25d299d287" category="paragraph">在设置配置程序节点时，客户会创建网桥接口，以便在节点本身以及为部署目的配置的 Bootstrap 虚拟机上正确路由流量。部署集群后， API 和传入 VIP 地址将从启动节点迁移到新部署的集群。</block>
  <block id="963d7d04e1f1692a7fc49ae899123dbd" category="paragraph">以下图像显示了 IPI 部署期间和部署完成后的环境。</block>
  <block id="f53272342c85041784b2d5136e6eaa7d" category="cell">裸机网络</block>
  <block id="11405696f0e53417a3847f430a7b8ed0" category="cell">配置网络</block>
  <block id="eb5f501445f81cb1f7f4cf290565f9c8" category="admonition">尽管这些网络中的每个网络实际上都由 VLAN 分隔，但必须在访问模式下设置每个物理端口并分配主 VLAN ，因为在 PXE 启动序列期间无法传递 VLAN 标记。</block>
  <block id="3ab0ae61b5256f874297403903fd5afc" category="paragraph">在部署 OpenShift 容器平台之前，应具备以下基础架构：</block>
  <block id="06a9d12a76441fd395abeba7bf0d7b91" category="list-text">至少一个 DNS 服务器，该服务器可提供可从带内管理网络和 VM 网络访问的完整主机名解析。</block>
  <block id="932e95da8a59703292a426466e703c7a" category="paragraph">Red Hat 虚拟化（ RHV ）是一个企业级虚拟数据中心平台，运行在 Red Hat Enterprise Linux （ RHEL ）上，并使用 KVM 虚拟机管理程序。</block>
  <block id="cd4c83df745cf56330120fb3ac308da2" category="paragraph">NetApp 解决方案上的 Red Hat OpenShift 使用两个数据交换机提供 25 Gbps 的主数据连接。它还使用两个额外的管理交换机，这些交换机以 1 Gbps 的速度提供连接，用于存储节点的带内管理以及 IPMI 功能的带外管理。OCP 使用 RHV 上的虚拟机逻辑网络进行集群管理。本节介绍解决方案中使用的每个虚拟网段的布局和用途，并概述部署解决方案的前提条件。</block>
  <block id="c347686b0750301dfca053b321126bcc" category="cell">对 RHP-H 节点， RHP-Manager 和 ovirtmgmt 网络进行管理</block>
  <block id="4a3fe6077a529bcbe033bbb7d13027d6" category="paragraph">由于 Red Hat OpenShift 最初使用三个主节点进行部署，因此在双节点配置中，可以确保至少有两个主节点将占用同一节点，如果特定节点不可用，可能会导致 OpenShift 中断。因此， Red Hat 的最佳实践是，在解决方案中至少部署三个 RHV-H 虚拟机管理程序节点，以便 OpenShift 主节点可以均匀分布，并且解决方案可以获得更多的容错能力。</block>
  <block id="02d7502b2b132a675665088322fde9b0" category="paragraph">为参数定义的条件可以是强制实施，也可以是软强制实施。强制实施可确保关联组中的 VM 始终严格遵循正负关联性，而不考虑外部条件。软强制实施可确保在可行的情况下为关联组中的 VM 设置更高的首选项，以遵循正或负关联性。在本文档所述的两个或三个虚拟机管理程序配置中，建议使用软关联性设置。在大型集群中，硬关联可以正确分布 OpenShift 节点。</block>
  <block id="2b083bcbbb2d2208e64c13cb183af44f" category="paragraph">IPI 可通过本文档前面讨论的交互式向导轻松部署 OpenShift 集群。但是，在集群部署过程中，可能需要更改某些默认值。</block>
  <block id="1d45b25ba986072287aaf72b6cf94130" category="paragraph">虽然默认情况下，由 NetApp ONTAP 提供支持的 Red Hat OpenShift 和 Astra Trident 不会在工作负载之间提供隔离，但它们提供了广泛的功能，可用于配置多租户。为了更好地了解如何在采用 NetApp ONTAP 支持的 Astra Trident 的 Red Hat OpenShift 集群上设计多租户解决方案，让我们考虑一个包含一系列要求的示例，并概述其配置。</block>
  <block id="385df0e95c28430fb792ec836529f371" category="paragraph">假设一个组织在一个 Red Hat OpenShift 集群上运行两个工作负载，作为两个不同团队正在处理的两个项目的一部分。这些工作负载的数据驻留在由 NetApp ONTAP NAS 后端的 Astra Trident 动态配置的 PVC 上。该组织需要为这两个工作负载设计多租户解决方案，并隔离用于这些项目的资源，以确保保持安全性和性能，主要侧重于为这些应用程序提供服务的数据。</block>
  <block id="9c965c0beb472bc9265925ebbc55507e" category="paragraph">下图展示了由 NetApp ONTAP 提供支持的带有 Astra Trident 的 Red Hat OpenShift 集群上的多租户解决方案。</block>
  <block id="72710b926f57dad99b29203c63f4e3fd" category="paragraph">从 Red Hat OpenShift 集群的角度来看，要开始使用的顶级资源是项目。OpenShift 项目可以视为将整个 OpenShift 集群划分为多个虚拟集群的集群资源。因此，项目级别的隔离为配置多租户提供了基础。</block>
  <block id="20e1834bb9396599a6dcf7d743aa1b36" category="paragraph">下一步是在集群中配置 RBAC 。最佳做法是，将处理单个项目或工作负载的所有开发人员配置到身份提供程序（ IdP ）中的单个用户组中。Red Hat OpenShift 允许 IdP 集成和用户组同步，从而允许将 IdP 中的用户和组导入到集群中。这样可以帮助集群管理员将项目专用集群资源的访问权限隔离给一个或多个处理该项目的用户组，从而限制对任何集群资源的未授权访问。要了解有关 IdP 与 Red Hat OpenShift 集成的详细信息，请参见相关文档<block ref="213cff8958909b80a9514e0c8321d8ef" category="inline-link-rx"></block>。</block>
  <block id="6d4e96186b1f4267def393ec42bf2d9e" category="paragraph">必须隔离用作 Red Hat OpenShift 集群永久性存储提供程序的共享存储，以确保在存储上为每个项目创建的卷在主机上显示为它们，就像在单独的存储上创建一样。为此，请在 NetApp ONTAP 上创建与项目或工作负载数量相同的 SVM （ Storage Virtual Machine ），并将每个 SVM 专用于一个工作负载。</block>
  <block id="76245f392269db8492c3610e325b1963" category="paragraph">由于存储类不是命名空间资源，我们如何确保拒绝另一命名空间或项目中的 Pod 向一个项目的存储类声明？问题解答将使用 ResourceQuotas 。ResourceQuotas 是控制每个项目资源总使用量的对象。它可以限制项目中的对象可以使用的资源数量以及总资源量。使用 ResourceQuotas 几乎可以限制项目中的所有资源，而高效地使用此功能可以帮助组织降低因过度配置或过度消耗资源而导致的成本和中断。请参见文档<block ref="9b2bb9683c8f6144876bed616f252527" category="inline-link-rx"></block> 有关详细信息 ...</block>
  <block id="5402bb91006fe391aea122e11c3607db" category="paragraph">对于这种使用情形，我们需要限制特定项目中的 Pod 从非专用于其项目的存储类中申请存储。为此，我们需要通过将 ` &lt;storage-class-name&gt;.storageclass.storage.k8s.io/persistentvolumeclaims` 设置为 0 来限制其他存储类的永久性卷请求。此外，集群管理员必须确保项目中的开发人员不应有权修改 ResourceQuotas 。</block>
  <block id="b1a934cbded2602c4186fb43d7c8a986" category="paragraph">根据具体使用情形，容器和虚拟机（ VM ）均可用作不同类型应用程序的最佳平台。因此，许多组织在容器上运行部分工作负载，而在 VM 上运行部分工作负载。通常，这会导致企业面临额外的挑战，需要管理不同的平台：虚拟机管理程序和应用程序容器编排程序。</block>
  <block id="14bd8c5f1032dd20f94d4434365c6530" category="admonition">本节中提供的角色定义只是一个示例。必须根据最终用户要求定义开发人员角色。</block>
  <block id="cf17c458ea3abaad557d7cfc69886dbe" category="list-text">在集群中的所有项目中创建一个用于管理 ResourceQuotas 的角色，以将其连接到存储管理员：</block>
  <block id="db99ab183aa8f56c951cf20e25e7465c" category="list-text">确保集群与组织的身份提供程序集成，并且用户组与集群组同步。以下示例显示身份提供程序已与集群集成并与用户组同步。</block>
  <block id="38f22acd9ae9c74099644738d613baaa" category="admonition">对于存储管理员，必须绑定两个角色： Trident 操作员和资源配额。</block>
  <block id="3434f6853d017037506e47f83a18c3eb" category="section-title">创建私有映像注册表</block>
  <block id="9b1c6f527a1a481b925397807f319e71" category="list-text">在 `sPec` 部分中输入以下存储参数，以编辑 imageeregistry 运算符。</block>
  <block id="9ef71cd5ccaeb28206cd64b1d184019c" category="list-text">在 `sPec` 部分中输入以下参数，以便使用自定义主机名创建 OpenShift 路由。保存并退出。</block>
  <block id="e0b23bc469102cf89472e5734da92a23" category="admonition">如果要为路由设置自定义主机名，则会使用上述路由配置。如果您希望 OpenShift 使用默认主机名创建路由，可以将以下参数添加到 `sPec` 部分： `defaultRoute ： true` 。</block>
  <block id="625bd6ae5e3ac822b187b90d50edb553" category="sidebar-title">自定义 TLS 证书</block>
  <block id="08e414328e39f86009287c06a5f23d23" category="paragraph">默认情况下，当您为路由使用自定义主机名时，它会使用 OpenShift 入口操作员的默认 TLS 配置。但是，您可以向路由添加自定义 TLS 配置。为此，请完成以下步骤：</block>
  <block id="60d14675c3111738a4ed19528764a7b1" category="list-text">使用路由的 TLS 证书和密钥创建密钥。</block>
  <block id="47f7f890b5c1bcb52ae163771dbf35b0" category="list-text">编辑 imageeregistry 运算符，并将以下参数添加到 `sPec` 部分。</block>
  <block id="9199ff34349c38138ad0275e447e6588" category="list-text">再次编辑 imageeregistry 运算符，并将该运算符的管理状态更改为 `Maned` state 。保存并退出。</block>
  <block id="2bc42a1a9a963d9a3ff2118466e5db07" category="list-text">如果满足所有前提条件，则会为专用映像注册表创建 PVC ， Pod 和服务。几分钟后，注册表就会启动。</block>
  <block id="1f3713e339193dd15865ca74785eaa2c" category="list-text">如果您对传入操作员 OpenShift 注册表路由使用默认 TLS 证书，则可以使用以下命令提取 TLS 证书。</block>
  <block id="295132dd97e1047a7c09e6a48054c469" category="list-text">要允许 OpenShift 节点访问并从注册表中提取映像，请将证书添加到 OpenShift 节点上的 Docker 客户端。使用 TLS 证书在 `OpenShift-config` 命名空间中创建一个配置映射，并将其修补到集群映像配置中以使此证书可信。</block>
  <block id="98f3e484001465a59149c551e8d88cf0" category="list-text">OpenShift 内部注册表由身份验证控制。所有 OpenShift 用户都可以访问 OpenShift 注册表，但登录用户可以执行的操作取决于用户权限。</block>
  <block id="561d4c8140016564eee98ecbc20f9add" category="list-text">要允许用户或用户组从注册表中提取映像，必须为用户分配注册表查看器角色。</block>
  <block id="88167e36ea0f872788407d0e01fc1382" category="list-text">要允许用户或用户组写入或推送映像，必须为用户分配注册表编辑器角色。</block>
  <block id="5ba9e8f3c64be4c82249856cac87a071" category="list-text">要使 OpenShift 节点能够访问注册表并推送或拉取映像，您需要配置拉取密钥。</block>
  <block id="fe2033a9e377624583baa802ffd9ce6d" category="list-text">要将其修补到服务帐户，请运行以下命令。</block>
  <block id="59bd1dbdd3278e23e67bcabffbc4d55a" category="list-text">要在 Pod 定义中引用 Pull secret ，请将以下参数添加到 `sPec` 部分。</block>
  <block id="c0c3b4069e9a2e249507f67a6a2a3b07" category="list-text">要从 OpenShift 节点以外的工作站推送或拉取映像，请完成以下步骤。</block>
  <block id="312eaa3acf94b813cfe857f63a602724" category="list-text">使用 oc login 命令登录到 OpenShift 。</block>
  <block id="cb4744e00672fbf6eba33b1b86d23ae0" category="list-text">使用 podman/Docker 命令使用 OpenShift 用户凭据登录到注册表。</block>
  <block id="aa20d170f1ff336ec9079cf6dd1ccee3" category="list-text">推送或拉图像。</block>
  <block id="85ca996063b5ec233e56a20ba93c5f44" category="list-text">导航到存储 &gt; Storage VM ，然后单击添加。通过提供所需的详细信息，创建两个 SVM ，一个用于 project-1 ，另一个用于 project-2 。此外，还可以创建 vsadmin 帐户来管理 SVM 及其资源。</block>
  <block id="b436e7799d01413277e05983e509574a" category="list-text">以存储管理员身份登录到 Red Hat OpenShift 集群。</block>
  <block id="f934b433773b966e5ebe0c7172decda4" category="admonition">在此示例中，我们使用的是 ontap-NAS 驱动程序。根据使用情形创建后端时，请使用相应的驱动程序。</block>
  <block id="4e92dab2ab2bbe684f09a2aca58c9e44" category="list-text">NetApp ONTAP 集群。</block>
  <block id="f675b3d5e1e137870f481a742a3ec0af" category="list-text">集群上安装的 Trident 。</block>
  <block id="1db1a9d97c708824712706fc4267ec25" category="list-text">安装了 tridentctl 和 oc 工具并将其添加到 $path 中的管理工作站。</block>
  <block id="7cf4175762acfbabf9178d34f2504b28" category="list-text">对 ONTAP 的管理员访问权限。</block>
  <block id="10a540d0ed57154e8676c5725af53935" category="list-text">对 OpenShift 集群的集群管理员访问。</block>
  <block id="6340f6ab1111f349228595ebceb8f6db" category="list-text">集群已与身份提供程序集成。</block>
  <block id="9e110c19bb79322a0b76199795550dea" category="list-text">身份提供程序经过配置，可以有效区分不同团队中的用户。</block>
  <block id="39d08ecbb9add7bd87659df206457a73" category="list-text">用于集线器集群的 Red Hat OpenShift 集群（版本 4.5 以上）</block>
  <block id="d60c66eb778a488709534045787b6a26" category="list-text">对 Red Hat OpenShift 集群的集群管理员访问</block>
  <block id="3fc5f6755312b7edeef9542bd55ef639" category="section-title">监管和风险</block>
  <block id="87f4e127e0ecf99187b35830ca7e78aa" category="list-text">从边栏导航到监管和风险。</block>
  <block id="0ecc505d3375f8bb3bd959aaaf7e710a" category="list-text">要创建合规性策略，请单击创建策略，输入策略标准的详细信息，然后选择应遵循此策略的集群。如果要自动修复此策略的违规，请选中 " 如果支持，则强制 " 复选框，然后单击 " 创建 " 。</block>
  <block id="ea1abad541ee7994705555d53c0281c3" category="list-text">导航到工作负载 &gt; 虚拟化 &gt; 虚拟机，然后单击要克隆的虚拟机旁边的省略号。</block>
  <block id="81ab8abf2317781c0eb6f4deeaeea5a5" category="list-text">导航到 "Storage"&gt;"PersistentVolumeClass" ，然后单击附加到源 VM 的 PVC 旁边的省略号。</block>
  <block id="5ba8ff3c009683ee423b0884c25360d0" category="list-text">导航到工作负载 &gt; 虚拟化 &gt; 虚拟机，然后单击创建 &gt; 使用 YAML 。</block>
  <block id="cd32f6b0aebb29494cbc9cc21a10c926" category="list-text">在规范 &gt; 模板 &gt; 规范 &gt; 卷部分中，附加克隆的 PVC ，而不是容器磁盘。根据您的要求提供新虚拟机的所有其他详细信息。</block>
  <block id="f79c612e785ac74789a25e8dda9e8731" category="doc">Astra Trident 概述</block>
  <block id="bd4a2d19c5168aa8c2b89b4affba2402" category="cell">9.8 ， 9.9.1</block>
  <block id="4af39dbe40f8a0467bbdd739a971f0ea" category="admonition">以下消息指示 Astra 控制中心已成功安装。</block>
  <block id="5946314197ad84982efa6561d9da8302" category="list-text">获取 traefik 服务负载平衡器 IP 。</block>
  <block id="298a1e8781e536e60684ab1700c60962" category="list-text">在 DNS 服务器中添加一个条目，将 Astra 控制中心 CRD 文件中提供的 FQDN 指向 traefik 服务的 `external-IP` 。</block>
  <block id="0c64767e085896708adcbcc1c32c55fe" category="inline-image-macro">为 Accc 图形用户界面添加 DNS 条目</block>
  <block id="1c278e58c0255ae1f09fc4fa520160b6" category="paragraph"><block ref="1c278e58c0255ae1f09fc4fa520160b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a37ba7c36c036650f5e1e7ded5232245" category="list-text">要使 Astra 控制中心的所有功能正常运行，需要获得许可证。要添加许可证，请导航到 " 帐户 "&gt;" 许可证 " ，单击 " 添加许可证 " ，然后上传许可证文件。</block>
  <block id="a003986254b5a6c136733113505348da" category="doc">安装 F5 BIG-IP 负载平衡器</block>
  <block id="048600e045fd4c5afe58ec9d65aa4b19" category="paragraph">F5 BIG-IP 是一款应用程序交付控制器（ Application Delivery Controller ， AD ），可提供一系列高级生产级流量管理和安全服务，例如 L4-L7 负载平衡， SSL/TLS 卸载， DNS ，防火墙等。这些服务可显著提高应用程序的可用性，安全性和性能。</block>
  <block id="5c47e8322efb7f77c0aa515fec29477e" category="paragraph">F5 BIG-IP 可以在专用硬件上，云中或内部虚拟设备上以各种方式进行部署和使用。请参见此处的文档，了解如何根据需要部署 F5 BIG-IP 。</block>
  <block id="16a275a8b38f9c5211732c331edb7135" category="paragraph">为了将 F5 BIG-IP 服务与 Red Hat OpenShift 高效集成， F5 提供了 BIG-IP 容器传入服务（ BIG-IP Container Ingress Service ， CIS ）。CI 作为控制器 POD 进行安装，用于监控 OpenShift API 以获取某些自定义资源定义（ Custom Resource Definitions ， CRD ），并管理 F5 BIG-IP 系统配置。可以配置 F5 BIG-IP CIS ，以控制 OpenShift 中的服务类型 LoadBalbalers" 和 " 路由 " 。</block>
  <block id="e3ce824a7aff01576faaac58df9e0b18" category="paragraph">此外，要自动分配 IP 地址以服务类型负载平衡器，您可以使用 F5 IPAM 控制器。F5 IPAM 控制器作为控制器 POD 进行安装，该控制器 POD 会通过 ipamLabel 标注监视 OpenShift API 以获取负载平衡器服务，以便从预配置的池分配 IP 地址。</block>
  <block id="3b08b142099d42d5280d7b493288bf63" category="paragraph">此页面列出了 F5 BIG-IP CIS 和 IPAM 控制器的安装和配置说明。作为前提条件，您必须已部署并获得 F5 BIG-IP 系统的许可。此外，它还必须获得 SDN 服务的许可，这些服务默认包含在 BIG-IP VE 基础许可证中。</block>
  <block id="5fb7b483d0c9fa099945579d826691b8" category="admonition">F5 BIG-IP 可以在独立模式或集群模式下部署。出于此验证的目的， F5 BIG-IP 部署在独立模式下，但出于生产目的，最好使用由大型 IP 组成的集群来避免单点故障。</block>
  <block id="0d3e8be481c0c23fd0a68da9a9340ef7" category="admonition">F5 BIG-IP 系统可以部署在专用硬件上，云中或内部部署的虚拟设备中，其版本高于 12.x ，以便与 F5 CIS 集成。在本文档中，我们已将 F5 BIG-IP 系统验证为虚拟设备，例如使用 BIG-IP VE 版本。</block>
  <block id="39bc153685f2a0c6d56db4227295a3b0" category="section-title">经过验证的版本</block>
  <block id="00d0a06cc7c922b3bc62b22524723ff8" category="cell">F5 BIG-IP VE 版本</block>
  <block id="5bd03f916d1e7b0410d0d3b2d12c6366" category="cell">16.1.0</block>
  <block id="c6f7874f49f685ffdf1b5a8aad8875c4" category="cell">F5 容器传入服务</block>
  <block id="21f47a5b35d016c2f0f8f57704079407" category="cell">2.5.1</block>
  <block id="9635118f932e26e24f0ca315d3843379" category="cell">F5 IPAM 控制器</block>
  <block id="5256eb2d6e3cf80e003a290e63843800" category="cell">0.1.4</block>
  <block id="088afeececf092d5a406e0f5022a9638" category="cell">F5 AS3</block>
  <block id="425b0ca2d1d9d5c75555116fcd1614bf" category="cell">3.30.0</block>
  <block id="7cd8fb6e31cc946c078d2740c76a9899" category="section-title">安装</block>
  <block id="b9a4064fa117596b59fb18df84df74df" category="inline-link">F5 AS3 GitHub 存储库</block>
  <block id="6463cf716c052865ec9f4716ff0b5d3f" category="list-text">安装 F5 Application Services 3 扩展，以允许 BIG-IP 系统接受 JSON 中的配置，而不是强制命令。转至<block ref="0d4e47593b830323684cdec40cb60c71" category="inline-link-rx"></block>，并下载最新的 RPM 文件。</block>
  <block id="4c0802ebd79a8c6e5ea4aed829f023c9" category="list-text">登录到 F5 BIG-IP 系统，导航到 "iApps" &gt; "Package Management LX" ，然后单击 "Import" 。</block>
  <block id="3536ed517a711f49cfe64071db031cf5" category="list-text">单击选择文件并选择已下载的 AS3 RPM 文件，单击确定，然后单击上传。</block>
  <block id="2a90f793207a5a0c028d8ccc45e943fd" category="inline-image-macro">上传 iApps</block>
  <block id="7a3eaac0605c201c339e116a475c0bf6" category="paragraph"><block ref="7a3eaac0605c201c339e116a475c0bf6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="caedd771b59d267eda8f88d329e8784f" category="list-text">确认 AS3 扩展已成功安装。</block>
  <block id="c434efeb83b6dc500ea7893f1ad4236b" category="inline-image-macro">AS3 安装验证</block>
  <block id="eb52ccb2be126d28d17e4383ae6ea6cf" category="paragraph"><block ref="eb52ccb2be126d28d17e4383ae6ea6cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97e9e05bfde432cfa7291b1e55a52ba7" category="list-text">接下来，配置 OpenShift 和 BIG-IP 系统之间通信所需的资源。首先，通过在 OpenShift SDN 的 BIG-IP 系统上创建 VXLAN 通道接口，在 OpenShift 和 BIG-IP 服务器之间创建通道。导航到 " 网络 "&gt;" 通道 "&gt;" 配置文件 " ，单击 " 创建 " ，然后将父配置文件设置为 VXLAN ，并将 " 洪水类型 " 设置为 " 多播 " 。输入配置文件的名称，然后单击完成。</block>
  <block id="faaca798da0468a250bf3c3bffc26681" category="inline-image-macro">创建 VXLAN 配置文件</block>
  <block id="bddf6bed69a1a2234f15cefc27853c50" category="paragraph"><block ref="bddf6bed69a1a2234f15cefc27853c50" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45ae0c96657fdc5a20e83839c2386c1e" category="list-text">导航到 " 网络 "&gt;" 通道 "&gt;" 通道列表 " ，单击 " 创建 " ，然后输入通道的名称和本地 IP 地址。选择在上一步中创建的通道配置文件，然后单击完成。</block>
  <block id="1497a4f92d416d6c80392ec3467ff140" category="inline-image-macro">创建 VXLAN 通道</block>
  <block id="53ce9cdf8cf7f6cb09991e817df94959" category="paragraph"><block ref="53ce9cdf8cf7f6cb09991e817df94959" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc5e5bc480b39177b8cb8c9c3a2266ae" category="list-text">使用 cluster-admin 权限登录到 Red Hat OpenShift 集群。</block>
  <block id="986e63a308b4bebd3f531e38fa5a06c7" category="list-text">在 OpenShift 上为 F5 BIG-IP 服务器创建一个子网，从而将子网从 OpenShift 集群扩展到 F5 BIG-IP 服务器。下载主机子网 YAML 定义。</block>
  <block id="fd4475e12938f5f51ba3f312b42cdd39" category="list-text">编辑主机子网文件并为 OpenShift SDN 添加 BIG-IP VTEP （ VXLAN 通道） IP 。</block>
  <block id="2e6d8a8db3c4d4a2227ffa0571be2a86" category="admonition">根据您的环境情况更改主机提示和其他详细信息。</block>
  <block id="7f9916ee1bc520d892dfbbb1e06e2732" category="list-text">创建 HostSubnet 资源。</block>
  <block id="7a46b2d02d466dda0cc67b215cb80bff" category="list-text">获取为 F5 BIG-IP 服务器创建的主机子网的集群 IP 子网范围。</block>
  <block id="4f6c1fea3654c07f1606c0c76509d0b0" category="list-text">在 OpenShift VXLAN 上使用与 F5 BIG-IP 服务器对应的 OpenShift 主机子网范围中的 IP 创建自 IP 。登录到 F5 BIG-IP 系统，导航到 " 网络 "&gt;" 自 IP " ，然后单击 " 创建 " 。输入为 F5 BIG-IP 主机子网创建的集群 IP 子网中的 IP ，选择 VXLAN 通道，然后输入其他详细信息。然后单击完成。</block>
  <block id="5c241806c0dd5ebb7030904151cb78ef" category="inline-image-macro">为 VXLAN 创建自 IP</block>
  <block id="ffad9e123d8b7013e7d4553570644879" category="paragraph"><block ref="ffad9e123d8b7013e7d4553570644879" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d094b7d82871afb601d2f30d416ba8d" category="list-text">在 F5 BIG-IP 系统中创建一个分区，以便在 CIS 中配置和使用。导航到系统 &gt; 用户 &gt; 分区列表，单击创建，然后输入详细信息。然后单击完成。</block>
  <block id="4d81871723233ec21ed69ab80e638779" category="inline-image-macro">创建 BIG-IP 分区</block>
  <block id="b83428617c6ed29213f89e68f142bd18" category="paragraph"><block ref="b83428617c6ed29213f89e68f142bd18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37397397fa66431e2fa681b97126c399" category="admonition">F5 建议不要对由 CIS 管理的分区进行手动配置。</block>
  <block id="81e4a49e9dbe0b55256fe5abf1b94fa4" category="list-text">使用 OperatorHub 中的运算符安装 F5 BIG-IP CIS 。使用集群管理员权限登录到 Red Hat OpenShift 集群，并使用 F5 BIG-IP 系统登录凭据创建一个密钥，这是操作员的前提条件。</block>
  <block id="5de4ac005898cabf55523098c40c549b" category="list-text">安装 F5 CIS CRD 。</block>
  <block id="0eddace1b16ed738fe1be181481c71b6" category="list-text">导航到 Operators &gt; OperatorHub ，搜索关键字 F5 ，然后单击 F5 Container In出口 服务磁贴。</block>
  <block id="07543409cb05595e273df71050b9a9c0" category="inline-image-macro">OperatorHub 中的 F5 CIS</block>
  <block id="334a7bbf4711d93b48b93c2b81d84a71" category="paragraph"><block ref="334a7bbf4711d93b48b93c2b81d84a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c25b2a3d320d6d02584fde4190d05d91" category="list-text">阅读操作员信息，然后单击安装。</block>
  <block id="60d3353ed1910ad5c7bd352d0c1bea85" category="inline-image-macro">OperatorHub 中的 F5 CIS Info 图块</block>
  <block id="1aa79507d413f19135716c8006afa423" category="paragraph"><block ref="1aa79507d413f19135716c8006afa423" category="inline-image-macro-rx" type="image"></block></block>
  <block id="637a1bc658defc200d903b27828aa8fb" category="list-text">在 Install Operator 屏幕上，保留所有默认参数，然后单击 Install 。</block>
  <block id="ccf254d7c8b666c9c127ec12fe14804b" category="inline-image-macro">安装 F5 CIS 运算符</block>
  <block id="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="paragraph"><block ref="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="636d8318702bc67a1613ceadf7ce9d00" category="list-text">安装操作员需要一段时间。</block>
  <block id="dffa3077bcff43536afd75bd61b11c0c" category="inline-image-macro">F5 CIS 操作员安装进度</block>
  <block id="b1be0ed9469d2ced1f6283b49735f5c1" category="paragraph"><block ref="b1be0ed9469d2ced1f6283b49735f5c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="197a0a4cc4a45ec9a62fe2b7335d8dfc" category="list-text">安装操作员后，将显示安装成功消息。</block>
  <block id="5bf83e99bfa132430d0b690181334933" category="list-text">导航到 Operators &gt; Installed Operators ，单击 F5 Container In出口 服务，然后单击 F5BigIpCtrl+Alt+Del 图块下的 Create Instance 。</block>
  <block id="a5f584f06c59c2cf4a4a4e8b42d495a2" category="inline-image-macro">创建 F5BigIpCtlr</block>
  <block id="a2574a02e64888de32a5a277ed05f668" category="paragraph"><block ref="a2574a02e64888de32a5a277ed05f668" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5ce9a4ef68c16a3ab5d0dd555305872" category="list-text">单击 YAML View ，并在更新必要参数后粘贴以下内容。</block>
  <block id="2e2beb899f89156ed06287fe6f78e6cf" category="admonition">在复制内容之前，更新以下参数 `bigip_partition` ， ` OpenShift_SDN_name` ， `bigip_url` 和 `bigip_login_secret` ，以反映您的设置值。</block>
  <block id="50a17348dc3f981a95001edcc80a428f" category="list-text">粘贴此内容后，单击创建。此操作将在 Kube-system 命名空间中安装 CIS Pod 。</block>
  <block id="72003ce6faa67d172e943ddd74fab63b" category="inline-image-macro">验证 F5 CIS Pod</block>
  <block id="ef76b6b9f85ff0ec00e48f565e13eff9" category="paragraph"><block ref="ef76b6b9f85ff0ec00e48f565e13eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc8632c05e82ccafb395157ccae4f5c3" category="admonition">默认情况下， Red Hat OpenShift 提供了一种通过路由公开服务以实现 L7 负载平衡的方法。内置的 OpenShift 路由器负责公布和处理这些路由的流量。但是，您也可以将 F5 CIS 配置为支持通过外部 F5 BIG-IP 系统的路由，该系统可以作为辅助路由器运行，也可以替代自托管 OpenShift 路由器运行。CIS 在 BIG-IP 系统中创建一个虚拟服务器，充当 OpenShift 路由的路由器， BIG-IP 负责处理公告和流量路由。有关启用此功能的参数的信息，请参见此处的文档。请注意，这些参数是在 APPS/v1 API 中为 OpenShift 部署资源定义的。因此，在将这些参数与 F5BigIpartl 资源 cis.f5.com/v1 API 结合使用时，请将参数名称的连字符（ - ）替换为下划线（ _ ）。</block>
  <block id="a6e55fc1fe932b26a294a0f2880478aa" category="list-text">传递给创建 CIS 资源的参数包括 `ipam ： true` 和 `custom_resource_mode ： true` 。要启用与 IPAM 控制器的 CIS 集成，需要使用这些参数。通过创建 F5 IPAM 资源验证 CIS 是否已启用 IPAM 集成。</block>
  <block id="84ac0b78989fa6595723d5541b8ec470" category="list-text">创建 F5 IPAM 控制器所需的服务帐户，角色和角色绑定。创建 YAML 文件并粘贴以下内容。</block>
  <block id="670c1074ae74616731a63f6b9462b94e" category="list-text">创建资源。</block>
  <block id="b7802bea6dc04d06b63232b6301621bb" category="list-text">创建一个 YAML 文件并粘贴下面提供的 F5 IPAM 部署定义。</block>
  <block id="6a1491ddca525bea3293eca6ea8019d0" category="admonition">更新以下 spec.template.spec.containers[0].args 中的 ip-range 参数，以反映与您的设置对应的 ipamLabel 和 IP 地址范围。</block>
  <block id="642252b62fe47e95caa77e3b06a7dbaf" category="admonition">要使 IPAM 控制器能够从定义的范围检测和分配 IP 地址，需要为类型为 loadbalancer 的服务标注 ipamLabels （`range1` 和` range2 `in below example] ）。</block>
  <block id="8f253132259909c28624117b3476a672" category="list-text">创建 F5 IPAM 控制器部署。</block>
  <block id="43946dccec13f46420eb559911e4c526" category="list-text">验证 F5 IPAM 控制器 Pod 是否正在运行。</block>
  <block id="1362b3e7985b4f24d6c2ef4438ee1f0e" category="list-text">创建 F5 IPAM 模式。</block>
  <block id="52b8ffce119fe77b28034f2fdd35eb5f" category="section-title">验证</block>
  <block id="32172ccfad6e7060b8f5e091e296f09c" category="list-text">创建类型为 loadbalancer 的服务</block>
  <block id="0847be44e618094bc81c848c7d131399" category="list-text">检查 IPAM 控制器是否为其分配了外部 IP 。</block>
  <block id="0e51a0606ba7833099aa57bd61c62ba6" category="list-text">创建部署并使用已创建的负载平衡器服务。</block>
  <block id="5f905cb56a4d1b364cab7fc57f4de4e5" category="list-text">检查 Pod 是否正在运行。</block>
  <block id="51b4d723f0434284233dab97982b185d" category="list-text">检查是否在 OpenShift 中为 loadbalancing 类型的服务在 BIG-IP 系统中创建了相应的虚拟服务器。导航到 " 本地流量 "&gt;" 虚拟服务器 "&gt;" 虚拟服务器列表 " 。</block>
  <block id="91193cea3335c4666b7dc31ca767030c" category="inline-image-macro">验证是否为相应的服务类型负载平衡器创建了 BIG-IP 虚拟服务器</block>
  <block id="879dfaa1de924ed5e9ccb98da9ac95cd" category="paragraph"><block ref="879dfaa1de924ed5e9ccb98da9ac95cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="10a93051f49f4080568cecc5ec30cd99" category="inline-link-macro">F5 BIG-IP</block>
  <block id="886218e92c071e06819887a13189b4e6" category="list-text"><block ref="886218e92c071e06819887a13189b4e6" category="inline-link-macro-rx"></block></block>
  <block id="0c3fd18fbca2ec11aa1ef250cf79f2e5" category="paragraph">NetApp Astra Control 采用 NetApp 数据保护技术，为有状态 Kubernetes 工作负载提供丰富的存储和应用程序感知型数据管理服务。Astra 控制服务可用于在云原生 Kubernetes 部署中支持有状态工作负载。Astra 控制中心可支持内部部署中的有状态工作负载，例如 Red Hat OpenShift 。有关详细信息，请访问 NetApp Astra Control 网站<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>。</block>
  <block id="1f23e5de73e650f12cbafec55d8a98cd" category="cell"><block ref="1f23e5de73e650f12cbafec55d8a98cd" category="inline-link-macro-rx"></block></block>
  <block id="69f55c7d7266874ad1ed57caf459c979" category="summary">此用例基于我们所做的最大的财务客户概念验证（ CPOC ）。过去，我们使用 NetApp 原位分析模块（ NIPAM ）将分析数据迁移到 NetApp ONTAP AI 。但是，由于 NetApp XCP 的最新增强功能和性能的提高，以及 NetApp 独特的数据移动工具解决方案方法，我们使用 NetApp XCP 重新注册数据迁移。</block>
  <block id="5084e1c3bd53b6115df08f4c40aadbe6" category="doc">数据湖到 ONTAP NFS</block>
  <block id="b1a11a01b3bdf3150e0240a1f037cdf5" category="section-title">客户面临的挑战和要求</block>
  <block id="9ed16d5ac47c336caaf9ca2b75930d78" category="paragraph">值得注意的客户挑战和要求包括：</block>
  <block id="b6976e1a47e217f1a7c746e8f57e327c" category="list-text">客户拥有不同类型的数据，包括结构化数据，非结构化数据和半结构化数据，日志， 以及数据湖中的机器到机器数据。AI 系统需要处理所有这些类型的数据，才能执行预测操作。如果数据位于数据湖本机文件系统中，则很难处理。</block>
  <block id="d85cb5080a9e99841f0ff6c36abdadad" category="list-text">客户的 AI 架构无法从 Hadoop 分布式文件系统（ Hadoop Distributed File System ， HDFS ）和 Hadoop 兼容文件系统（ Hadoop Compatible File System ， HCFS ）访问数据，因此 AI 操作无法使用这些数据。AI 要求数据采用可理解的文件系统格式，例如 NFS 。</block>
  <block id="982b6c87ace8f5b95c0523bd0557f4e2" category="list-text">由于数据量大，吞吐量大，因此需要采用一些特殊的流程从数据湖中移动数据，并且需要采用经济高效的方法将数据移动到 AI 系统。</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="section-title">数据移动者解决方案</block>
  <block id="b0a9a6f2387f2a23e13931f68fc509c1" category="paragraph">在此解决方案中， MapR 文件系统（ MapR-FS ）是从 MapR 集群中的本地磁盘创建的。MapR NFS 网关在每个数据节点上使用虚拟 IP 进行配置。文件服务器服务用于存储和管理 MapR-FS 数据。NFS 网关使 Map-FS 数据可通过虚拟 IP 从 NFS 客户端访问。每个 MapR 数据节点上都运行一个 XCP 实例，用于将数据从映射 NFS 网关传输到 NetApp ONTAP NFS 。每个 XCP 实例都会将一组特定的源文件夹传输到目标位置。</block>
  <block id="01e1c2900284f91d77ea71ffd32c6d18" category="paragraph">下图显示了使用 XCP 的 MapR 集群的 NetApp 数据移动工具解决方案。</block>
  <block id="a7dcdfa2099e01480afb3c060c679f10" category="paragraph"><block ref="a7dcdfa2099e01480afb3c060c679f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="409f476aa8c516a92f8d6a42e21db5a0" category="inline-link">使用 XCP 将数据从数据湖和高性能计算迁移到 ONTAP NFS</block>
  <block id="4084b5f9c9bab8db38eb6e04a3b3a4cc" category="paragraph">有关详细的客户使用情形，录制的演示以及测试结果，请参见<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> 博客</block>
  <block id="6cef4abedb8153458ee404a47b193489" category="inline-link">TR-4732 ：从大数据分析数据到人工智能</block>
  <block id="520ef13ea64298a652262e37756b6bd4" category="paragraph">有关使用 NetApp XCP 将 MapR-FS 数据移动到 ONTAP NFS 中的详细步骤，请参见中的附录 B<block ref="c952a09d2ff4403056a594c41db26c8d" category="inline-link-rx"></block>。</block>
  <block id="89185de94c95d958df7a1d1f328c5d3d" category="summary">要更好地规划和完成迁移，需要遵循不同的迁移阶段。要使用 NetApp XCP 从第三方 NAS 存储或直连 NAS 导出存储迁移数据，请遵循本节中提供的迁移准则。</block>
  <block id="ee5b035493cdde88f6472904ffe00677" category="doc">迁移工作流</block>
  <block id="5b312b66520bbb17746eeb5c9959e4ef" category="paragraph">下图显示了从任何 NAS 到 NetApp NAS 的迁移工作流。</block>
  <block id="228d4a26c37192668bb7f7bf0d81ce40" category="paragraph"><block ref="228d4a26c37192668bb7f7bf0d81ce40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0e69ccbb7ad96f546f7924206944bfa" category="section-title">内部部署</block>
  <block id="8df17c51ab4a9817f3fe7cea57052110" category="paragraph">从任何 NAS 到 NetApp NAS 的迁移工作流包括以下步骤：</block>
  <block id="3bd3dda9341b512ee536cc6e48d51a69" category="list-text">发现 NAS 共享和数据。</block>
  <block id="7800ed0aa4aebf1d63fd7120c2bcf538" category="list-text">扫描数据并生成报告以查找数据布局。</block>
  <block id="8e9880476ad79e202d93a0a7d0bb5f5b" category="list-text">运行 XCP Copy 命令创建基线。要加快迁移速度，请选择更多 XCP 实例并在子文件夹级别拆分工作负载，以启动并行迁移作业。</block>
  <block id="57324e972ea87c8e788d9831e510bc6d" category="list-text">对于增量更新，请使用 XCP sync ，直到转换窗口的更改率较低为止。</block>
  <block id="3812202d715addac73d7122672d3c8d0" category="list-text">运行 XCP sync 命令以完成迁移，将源标记为只读以执行最终同步。</block>
  <block id="2c1d8a91f274a7723f6ad2ffefc81b62" category="list-text">要验证数据传输是否正确，请运行 `XCP verify` 命令来比较源和目标。</block>
  <block id="8f4cde54f5af74d15d142ad98344aab6" category="paragraph">下图显示了从内部迁移到云的工作流。</block>
  <block id="9d1b3862e72bece8266c1c8b1098c696" category="paragraph"><block ref="9d1b3862e72bece8266c1c8b1098c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2fef7fa18bd688132425321b9188bb" category="paragraph">如果内部与云之间没有直接互联网连接，您必须通过叉车等脱机数据传输方法将数据从内部传输到云。每个云服务提供商都有一种不同的方法，使用不同的术语将数据移动到其数据中心。</block>
  <block id="9e76bcaf48df4797c2e546f778fd72f8" category="paragraph">下图展示了在不使用 ExpressRoute 的情况下从内部部署到 Azure 的数据移动程序解决方案。</block>
  <block id="e13bab0261f71ca4765f8b68cea20a43" category="paragraph"><block ref="e13bab0261f71ca4765f8b68cea20a43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423066080659363cc444ec5dee611f48" category="paragraph">您可以对不同云服务提供商提供的相应组件使用类似的架构。</block>
  <block id="c4e9391c8d60f1f326246cd6b6705492" category="summary">NetApp 收到了查找单个卷或多个卷中重复文件的请求。NetApp 提供了以下解决方案。</block>
  <block id="2e4e5fbe1f8f460b943ac3ed031c9dcf" category="doc">重复文件</block>
  <block id="dc4b36d55f5f1f0af63ed899a010c8f1" category="paragraph">对于单个卷，运行以下命令：</block>
  <block id="2d2f31777cf3433071b9bcd33f39279a" category="paragraph">对于多个卷，请运行以下命令：</block>
  <block id="b25f76deff236f93a3afa73c8a5b2a2c" category="summary">此用例基于 NetApp 旅游行业中最大的客户将数百万个小型内部文件迁移到云。</block>
  <block id="4b1739353c6d18cea69ed6a274b7135f" category="doc">使用 XCP 数据移动器将数百万个小文件迁移到灵活存储</block>
  <block id="bb29cc4e9e4447f7bad1e81c1c5a9a1f" category="paragraph">此用例基于 NetApp 旅游行业中最大的内部到云数据迁移客户。由于 COVID-19 降低了旅游行业的需求，因此客户希望在其内部环境中为需求定价应用程序节省高端存储的资本支出。该客户的 SLA 非常严格，需要将数百万个小文件迁移到云。</block>
  <block id="81ec900a5387f7a686d1451adaddf399" category="paragraph">下图展示了小型文件的数据从内部迁移到 Azure NetApp Files 。</block>
  <block id="214c5e9894032cde0e65b576e32294b9" category="paragraph"><block ref="214c5e9894032cde0e65b576e32294b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="099a60093e7de3795f557974125ce82b" category="inline-link">NetApp XCP Data Mover 解决方案：从内部部署到云</block>
  <block id="50d4edabefc40ad9614b567197696a2e" category="paragraph">有关详细信息，请参见<block ref="2c0eb3741003532ef113837d4b882a9a" category="inline-link-rx"></block> 博客</block>
  <block id="485f9678c52b78d051ddff564d873eb9" category="summary">本节中的命令以 CSV 格式转储数据。您可以对 " 大小 " 列求和以获取数据的总大小。</block>
  <block id="92f6d6878e37105d20e75151b95d4e6a" category="doc">从 SMB/CIFS 共享创建 CSV 文件</block>
  <block id="d122031c67144a65ca4721f8324ae0b3" category="paragraph">以下命令将以 CSV 格式转储数据。您可以对 " 大小 " 列求和以获取数据的总大小。</block>
  <block id="1bed902c0754e4abc7598b7f1a0450e0" category="paragraph">输出应类似于以下示例：</block>
  <block id="f7c322db5a6c805aed8a38858c7ba770" category="paragraph">要扫描三个子目录的深度并按排序顺序提供结果，请运行 `XCP -du` 命令，并将每个目录级别的大小转储到三个子目录的深度。</block>
  <block id="7c12bd6fa64456eb3a61460a4bbb98e6" category="paragraph">要进行排序，请将信息转储到 CSV 文件并对信息进行排序。</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">要了解有关本文档中所述信息的更多信息，请参见以下文档和 / 或网站：</block>
  <block id="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link"><block ref="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link-rx"></block></block>
  <block id="eba010943793fb5b647ad292a452b3ff" category="list-text">NetApp XCP 博客<block ref="2639c38af267ba997fc1d85740cfc9a6" category="inline-link-rx"></block></block>
  <block id="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link"><block ref="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link-rx"></block></block>
  <block id="fb8d9f206204f9562c2a67c6b37a7d1b" category="list-text">NetApp XCP 用户指南<block ref="05f41a166d52148335e3a0df2eafec23" category="inline-link-rx"></block></block>
  <block id="e2c2bd378a3ae3740034d637754af7e2" category="inline-link"><block ref="e2c2bd378a3ae3740034d637754af7e2" category="inline-link-rx"></block></block>
  <block id="79b44e54a5eac82beac2de86249cd862" category="list-text">将大数据分析数据转换为人工智能—适用于 AI 的数据移动工具解决方案<block ref="79ced727b5c9638c0385a25671803fba" category="inline-link-rx"></block></block>
  <block id="0706a8a70e2892183b45c55ef1394714" category="summary">本节介绍使用不同文件大小（即 100 万个 NFS 文件）执行 XCP 复制和 XCP 同步操作的大致时间。</block>
  <block id="137e4d3e0bc5586af6fc7ca9441511e1" category="doc">规模估算准则</block>
  <block id="5224a4cb1d59edb5630ae27e640409e9" category="section-title">根据测试估计时间</block>
  <block id="1112334374c9149cc8ad8e80a76f2e56" category="paragraph">下图显示了 XCP 复制操作的结果。</block>
  <block id="d6852faef2642951731c8d64e3009dbe" category="paragraph"><block ref="d6852faef2642951731c8d64e3009dbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58fe8c2d511caf443cb23313cb89181b" category="paragraph">下图显示了 XCP 同步重命名和链接操作的结果。</block>
  <block id="319b9e8dee4108359b7ef17af2fb492d" category="paragraph"><block ref="319b9e8dee4108359b7ef17af2fb492d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2186640ac8cac7be2b0f3940d871bf04" category="paragraph">文件大小与传输重命名的源文件所需的 `XCP 同步` 完成时间不符；图形为线性图形。</block>
  <block id="de54b82b6e27abb7d6f924e14d40a351" category="paragraph">链路类型包括软链路，硬链路和多链路。软链接被视为普通文件。文件大小与完成 XCP 同步操作的时间无关。</block>
  <block id="db3eb29ec347d79a716c6235063b1955" category="paragraph">下图显示了 XCP 同步附加和删除操作的结果。</block>
  <block id="feeff6134484088b1b404089dc5f92d9" category="paragraph"><block ref="feeff6134484088b1b404089dc5f92d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64c7d081568c95905b16364c19e1be1" category="paragraph">对于附加和删除操作，与较小的文件大小相比，较大的文件需要更多的时间。完成此操作所需的时间与附加和删除更改的百分比呈线性增长。</block>
  <block id="ecc8d4faf16ec3b08a8badd1d71421d3" category="section-title">将 XCP 1.6.1 与 XCP 1.5 进行比较</block>
  <block id="ded6c17dda87ca50a7ecde2418543075" category="paragraph"><block ref="ded6c17dda87ca50a7ecde2418543075" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09a0804a78587affdd9192afd0f8c80c" category="paragraph">下图显示了 XCP 1.6.1 与 1.5 （ 16K 大小为 100 万个文件）的 XCP 同步性能结果。</block>
  <block id="b2733f54373c0149b19c3b37afbcb7da" category="paragraph"><block ref="b2733f54373c0149b19c3b37afbcb7da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7770abf0d9a0789407ea0a0e81cc5a6" category="paragraph"><block ref="e7770abf0d9a0789407ea0a0e81cc5a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71c6a3c1c59fc41b371a18011d1d5c9b" category="paragraph">平均而言，对于大小为 1 MB 的文件，在执行 `XCP sync` 差异增量更新 - 重命名，附加，链接和删除操作时， XCP 1.7 的性能会在 XCP 1.6.3 上提高或类似于 XCP 1.6.3 。</block>
  <block id="a01ed8ff3f6e9e3ac0c0068a083281f2" category="summary">本节提供使用 NetApp XCP 进行数据迁移的故障排除指导。</block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">故障排除</block>
  <block id="95109c432d89e67182659615993ba75d" category="section-title">错误 1 ： XCP 失败， nfs3 错误 70 ： xcp.log 中的文件句柄陈旧错误</block>
  <block id="99b1b0e3547443c29793187326a64dbc" category="paragraph">* 原因和指导。 *</block>
  <block id="0774d3e8b775fcc34e680b302e85f3c1" category="paragraph">挂载源文件夹并验证此文件夹是否存在。如果该错误不存在或已删除，您将收到 `stale filehandle` 错误，在这种情况下，您可以忽略该错误。</block>
  <block id="8fefb715a66a069c9e9318a58ecfdaee" category="section-title">错误 2 ： NetApp NFS 目标卷有空间，但 XCP 失败，并显示 nfs3 错误 28 ：设备上没有剩余空间</block>
  <block id="bba52daa861e8093e201c3939f43057f" category="list-text">运行 `df` 命令检查 NFS 目标卷的空间或检查存储。</block>
  <block id="20183145becc54cc822a80107f92f13d" category="list-text">检查存储控制器中的索引节点。</block>
  <block id="fe3a96130e3ec3092026a84e4dd12e50" category="list-text">如果使用索引节点，请运行以下命令以增加索引节点数：</block>
  <block id="3d5c39f585b0e679dbfe0855d556f0af" category="summary">NetApp XCP 使用多线程和可自定义的功能传输数据。它专为三种主要使用情形而设计—数据移动或迁移，文件系统分析和快速目录树删除。</block>
  <block id="6416bf9c9c9445fbe2e15f69fa8371d2" category="paragraph">NetApp XCP 使用多线程和可自定义的功能传输数据。它专为三大用例而设计：数据移动或迁移，文件系统分析和快速目录树删除。</block>
  <block id="7817bd783e8db0557909483f54288eae" category="section-title">数据移动或迁移</block>
  <block id="a7786f240f16aadfd675c46be438f64e" category="paragraph">NetApp XCP 可将数据从任何 NAS 传输到 NetApp NAS 。此过程包括四个主要操作：扫描，复制，同步和验证。此外，还有一些有助于数据监控和传输的其他功能：</block>
  <block id="59e4194e1b171063beeb99722a68e7af" category="list-text">* 复制。 * 执行基线数据传输。</block>
  <block id="a75ddee1308f2f19e478595122434544" category="list-text">* 同步 * 执行增量数据传输。</block>
  <block id="ae4ab572ec7de44b385c01df54f00d17" category="list-text">* 验证。 * 对目标执行全面验证。</block>
  <block id="8ddbaa98ade9dcd56d4960b7abd22525" category="list-text">* 显示（可选）。 * 发现 NAS 共享。</block>
  <block id="4f4544fb0f8ed8f32e27a8b8651a46e6" category="paragraph">下图显示了 XCP 数据迁移和复制操作。</block>
  <block id="6d97d3e510fc0fba449ece8ddd3f3d10" category="paragraph"><block ref="6d97d3e510fc0fba449ece8ddd3f3d10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="657bad21acd4ceb926477ced53a4ec55" category="section-title">文件系统分析</block>
  <block id="65424b0dc0515cfa3b67e71712012db0" category="paragraph">NetApp XCP 本机支持您识别，检查和分析非结构化数据以提高洞察力，这是企业客户的一项重要要求，他们需要利用这些洞察力更好地进行规划，实施高价值数字资产，并通过报告和评估实现数据监管。</block>
  <block id="03c5a03e8b03794f5fa193e72245496c" category="paragraph">处理敏感数据的客户可以使用 NetApp XCP 问题解答解决典型的操作问题，例如：</block>
  <block id="6ad28c778baa08cff585599e160c12c8" category="list-text">我的数据在哪里？</block>
  <block id="5eccfafcfad0fb3dcd5f4f1036fed9f9" category="list-text">我们拥有多少数据和哪些类型的文件？</block>
  <block id="b1c54971a6211d7b7e3d074bff16b4c9" category="list-text">哪些数据正在使用中，有多少数据处于休眠状态？</block>
  <block id="81ff19b428c80049b09f8e1e6e55cfde" category="paragraph"><block ref="81ff19b428c80049b09f8e1e6e55cfde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a6c498fb90ee345d997f888fce3b18" category="section-title">删除</block>
  <block id="4125c56415a1c3b98b49ee7f8c2ebfc3" category="paragraph">存储团队和电子设计自动化（ Electronic Design Automation ， EDA ）工作负载清理大型目录可能非常困难，无论是陈旧的数据还是需要清理以恢复存储空间的测试数据。XCP 提供了快速删除功能，可以删除完整的目录树。NetApp XCP 删除功能可从给定 NAS 路径中删除文件和文件夹。您可以利用匹配筛选器删除一组特定的文件和文件夹。对于大量文件和文件夹，您可以使用强制选项，该选项不需要确认即可删除。</block>
  <block id="ecfd5328aaeaeb8ab72037598049a32c" category="section-title">支持实时源迁移</block>
  <block id="286a0f56c729672b0709605c558d0008" category="paragraph">此功能支持源上的更改，但不支持目标上的更改。在迁移期间，目标不应处于活动状态。只有 NFS 迁移才支持实时源迁移。</block>
  <block id="2c346a482fcf83bd03d1d51f65d58b8d" category="admonition">实时源迁移不需要特殊设置。</block>
  <block id="ba41152bc4991a294ab26fbe691d52e3" category="section-title">XCP 的前提条件</block>
  <block id="010e3e2a3d44100784dac368cdb601c0" category="paragraph">在部署 NetApp XCP 之前，必须满足以下前提条件：</block>
  <block id="b76760dcfae800f7180ec4e8c57a8e2f" category="list-text">运行以下命令，验证 NFS 服务器使用的 NFS 端口：</block>
  <block id="a9a9fca38da059af5a55e2fc58ef3851" category="list-text">要访问执行 XCP 操作的位置，例如内部或云实例（例如 Azure ， AWS 或 Google 虚拟机虚拟机虚拟机虚拟机虚拟机虚拟机虚拟机虚拟机虚拟机虚拟机实例），请打开 NFS 端口的防火墙端口。</block>
  <block id="b22a57ce186f512ec584f5aac1d3de34" category="list-text">使用 telnet 命令 ` &lt;on-prem nfs data LIF IP 或 NAS IP &gt; 2049` 确认 NFS 端口可从 XCP 服务器访问。默认端口为 2049. 。如果您的环境具有其他端口，请使用该 IP 。</block>
  <block id="e54a7adb3b7e28ed3d693d972fc48fd0" category="list-text">对于 NFS ，使用 `showmount -e &lt; NAS IP &gt;` 命令验证共享是否可从 XCP 服务器访问。</block>
  <block id="da7f6a983e12f3b14b965ea651990ca9" category="list-text">将目标卷上的索引节点数增加到源文件上的文件数（文件数）以上。</block>
  <block id="71858e85f290ec0f6955841bab9f3aef" category="inline-link">NetApp XCP 许可证门户</block>
  <block id="14324adbfb79ad4b6832f6a02a1275db" category="list-text">从下载 XCP 许可证<block ref="eab886d42d2df7a710066e6d9bf6f5f5" category="inline-link-rx"></block>。</block>
  <block id="7481213bd7173438d06de418474e428b" category="list-text">您必须在 mysupport.netapp.com 上拥有 NetApp 帐户，或者可以免费注册。</block>
  <block id="d25e9f08475ddf6a2701e7cfbd67ff06" category="list-text">下载许可证并准备好。</block>
  <block id="3d19c697861d11cce0f1d78d41cfea64" category="list-text">创建 NAS 卷并为数据目标配置共享。</block>
  <block id="4f2a304b9680876edc7cb61b5c4c7134" category="list-text">对于多个 XCP 实例，您必须有一个或多个服务器或云实例才能将数据从多个源文件夹或文件传输到目标。</block>
  <block id="adc4e34febc2f5919cfa03870630c2fc" category="list-text">maxdir size （默认值为 308MB ）用于定义单个文件夹中的最大文件数（大约 100 万个）。增加 maxdir size 值以增加文件数。增加此值会影响额外的 CPU 周期。</block>
  <block id="a1552408599f6e2171495d55ae375802" category="list-text">在云环境中， NetApp 建议您在内部环境和云环境之间设置 ExpressRoute （ Azure ）， Direct Connect （ AWS ）或 Cloud Interconnect （ GCP ）。</block>
  <block id="7ed4381f9a10813d06ebeaf5c947c2c1" category="summary">NetApp XCP 文件分析 GUI 可通过在后端使用 XCP 并可视化任何 NAS （ NFS ， SMB ）文件系统的统计信息（如图形和视图）来帮助运行文件系统扫描。</block>
  <block id="250a5d043009990eb69a399d7c630462" category="doc">文件分析</block>
  <block id="0f2604fbc18e6e91ba050460e6557361" category="paragraph">NetApp XCP 文件分析 GUI 可通过在后端使用 XCP 并可视化任何 NAS （ NFS ， SMB ）文件系统的统计信息（如图形和视图）来帮助运行文件系统扫描。从 1.6 开始， XCP 可通过使用 Configure 和 systemctl 选项通过简单的部署步骤作为服务运行。XCP 配置选项可指导您安装和配置 Postgres 和 Web 服务器以及收集凭据。systemctl 选项将 XCP 作为服务从图形用户界面运行 REST API 通信。</block>
  <block id="914cb171c700c273306e8265b56f4973" category="paragraph">下图显示了 XCP 文件分析流。</block>
  <block id="538e51b99e800ab65e133b5d57b2dc7f" category="paragraph"><block ref="538e51b99e800ab65e133b5d57b2dc7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bcdbf2b32a87f7efd13f706d43954d5" category="inline-link">NetApp XCP 1.6 改进了开放式文件分析和基础架构</block>
  <block id="168c81694a3b19988d829a9baeda23fd" category="list-text">使用 `XCP scan` 和 ` -match` 筛选器生成一年后修改的文件列表，其中包含占用的空间。</block>
  <block id="de615506a73ca5960be54d36ba7fcd5b" category="list-text">查找一年以上的文件所使用的空间。</block>
  <block id="d2d1f03d5f19a1229103a85cc9224a61" category="list-text">查找一年多前修改的数据的总大小和图形视图。</block>
  <block id="d706f3d28ee3e74f9a6829c882169af8" category="paragraph">以下报告是对一年多前修改过的文件的自定义扫描示例。</block>
  <block id="4d614048a495643d1c641a86e53b78d3" category="paragraph"><block ref="4d614048a495643d1c641a86e53b78d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="035fe4f74f99e66d6525774bf40236f9" category="summary">本节介绍使用 NetApp XCP 迁移数据的最佳实践，准则和建议。</block>
  <block id="52f7ac44cac2d8d1a3f005648d7521e3" category="doc">最佳实践准则和建议</block>
  <block id="1cce79308861dd86d5e56af13afefaf2" category="list-text">使用支持 IMT 的 XCP 客户端操作系统。IMT 支持的客户端已通过 NetApp 认证。</block>
  <block id="ec653488c4b3b9bb00702a4fb937f5b4" category="list-text">在 Linux 操作系统中以 root 用户身份运行 XCP 以执行迁移。您可以以 sudo 用户身份运行 XCP 命令，但 XCP 不支持此命令。</block>
  <block id="8c8f6415908fe0a235f0850d80a398a4" category="list-text">每个客户端仅运行一个 XCP 实例。从技术上讲，您可以从不同的位置在同一主机上运行多个 XCP 实例，但这不是受支持的做法。确实，运行许多实例可能会导致失败。</block>
  <block id="cac486281cae3e805e89a64673c47eb3" category="list-text">在当前 XCP 版本中，不支持实时源。如果源 NetApp 卷处于活动状态，并由应用程序和用户持续更改，则应创建源卷的快照以执行迁移。</block>
  <block id="c1f9797ffa66b762cf07348c6bc4a005" category="list-text">最佳做法是，为每个增量同步创建一个名称不同的新快照，以便在发生故障时根据快照名称轻松创建增量迁移路径。</block>
  <block id="1309895bb5c78406c77a6cc2800160eb" category="list-text">如果要执行基于快照的迁移，最佳做法是继续执行基于快照的迁移，直到转换为止。</block>
  <block id="cc9954d8dc3e80c40af9d0a7ca3de005" category="list-text">如果您的文件数超过 1000 万个，并且增量数据更改率超过 50% ，则最佳做法是使用比安装和管理指南中的最低建议更高的核心数和更多的内存。</block>
  <block id="7776aec966d5a0c71bd4e8230f9470b8" category="summary">此用例基于电视网络客户。客户希望将 Oracle Recovery Manager （ RMAN ）备份文件迁移到云，并使用 Azure NetApp Files 和 Pacemaker 软件运行 Oracle E-Business Suite （ EBS ）应用程序。客户还希望将其数据库备份文件迁移到按需云存储，并将大型文件（每个文件的大小介于 25 GB 到 50 GB 之间）传输到 Azure 。</block>
  <block id="8108bac490ceb375198c578e8a439026" category="doc">使用 XCP Data Mover 迁移大型文件</block>
  <block id="06470d7a09a56d555bad98bdf38a6cad" category="paragraph">下图说明了将大型文件的数据从内部迁移到 Azure NetApp Files 的过程。</block>
  <block id="ddf97b6ffb913bd772848e3ebecfc8c1" category="summary">本节介绍 NetApp XCP 的数据传输部署步骤。</block>
  <block id="8388066510b59c8d3387373b6969a7af" category="doc">部署步骤</block>
  <block id="8449c94058b7c2e686c3e19f7e772a65" category="section-title">测试台详细信息</block>
  <block id="94cb70bde9d89f0b10ffdca34b0bec22" category="paragraph">下表提供了用于此部署和性能验证的测试台的详细信息。</block>
  <block id="57419d904381619fcf00bc94e4ce26f1" category="cell">XCP 1.7 版</block>
  <block id="0bf2dca8ce9b94406660e58b59a3dbbd" category="list-text">一台 Linux 服务器— Linux （ RHEL 7.9 或 RHEL 8 ）</block>
  <block id="d85d793ce9fe1772209fa5e17fb29449" category="list-text">一台 Windows 服务器— Windows Server 2019 标准版</block>
  <block id="91ea491db15b6d672d79b23fb98eb089" category="cell">源卷的 NetApp AFF 存储阵列 HA 对</block>
  <block id="23ec9249d03285a513eaaf182a7bcd49" category="list-text">AFF8080</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">NFS 协议</block>
  <block id="80fdc6d88149270be735269f2ff65645" category="cell">用于目标卷的 NetApp AFF 存储阵列 HA 对</block>
  <block id="203165a49e3a391bdbc44e3a05d54279" category="list-text">ONTAP 9.</block>
  <block id="28712ee052ea500eba0cdbb1d847277f" category="cell">Fujitsu PRIMERGY RX2540 服务器</block>
  <block id="539c5af1c2682685cd076697aaa6c700" category="cell">每个均配备： * 48 个 CPU * Intel Xeon * 256 GB 物理内存 * 10GbE 双端口</block>
  <block id="0cc5c79089d6ca0752529568758efc4c" category="cell">10GbE</block>
  <block id="2879e817640f94636340918850eb6903" category="inline-link">《 NetApp XCP 用户指南》</block>
  <block id="f2dd54ec57ec5464ee3aa191a48a8a43" category="paragraph">要部署 NetApp XCP 以进行数据传输，请先在目标位置安装并激活 XCP 软件。您可以在中查看详细信息<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>。为此，请完成以下步骤：</block>
  <block id="c58c8903e33903d2e630277aa3a78795" category="inline-link">NetApp XCP （下载）页面</block>
  <block id="2d1acef34bb45f2c1878c6b576f3b400" category="list-text">从下载 XCP 软件<block ref="13844fc5dba1627d28169d2acfff11e2" category="inline-link-rx"></block>。</block>
  <block id="8319752fe43598ddb329e536217c1cb5" category="list-text">将下载的 XCP tar 文件复制到 XCP 服务器。</block>
  <block id="c9b8e059d1597eaead43d286e91c91e3" category="list-text">取消压缩 tarball 。</block>
  <block id="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link"><block ref="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link-rx"></block></block>
  <block id="19f1deecf23a78878eb01c772b9233e0" category="list-text">从下载许可证<block ref="4da39fde529d1b69f60873c302229eed" category="inline-link-rx"></block> 并复制到 XCP 服务器。</block>
  <block id="3df11515e644382207c1430c36ea48bb" category="list-text">激活许可证。</block>
  <block id="ad7984249c2054b4da5fd3b57b1b91ef" category="list-text">找到源 NFS 端口和目标 NFS 服务器。默认端口为 2049. 。</block>
  <block id="79fe861b8c719b1a534bdbcace1444a2" category="list-text">检查 NFS 连接。使用 telnet 访问 NFS 服务器端口，检查 NFS 服务器（源和目标）。</block>
  <block id="5e471de79dbe02105770bcf04bc501d5" category="list-text">配置目录。</block>
  <block id="67005679d502da10622f2104421e894b" category="list-text">为 XCP 目录创建 NFS 卷并导出 NFS 。您还可以利用操作系统 NFS 导出来导出 XCP 目录。</block>
  <block id="d6f2a18783592d1858e3e5bdcabd4567" category="list-text">检查 NFS 导出。</block>
  <block id="39b638480b201a7448774e8186012e4e" category="list-text">更新 `xcp.ini` 。</block>
  <block id="9d44d1309af47903754b16c403f68774" category="list-text">使用 `XCP show` 查找源 NAS 导出。查找：</block>
  <block id="fbff9a42f0ba33571594cb39da93ef4b" category="list-text">（可选）扫描源 NAS 数据。</block>
  <block id="82d1938e7390e37babdea8d6fd359156" category="paragraph">扫描源 NAS 数据有助于您了解数据布局并发现任何可能的迁移问题。XCP 扫描操作时间与文件数量和目录深度成比例。如果您熟悉 NAS 数据，可以跳过此步骤。</block>
  <block id="c6e94e11da5ba5bce0f27b8c782e4110" category="list-text">检查 `XCP scan` 创建的报告。主要搜索无法读取的文件夹和无法读取的文件。</block>
  <block id="6a6a10773cfc849f638ac0137a5f08d6" category="list-text">（可选）更改索引节点。查看索引节点数，并根据目录卷和目标卷要迁移或复制的文件数（如果需要）修改索引节点数。</block>
  <block id="342779baf0b15fdf377f142c987e896a" category="list-text">扫描目标卷。</block>
  <block id="a88831977a2b62e982b722f6fa6662b5" category="list-text">检查源卷和目标卷空间。</block>
  <block id="4b14d92fd07932987cf7416eb7f604ca" category="list-text">使用 `XCP copy` 将数据从源复制到目标并检查摘要。</block>
  <block id="506aae448569ed08125f41ed940eb00b" category="admonition">默认情况下， XCP 会创建七个并行进程来复制数据。可以对此进行调整。</block>
  <block id="5c46a2da3e6e0423829946fe877c50b8" category="admonition">NetApp 建议源卷为只读卷。源卷是实时活动文件系统。`XCP 副本` 操作可能会失败，因为 NetApp XCP 不支持由应用程序持续更改的实时源。</block>
  <block id="0f7dbc07af0b5c3ba51ff604b81ebe8a" category="paragraph">对于 Linux ， XCP 需要索引 ID ，因为 XCP Linux 会执行目录编制。</block>
  <block id="764363dd147880ab6aca242a0417562e" category="list-text">（可选）检查目标 NetApp 卷上的索引节点。</block>
  <block id="ab3ba5fb62db279b7d07bac650a6c2d2" category="list-text">使用 `XCP sync` 执行增量更新。</block>
  <block id="6cdfbe571ba2209e0a76f3bcabfee9f6" category="paragraph">在本文档中，为了模拟实时，对源数据中的 100 万个文件进行了重命名，然后使用 `XCP sync` 将更新后的文件复制到目标。对于 Windows ， XCP 既需要源路径，也需要目标路径。</block>
  <block id="13475b4ca9a916769b9d63f4fddfa18d" category="list-text">验证数据传输。您可以使用 `XCP verify` 来验证源和目标是否具有相同的数据。</block>
  <block id="1cd06f171a5a99926a67bd673014f765" category="paragraph">XCP 文档为 `scan` ， `copy` ， `sync` 和 `verify` 操作提供了多个选项（包括示例）。有关详细信息，请参见<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>。</block>
  <block id="efa146517859e051c07fabac4c88d3e7" category="admonition">Windows 客户应使用访问控制列表（ ACL ）复制数据。NetApp 建议使用命令 `XCP copy -acl -fallbackuser\&lt;username&gt; -fallbackgroup\&lt;username or groupname&gt; &lt;source&gt; &lt;destination&gt;` 。考虑到包含使用 ACL 的 SMB 数据的源卷以及 NFS 和 SMB 均可访问的数据，目标卷必须为 NTFS 卷，以获得最佳性能。使用 XCP （ NFS 版本）从 Linux 服务器复制数据，并使用 Windows 服务器中的 ` -acl` 和 ` -noddata` 选项执行 XCP （ SMB 版本） sync ，以便将 ACL 从源数据复制到目标 SMB 数据。</block>
  <block id="85760de676a9f74f28f26115c39c9a0b" category="inline-link">正在配置 " 管理审核和安全日志 " 策略</block>
  <block id="a0251b301ad566d86ffa3916c5510295" category="paragraph">有关详细步骤，请参见<block ref="06fdba77988da3047baf401e4fdefca5" category="inline-link-rx"></block>。</block>
  <block id="945407c0c602d0c34ead1ebb5427a84b" category="summary">我们使用 NetApp XCP 将数据从 GPFS 迁移到 NFS ，以便 GPU 可以处理数据。AI 通常处理来自网络文件系统的数据。</block>
  <block id="1f797a3a419cdffd442fc4b662974908" category="doc">从高性能计算到 ONTAP NFS</block>
  <block id="a4a4d9553ba807d3f28f8f25ea56cfec" category="paragraph">此用例是根据现场组织的请求创建的。一些 NetApp 客户的数据位于高性能计算环境中，该环境可为培训模型提供数据分析，并使研究组织能够深入了解和了解大量数字数据。NetApp 现场工程师需要一个详细的操作步骤才能将数据从 IBM 的 GPFS 提取到 NFS 。我们使用 NetApp XCP 将数据从 GPFS 迁移到 NFS ，以便 GPU 可以处理数据。AI 通常处理来自网络文件系统的数据。</block>
  <block id="0ce008ed1a75e69e9f21d1ad29ed23dd" category="paragraph">有关高性能计算到 ONTAP NFS 使用情形，录制的演示和测试结果的详细信息，请参见<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> 博客</block>
  <block id="fb64727a5df67d0ceff6f0a11b531ab5" category="paragraph">有关使用 NetApp XCP 将 MapR-FS 数据移动到 ONTAP NFS 中的详细步骤，请参见中的附录 A ： gpfs 到 NFS―详细步骤<block ref="e760c508aca9c545c45aba81e95e5593" category="inline-link-rx"></block>。</block>
  <block id="1ebf7a1cb4f3826913a58c19018c694e" category="paragraph">本节介绍客户场景及其架构。</block>
  <block id="322bc614a8031f8c334d233f8221a4ab" category="summary">本节详细介绍了将数据从 7- 模式 NetApp Data ONTAP 迁移到 ONTAP 的步骤。</block>
  <block id="30ee25b2188724428e827e97bab504fe" category="doc">将数据从 7- 模式迁移到 ONTAP</block>
  <block id="3ec8186e1900b95154cccf8ccea38023" category="section-title">将 7- 模式 NFSv3 存储过渡到 ONTAP 以获取 NFS 数据</block>
  <block id="e70a6b3d23d1e0da94c71a9ea26747d1" category="paragraph">本节介绍下表中的分步操作步骤，用于将源 7- 模式 NFSv3 导出过渡到 ONTAP 系统。</block>
  <block id="cad365d13740342c8f6199feb7229137" category="paragraph">NetApp 假定源 7- 模式 NFSv3 卷已导出并挂载在客户端系统上，并且 XCP 已安装在 Linux 系统上。</block>
  <block id="b40dbfa52a308abff927380b983cd868" category="list-text">验证目标 ONTAP 系统是否运行正常。</block>
  <block id="39745ae9472f91abcd9e844389157858" category="list-text">验证目标系统上是否至少存在一个非根聚合。聚合正常。</block>
  <block id="47e01226b4fdf549d938eb5c6196970d" category="paragraph">如果没有数据聚合，请使用 `storage aggr create` 命令创建一个新聚合。</block>
  <block id="5c52d0e31e44663ee633be681387faa1" category="list-text">在目标集群系统上创建 Storage Virtual Machine （ SVM ）。</block>
  <block id="426b5839edbb7a7772be396e7eaceace" category="list-text">从目标 SVM 中删除 FCP ， iSCSI ， NDMP 和 CIDS 协议。</block>
  <block id="d03930721e424cdac105ccd0172f7dbe" category="paragraph">验证此 SVM 是否支持 NFS 协议。</block>
  <block id="4d6b5eb9160c3c34e9ff5535c403cea9" category="list-text">在目标 SVM 上创建新的读写数据卷。验证安全模式，语言设置和容量要求是否与源卷匹配。</block>
  <block id="a2cebf1e91b2a266a58458873c8980fd" category="list-text">创建数据 LIF 以处理 NFS 客户端请求。</block>
  <block id="6817d90b89495074e679248b56128378" category="paragraph">验证是否已成功创建 LIF 。</block>
  <block id="3a014fae7f5d70cc01c593a8401140ee" category="list-text">如果需要，使用 SVM 创建静态路由。</block>
  <block id="84bb87c2987a4b39ea23430f38570808" category="paragraph">验证是否已成功创建路由。</block>
  <block id="54b19b8b3b6de7bce018de598a1645ea" category="list-text">在 SVM 命名空间中挂载目标 NFS 数据卷。</block>
  <block id="6365adb4324221d944bc90c4663dfe5a" category="paragraph">验证是否已成功挂载此卷。</block>
  <block id="991398c32a43bcf95d7fa14129a6fcb0" category="paragraph">您也可以使用 `volume create` 命令指定卷挂载选项（接合路径）。</block>
  <block id="6c02d24a81dd4d9b1ad7a15079b4f122" category="list-text">在目标 SVM 上启动 NFS 服务。</block>
  <block id="e210fe657c5d46e3e11ca263d1a18af7" category="paragraph">验证此服务是否已启动并正在运行。</block>
  <block id="304683b37151feda067e3acfde300057" category="list-text">验证默认 NFS 导出策略是否已应用于目标 SVM 。</block>
  <block id="353fde8a37910716dc00dec81475c0d5" category="list-text">如果需要，为目标 SVM 创建新的自定义导出策略。</block>
  <block id="174608facfdad6448222d6d46c87fba5" category="paragraph">验证是否已成功创建新的自定义导出策略。</block>
  <block id="4007cf260b496d35ba0e925f1e7a183d" category="list-text">修改导出策略规则以允许访问 NFS 客户端。</block>
  <block id="5f249df749512e129505d18fd47d7010" category="list-text">验证是否允许客户端访问卷。</block>
  <block id="94a80f56f92334f07fd30337692ca889" category="list-text">连接到 Linux NFS 服务器。为 NFS 导出的卷创建挂载点。</block>
  <block id="725ae014e8d8f66f0f2d477fa656ba32" category="list-text">在此挂载点挂载目标 NFSv3 导出的卷。</block>
  <block id="a345b19bdd483ecd745a2e643b756bc6" category="admonition">NFSv3 卷应导出，但不一定由 NFS 服务器挂载。如果可以挂载这些卷，则 XCP Linux 主机客户端会挂载这些卷。</block>
  <block id="b5b2af7fb88c03cfd258cdd77fc6fbe1" category="paragraph">验证是否已成功创建挂载点。</block>
  <block id="8d3ac4d5ea9c5d5c45d7322512d7b778" category="list-text">在 NFS 导出的挂载点上创建一个测试文件，以启用读写访问。</block>
  <block id="07e483b5917b8a9e91a22b2ebc20961a" category="admonition">读写测试完成后，从目标 NFS 挂载点删除该文件。</block>
  <block id="09280cd628b820e696b87163b3fe0fde" category="list-text">连接到安装了 XCP 的 Linux 客户端系统。浏览到 XCP 安装路径。</block>
  <block id="86de6eeea329a50737c7056637f43e49" category="list-text">在 XCP Linux 客户端主机系统上运行 `XCP show` 命令，查询源 7- 模式 NFSv3 导出。</block>
  <block id="080173849f5fec049b214897a2882295" category="list-text">扫描源 NFSv3 导出的路径并打印其文件结构的统计信息。</block>
  <block id="df86b239e412ba3ba7192b581381b444" category="paragraph">NetApp 建议在 XCP `scan` ， `copy` 和 `sync` 操作期间将源 NFSv3 导出置于只读模式。</block>
  <block id="695efe20ffcfc7c261e44cbb1b62cc78" category="list-text">将源 7- 模式 NFSv3 导出复制到目标 ONTAP 系统上的 NFSv3 导出。</block>
  <block id="50515e001679292835a498c6bd3f3c31" category="list-text">复制完成后，验证源和目标 NFSv3 导出是否具有相同的数据。运行 `XCP verify` 命令。</block>
  <block id="70d6a53ca7c3c592cb4099e2988c226c" category="paragraph">如果 `XCP verify` 发现源数据与目标数据之间存在差异，则摘要中会报告错误 `no such file or directory` 。要修复此问题描述，请运行 `XCP sync` 命令将源更改复制到目标。</block>
  <block id="505d73172f49d62bd99779ab53aa5eeb" category="list-text">在转换之前和期间，再次运行 `verify` 。如果源包含新数据或更新的数据，请执行增量更新。运行 `XCP sync` 命令。</block>
  <block id="887abb0b5917a0a6b0c47f5ef3eca1ce" category="list-text">要恢复先前中断的复制操作，请运行 `XCP resume` 命令。</block>
  <block id="f807709818ec3fbc508863a00ea17044" category="paragraph">在 `re恢复` 完成复制文件后，再次运行 `ve执行` 以使源存储和目标存储具有相同的数据。</block>
  <block id="d78900410b9203071958256c3d6a7701" category="list-text">NFSv3 客户端主机需要卸载从 7- 模式存储配置的源 NFSv3 导出，并从 ONTAP 挂载目标 NFSv3 导出。转换需要中断。</block>
  <block id="6bd42ffcfd349b793e9f6c6f00c18cd8" category="section-title">将 7- 模式卷 Snapshot 副本过渡到 ONTAP</block>
  <block id="fefac3d628a2abc2d1677e073a0688e7" category="paragraph">本节介绍用于将源 7- 模式卷 NetApp Snapshot 副本过渡到 ONTAP 的操作步骤。</block>
  <block id="721e28a3edb434ca3d7f37307126504c" category="admonition">NetApp 假定源 7- 模式卷已导出并挂载在客户端系统上，并且 XCP 已安装在 Linux 系统上。Snapshot 副本是卷的时间点映像，用于记录自上次 Snapshot 副本以来的增量更改。使用 ` -snap` 选项并将 7- 模式系统作为源。</block>
  <block id="e18566c8fe02de3e35e48df30daa5189" category="paragraph">* 警告： * 保留基本 Snapshot 副本。基线副本完成后，请勿删除基线 Snapshot 副本。要执行进一步的同步操作，需要使用基本 Snapshot 副本。</block>
  <block id="50bdf0eaa7b3716343ae0345a98e1a5f" category="list-text">在目标集群系统上创建 SVM 。</block>
  <block id="2e4b636c74015de6d92a2eb874c15a88" category="list-text">从目标 SVM 中删除 FCP ， iSCSI ， NDMP 和 CIFS 协议。</block>
  <block id="c45e0bc468a9249c2954fa84c21f833e" category="list-text">如果需要，使用 SVM 创建静态路由。</block>
  <block id="f35ea333881cef53fcd944d5a052be9d" category="paragraph">验证是否已成功挂载此卷。</block>
  <block id="71c0d546c4569fd9a5798bdbc9729ab6" category="paragraph">您也可以使用 `volume create` 命令指定卷挂载选项（接合路径）。</block>
  <block id="7ec3f8d8dd165416936305e1ca1530f0" category="list-text">验证默认 NFS 导出策略是否应用于目标 SVM 。</block>
  <block id="f69801ea46df8aed1b26399a9330f459" category="list-text">修改导出策略规则以允许访问目标系统上的 NFS 客户端。</block>
  <block id="9fee35c8bded36b1931a6addb7635a81" category="list-text">验证客户端是否有权访问目标卷。</block>
  <block id="7633c6765c7399ce0f1ecbca891fb11c" category="paragraph">NetApp 建议在 `XCP scan` ， `copy` 和 `sync` 操作期间将源 NFSv3 导出置于只读模式。在 `sync` 操作中，您必须使用相应的值传递 ` -snap` 选项。</block>
  <block id="486e9eb5a73ed3d87e070761d3ceeefe" category="list-text">将源 7- 模式 NFSv3 快照（基本）复制到目标 ONTAP 系统上的 NFSv3 导出。</block>
  <block id="160bb3a75d27ad175143123df09bce76" category="admonition">保留此基本快照以执行进一步的同步操作。</block>
  <block id="97ba1a5f7ee8f9243390e46469b6e8f3" category="list-text">复制完成后，验证源和目标 NFSv3 导出是否具有相同的数据。运行 `XCP verify` 命令。</block>
  <block id="44842ca325a3ba46b3b4703a79fab171" category="paragraph">如果 `verify` 发现源数据与目标数据之间的差异，则摘要中会报告错误 `no such file or directory `。要修复此问题描述，请运行 `XCP sync` 命令将源更改复制到目标。</block>
  <block id="030bc6fe403e876e1c932987ece73d61" category="list-text">在转换之前和期间，再次运行 `verify` 。如果源包含新数据或更新的数据，请执行增量更新。如果存在增量更改，请为这些更改创建一个新的 Snapshot 副本，并使用 ` -snap` 选项传递该快照路径以执行同步操作。</block>
  <block id="b29cfae254be5e3cfc339ed594ea9378" category="paragraph">使用 ` -snap` 选项和快照路径运行 `XCP sync` 命令。</block>
  <block id="2885d0e1370007423656773743ce189b" category="admonition">对于此操作，需要使用基本快照。</block>
  <block id="121dba07a28112a093b812991271c895" category="list-text">NFSv3 客户端主机必须卸载从 7- 模式存储配置的源 NFSv3 导出，并从 ONTAP 挂载目标 NFSv3 导出。此转换需要中断。</block>
  <block id="6db55966f4a2b44c31ed7672f14d023e" category="section-title">将 ACLv4 从 NetApp 7- 模式迁移到 NetApp 存储系统</block>
  <block id="8f81754856c547fbd3e5295b9da06cc7" category="paragraph">本节介绍将源 NFSv4 导出过渡到 ONTAP 系统的分步操作步骤。</block>
  <block id="fd58e84bd534e0ff49a00942e9ee2002" category="admonition">NetApp 假定源 NFSv4 卷已导出并挂载在客户端系统上，并且 XCP 已安装在 Linux 系统上。源系统应为支持 ACL 的 NetApp 7- 模式系统。ACL 迁移仅支持从 NetApp 迁移到 NetApp 。要复制名称中包含特殊字符的文件，请确保源和目标支持 UTF-8 编码语言。</block>
  <block id="88464fae780b488ca9d39f305a3b3777" category="section-title">将源 NFSv4 导出迁移到 ONTAP 的前提条件</block>
  <block id="078b760bc7ad8cae447a095cc53029af" category="paragraph">在将源 NFSv4 导出迁移到 ONTAP 之前，必须满足以下前提条件：</block>
  <block id="abb629da0d811e197b383d473d19f265" category="list-text">目标系统必须配置 NFSv4 。</block>
  <block id="09e4d7a665b5df121af76a08951028cf" category="list-text">NFSv4 源和目标必须挂载在 XCP 主机上。选择 NFS v4.0 以匹配源存储和目标存储，并验证源系统和目标系统上是否已启用 ACL 。</block>
  <block id="c36e1764174e8e6a7791e7afd73f3294" category="list-text">XCP 要求在 XCP 主机上挂载源 / 目标路径以进行 ACL 处理。在以下示例中， `vol1 （ 10.63.5.56 ： /vol1 ）` 已挂载在 ` /mnt/vol1` 路径上：</block>
  <block id="baa4716341f52ff4d0642ca1398e16f1" category="section-title">子目录选项</block>
  <block id="66f63b7de79aaf05b47a1b63467b2a84" category="paragraph">使用子目录的两个选项如下：</block>
  <block id="5d1498ef6a2ee01cb9031bbf8a8dadc4" category="list-text">要使 XCP 在子目录 ` （ /vol1/dir1/DIR11` ）上运行，请在 XCP 主机上挂载完整路径（`10.63.5.56 ： /vol1/dir1/DIR11` ）。</block>
  <block id="39b3225d42725e9616ca3fee7aa7cbb6" category="paragraph">如果未挂载完整路径， XCP 将报告以下错误：</block>
  <block id="84274fa575b6d9b0177512a818215d91" category="list-text">使用子目录语法（ `mount ：子目录 /qtree/.snapshot` ），如以下示例所示：</block>
  <block id="8dd9bb3f47ac0b27a42761c265b0c720" category="paragraph">要将 ACLv4 从 NetApp 7- 模式迁移到 NetApp 存储系统，请完成以下步骤。</block>
  <block id="b2f12804e995a318c2272527efb05774" category="paragraph">验证是否已成功创建 SVM 。</block>
  <block id="b887d08ec971525ffbfec7f19d01d72d" category="list-text">检查默认 NFS 导出策略是否应用于目标 SVM 。</block>
  <block id="1c94e1638450716cd57f55bafd07e60f" category="paragraph">验证是否已修改策略规则。</block>
  <block id="132fa7c123291d5007311a22ff8f5654" category="list-text">在此挂载点挂载目标 NFSv4 导出的卷。</block>
  <block id="c686c09824f51c6e681d87d1deb44c71" category="admonition">NFSv4 卷应导出，但不一定由 NFS 服务器挂载。如果可以挂载这些卷，则 XCP Linux 主机客户端会挂载这些卷。</block>
  <block id="e943b6ad310412b689f42adec28acf3a" category="paragraph">验证是否已创建文件。</block>
  <block id="35ce5d99ee6b9bb871da972e459e7259" category="list-text">在 XCP Linux 客户端主机系统上运行 `XCP show` 命令，查询源 NFSv4 导出。</block>
  <block id="97cc35dcdaf8c5c5fa0e936cd31e9907" category="list-text">扫描源 NFSv4 导出的路径并打印其文件结构的统计信息。</block>
  <block id="5073080976611febfcee79295d42232e" category="paragraph">NetApp 建议在 `XCP scan` ， `copy` 和 `sync` 操作期间将源 NFSv4 导出置于只读模式。</block>
  <block id="f120bcab91519def54b7b66ee0fbecfe" category="list-text">将源 NFSv4 导出复制到目标 ONTAP 系统上的 NFSv4 导出。</block>
  <block id="39ff9cab7c62e62bf182a632271eb700" category="list-text">完成 `copy` 后，验证源和目标 NFSv4 导出是否具有相同的数据。运行 `XCP verify` 命令。</block>
  <block id="977c8a5f0f7f70041a1c6359c72cb1cd" category="paragraph">如果 `verify` 发现源数据与目标数据之间的差异，则摘要中会报告错误 `no such file or directory` 。要修复此问题描述，请运行 `XCP sync` 命令将源更改复制到目标。</block>
  <block id="29aee025cf0bcad3c355bd0aad4516e6" category="admonition">对于此操作，需要使用先前的副本索引名称或编号。</block>
  <block id="ee0fd4f8758695ad7502bee81363478a" category="list-text">要恢复先前中断的 `copy` 操作，请运行 `XCP resume` 命令。</block>
  <block id="cdc35fb8de987dae3f48c142ffcb0686" category="section-title">将 7- 模式 SMB 存储过渡到 ONTAP 以获取 CIFS 数据</block>
  <block id="74efc43b80fa7a84f709780789176e0d" category="paragraph">本节介绍将源 7- 模式 SMB 共享过渡到 ONTAP 系统的分步操作步骤。</block>
  <block id="f6f758220d5d00061aaa03b99e14785b" category="admonition">NetApp 假定 7- 模式和 ONTAP 系统已获得 SMB 许可。此时将创建目标 SVM ，导出源和目标 SMB 共享，并安装 XCP 并获得许可。</block>
  <block id="281c766457d5499048f9440f61957421" category="list-text">扫描 SMB 共享中的文件和目录。</block>
  <block id="95c490ed8cb5d13c961fc2c50c372940" category="list-text">将文件（带或不带 ACL ）从源 SMB 共享复制到目标 SMB 共享。以下示例显示了一个具有 ACL 的副本。</block>
  <block id="dc056263ce0a29568cee559ae8ec35dc" category="admonition">如果没有数据聚合，请使用 storage `aggr create` 命令创建一个新聚合。</block>
  <block id="7c34f7c35c71ba790649c5563408e77e" category="list-text">同步源和目标上的文件。</block>
  <block id="974c1ef10ec8fef5b3ff19989555d061" category="list-text">验证是否已正确复制这些文件。</block>
  <block id="5dc302565fd7f552e134618ee18d2be2" category="summary">此解决方案基于需要根据特定日期复制数据的客户。</block>
  <block id="07f04efd2f421076b9aa06c4fee83be5" category="doc">基于日期的特定数据扫描和复制</block>
  <block id="e0b5216bc931e3e5fd7efb74ad10b1d3" category="paragraph">此解决方案基于需要根据特定日期复制数据的客户。验证以下详细信息：</block>
  <block id="89bddd14a9f02aeace6d5ffadf25e4f3" category="summary">本文档提供了 NetApp XCP 最佳实践准则和基于测试场景的解决方案。这些最佳实践涵盖了内部以及云，文件系统分析，故障排除和 XCP 性能调整的迁移工作流。</block>
  <block id="e7b1326bcbbf0b5513213b2373b5721a" category="doc">TR-4863 ：《 NetApp XCP 最佳实践指南—数据移动，文件迁移和分析》</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">NetApp 公司 Karthikeyan Nagalingam</block>
  <block id="88d20f11fbf1788b5271fcc5d5297a41" category="paragraph">本文档提供了 NetApp XCP 最佳实践准则和基于测试场景的解决方案。这些最佳实践涵盖内部以及云，文件系统分析，故障排除和 XCP 性能调整的迁移工作流。测试场景部分介绍了客户使用情形及其要求，使用 XCP 的 NetApp 解决方案以及为客户带来的优势。</block>
  <block id="7e0710b4cb48030b7a4c065128b88194" category="summary">本节介绍将包含安全信息的 CIFS 数据从源系统迁移到目标 ONTAP 系统的分步操作步骤。</block>
  <block id="82f0875c37eacadc40a7a7fb2a6b6313" category="doc">使用 ACL 将 CIFS 数据从源存储箱迁移到 ONTAP</block>
  <block id="c55bb6c3381ca2d8a4016e387cc62883" category="list-text">创建数据 LIF 以处理 SMB 客户端请求。</block>
  <block id="5368b7f480b92b4a2a9b475e6e9cf953" category="list-text">在 SVM 命名空间中挂载目标数据卷。</block>
  <block id="18f8848c17d02fd34b293885d5d3a215" category="list-text">在目标 SVM 上启动 CIFS 服务。</block>
  <block id="cf1269d629dc2110f2ae65edf8662b79" category="list-text">验证默认导出策略是否应用于目标 SVM 。</block>
  <block id="74e1ca9e0b551a7349207f3d546b9f51" category="list-text">修改导出策略规则以允许访问 CIFS 客户端。</block>
  <block id="3c19a2ac394a25f9ace05db18ad86c8b" category="paragraph">验证是否已修改策略规则。</block>
  <block id="876afc73f4771f46cfc9dba7fb687744" category="list-text">连接到安装了 XCP 的 Windows 客户端系统。浏览到 XCP 安装路径。</block>
  <block id="e73a44af938fa16a4816d3639d2f3b69" category="list-text">在 XCP Windows 客户端主机系统上运行 `XCP show` 命令，以查询源节点 SMB 导出。</block>
  <block id="7132ef955ec5e0151ccd0790da2551d7" category="list-text">运行 `help` 命令进行复制。</block>
  <block id="268b71a144890a49d97f8ca062fd48f9" category="list-text">在目标 ONTAP 系统上，获取需要作为 `backfall-user` 和 `backfall-group` 参数路径的值提供的本地用户和本地组名称列表。</block>
  <block id="ac9ad1198db0fb6f730a1f3aa97c35ab" category="list-text">要将使用 ACL 的 CIFS 数据从源迁移到目标，请使用 ` -acl` 和 ` – backft-user/group` 选项运行 `XCP copy` 命令。</block>
  <block id="a53e836d6264ad1778a4e1a7ae34f58c" category="paragraph">对于 `backfall-user/group` 选项，指定 Active Directory 中的任何用户或组，或者将本地用户 / 组分配给目标系统。</block>
  <block id="9aa080e55cad2c9968cc50de60a3f88e" category="list-text">如果 `XCP copy` 导致错误消息 `error failed to Obtain fallbackt security principal` ，请在 hosts 文件（`C ： \Windows\System32\drivers\etc\hosts` ）中添加目标框。</block>
  <block id="b7ceaa0e08e9de5bf76572a50529f752" category="paragraph">对 NetApp 存储目标框条目使用以下格式。</block>
  <block id="569ccf25ad533b79cf2f639f0326d943" category="list-text">在 hosts 文件中添加目标框条目后，如果仍收到错误消息 `error failed to get backfalling security principal` ，则表示目标系统中不存在用户 / 组。</block>
  <block id="4a909d1b3a171fdcddc8da070e839ecc" category="list-text">使用 `XCP copy` 迁移使用 ACL （包含或不包含根文件夹）的 CIFS 数据。</block>
  <block id="a4ebb620bc1fbff4f93249967cd47f4b" category="paragraph">如果没有根文件夹，请运行以下命令：</block>
  <block id="f6c1a65a9150853333bf43b4a6dc9e5b" category="paragraph">使用根文件夹运行以下命令：</block>
  <block id="dc0b758a04bbb9e380300887d831e4e1" category="summary">本节提供了一些调整参数，这些参数有助于提高 XCP 操作的性能。</block>
  <block id="9db3ca538820d0cfb7b44ef80f16ca98" category="doc">性能调整</block>
  <block id="ec6136417c258c9b7f95c39765c5ca51" category="paragraph">本节提供了一些有助于提高 XCP 操作性能的调整参数：</block>
  <block id="dd10b781bf6dd686a8631401ce0fba96" category="list-text">为了更好地扩展工作负载并将其分布在多个 XCP 实例之间，请拆分每个 XCP 实例的子文件夹以进行迁移和数据传输。</block>
  <block id="37e9b10f81fe31cb6b80609f724b34f8" category="list-text">XCP 可以使用最大的 CPU 资源— CPU 核越多，性能就越好。因此， XCP 服务器中应具有更多 CPU 。我们在实验室中测试了 128 GB RAM 和 48 个核心 CPU ，与 8 个 CPU 和 8 GB RAM 相比，性能更好。</block>
  <block id="a174d00dcd4849e0653429de84c71cde" category="list-text">对于 Azure NetApp Files ，性能因服务级别而异。有关详细信息，请参见下表，其中显示了 Azure NetApp Files 服务级别和性能详细信息。</block>
  <block id="6d59be48f566a73e053e12167b279be5" category="cell">服务级别</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">标准</block>
  <block id="8d5e7e72f12067991186cdf3cb7d5d9d" category="cell">高级版</block>
  <block id="7057376a419b3334cc7b8b7a9f064abb" category="cell">超级</block>
  <block id="0b85467ebafa7ca3c47e82dc38184484" category="cell">吞吐量</block>
  <block id="adcda45ec4de9aeb48e1893272b078d1" category="cell">16 Mbps/ TB （ TB ）</block>
  <block id="93209d2e9d1ed8d87a279cef886b5021" category="cell">64 MBps/TB</block>
  <block id="f646efbbd60d091e92b32611965c4f1c" category="cell">128 MBPS/TB</block>
  <block id="4a9cc851fc41c5762618832386fa4937" category="cell">工作负载类型</block>
  <block id="11969136028e1ffaeed70de5e59bde33" category="cell">通用文件共享，电子邮件和 Web</block>
  <block id="76ab8c335a6bb24396ea1953bac75705" category="cell">BMS ，数据库和应用程序</block>
  <block id="9dab8e594b90062c0612cbb1676234ba" category="cell">延迟敏感型应用程序</block>
  <block id="0a568304277380e4cfb0f2d2abbd99b4" category="cell">性能说明</block>
  <block id="c55268b956eecd1d58f60723a410c808" category="cell">标准性能：每 TB 1 ， 000 次 IOPS （ 16 K I/O ）和 16 Mbps/TB</block>
  <block id="536d2154a9035458ae8efd38b24f3ea7" category="cell">卓越的性能—每 TB 4 ， 000 次 IOPS （ 16 K I/O ）和 64 MBPS/TB</block>
  <block id="91ff77656b0dc231fcbe8f488a15a253" category="cell">极致性能：每 TB 8 ， 000 次 IOPS （ 16 K I/O ）和 128 MBPS/TB</block>
  <block id="121bc30e927e8a3d918fc90c0ec18fee" category="paragraph">您必须根据吞吐量和工作负载类型选择合适的服务级别。大多数客户都从高级级别开始，并根据工作负载更改服务级别。</block>
  <block id="4b1c76979225b75a8e5f476356ed17e8" category="paragraph">基于 NetApp 的 VMware ：您的旅程从这里开始！</block>
  <block id="d7b056332bb039010d62c71ede534471" category="paragraph">如果您已准备好开始对 VMware 环境进行转型，请浏览最新的解决方案概述，查看我们最新的技术解决方案和产品演示。如果您已准备好下一步行动，请与 NetApp 和 VMware 专家社区接洽，帮助您规划和执行数据中心现代化，混合云或容器化应用程序计划。</block>
  <block id="be52ccc9c4dbcee449a6257062c0bcda" category="paragraph">不确定从何处开始？ <block ref="dcd7ec98fb935d9a5fd8ade723a47456" category="inline-link-macro-rx"></block> NetApp 的 VMware 专家成员。</block>
  <block id="27b7a196b8196df4eeee9d21ade20a45" category="inline-link-macro">PDF 格式</block>
  <block id="e2fd99d21fbe7a1b2ed6388c40d48b0f" category="admonition">此页面上显示的内容也可从中下载 <block ref="a182addaadbc8a97de909268c8dc9bf0" category="inline-link-macro-rx"></block>。</block>
  <block id="9d0be07780aeb437025d4b3420d12540" category="sidebar">NetApp XCP 数据迁移</block>
  <block id="68dfe5056c735db544868f482f9f1d6f" category="sidebar">NetApp XCP 最佳实践指南</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="sidebar">客户情形</block>
  <block id="c5071cdf8081474104ef1eee5ec6d784" category="sidebar">使用 ACL 将 CIFS 数据从源存储箱迁移到 ONTAP</block>
  <block id="6be5bc354916244292cf704d8a451541" category="inline-link-macro">视频：使用 Astra 控制中心迁移工作负载—采用 NetApp 的 Red Hat OpenShift</block>
  <block id="c0a8420c339dd9d57d40448c30a749df" category="inline-link-macro">视频：使用 Astra Trident 和 SnapMirror 迁移工作负载—采用 NetApp 的 Red Hat OpenShift</block>
  <block id="7527b11aa1f9aa169a9d6103e9c4c417" category="paragraph">Azure NetApp Files ，速写和 dask 可通过与 Docker 和 Kubernetes 等业务流程工具集成来加快和简化大规模 ML 处理和培训的部署。通过统一端到端数据管道，此解决方案可降低许多高级计算工作负载固有的延迟和复杂性，从而有效地弥补开发和运营之间的差距。在培训阶段，数据科学家可以对大型数据集运行查询，并与其他用户安全地共享数据和算法模型。</block>
  <block id="a93fc9ba708498e20819f22e22ecfa5c" category="paragraph">通过在云中构建端到端分布式培训模型和数据管道，我们展示了与不利用 GPU 加速数据处理和计算框架的传统开源方法相比，工作流总完成时间有两个显著的提升。</block>
  <block id="fcceee9f9e65e4b0d089c6c433f6c191" category="paragraph">NetApp ， Microsoft ，开源业务流程框架和 NVIDIA 的结合，将最新技术作为托管服务集于一身，并具有极大的灵活性，可加快技术采用速度，加快新 AI/ML 应用程序的上市速度。这些高级服务在云原生环境中提供，可以轻松地移植到内部部署和混合部署架构中。</block>
  <block id="b622f3d3bde9c5202a2be0c23982e0b2" category="paragraph">此用例基于公开发布的<block ref="f00b4c49198828625540594bcd2c0e57" category="inline-link-rx"></block> 数据集来自<block ref="3ba217c046bd683ab55f300076736b4a" category="inline-link-rx"></block>。随着 ML 平台和应用程序的最新发展，我们现在非常关注大规模学习。点击率（ CTR ）是指每 100 次在线广告曝光的平均点击次数（以百分比表示）。它已广泛用作各种行业垂直市场和用例的关键指标，包括数字营销，零售，电子商务和服务提供商。使用 CTR 作为潜在客户流量的重要指标的示例包括：</block>
  <block id="d86cf69a8b82547a94ca3f6a307cf9a6" category="inline-link">Google 分析</block>
  <block id="fe123d76ac9bec74ba2056b6a34fbf5d" category="inline-link">AD 排名</block>
  <block id="747d705222dc64c89cfadd75a9792b30" category="list-text">* 数字营销： * 在中<block ref="6c9e2e85af2f8f35c64de5000ebda91e" category="inline-link-rx"></block>，可以使用 CTR 来衡量广告商或商家的关键字，广告和免费列表的表现。如果 CTR 较高，则表明用户发现您的广告和列表很有用且相关。CTR 还有助于实现关键字的预期 CTR ，它是的组成部分<block ref="428c3403a03510f9dc338448b285e764" category="inline-link-rx"></block>。</block>
  <block id="8a2e97f5a0cefdd4b76863bdd3773fb2" category="list-text">* 电子商务： * 除利用外<block ref="8785133d6074d4ab5f5345c36bc35a21" category="inline-link-rx"></block>，电子商务后端至少有一些访客统计信息。虽然这些统计信息乍看起来可能并不有用，但通常很容易阅读，并且可能比其他信息更准确。由此类统计信息组成的第一方数据集属于专有数据集，因此与电子商务销售商，买家和平台最相关。这些数据集可用于设置基准，并通过构建时间序列来与去年和昨天的结果进行比较，以供进一步分析。</block>
  <block id="5737cd832bf93fd33459cf0a04787441" category="list-text">* 零售： * Brick-and-mortar 零售商可以将访客数量和客户数量与 CTR 相关联。客户数量可从其销售点历史记录中查看。零售商网站或广告流量的 CTR 可能会导致上述销售。忠诚度计划是另一个用例，因为从在线广告或其他网站转出的客户可能会加入该计划以获得奖励。零售商可以通过忠诚度计划赢得客户，并记录销售历史记录中的行为，从而构建一个建议系统，该系统不仅可以预测不同类别的消费者购买行为，还可以对优惠券进行个性化设置并减少流失。</block>
  <block id="32c14bcab423a033bf540425e236d3e6" category="list-text">* 服务提供商： * 电信公司和互联网服务提供商拥有大量第一方用户遥测数据，可用于富有洞察力的 AI ， ML 和分析用例。例如，电信可以利用其移动用户每天的 Web 浏览顶级域历史日志来微调现有模型，以生成最新的受众细分，预测客户行为，并与广告商协作发布实时广告，从而获得更好的在线体验。在这种数据驱动型营销工作流中， CTR 是反映转换的一个重要指标。</block>
  <block id="78ae79f63f58a3ac75e77e3a075fd19e" category="inline-link">Trigeo Terabyte 单击 Logs</block>
  <block id="deb698cbe7918324e2e1564708266732" category="paragraph">在数字化营销背景下，<block ref="cc065865c19a3af4babfdf02c1c6b55d" category="inline-link-rx"></block> 现在是评估 ML 平台和算法可扩展性的参考数据集。通过预测点击率，广告宣传者可以选择最有可能对广告做出响应的访客，分析浏览历史记录，并根据用户兴趣显示最相关的广告。</block>
  <block id="5f326be91a09bc93ca87444e834df2a6" category="paragraph">本技术报告中提供的解决方案重点介绍了以下优势：</block>
  <block id="e150c8d445e71cda899957943e39b75f" category="list-text">分布式培训的 dask 并行计算框架</block>
  <block id="ec61531814ab09c5338813eecc764692" category="paragraph">基于快速 AI 和 Azure NetApp Files 构建的端到端工作流展示了随机林模型训练时间大幅缩短两个数量级。与传统的熊猫方法相比，每天处理实际点击日志时，这种改进非常重要，其中每天包含 45 GB 的结构化表格数据（平均）。这相当于一个包含大约 200 亿行的 DataFrame 。我们将在本技术报告中演示集群环境设置，框架和库安装，数据加载和处理，传统培训与分布式培训，可视化和监控，并比较关键的端到端运行时结果。</block>
  <block id="0359d40b3d1a900a1841f1e8bd783cd5" category="doc">TR-4904 ： Azure 中的分布式培训—点击率预测</block>
  <block id="1863627f5be51826024a24014fce26ff" category="sidebar">Azure 中的分布式培训—点击率预测</block>
  <block id="458df51beb3b33cfa61bdc8725403f5b" category="sidebar">Jupyter 笔记本电脑供参考</block>
  <block id="8d7efa937e97b1a8187ff8f122d9732a" category="sidebar">针对基于云的 VMware 部署优化存储</block>
  <block id="5a6bd3a9e0048284caf2b5f521d90959" category="list-text"><block ref="5a6bd3a9e0048284caf2b5f521d90959" category="inline-link-macro-rx"></block></block>
  <block id="2625fb6375d503af481868caf90606c9" category="summary">本节链接到与本技术报告相关的两台 Jupyter 笔记本电脑。</block>
  <block id="91409fc3ebd20becb4eb816cbcceb02e" category="doc">Jupyter 笔记本电脑作为参考</block>
  <block id="cdd5560e07964d04d88721f16446a3b6" category="paragraph">本技术报告涉及两款 Jupyter 笔记本电脑：</block>
  <block id="1490d9a5ddbc6bcbe6cedaa01eb50f99" category="inline-link-macro">* ct-andasrf-colled.ipynb.*</block>
  <block id="562c7333f0fea5590cfeb818a55e6557" category="list-text"><block ref="6f686a9606ae64621340ea0a5e72dfde" category="inline-link-macro-rx"></block> 此笔记本电脑可从 Criteo TB Click Logs 数据集加载第 15 天的数据，将数据处理并格式化到一个熊猫 DataFrame 中，训练一个 Scikit 学习随机林模型，执行预测并计算准确性。</block>
  <block id="c0cb1f1199ae4e4bdfa626e26a5a25cd" category="inline-link-macro">* Criteo_dask_rf.ipynb.*</block>
  <block id="fa93cb17bf7778768ccae778487bf90d" category="list-text"><block ref="01d86d8522c2722466fcbda71181d3ff" category="inline-link-macro-rx"></block> 此笔记本电脑可从 Criteo Terabyte Click Logs 数据集加载第 15 天数据，将数据处理并格式化为 dask cuDF ，训练 dask cuML 随机林模型，执行预测并计算准确性。这种分布式数据和模型处理和培训方法通过利用多个具有 GPU 的员工节点来实现高效率。与传统的 ML 方法相比，处理的数据越多，节省的时间就越多。您可以将此笔记本电脑部署在云，内部或混合环境中，其中 Kubernetes 集群包含不同位置的计算和存储，前提是您的网络设置可以自由移动数据和分发型号。</block>
  <block id="95e5ff389c2796a171f904ad5b9322f6" category="list-text">NetApp 和 VMware Cloud Foundation （ VCF ）</block>
  <block id="81cd1d42ffdb75544144e24cf0f8dc54" category="inline-link-macro">第 1 部分：入门</block>
  <block id="837bbffc16dc6e344470df1114a13c87" category="list-text"><block ref="837bbffc16dc6e344470df1114a13c87" category="inline-link-macro-rx"></block></block>
  <block id="0437c596200f9be8466a3200f5cf2438" category="inline-link-macro">第 2 部分： vcf 和 ONTAP 主存储</block>
  <block id="e361fc9a6477c5857207bca25b3d797f" category="list-text"><block ref="e361fc9a6477c5857207bca25b3d797f" category="inline-link-macro-rx"></block></block>
  <block id="14c9e898417d6b3caceb9c60335c4bb3" category="inline-link-macro">第 3 部分： vcf 和 Element 主体存储</block>
  <block id="aa37de763ea804c1fb3fe637fb6ee5ef" category="list-text"><block ref="aa37de763ea804c1fb3fe637fb6ee5ef" category="inline-link-macro-rx"></block></block>
  <block id="fbbcbe8b70235742e3e6aa656c7815d9" category="inline-link-macro">第 4 部分：适用于 VMware 的 ONTAP 工具和补充存储</block>
  <block id="de8f12d6d2f85119918d1bbb774d43c8" category="list-text"><block ref="de8f12d6d2f85119918d1bbb774d43c8" category="inline-link-macro-rx"></block></block>
  <block id="00d07ce14f227693b9dabba2f52b53a5" category="inline-link-macro">使用基于 NetApp 的云产品开始使用 Azure VMware 解决方案</block>
  <block id="ac66988ead29ba5f4ed32ec3894527e7" category="list-text"><block ref="ac66988ead29ba5f4ed32ec3894527e7" category="inline-link-macro-rx"></block></block>
  <block id="3123a26626e19f387157faf3a8e35e86" category="list-text">您必须对 Red Hat OpenShift 集群具有集群管理员访问权限。</block>
  <block id="abfe00e88b26a267771078e0295b1573" category="admonition">Docker 安装的 Docker 版本必须大于 20.10 ，而 Podman 安装的 Podman 版本必须大于 3.0 。</block>
  <block id="e2f745ac603721ed9903b0acea00d059" category="admonition">如果使用 `kubeadmin` user 登录到专用注册表，请使用 token 代替 password - `podman login -u Ocp-user -p token -tls-verify=false astra-registry.apps.ocp-vmw.cie.netapp.com` 。</block>
  <block id="e4b91f5b748fa6ef8813d2871257b134" category="admonition">或者，您也可以创建服务帐户，分配注册表编辑器和 / 或注册表查看器角色（取决于您是否需要推 / 拉访问），并使用服务帐户的令牌登录到注册表。</block>
  <block id="ad533c54cadd80fbf8f60e58b7d3abd6" category="admonition">如果使用 `kubeadmin` user 登录到专用注册表，请使用 token 代替 password - `docker login -u Ocp-user -p token astra-registry.apps.ocp-vmw.cie.netapp.com` 。</block>
  <block id="4324c8f0a70a221bdde33868774e5a76" category="list-text">编辑 Astra 控制中心操作员 CR `Astra_control_center_operator_deploy.YAML` 这是 Astra 控制中心部署的一组所有资源。在操作员 CR 中，找到 `Acc-operator-controller-manager` 的部署定义，并输入注册表的 FQDN 以及将映像推送到注册表时提供的组织名称（在此示例中为 `astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra` ） 替换文本 `ASTRA_image_regRegistry` 并提供我们刚刚在 `imagePullSecret` 部分中创建的密钥名称。验证操作员的其他详细信息，保存并关闭。</block>
  <block id="0f436b7e192eae471d7abf1265bb4c02" category="list-text">通过浏览 Astra 控制中心的 FQDN 登录到该 GUI 。</block>
  <block id="8b2aacc194c3dc4c36ce93a57e31685c" category="list-text">从当前默认存储类中删除默认标注，并将支持 Trident 的存储类标注为 OpenShift 集群的默认值。</block>
  <block id="53557215e4d209eda16495dbe5f7c505" category="paragraph">+ 注意：如果您使用 `kubeadmin` user 登录到专用注册表，请使用 token 代替密码。</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">本节介绍此 AI 解决方案的技术基础。</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">一流的 NetApp AFF 存储系统支持在边缘进行 AI 推理部署，通过行业领先的性能，卓越的灵活性，云集成和一流的数据管理满足企业级存储需求。NetApp AFF 系统专为闪存设计，可帮助加速，管理和保护业务关键型数据。</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">入门级 NetApp AFF 存储系统基于 FAS2750 硬件和 SSD 闪存介质</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">HA 配置中的两个控制器</block>
  <block id="7df12cd193e8452ed6fc45ca8bcd3771" category="paragraph"><block ref="7df12cd193e8452ed6fc45ca8bcd3771" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">NetApp 入门级 AFF C190 存储系统支持以下功能：</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">最大驱动器数为 24 个 960 GB SSD</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">两种可能的配置：</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">以太网（ 10GbE ）： 4 个 10GBASE-T （ RJ-45 ）端口</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">统一（ 16 Gb FC 或 10GbE ）： 4 个统一目标适配器 2 （ UTA2 ）端口</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">最大有效容量为 50.5 TB</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">对于 NAS 工作负载，一个入门级 AFF C190 系统支持连续读取吞吐量为 4.4 GBps ，延迟为 1 毫秒或更短的小型随机读取吞吐量为 230 K IOPS 。</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp 还提供了其他入门级存储系统，可为大规模部署提供更高的性能和可扩展性。对于 NAS 工作负载，一个入门级 AFF A220 系统支持：</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">顺序读取的吞吐量为 6.2 GBps</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">在延迟不超过 1 毫秒的情况下进行小型随机读取时，可实现 375000 IOPS</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">最大驱动器数为 144 个 960 GB ， 3.8 TB 或 7.6 TB SSD</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220 可扩展到 1 PB 以上的有效容量</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">最大有效容量为 35 PB ，最大横向扩展为 2-24 个节点（ 12 个 HA 对）</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">与 AFF A220 相比，性能提高≥ 45%</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440 ， 000 次 IOPS 随机读取 @1 毫秒</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">基于最新的 NetApp ONTAP 版本 ONTAP 9.8 构建</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">利用两个 25 Gb 以太网实现 HA 和集群互连</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">NetApp E 系列 EF 系统</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">EF 系列是一组入门级和中端全闪存 SAN 存储阵列，可通过 NetApp SANtricity 软件加快数据访问速度，并帮助您更快地从中获得价值。这些系统提供 SAS 和 NVMe 闪存存储，并为您提供经济实惠的至极高 IOPS ， 100 微秒以下的响应时间以及高达 44 GBps 的带宽，使其成为混合工作负载以及 AI 推理和高性能计算（ HPC ）等要求苛刻的应用程序的理想之选。</block>
  <block id="51ffc2dfd09bb521be00106f197d1009" category="paragraph"><block ref="51ffc2dfd09bb521be00106f197d1009" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">支持 32 Gb/16 Gb FC ， 25 Gb/10 Gb iSCSI 和 12 Gb SAS</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">最大有效容量为 96 个驱动器，总容量为 1.5 PB</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">10 Gbps 吞吐量（顺序读取）</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">30 万次 IOPS （随机读取）</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">NetApp EF280 是 NetApp 产品组合中成本最低的全闪存阵列（ AFA ）</block>
  <block id="44114b1635cead15f56735bad0467251" category="section-title">NetApp EF300</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24 个 NVMe SSD 驱动器，总容量为 367 TB</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">扩展选项，总容量为 240 个 NL-SAS HDD ， 96 个 SAS SSD 或两者的组合</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100 GB NVMe/IB ， NVMe/RoCE ， iSE/IB 和 SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32 GB NVMe/FC ， FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">25 GB iSCSI</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20 Gbps （顺序读取）</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670K IOPS （随机读取）</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">NetApp EF 系列 NetApp EF 系列全闪存阵列 EF600 ， F300 ， EF570 和 EF280 产品规格</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">有关详细信息，请参见<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block>。</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">简化数据管理</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">数据管理对于企业 IT 运营至关重要，以便将适当的资源用于应用程序和数据集。ONTAP 具有以下功能，可简化操作并降低总运营成本：</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">* 实时数据缩减和扩展的重复数据删除。 * 数据缩减可减少存储块中浪费的空间，重复数据删除可显著提高有效容量。此适用场景数据存储在本地，并分层到云。</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">* 最低，最高和自适应服务质量（ AQoS ）。 * 细粒度服务质量（ QoS ）控制有助于在高度共享的环境中保持关键应用程序的性能水平。</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool 。 * 此功能可将冷数据自动分层到公有和私有云存储选项，包括 Amazon Web Services （ AWS ）， Azure 和 NetApp StorageGRID Storage 解决方案。有关 FabricPool 的详细信息，请参见 <block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block>。</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">加速和保护数据</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 可提供卓越的性能和数据保护，并通过以下方式扩展这些功能：</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">* 性能和低延迟。 * ONTAP 可提供尽可能高的吞吐量，并尽可能降低延迟。</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* NetApp 卷加密（ NVE ）。 * ONTAP 提供原生卷级加密，并支持板载和外部密钥管理。</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">* 多租户和多因素身份验证。 * ONTAP 支持以最高的安全性级别共享基础架构资源。</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">Future-Proof 基础架构</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 具有以下功能，可满足不断变化的苛刻业务需求：</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">* 无缝扩展和无中断运行。 * ONTAP 支持向现有控制器和横向扩展集群无中断添加容量。客户可以升级到 NVMe 和 32 Gb FC 等最新技术，而无需进行成本高昂的数据迁移或中断。</block>
  <block id="0cee26e8172666a9085f957269fc4b64" category="list-text">* 云连接。 * ONTAP 是云连接最广泛的存储管理软件，可在所有公有云中选择软件定义的存储（ ONTAP Select ）和云原生实例（ NetApp Cloud Volumes Service ）。</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">* 与新兴应用程序集成。 * ONTAP 使用支持现有企业级应用程序的相同基础架构，为下一代平台和应用程序（例如自动驾驶汽车，智能城市和行业 4.0 ）提供企业级数据服务。</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">NetApp E 系列 SANtricity 软件产品规格</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity 旨在为 E 系列混合闪存和 EF 系列全闪存阵列提供行业领先的性能，可靠性和精简性。为繁重工作负载应用程序（包括数据分析，视频监控以及备份和恢复）实现 E 系列混合闪存和 EF 系列全闪存阵列的最高性能和利用率。借助 SANtricity ，可以在存储保持联机状态的同时完成配置调整，维护，容量扩展和其他任务。SANtricity 还提供卓越的数据保护，主动监控和认证安全性—所有这些功能均可通过易于使用的机载 System Manager 界面进行访问。要了解更多信息，请参见<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block>。</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">性能优化</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">经过性能优化的 SANtricity 软件可为您的所有数据分析，视频监控和备份应用程序提供具有高 IOPS ，高吞吐量和低延迟的数据。提高高 IOPS ，低延迟应用程序和高带宽，高吞吐量应用程序的性能。</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">最大限度地延长正常运行时间</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">在存储保持联机的情况下完成所有管理任务。在不中断 I/O 的情况下调整配置，执行维护或扩展容量借助自动化功能，联机配置，最先进的动态磁盘池（ Dynamic Disk Pool ， DPP ）技术等实现同类最佳的可靠性。</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">请轻松休息</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">SANtricity 软件可通过易于使用的机载 System Manager 界面提供卓越的数据保护，主动监控和认证安全性。简化存储管理任务。获得对所有 E 系列存储系统进行高级调整所需的灵活性。随时随地管理您的 NetApp E 系列系统。我们基于 Web 的盒装界面简化了您的管理工作流。</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block> NetApp 是适用于 Docker 和 Kubernetes 的开源动态存储编排程序，可简化永久性存储的创建，管理和使用。Trident 是 Kubernetes 原生应用程序，直接在 Kubernetes 集群中运行。借助 Trident ，客户可以将 DL 容器映像无缝部署到 NetApp 存储上，并为 AI 容器部署提供企业级体验。Kubernetes 用户（例如 ML 开发人员和数据科学家）可以创建，管理和自动化流程编排和克隆，从而充分利用 NetApp 技术提供的 NetApp 高级数据管理功能。</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="section-title">联想 ThinkSystem 服务器</block>
  <block id="e76fa728781968dd4a707e2d3b1d8108" category="paragraph">联想 ThinkSystem 服务器采用创新的硬件，软件和服务，可解决客户当前面临的挑战，并提供一种循序渐进的模块化设计方法来应对未来的挑战。这些服务器利用同类最佳的行业标准技术以及联想的差异化创新技术，为 x86 服务器提供最大的灵活性。</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">部署联想 ThinkSystem 服务器的主要优势包括：</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">高度可扩展的模块化设计，可随业务发展而扩展</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">行业领先的弹性，可节省数小时的成本高昂的计划外停机时间</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">快速闪存技术可实现更低的延迟，更快的响应速度以及更智能的实时数据管理</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">在 AI 领域，联想正在采取切实可行的方法帮助企业了解 ML 和 AI 的优势并将其用于工作负载。联想客户可以在联想 AI 创新中心探索和评估联想 AI 产品，以充分了解其特定用例的价值。为了缩短实现价值的时间，这种以客户为中心的方法可以为客户提供解决方案开发平台的概念验证，这些平台已准备就绪，可供 AI 使用并进行优化。</block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="section-title">联想 ThinkSystem SE350 边缘服务器</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">通过边缘计算，可以在将 IoT 设备中的数据发送到数据中心或云之前在网络边缘对其进行分析。如下图所示，联想 ThinkSystem SE350 专为满足边缘部署的独特要求而设计，采用紧凑的加固型环境加固外形，重点关注灵活性，连接性，安全性和远程易管理性。</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">SE350 采用 Intel Xeon D 处理器，可以灵活地支持边缘 AI 工作负载的加速，专为应对数据中心以外各种环境中服务器部署的挑战而构建。</block>
  <block id="b739a166d96ffd72ac4d456012bfbe21" category="paragraph"><block ref="b739a166d96ffd72ac4d456012bfbe21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="paragraph"><block ref="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="section-title">MLPerf</block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">MLPerf 推理 v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf 是用于评估 AI 性能的行业领先基准套件。它涵盖应用 AI 的许多方面，包括图像分类，对象检测，医学影像和自然语言处理（ NLP ）。在此验证中，我们使用了推理 v0.7 工作负载，这是此验证完成时 MLPerf 推理的最新迭代。。<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> 套件包括四个适用于数据中心和边缘系统的新基准：</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">Transformers （ Bert ）提供的 * 双向编码器表示法经过微调，可使用 squad 数据集回答问题。</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">* 深度学习建议模式（ DLRM ）是一种个性化和建议模式，经过培训可优化点击率（ CTR ）。</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">* 3D U-Net.* 3D U-Net 架构接受过有关脑肿瘤分段（ Bras ）数据集的培训。</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">* RNN-T.* 经常性神经网络传感器（ RNNP-T ）是一种自动语音识别（ Automatic Speech Recognition ， ASR ）模型，该模型经过部分 LibriSpeech 的训练。MLPerf 推理结果和代码已公开发布，并已获得 Apache 许可证。MLPerf 推理具有一个 Edge 分支，可支持以下情形：</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">* 单一流。 * 此场景模拟响应能力是关键因素的系统，例如在智能手机上执行脱机 AI 查询。各个查询将发送到系统并记录响应时间。结果将报告所有响应的 90 百分位延迟。</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">* 多流。 * 此基准测试适用于处理来自多个传感器的输入的系统。在测试期间，系统会按固定的时间间隔发送查询。会施加 QoS 限制（允许的最大延迟）。此测试将报告系统在满足 QoS 限制的情况下可以处理的流数量。</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">* 脱机。 * 这是涉及批处理应用程序的最简单情形，指标是每秒样本吞吐量。系统可以使用所有数据，基准测试可测量处理所有样本所需的时间。</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="c953c121914b99f83398f20ab2160ed1" category="paragraph">联想已发布了本文档中使用的服务器 SE350 与 T4 的 MLPerf 推理得分。有关结果，请参见<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> 在条目 #0.7-145 的 " 边缘，封闭分区 " 一节中。</block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">AI 驱动的自动化和边缘计算是帮助业务组织实现数字化转型并最大限度地提高运营效率和安全性的领先方法。借助边缘计算，数据处理速度更快，因为它不必往返于数据中心。因此，将数据来回发送到数据中心或云的相关成本会降低。</block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">AI 驱动的自动化和边缘计算是帮助业务组织实现数字化转型并最大限度地提高运营效率和安全性的领先方法。借助边缘计算，数据处理速度更快，因为它不必往返于数据中心。因此，将数据来回发送到数据中心或云的相关成本会降低。如果企业必须使用部署在边缘的人工智能推理模型近乎实时地做出决策，则降低延迟和提高速度将非常有用。</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">NetApp 存储系统可提供与本地 SSD 存储相同或更好的性能，并为数据科学家，数据工程师， AI/ML 开发人员以及业务或 IT 决策者带来以下优势：</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">在 AI 系统，分析和其他关键业务系统之间轻松共享数据。这种数据共享可减少基础架构开销，提高性能并简化整个企业的数据管理。</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">可独立扩展的计算和存储，最大限度地降低成本并提高资源利用率。</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">利用集成的 Snapshot 副本和克隆简化开发和部署工作流，实现瞬时且节省空间的用户工作空间，集成版本控制和自动化部署。</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">企业级数据保护，可实现灾难恢复和业务连续性。本文档中介绍的 NetApp 和联想解决方案是一种灵活的横向扩展架构，非常适合在边缘进行企业级 AI 推理部署。</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">J.Falkanger ，高级联想 HPC &amp; AI 解决方案经理</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">NetApp 技术营销工程师 Dave Arnette</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">NetApp E 系列 AI 解决方案技术主管 Joey Parnell</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">NetApp QA 工程师 Cody Harryman</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">NetApp AFF A 系列阵列产品页面</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">NetApp ONTAP 数据管理软件— ONTAP 9 信息库</block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727 ：《 NetApp EF 系列简介》</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">NetApp E 系列 SANtricity 软件产品规格</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">适用于容器的 NetApp 持久存储— NetApp Trident</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">TensorFlow 基准测试</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">联想 ThinkSystem DM5100F 统一闪存存储阵列</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">初始版本。</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">版本 2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">2021年10月</block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">您可以调整用于验证的设置，以适合其他使用情形。</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">架构规模估算选项</block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">计算服务器</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">我们使用的是 Intel Xeon D-2123IT CPU ，这是 SE350 支持的最低 CPU 级别，具有四个物理核心和 60 瓦 TDP 。虽然服务器不支持更换 CPU ，但可以订购功能更强大的 CPU 。支持的最大 CPU 是 Intel Xeon D-2183IT ， 16 核， 100 瓦，运行频率为 2.20 GHz 。这样可以显著提高 CPU 计算能力。虽然 CPU 本身并不是运行推理工作负载的瓶颈，但它有助于处理数据以及执行与推理相关的其他任务。目前， NVIDIA T4 是唯一可用于边缘使用情形的 GPU ；因此，目前无法升级或降级 GPU 。</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">共享存储</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">在测试和验证中，我们在本文档中使用了 NetApp AFF C190 系统，该系统的最大存储容量为 50.5 TB ，连续读取的吞吐量为 4.4 GBps ，小型随机读取的 IOPS 为 230k ，经证实非常适合边缘推理工作负载。</block>
  <block id="bb33c803e43b816786d862bbbbf2c824" category="paragraph">但是，如果您需要更多存储容量或更快的网络速度，则应使用 NetApp AFF A220 或<block ref="03f94a30ec5c979321fdd9a1ba99a1c6" category="inline-link-rx"></block> 存储系统此外， NetApp EF280 系统的最大容量为 1.5 PB ，带宽为 10 Gbps ，也用于此解决方案验证。如果您希望使用更高带宽获得更多存储容量，<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> 可以使用。</block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">本节介绍用于验证此解决方案的测试过程。</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">测试操作步骤</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">操作系统和 AI 推理设置</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">code</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">对于 AFF C190 ，我们使用支持 NVIDIA GPU 的 Ubuntu 18.04 和 Docker ，并使用 MLPerf<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> 在联想提交到 MLPerf 推理 v0.7 的过程中提供。</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">对于 EF280 ，我们将 Ubuntu 20.04 与 NVIDIA 驱动程序结合使用，并将 Docker 与 NVIDIA GPU 和 MLPerf 结合使用<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> 在联想提交到 MLPerf 推理 v1.1 的过程中提供。</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">要设置 AI 推理，请执行以下步骤：</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">在使用本地数据进行测试时，您应在共享存储上共享此目录以供网络存储使用情形使用，或者在本地磁盘上共享此目录。</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">以下命令全部从正在运行的 Docker 容器中执行：</block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">要运行推理工作负载，请运行以下命令（一个命令）：</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">AI 推理运行</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">执行了三种类型的运行：</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">使用本地存储的单服务器 AI 推理</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">使用网络存储的单服务器 AI 推理</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">使用网络存储的多服务器 AI 推理</block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">本节介绍测试的配置，网络基础架构， SE350 服务器以及存储配置详细信息。</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">测试配置</block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">下图显示了测试配置。我们使用了 NetApp AFF C190 存储系统和两个联想 ThinkSystem SE350 服务器（每个服务器都有一个 NVIDIA T4 加速器）。这些组件通过 10GbE 网络交换机进行连接。网络存储包含验证 / 测试数据集和经过预先培训的模型。这些服务器可提供计算功能，并可通过 NFS 协议访问存储。</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">本节介绍测试的配置，网络基础架构， SE350 服务器以及存储配置详细信息。下表列出了解决方案架构的基本组件。</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">2 个 SE350 服务器，每个服务器具有一个 NVIDIA T4 GPU 卡</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">每个服务器都包含一个 Intel Xeon D-2123IT CPU ，其中四个物理核心运行速度为 2.20GHz ，并具有 128 GB RAM</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">入门级 NetApp AFF 存储系统（ HA 对）</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">NetApp ONTAP 9 软件</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24 个 960 GB SSD</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">每个控制器一个接口组，挂载点有四个逻辑 IP 地址</block>
  <block id="1a538c197da3186f1eba50d82572dc34" category="paragraph"><block ref="1a538c197da3186f1eba50d82572dc34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">下表列出了存储配置：具有 2RU 的 AFF C190 ， 24 个驱动器插槽。</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">控制器</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">聚合</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">FlexGroup 卷</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">聚合大小</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">卷大小</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">操作系统挂载点</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">控制器 1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">aggr1.</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netapplenovo_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42 TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15 TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/NetApp_Lenovo ， fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">控制器 2.</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Aggr2.</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">/netappLenovo AI_fg 文件夹包含用于模型验证的数据集。</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">下图显示了测试配置。我们使用了 NetApp EF280 存储系统和两个联想 ThinkSystem SE350 服务器（每个服务器都有一个 NVIDIA T4 加速器）。这些组件通过 10GbE 网络交换机进行连接。网络存储包含验证 / 测试数据集和经过预先培训的模型。这些服务器可提供计算功能，并可通过 NFS 协议访问存储。</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">下表列出了 EF280 的存储配置。</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">卷组</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">Volume</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDP 大小</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">连接方法</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">卷 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16 TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 到 iSCSI LUN 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">第 2 卷</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 到 iSCSI LUN 1</block>
  <block id="43fa57e4031b0f759153c9c9fa49e6ed" category="paragraph"><block ref="43fa57e4031b0f759153c9c9fa49e6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="290612199861c31d1036b185b4e69b75" category="doc">摘要</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">高级驾驶辅助系统（ ADAS ），行业 4.0 ，智能城市和物联网（ IoT ）等多种新兴应用场景需要在近乎零的延迟下处理持续数据流。本文档介绍了一种计算和存储架构，用于在边缘环境中为 NetApp 存储控制器和联想 ThinkSystem 服务器部署基于 GPU 的人工智能（ AI ）推理。本文档还提供了行业标准 MLPerf 推理基准测试的性能数据，用于评估配备 NVIDIA T4 GPU 的边缘服务器上的各种推理任务。我们对脱机，单流和多流推理情形的性能进行了调查，并显示具有经济高效的共享网络存储系统的架构具有高性能，为多个边缘服务器的数据和模型管理提供了一个中心。</block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">我们会运行大量测试来评估建议的架构的性能。有六种不同的工作负载（图像分类，对象检测（小），对象检测（大），医学影像，语音到文本， 和自然语言处理（ NLP ），您可以在三种不同的情形下运行：脱机，单流和多流。</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">测试结果</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">最后一种情形仅适用于映像分类和对象检测。</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">这样可以提供 15 个可能的工作负载，这些工作负载都在三种不同的设置下进行了测试：</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">单个服务器 / 本地存储</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">单个服务器 / 网络存储</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">多服务器 / 网络存储</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">以下各节将介绍这些结果。</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">AFF 脱机情形中的 AI 推理</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">在这种情况下，服务器可以使用所有数据，并测量了处理所有样本所需的时间。我们会将带宽报告为每秒样本数作为测试结果。如果使用了多个计算服务器，则会报告所有服务器的总带宽总和。下图显示了所有这三种使用情形的结果。对于双服务器情形，我们会报告两个服务器的总带宽。</block>
  <block id="d39bc80b598327ae50c15f64c44bb6ea" category="paragraph"><block ref="d39bc80b598327ae50c15f64c44bb6ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">结果显示，网络存储不会对性能产生负面影响，更改极少，对于某些任务，未找到任何结果。添加第二台服务器时，总带宽恰好是两倍，或者最差情况下，更改率小于 1% 。</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">在 AFF 的单个流方案中进行 AI 推理</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">此基准测试可测量延迟。对于多个计算服务器案例，我们会报告平均延迟。下图显示了这组任务的结果。对于双服务器案例，我们会报告两个服务器的平均延迟。</block>
  <block id="01f3906715186988e276bc34ebc661c0" category="paragraph"><block ref="01f3906715186988e276bc34ebc661c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">结果再次表明，网络存储足以处理这些任务。在一台服务器的情况下，本地存储与网络存储之间的差别很小或没有差别。同样，当两个服务器使用相同的存储时，两个服务器上的延迟保持不变或变化量非常小。</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">在 AFF 的多流方案中进行 AI 推理</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">在这种情况下，结果是系统在满足 QoS 限制的情况下可以处理的流数量。因此，结果始终为整数。对于多个服务器，我们会报告所有服务器上的流总数。并非所有工作负载都支持此方案，但我们已执行了这些工作负载。下图总结了我们的测试结果。对于双服务器案例，我们会报告两个服务器的流总数。</block>
  <block id="758b60f43cbc650fded1dcf9be428fa5" category="paragraph"><block ref="758b60f43cbc650fded1dcf9be428fa5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">结果显示了设置的完美性能—本地存储和网络存储的结果相同，添加第二个服务器会使建议设置可以处理的流数量增加一倍。</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">EF 的测试结果</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">我们会运行大量测试来评估建议的架构的性能。有六种不同的工作负载（图像分类，对象检测（小），对象检测（大），医学影像，语音到文本， 和自然语言处理（ NLP ）），这两种情况下运行：脱机和单流。以下各节将介绍这些结果。</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">EF 脱机情形中的 AI 推理</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">在这种情况下，服务器可以使用所有数据，并测量了处理所有样本所需的时间。我们会将带宽报告为每秒样本数作为测试结果。对于单节点运行，我们会报告两个服务器的平均值，而对于两个服务器运行，我们会报告所有服务器的总带宽总和。下图显示了使用情形的结果。</block>
  <block id="8e793f971410e2b57df427d1305ee0a2" category="paragraph"><block ref="8e793f971410e2b57df427d1305ee0a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">在一个流场景中对 EF 进行 AI 推理</block>
  <block id="5656e3a262dfb3d6e1cba96551717de0" category="paragraph"><block ref="5656e3a262dfb3d6e1cba96551717de0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">本文档介绍了一种计算和存储架构，用于在边缘环境中针对新兴应用程序场景在 NetApp 存储控制器和联想 ThinkSystem 服务器上部署基于 GPU 的人工智能（ AI ）推理。</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886 ：《前沿人工智能推理—采用联想 ThinkSystem 的 NetApp —解决方案设计》</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">NetApp 公司 Sathish Thyagarajan ，联想公司 Mirosav Hodak</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">企业越来越多地在网络边缘生成海量数据。为了从智能传感器和物联网数据中获得最大价值，企业正在寻找支持边缘计算的实时事件流式解决方案。因此，在数据中心以外的边缘执行计算要求苛刻的作业的情况越来越多。AI 推理是这一趋势的推动因素之一。边缘服务器可以为这些工作负载提供足够的计算能力，尤其是在使用加速器时，但有限的存储通常是问题描述，尤其是在多服务器环境中。在本文档中，我们将介绍如何在边缘环境中部署共享存储系统，以及该系统如何在不影响性能的情况下为 AI 推理工作负载带来优势。</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">本文档介绍了边缘 AI 推理的参考架构。它将多个联想 ThinkSystem 边缘服务器与一个 NetApp 存储系统相结合，创建了一个易于部署和管理的解决方案。本指南旨在为各种情形下的实际部署提供一个基线指南，例如，在工厂车间安装多个摄像头和工业传感器，零售交易中的销售点（ POS ）系统或用于识别自动驾驶车辆中的视觉异常的完全自驾（ FSD ）系统。</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">本文档介绍了对由联想 ThinkSystem SE350 边缘服务器和入门级 NetApp AFF 和 EF 系列存储系统组成的计算和存储配置的测试和验证。这些参考架构可为 AI 部署提供高效且经济高效的解决方案，同时还可通过 NetApp ONTAP 和 NetApp SANtricity 数据管理软件提供全面的数据服务，集成数据保护，无缝可扩展性以及云连接数据存储。</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">本文档面向以下受众：</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">希望在边缘将 AI 产品化的业务主管和企业架构师。</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">数据科学家，数据工程师，人工智能 / 机器学习（ AI / 机器学习， ML ）研究人员和人工智能系统开发人员。</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">设计用于开发 AI/ML 模型和应用程序的解决方案的企业架构师。</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">数据科学家和 AI 工程师正在寻找部署深度学习（ DL ）和 ML 模型的高效方法。</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">边缘设备管理器和边缘服务器管理员，负责部署和管理边缘推理模型。</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">解决方案架构</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">边缘计算设备对从摄像机，传感器等接收的数据执行推理。</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">一种可用于多种用途的共享存储元素：</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">为推理模型和执行推理所需的其他数据提供一个中央位置。计算服务器可以直接访问存储，并在网络中使用推理模型，而无需将其复制到本地。</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">此处推送更新的型号。</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">对边缘服务器接收的输入数据进行归档，以供日后分析。例如，如果边缘设备连接到摄像机，则存储元素会保留摄像机捕获的视频。</block>
  <block id="45d9a14c8d568ce70d22acbde8373657" category="paragraph"><block ref="45d9a14c8d568ce70d22acbde8373657" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">红色</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">蓝色</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">联想计算系统</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">NetApp AFF 存储系统</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">边缘设备对来自摄像机，传感器等的输入执行推理。</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">共享存储，用于存放边缘设备的推理模型和数据，以供日后分析。</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">NetApp 和联想解决方案具有以下主要优势：</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">GPU 加快了边缘计算速度。</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">部署从共享存储提供支持和管理的多个边缘服务器。</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">强大的数据保护功能，可满足低恢复点目标（ RPO ）和恢复时间目标（ RTO ）的要求，而不会丢失任何数据。</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">利用 NetApp Snapshot 副本和克隆优化数据管理，以简化开发工作流。</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">如何使用此架构</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">本文档将验证建议架构的设计和性能。但是，我们尚未测试某些软件级别的组件，例如容器，工作负载或模型管理以及与内部云或数据中心的数据同步，因为它们是特定于部署情形的。此处有多种选择。</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">解决方案区域</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">AI 推理和边缘计算的主要优势是设备能够在无延迟的情况下以高质量计算，处理和分析数据。本文档中需要介绍的边缘计算用例太多，但下面是几个突出的示例：</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">汽车：自动驾驶汽车</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">典型的边缘计算图示位于自动驾驶汽车（ AV ）中的高级驾驶辅助系统（ ADAS ）中。无人驾驶汽车中的 AI 必须快速处理来自摄像机和传感器的大量数据，才能成为成功的安全驱动器。在对象和人类之间进行解释所花费的时间过长可能意味着生命或死亡，因此能够尽可能接近车辆处理数据至关重要。在这种情况下，一个或多个边缘计算服务器处理来自摄像机，雷达， LIDAR 和其他传感器的输入，而共享存储则保存推理模型并存储来自传感器的输入数据。</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">医疗保健：患者监控</block>
  <block id="a5031cd8ea18cb91370c532194ecd58e" category="paragraph">AI 和边缘计算的最大影响之一是，它能够在家庭护理和集中护理部门（ ICU ）中增强对慢性病患者的持续监控。监控 Insulin 级别，呼吸，神经活动，心率和消化系统功能的边缘设备中的数据需要即时分析数据，必须立即对这些数据执行操作，因为拯救生命的行动时间有限。</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">零售：无收银员付款</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">边缘计算可以为 AI 和 ML 提供支持，帮助零售商缩短结账时间并增加流量。无收银员系统支持各种组件，例如：</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">身份验证和访问。将物理购物者连接到经过验证的帐户并允许访问零售空间。</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">清单监控。使用传感器， RFID 标签和计算机视觉系统帮助确认买家选择或取消选择商品。</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">此处，每个边缘服务器都会处理每个签出计数器，而共享存储系统则充当一个中央同步点。</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">金融服务：信息亭的人员安全和防止欺诈</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">银行组织正在使用 AI 和边缘计算来创新和打造个性化的银行体验。利用实时数据分析和人工智能推理的交互式信息亭现在不仅可以帮助客户提取资金，还可以通过从摄像机捕获的图像主动监控信息亭，以识别对人类安全或欺诈行为的风险。在这种情况下，边缘计算服务器和共享存储系统连接到交互式信息亭和摄像机，以帮助银行使用 AI 推理模型收集和处理数据。</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">制造业：行业 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">第四次工业革命（工业 4.0 ）已经开始，同时也出现了 Smart Factory 和 3D 打印等新兴趋势。为迎接数据主导的未来，大规模机器到机器（ M2M ）通信和物联网已集成在一起，可提高自动化程度，无需人工干预。制造业已经高度自动化，增加 AI 功能是长期趋势的自然延续。AI 可实现自动化操作，借助计算机视觉和其他 AI 功能，可以实现自动化操作。您可以自动执行质量控制或依赖于人类远见或决策的任务，以便更快地分析工厂车间内装配线上的材料，从而帮助制造工厂满足所需的 ISO 安全和质量管理标准。此处，每个计算边缘服务器都连接到一组传感器，用于监控制造过程，更新的推理模型会根据需要推送到共享存储。</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">电信：防锈检测，塔式检查和网络优化</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">电信行业使用计算机视觉和人工智能技术来处理图像，这些图像可自动检测到是否存在防腐问题，并识别含有防腐问题的单元塔，因此需要进一步检查。近年来，使用无人机图像和 AI 模型来识别塔中不同的区域，以分析防腐，表面裂纹和防腐的情况有所增加。对 AI 技术的需求继续增长，这些技术可以高效地检查电信基础架构和单元塔，定期评估其降级情况，并在需要时及时修复。</block>
  <block id="50dba7db75064ae2e0beea487226ed46" category="paragraph">此外，电信领域另一个新兴的使用情形是，使用 AI 和 ML 算法预测数据流量模式，检测支持 5G 的设备，以及自动化和增强多输入和多输出（ MIMG ）能源管理。在无线电塔上使用了 MIMO 硬件来增加网络容量，但这会带来额外的能源成本。在单元站点上部署的 ML 型号的 "MIMO 休眠模式 " 可以预测是否高效使用了无线电，并有助于降低移动网络运营商（ MNO ）的能耗成本。AI 推理和边缘计算解决方案可帮助 MNO 减少来回传输到数据中心的数据量，降低 TCO ，优化网络运营并提高最终用户的整体性能。</block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">本文档遵循 MLPerf 推理 v0.7 代码， MLPerf 推理 v1.1 代码和规则。我们运行的基准测试是为在边缘进行推理而设计的，如本节所示的表中所定义。</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">测试计划</block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">rules</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">区域</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">任务</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">QSL 大小</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">质量</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">多流延迟限制</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">愿景</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">映像分类</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNet （ 224x224 ）</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">FP32 的 99%</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50 毫秒</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">对象检测（大型）</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD - ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">可可可（ 1200 x 1200 ）</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66 毫秒</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">对象检测（小型）</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD — MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">可可可（ 300 x 300 ）</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">医学影像分段</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">Brats 2019 （ 224x224x160 ）</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">FP32 的 99% 和 99.9%</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">不适用</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">语音</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">语音到文本</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Libraispeech 开发清理</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">language</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">语言处理</block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="cell">Bert</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">Sad v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">场景</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">映像分类</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">单流，脱机，多流</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">单个流，脱机</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">语音到文本</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">我们使用在此验证中开发的网络存储架构执行了这些基准测试，并将结果与先前提交给 MLPerf 的边缘服务器上本地运行的结果进行了比较。比较结果是，确定共享存储对推理性能有多大影响。</block>
  <block id="012b603d852affe4779f095a5c59f0c5" category="summary">公有云的灵活性，实现价值的时间和成本节省都是企业采用公有云进行数据库应用程序开发和测试的有意义的价值主张。SnapCenter 是快速实现这一目标的最佳工具。SnapCenter 不仅可以在内部保护您的生产数据库，还可以在公有云中快速克隆副本以进行应用程序开发或代码测试，同时只需极少的额外存储。下面详细介绍了使用该工具的分步过程。</block>
  <block id="38da6679588aeb2754e14dd58994685e" category="doc">用于将开发 / 测试容量激增到云的工作流</block>
  <block id="4d8a5b6bc9c43ab79e376d1aa4d83217" category="paragraph">对于采用公有云进行数据库应用程序开发和测试的企业而言，公有云的灵活性，价值实现时间和成本节省都是有意义的价值主张。SnapCenter 是实现这一目标的最佳工具。SnapCenter 不仅可以在内部保护生产数据库，而且还可以在公有云中快速克隆副本以进行应用程序开发或代码测试，同时只需极少的额外存储。下面详细介绍了使用此工具的分步过程。</block>
  <block id="b47b42841be2e173707ab5884714970b" category="section-title">从复制的 Snapshot 备份克隆 Oracle 数据库以进行开发 / 测试</block>
  <block id="8d90529d1117b8d3781bd6781acf4e91" category="list-text">使用适用于 Oracle 的数据库管理用户 ID 登录到 SnapCenter 。导航到资源选项卡，其中显示了受 SnapCenter 保护的 Oracle 数据库。</block>
  <block id="a95ff2a2ae2905b0bb3bd0efa211a040" category="paragraph"><block ref="a95ff2a2ae2905b0bb3bd0efa211a040" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d539d2e9659870aa79747206fac4769" category="list-text">单击备份拓扑和详细视图的预期内部数据库名称。如果启用了二级复制位置，则会显示链接镜像备份。</block>
  <block id="20111f4a74a9c065157aa13379000a73" category="paragraph"><block ref="20111f4a74a9c065157aa13379000a73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4a9c1f33e524696d6f3adebf89947bb" category="list-text">通过单击镜像备份切换到镜像备份视图。然后显示二级镜像备份。</block>
  <block id="e1cbaea95bcc154ccf9e8aece7fc73b3" category="paragraph"><block ref="e1cbaea95bcc154ccf9e8aece7fc73b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4726a244c3941457e8f62b49c83d35d1" category="list-text">选择要克隆的镜像二级数据库备份副本，并按时间和系统更改编号或 SCN 确定恢复点。通常，恢复点应是完整数据库备份时间的末尾，或者要克隆的 SCN 。确定恢复点后，必须挂载所需的日志文件备份以进行恢复。日志文件备份应挂载到要托管克隆数据库的目标数据库服务器。</block>
  <block id="81d132cd1ae26e007bb608e5f8609288" category="paragraph"><block ref="81d132cd1ae26e007bb608e5f8609288" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2dc441031605bf54d78fde13b3efc3c" category="paragraph"><block ref="b2dc441031605bf54d78fde13b3efc3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22a17e5abcfc4b5e70ebdea098cd1891" category="admonition">如果启用了日志修剪，并且恢复点扩展到上次日志修剪之后，则可能需要挂载多个归档日志备份。</block>
  <block id="e9606676533bbe916f4b4b6824eac195" category="list-text">突出显示要克隆的完整数据库备份副本，然后单击克隆按钮以启动数据库克隆工作流。</block>
  <block id="48493c19ee97a291cd320501daf5c721" category="paragraph"><block ref="48493c19ee97a291cd320501daf5c721" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c06d82b497809fcc0fd06d00c6d91a5" category="list-text">为完整的容器数据库或 CDB 克隆选择正确的克隆数据库 SID 。</block>
  <block id="f6ee6a459784097119ec1eee6224152e" category="paragraph"><block ref="f6ee6a459784097119ec1eee6224152e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2c50a030b1c5313fca09568edf8c0f9" category="list-text">选择云中的目标克隆主机，数据文件，控制文件和重做日志目录将通过克隆工作流创建。</block>
  <block id="323554a005f5e77dfaa765ea81e645be" category="paragraph"><block ref="323554a005f5e77dfaa765ea81e645be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="701f017aeafb71656cf2bc3a9bd34862" category="list-text">无凭据名称用于基于操作系统的身份验证，这会使数据库端口变得不相关。按照目标克隆数据库服务器中的配置填写正确的 Oracle 主目录， Oracle 操作系统用户和 Oracle 操作系统组。</block>
  <block id="c5237b674d4a9cd38d44c5e546cc51d4" category="paragraph"><block ref="c5237b674d4a9cd38d44c5e546cc51d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26a911f3c85fc3c73d79253e65bf30e3" category="list-text">指定克隆操作前要运行的脚本。更重要的是，可以在此处调整或定义数据库实例参数。</block>
  <block id="56774e452bc62021e52de3e3fea844a2" category="paragraph"><block ref="56774e452bc62021e52de3e3fea844a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09d7240367714707474d63a3a574222b" category="list-text">按日期和时间或 SCN 指定恢复点。直到 " 取消 " 将数据库恢复到可用的归档日志为止。从挂载归档日志卷的目标主机指定外部归档日志位置。如果目标服务器 Oracle 所有者与内部生产服务器不同，请验证目标服务器 Oracle 所有者是否可以读取归档日志目录。</block>
  <block id="6cb86841376102e5b8924f9909b8f570" category="paragraph"><block ref="6cb86841376102e5b8924f9909b8f570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70b171a9c984de6358afb3557fe84586" category="paragraph"><block ref="70b171a9c984de6358afb3557fe84586" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a752afaf144d06159ca3eec8bb23455f" category="list-text">如果需要，配置 SMTP 服务器以发送电子邮件通知。</block>
  <block id="b30b70196320d22207ea0d5d95d2c841" category="paragraph"><block ref="b30b70196320d22207ea0d5d95d2c841" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0421be6f676ac1ddace9e39eeeb54f0f" category="list-text">克隆摘要。</block>
  <block id="a930a442bf914f516109fbb28bf2fbd1" category="paragraph"><block ref="a930a442bf914f516109fbb28bf2fbd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d929881b22cd699e243e2343bd707d" category="list-text">您应在克隆后进行验证，以确保克隆的数据库正常运行。可以在开发 / 测试数据库上执行一些附加任务，例如启动侦听器或关闭数据库日志归档模式。</block>
  <block id="9991775de6f914e5a41601ba523e3193" category="paragraph"><block ref="9991775de6f914e5a41601ba523e3193" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58732c8d9b1293bb6666ef2284840fd3" category="section-title">克隆 SQL 数据库，以便从复制的 Snapshot 备份进行开发 / 测试</block>
  <block id="605f2bb9d099f78e26260848db117df7" category="list-text">使用 SQL Server 的数据库管理用户 ID 登录到 SnapCenter 。导航到 " 资源 " 选项卡，其中显示了受 SnapCenter 保护的 SQL Sever 用户数据库以及公有云中的目标备用 SQL 实例。</block>
  <block id="d238acd8e02d4df70c9b55828a4b8801" category="paragraph"><block ref="d238acd8e02d4df70c9b55828a4b8801" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39c34a717e197c67b1fc8d678db5815b" category="list-text">单击备份拓扑和详细视图的预期内部 SQL Server 用户数据库名称。如果启用了二级复制位置，则会显示链接镜像备份。</block>
  <block id="8c57a9d29ca9640330e03e6edca2b6e5" category="paragraph"><block ref="8c57a9d29ca9640330e03e6edca2b6e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a5910fa5df5b6482c00b15ae683eef0f" category="list-text">通过单击镜像备份切换到镜像备份视图。然后显示二级镜像备份。由于 SnapCenter 会将 SQL Server 事务日志备份到专用驱动器进行恢复，因此此处仅显示完整的数据库备份。</block>
  <block id="f8d3ed6786c765a87cec8464a574076a" category="paragraph"><block ref="f8d3ed6786c765a87cec8464a574076a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="368014bae8201ab49d2207a53c907069" category="list-text">选择备份副本，然后单击克隆按钮以启动从备份克隆工作流。</block>
  <block id="87dbbaf733c71b9d4e0027ad4a85e709" category="paragraph"><block ref="87dbbaf733c71b9d4e0027ad4a85e709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75c22c861d423e3f3450da18d56f0599" category="paragraph"><block ref="75c22c861d423e3f3450da18d56f0599" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44258030a87117191bde6d62511ddb9a" category="list-text">选择一个云服务器作为目标克隆服务器，克隆实例名称和克隆数据库名称。选择自动分配挂载点或用户定义的挂载点路径。</block>
  <block id="7841eed97c9a860bcb6a46b08ea08c11" category="paragraph"><block ref="7841eed97c9a860bcb6a46b08ea08c11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18145dc97ae06034ae9aafa8b98cb36e" category="list-text">按日志备份时间或特定日期和时间确定恢复点。</block>
  <block id="b2798123b4d42e447362355b510a424c" category="paragraph"><block ref="b2798123b4d42e447362355b510a424c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b9becceddf802cada91d9e2aa84ac5a" category="list-text">指定在克隆操作前后运行的可选脚本。</block>
  <block id="adee0219db450497bd0f545df8d862c7" category="paragraph"><block ref="adee0219db450497bd0f545df8d862c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e41b01ffd717fd3d0b5788e608e50b52" category="list-text">如果需要电子邮件通知，请配置 SMTP 服务器。</block>
  <block id="9b758c550d5da3ecb44f04ae804293d4" category="paragraph"><block ref="9b758c550d5da3ecb44f04ae804293d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc89ae2ec0203249b8e60785a63ca258" category="list-text">克隆摘要。</block>
  <block id="ab74d2d908acf5c3e01544cd4b871b73" category="paragraph"><block ref="ab74d2d908acf5c3e01544cd4b871b73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28725828580a55d904e8b2a39f377eb9" category="list-text">监控作业状态并验证目标用户数据库是否已连接到云克隆服务器中的目标 SQL 实例。</block>
  <block id="766259946fc034002a24d5f23655c73e" category="paragraph"><block ref="766259946fc034002a24d5f23655c73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d512bf68b17268adfe539f9722d869b4" category="section-title">克隆后配置</block>
  <block id="50d9180ea26c89fbe6506d71d81d3fb1" category="list-text">内部 Oracle 生产数据库通常以日志归档模式运行。开发或测试数据库不需要此模式。要关闭日志归档模式，请以 sysdba 身份登录到 Oracle 数据库，执行 log mode change 命令并启动数据库以进行访问。</block>
  <block id="b205237d51ff9525496f4b2252942213" category="list-text">配置 Oracle 侦听器，或者向现有侦听器注册新克隆的数据库以供用户访问。</block>
  <block id="800699a04cdaa75b2219988799b0a048" category="list-text">对于 SQL Server ，将日志模式从 Full 更改为 Easy ，以便 SQL Server 开发 / 测试日志文件在填满日志卷时可以随时缩减。</block>
  <block id="89e018d207fd292a4926870904035c18" category="section-title">刷新克隆数据库</block>
  <block id="d84550ba9a340ebf4fa6698dff5ba344" category="list-text">丢弃克隆的数据库并清理云数据库服务器环境。然后，按照上述过程使用新数据克隆新数据库。克隆新数据库只需几分钟。</block>
  <block id="1170d6f09309cb8dc382034a34680937" category="inline-link-macro">刷新克隆</block>
  <block id="fef062eeb7771b01e620bb2460b1bf9a" category="list-text">关闭克隆数据库，使用命令行界面运行克隆刷新命令。有关详细信息，请参见以下 SnapCenter 文档： <block ref="1e4035dee07650c706f8f0714c384872" category="inline-link-macro-rx"></block>。</block>
  <block id="2d6962c20ba37b34437afc30e6838e0d" category="inline-link-macro">NetApp 解决方案自动化社区支持 Slack 通道</block>
  <block id="7b88d7d11804db6b079e226a6f043ea7" category="paragraph">如果您需要有关此解决方案和用例的帮助，请加入 <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> 并寻找解决方案自动化渠道来发布您的问题或询问。</block>
  <block id="d83342bb55cac062a4841a3b7a62a7fd" category="summary">本节概述了为满足上一节所述的前提条件要求而必须完成的任务。下一节提供了内部部署和公有云操作的高级任务列表。可以通过单击相关链接访问详细的流程和过程。</block>
  <block id="21475c5fe4cf73cfbf7756ed71e43375" category="doc">入门概述</block>
  <block id="b2e7ae8381268c9d97dc3576aa67da04" category="list-text">在 SnapCenter 中设置数据库管理员用户</block>
  <block id="e1c4efcd7b5b155c8a6e57d348b6c071" category="list-text">SnapCenter 插件安装前提条件</block>
  <block id="cf69df8da81eda7b468d606f3e9aff06" category="list-text">SnapCenter 主机插件安装</block>
  <block id="2a6faa57bc6cc0f7a4c90cebd5e63344" category="list-text">数据库资源发现</block>
  <block id="2a36af746a3cc41f6964edac717b5206" category="list-text">设置存储集群对等和数据库卷复制</block>
  <block id="a227a5da83d0a04e6e8e7e76a89eba09" category="list-text">将 CVO 数据库存储 SVM 添加到 SnapCenter</block>
  <block id="c615eed91e2ab578525394d0ff0138d9" category="list-text">在 SnapCenter 中设置数据库备份策略</block>
  <block id="8ecb914dad4186dafb38268be6fc8a1f" category="list-text">实施备份策略以保护数据库</block>
  <block id="3041fe5faf49efefd030e278790b4faf" category="list-text">验证备份</block>
  <block id="8a3f037eef48de78bfe13d14e3d7cdfa" category="section-title">AWS 公有云</block>
  <block id="0bcf61b20ebca1ef90cb7982284867a6" category="list-text">飞行前检查</block>
  <block id="c27b238e54d27696cafed4684c6f1335" category="list-text">在 AWS 中部署 Cloud Manager 和 Cloud Volumes ONTAP 的步骤</block>
  <block id="2bb50575568fc6429e2c1cef751d40f4" category="list-text">为数据库工作负载部署 EC2 计算实例</block>
  <block id="bc2dcb446bec0ecd131a2e612dbd1ecd" category="paragraph">有关详细信息，请单击以下链接：</block>
  <block id="7146594a919f2b006b1b0911c7b6d7da" category="inline-link-macro">内部部署</block>
  <block id="21aa279d0a145dcaab5feaa02df2c02a" category="inline-link-macro">公有云— AWS</block>
  <block id="fd0476c0c92270df2d75402a67cfe0f4" category="paragraph"><block ref="8f0e2d08c6bad9ef491c2061921b9d90" category="inline-link-macro-rx"></block>， <block ref="11145243f1982fd305768240bff5daad" category="inline-link-macro-rx"></block></block>
  <block id="ff9d8653752bd48bb6b73cf97f207af1" category="summary">采用 SnapCenter 灾难恢复工作流的混合云数据库解决方案</block>
  <block id="ac2e8778240cb518ee14b1defbf55765" category="doc">灾难恢复工作流</block>
  <block id="8e84608bd62584b2f262d60fd734714f" category="paragraph">企业已将公有云作为灾难恢复的可行资源和目标。SnapCenter 可以尽可能无缝地执行此过程。此灾难恢复工作流与克隆工作流非常相似，但数据库恢复会通过复制到云的最后一个可用日志运行，以恢复所有可能的业务事务。但是，对于灾难恢复，还需要执行其他预配置和后配置步骤。</block>
  <block id="e230d95c57c5534b3e90b93fddbcb1c9" category="section-title">将内部 Oracle 生产数据库克隆到云中进行灾难恢复</block>
  <block id="db9517755259859dbae095126c803544" category="list-text">为了验证克隆恢复是否通过最后一个可用日志运行，我们创建了一个小测试表并插入了一行。测试数据将在完全恢复到最后一个可用日志后进行恢复。</block>
  <block id="39f00f2f1a95739a075844dcffac1441" category="paragraph"><block ref="39f00f2f1a95739a075844dcffac1441" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fd1337293be82f7472d90bc35f51e90" category="list-text">以 Oracle 的数据库管理用户 ID 登录到 SnapCenter 。导航到资源选项卡，其中显示了受 SnapCenter 保护的 Oracle 数据库。</block>
  <block id="1ddb1f7854ac534473544de627fc5289" category="paragraph"><block ref="1ddb1f7854ac534473544de627fc5289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e795ef17ab8e08159909afe558c32a1c" category="list-text">选择 Oracle 日志资源组，然后单击立即备份以手动运行 Oracle 日志备份，以便将最新事务刷新到云中的目标。在实际灾难恢复场景中，最后一个可恢复的事务取决于向云复制数据库日志卷的频率，而这反过来又取决于公司的 RTO 或 RPO 策略。</block>
  <block id="e3ea77c81b6559a6984aee62074951ec" category="paragraph"><block ref="e3ea77c81b6559a6984aee62074951ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44d1c907c1d5302eb896d76cae9b5e7f" category="paragraph"><block ref="44d1c907c1d5302eb896d76cae9b5e7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d77575716b9cd49ab1453e367c405abe" category="admonition">在灾难恢复情形下，异步 SnapMirror 会在数据库日志备份间隔内丢失未将其备份到云目标的数据。为了最大限度地减少数据丢失，可以计划更频繁的日志备份。但是，在技术上可以实现的日志备份频率有一定限制。</block>
  <block id="c684c2587fa959f3df40953faab1c1a1" category="list-text">选择二级镜像备份上的最后一个日志备份，然后挂载日志备份。</block>
  <block id="4d27921136b62a393650eec8f38c5a39" category="paragraph"><block ref="4d27921136b62a393650eec8f38c5a39" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6784de36878125b88feb4c3192d2aa3d" category="paragraph"><block ref="6784de36878125b88feb4c3192d2aa3d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fbfa0a2a63c1090863dedb14664d443c" category="list-text">选择上次完整数据库备份，然后单击克隆以启动克隆工作流。</block>
  <block id="ecafa568fe2f36fee38130d0f80eeafc" category="paragraph"><block ref="ecafa568fe2f36fee38130d0f80eeafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3aa765536eeb5bd55823afbb43c9efdc" category="list-text">在主机上选择一个唯一的克隆数据库 ID 。</block>
  <block id="6d4d1ea488e25d46cd7824491f3f98fb" category="paragraph"><block ref="6d4d1ea488e25d46cd7824491f3f98fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d57d235b31b66e982ae6d433fa33948e" category="list-text">为 Oracle 闪存恢复区域和联机日志配置日志卷并将其挂载到目标灾难恢复服务器。</block>
  <block id="4ef6ef644cc7510226d8d150ce9cfe73" category="paragraph"><block ref="4ef6ef644cc7510226d8d150ce9cfe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d5730b3167534121e5ac4fcdf84cf1f" category="paragraph"><block ref="4d5730b3167534121e5ac4fcdf84cf1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6142419cbd2b279a240db52011ea3cab" category="admonition">Oracle 克隆操作步骤不会创建日志卷，而是需要在克隆之前在灾难恢复服务器上配置日志卷。</block>
  <block id="b20da77a777ef0a84d95f447b254387c" category="list-text">选择目标克隆主机和位置以放置数据文件，控制文件和重做日志。</block>
  <block id="326062662ffdb461c61b5ddfc54974bc" category="paragraph"><block ref="326062662ffdb461c61b5ddfc54974bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b126b14adfdc04f12e6a00531155f4a" category="list-text">选择克隆的凭据。填写目标服务器上 Oracle 主配置的详细信息。</block>
  <block id="ee4a9d80953ee6db29e5577ef13327ba" category="paragraph"><block ref="ee4a9d80953ee6db29e5577ef13327ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c76f59dc52686a71eb5917bbcabfa212" category="list-text">指定克隆前要运行的脚本。可以根据需要调整数据库参数。</block>
  <block id="31b131b08153ae34a96d1e17fa891e1f" category="paragraph"><block ref="31b131b08153ae34a96d1e17fa891e1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7018f70f78c5e3154b2620e31167c12e" category="list-text">选择直到取消作为恢复选项，以便恢复通过所有可用的归档日志运行，以重新输出复制到二级云位置的最后一个事务。</block>
  <block id="57fa7fef5a8266470204775391a701d3" category="paragraph"><block ref="57fa7fef5a8266470204775391a701d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6233d74c8f9820a1029624d60ab66049" category="list-text">如果需要，配置 SMTP 服务器以发送电子邮件通知。</block>
  <block id="a563132424d4d3d255697521a0446bc9" category="paragraph"><block ref="a563132424d4d3d255697521a0446bc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0cd00abfa258b121d480ce7d27e63" category="list-text">灾难恢复克隆摘要。</block>
  <block id="0f66818ccf8a8dd3d6491b9bcf74c02e" category="paragraph"><block ref="0f66818ccf8a8dd3d6491b9bcf74c02e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4ff014e6bff5ee06349d607c14fcf9e" category="list-text">克隆的数据库会在克隆完成后立即注册到 SnapCenter 中，然后可用于备份保护。</block>
  <block id="18eac7477ab0c6038ec443444677a1eb" category="paragraph"><block ref="18eac7477ab0c6038ec443444677a1eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22d74aee547ad10d104f875521cfa6d7" category="section-title">对 Oracle 进行灾难恢复克隆后验证和配置</block>
  <block id="9d58cce71d4c85948ccecfea105367ed" category="list-text">验证在云中的灾难恢复位置上刷新，复制和恢复的最后一个测试事务。</block>
  <block id="1db3ba1f62cbb82a66232de851bad3ce" category="paragraph"><block ref="1db3ba1f62cbb82a66232de851bad3ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61b3573abc722a493f53ed27503f7eff" category="list-text">配置闪存恢复区域。</block>
  <block id="71ca9fe67f8c3826e171fb227af4f666" category="paragraph"><block ref="71ca9fe67f8c3826e171fb227af4f666" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4005d553f013abc53c6a1a65aed1d65f" category="list-text">配置用于用户访问的 Oracle 侦听器。</block>
  <block id="0c79c2a9e4fd1ea908a63d58f1f44917" category="list-text">将克隆的卷拆离复制的源卷。</block>
  <block id="42e82bb35283d9f2e2b444419f518667" category="list-text">将复制从云反向复制到内部，并重建发生故障的内部数据库服务器。</block>
  <block id="4ce2420dd00dd0b543e2e51bf7c1c135" category="admonition">克隆拆分可能会产生比正常操作高得多的临时存储空间利用率。但是，在重建内部数据库服务器后，可以释放额外的空间。</block>
  <block id="0e70133bb418f4025b82a6a35301e209" category="section-title">将内部 SQL 生产数据库克隆到云中进行灾难恢复</block>
  <block id="32bfa00a92b9f85d791a43f6d70a35cd" category="list-text">同样，为了验证 SQL 克隆恢复是否经过了最后一个可用日志，我们创建了一个小测试表并插入了一行。测试数据将在完全恢复到最后一个可用日志后进行恢复。</block>
  <block id="321bd96e83b00fcd04bfcc72ec4564ff" category="paragraph"><block ref="321bd96e83b00fcd04bfcc72ec4564ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3b7f1fcf93afdd055ec19e230b54347" category="list-text">使用 SQL Server 的数据库管理用户 ID 登录到 SnapCenter 。导航到资源选项卡，其中显示了 SQL Server 保护资源组。</block>
  <block id="c9673e38d22c239c3b46259620b7b190" category="paragraph"><block ref="c9673e38d22c239c3b46259620b7b190" category="inline-image-macro-rx" type="image"></block></block>
  <block id="608bfa3334f97023b71f6b7a04742bd6" category="list-text">手动运行日志备份以将最后一个事务刷新到公有云中的二级存储。</block>
  <block id="94ca8d0daf1445cae1bbc5a13d7b0c42" category="paragraph"><block ref="94ca8d0daf1445cae1bbc5a13d7b0c42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b9ced1d8d8e91eb2606cb7d0932fa4" category="list-text">为克隆选择最后一个完整的 SQL Server 备份。</block>
  <block id="f93fa51d605a26ef233b6fb9c5489266" category="paragraph"><block ref="f93fa51d605a26ef233b6fb9c5489266" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82efcc579f2220a65dbe5cdd64f47253" category="list-text">设置克隆设置，例如克隆服务器，克隆实例，克隆名称和挂载选项。执行克隆的二级存储位置会自动填充。</block>
  <block id="bb5bdefa03845f9483d1e3fcf8d3b40f" category="paragraph"><block ref="bb5bdefa03845f9483d1e3fcf8d3b40f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d84ecf0ed314694d6e3ad9b2a96a198" category="list-text">选择要应用的所有日志备份。</block>
  <block id="79284af3915a1bc3e4d4d3993acd9042" category="paragraph"><block ref="79284af3915a1bc3e4d4d3993acd9042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f68fbd76be71ebe267aa207f7bef25f" category="list-text">指定克隆前后要运行的任何可选脚本。</block>
  <block id="1f29cf99c49ef1910181e451424c3796" category="paragraph"><block ref="1f29cf99c49ef1910181e451424c3796" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ac43ede08a0b7154673a619b979f17d" category="list-text">如果需要电子邮件通知，请指定 SMTP 服务器。</block>
  <block id="e8aa5b543b67c22f0a2a205562794787" category="paragraph"><block ref="e8aa5b543b67c22f0a2a205562794787" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7338d3af995c4a281de85493129cc18" category="list-text">灾难恢复克隆摘要。克隆的数据库会立即注册到 SnapCenter 中，并可用于备份保护。</block>
  <block id="332fb27e1cc349fc79252fbfc5de6ad0" category="paragraph"><block ref="332fb27e1cc349fc79252fbfc5de6ad0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8be7490bb89f986a83768e6a71d78ee8" category="paragraph"><block ref="8be7490bb89f986a83768e6a71d78ee8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f01a56e31a650c5bb83408b5238270e" category="section-title">SQL 的灾难恢复克隆后验证和配置</block>
  <block id="029640b7bf09578f05703e407e99b8d7" category="list-text">监控克隆作业状态。</block>
  <block id="d5f350d5580b71105a1718557ce88137" category="paragraph"><block ref="d5f350d5580b71105a1718557ce88137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68236fcee9bee8dbdc1c54b7b2d84b34" category="list-text">验证是否已使用所有日志文件克隆和恢复来复制和恢复最后一个事务。</block>
  <block id="3ebb58ab28579acf2742808bf95fc07e" category="paragraph"><block ref="3ebb58ab28579acf2742808bf95fc07e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50159c53d6f87eb33c314abd9f0bd28f" category="list-text">在灾难恢复服务器上配置一个新的 SnapCenter 日志目录以进行 SQL Server 日志备份。</block>
  <block id="50f8c30e062c542679b96127a844db6a" category="paragraph">如果您需要有关此解决方案和用例的帮助，请加入 <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> 并寻找解决方案自动化渠道来发布您的问题或询问。</block>
  <block id="467bda78c0e1adcc5ed650843fbfbdf5" category="summary">本节介绍在 AWS 中部署 Cloud Manager 和 Cloud Volumes ONTAP 的过程。</block>
  <block id="298a4809d5445df75b6c4a9fb94074a4" category="doc">AWS 公有云入门</block>
  <block id="87aa698992e009d04733c9906225592c" category="admonition">为了便于操作，我们根据 AWS 中的部署创建了本文档。但是， Azure 和 GCP 的过程非常相似。</block>
  <block id="39845311263ccad04c0d4f0b9aa9d4c6" category="section-title">1 ，飞行前检查</block>
  <block id="12ed93944854c12caa37886d620f16db" category="paragraph">在部署之前，请确保基础架构已准备就绪，以便在下一阶段进行部署。其中包括：</block>
  <block id="c6368ae044df0f7bb26ed60afda5c591" category="list-text">AWS 帐户</block>
  <block id="4019c185756035c18c03fabfccd7d4b2" category="list-text">您选择的地区的 VPC</block>
  <block id="fca5d2fece6e360f78dff4573ba04a20" category="list-text">可访问公有 Internet 的子网</block>
  <block id="e3e5c3dadc3e70d536645a3be9744f79" category="list-text">向 AWS 帐户添加 IAM 角色的权限</block>
  <block id="bd5c82fb0e0371a168f609848b11e92a" category="list-text">AWS 用户的机密密钥和访问密钥</block>
  <block id="c3d1ff3c88148b2246bb0972916da82a" category="section-title">在 AWS 中部署 Cloud Manager 和 Cloud Volumes ONTAP 的步骤</block>
  <block id="6d0eb695a99109617b806676e9610075" category="inline-link">NetApp Cloud 文档</block>
  <block id="593581e466784760a050bceaea5e0c48" category="admonition">部署 Cloud Manager 和 Cloud Volumes ONTAP 的方法有多种；此方法最简单，但需要的权限最多。如果此方法不适用于您的 AWS 环境，请参考<block ref="97a20614f8c0e53f461a9353634e5e51" category="inline-link-rx"></block>。</block>
  <block id="bb3e779fdf877143137572122cf424e3" category="section-title">部署 Cloud Manager 连接器</block>
  <block id="4c6e32ff373dc3ce5b49202f92f01b08" category="list-text">导航到<block ref="143fea272f01f72dbdc942451156df21" category="inline-link-rx"></block> 并登录或注册。</block>
  <block id="356cf5e12d635c19d987b1b195ff5a40" category="paragraph"><block ref="356cf5e12d635c19d987b1b195ff5a40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2300b8579a8761e452d89a2af6636b7d" category="list-text">登录后，您应转到 " 画布 " 。</block>
  <block id="af93b0b88e1db5f3aa229d2336fedb3c" category="paragraph"><block ref="af93b0b88e1db5f3aa229d2336fedb3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3fbf2c408ce86ff3403990e7e32dcb3" category="list-text">单击 " 添加工作环境 " ，然后在 AWS 中选择 Cloud Volumes ONTAP 。您还可以在此处选择是要部署单节点系统还是高可用性对。我已选择部署高可用性对。</block>
  <block id="bb18ff1ebac7ea2039aa297469c76b76" category="paragraph"><block ref="bb18ff1ebac7ea2039aa297469c76b76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="016aa0c0a7322975ec4b8eeac805f2c0" category="list-text">如果尚未创建连接器，则会显示一个弹出窗口，要求您创建连接器。</block>
  <block id="a05691eb0d806668c3796d3d6fe01157" category="paragraph"><block ref="a05691eb0d806668c3796d3d6fe01157" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fc3362a0d8ab63cc8fa21bbd0fb07db" category="list-text">单击 " 让我们开始 " ，然后选择 "AWS" 。</block>
  <block id="55f5adc74d49945abd7798742f307124" category="paragraph"><block ref="55f5adc74d49945abd7798742f307124" category="inline-image-macro-rx" type="image"></block></block>
  <block id="deae4c054bb3102bbf634b14534da9bf" category="inline-link">NetApp 策略页面</block>
  <block id="651d429a2b6cfcd93f6adb1d4825a214" category="list-text">输入您的机密密钥和访问密钥。确保您的用户具有上所述的正确权限<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block>。</block>
  <block id="94497191b0b0c6d05a2df7d2175e87f5" category="paragraph"><block ref="94497191b0b0c6d05a2df7d2175e87f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d59b60a74630e45f83fd3c48207b47" category="list-text">为连接器指定一个名称，并使用上所述的预定义角色<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block> 或者要求 Cloud Manager 为您创建角色。</block>
  <block id="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="paragraph"><block ref="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02d395705fb063ad8d33d8c83c856e6f" category="list-text">提供部署连接器所需的网络信息。验证是否已通过以下方式启用出站 Internet 访问：</block>
  <block id="8215126360cbe5d8f5566c7ffc8cf224" category="list-text">为连接器提供公有 IP 地址</block>
  <block id="22adb619c008bfd7495288573093ae44" category="list-text">为连接器提供一个代理以供其使用</block>
  <block id="58a149795bbe86e4e0d4ab8f10413219" category="list-text">为连接器提供通过 Internet 网关到公有 Internet 的路由</block>
  <block id="5908ad1cf5bd748238e305dd5fc52fac" category="paragraph"><block ref="5908ad1cf5bd748238e305dd5fc52fac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c58ebc9f032dc8d2e5c4f522cedbe0b" category="list-text">通过提供安全组或创建新的安全组，通过 SSH ， HTTP 和 HTTPS 提供与连接器的通信。我已启用仅从 IP 地址访问此连接器的功能。</block>
  <block id="1d39d9c13f50dd25f7e54173c87c633a" category="paragraph"><block ref="1d39d9c13f50dd25f7e54173c87c633a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb444cfaba774437ecdbbb95856d94cd" category="list-text">查看摘要页面上的信息，然后单击添加以部署连接器。</block>
  <block id="5576df68e3720f55e585e7e091d5b9e3" category="paragraph"><block ref="5576df68e3720f55e585e7e091d5b9e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4255ace47c9ad7f2907c18df7512bb9f" category="list-text">现在，此连接器将使用云形成堆栈进行部署。您可以从 Cloud Manager 或通过 AWS 监控其进度。</block>
  <block id="ff7fb4bedc0d09880f85d9745ec258a5" category="paragraph"><block ref="ff7fb4bedc0d09880f85d9745ec258a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca320cc147e2b9fac2dd7379e91012b6" category="list-text">部署完成后，将显示一个成功页面。</block>
  <block id="f5bbadf1ed57058e80e27764684e6314" category="paragraph"><block ref="f5bbadf1ed57058e80e27764684e6314" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6382283fd45b13b5c983745731fec990" category="section-title">部署 Cloud Volumes ONTAP</block>
  <block id="5fe90897c7135ba3020c4a397f55adb6" category="list-text">根据您的要求选择 AWS 和部署类型。</block>
  <block id="63b636f2002a2e7b7c2e2420cd64ff73" category="paragraph"><block ref="63b636f2002a2e7b7c2e2420cd64ff73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf1300c5621fdebe8c1a70fade44f3b" category="list-text">如果尚未分配任何订阅，而您希望使用 PAYGO 购买，请选择编辑凭据。</block>
  <block id="b893bded7e1bd3419a443758a8ef410f" category="paragraph"><block ref="b893bded7e1bd3419a443758a8ef410f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88eb84b1a8f0417c9de6e1202125df56" category="list-text">选择添加订阅。</block>
  <block id="0b5d3e3d1a9347ff4a7395d09208a8f4" category="paragraph"><block ref="0b5d3e3d1a9347ff4a7395d09208a8f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="052208bafdfe08bc8f0735a78226e541" category="list-text">选择要订阅的合同类型。我选择了按需购买。</block>
  <block id="4d5ab1ed0682fe644e831558598d4638" category="paragraph"><block ref="4d5ab1ed0682fe644e831558598d4638" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65577508f7897e730adb501d0db73913" category="list-text">系统会将您重定向到 AWS ；选择 Continue to Subscribe 。</block>
  <block id="ac33260d1e06f504f1dcac229aeb269c" category="paragraph"><block ref="ac33260d1e06f504f1dcac229aeb269c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="439c4fb23c120f0a99894c630cedaabd" category="list-text">订阅后，您将重定向回 NetApp Cloud Central 。如果您已订阅，但未被重定向，请选择 " 单击此处 " 链接。</block>
  <block id="a90c8b1fc04a41aff490fd2b269f5932" category="paragraph"><block ref="a90c8b1fc04a41aff490fd2b269f5932" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14b9e98d2b57da92c29826ce7de32c32" category="list-text">系统会将您重定向到 Cloud Central ，您必须在其中为订阅命名并将其分配给 Cloud Central 帐户。</block>
  <block id="c89376fd9624f6ebda7959df6176ef34" category="paragraph"><block ref="c89376fd9624f6ebda7959df6176ef34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4508f5994d1b34ff85cd1e8a1884d6c1" category="list-text">成功后，将显示一个复选标记页面。导航回 Cloud Manager 选项卡。</block>
  <block id="2b206bbd8f3b20e3282b660a356d90be" category="paragraph"><block ref="2b206bbd8f3b20e3282b660a356d90be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3294e5fb9ec1c42cde7ebf9b206c583" category="list-text">现在，此订阅将显示在 Cloud Central 中。单击应用以继续。</block>
  <block id="37ce5c33a55d907edabe632c39a2707c" category="paragraph"><block ref="37ce5c33a55d907edabe632c39a2707c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7927b068a5dddb4852b2e7dc256544" category="list-text">输入工作环境详细信息，例如：</block>
  <block id="0dbae4d42c7a0db53e2eb32adee12892" category="list-text">Cluster name</block>
  <block id="0c191ee206a91460fd94e2ff976a38e7" category="list-text">Cluster password</block>
  <block id="53aa18427d1e2c7b7113c668561a62d2" category="list-text">AWS 标记（可选）</block>
  <block id="d3b6ff1e8c6317d132d3a5e974f1374c" category="paragraph"><block ref="d3b6ff1e8c6317d132d3a5e974f1374c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fb5b261ae3a3581304a283ef70a5246" category="inline-link">NetApp Cloud 主页</block>
  <block id="e7b29c75e71a48483734401322ef6e92" category="list-text">选择要部署的其他服务。要了解有关这些服务的更多信息，请访问<block ref="1bb1213784e04e4f47d06f252d1ba164" category="inline-link-rx"></block>。</block>
  <block id="88e71a2c19d98c79d2ed51a753c8a4c2" category="paragraph"><block ref="88e71a2c19d98c79d2ed51a753c8a4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0dffa77d5644a3816ba69e24ce813ff" category="list-text">选择是部署在多个可用性区域中（即三个子网，每个子网位于不同的 AZ 中），还是部署一个可用性区域。我选择了多个 AZs 。</block>
  <block id="6e4a3fe2b0629dae504d8e727147f709" category="paragraph"><block ref="6e4a3fe2b0629dae504d8e727147f709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b889b7255c34e7f230e392668605860" category="list-text">选择要部署到的集群的区域， VPC 和安全组。在本节中，您还可以为每个节点（和调解器）分配可用性分区以及它们所占用的子网。</block>
  <block id="9ad68c9f72863557931a8569462bff52" category="paragraph"><block ref="9ad68c9f72863557931a8569462bff52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be43ebbf5380089f153e4f1b13e35e6f" category="list-text">选择节点和调解器的连接方法。</block>
  <block id="8bf6da8b537127466c4421c1ae3169be" category="paragraph"><block ref="8bf6da8b537127466c4421c1ae3169be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="204bd52e1d13052712299779cf041df6" category="admonition">调解器需要与 AWS API 进行通信。只要在部署调解器 EC2 实例后可以访问公有，就不需要 API IP 地址。</block>
  <block id="52fade87431f9acc43b7bf6e4c5fd2f1" category="inline-link">NetApp Cloud 文档</block>
  <block id="0c79e4a46253eeb94ba6b8218928aa99" category="list-text">浮动 IP 地址用于访问 Cloud Volumes ONTAP 使用的各种 IP 地址，包括集群管理和数据提供 IP 。这些地址必须是您的网络中尚未可路由的地址，并且已添加到 AWS 环境中的路由表中。要在故障转移期间为 HA 对启用一致的 IP 地址，需要使用这些地址。有关浮动 IP 地址的详细信息，请参见<block ref="72cde540b4f97efa19e071f729439801" category="inline-link-rx"></block>。</block>
  <block id="fd4a46ceddfb2402b7e37177af575e04" category="paragraph"><block ref="fd4a46ceddfb2402b7e37177af575e04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ca6b5e9b64aed9132a6be07d061f3b" category="list-text">选择将浮动 IP 地址添加到的路由表。客户端使用这些路由表与 Cloud Volumes ONTAP 进行通信。</block>
  <block id="3453ab81a2f04d5c39ae750fb79ece2a" category="paragraph"><block ref="3453ab81a2f04d5c39ae750fb79ece2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af918e519f9c0db1ed5ab4fd4b6e9e05" category="list-text">选择是启用 AWS 托管加密还是启用 AWS KMS 对 ONTAP 根磁盘，启动磁盘和数据磁盘进行加密。</block>
  <block id="058eaefa711702bd45c5f6650cf01e4c" category="paragraph"><block ref="058eaefa711702bd45c5f6650cf01e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01bd54fa77587425fca4a6c352309b5c" category="list-text">选择您的许可模式。如果您不知道选择哪种，请联系您的 NetApp 代表。</block>
  <block id="e5e49184799594a9fa690c9122eb883e" category="paragraph"><block ref="e5e49184799594a9fa690c9122eb883e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04110b24d1459a6e21e35ad976a8f10e" category="list-text">选择最适合您的用例的配置。这与 " 前提条件 " 页面中所述的规模估算注意事项相关。</block>
  <block id="e19584159c9c3791a9e3c462cb0aa451" category="paragraph"><block ref="e19584159c9c3791a9e3c462cb0aa451" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ed47788a525c6d08246bfa2f90922da" category="list-text">也可以创建卷。这不是必需的，因为后续步骤使用 SnapMirror ，这将为我们创建卷。</block>
  <block id="01da9401385484b72ba9c016ac6c19ab" category="paragraph"><block ref="01da9401385484b72ba9c016ac6c19ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76011f95c4e1b3f68fa5829dab0fb786" category="list-text">查看所做的选择并勾选相应的复选框，确认您了解 Cloud Manager 是否已将资源部署到 AWS 环境中。准备好后，单击 "Go" 。</block>
  <block id="7b78e746aa55ffe6fee1f3e0b65b8cca" category="paragraph"><block ref="7b78e746aa55ffe6fee1f3e0b65b8cca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13b7f009673a469e5482a96832be1473" category="list-text">Cloud Volumes ONTAP 现在开始其部署过程。Cloud Manager 使用 AWS API 和云构成堆栈来部署 Cloud Volumes ONTAP 。然后，它会根据您的规格对系统进行配置，为您提供一个可立即使用的即用系统。此过程的时间安排因所做的选择而异。</block>
  <block id="11d15d8a4bb9195b48d5010fa30fa547" category="paragraph"><block ref="11d15d8a4bb9195b48d5010fa30fa547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e63d2329924bb302fb012e7916b3614" category="list-text">您可以通过导航到时间线来监控进度。</block>
  <block id="77405312cc4c1e96d3f7f796e838bf89" category="paragraph"><block ref="77405312cc4c1e96d3f7f796e838bf89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b4df7cc92b3ee31f5d95082a78c7903" category="list-text">时间线可作为对 Cloud Manager 中执行的所有操作的审核。您可以查看 Cloud Manager 在设置到 AWS 和 ONTAP 集群期间发出的所有 API 调用。此外，还可以有效地使用此功能对您遇到的任何问题进行故障排除。</block>
  <block id="8c17e020c76595308d57605fa71dc7af" category="paragraph"><block ref="8c17e020c76595308d57605fa71dc7af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c5674ad1910f0a25455fdeb0f3f097a" category="list-text">部署完成后， CVO 集群将显示在当前容量所在的 Canvas 上。处于当前状态的 ONTAP 集群已完全配置，可以实现真正的即装即用体验。</block>
  <block id="db044bc640be9fc8227b7ada891f279d" category="paragraph"><block ref="db044bc640be9fc8227b7ada891f279d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28d2e01957d5845ff59688f17bd34339" category="section-title">从内部部署到云配置 SnapMirror</block>
  <block id="081494b1a178710486921a42e2bdfa87" category="paragraph">现在，您已部署源 ONTAP 系统和目标 ONTAP 系统，您可以将包含数据库数据的卷复制到云中。</block>
  <block id="cb3269c2496a99fb03bebe82b6a3e4bc" category="inline-link">SnapMirror 兼容性表</block>
  <block id="46aad6288d89ba29f38b4742bf018aca" category="paragraph">有关适用于 SnapMirror 的兼容 ONTAP 版本的指南，请参见<block ref="f75a4f2138bf92eb17ef87cad85a9e34" category="inline-link-rx"></block>。</block>
  <block id="36c5350a8474f2212fecc811eb77df57" category="list-text">单击源 ONTAP 系统（内部），然后将其拖放到目标，选择复制 &gt; 启用或选择复制 &gt; 菜单 &gt; 复制。</block>
  <block id="5dbe69ec28d70286f46385336e96d003" category="paragraph"><block ref="5dbe69ec28d70286f46385336e96d003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8771a8fdaa9e84a7eef7540edcca5f40" category="paragraph">选择启用。</block>
  <block id="ac21962f3f0ae9f9c17b26196452f903" category="paragraph"><block ref="ac21962f3f0ae9f9c17b26196452f903" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6a8dc55f6f333187a100f6ed328bdc0" category="paragraph">或选项。</block>
  <block id="949fa0a5e194cf44c9e08903cb914566" category="paragraph"><block ref="949fa0a5e194cf44c9e08903cb914566" category="inline-image-macro-rx" type="image"></block></block>
  <block id="066bf779660ad446aa9b0d4021c4bf40" category="paragraph">复制。</block>
  <block id="deafbb4908c633cb93a7f7e76b31da08" category="paragraph"><block ref="deafbb4908c633cb93a7f7e76b31da08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a803b2a55429f981d25fbb8da94aef7" category="list-text">如果未拖放，请选择要复制到的目标集群。</block>
  <block id="630e74180bc1b6c0c0c866d5478ff029" category="paragraph"><block ref="630e74180bc1b6c0c0c866d5478ff029" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761124dc5e0730086556a7d33d43418c" category="list-text">选择要复制的卷。我们复制了数据和所有日志卷。</block>
  <block id="7bec2596a51a0d4a808a37dec9e6c540" category="paragraph"><block ref="7bec2596a51a0d4a808a37dec9e6c540" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bde4e8497f5ecaef866c0f049aada776" category="list-text">选择目标磁盘类型和分层策略。对于灾难恢复，我们建议使用 SSD 作为磁盘类型，并保持数据分层。数据分层可将镜像数据分层为低成本的对象存储，并节省使用本地磁盘的成本。中断关系或克隆卷时，数据将使用快速的本地存储。</block>
  <block id="a7d9908d0f610b3db167c894d109d1ec" category="paragraph"><block ref="a7d9908d0f610b3db167c894d109d1ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f06f2f09c024b69ef3944a8cd78ad9" category="list-text">选择目标卷名称： we chose ` [source_volume_name]_dr` 。</block>
  <block id="6f8ba85bc89d216799431f124e48b25f" category="paragraph"><block ref="6f8ba85bc89d216799431f124e48b25f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2882a0dbc1a6ad74198ac2cb6316870d" category="list-text">选择复制的最大传输速率。这样，如果您与云的连接带宽较低，例如 VPN ，则可以节省带宽。</block>
  <block id="041263f562a9058ae414685962469951" category="paragraph"><block ref="041263f562a9058ae414685962469951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f81dd66e0f0847d4cb1d2d12fadcc2f3" category="list-text">定义复制策略。我们选择了镜像，它会获取最新的数据集并将其复制到目标卷。您也可以根据自己的要求选择其他策略。</block>
  <block id="d0b86e2934c870915aaa77674d1d79d7" category="paragraph"><block ref="d0b86e2934c870915aaa77674d1d79d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4db5384e8d04b01ff24a9178b3efaf6a" category="list-text">选择触发复制的计划。NetApp 建议为数据卷设置 " 每日 " 计划，并为日志卷设置 " 每小时 " 计划，但可以根据要求进行更改。</block>
  <block id="c6715d4de4d68a1f8eb9cb8acb63b097" category="paragraph"><block ref="c6715d4de4d68a1f8eb9cb8acb63b097" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02e3a269661e3c96a86a075872a1b269" category="list-text">查看输入的信息，单击 Go 以触发集群对等方和 SVM 对等方（如果这是您首次在两个集群之间复制），然后实施并初始化 SnapMirror 关系。</block>
  <block id="75c2d297cd7282b30ce0400170110307" category="paragraph"><block ref="75c2d297cd7282b30ce0400170110307" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c160366cab97ee8f1a35416d1294ddb" category="list-text">继续对数据卷和日志卷执行此过程。</block>
  <block id="64853c47f4f907262466c1e5ad154c8c" category="list-text">要检查所有关系，请导航到 Cloud Manager 中的复制选项卡。您可以在此处管理您的关系并检查其状态。</block>
  <block id="641e620fe8c714d7381775d20a707726" category="paragraph"><block ref="641e620fe8c714d7381775d20a707726" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c88bec52f9e24233a78b6a90efa32ec6" category="list-text">复制完所有卷后，您将处于稳定状态，并准备好继续执行灾难恢复和开发 / 测试工作流。</block>
  <block id="86fb3ee49ae2f8c0ee121c551a8f08c2" category="section-title">3. 为数据库工作负载部署 EC2 计算实例</block>
  <block id="91ba52045df2b9244f28270482f749c9" category="inline-link">EC2 实例类型</block>
  <block id="33aaa72e62140af9cecb2c48f836b84b" category="paragraph">AWS 已为各种工作负载预配置 EC2 计算实例。选择实例类型可确定 CPU 核数，内存容量，存储类型和容量以及网络性能。在使用情形中，除了操作系统分区之外，用于运行数据库工作负载的主存储是从 CVO 或 FSX ONTAP 存储引擎分配的。因此，需要考虑的主要因素是 CPU 核心，内存和网络性能级别的选择。可在此处找到典型的 AWS EC2 实例类型：<block ref="9334d5b9e602c5921b4f295f6041489b" category="inline-link-rx"></block>。</block>
  <block id="0af43c3d809d6e56a6a7a0d1ed039bbc" category="section-title">调整计算实例大小</block>
  <block id="0b6e77aedd6bd733f979314fef2a98d7" category="list-text">根据所需的工作负载选择正确的实例类型。需要考虑的因素包括要支持的业务事务数，并发用户数，数据集规模估算等。</block>
  <block id="c421d122321bec48d6b30858f4e7b515" category="inline-link">Amazon EC2</block>
  <block id="ed4b68006572e288530a2152f7fbe5fe" category="list-text">可以通过 EC2 信息板启动 EC2 实例部署。确切的部署过程不在此解决方案的范围内。请参见<block ref="3a5862dd365e3998013717e9cf118a9a" category="inline-link-rx"></block> 了解详细信息。</block>
  <block id="708991723f71fa1bd7b8081be442552c" category="section-title">Oracle 工作负载的 Linux 实例配置</block>
  <block id="5c17b7d75ff16063f772234e1ea8eeb1" category="paragraph">本节介绍部署 EC2 Linux 实例后的其他配置步骤。</block>
  <block id="39d786446455bb2b3017b793805fc902" category="list-text">将 Oracle 备用实例添加到 DNS 服务器，以便在 SnapCenter 管理域中进行名称解析。</block>
  <block id="385a2a4f5305fe5ce8017f18fb7eabd4" category="list-text">添加一个 Linux 管理用户 ID 作为 SnapCenter OS 凭据，并具有 sudo 权限，而不需要密码。在 EC2 实例上启用 ID 和 SSH 密码身份验证。（默认情况下，在 EC2 实例上， SSH 密码身份验证和无密码 sudo 处于关闭状态。）</block>
  <block id="a2b4677d7a72840a78373c600441681a" category="list-text">将 Oracle 安装配置为与内部 Oracle 安装相匹配，例如操作系统修补程序， Oracle 版本和修补程序等。</block>
  <block id="66b65364302a847feb2630bfd7974256" category="inline-link">Oracle 19c 自动化部署</block>
  <block id="fa470598a181c1ed905bace243e46aa3" category="list-text">可以利用 NetApp Ansible DB 自动化角色为数据库开发 / 测试和灾难恢复用例配置 EC2 实例。可以从 NetApp 公有 GitHub 站点下载自动化代码：<block ref="437f8b44ff65600fb5697e9d369a0c54" category="inline-link-rx"></block>。目标是在 EC2 实例上安装和配置数据库软件堆栈，以匹配内部操作系统和数据库配置。</block>
  <block id="97875b4799caf4c948118e7b4776c9fb" category="section-title">SQL Server 工作负载的 Windows 实例配置</block>
  <block id="c63751cfdcf8c0b4e26635a47c7f0d97" category="paragraph">本节列出了最初部署 EC2 Windows 实例后的其他配置步骤。</block>
  <block id="5f44e6a78874f9f49acae3caa71cc14d" category="list-text">检索 Windows 管理员密码以通过 RDP 登录到实例。</block>
  <block id="eabafc642b0901afd6622ab0f19d9ef0" category="list-text">禁用 Windows 防火墙，将主机加入 Windows SnapCenter 域，然后将实例添加到 DNS 服务器以进行名称解析。</block>
  <block id="08bf2d7ff3ac9ab37cfa8dc449b3c8da" category="list-text">配置 SnapCenter 日志卷以存储 SQL Server 日志文件。</block>
  <block id="f97ac9d1946c873247af15165559b47a" category="list-text">在 Windows 主机上配置 iSCSI 以挂载卷并格式化磁盘驱动器。</block>
  <block id="6c2a9c611f48cae767f6ebea6fca0457" category="inline-link">NetApp 自动化</block>
  <block id="6dea6226167bd38268de4c4d948d72de" category="list-text">同样，以前的许多任务都可以通过适用于 SQL Server 的 NetApp 自动化解决方案实现自动化。有关新发布的角色和解决方案，请访问 NetApp Automation 公有 GitHub 站点：<block ref="8cafb3a3b1222d318fcd262791229701" category="inline-link-rx"></block>。</block>
  <block id="ac9bef0f960e3a46befd2d06b223b61d" category="summary">本节介绍了开发 / 测试和灾难恢复操作的典型混合云架构。</block>
  <block id="4085a97aa705c0122bbcec0c84dd97d3" category="paragraph">以下架构图展示了在混合云中实施企业数据库操作的典型实施，用于开发 / 测试和灾难恢复操作。</block>
  <block id="acb339f710a626679c374df5b90c5416" category="paragraph"><block ref="acb339f710a626679c374df5b90c5416" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cdc302c6d83b60c8ec7ad0b550e55a8" category="paragraph">在正常业务运营中，可以克隆云中的同步数据库卷并将其挂载到开发 / 测试数据库实例中，以进行应用程序开发或测试。如果发生故障，则可以激活云中的同步数据库卷以进行灾难恢复。</block>
  <block id="c94d29f1f4f8ef37e9d27f30b7d7c67d" category="summary">必须在内部完成本节所述的任务，以便准备 SnapCenter 混合云数据库工作负载环境。</block>
  <block id="f6a196d9d3a941e76765e4a9395630c4" category="doc">内部部署的前提条件</block>
  <block id="40931dcd4d9132545ec0faf2c5fb1b64" category="paragraph">要准备 SnapCenter 混合云数据库工作负载环境，必须在内部完成以下任务。</block>
  <block id="79daf399b9626cde309801f41a1e2e14" category="section-title">SnapCenter 安装和配置</block>
  <block id="2607530756fefa4173e12cfcd5fbfb01" category="paragraph">NetApp SnapCenter 工具是一款基于 Windows 的应用程序，通常在 Windows 域环境中运行，但也可以部署工作组。它基于多层架构，其中包括用于数据库工作负载的集中式管理服务器（ SnapCenter 服务器）和数据库服务器主机上的 SnapCenter 插件。以下是混合云部署的几个主要注意事项。</block>
  <block id="9f8c0bcd11d7afd1dd2ee818191cb914" category="list-text">* 单实例或 HA 部署。 * HA 部署可在单个 SnapCenter 实例服务器发生故障时提供冗余。</block>
  <block id="1bfa2867d5aa49106efbf3ac752f3084" category="list-text">* 名称解析。 * 必须在 SnapCenter 服务器上配置 DNS 以解析所有数据库主机，并在存储 SVM 上配置 DNS 以进行正向和反向查找。此外，还必须在数据库服务器上配置 DNS ，以解析 SnapCenter 服务器和存储 SVM ，以便进行正向和反向查找。</block>
  <block id="41f54308d86c1d7b525475d6ead22892" category="list-text">* 基于角色的访问控制（ Role-Based Access Control ， RBAC ）配置。 * 对于混合数据库工作负载，您可能需要使用 RBAC 隔离不同数据库平台的管理职责，例如 Oracle 数据库管理员或 SQL Server 管理员。必须为数据库管理员用户授予必要的权限。</block>
  <block id="5aee5dffd2e329652ec35995add763ae" category="list-text">* 启用基于策略的备份策略。 * 以强制实施备份一致性和可靠性。</block>
  <block id="dde4790e572aa9d01cd58fcfd8498766" category="list-text">* 在防火墙上打开所需的网络端口。 * 用于使内部 SnapCenter 服务器与云数据库主机中安装的代理进行通信。</block>
  <block id="e2962676531ebdcf62cb2a7b96042e77" category="list-text">* 端口必须处于打开状态，才能在内部和公有云之间传输 SnapMirror 流量。 * SnapCenter 服务器依靠 ONTAP SnapMirror 将现场 Snapshot 备份复制到云 CVO 存储 SVM 。</block>
  <block id="549762060d7242346fa79f39cba51791" category="inline-link-macro">SnapCenter 安装工作流</block>
  <block id="aec875397d57826c45f7072636026a07" category="paragraph">仔细规划安装前的规划和考虑后，单击此项 <block ref="f44e9d032441cc842cad02c3aab57d84" category="inline-link-macro-rx"></block> 有关 SnapCenter 安装和配置的详细信息。</block>
  <block id="df3fb602185c77a88bab186791d02636" category="section-title">内部数据库服务器存储配置</block>
  <block id="f7f3a649be867b87ccb26789453199db" category="paragraph">存储性能在数据库和应用程序的整体性能中发挥着重要作用。精心设计的存储布局不仅可以提高数据库性能，还可以轻松管理数据库备份和恢复。在定义存储布局时，应考虑多个因素，包括数据库大小，数据库的预期数据更改率以及执行备份的频率。</block>
  <block id="8481231881c8e64b34aa3c7e29510a25" category="paragraph">对于虚拟化数据库工作负载，通过 NFS 或 iSCSI 将存储 LUN 直接连接到子虚拟机通常比通过 VMDK 分配的存储性能更高。NetApp 建议采用下图所示的 LUN 上的大型 SQL Server 数据库的存储布局。</block>
  <block id="cc75f443d22e45e490468a8f20689d77" category="paragraph"><block ref="cc75f443d22e45e490468a8f20689d77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99aea05cf884bfdec230afa5250968b2" category="paragraph">下图显示了 NetApp 为 LUN 上的小型或中型 SQL Server 数据库建议的存储布局。</block>
  <block id="9fc72535f1113895818f8aa60ef773e7" category="paragraph"><block ref="9fc72535f1113895818f8aa60ef773e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ecde8f778d0dd0676f392793ce4382" category="admonition">日志目录专用于 SnapCenter ，用于执行事务日志汇总以恢复数据库。对于超大型数据库，可以为一个卷分配多个 LUN ，以提高性能。</block>
  <block id="ee9158729a15dbd90d166650ba285d0e" category="paragraph">对于 Oracle 数据库工作负载， SnapCenter 支持以 ONTAP 存储为后盾的数据库环境，这些环境作为物理设备或虚拟设备挂载到主机上。您可以根据环境的严重性将整个数据库托管在一个或多个存储设备上。通常，客户会将专用存储上的数据文件与控制文件，重做文件和归档日志文件等所有其他文件隔离。这有助于管理员在几秒到几分钟内使用 Snapshot 技术快速还原（ ONTAP 单文件 SnapRestore ）或克隆大型关键数据库（ PB 级）。</block>
  <block id="b31fbb7e1a6e863315e431fdf9c00db9" category="paragraph"><block ref="b31fbb7e1a6e863315e431fdf9c00db9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="959a3405dfdfb0469534f5276ffb8e5e" category="paragraph">对于对延迟敏感的任务关键型工作负载，应将专用存储卷部署到不同类型的 Oracle 文件，以尽可能实现最佳延迟。对于大型数据库，应为数据文件分配每个卷的多个 LUN （ NetApp 建议最多八个）。</block>
  <block id="ac111cbcae2e9eaedafe418acc3a2cab" category="paragraph"><block ref="ac111cbcae2e9eaedafe418acc3a2cab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2702ce3d59ec94853fa030462b309f2f" category="paragraph">对于较小的 Oracle 数据库， SnapCenter 支持共享存储布局，在此布局中，您可以在同一个存储卷或 LUN 上托管多个数据库或数据库的一部分。作为此布局的一个示例，您可以将所有数据库的数据文件托管在 +data ASM 磁盘组或卷组上。其余文件（重做，归档日志和控制文件）可以托管在另一个专用磁盘组或卷组（ LVM ）上。此类部署场景如下所示。</block>
  <block id="6c12e98a6e201f55836390c2a6232e5a" category="paragraph"><block ref="6c12e98a6e201f55836390c2a6232e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93cf45b97655292e0536b810cb248828" category="paragraph">为了便于重新定位 Oracle 数据库， Oracle 二进制文件应安装在常规备份策略中包含的单独 LUN 上。这样可以确保在将数据库重新定位到新服务器主机时，可以启动 Oracle 堆栈进行恢复，而不会因 Oracle 二进制文件不同步而出现任何潜在问题。</block>
  <block id="1e69a4a8adec0842d1e110e970112268" category="section-title">许可要求</block>
  <block id="7f59934b2c0edd33f0d981f3bc4d12e7" category="paragraph">SnapCenter 是 NetApp 提供的许可软件。它通常包含在内部 ONTAP 许可证中。但是，对于混合云部署，要将 CVO 作为目标数据复制目标添加到 SnapCenter ，还需要 SnapCenter 的云许可证。有关详细信息，请查看以下 SnapCenter 基于容量的标准许可证链接：</block>
  <block id="9e86ae6c96041e3cb31e88116102ee35" category="inline-link-macro">基于容量的 SnapCenter 标准版许可证</block>
  <block id="a1d51b5b5f3258b40cbe392146bc8868" category="paragraph"><block ref="a1d51b5b5f3258b40cbe392146bc8868" category="inline-link-macro-rx"></block></block>
  <block id="85db56d490cdd7a31d40697ad1c9be3c" category="section-title">网络和安全性</block>
  <block id="254215e6d18fb5582ba78464fa468553" category="paragraph">在混合数据库操作中，如果需要一个可通过卷到云进行开发 / 测试和灾难恢复的内部生产数据库，则在设置环境并从内部数据中心连接到公有云时，网络连接和安全性是一个重要的考虑因素。</block>
  <block id="1e356fab450b44971b6cdbd1c25586b8" category="paragraph">公有云通常使用虚拟私有云（ Virtual Private Cloud ， VPC ）隔离公共云平台中的不同用户。在单个 VPC 中，可以使用安全组等措施来控制安全性，这些安全组可根据用户锁定 VPC 的需求进行配置。</block>
  <block id="5192a6d33c7a0127a67cbd7e07801735" category="paragraph">可以通过 VPN 通道保护从内部数据中心到 VPC 的连接。在 VPN 网关上，可以使用 NAT 和防火墙规则来加强安全性，这些规则可以阻止尝试从 Internet 上的主机与企业数据中心内的主机建立网络连接。</block>
  <block id="04a3995237c020c6a587d8a7723af6a6" category="paragraph">有关网络和安全注意事项，请查看您选择的公有云的相关入站和出站 CVO 规则：</block>
  <block id="d15513a147fbd525b88805bee9ea17ea" category="inline-link-macro">CVO - AWS 的安全组规则</block>
  <block id="f8d1f085169118c4d407be16136389c6" category="list-text"><block ref="f8d1f085169118c4d407be16136389c6" category="inline-link-macro-rx"></block></block>
  <block id="39f48b44d100d16ed6e2b931111663b7" category="inline-link-macro">CVO 的安全组规则— Azure</block>
  <block id="bcde746324630d82052a4fc9861cfea6" category="list-text"><block ref="bcde746324630d82052a4fc9861cfea6" category="inline-link-macro-rx"></block></block>
  <block id="7b20c547f2fd113499deaa3c0e418282" category="inline-link-macro">CVO - GCP 的防火墙规则</block>
  <block id="acde731d82a437ab33cb200791f7a197" category="list-text"><block ref="acde731d82a437ab33cb200791f7a197" category="inline-link-macro-rx"></block></block>
  <block id="d9446a69434b7c7fdec5c9e35d222834" category="section-title">使用 Ansible 自动化在内部和云之间同步数据库实例—可选</block>
  <block id="1c7c9b49a62ea0dc765d1439120cfc8f" category="paragraph">为了简化混合云数据库环境的管理， NetApp 强烈建议您部署 Ansible 控制器来自动执行某些管理任务，例如将计算实例保持在内部和云中的同步。这一点尤其重要，因为云中的不同步计算实例可能会因缺少内核软件包和其他问题而导致云中恢复的数据库出现错误。</block>
  <block id="7468552c7fc3a7ca377b7fc2405a9940" category="paragraph">此外， Ansible 控制器的自动化功能还可用于在某些任务中扩充 SnapCenter ，例如，拆分 SnapMirror 实例以激活灾难恢复数据副本以投入生产。</block>
  <block id="6ac547919eb6ca11f5a8387eaf990843" category="inline-link-macro">RedHat/CentOS Ansible Controller 设置</block>
  <block id="c8e133fc33bbdb52f84b3532496f2ac8" category="inline-link-macro">Ubuntu 或 Debian Ansible 控制器设置</block>
  <block id="6f332c2f54a4d49478f9588c5cd6c57c" category="paragraph">按照以下说明为 RedHat 或 CentOS 计算机设置 Ansible 控制节点： <block ref="fedce547519117863322cfa54cc2ba7d" category="inline-link-macro-rx"></block>。按照以下说明为 Ubuntu 或 Debian 计算机设置 Ansible 控制节点： <block ref="1c50818f5fe40dbc8b2e05138d554fa4" category="inline-link-macro-rx"></block>。</block>
  <block id="d89002d36151bd13d2bba69f3533ee5f" category="summary">此解决方案为 NetApp 现场人员和客户提供了在公有云中使用基于 NetApp SnapCenter 图形用户界面的工具和 NetApp 存储服务 CVO 配置，操作数据库并将其迁移到混合云环境的说明和指导。</block>
  <block id="8269707c3930f3cbcd49193be33bc125" category="doc">TR-4908 ：《采用 SnapCenter 的混合云数据库解决方案概述》</block>
  <block id="7c4d94e1b484fb577b0aeafbec788ea1" category="paragraph">NetApp 公司 Alan Cao ， Felix Melligan</block>
  <block id="268a30b4d0cad062acd42967ce0fab50" category="paragraph">在以下使用情形下，此解决方案可为 NetApp 现场人员和客户提供有关使用基于 NetApp SnapCenter 图形用户界面的工具和公有云中的 NetApp 存储服务 CVO 配置，操作数据库以及将数据库迁移到混合云环境的说明和指导：</block>
  <block id="e88a2467c8ad8bf481854b1a745a875b" category="list-text">混合云中的数据库开发 / 测试操作</block>
  <block id="3c9552536897a076f75b078a5e2a3703" category="list-text">混合云中的数据库灾难恢复</block>
  <block id="a1ac690c228caf22f3228d3a4d8b5cab" category="paragraph">如今，出于性能，安全性和 / 或其他原因，许多企业数据库仍驻留在私有企业数据中心。这种混合云数据库解决方案支持企业在站点上运行主数据库，同时使用公有云进行开发 / 测试数据库操作以及灾难恢复，以降低许可和运营成本。</block>
  <block id="d900d125b3be40bcb79452d624c38561" category="paragraph">许多企业数据库，例如 Oracle ， SQL Server ， SAP HANA 等， 许可和运营成本高昂。许多客户会根据其数据库环境中的计算核心数量支付一次性许可证费用以及年度支持成本，无论这些核心是用于开发，测试，生产还是灾难恢复。其中许多环境可能无法在整个应用程序生命周期内得到充分利用。</block>
  <block id="1f49cc83c5c3735827e3353f320f5f7f" category="paragraph">这些解决方案为客户提供了一个选项，可通过将专用于开发，测试或灾难恢复的数据库环境迁移到云来降低可获得许可的核心数量。通过使用公共云规模，冗余，高可用性和基于消费的计费模式，许可和运营成本可以大幅节省，同时不会影响任何应用程序的可用性或可用性。</block>
  <block id="1a197dd926608052c7d43edfd09556fa" category="paragraph">除了潜在的数据库许可证成本节省之外， NetApp 基于容量的 CVO 许可证模式还可以帮助客户节省每 GB 的存储成本，同时还可以为客户提供竞争对手的存储服务所不具备的高数据库易管理性。下图显示了公有云中常见存储服务的存储成本比较。</block>
  <block id="810fba7bc9a3829eb522ebbc24326a08" category="paragraph"><block ref="810fba7bc9a3829eb522ebbc24326a08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e222eb27a0002f2960d1cf1e14bbf7d" category="paragraph">此解决方案表明，通过使用基于 SnapCenter 图形用户界面的软件工具和 NetApp SnapMirror 技术，可以轻松设置，实施和操作混合云数据库操作。</block>
  <block id="26cc8c416b5c9fd6bec3dc68e6f2f0c8" category="paragraph">以下视频演示了 SnapCenter 的实际应用：</block>
  <block id="edc6673fe24c4867029921bbe72f25cb" category="inline-link">使用 SnapCenter 在混合云中备份 Oracle 数据库</block>
  <block id="b10d6cd72b187359c3769fbf5ff10e4c" category="list-text"><block ref="0d160cec2141981b284cd9986321651e" category="inline-link-rx"></block></block>
  <block id="68d9033a95c0ed286c9b7e0e7454cd86" category="inline-link">SnapCenter - 将开发 / 测试克隆到 AWS 云以创建 数据库</block>
  <block id="da8d0116fa67f0499837675277668911" category="list-text"><block ref="da8d0116fa67f0499837675277668911" category="inline-link-rx"></block></block>
  <block id="3b04263461ad5a7b57aa872e093ec9fa" category="paragraph">值得注意的是，尽管本文档中的插图显示 CVO 是公有云中的目标存储实例，但解决方案也已通过全面验证，适用于 AWS 的新版本 FSX ONTAP 存储引擎已发布。</block>
  <block id="c5a6d2f45fc4352f35e95d92c804b6f2" category="paragraph">要自行测试解决方案和用例，可通过以下链接请求 NetApp 按需实验室 SL10680 ： https://labondemand.netapp.com/lod3/labtest/request?nodeid=68761&amp;destination=lod3/testlabs[TL_AWS_004 HCOD ： AWS - nw ， SnapCenter （ OnPrem ）^ 。</block>
  <block id="8f7280c86689be0a39cdf74aa673040d" category="summary">此解决方案在混合云环境中设计，用于支持内部生产数据库，这些数据库可以突发到所有常见的公有云中进行开发 / 测试和灾难恢复操作。</block>
  <block id="132f2888eb2cfdeef2730212f50c53e3" category="doc">SnapCenter 要求</block>
  <block id="185b108b21dccef917f415be6026c91c" category="paragraph">我们假定生产数据库服务器托管在内部，并从 ONTAP 存储集群向数据库主机提供数据库卷。SnapCenter 软件安装在内部，用于将数据库备份和数据复制到云。建议使用 Ansible 控制器，但在与公有云中的备用灾难恢复实例或开发 / 测试实例同步的数据库部署自动化或操作系统内核和数据库配置时不需要此控制器。</block>
  <block id="47099d9ea153f8abfa5b6b70da253b3a" category="cell">* 内部部署 *</block>
  <block id="d36407241494bfc1e84614ad1b0dd6a4" category="cell">SnapCenter 支持的任何数据库和版本</block>
  <block id="8c8c8ca7a4093a1210412a3a5e5ad55f" category="cell">SnapCenter v4.4 或更高版本</block>
  <block id="9d9ebf67dab68c3c892de99e981039cf" category="cell">Ansible v2.09 或更高版本</block>
  <block id="62dd4f48e99b13c8a00fbaba684f9592" category="cell">ONTAP 集群 9.x</block>
  <block id="d0fdc58e1e05d6cbc8b1beb072bfa235" category="cell">已配置集群间 LIF</block>
  <block id="7135df562bcb25bfdf20e4317b923b88" category="cell">从内部到云 VPC 的连接（ VPN ，互连等）</block>
  <block id="8c27863f5ffd0e66a9304eaca2e47fde" category="cell">网络端口打开 - ssh 22 - TCP 8145 ， 8146 ， 10000 ， 11104 ， 11105</block>
  <block id="bcb9f3419f724f768e30956a4427261d" category="cell">* 云 - AWS*</block>
  <block id="61c90d44785278f980592f082ef500f1" category="inline-link">Cloud Manager Connector</block>
  <block id="97bc5062dceccb6827b1e3f0522035f0" category="cell"><block ref="97bc5062dceccb6827b1e3f0522035f0" category="inline-link-rx"></block></block>
  <block id="2f077494ceff1f33085c5b163c3673b3" category="cell"><block ref="2f077494ceff1f33085c5b163c3673b3" category="inline-link-rx"></block></block>
  <block id="59b2c9424963f98d73ec69c59dde54cb" category="cell">将数据库操作系统 EC2 实例与本地匹配</block>
  <block id="e26786a16da88ee829ab76c48fd3b003" category="cell">* 云 - Azure*</block>
  <block id="c2f8674b07907f393b67a3f9e98d3d56" category="cell"><block ref="c2f8674b07907f393b67a3f9e98d3d56" category="inline-link-rx"></block></block>
  <block id="a8dd724647657a383eb37fd8775ec1a9" category="cell"><block ref="a8dd724647657a383eb37fd8775ec1a9" category="inline-link-rx"></block></block>
  <block id="8bede1f0e559918be01f0646b75b4257" category="cell">将数据库操作系统 Azure 虚拟机与本地匹配</block>
  <block id="b2a454fb4ff03b84162c59d674fdae25" category="cell">* 云 - GCP*</block>
  <block id="af072236983e991ab34e773871b10236" category="cell"><block ref="af072236983e991ab34e773871b10236" category="inline-link-rx"></block></block>
  <block id="499477cf7953707f63a1b1313c8c065a" category="cell"><block ref="499477cf7953707f63a1b1313c8c065a" category="inline-link-rx"></block></block>
  <block id="2900c5e1ee191606f20d007194e70edf" category="cell">将数据库操作系统 Google 计算引擎实例与内部环境匹配</block>
  <block id="d0bb28dcc0cc1b523a41bbb46875db9e" category="summary">在安装 Cloud Manager Connector 和 Cloud Volumes ONTAP 并配置 SnapMirror 之前，我们必须为云环境做一些准备。此页面介绍了部署 Cloud Volumes ONTAP 时需要执行的工作以及注意事项。</block>
  <block id="8c6fb9ece3bad11d3e76d1344d9ed9ab" category="doc">公有云的前提条件</block>
  <block id="5a2798d22185b0e40ea502bbbb171d38" category="section-title">Cloud Manager 和 Cloud Volumes ONTAP 部署前提条件检查清单</block>
  <block id="1e094e6477be231098329b0096c7221f" category="list-text">NetApp Cloud Central 登录</block>
  <block id="b59e275c4ece2430dff67db92845ab7f" category="list-text">从 Web 浏览器到多个端点的网络访问</block>
  <block id="d2ed5c7ede8a1ce9d218ec60b0f03935" category="list-text">连接器的网络位置</block>
  <block id="0d07862d67097acd517fe27c0de099d7" category="list-text">云提供商权限</block>
  <block id="203802866ac2835e79bd76c94a3761c2" category="list-text">为单个服务建立网络</block>
  <block id="c4d5e1cbdfc47a0fdcb4a1a9dddd9e17" category="inline-link">云文档</block>
  <block id="1a22a3f7b690b2ec8919c8806633fb26" category="paragraph">有关入门内容的详细信息，请访问我们的<block ref="247d95fa755d21bb8790cc6d7a2fc412" category="inline-link-rx"></block>。</block>
  <block id="ea61e2c2ff507048203824add1eb7c21" category="section-title">注意事项</block>
  <block id="176ca67b83510a1281a4cfc749a3543a" category="section-title">1. 什么是 Cloud Manager 连接器？</block>
  <block id="1681641037afae45bd6074dcde9eed00" category="paragraph">在大多数情况下， Cloud Central 帐户管理员必须在云或内部网络中部署连接器。借助此连接器， Cloud Manager 可以管理公有云环境中的资源和流程。</block>
  <block id="8a78be5d168f00b24bf1625de3d5409c" category="paragraph">有关连接器的详细信息，请访问我们的<block ref="f39c14bbbbdd46ca70a63fb06046c789" category="inline-link-rx"></block>。</block>
  <block id="fcc2bf38b8157a22b5fc6975b7054acc" category="section-title">2. Cloud Volumes ONTAP 规模估算和架构</block>
  <block id="1c09b5154aa1f43cb9ebcbd6fea5eadc" category="paragraph">部署 Cloud Volumes ONTAP 时，您可以选择预定义的软件包或创建自己的配置。虽然其中许多值稍后可以无中断地进行更改，但在部署之前，需要根据要在云中部署的工作负载做出一些关键决策。</block>
  <block id="331ce28903aee0b30cd3c94e5483edf5" category="inline-link">CVO 规模估算工具</block>
  <block id="acaed5d74e38e1779b3831dcf51c7600" category="paragraph">每个云提供商都有不同的部署选项，几乎每个工作负载都有自己的独特属性。NetApp 具有<block ref="6a71e7e42ab9335484c5530029f79b92" category="inline-link-rx"></block> 这有助于根据容量和性能正确估算部署规模，但它是围绕一些基本概念构建的，值得考虑：</block>
  <block id="145c90afb7955854f2371e9decf3de9b" category="list-text">所需容量</block>
  <block id="f1521b662bf51f1af6c2d38bd610afae" category="list-text">云虚拟机的网络功能</block>
  <block id="f75d8ba5edc8017382d5df68baf9e30f" category="list-text">云存储的性能特征</block>
  <block id="af9d66ea3132fcfeb46b85557bc1af1b" category="paragraph">关键在于规划的配置不仅要满足当前的容量和性能要求，还要考虑未来的增长。这通常称为容量余量和性能余量。</block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="inline-link">AWS</block>
  <block id="3a580f142203677f1f0bc30898f63f53" category="inline-link">Azure 酒店</block>
  <block id="c731f72e1d22a7c5e01a7cb789a8885e" category="inline-link">GCP</block>
  <block id="180f0326dff3a03aecf5e184943d108a" category="paragraph">如果您希望了解更多信息，请阅读有关正确规划的文档<block ref="af5d70b69c3436f8bcf6f7b9579c4e83" category="inline-link-rx"></block>，<block ref="c2e85b51d3015b4c720388e64a3de23e" category="inline-link-rx"></block>，和<block ref="b1068926334a08925797774f64291db4" category="inline-link-rx"></block>。</block>
  <block id="c50ea1f0c6dcf02fbdd39e1e6b5befc2" category="section-title">3. 单节点还是高可用性？</block>
  <block id="eadb13b9c72271dbf16967e78059fea4" category="paragraph">在所有云中，您可以选择在单个节点或具有两个节点的集群模式高可用性对中部署 CVO 。根据使用情形，您可能希望部署一个节点以节省成本，或者部署一个 HA 对以提供进一步的可用性和冗余。</block>
  <block id="9cbd119b18cd836b6020fcfd3bfbe37f" category="paragraph">对于灾难恢复使用情形或为开发和测试而启动临时存储的情形，单个节点很常见，因为突然的区域或基础架构中断所造成的影响较小。但是，对于任何生产用例，如果数据仅位于一个位置，或者数据集必须具有更多冗余和可用性，则建议使用高可用性。</block>
  <block id="83d2ad0cda1f71c52878284cc7c1f713" category="paragraph">有关每个云高可用性版本的架构的详细信息，请访问的文档<block ref="4344469628657b2a6a0d147e5e6fbc9a" category="inline-link-rx"></block>，<block ref="28a8305eced80cb5b1351f5cffb268ae" category="inline-link-rx"></block> 和<block ref="1b945d178a8347e94e5c5456dc9e6db8" category="inline-link-rx"></block>。</block>
  <block id="a10998cc3e1dc7f2a013754d935c4f26" category="summary">NetApp SnapCenter 工具使用基于角色的访问控制（ Role-Based Access Control ， RBAC ）来管理用户资源访问和权限授予，而 SnapCenter 安装会创建预先填充的角色。您还可以根据需要或应用程序创建自定义角色。</block>
  <block id="7e3b07f9add4cd78ade3c795a52dfad2" category="doc">内部部署入门</block>
  <block id="d30e54646ba482722332f48ddc22bde5" category="section-title">1. 在 SnapCenter 中设置数据库管理员用户</block>
  <block id="27733e8f07432bb94ac7621b28d3b2c8" category="paragraph">某些 SnapCenter 资源只能使用 SnapCenterAdmin 角色进行配置。然后，可以将资源分配给其他用户 ID 以进行访问。</block>
  <block id="64784aa3cec13e83af6e941f8489cf06" category="paragraph">在预安装和配置的内部 SnapCenter 环境中，以下任务可能已完成。如果不是，以下步骤将创建一个数据库管理员用户：</block>
  <block id="c8867eac833e7bb55520105b00139f1a" category="list-text">将管理员用户添加到 Windows Active Directory 。</block>
  <block id="dd3e743eb52cbe7c2b6104573a9767e0" category="list-text">使用 SnapCenterAdmin 角色授予的 ID 登录到 SnapCenter 。</block>
  <block id="a6bd76cb24271ba173d16f01bf4108d0" category="list-text">导航到设置和用户下的访问选项卡，然后单击添加以添加新用户。新用户 ID 将链接到步骤 1 中在 Windows Active Directory 中创建的管理员用户。。根据需要为用户分配适当的角色。根据需要向管理员用户分配资源。</block>
  <block id="6a67bb048bd14dd348cca7f81b62d699" category="paragraph"><block ref="6a67bb048bd14dd348cca7f81b62d699" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5d2c51e83f473f137861a132554d1916" category="section-title">2. SnapCenter 插件安装前提条件</block>
  <block id="7bd973d4d28d6fcf5f50379b33a49758" category="paragraph">SnapCenter 使用数据库主机上运行的插件代理执行备份，还原，克隆和其他功能。它会通过在设置和凭据选项卡下配置的凭据连接到数据库主机和数据库，以便安装插件和执行其他管理功能。根据目标主机类型（如 Linux 或 Windows ）以及数据库类型，有特定的权限要求。</block>
  <block id="c342f214098114b90cb67297a2ef5dc3" category="paragraph">在安装 SnapCenter 插件之前，必须配置数据库主机凭据。通常，您希望使用数据库主机上的管理员用户帐户作为插件安装的主机连接凭据。您还可以使用基于操作系统的身份验证为数据库访问授予相同的用户 ID 。另一方面，您还可以使用不同数据库用户 ID 进行数据库身份验证，以进行数据库管理访问。如果您决定使用基于操作系统的身份验证，则必须为操作系统管理员用户 ID 授予数据库访问权限。对于基于 Windows 域的 SQL Server 安装，可以使用域管理员帐户管理域中的所有 SQL Server 。</block>
  <block id="19df1192effefad83e57653fd3a47415" category="paragraph">适用于 SQL Server 的 Windows 主机：</block>
  <block id="e1cc3ce53d7753e33588201db3d3b147" category="list-text">如果使用 Windows 凭据进行身份验证，则必须在安装插件之前设置凭据。</block>
  <block id="a82f1290b72a26d654b93632a1ec50bb" category="list-text">如果使用 SQL Server 实例进行身份验证，则必须在安装插件后添加凭据。</block>
  <block id="63f74bef6650942c6795f96366a39e6a" category="list-text">如果在设置凭据时启用了 SQL 身份验证，则发现的实例或数据库将显示一个红色锁定图标。如果显示锁定图标，则必须指定实例或数据库凭据才能成功将实例或数据库添加到资源组。</block>
  <block id="b61dad3bbbf3270bf2dada5c2ac1f775" category="list-text">满足以下条件时，必须将凭据分配给不具有 sysadmin 访问权限的 RBAC 用户：</block>
  <block id="34cefb5a19894e4f9b1b068544c0f591" category="list-text">此凭据将分配给 SQL 实例。</block>
  <block id="6707464a5871a6aa26dcf785bea4052c" category="list-text">SQL 实例或主机已分配给 RBAC 用户。</block>
  <block id="4bc8aac02ff00d874ad8b4ccd4d745ed" category="list-text">RBAC DB 管理员用户必须同时具有资源组和备份权限。</block>
  <block id="9198b455aa67840c7a69c7a54e94301a" category="paragraph">适用于 Oracle 的 UNIX 主机：</block>
  <block id="71d53e54a48cfe7de69347bcd854ef30" category="list-text">您必须已通过编辑 sshd.conf 并重新启动 sshd 服务为 root 或非 root 用户启用基于密码的 SSH 连接。默认情况下， AWS 实例上基于密码的 SSH 身份验证处于关闭状态。</block>
  <block id="efa873f0464a14d54b066f475ad74480" category="list-text">为非 root 用户配置 sudo 权限以安装和启动插件过程。安装插件后，这些进程将以有效 root 用户身份运行。</block>
  <block id="82a2174029175f8fbc3f52fea4e18c84" category="list-text">使用 Linux 身份验证模式为安装用户创建凭据。</block>
  <block id="86b3cc44ebd8e0a9185e48c4f22e81e9" category="list-text">必须在 Linux 主机上安装 Java 1.8.x （ 64 位）。</block>
  <block id="c1e8851d10ecc615c47a47f704569d29" category="list-text">安装 Oracle 数据库插件还会安装适用于 Unix 的 SnapCenter 插件。</block>
  <block id="7efb27733d1fb21feae901a41580dced" category="section-title">3. SnapCenter 主机插件安装</block>
  <block id="37a5c714defad8175b81b4d49eb0544c" category="admonition">在尝试在云数据库服务器实例上安装 SnapCenter 插件之前，请确保已完成计算实例部署的相关云部分中列出的所有配置步骤。</block>
  <block id="283aa502c28fe1c9ff8dadd1700955fc" category="paragraph">以下步骤说明了在主机上安装 SnapCenter 插件时如何将数据库主机添加到 SnapCenter 中。操作步骤适用场景同时添加内部主机和云主机。以下演示将添加驻留在 AWS 中的 Windows 或 Linux 主机。</block>
  <block id="81ed46777c39c0d0618953601572fc27" category="section-title">配置 SnapCenter VMware 全局设置</block>
  <block id="2aa8a40dbbfb6b52621408c81aa5373c" category="paragraph">导航到设置 &gt; 全局设置。在 Hypervisor Settings 下选择 "VM have iSCSI direct attached disks or NFS for all the hosts" ，然后单击 Update 。</block>
  <block id="4c120331c9eea223eee675b6588d76ee" category="paragraph"><block ref="4c120331c9eea223eee675b6588d76ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f63a469619859e4cfab52fd63523aca" category="section-title">添加 Windows 主机并在主机上安装插件</block>
  <block id="997da6deedab4436b559e3a8f7f05a2e" category="list-text">使用具有 SnapCenterAdmin 权限的用户 ID 登录到 SnapCenter 。</block>
  <block id="97e7f600216a2e9ae18423777e11ad9c" category="list-text">单击左侧菜单中的主机选项卡，然后单击添加以打开添加主机工作流。</block>
  <block id="35314bae57d7ff62ab36156211c1cc71" category="list-text">选择 Windows 作为主机类型；主机名可以是主机名或 IP 地址。主机名必须从 SnapCenter 主机解析为正确的主机 IP 地址。选择在步骤 2 中创建的主机凭据。选择 Microsoft Windows 和 Microsoft SQL Server 作为要安装的插件软件包。</block>
  <block id="b9740ae9eb2ef0fe27e4c541d06a961f" category="paragraph"><block ref="b9740ae9eb2ef0fe27e4c541d06a961f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31efcd689861354799bb539ab2571ebe" category="list-text">在 Windows 主机上安装此插件后，其整体状态将显示为 "Configure log directory" 。</block>
  <block id="0e15e25c5ee21469698f72cf35caa7bf" category="paragraph"><block ref="0e15e25c5ee21469698f72cf35caa7bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2aeaa4503c6d72513c0dbe0f205ee3b" category="list-text">单击主机名以打开 SQL Server 日志目录配置。</block>
  <block id="6fc78660a180b747f815b878c89e3cb0" category="paragraph"><block ref="6fc78660a180b747f815b878c89e3cb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb2b40646a77b4f044e7fa04ea20306" category="list-text">单击 " 配置日志目录 " 以打开 " 为 SQL Server 配置插件 " 。</block>
  <block id="5e3bf9ddacfcad12c5cf63614a869ad4" category="paragraph"><block ref="5e3bf9ddacfcad12c5cf63614a869ad4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7143b5d162d385dfb1af07f61c59f65" category="list-text">单击浏览以发现 NetApp 存储，以便可以设置日志目录； SnapCenter 使用此日志目录来汇总 SQL Server 事务日志文件。然后单击保存。</block>
  <block id="50eb49de485da684ac1556947ac46aba" category="paragraph"><block ref="50eb49de485da684ac1556947ac46aba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0d88588bdb07dd412a4ba1d08348b29" category="admonition">要发现配置到数据库主机的 NetApp 存储，必须将存储（内部或 CVO ）添加到 SnapCenter 中，如 CVO 的步骤 6 中所示。</block>
  <block id="d744af12906d55ab51aa932b3ffcd121" category="list-text">配置日志目录后， Windows 主机插件的整体状态将更改为正在运行。</block>
  <block id="3f7bfffdbb76fd620b0a31d300415528" category="paragraph"><block ref="3f7bfffdbb76fd620b0a31d300415528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41517f2e270a138f4ae92988a4cbdd2" category="list-text">要将主机分配给数据库管理用户 ID ，请导航到 " 设置和用户 " 下的 " 访问 " 选项卡，单击数据库管理用户 ID （在我们的情况下，是指需要将主机分配到的 sqldba ），然后单击 " 保存 " 完成主机资源分配。</block>
  <block id="b21f826d2ea15e58b9c8aadccb566cfe" category="paragraph"><block ref="b21f826d2ea15e58b9c8aadccb566cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021de72edbb0f174ffe954c5e5367b80" category="paragraph"><block ref="021de72edbb0f174ffe954c5e5367b80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2fe19c733a6342990513e02264db163" category="section-title">添加 Unix 主机并在主机上安装插件</block>
  <block id="6a0f36be9f208d20c3c1145c3a09b876" category="list-text">单击左侧菜单中的主机选项卡，然后单击添加以打开添加主机工作流。</block>
  <block id="dd8c6d773e31c4254eb58b4b5e2ae1be" category="list-text">选择 Linux 作为主机类型。主机名可以是主机名或 IP 地址。但是，必须解析主机名，以更正 SnapCenter 主机的主机 IP 地址。选择在步骤 2 中创建的主机凭据。主机凭据需要 sudo 权限。选中 Oracle Database 作为要安装的插件，该插件将同时安装 Oracle 和 Linux 主机插件。</block>
  <block id="7d4cdef2144fd1466fae298bd27476d1" category="paragraph"><block ref="7d4cdef2144fd1466fae298bd27476d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="711730391561a228d41f7fede13ca6e8" category="list-text">单击更多选项并选择 " 跳过预安装检查 " 。 系统会提示您确认是否跳过预安装检查。单击是，然后单击保存。</block>
  <block id="3511b18d059f3f300b5fbe827f7273ac" category="paragraph"><block ref="3511b18d059f3f300b5fbe827f7273ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e095a093138c6b1968d313d5f799255a" category="list-text">单击提交以开始安装插件。系统将提示您确认指纹，如下所示。</block>
  <block id="146c4805beb9310e4554842f776cb88b" category="paragraph"><block ref="146c4805beb9310e4554842f776cb88b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53dcda6f2c03efbe73ae5eb311852a8d" category="list-text">SnapCenter 将执行主机验证和注册，然后该插件将安装在 Linux 主机上。状态将从 " 正在安装插件 " 更改为 " 正在运行 " 。</block>
  <block id="2636403a6c50748422736d9d84a3e4be" category="paragraph"><block ref="2636403a6c50748422736d9d84a3e4be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="33ea9d9313933c68d640ebb655ec43dc" category="list-text">将新添加的主机分配给正确的数据库管理用户 ID （在我们的案例中为 oradba ）。</block>
  <block id="2815d2f5e3b49d9332a320ec997271dd" category="paragraph"><block ref="2815d2f5e3b49d9332a320ec997271dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb6a9566891a97e0f8fbaefbd4878bdd" category="paragraph"><block ref="eb6a9566891a97e0f8fbaefbd4878bdd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b4c839521fd41e845e6e8c3158b809b" category="section-title">4. 数据库资源发现</block>
  <block id="45e46a9524f23884445bf542bf464b93" category="paragraph">成功安装插件后，可以立即发现主机上的数据库资源。单击左侧菜单中的 "Resources" 选项卡。根据数据库平台的类型，可以使用多种视图，例如数据库，资源组等。如果未发现和显示主机上的资源，则可能需要单击刷新资源选项卡。</block>
  <block id="79fca6395972f8079320d3229822e491" category="paragraph"><block ref="79fca6395972f8079320d3229822e491" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66789731e61fd3d4b6024e5fcb0945e1" category="paragraph">首次发现数据库时，整体状态显示为 " 不受保护 " 。 上一屏幕截图显示了一个尚未受备份策略保护的 Oracle 数据库。</block>
  <block id="68148a1249ca9110d03c698ae152932a" category="paragraph">设置备份配置或策略并执行备份后，数据库的整体状态会将备份状态显示为 " 备份成功 " ，并显示上次备份的时间戳。以下屏幕截图显示了 SQL Server 用户数据库的备份状态。</block>
  <block id="2cdfb74ac3aabfde7e1fae347ed5afc7" category="paragraph"><block ref="2cdfb74ac3aabfde7e1fae347ed5afc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c9616324bc00808729d46fba94ad75" category="paragraph">如果未正确设置数据库访问凭据，则红色锁定按钮表示数据库不可访问。例如，如果 Windows 凭据不具有对数据库实例的 sysadmin 访问权限，则必须重新配置数据库凭据以解除红色锁定。</block>
  <block id="dd4606e87689c86d82a694412c5654a5" category="paragraph"><block ref="dd4606e87689c86d82a694412c5654a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="884f07ad394b89553e7d6d1f90fae584" category="paragraph"><block ref="884f07ad394b89553e7d6d1f90fae584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0024854a814ddd68bcf3907357c46bc2" category="paragraph">在 Windows 级别或数据库级别配置相应的凭据后，红色锁定将消失，并收集和查看 SQL Server 类型信息。</block>
  <block id="95c88e08b2fd416b4514ce2454af2038" category="paragraph"><block ref="95c88e08b2fd416b4514ce2454af2038" category="inline-image-macro-rx" type="image"></block></block>
  <block id="864f4d2595d06e5e8b46b08edb3899e6" category="section-title">5. 设置存储集群对等和数据库卷复制</block>
  <block id="785196ec55a9e713ad1a4f962baa31dd" category="paragraph">为了使用公有云作为目标目标目标来保护内部数据库数据，使用 NetApp SnapMirror 技术将内部 ONTAP 集群数据库卷复制到云 CVO 。然后，可以克隆复制的目标卷以进行开发 / 运营或灾难恢复。通过以下高级步骤，您可以设置集群对等和数据库卷复制。</block>
  <block id="1f1927293f04e4cf0fc91a7e389612eb" category="list-text">在内部集群和 CVO 集群实例上配置集群间 LIF 以建立集群对等关系。此步骤可使用 ONTAP 系统管理器执行。默认 CVO 部署会自动配置集群间 LIF 。</block>
  <block id="9547803d96e78bbc38305e6300f7a800" category="paragraph">内部集群：</block>
  <block id="2ef6da9ba547bc5361495650ac3fc992" category="paragraph"><block ref="2ef6da9ba547bc5361495650ac3fc992" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3c5b3e342f57b792e2263e69e41677a" category="paragraph">目标 CVO 集群：</block>
  <block id="d94586e4cd285619a4f1ef0e06636dd1" category="paragraph"><block ref="d94586e4cd285619a4f1ef0e06636dd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79d372933b80ed2ca8ca14d8458828af" category="inline-link-macro">入门— AWS 公有云</block>
  <block id="6a87ea28950f9209121872c9d2690049" category="list-text">配置集群间 LIF 后，可以使用 NetApp Cloud Manager 中的拖放功能设置集群对等和卷复制。请参见 <block ref="28783e162df4af496939d6f9f6f31d5f" category="inline-link-macro-rx"></block> 了解详细信息。</block>
  <block id="d1567c6c8f0752cbc7deb6d9f639ba12" category="paragraph">或者，也可以使用 ONTAP 系统管理器执行集群对等和数据库卷复制，如下所示：</block>
  <block id="494c0b53ff31502c0c1105881e2e389a" category="list-text">登录到 ONTAP 系统管理器。导航到集群 &gt; 设置，然后单击对等集群，以便与云中的 CVO 实例建立集群对等关系。</block>
  <block id="ba770272a0f634af47a5788634e80d54" category="paragraph"><block ref="ba770272a0f634af47a5788634e80d54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54de72c782c4b4ccc7f2914a858d5356" category="list-text">转到卷选项卡。选择要复制的数据库卷，然后单击保护。</block>
  <block id="32588f46a47679329b03194fd2e9084f" category="paragraph"><block ref="32588f46a47679329b03194fd2e9084f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0aace069b478e8b2b0753f855f2be94" category="list-text">将保护策略设置为异步。选择目标集群和 Storage SVM 。</block>
  <block id="7dbec53b432ae53f7e454836ad0dad00" category="paragraph"><block ref="7dbec53b432ae53f7e454836ad0dad00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a2a64fe8af0790615a9344069794e2e" category="list-text">验证卷是否已在源和目标之间同步，以及复制关系是否运行正常。</block>
  <block id="97edcd79a5e90d9caafde40fcb586185" category="paragraph"><block ref="97edcd79a5e90d9caafde40fcb586185" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36097c4ad6058de288de8992f89adbb8" category="section-title">6. 将 CVO 数据库存储 SVM 添加到 SnapCenter</block>
  <block id="ebcf85d67af3f672ade8bd7b224a8a2b" category="list-text">从菜单中单击存储系统选项卡，然后单击新建将托管复制的目标数据库卷的 CVO 存储 SVM 添加到 SnapCenter 。在存储系统字段中输入集群管理 IP ，然后输入相应的用户名和密码。</block>
  <block id="41e9c94a0c8cb108959099b8f87adb82" category="paragraph"><block ref="41e9c94a0c8cb108959099b8f87adb82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a27406b63f99780f65572b95f2f72348" category="list-text">单击更多选项以打开其他存储配置选项。在平台字段中，选择 Cloud Volumes ONTAP ，选中二级，然后单击保存。</block>
  <block id="8a60464ab91cb2499a03c722639c3aee" category="paragraph"><block ref="8a60464ab91cb2499a03c722639c3aee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b474a0a2de59b8e3013112beb48af7b7" category="list-text">将存储系统分配给 SnapCenter 数据库管理用户 ID ，如所示 <block ref="8a46cbc3838a53b9205abb25a577bbc8" category="inline-xref-macro-rx"></block>。</block>
  <block id="8691f91a1fe977fd76aa5e53b0f71034" category="paragraph"><block ref="8691f91a1fe977fd76aa5e53b0f71034" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39ec95149453e7bb6b73f1c03228e85c" category="section-title">7. 在 SnapCenter 中设置数据库备份策略</block>
  <block id="37d9f685e375f77a2231e13c88ccc606" category="paragraph">以下过程演示了如何创建完整的数据库或日志文件备份策略。然后，可以实施此策略来保护数据库资源。恢复点目标（ RPO ）或恢复时间目标（ RTO ）决定了数据库和 / 或日志备份的频率。</block>
  <block id="739184f368f13e142dd034fcdc853594" category="section-title">为 Oracle 创建完整的数据库备份策略</block>
  <block id="94b39254a7aba068b68fec64f6331b0b" category="list-text">以数据库管理用户 ID 身份登录到 SnapCenter ，单击设置，然后单击策略。</block>
  <block id="90affc4ffbb767a3d1272be5e1ad8f0c" category="paragraph"><block ref="90affc4ffbb767a3d1272be5e1ad8f0c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1d144b8c78fc8541b57aa9f0ca863a6" category="list-text">单击 " 新建 " 启动新的备份策略创建工作流或选择要修改的现有策略。</block>
  <block id="29618ae8465c694d23d68e171fe9d905" category="paragraph"><block ref="29618ae8465c694d23d68e171fe9d905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c9dac29c26006ce512153a9bdabcc95" category="list-text">选择备份类型和计划频率。</block>
  <block id="10e2791563a2891fd7e4e68c5673671b" category="paragraph"><block ref="10e2791563a2891fd7e4e68c5673671b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4df94ad44381c9fb7fe2f8d01dcd16d8" category="list-text">设置备份保留设置。此选项用于定义要保留的完整数据库备份副本数。</block>
  <block id="6dcc4aa023085480846059b6b1d5e5b3" category="paragraph"><block ref="6dcc4aa023085480846059b6b1d5e5b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd634020906b35a41e0ba633eddeb96a" category="list-text">选择二级复制选项以将要复制到云中二级位置的本地主快照备份推送到云中。</block>
  <block id="25ef9e4c73a2da8519e8d232b6a95fcb" category="paragraph"><block ref="25ef9e4c73a2da8519e8d232b6a95fcb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2e3af55a4355bc46e91425ac5701174" category="list-text">指定在备份运行前后运行的任何可选脚本。</block>
  <block id="326d50fae4f713cebe97d0f6bb23a2d9" category="paragraph"><block ref="326d50fae4f713cebe97d0f6bb23a2d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd009bc210e371d36d466b592179e883" category="list-text">根据需要运行备份验证。</block>
  <block id="0b132e3438f5cf31e90f45e79710f0b9" category="paragraph"><block ref="0b132e3438f5cf31e90f45e79710f0b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba73d3ec3f929ff18665087076291ac" category="list-text">摘要</block>
  <block id="4f92fa99421beeb9f74ee7613de52706" category="paragraph"><block ref="4f92fa99421beeb9f74ee7613de52706" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3594f2789840eda9633139ca530384a" category="section-title">为 Oracle 创建数据库日志备份策略</block>
  <block id="be763ec2afcb0358426bb0abcae4dd60" category="list-text">使用数据库管理用户 ID 登录到 SnapCenter ，单击设置，然后单击策略。</block>
  <block id="b0e663a3d363868d6c71ab9ec37940c6" category="list-text">单击 " 新建 " 启动新的备份策略创建工作流，或者选择现有策略进行修改。</block>
  <block id="fa2687f5a5fbedb43745f649a2e11950" category="paragraph"><block ref="fa2687f5a5fbedb43745f649a2e11950" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0938f6574b189bdac27cdd92abc521c5" category="paragraph"><block ref="0938f6574b189bdac27cdd92abc521c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59480846ec23463481d361bf3026235e" category="list-text">设置日志保留期限。</block>
  <block id="c8df578fbf71151edda735bc81e8511c" category="paragraph"><block ref="c8df578fbf71151edda735bc81e8511c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04ba33c0584145006ca637b4556aa919" category="list-text">启用复制到公有云中的二级位置。</block>
  <block id="fdbe42a8484a3e984e4aacb6a31cccef" category="paragraph"><block ref="fdbe42a8484a3e984e4aacb6a31cccef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab9406cbd3a8f082700523fdac8a0c1d" category="list-text">指定在日志备份前后运行的任何可选脚本。</block>
  <block id="5b04423521e56720f1f5d0291db584ef" category="paragraph"><block ref="5b04423521e56720f1f5d0291db584ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4b55e05a9ae89fe14377b98bc8a8166" category="list-text">指定任何备份验证脚本。</block>
  <block id="c4dc219fd9466ab86c22ac8e859384ea" category="paragraph"><block ref="c4dc219fd9466ab86c22ac8e859384ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2564f2d008c62044da1b7f7397252edf" category="paragraph"><block ref="2564f2d008c62044da1b7f7397252edf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe147647227dfec6603bc76daf30463e" category="section-title">为 SQL 创建完整的数据库备份策略</block>
  <block id="fa726a7e85857bee77ace96dcf7e5316" category="paragraph"><block ref="fa726a7e85857bee77ace96dcf7e5316" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce2168daff0c9b1a74e59d999d6ead44" category="paragraph"><block ref="ce2168daff0c9b1a74e59d999d6ead44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30637cfd5a5cc820d6bc4116fccfff7e" category="list-text">定义备份选项和计划频率。对于配置了可用性组的 SQL Server ，可以设置首选备份副本。</block>
  <block id="b520dcfd25c4b29395bb9b12ac643bb2" category="paragraph"><block ref="b520dcfd25c4b29395bb9b12ac643bb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f74ada8393aecd40e892de04b5b30f8" category="list-text">设置备份保留期限。</block>
  <block id="4ade95d8122243cda1455b04504d3367" category="paragraph"><block ref="4ade95d8122243cda1455b04504d3367" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1a67a80a7ad9403781b210983ea778d" category="list-text">启用备份副本复制到云中的二级位置。</block>
  <block id="caf8324e53d9bb41b3ecb64f3e3b7dda" category="paragraph"><block ref="caf8324e53d9bb41b3ecb64f3e3b7dda" category="inline-image-macro-rx" type="image"></block></block>
  <block id="17b7b360fc2163537795a34cd8d14d6a" category="list-text">指定在备份作业之前或之后运行的任何可选脚本。</block>
  <block id="abbc7de57d2b0d5d1c462b7513199253" category="paragraph"><block ref="abbc7de57d2b0d5d1c462b7513199253" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb836d972496d965dd2170ed1480917b" category="list-text">指定用于运行备份验证的选项。</block>
  <block id="b4dd01df6b310e6b0814328a86bd6ed6" category="paragraph"><block ref="b4dd01df6b310e6b0814328a86bd6ed6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67cfb8548ccb78172db31d7af494fa02" category="paragraph"><block ref="67cfb8548ccb78172db31d7af494fa02" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b67ed2348002e614d5a35151577632" category="section-title">为 SQL 创建数据库日志备份策略。</block>
  <block id="b405195aec7cf62440373fcdc490dec6" category="list-text">使用数据库管理用户 ID 登录到 SnapCenter ，单击 " 设置 "&gt;" 策略 " ，然后单击 " 新建 " 以启动新的策略创建工作流。</block>
  <block id="c236030076b67936a7c1c11d49408838" category="paragraph"><block ref="c236030076b67936a7c1c11d49408838" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acdaf46fc90606d68f3f2b52cca5e95b" category="list-text">定义日志备份选项和计划频率。对于配置了可用性组的 SQL Server ，可以设置首选备份副本。</block>
  <block id="19ab604707a9384fa4883cedd5a525f9" category="paragraph"><block ref="19ab604707a9384fa4883cedd5a525f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da00d968a5d810d846ddc815b8f405a4" category="list-text">SQL Server 数据备份策略定义日志备份保留；接受此处的默认值。</block>
  <block id="783828e5ae6dcfd713966e7301831296" category="paragraph"><block ref="783828e5ae6dcfd713966e7301831296" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d04d89062d3ed67bbc9c4aee35bdba7f" category="list-text">启用日志备份复制到云中的二级卷。</block>
  <block id="b1968bd01bc5c402dcd27c99ce6326cc" category="paragraph"><block ref="b1968bd01bc5c402dcd27c99ce6326cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30c50cf9d6726341a29a3caf97dc84e8" category="paragraph"><block ref="30c50cf9d6726341a29a3caf97dc84e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4d9b291b4ffaddb50c99313e530077f" category="paragraph"><block ref="c4d9b291b4ffaddb50c99313e530077f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f28f6c36698b3a4cd47cbeead15eddf2" category="section-title">8. 实施备份策略以保护数据库</block>
  <block id="37b889cc1b57f66ae9018b6eacb891ba" category="paragraph">SnapCenter 使用资源组以数据库资源的逻辑分组形式备份数据库，例如，服务器上托管的多个数据库，共享相同存储卷的数据库，支持业务应用程序的多个数据库等。保护单个数据库会创建自己的资源组。以下过程演示如何实施第 7 节中创建的备份策略来保护 Oracle 和 SQL Server 数据库。</block>
  <block id="0603dbbe978e4cd3ee1c45ba96a1aa6f" category="section-title">创建一个资源组以对 Oracle 进行完整备份</block>
  <block id="5f4e02f34bcd7993867c4b3297a171d0" category="list-text">使用数据库管理用户 ID 登录到 SnapCenter ，然后导航到资源选项卡。在视图下拉列表中，选择数据库或资源组以启动资源组创建工作流。</block>
  <block id="6eac6f96ac8d968dfec8184d16a73d43" category="paragraph"><block ref="6eac6f96ac8d968dfec8184d16a73d43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="98dcf41bcde9cb6c4235a6a7dfe69346" category="list-text">提供资源组的名称和标记。您可以为 Snapshot 副本定义命名格式，并绕过冗余归档日志目标（如果已配置）。</block>
  <block id="a75ba82042ae54dd2e68cf6c7a26614c" category="paragraph"><block ref="a75ba82042ae54dd2e68cf6c7a26614c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0cd85a82e6f02b779006b158b9c5f828" category="list-text">将数据库资源添加到资源组。</block>
  <block id="3836a8be1f86b6658a7fa6b180e4a72d" category="paragraph"><block ref="3836a8be1f86b6658a7fa6b180e4a72d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cee52cb6702e7590fbef45eccc8fb2df" category="list-text">从下拉列表中选择在第 7 节中创建的完整备份策略。</block>
  <block id="af900bffdda986bc1db955ae78832742" category="paragraph"><block ref="af900bffdda986bc1db955ae78832742" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fe872cd84ea2e9051770379e63f9caf" category="list-text">单击（ + ）号可配置所需的备份计划。</block>
  <block id="9da504fd8ab60cfcc873608530cf5d56" category="paragraph"><block ref="9da504fd8ab60cfcc873608530cf5d56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdc27a4c5d48dbfc04f81ecac85acd64" category="list-text">单击 Load Locators 以加载源卷和目标卷。</block>
  <block id="7242164857e43688f8a7bec97559c36e" category="paragraph"><block ref="7242164857e43688f8a7bec97559c36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b612dc8868902cf8fbf2b1024ad94e65" category="paragraph"><block ref="b612dc8868902cf8fbf2b1024ad94e65" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95633243861715786b64e1554b629435" category="paragraph"><block ref="95633243861715786b64e1554b629435" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f7192b9766e6f09c261f3ca3d3bddc8" category="section-title">为 Oracle 的日志备份创建一个资源组</block>
  <block id="1a0cd5de7c84ddbf632838dd9f510d37" category="paragraph"><block ref="1a0cd5de7c84ddbf632838dd9f510d37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0ad3d9537c50952c04b71be3f9d4579" category="paragraph"><block ref="f0ad3d9537c50952c04b71be3f9d4579" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c33c31714f671e112fbe52b660d3e7a4" category="paragraph"><block ref="c33c31714f671e112fbe52b660d3e7a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03955b73285eab0d68e90c627da9726d" category="list-text">从下拉列表中选择在第 7 节中创建的日志备份策略。</block>
  <block id="6286629570d2ca91cf6860e7da6e9073" category="paragraph"><block ref="6286629570d2ca91cf6860e7da6e9073" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88c73129e9a418955658ce5c48d9d8b5" category="list-text">单击（ + ）号可配置所需的备份计划。</block>
  <block id="8cdd30063d988671ffa9240fe171b1ce" category="paragraph"><block ref="8cdd30063d988671ffa9240fe171b1ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eacfd6f10777b8dfb41199e4d4dfa915" category="list-text">如果配置了备份验证，则会显示在此处。</block>
  <block id="69911c1794125b768effca94c8153987" category="paragraph"><block ref="69911c1794125b768effca94c8153987" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a27fac4b1d49d5468930a56c3a6de56" category="list-text">如果需要，配置用于电子邮件通知的 SMTP 服务器。</block>
  <block id="fd540644538dcedf1f6543455447728f" category="paragraph"><block ref="fd540644538dcedf1f6543455447728f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="554dbe35f6afa38e8232497f5d05d1c1" category="paragraph"><block ref="554dbe35f6afa38e8232497f5d05d1c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf688c7a95f421447e84a47fd03f3aa2" category="section-title">创建用于 SQL Server 完整备份的资源组</block>
  <block id="d08ef097ee33c4a3506183adeb51c5e7" category="list-text">使用数据库管理用户 ID 登录到 SnapCenter ，然后导航到资源选项卡。在视图下拉列表中，选择数据库或资源组以启动资源组创建工作流。提供资源组的名称和标记。您可以为 Snapshot 副本定义命名格式。</block>
  <block id="87d2630813d214672697efc01974d64e" category="paragraph"><block ref="87d2630813d214672697efc01974d64e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ace5324d60cb3faa1863efd675149" category="list-text">选择要备份的数据库资源。</block>
  <block id="15330fe5b8f32032bd3b30c091d7dc4b" category="paragraph"><block ref="15330fe5b8f32032bd3b30c091d7dc4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2fc1974f486effa4a60bf216e63a88d5" category="list-text">选择在第 7 节中创建的完整 SQL 备份策略。</block>
  <block id="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="paragraph"><block ref="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b70beeb570488ba753a620378cacd8" category="list-text">添加准确的备份时间以及频率。</block>
  <block id="8fa0a3897bc03e9b1653d17308464031" category="paragraph"><block ref="8fa0a3897bc03e9b1653d17308464031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49252579bd8140847f4bbac20ef89b07" category="list-text">如果要执行备份验证，请在二级系统上为备份选择验证服务器。单击加载定位器以填充二级存储位置。</block>
  <block id="355e5eb56524b7365674014ea5868ee6" category="paragraph"><block ref="355e5eb56524b7365674014ea5868ee6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19e819eadb96ee5769ff4c6309352a62" category="paragraph"><block ref="19e819eadb96ee5769ff4c6309352a62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0be278d93ec2e64895e31bf440c54b98" category="paragraph"><block ref="0be278d93ec2e64895e31bf440c54b98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4dd921984d3a8a89e7df5c97875b923" category="section-title">为 SQL Server 的日志备份创建一个资源组</block>
  <block id="4e94ca9b995e68691b4e67b82b9f5bce" category="list-text">使用数据库管理用户 ID 登录到 SnapCenter ，然后导航到资源选项卡。在视图下拉列表中，选择数据库或资源组以启动资源组创建工作流。提供资源组的名称和标记。您可以为 Snapshot 副本定义命名格式。</block>
  <block id="4e71263f0aec815017fd21a22ddb87d6" category="paragraph"><block ref="4e71263f0aec815017fd21a22ddb87d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="013faf9f6cde83814469c6d583e10702" category="paragraph"><block ref="013faf9f6cde83814469c6d583e10702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23e15d7c127e66b1da1d72072a29e9eb" category="list-text">选择在第 7 节中创建的 SQL 日志备份策略。</block>
  <block id="52a8553e4c33eb8353d56286d3845b28" category="paragraph"><block ref="52a8553e4c33eb8353d56286d3845b28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e7cac98c16b45d7e4ebec8786b8fda1" category="list-text">添加准确的备份时间以及频率。</block>
  <block id="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="paragraph"><block ref="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68398b6746dde91649e96505d97acc40" category="list-text">如果要执行备份验证，请在二级系统上为备份选择验证服务器。单击负载定位器以填充二级存储位置。</block>
  <block id="3bde998a2436b40589b20d91a713d3ee" category="paragraph"><block ref="3bde998a2436b40589b20d91a713d3ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80000e8cb7742af4686df786fdf38249" category="paragraph"><block ref="80000e8cb7742af4686df786fdf38249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d32fb038efa6b409f8dedd0e02a10f26" category="paragraph"><block ref="d32fb038efa6b409f8dedd0e02a10f26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c72629a46c2e88cf7f6a012167bb16" category="section-title">9. 验证备份</block>
  <block id="d1c55c296cbdaa8d88eda765a6158b62" category="paragraph">创建数据库备份资源组以保护数据库资源后，备份作业将根据预定义的计划运行。在监控选项卡下检查作业执行状态。</block>
  <block id="5f9af2a4e435e2b39c27f43b580d6d20" category="paragraph"><block ref="5f9af2a4e435e2b39c27f43b580d6d20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57882e224a8cbe8f694da9b1d8fa503e" category="paragraph">转到资源选项卡，单击数据库名称以查看数据库备份的详细信息，然后在本地副本和镜像副本之间切换，以验证 Snapshot 备份是否已复制到公有云中的二级位置。</block>
  <block id="f9b40afbdb387dd32b8523c95080a898" category="paragraph"><block ref="f9b40afbdb387dd32b8523c95080a898" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28268d417882b5cf7a3d3ee3a15834c8" category="paragraph">此时，云中的数据库备份副本已做好克隆准备，可以运行开发 / 测试流程，或者在发生主故障时进行灾难恢复。</block>
  <block id="0f22160e43c900ef7426d8a19e9f482d" category="summary">在执行混合云数据库工作负载之前，必须在内部和云中配置某些前提条件。下一节简要介绍了此过程，以下链接提供了有关必要的系统配置的详细信息。</block>
  <block id="1dad826770c4d2c619351c974f725b36" category="doc">前提条件配置</block>
  <block id="4df40e141b0559f15db8f84f78aed013" category="section-title">内部部署</block>
  <block id="caea8340e2d186a540518d08602aa065" category="list-text">自动化</block>
  <block id="761883c0d5c55fba5b200ac8ac0d86e5" category="section-title">公有云</block>
  <block id="37aa83a33297d9d16b4423be342598bb" category="list-text">连接器的网络位置</block>
  <block id="74c043a4451dd260729a23ce96aa1550" category="paragraph">重要注意事项：</block>
  <block id="7aee27c83b5e3622c1d8cbd5c2098c60" category="list-text">在何处部署 Cloud Manager Connector ？</block>
  <block id="43fd5c6fa3d9ba8a215c31f3bf0a9859" category="list-text">Cloud Volume ONTAP 规模估算和架构</block>
  <block id="7a0e00d70e3b0ff06476a52565f923c4" category="list-text">单节点还是高可用性？</block>
  <block id="2d0b46fff3ae203a435b167c7111b389" category="paragraph">以下链接提供了更多详细信息：</block>
  <block id="cfd98f49422c4fba755a2ff74c55a4a0" category="paragraph"><block ref="cfd98f49422c4fba755a2ff74c55a4a0" category="inline-link-macro-rx"></block></block>
  <block id="704849d56e695ab8f9df0b106e0d7e33" category="inline-link-macro">公有云</block>
  <block id="96e41b2b281ca4b71edf4ed16e46a2be" category="paragraph"><block ref="96e41b2b281ca4b71edf4ed16e46a2be" category="inline-link-macro-rx"></block></block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">边缘人工智能推理—采用联想 ThinkSystem 的 NetApp —解决方案设计</block>
  <block id="30b22b544972f5adb280ca2975099846" category="sidebar">采用 SnapCenter 的混合云数据库解决方案</block>
  <block id="59f8ae0d5c4ba13dee4828e2727c8859" category="sidebar">内部部署入门</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">下图显示了 NetApp EF280 存储系统。</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1 是 NetApp 推出的最新一代存储管理软件，可帮助企业打造现代化的基础架构并过渡到云就绪数据中心。借助行业领先的数据管理功能，无论数据位于何处， ONTAP 都可以通过一组工具来管理和保护数据。您还可以将数据自由移动到需要的任何位置：边缘，核心或云。ONTAP 9.8.1 提供了许多功能，可简化数据管理，加快和保护关键数据，并在混合云架构中实现下一代基础架构功能。</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">下载需要注册的数据集， ImageNet 2012 验证集， Criteo TB 数据集和 Brats 2019 训练集，然后解压缩这些文件。</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">创建一个至少包含 1 TB 的工作目录，并定义环境变量 `MLPERF_scrating_path` 引用该目录。</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">运行 make `prebuild` 命令，该命令可为所需的推理任务构建并启动 Docker 容器。</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">为 MLPerf 推理任务下载经过预先培训的 AI 型号： `make download_model`</block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">下载可免费下载的其他数据集： `make download_data`</block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">预处理数据： make `preprocess_data`</block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">运行： `m构建` 。</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">针对计算服务器中的 GPU 优化的构建推理引擎： `make generate_engine`</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">此基准测试可测量延迟。对于所有情况，我们都会报告运行中涉及的所有服务器的平均延迟。系统将提供此任务套件的结果。</block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">结果再次显示，网络存储足以处理这些任务。在一台服务器的情况下，本地存储与网络存储之间的差别很小或没有差别。同样，当两个服务器使用相同的存储时，两个服务器上的延迟保持不变或变化量非常小。</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">此联想 ThinkSystem 服务器和 NetApp ONTAP 或 NetApp SANtricity 存储解决方案旨在利用 GPU 与传统 CPU 的处理能力处理大型数据集上的 AI 推理。此验证通过一个架构来展示高性能和最佳数据管理，该架构使用一个或多个与单个 NetApp AFF 存储系统互连的联想 SR350 边缘服务器，如以下两个图所示。</block>
  <block id="aacb24ff7918ccc37aea66f8c9548b68" category="paragraph"><block ref="aacb24ff7918ccc37aea66f8c9548b68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">下图中的逻辑架构概述显示了此架构中计算和存储元素的角色。具体而言，它显示以下内容：</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">本文档遵循 MLPerf 推理 v0.7<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block>， MLPerf 推理 v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block>，和<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block>。我们运行了专为在边缘进行推理而设计的 MLPerf 基准测试，如下表所述。</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">下表介绍了 Edge 基准测试场景。</block>
  <block id="5174c42549c4dd0407a40298a4d9e362" category="paragraph"><block ref="5174c42549c4dd0407a40298a4d9e362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">在此使用情形中，客户要求在同一数据中心和远程位置快速高效地基于包含大量分析数据以用于 DevTest 和报告目的的现有 Hadoop 集群构建新的 Hadoop/Spark 集群。</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">用例 3 ：对现有 Hadoop 数据启用 DevTest</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">场景</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">在这种情况下，多个 Spark 或 Hadoop 集群是通过在内部以及灾难恢复位置实施大型 Hadoop 数据湖而构建的。</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="section-title">要求和挑战</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">此用例的主要要求和挑战包括：</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">创建多个 Hadoop 集群以实现 DevTest ， QA 或任何其他需要访问相同生产数据的目的。此处的挑战是，以节省空间的方式瞬时克隆多个非常大的 Hadoop 集群。</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">将 Hadoop 数据同步到 DevTest 和报告团队，以提高运营效率。</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">使用相同的凭据在生产集群和新集群之间分发 Hadoop 数据。</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">使用计划策略高效创建 QA 集群，而不会影响生产集群。</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">解决方案</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">FlexClone 技术用于问题解答上述要求。FlexClone 技术是 Snapshot 副本的读 / 写副本。它会从父 Snapshot 副本数据读取数据，并且只会为新的 / 修改的块占用额外空间。速度快，节省空间。</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">首先，使用 NetApp 一致性组创建现有集群的 Snapshot 副本。</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">此图显示了用于 DevTest 的 Hadoop 集群。</block>
  <block id="4157075925c8c1518cc71d1d0abab403" category="paragraph"><block ref="4157075925c8c1518cc71d1d0abab403" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">本节概述了 NetApp 为满足各种 Hadoop 数据保护要求而提供的使用情形和解决方案。</block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">本节概述了 NetApp 为满足各种 Hadoop 数据保护要求而提供的使用情形和解决方案。通过使用 NetApp 提供支持的 Data Fabric ，客户可以：</block>
  <block id="ce0bf05854efb234905c751e40774ab5" category="list-text">利用 NetApp 丰富的数据管理功能并与 Hadoop 原生工作流集成，灵活选择合适的数据保护解决方案。</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">将 Hadoop 集群备份窗口时间缩短近 70% 。</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">消除 Hadoop 集群备份所带来的任何性能影响。</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">同时提供从不同云提供商到单个分析数据源的多云数据保护和数据访问。</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">使用 FlexClone 技术快速创建节省空间的 Hadoop 集群副本。</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">要了解有关本文档中所述信息的更多信息，请参见以下文档和 / 或网站：</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">NetApp 大数据分析解决方案</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">采用 NetApp 存储的 Apache Spark 工作负载</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">适用于 Apache Spark 的 NetApp 存储解决方案</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">NetApp 支持的 Data Fabric 上的 Apache Hadoop</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="list-text">NetApp 原位分析模块</block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">致谢</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">NetApp ANZ 维多利亚地区销售代表 Paul Burland</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">NetApp 业务开发经理 Hoseb Dermanilian</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">NetApp MPSG 总监 Lee Dorrier</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">NetApp ANZ 维多利亚区 SE 系统工程师 David Thiessen</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">2018 年 1 月</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">更新了用例 5 ：加快分析工作负载的速度</block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">在这种情况下，客户拥有一个大型内部 Hadoop 存储库，并希望对其进行备份以实现灾难恢复。但是，客户当前的备份解决方案成本高昂，并且备份时间过长，超过 24 小时。</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">用例 1 ：备份 Hadoop 数据</block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">软件向后兼容性：</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">建议的备用备份解决方案应与生产 Hadoop 集群中当前正在运行的软件版本兼容。</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">为了满足承诺的 SLA ，建议的替代解决方案应实现极低的 RPO 和 RTO 。</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">NetApp 备份解决方案创建的备份可以在本地构建于数据中心的 Hadoop 集群中使用，也可以在远程站点的灾难恢复位置运行的 Hadoop 集群中使用。</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">建议的解决方案必须经济高效。</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">建议的解决方案必须减少备份期间对当前正在运行的生产分析作业的性能影响。</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">下图显示了原始 Hadoop 原生备份解决方案。</block>
  <block id="2975218bd3c71a4ac4eac95d3529a9cb" category="paragraph"><block ref="2975218bd3c71a4ac4eac95d3529a9cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">生产数据通过中间备份集群保护到磁带：</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">通过运行 `hadoop distcp -update &lt;hdfs1&gt; &lt;hdfs2&gt;` 命令，可以将 HDFS1 数据复制到 HDFS2 。</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">备份集群充当 NFS 网关，数据通过 Linux `CP` 命令通过磁带库手动复制到磁带。</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">原始 Hadoop 原生备份解决方案的优势包括：</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">解决方案基于 Hadoop 原生命令，用户无需学习新过程。</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">解决方案采用行业标准架构和硬件。</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">原始 Hadoop 原生备份解决方案的缺点包括：</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">备份窗口时间过长超过 24 小时，因此生产数据容易受到影响。</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">备份期间集群性能显著下降。</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">复制到磁带是一个手动过程。</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">备份解决方案在所需的硬件和手动过程所需的工时方面成本高昂。</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">备份解决方案</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">根据这些挑战和要求，并考虑到现有备份系统，建议了三种可能的备份解决方案。以下各小节分别介绍了这三种不同的备份解决方案，分别标记为解决方案 A 到解决方案 C</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">解决方案 A</block>
  <block id="411ee6c684ee720eff303771433e41d6" category="paragraph"><block ref="411ee6c684ee720eff303771433e41d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">解决方案 A 的详细任务包括：</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">生产 Hadoop 集群的 HDFS 中包含需要保护的客户分析数据。</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">具有 HDFS 的备份 Hadoop 集群充当数据的中间位置。在生产和备份 Hadoop 集群中，只需一组磁盘（ JBOD ）即可为 HDFS 提供存储。</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">运行 `hadoop distcp – update – diff &lt;hdfs1&gt; &lt;hdfs2&gt;` 命令，保护 Hadoop 生产数据，使其从生产集群 HDFS 传输到备份集群 HDFS 。</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Hadoop 快照用于保护数据从生产环境传输到备份 Hadoop 集群。</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">NetApp ONTAP 存储控制器可提供一个 NFS 导出卷，该卷会配置到备份 Hadoop 集群。</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">将数据存储在 NetApp 存储系统的 NFS 中后，将使用 NetApp Snapshot ， SnapRestore 和 FlexClone 技术根据需要备份，还原和复制 Hadoop 数据。</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">使用 SnapMirror 技术，可以将 Hadoop 数据保护到云端以及灾难恢复位置。</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">解决方案 A 的优势包括：</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Hadoop 生产数据受备份集群保护。</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">HDFS 数据通过 NFS 进行保护，从而可以保护云和灾难恢复位置。</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">通过将备份操作卸载到备份集群来提高性能。</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">无需手动执行磁带操作</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">支持通过 NetApp 工具实现企业管理功能。</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">只需对现有环境进行极少的更改。</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">是一种经济高效的解决方案。</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">此解决方案的缺点是，它需要一个备份集群和额外的映射器来提高性能。</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">由于解决方案 A 的简单性，成本和整体性能，客户最近部署了它。</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">在此解决方案中，可以使用 ONTAP 中的 SAN 磁盘，而不是 JBOD 。此选项会将备份集群存储负载卸载到 ONTAP ；但是，缺点是需要 SAN 网络结构交换机。</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">解决方案 B</block>
  <block id="303388aba87d7dcff207a6cd098b0cfe" category="paragraph"><block ref="303388aba87d7dcff207a6cd098b0cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">解决方案 B 的详细任务包括：</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">NetApp ONTAP 存储控制器可为生产 Hadoop 集群配置 NFS 导出。</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">将数据存储在 NetApp 存储系统的 NFS 中后，将使用 Snapshot ， SnapRestore 和 FlexClone 技术根据需要备份，还原和复制 Hadoop 数据。</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">解决方案 B 的优势包括：</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">生产集群针对备份解决方案进行了少许修改，从而简化了实施并降低了额外的基础架构成本。</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">备份操作不需要备份集群。</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">HDFS 生产数据在转换为 NFS 数据时会受到保护。</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">解决方案支持通过 NetApp 工具执行企业管理功能。</block>
  <block id="02946730aaff0e3d8abfa986a2fe949d" category="paragraph">此解决方案的缺点是它在生产集群中实施，这可能会在生产集群中添加其他管理员任务。</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">解决方案 C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">在解决方案 C 中， NetApp SAN 卷会直接配置到 Hadoop 生产集群中以用于 HDFS 存储，如下图所示。</block>
  <block id="dc460b3501caf17186202576855a6d3c" category="paragraph"><block ref="dc460b3501caf17186202576855a6d3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">解决方案 C 的详细步骤包括：</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">NetApp ONTAP SAN 存储在生产 Hadoop 集群上配置为用于 HDFS 数据存储。</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">NetApp Snapshot 和 SnapMirror 技术用于备份生产 Hadoop 集群中的 HDFS 数据。</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">在 Snapshot 副本备份过程中， Hadoop/Spark 集群的生产不会对性能产生影响，因为备份位于存储层。</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">无论数据大小如何， Snapshot 技术均可在数秒内完成备份。</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">解决方案 C 的优势包括：</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">可以使用 Snapshot 技术创建节省空间的备份。</block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">此使用情形基于广播客户，该客户需要将基于云的分析数据备份到其内部数据中心。</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">用例 2 ：从云到内部环境的备份和灾难恢复</block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">此使用情形基于广播客户，该客户需要将基于云的分析数据备份到其内部数据中心，如下图所示。</block>
  <block id="063e138ba69a95a99bd2f908b540e210" category="paragraph"><block ref="063e138ba69a95a99bd2f908b540e210" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">在这种情况下， IoT 传感器数据会载入云中，并使用 AWS 中的开源 Apache Spark 集群进行分析。需要将处理后的数据从云备份到内部环境。</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">启用数据保护不会发生原因对云中的生产 Spark 或 Hadoop 集群产生任何性能影响。</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">云传感器数据需要以高效安全的方式移动和保护到内部。</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">可以在不同条件下灵活地将数据从云传输到内部环境，例如按需，瞬时以及在集群负载较低的情况下。</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">客户使用 AWS Elastic Block Store （ EBS ）作为其 Spark 集群 HDFS 存储，通过 Kafka 从远程传感器接收和载入数据。因此， HDFS 存储充当备份数据的源。</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">为了满足这些要求， NetApp ONTAP 云部署在 AWS 中，并创建一个 NFS 共享作为 Spark 或 Hadoop 集群的备份目标。</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">此图显示了从云到内部解决方案的备份和灾难恢复。</block>
  <block id="94c7a6b63152038de5e8b2763cdef06c" category="paragraph"><block ref="94c7a6b63152038de5e8b2763cdef06c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69efde21ccf40f1dda4d665f81bacefe" category="summary">在这种情况下，一家大型金融服务和投资银行的分析平台使用 NetApp NFS 存储解决方案进行了现代化改造，从而显著改进了资产管理和定量业务部门的投资风险和衍生产品分析。</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">用例 5 ：加快分析工作负载的速度</block>
  <block id="24b0e878b8196875cd088397ac8312a9" category="paragraph">在客户的现有环境中，用于分析平台的 Hadoop 基础架构利用了 Hadoop 服务器的内部存储。由于 JBOD 环境的专有性，组织内的许多内部客户无法利用其蒙特卡罗量化模型，这种模拟依赖于重复的实时数据样本。无法以最佳方式了解市场波动的不确定性影响，这对量化资产管理业务单位不利。</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">该银行的量化业务部门需要一种高效的预测方法来实现准确，及时的预测。为此，该团队认识到需要对基础架构进行现代化改造，减少现有 I/O 等待时间并提高 Hadoop 和 Spark 等分析应用程序的性能，以便高效模拟投资模型，衡量潜在收益并分析风险。</block>
  <block id="5ff37557b096819452a25d129a312360" category="paragraph">客户的现有 Spark 解决方案具有 JBOD 。然后，利用 NetApp ONTAP ， NetApp StorageGRID 和从 MinIO 网关到 NFS ，减少了银行的量化财务团队对评估潜在收益和风险的投资模型进行模拟和分析的 I/O 等待时间。此图显示了采用 NetApp 存储的 Spark 解决方案。</block>
  <block id="095ba715431845442ef6bf2f4283ad1c" category="paragraph"><block ref="095ba715431845442ef6bf2f4283ad1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">如上图所示，我们部署了 AFF A800 ， A700 系统和 StorageGRID ，以便在具有 Spark 的六节点 Hadoop 集群中通过 NFS 和 S3 协议访问 parquet 文件，并为数据分析操作提供了 YARN 和 Hive 元数据服务。</block>
  <block id="bc12facb8aa0a34db56b00fdbc21c351" category="paragraph">客户旧环境中的直连存储（ DAS ）解决方案在独立扩展计算和存储方面存在缺点。借助 NetApp ONTAP 解决方案 for Spark ，该银行的财务分析业务部门能够将存储与计算分离，并根据需要无缝地更有效地提供基础架构资源。</block>
  <block id="582c4aa65d1bd005ddc785db8b807fca" category="paragraph">通过将 ONTAP 与 NFS 结合使用，计算服务器 CPU 几乎可以完全用于 Spark SQL 作业， I/O 等待时间缩短了近 70% ，从而为 Spark 工作负载提供了更好的计算能力和性能提升。随后，随着 CPU 利用率的提高，客户还可以利用 GPUDirect 等 GPU 进一步实现平台现代化。此外， StorageGRID 还为 Spark 工作负载提供了低成本存储选项，而 MinIO 网关则可通过 S3 协议安全访问 NFS 数据。对于云中的数据， NetApp 建议使用 Cloud Volumes ONTAP ， Azure NetApp Files 和 NetApp Cloud Volumes Service 。</block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp 是一款原生工具，用于大型集群间和集群内复制。Hadoop DistCp 基本过程是一个典型的备份工作流，它使用诸如 MapReduce 等 Hadoop 原生工具将 Hadoop 数据从 HDFS 源复制到相应目标。</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Hadoop 数据保护和 NetApp</block>
  <block id="6369c8cb38b142174d2f84d12d2f0420" category="paragraph"><block ref="6369c8cb38b142174d2f84d12d2f0420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">此使用情形适用于负责为客户的大数据分析数据提供多云连接的云服务合作伙伴。</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">用例 4 ：数据保护和多云连接</block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">在这种情况下，在 AWS 中从不同来源接收的物联网数据存储在 NPS 的中央位置。NPS 存储连接到 AWS 和 Azure 中的 Spark 或 Hadoop 集群，从而支持在多个云中运行的大数据分析应用程序访问相同的数据。</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">客户希望使用多个云对相同数据运行分析作业。</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">必须通过不同的传感器和中心从内部和云等不同来源接收数据。</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">解决方案必须高效且经济高效。</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">主要挑战是构建一个经济高效的解决方案，以便在内部和不同云之间提供混合分析服务。</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">此图显示了数据保护和多云连接解决方案。</block>
  <block id="faaf8e6278dc7a68fd1dd98dfe7f525a" category="paragraph"><block ref="faaf8e6278dc7a68fd1dd98dfe7f525a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">因此，由于内部和 NPS 存储均运行 ONTAP 软件，因此 SnapMirror 可以将 NPS 数据镜像到内部集群，从而在内部和多个云之间提供混合云分析。</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">为了获得最佳性能， NetApp 通常建议使用多个网络接口和直接连接 / 快速路由从云实例访问数据。</block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">本节将简要介绍数据保护使用情形的问题描述，这是本白皮书的重点内容。其余部分将详细介绍每个使用情形，例如客户问题（场景），要求和挑战以及解决方案。</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Hadoop 数据保护用例概述</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">一家大型广播公司利用 NetApp 提供支持的 Data Fabric 作为组件，根据不同的数据传输模式（例如按需，即时， 或基于 Hadoop/Spark 集群负载。</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">NetApp 解决方案帮助在线音乐分销商在不同的分支中快速构建多个节省空间的 Hadoop 集群，以便使用计划的策略创建报告并运行每日 DevTest 任务。</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">一家大型服务提供商使用由 NetApp 提供支持的 Data Fabric ，从不同的云实例为其客户提供多云分析。</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">最大的金融服务和投资银行之一使用 NetApp 网络连接存储解决方案来缩短 I/O 等待时间并加快其量化金融分析平台的运行速度。</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">由 NetApp 提供支持的 Data Fabric 可简化并集成云环境和内部环境中的数据管理，以加速数字化转型。由 NetApp 提供支持的 Data Fabric 可提供一致且集成的数据管理服务和应用程序（组件），以实现数据可见性和洞察力，数据访问和控制以及数据保护和安全。</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">NetApp 为大数据架构提供支持的 Data Fabric</block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">由 NetApp 提供支持的 Data Fabric 可简化并集成云环境和内部环境中的数据管理，以加速数字化转型。</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">由 NetApp 提供支持的 Data Fabric 可提供一致且集成的数据管理服务和应用程序（组件），以实现数据可见性和洞察力，数据访问和控制以及数据保护和安全，如下图所示。</block>
  <block id="22313f8779f9135c9b421ac0d4b320fb" category="paragraph"><block ref="22313f8779f9135c9b421ac0d4b320fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">经验证的 Data Fabric 客户用例</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">由 NetApp 提供支持的 Data Fabric 为客户提供了以下九个经验证的使用情形：</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">加快分析工作负载的速度</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">加快开发运营转型</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">构建云托管基础架构</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">集成云数据服务</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">保护和保护数据</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">优化非结构化数据</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">提高数据中心效率</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">提供数据洞察力和控制力</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">简化和自动化</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">本文档涵盖九个使用情形中的两个（及其解决方案）：</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">NetApp NFS 直接访问</block>
  <block id="96e1e6bac181280c42ba5de56a8ef4c2" category="paragraph"><block ref="96e1e6bac181280c42ba5de56a8ef4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">NetApp NFS 直接访问为 Hadoop/Spark 集群提供了两种部署选项：</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">默认情况下， Hadoop/Spark 集群使用 Hadoop 分布式文件系统（ HDFS ）进行数据存储和默认文件系统。NetApp NFS 直接访问可以将默认 HDFS 替换为 NFS 存储作为默认文件系统，从而对 NFS 数据执行直接分析操作。</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">在另一种部署选项中， NetApp NFS 直接访问支持在一个 Hadoop/Spark 集群中将 NFS 与 HDFS 配置为额外的存储。在这种情况下，客户可以通过 NFS 导出共享数据，并从同一集群访问数据以及 HDFS 数据。</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">使用 NetApp NFS 直接访问的主要优势包括：</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">分析当前位置的数据，防止执行将分析数据移动到 HDFS 等 Hadoop 基础架构这一耗时且性能极高的任务。</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">将副本数量从三个减少为一个。</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">支持用户分离计算和存储，以便独立扩展。</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">利用 ONTAP 丰富的数据管理功能提供企业数据保护。</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">已通过 Hortonworks 数据平台认证。</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">支持混合数据分析部署。</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">利用动态多线程功能缩短备份时间。</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">大数据的组件</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">由 NetApp 提供支持的 Data Fabric 集成了数据管理服务和应用程序（组件），用于实现数据访问，控制，保护和安全性，如下图所示。</block>
  <block id="f0a67f0f8f389fb239ce107f693a7e68" category="paragraph"><block ref="f0a67f0f8f389fb239ce107f693a7e68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">上图中的组件包括：</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* NetApp NFS 直接访问。 * 为最新的 Hadoop 和 Spark 集群提供对 NetApp NFS 卷的直接访问，而无需额外的软件或驱动程序要求。</block>
  <block id="2867a490011894512662b9423698d0e0" category="list-text">* NetApp Cloud Volumes ONTAP 和云卷服务。 * 基于在 Microsoft Azure 云服务的 Amazon Web Services （ AWS ）或 Azure NetApp Files （ ANF ）中运行的 ONTAP 的软件定义的连接存储。</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">* NetApp SnapMirror 技术 * 。在内部部署和 ONTAP 云或 NPS 实例之间提供数据保护功能。</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">* 云服务提供商。 * 这些提供商包括 AWS ， Microsoft Azure ， Google Cloud 和 IBM Cloud 。</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">* PaaaS 。 * 基于云的分析服务，例如 AWS 中的 Amazon Elastic MapReduce （ EMR ）和 Databricks 以及 Microsoft Azure HDInsight 和 Azure Databricks 。</block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">本文档介绍使用 NetApp AFF 和 FAS 存储系统， NetApp Cloud Volumes ONTAP ， NetApp 互联存储以及适用于 Spark 和 Hadoop 的 NetApp FlexClone 技术的混合云数据解决方案。客户可以通过这些解决方案架构为其环境选择合适的数据保护解决方案。NetApp 在与客户及其业务用例进行交互的基础上设计了这些解决方案。</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="doc">TR-4657 ： NetApp 混合云数据解决方案—基于客户用例的 Spark 和 Hadoop</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">NetApp 公司 Karthikeyan Nagalingam 和 Sathish Thyagarajan</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">本文档介绍使用 NetApp AFF 和 FAS 存储系统， NetApp Cloud Volumes ONTAP ， NetApp 互联存储以及适用于 Spark 和 Hadoop 的 NetApp FlexClone 技术的混合云数据解决方案。客户可以通过这些解决方案架构为其环境选择合适的数据保护解决方案。NetApp 在与客户及其业务用例进行交互的基础上设计了这些解决方案。本文档提供了以下详细信息：</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">为什么我们需要针对 Spark 和 Hadoop 环境以及客户面临的挑战提供数据保护。</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">由 NetApp 愿景提供支持的 Data Fabric 及其组件和服务。</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">如何使用这些组件构建灵活的数据保护工作流。</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">根据实际客户使用情形确定的多个架构的优缺点。每个用例都包含以下组件：</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">解决方案</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">解决方案摘要</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">为什么选择 Hadoop 数据保护？</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">在 Hadoop 和 Spark 环境中，必须解决以下问题：</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">* 软件或人为故障。 * 执行 Hadoop 数据操作时，软件更新中出现人为错误，可能导致出现错误行为，发生原因从而可能导致作业产生意外结果。在这种情况下，我们需要保护数据，以避免出现故障或出现不合理的结果。例如，由于对流量信号分析应用程序进行的软件更新执行不当，这是一项新功能，无法以纯文本的形式正确分析流量信号数据。该软件仍会分析 JSON 和其他非文本文件格式，从而导致实时流量控制分析系统生成缺少数据点的预测结果。这种情况可能会导致发生原因输出出现故障，从而可能导致交通信号发生意外。通过提供快速回滚到先前工作应用程序版本的功能，数据保护可以解决此问题描述问题。</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">* 大小和规模。 * 由于数据源和卷的数量不断增加，分析数据的大小每天都在增长。社交媒体，移动应用程序，数据分析和云计算平台是当前大数据市场中的主要数据源，该市场的增长速度非常快，因此需要对数据进行保护，以确保准确的数据运行。</block>
  <block id="80908b4b31d37977701d3694fbc636ac" category="list-text">* Hadoop 的原生数据保护。 * Hadoop 具有一个原生命令来保护数据，但此命令不会在备份期间提供数据的一致性。它仅支持目录级备份。Hadoop 创建的快照为只读快照，不能用于直接重复使用备份数据。</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Hadoop 和 Spark 客户面临的数据保护挑战</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Hadoop 和 Spark 客户面临的一个常见挑战是，在数据保护期间，在不对生产集群性能产生负面影响的情况下，缩短备份时间并提高备份可靠性。</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">客户还需要最大限度地减少恢复点目标（ RPO ）和恢复时间目标（ RTO ）停机时间，并控制其内部和基于云的灾难恢复站点，以实现最佳业务连续性。这种控制通常来自企业级管理工具。</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Hadoop 和 Spark 环境非常复杂，因为不仅数据量庞大且不断增长，而且数据的到达速度也在不断提高。在这种情况下，很难从源数据快速创建高效，最新的 DevTest 和 QA 环境。NetApp 认识到这些挑战，并提供了本白皮书中介绍的解决方案。</block>
  <block id="a8a1e11a906a27bd156606bf4717e8e8" category="summary">此支持中心解决方案的架构以 NVIDIA 的预构建工具和 NetApp DataOps 工具包为核心。NVIDIA 的工具可用于使用预构建的型号和管道快速部署高性能 AI 解决方案。NetApp DataOps 工具包可简化各种数据管理任务，以加快开发速度。</block>
  <block id="c779b37f861deb44744634dea201514f" category="inline-link-macro">NVIDIA RIVA</block>
  <block id="ccfdc9ae99a97b7a6b8ad83a329bcdc8" category="paragraph"><block ref="eb3a0fd60dc608626ce6d809beb18359" category="inline-link-macro-rx"></block> 是一款 GPU 加速 SDK ，用于构建多模式对话 AI 应用程序，在 GPU 上提供实时性能。NVIDIA Train ， Aadapt ， and Optimize （ TAO ）工具包提供了一种更快，更简单的方法来加快训练速度，并快速创建高度准确且性能优异的特定域 AI 模型。</block>
  <block id="600ff5755ecd6aa4213eb806162b679e" category="paragraph">NetApp DataOps 工具包是一个 Python 库，可使开发人员，数据科学家，开发运营工程师和数据工程师轻松执行各种数据管理任务。其中包括近乎即时地配置新的数据卷或 JupyterLab 工作空间，近乎即时地克隆数据卷或 JupyterLab 工作空间，以及近乎即时地对数据卷或 JupyterLab 工作空间进行快照，以实现可追溯性和基线化。</block>
  <block id="5d103a663d28ddc9aa2af5f7b958e52c" category="inline-link">Riva</block>
  <block id="cc7a5a83afae781789c3a002465500b5" category="inline-link">TAO 工具包</block>
  <block id="9595827147dc1170c44979ae1fcabaa6" category="paragraph">在 GPU 加速数据中心中，企业可以使用 NVIDIA<block ref="cfd3aefe24e0725c1b0424dd8b503dc1" category="inline-link-rx"></block> 用于构建对话式 AI 应用程序的框架<block ref="ccdd6931e40e98163a0ae3c3c3bfb185" category="inline-link-rx"></block> 使用传输 L 学习技术连接模型修剪和重新培训。这些计算应用程序和工作流由提供支持<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>，实现 ONTAP 提供的最佳数据管理功能。通过该工具包，企业数据团队可以利用相关的结构化和非结构化数据，通过快照和克隆快速构建模型的原型，以实现可追溯性，版本控制， A/B 测试，从而提供安全性，监管， 和合规性。请参见一节 <block ref="3f1432f6921bc0c51d34759cb0d748ab" category="inline-link-macro-rx"></block> 有关详细信息：</block>
  <block id="816c3453eeba98af344f96d7eefe8834" category="paragraph">此解决方案演示了音频文件处理， NLP 模型培训，传输学习和数据管理详细步骤。生成的端到端管道生成一个情感摘要，该摘要会实时显示在人力支持代理的信息板上。</block>
  <block id="b6fb1598d37d2537eed4160a485b790e" category="paragraph"><block ref="b6fb1598d37d2537eed4160a485b790e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62519b55e4debcf57caf02c89620de61" category="cell">响应延迟测试</block>
  <block id="b763dc0a5ffab97a986c74098214cae6" category="cell">时间（毫秒）</block>
  <block id="08fa9c0a2e18301dd14e18c393fb4280" category="cell">数据处理</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="08db96f19d3c99c2b42fd180d9d81580" category="cell">推理</block>
  <block id="212e6da10eee5f14935bd37b84fe9684" category="paragraph">这些响应时间测试针对 560 个对话中 50 ， 000 多个音频文件运行。每个音频文件的大小为 ~100KB ，转换为 wav 时大小为 ~1 MB 。数据处理步骤会将 MP3 转换为 wav 文件。推理步骤会将音频文件转换为文本，并从文本中提取感受。这些步骤彼此独立，可以并行处理以加快此过程。</block>
  <block id="c18e24981c583441c6975f2116288cb7" category="paragraph">考虑到在商店之间传输数据的延迟，经理应该能够在句子结尾的一秒内看到实时情感分析的更新。</block>
  <block id="1c4968697a5851a64ad0fbf1b594e919" category="section-title">NVIDIA Riva 硬件</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">os</block>
  <block id="4c8be35e5fe3d8471f378a69f74c0ab6" category="cell">Linux x86_64</block>
  <block id="4d240f00b5a82cfaaf594cdc72f552f3" category="cell">GPU 内存（ As1 ）</block>
  <block id="3fa503e0bb3bf46423ef9176821a1f6c" category="cell">流模型： ~5600 MB 非流模型： ~3100 MB</block>
  <block id="6345afe417f42d9e0cf6a269bff00b4c" category="cell">GPU 内存（ NLP ）</block>
  <block id="217941fb2e441b0bae1b5fec0b454c31" category="cell">~每个 Bert 型号 500 MB</block>
  <block id="7e04ebd38c78635d1f8aa53de0dde49b" category="section-title">NVIDIA TAO 工具包硬件</block>
  <block id="03282e46abfd7449ab38bb851caf2c8d" category="cell">系统 RAM</block>
  <block id="edaf98e5dae9931cbd74a93b3dd93849" category="cell">32 GB</block>
  <block id="6ddfc451ef4f9a7613468cd288d2ab3e" category="cell">GPU RAM</block>
  <block id="2b55387dd066c5bac646ac61543d152d" category="cell">CPU</block>
  <block id="04911a799cc8712b473ed5a3cb2b8904" category="cell">8 个核心</block>
  <block id="fceec3562665d08f1dd24689f68f0f29" category="cell">NVIDIA （ A100 ， V100 和 RTX 30x0 ）</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD</block>
  <block id="2f9289dfcac06a2ba95650d7e24ea9e8" category="cell">100 GB</block>
  <block id="19aa61315132dbea1d19c7aeeef5f5b2" category="section-title">闪存存储系统</block>
  <block id="fd5487a1e906d6cd514dbbc16f17a489" category="paragraph">ONTAP 9.9 是 NetApp 推出的最新一代存储管理软件，可帮助企业打造现代化的基础架构并过渡到云就绪数据中心。借助行业领先的数据管理功能，无论数据位于何处， ONTAP 都可以通过一组工具来管理和保护数据。您还可以将数据自由移动到需要的任何位置：边缘，核心或云。ONTAP 9.9 包含许多功能，可简化数据管理，加快和保护关键数据，并在混合云架构中实现下一代基础架构功能。</block>
  <block id="df2c24964ca3e99761acc48b2c8a75c9" category="list-text">NetApp ONTAP S3</block>
  <block id="1a4c7c9b6e3157ccd0101fd0836c0bfc" category="list-text">NetApp Cloud Volumes Service</block>
  <block id="ddcf3699b41cd4c4ee5be4b9dd95c1e6" category="list-text">Amazon Simple Storage Service （ Amazon S3 ）</block>
  <block id="8224436b00c48149c863f4b17219a19d" category="list-text">Amazon Elastic File System （ Amazon EFS ）</block>
  <block id="52745271323ee9ea30e3a37d0338d118" category="list-text">Azure Blob</block>
  <block id="833c2c211a541e50ad94433664e4b5c1" category="list-text">Google Cloud 存储</block>
  <block id="5446a6bee3301e1f52824fc0affa6299" category="list-text">IBM 云对象存储</block>
  <block id="a5c952f5be43013a024d778712474fbc" category="paragraph">StorageGRID 软件定义的对象存储套件可无缝支持公有，私有云和混合多云环境中的各种用例。借助行业领先的创新技术， NetApp StorageGRID 可存储，保护和保留非结构化数据，以供多用途使用，包括长期的自动化生命周期管理。有关详细信息，请参见<block ref="7660f0463c83c682b9f091117b07c3b3" category="inline-link-rx"></block> 站点</block>
  <block id="6ffce2da93d4b296032f30d7b2adea01" category="paragraph">下表列出了实施此解决方案所需的软件组件。在任何特定解决方案实施中使用的软件组件可能会因客户要求而异。</block>
  <block id="d20072ce64f4d9efd57e036d2b7c30ec" category="cell">主机</block>
  <block id="7915eebeca25d928212b5d457786a549" category="cell">Riva （原 JarVis ）</block>
  <block id="1bf6e69c18341244d990250bf5aa3ce0" category="cell">1.4.0</block>
  <block id="7a2cd4790985cbbb0b362dfe8e59d991" category="cell">TAO 工具包（以前称为传输学习工具包）</block>
  <block id="55c82b601deae028c1c5e87fd820923d" category="cell">3.0</block>
  <block id="67c6ecbcd91c613e8659b3f0c4b01510" category="cell">9.9.1</block>
  <block id="8bec4fb7fbc1430e393d3f41063748e7" category="cell">DGX 操作系统</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="1b13fe3d4acac980a061d9efb92000d5" category="cell">DOTK</block>
  <block id="d233662f9c26d1a06118c93ef2fd1de9" category="cell">2.0.0</block>
  <block id="76e535c7d7533499b0d86f60a0d15b84" category="section-title">NVIDIA Riva 软件</block>
  <block id="5d7bf724a19463b3251c61a94a446c4c" category="cell">如果不使用 DGX ，则大于 19.02 （安装了 NVIDI-Docker ） &gt;=19.03</block>
  <block id="3ff6010d41ffb33d6f0971a202e76ad7" category="cell">NVIDIA 驱动程序</block>
  <block id="616120c1963dd46f2321dd37e823f8a0" category="cell">对于数据中心 GPU ，则为 465.19.01+ 418.40+ ， 440.33+ ， 450.51+ ， 460.27+</block>
  <block id="88f8128d405513d54a3e9831c73f87a0" category="cell">容器操作系统</block>
  <block id="73611f9a837b7a25dad3a9c5d1a98658" category="cell">Ubuntu 20.04</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="cell">CUDA</block>
  <block id="a26b47ba45087eadbeaa7c4802b3a8c8" category="cell">11.3.0</block>
  <block id="d92ef06e9564a9db573d075b4220057e" category="cell">cucBLAS</block>
  <block id="a8a364c27ce7406b7be591b4f973d5bb" category="cell">11.5.1.101</block>
  <block id="9bfd6cd63a5597c998aa2d96564f5c34" category="cell">cuDNN</block>
  <block id="15daa8f1432fd7e2b07f63097623dfab" category="cell">8.2.0.41</block>
  <block id="1ed15cc4178fd8ec4d845042a8f1ead0" category="cell">NCCL</block>
  <block id="f10585a0c5c8f535143471006baef867" category="cell">2.9.6</block>
  <block id="61918500e2bc645b2aea3f447086a8a5" category="cell">TensorRT</block>
  <block id="086934e5e95d3c797fc75f38fb3d086c" category="cell">7.2.3.4</block>
  <block id="d024876954df77538311467564f00917" category="cell">Triton 推理服务器</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="2efc85a476098fde0ecbf8d81505b612" category="section-title">NVIDIA TAO 工具包软件</block>
  <block id="cb6c22f673a55391483c7f040d8cf637" category="cell">Ubuntu 18.04 LTS</block>
  <block id="23eeeb4347bdd26bfc6b7ee9a3b755dd" category="cell">Python</block>
  <block id="c80362c25c18981fcf433e78dda5de78" category="cell">&gt;=3.6.9</block>
  <block id="aec7ff22e2f74b581cffbfa59e63f347" category="cell">Docker — ce</block>
  <block id="21ca3af3ea5e6a282911a64dbf5ced7a" category="cell">19.03.5</block>
  <block id="0cf76d9b00333f4396d0424ae164dd07" category="cell">Docker API</block>
  <block id="ca2b7e7213f7ba5d4b3923e807af27df" category="cell">1.40</block>
  <block id="ad2f80b0463af47fcb7430e0e1789841" category="cell">nvidia-container-toolkit</block>
  <block id="12b58130c1d9383cf3bf63391bd04721" category="cell">&gt;1.3.0-1</block>
  <block id="cec57b9746d41fd1c1749d591dbd7baf" category="cell">nvidia-container-runtime</block>
  <block id="68b90d96e3d934d65890ff695d37f354" category="cell">3.4.0-1.</block>
  <block id="f235b98dbe494fca328354abf0b52858" category="cell">nvidia-docker2.</block>
  <block id="10439f6f665bce43173e2871a0b7bfc6" category="cell">2.5.0-1.</block>
  <block id="fd3811d814e856dc6a43152673bb6753" category="cell">NVIDIA 驱动程序</block>
  <block id="06c61cdd8c93e750b3e0d4e2537416ea" category="cell">&gt;455</block>
  <block id="b6da1806d8ccb5327c3d80bbcfea4737" category="cell">Python-pip</block>
  <block id="7b043cb99d00fe56df3fead569b1a4de" category="cell">&gt;21.06</block>
  <block id="3bdf92e45d10e51e2bdc2b16cf33f345" category="cell">nvidia-pyindex</block>
  <block id="9ca445b9db010a99239196af5ac3a8b9" category="cell">最新版本</block>
  <block id="cf87f69879c53ebf670ee8bd793ad7ba" category="section-title">用例详细信息</block>
  <block id="7cb906d40b2e5bad2205a60ef8b6a019" category="list-text">情感分析</block>
  <block id="52a38da70697d6c80e3b6a204f64263f" category="paragraph"><block ref="52a38da70697d6c80e3b6a204f64263f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8ff4a485cc084b2a4b5bb829cf18055" category="paragraph">语音到文本使用情形首先会为支持中心载入音频文件。然后，根据 Riva 所需的结构对该音频进行处理。如果尚未将音频文件拆分为其分析单元，则必须先执行此操作，然后再将音频传递给 Riva 。处理完此音频文件后，它将作为 API 调用传递到 Riva 服务器。该服务器采用其托管的众多型号之一，并返回响应。此语音到文本（自动语音识别的一部分）将返回音频的文本表示形式。此时，管道将切换到情感分析部分。</block>
  <block id="230007c23660d290efdea5586b1716aa" category="paragraph">对于情感分析，自动语音识别输出的文本将作为文本分类的输入。文本分类是用于将文本分类为任意数量的类别的 NVIDIA 组件。对于支持中心对话，情绪类别从正面到负面不等。可以使用一个组套来评估模型的性能，以确定微调步骤是否成功。</block>
  <block id="3390cebd79348bc76a1e5eb5f169bedf" category="paragraph"><block ref="3390cebd79348bc76a1e5eb5f169bedf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="952b3f5758e644ef2558d59d3aace0b1" category="inline-link">NVIDIA NGC 目录</block>
  <block id="4fa0a0d712258621946173068bf4f7e0" category="paragraph">在 TAO 工具包中，语音到文本和情感分析也使用类似的管道。主要区别在于使用了微调模型所需的标签。TAO 工具包管道从处理数据文件开始。然后是经过预先培训的型号（来自<block ref="aaddb3bb47bcb0ca6e2a55cdce808e9b" category="inline-link-rx"></block>）。经过微调的模型会根据其相应的性能指标进行评估，如果性能比预先训练的模型更高，则会部署到 Riva 服务器。</block>
  <block id="431db7b0dc79bb29f07c20c6060c3338" category="summary">本节列出了适用于此解决方案的 Jupyter 笔记本电脑和其他资源。</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="doc">视频和演示</block>
  <block id="4b8db041d93aa27fd0cc94a261e224ca" category="inline-link-macro">"Support-Center-sentiment-Analysis-Pipeline.ipynb "</block>
  <block id="4e336784d7218f9fd7024470cba6b522" category="inline-link">"Support-Center-Mode-Transfer-Learning-and-fine-Tuned.ipynb "</block>
  <block id="46e3dcdd2c6c30a1d9fcf40d37f0deb3" category="paragraph">有两台笔记本电脑包含情感分析管道：<block ref="8ed620ac9482ce00db4c0f6de7250148" category="inline-link-rx"></block> 和 <block ref="ff8619e3bd3fbeea07c38337a7b773f7" category="inline-link-macro-rx"></block>。这些笔记本电脑共同演示了如何开发管道，以便使用根据用户数据微调的最先进深度学习模型，载入支持中心数据并从每句话中提取情感。</block>
  <block id="fa8c0b2056c13341c1455ad44cc91889" category="section-title">支持中心—情感分析管道 .ipynb</block>
  <block id="6b3450c2b921c398bbf90a1aee0b016c" category="paragraph">此笔记本电脑包含推理 Riva 管道，用于载入音频，将其转换为文本以及提取情感以供外部信息板使用。如果尚未下载和处理数据集，则会自动下载和处理该数据集。该笔记本电脑的第一部分是语音到文本，用于将音频文件转换为文本。接下来是 " 情感分析 " 部分，该部分将提取每个文本句子的感受，并以类似于建议的信息板的格式显示这些结果。</block>
  <block id="63abda3d2c420172da9a3a20c7f64dda" category="admonition">此笔记本电脑必须在模型训练和微调之前运行，因为必须下载并转换为正确格式的 mp3 数据集。</block>
  <block id="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="paragraph"><block ref="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="295c2feb943bbe2efca238849828084e" category="section-title">支持中心—模型训练和微调。 ipynb</block>
  <block id="6efbeb8cfc7e387edbf91bad41170349" category="paragraph">在执行此笔记本电脑之前，必须先设置 TAO 工具包虚拟环境（有关安装说明，请参见 " 命令概述 " 中的 "TAO 工具包 " 一节）。</block>
  <block id="a9d805c9ddfdf62e60632a9754e29404" category="paragraph">此笔记本电脑依靠 TAO 工具包根据客户数据微调深度学习模型。与上一个笔记本电脑一样，这一款笔记本电脑分为两个部分，分别用于语音到文本和情感分析组件。每个部分都将介绍数据处理，模型培训和微调，结果评估和模型导出。最后，我们将在最后一节中介绍如何部署这两种经过微调的型号，以便在 Riva 中使用。</block>
  <block id="b40454c57dd60f999f3243514cd90ede" category="paragraph"><block ref="b40454c57dd60f999f3243514cd90ede" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00a9f41b5383bf6bcb5b7f6540d427b4" category="summary">NVIDIA ， AWS ， Google 等公司发布的经过预先训练的建模工具，凭借当前最先进的状态，现在可以相对轻松地建立一个包含复杂模型的端到端管道并进行自定义。</block>
  <block id="710217ef02bea8d1d76bc6fc0e7bc056" category="paragraph">由于这些支持中心处理的呼叫数量众多，如果手动执行，则可能需要很长时间才能评估呼叫性能。传统方法，例如字包计数和其他方法，可以实现一定程度的自动化，但这些方法不能捕获动态语言的更细微的方面和语义上下文。AI 建模技术可用于自动执行其中一些更精细的分析。此外，随着 NVIDIA ， AWS ， Google 等公司发布的最新的经过预先培训的建模工具，现在可以相对轻松地建立一个包含复杂模型的端到端管道并进行自定义。</block>
  <block id="dd4541bcdb4728a1a380e825494f08e2" category="paragraph">支持中心情感分析的端到端管道，可在员工与来电者交谈时实时载入音频文件。然后，这些音频文件将进行处理，以便在将其转换为文本格式的语音到文本组件中使用。对话中的每一句话都会收到一个标签，用于指示情绪（积极，消极或中立）。</block>
  <block id="cfc9b6a29659e2208f66d876bd355200" category="paragraph">情绪分析可以为对话提供一个重要方面，用于评估通话性能。这些情感为员工和来电者之间的互动增加了一个深度。人工智能辅助的情绪信息板可为经理实时跟踪对话中的情绪，并对员工过去的通话进行回顾性分析。</block>
  <block id="2357d01362feabb1716e49b27d23f9cf" category="inline-link">NVIDIA Maxine</block>
  <block id="a2415fcdba82ba111e08286b17d98943" category="paragraph">预构建的工具可以通过强大的方式组合在一起，快速创建端到端 AI 管道来解决此问题。在这种情况下，可以使用 NVIDIA Riva 库执行两项串联任务：音频抄写和情感分析。第一种是受监控学习信号处理算法，第二种是受监控学习 NLP 分类算法。这些即装即用的算法可以使用 NVIDIA TAO 工具包针对与业务相关的数据的任何相关使用情形进行微调。这样，构建的解决方案就会更加准确，功能更强大，只需成本和资源的一小部分。客户可以采用<block ref="2aa9e1b3ec0ddf7f0bf09cdb2976222a" category="inline-link-rx"></block> 支持中心设计中 GPU 加速视频会议应用程序的框架。</block>
  <block id="076dd41fe8ba902e5439b5ba07f330ee" category="paragraph">以下用例是此解决方案的核心。这两种使用情形都使用 TAO 工具包进行模型微调，使用 Riva 进行模型部署。</block>
  <block id="bc176e8f914533ec222bba678e13955f" category="paragraph">为了分析员工和客户之间的支持中心互动，可以通过管道进行每一次以音频通话形式进行的客户对话，以得出句子级别的感受。然后，人类可以验证这些情感，为这些情感提供合理的理由，或者根据需要进行调整。然后，标记的数据将传递到微调步骤，以改善情绪预测。如果已存在标记的情感数据，则可以加快模型微调。无论哪种情况，管道都可通用于需要输入音频和对句子进行分类的其他解决方案。</block>
  <block id="91fa9ce0e0cb723f35d6cc55f796be7e" category="paragraph"><block ref="91fa9ce0e0cb723f35d6cc55f796be7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8836d456396ee0865c317994c018a24b" category="paragraph">AI Sentiment 输出会上传到外部云数据库或公司管理的存储系统。情感输出将从这一更大的数据库传输到本地存储，以在为经理显示情感分析的信息板中使用。信息板的主要功能是与客户服务员工实时互动。经理可以通过实时更新每句话的感受，并对员工过去的表现或客户反应进行历史回顾，评估员工的通话并提供反馈。</block>
  <block id="586779135ffb596b1f1844ada64164b6" category="paragraph"><block ref="586779135ffb596b1f1844ada64164b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="539788a6fdaffc74393f282739bdd3e2" category="paragraph">。 <block ref="95472f01c3cd86dddef6619dbb9af815" category="inline-link-macro-rx"></block> 即使在 Riva 推理管道生成情感标签之后，也可以继续管理数据存储系统。这些 AI 结果可以上传到 NetApp DataOps 工具包管理的数据存储系统。数据存储系统必须能够管理数百个插件并每分钟进行一次选择。本地设备存储系统实时查询较大的数据存储以进行提取。此外，还可以查询较大的数据存储实例以查找历史数据，从而进一步增强信息板体验。NetApp DataOps 工具包可通过快速克隆数据并将其分发到使用该数据的所有信息板，从而为这两种用途提供便利。</block>
  <block id="679db67ee98260ef471da732862ed356" category="list-text">员工经理</block>
  <block id="7e6beec614d536589c47de8f77fa1b1a" category="list-text">数据工程师 / 数据科学家</block>
  <block id="a2ce7e25564bee3c78076bcff87d1329" category="list-text">IT 管理员（内部，云或混合）</block>
  <block id="8dcd09ac05ad9012a6ff01f7b5fc337b" category="paragraph">在整个对话过程中跟踪情绪是评估员工绩效的宝贵工具。通过使用 AI 信息板，经理可以实时了解员工和来电者如何改变自己的感受，从而可以开展实时评估和指导会议。此外，企业还可以从参与语音对话，文本聊天机器人和视频会议的客户中获得宝贵的客户见解。此类客户分析可利用大规模多模式处理功能以及现代化的一流 AI 模型和工作流。</block>
  <block id="b7c29e65097b6ed45e464f6492ff670d" category="paragraph">在数据方面，支持中心每天都会处理大量音频文件。NetApp DataOps 工具包可帮助执行此数据处理任务，以便定期对模型和情感分析信息板进行微调。</block>
  <block id="1da289b166db713f9283c5be78ef5b96" category="paragraph">IT 管理员还可以从 NetApp DataOps 工具包中受益，因为它允许他们在部署和生产环境之间快速移动数据。此外，还必须对 NVIDIA 环境和服务器进行管理和分布，以便进行实时推理。</block>
  <block id="c1579c333c7c7a4e52136c7f58a7efc6" category="summary">本技术报告中建议的解决方案已经证明能够为交付如此卓越的客户体验提供支持，现在的挑战是确保企业采取行动来实现 AI 基础架构和工作流的现代化。</block>
  <block id="50d6e8cef34560d1d68c6688a12b1cb8" category="paragraph">随着客户体验日益被视为关键的竞争战场， AI 增强型全球支持中心成为几乎每个行业的公司都无法忽视的关键组成部分。本技术报告中建议的解决方案已经证明能够为交付如此卓越的客户体验提供支持，现在的挑战是确保企业采取行动来实现 AI 基础架构和工作流的现代化。</block>
  <block id="f6e349295b2165b25a412793116b8675" category="paragraph">AI 在客户服务中的最佳实施方式不是取代人工代理。相反， AI 可以通过实时情感分析，争议上报和多模式情感计算，让他们能够创造卓越的客户体验，从而检测语言，非语言和面部线索，通过这些线索，全面的 AI 模型可以大规模地提出建议，并补充个人代理可能缺少的内容。AI 还可以更好地匹配具有当前可用代理的特定客户。利用 AI ，企业可以从客户对提供商产品，服务和品牌形象的想法和印象中汲取宝贵的意见。</block>
  <block id="eb5cb6f03236a80f7ddd5085afa95729" category="paragraph">解决方案还可用于为支持代理构建时间序列数据，以用作客观的性能评估指标。传统的客户满意度调查通常缺乏足够的响应。通过收集员工和客户的长期情绪，雇主可以就支持代理的表现做出明智的决策。</block>
  <block id="aa20fc291fbb8ceda8651d8d8ee9dba6" category="paragraph">NetApp ， SFL 科学，开源业务流程框架和 NVIDIA 相结合，将最新技术作为托管服务集于一身，并具有极大的灵活性，可加快技术采用速度，加快新 AI/ML 应用程序的上市速度。这些高级服务在内部环境中提供，可轻松移植到云原生环境以及混合部署架构中。</block>
  <block id="c5648cc9e6e76ab4aa041d71661d0288" category="list-text">3D 交互式演示</block>
  <block id="26e071d5769be8e940617a0c8dd5c22d" category="inline-link">www.netapp.com/ai</block>
  <block id="9e22db1b830d668e86d5dc1b5c204555" category="paragraph"><block ref="9e22db1b830d668e86d5dc1b5c204555" category="inline-link-rx"></block></block>
  <block id="1fa584a3d1190f1a7fdded0c91412cac" category="list-text">直接与 NetApp AI 专家联系</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="488d7301e5d1a52040c33186d7e11657" category="paragraph"><block ref="488d7301e5d1a52040c33186d7e11657" category="inline-link-rx"></block></block>
  <block id="787dd83fbbc162f0279e320ada1f7c0b" category="list-text">《采用 NetApp 解决方案的 NVDIA 基本命令平台》简介</block>
  <block id="5541299dd0999c42fcd24fd754001e38" category="inline-link"><block ref="5541299dd0999c42fcd24fd754001e38" category="inline-link-rx"></block></block>
  <block id="ac527e3c2b2d8a080840aa28c13b127b" category="paragraph"><block ref="ac527e3c2b2d8a080840aa28c13b127b" category="inline-link-rx"></block></block>
  <block id="465b9c508fba1d27d188eb21e0655293" category="list-text">NetApp 的 AI 10 大理由信息图</block>
  <block id="75048e22ffd1c45ce07e6cae3170780a" category="inline-link"><block ref="75048e22ffd1c45ce07e6cae3170780a" category="inline-link-rx"></block></block>
  <block id="e2435a6f01dee5a11f6cd698a292183d" category="paragraph"><block ref="e2435a6f01dee5a11f6cd698a292183d" category="inline-link-rx"></block></block>
  <block id="66d4373905c5c7c0a3f51e5480d443b2" category="list-text">医疗保健领域的人工智能：深入学习如何在 lung-CT 扫描中识别 COVID-19 病变白皮书</block>
  <block id="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link"><block ref="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link-rx"></block></block>
  <block id="d1e9d43080e6c2364ee86ac930ae1341" category="paragraph"><block ref="d1e9d43080e6c2364ee86ac930ae1341" category="inline-link-rx"></block></block>
  <block id="2ece031fbb30496ba2ec244a07557107" category="list-text">医疗保健领域的人工智能：监控医疗保健环境中的面部掩模使用情况白皮书</block>
  <block id="aa895997d9bc7e84d90779885cb936b7" category="inline-link"><block ref="aa895997d9bc7e84d90779885cb936b7" category="inline-link-rx"></block></block>
  <block id="4ac3d75f4e132824f0fe3a418d42a9f9" category="paragraph"><block ref="4ac3d75f4e132824f0fe3a418d42a9f9" category="inline-link-rx"></block></block>
  <block id="ff11da2c36a9883c6eb658395f3de353" category="list-text">医疗保健领域的人工智能：诊断成像技术报告</block>
  <block id="41575d740e0d837694e2fa66ce618124" category="inline-link"><block ref="41575d740e0d837694e2fa66ce618124" category="inline-link-rx"></block></block>
  <block id="61a15cd6b61d637fb54ae6ae99ae39d5" category="paragraph"><block ref="61a15cd6b61d637fb54ae6ae99ae39d5" category="inline-link-rx"></block></block>
  <block id="1527888e6b729290296c51cf9c3aeeec" category="list-text">AI for Retail ：使用 NVIDIA Riva 的 NetApp 对话 AI</block>
  <block id="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link"><block ref="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link-rx"></block></block>
  <block id="dc1f6c62d8de3b68ec946b66d053f5a7" category="paragraph"><block ref="dc1f6c62d8de3b68ec946b66d053f5a7" category="inline-link-rx"></block></block>
  <block id="2281741ceb773b1efc91b48b4e5e04fe" category="list-text">NetApp ONTAP AI 解决方案简介</block>
  <block id="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link"><block ref="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link-rx"></block></block>
  <block id="a32cc63ad53dc74caf680b96a921ad3b" category="paragraph"><block ref="a32cc63ad53dc74caf680b96a921ad3b" category="inline-link-rx"></block></block>
  <block id="c6b4ec978259e83d537f6a179912448a" category="list-text">NetApp DataOps 工具包解决方案简介</block>
  <block id="c50b3ec30c711b6233dd7753f12165d4" category="inline-link"><block ref="c50b3ec30c711b6233dd7753f12165d4" category="inline-link-rx"></block></block>
  <block id="a045bf4eb32fbbf6c351d4c3cbd5932c" category="paragraph"><block ref="a045bf4eb32fbbf6c351d4c3cbd5932c" category="inline-link-rx"></block></block>
  <block id="9399af78c2a9b2a197612e42bf8b8f79" category="list-text">NetApp AI 控制平面解决方案简介</block>
  <block id="c771257beb97f479ebb6d342d91b61bd" category="inline-link"><block ref="c771257beb97f479ebb6d342d91b61bd" category="inline-link-rx"></block></block>
  <block id="ce6060d7bc79a57fdb337f6364f0e8a9" category="paragraph"><block ref="ce6060d7bc79a57fdb337f6364f0e8a9" category="inline-link-rx"></block></block>
  <block id="b6e1af8dc83073dfa46f061507b15586" category="list-text">《利用 Data Drive AI 转变行业》电子书</block>
  <block id="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link"><block ref="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link-rx"></block></block>
  <block id="195010aa6331d4b94de36f6aa5cf3fc7" category="paragraph"><block ref="195010aa6331d4b94de36f6aa5cf3fc7" category="inline-link-rx"></block></block>
  <block id="4dcaafba5ac7511b65c0f3a3688f8d81" category="list-text">NetApp EF 系列 AI 解决方案简介</block>
  <block id="385bae1ac9580238d4ef22dad99878c3" category="inline-link"><block ref="385bae1ac9580238d4ef22dad99878c3" category="inline-link-rx"></block></block>
  <block id="5bbcd3b785c7ecb740b1302ea68fb4ff" category="paragraph"><block ref="5bbcd3b785c7ecb740b1302ea68fb4ff" category="inline-link-rx"></block></block>
  <block id="e72de1f0850154df8bf93fae76b2276d" category="list-text">NetApp AI 和联想 ThinkSystem for AI 推理解决方案简介</block>
  <block id="883d1d69b62bc20ea26446649b6c95b0" category="inline-link"><block ref="883d1d69b62bc20ea26446649b6c95b0" category="inline-link-rx"></block></block>
  <block id="74686a12110c0c39ad22ac2252bcb1a1" category="paragraph"><block ref="74686a12110c0c39ad22ac2252bcb1a1" category="inline-link-rx"></block></block>
  <block id="8954bee2812529847e7f3108185fc57d" category="list-text">NetApp AI 和联想 ThinkSystem for Enterprise AI 和 ML 解决方案简介</block>
  <block id="f877ccffca68b901c2c61513c04dbf37" category="inline-link"><block ref="f877ccffca68b901c2c61513c04dbf37" category="inline-link-rx"></block></block>
  <block id="214ebd5c8513ce31087d4bf0cd12af76" category="paragraph"><block ref="214ebd5c8513ce31087d4bf0cd12af76" category="inline-link-rx"></block></block>
  <block id="7cbca96fc14ecadf4054303e98a81787" category="list-text">NetApp 和 NVIDIA —重新定义人工智能视频的可能</block>
  <block id="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link"><block ref="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link-rx"></block></block>
  <block id="c7531fbb829ae07f04aab76de6fad46c" category="paragraph"><block ref="c7531fbb829ae07f04aab76de6fad46c" category="inline-link-rx"></block></block>
  <block id="f521e3eae9fd2145ce8aeede6602641d" category="summary">本节介绍此解决方案的不同组件的设计注意事项。</block>
  <block id="35ff22a5291df56d5075c29d8dc65044" category="section-title">网络和计算设计</block>
  <block id="49d41bdb2234e0a4330f0c9d7d03853a" category="paragraph">根据数据安全性的限制，所有数据都必须保留在客户的基础架构或安全环境中。</block>
  <block id="5a20c2b759137410d60f5ce368ca45d2" category="paragraph"><block ref="5a20c2b759137410d60f5ce368ca45d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d6e133bd239a98d559f693ee2ff5ecc" category="section-title">存储设计</block>
  <block id="3051d856c7b26f6d385279d67a8a532b" category="paragraph">NetApp DataOps 工具包是用于管理存储系统的主要服务。DataOps 工具包是一个 Python 库，可使开发人员，数据科学家，开发运营工程师和数据工程师轻松执行各种数据管理任务，例如近乎即时地配置新的数据卷或 JupyterLab 工作空间，近乎即时地克隆数据卷或 JupyterLab 工作空间， 以及接近瞬时的数据卷快照或 JupyterLab 工作空间快照，以实现可追溯性或基线化。此 Python 库可以用作命令行实用程序或函数库，可以导入到任何 Python 程序或 Jupyter Notebook 中。</block>
  <block id="6f9e8585e5f750b8ceb149639b1e25e6" category="section-title">RIVA 最佳实践</block>
  <block id="7ecab6bd65c2f169e987be2f59219357" category="inline-link">最佳数据实践</block>
  <block id="f51b8fa6c731ea53318149e50e826ddb" category="paragraph">NVIDIA 提供了多种常规功能<block ref="f6aee1daf7f2fd9cd207fcd26f08d8be" category="inline-link-rx"></block> 要使用 Riva ，请执行以下操作：</block>
  <block id="20430e77ba2ecbe15261761c8f4fa2c4" category="list-text">* 如果可能，请使用无损音频格式。 * 使用像 mp3 这样的有损编解码器可能会降低质量。</block>
  <block id="8b3e389f067f32da1e1ab7df2b8d8155" category="list-text">* 扩充训练数据。 * 在音频训练数据中增加背景噪声最初会降低准确性，但同时提高稳定性。</block>
  <block id="b37d69a795b4d7bb6e0f28a42c3ef8ae" category="list-text">* 如果使用的是擦文本，请限制词汇大小。 * 许多在线源都包含拼写错误或辅助发音以及不常见的词。删除这些内容可以改进语言模式。</block>
  <block id="6afe4c71ada39a70da349380efbad345" category="list-text">* 如果可能，请使用最小采样速率 16kH* 。但是，请尝试不要重新采样，因为这样做会降低音频质量。</block>
  <block id="cab3977e4ad163e19ab6245a9b09f541" category="paragraph">除了这些最佳实践之外，客户还必须优先收集具有代表性的样本数据集，并为管道的每个步骤提供准确的标签。换言之，样本数据集应按比例反映目标数据集所示的指定特征。同样，数据集标注器也有责任平衡标记的准确性和速度，以便最大限度地提高数据的质量和数量。例如，此支持中心解决方案需要音频文件，带标签的文本和情感标签。此解决方案的顺序性意味着从管道开始的错误会一直传播到管道的末尾如果音频文件质量较差，则文本抄录和情感标签也会是。</block>
  <block id="0b6b65c9613285433178682e3550355c" category="paragraph">此错误传播方式与此类似，适用场景是对接受过此数据培训的模型进行的。如果情感预测 100% 准确，但语音到文本模式表现不佳，则最终管道将受初始音频到文本抄录的限制。开发人员必须单独考虑每个模型的性能，并将其作为更大管道的组成部分。在这种特定情况下，最终目标是开发一个能够准确预测情绪的渠道。因此，评估管道的总体指标是感受的准确性，而语音到文本的文字记录直接影响到这一点。</block>
  <block id="f3b552e561f520013398b3be885a4420" category="paragraph"><block ref="f3b552e561f520013398b3be885a4420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1ce31a9f2a1a3a478bb69589e180bd" category="paragraph">NetApp DataOps 工具包利用其近乎瞬时的数据克隆技术补充了数据质量检查管道。必须对每个标记的文件进行评估，并将其与现有标记的文件进行比较。在各种数据存储系统之间分布这些质量检查可确保快速高效地执行这些检查。</block>
  <block id="34d110ef6b6b3684adfe9c791fce2f95" category="summary">本节介绍部署此解决方案所需的详细步骤。</block>
  <block id="e0673e67d0ae2470ff4a9a3a926792b0" category="doc">部署支持中心观点分析</block>
  <block id="b23f4e3eb5ff4f900ba54c824bf7a676" category="paragraph">部署解决方案涉及以下组件：</block>
  <block id="1b497bff4e1d2dff7f8855237612936b" category="list-text">NGC 配置</block>
  <block id="2dcf1afb8ed1445e4b167ef91fdd8a1b" category="list-text">NVIDIA Riva 服务器</block>
  <block id="6894a1e922948fc0bc9cc96291183448" category="list-text">NVIDIA TAO 工具包</block>
  <block id="3b498dd8feee94c2dbcb419be10d3b70" category="list-text">将 TAO 模型导出到 Riva</block>
  <block id="534b37206d500ff97473ada660fb69d3" category="paragraph">要执行部署，请完成以下步骤：</block>
  <block id="2f6c7bd50828792593b3aa4deff875cc" category="section-title">NetApp DataOps 工具包：支持中心情感分析</block>
  <block id="3b84de14b99e2695fdfd099f56b254be" category="paragraph">以使用<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>，完成以下步骤：</block>
  <block id="d19523f192f664c9e34bf949d6f084c3" category="list-text">通过 Pip 安装工具包。</block>
  <block id="1fe6ae43439f5ccecf9883686d6b3784" category="list-text">配置数据管理</block>
  <block id="36b413e2c45a91e66db4aac6abd67ba1" category="section-title">NGC 配置：支持中心情感分析</block>
  <block id="e3ab64bcab09d9eb8219520405242267" category="inline-link">NVIDIA NGC</block>
  <block id="f526ba073cf7bc97c2b0d3bfe091e293" category="paragraph">进行设置<block ref="5b4e29c9d8254a25bb1abc36cd17ca4c" category="inline-link-rx"></block>，完成以下步骤：</block>
  <block id="a485a457c113aa9f2f8096ac1ca500d7" category="list-text">下载 NGC 。</block>
  <block id="7438544460c4a4fdf0b70bb65bb03a92" category="list-text">将当前目录添加到路径。</block>
  <block id="4f1208b2473595e5f4c3118c13de0fcc" category="list-text">您必须配置 NGC 命令行界面以供使用，才能运行命令。出现提示时，输入以下命令，包括 API 密钥。</block>
  <block id="5307692c5f99e57b8002a6a87f08c240" category="paragraph">对于不基于 Linux 的操作系统，请访问<block ref="481e32faa0c657434738f6f0a550651b" category="inline-link-rx"></block>。</block>
  <block id="326419ec6a380f68d7d15a373452bf35" category="section-title">NVIDIA Riva 服务器：支持中心情感分析</block>
  <block id="92ed82a726e834b50a6863c8c4e9db4e" category="paragraph">进行设置<block ref="fb85035785391c7c4b815d01de952f38" category="inline-link-rx"></block>，完成以下步骤：</block>
  <block id="a4fc5fd3d1cea05f031d5adc045dc1e0" category="list-text">从 NGC 下载 Riva 文件。</block>
  <block id="5f2573d8cf9e274560d9a9b3eb2e1aaa" category="list-text">初始化 Riva 设置（`Riva_init.sh` ）。</block>
  <block id="3b570ac682cfeffcdb2c7243afdbf285" category="list-text">启动 Riva 服务器（`Riva_start.sh` ）。</block>
  <block id="d44d4e10378cce2928c99a4b49e45cea" category="list-text">启动 Riva 客户端（`Riva_start_client.sh` ）。</block>
  <block id="6846c1a17ddaf84e01f26ec51c151e78" category="inline-link">FFmpeg</block>
  <block id="22c9c751571566e0566c448194d9d64f" category="list-text">在 Riva 客户端中，安装音频处理库（<block ref="3e294dfc4ee3a49adac5a070482274ce" category="inline-link-rx"></block>）</block>
  <block id="8637711b2ee1b94fe789bb28e88c4b61" category="list-text">启动<block ref="37a4c4b3ad3c3851ac5717bfd3104346" category="inline-link-rx"></block> 服务器</block>
  <block id="b57a5203a9fd3e877aacee6cba6bc9c8" category="list-text">运行 Riva 推理管道笔记本电脑。</block>
  <block id="5dceab25ae38dae0d7ed3167abd32377" category="section-title">NVIDIA TAO 工具包：支持中心情感分析</block>
  <block id="2418d4c7f6be40d5c9a50e4aecab1b27" category="paragraph">要设置 NVIDIA TAO 工具包，请完成以下步骤：</block>
  <block id="630eef78d15fd844ba4a38ea7f7a9c79" category="inline-link">虚拟环境</block>
  <block id="35fb58d5f90347e4f0c445b4968db5f6" category="list-text">准备并激活<block ref="3d97a4392c0af686650645d1371fa8ef" category="inline-link-rx"></block> 适用于 TAO 工具包。</block>
  <block id="0a80b2068950d6e04f34c0142a10e719" category="inline-link">所需的软件包</block>
  <block id="40eb0bd8a87ab1b39e8f2ee5ea287a22" category="list-text">安装<block ref="3646357cb54591ae95dd3b8f0889f0c2" category="inline-link-rx"></block>。</block>
  <block id="c0e95a7dacbc170e387c4e1a0fe41a0b" category="list-text">手动拉取训练和微调期间使用的图像。</block>
  <block id="b5a6ae7c1df936b55910309efc466f01" category="list-text">运行 TAO 微调笔记本电脑。</block>
  <block id="e6dda626093691f78b3127a8faa82b6e" category="section-title">将 TAO 模型导出到 Riva ：支持中心情感分析</block>
  <block id="6a358d81cb24a7e408b0339062f6bb92" category="inline-link">Riva 中的 TAO 工具包模型</block>
  <block id="53ace4ba305859107cead3e5b0b53b8b" category="paragraph">以使用<block ref="ce50a5bf8eb35af9ad9bb322336ee3af" category="inline-link-rx"></block>，完成以下步骤：</block>
  <block id="08c3be8307b7659c6ad67ee4d9659d58" category="list-text">将模型保存在 TAO 微调笔记本中。</block>
  <block id="ac711bb6af28947dfa8b29512acb36e8" category="list-text">将经过 TAO 训练的型号复制到 Riva 型号目录。</block>
  <block id="1317e1d8d20d5c44c680825aba2196e6" category="section-title">部署障碍</block>
  <block id="6e3da39922ebbd1a8a1a5a7238a89168" category="paragraph">在开发您自己的解决方案时，请谨记以下几点：</block>
  <block id="47c0613abd5b97b67a94c2355692cf08" category="list-text">首先安装 NetApp DataOps 工具包，以确保数据存储系统以最佳状态运行。</block>
  <block id="943f803f8c6b4c6508bc97536a6d7b2b" category="list-text">必须先安装 NVIDIA NGC ，再安装其他任何版本，因为它会对映像和型号的下载进行身份验证。</block>
  <block id="70367b72bfd96b5608a7c72ac3f983bf" category="list-text">必须先安装 Riva ，然后再安装 TAO 工具包。Riva 安装会根据需要配置 Docker 守护进程以提取映像。</block>
  <block id="1ed7124aa68792cb6ce3049f6f1d4f7b" category="list-text">DGX 和 Docker 必须能够访问 Internet 才能下载这些型号。</block>
  <block id="0e85d8fd0ce7acdba87f57325a14b3fb" category="summary">如上一节所述，只要有两个或更多机器学习模型按顺序运行，错误就会传播到整个管道中。对于此解决方案，句子的感受是衡量公司股票风险水平的最重要因素。语音到文本模式虽然对管道至关重要，但在预测情感之前，它是预处理单元。</block>
  <block id="6700d3710d10e74d6e48f994b760d48b" category="doc">验证结果</block>
  <block id="2e10a4ae90aad11c07592a14fbf8c5c6" category="paragraph">如上一节所述，只要有两个或更多机器学习模型按顺序运行，错误就会传播到整个管道中。对于此解决方案，句子的感受是衡量公司股票风险水平的最重要因素。语音到文本模式虽然对管道至关重要，但在预测情感之前，它是预处理单元。真正重要的是基本事实句子与预测的句子之间的情感差异。此选项用作错误率（ WER ）一词的代理。语音到文本的准确性非常重要，但 WER 不会直接用于最终管道指标。</block>
  <block id="0fc4c7871adf5db8dd2b13fc4c381da8" category="paragraph">可以根据每句话的 F1 分数，回顾和精确度计算这些情感指标。然后，可以汇总结果并将其显示在混乱列表中，同时还可以显示每个指标的置信区间。</block>
  <block id="66554c8f1474c5658d17e23710901f98" category="paragraph">使用传输学习的优势在于，模型性能提高，只需满足极少的数据要求，培训时间和成本。此外，还应将经过微调的模型与其基线版本进行比较，以确保传输学习可以提高性能，而不会影响性能。换言之，经过微调的模型在支持中心数据上的性能应比预先训练的模型更好。</block>
  <block id="6e979ee914c9401fddd049d16cdef66a" category="section-title">渠道评估</block>
  <block id="7f109f66c71a1fd15436d1c413354c41" category="cell">测试用例</block>
  <block id="e7f1ec3a5f35af805407a8a531eefb79" category="cell">测试编号</block>
  <block id="6bf1af9a7f1b6dd6cca4b7434097ad94" category="cell">渠道感受指标</block>
  <block id="beed3529b961c63b785104d7a17cf5f4" category="cell">测试前提条件</block>
  <block id="c7320b1f70fd8a9831e530d17a82f34d" category="cell">经过微调的语音到文本和情感分析模型模型</block>
  <block id="9d5b1bc6dcdedf0c8750e543fab75738" category="cell">预期结果</block>
  <block id="74015a89b882f01e94433a9c1f1c904c" category="cell">经过微调的模型的情感指标比原始的预先训练模型的性能更好。</block>
  <block id="68d279a19e31962e0ab0b648f25c07ee" category="list-text">计算基线模型的情感指标。</block>
  <block id="b6168629c9e5a47b0637aa362112642d" category="list-text">计算经过微调的模型的情感指标。</block>
  <block id="97ae5da5f745d90cf815a206b3549e0a" category="list-text">计算这些指标之间的差异。</block>
  <block id="fc997f472d1b5e66aadb364e10c29f4f" category="list-text">计算所有句子之间的差异平均值。</block>
  <block id="67d45a00257105f21f4427f31e0c9fa1" category="summary">本技术报告为客户在企业级全球支持中心内使用 NetApp 数据管理技术和 NVIDIA 软件框架以及传输学习和对话 AI 执行情感分析提供了设计指导。</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="doc">TR-4910 ：《利用 NetApp AI 进行客户沟通时的情感分析》</block>
  <block id="22268d4ee4f32cda2f20141957aac961" category="paragraph">SML 科学公司 Rick Huang ， Sathish Thyagarajan 和 NetApp 公司迭戈 Sosa-Coba 的 David Arnette</block>
  <block id="0c450c48691e7a55b657f2cb7d18a0dd" category="paragraph">本技术报告为客户在企业级全球支持中心内使用 NetApp 数据管理技术和 NVIDIA 软件框架以及传输学习和对话 AI 执行情感分析提供了设计指导。此解决方案适用于希望从代表聊天日志，电子邮件和其他文本或音频通信的录制语音或文本文件中获得客户见解的任何行业。我们实施了一个端到端管道，用于在采用 NetApp 云连接全闪存存储的 GPU 加速计算集群上展示自动语音识别，实时情感分析和深度学习的自然语言处理模式 - 再培训功能。可以对大规模的一流语言模型进行培训和优化，以便与全球支持中心快速进行推理，从而打造卓越的客户体验，并对员工的长期业绩进行客观评估。</block>
  <block id="549c85ede9b39be6ef0eec80db7e098c" category="paragraph">情绪分析是自然语言处理（ NLP ）中的一个研究领域，通过该领域，可以从文本中提取积极，负面或中立的情绪。随着越来越多的人与人工智能系统互动，对话式人工智能系统的集成程度已提升到接近全球水平。情感分析有多种使用情形，从确定支持中心员工在与来电者对话中的表现，提供适当的自动聊天机器人响应，到根据公司代表与受众在季度收益通话中的互动预测公司的股票价格。此外，情感分析可用于确定客户对品牌提供的产品，服务或支持的看法。</block>
  <block id="5855677156d63ad3c93a7b5382098060" category="paragraph">此端到端解决方案使用 NLP 模型执行高级别的情感分析，从而支持支持中心分析框架。录音会处理成书面文本，并从对话的每一句话中提取情感。可以将结果汇总到信息板中，以便对对话感受进行分析，包括历史和实时分析。此解决方案可以概括为具有类似数据模式和输出需求的其他解决方案。利用适当的数据，可以完成其他使用情形。例如，可以使用相同的端到端管道分析公司收益调用的情绪。由于管道的灵活性，还可以进行其他形式的 NLP 分析，例如主题建模和命名实体识别（ NER ）。</block>
  <block id="ea4f750fd9fd89aeff4ca8d4162fb673" category="paragraph">NVIDIA Riva ， NVIDIA TAO 工具包和 NetApp DataOps 工具包共同实现了这些 AI 实施。NVIDIA 的工具可用于使用预构建的型号和管道快速部署高性能 AI 解决方案。NetApp DataOps 工具包可简化各种数据管理任务，以加快开发速度。</block>
  <block id="7a7e97f7fcf4e2974d9a6feee2b056f8" category="section-title">客户价值</block>
  <block id="3815ef30c3d6c6bdc3862cc9530d091e" category="paragraph">企业可以通过员工评估和客户响应工具在文本，音频和视频对话中获得价值，以便进行情绪分析。经理可以从信息板中提供的信息中受益，从而可以根据对话的两个方面评估员工和客户满意度。</block>
  <block id="da210ea22d819ca26070a3795f9a14d4" category="paragraph">此外， NetApp DataOps 工具包还可管理客户基础架构中数据的版本控制和分配。这样就会频繁更新信息板中提供的分析，而不会产生庞大的数据存储成本。</block>
  <block id="ea490901c403ce2b2a89f80227d0fb90" category="paragraph">计划二进制文件和数据库复制攻略手册</block>
  <block id="2c777d857235f251004d6d8d70c9751d" category="list-text">复制先前创建的作业模板。</block>
  <block id="1eb977b1f69b531db931e9c62c1a0de9" category="list-text">找到 ontap/CVO 设置模板，然后在最右侧单击复制模板</block>
  <block id="3c96e57d33780bedfb652def025f39de" category="list-text">单击复制的模板上的编辑模板，然后将名称更改为二进制和数据库复制攻略手册。</block>
  <block id="b07fb736e8c17cea7e9e3753e7a67fd1" category="list-text">保留该模板的相同清单，项目和凭据。</block>
  <block id="f42c6e71dcb07b403b8393d5ab7f7fe4" category="list-text">选择 ora_replication cc.yml 作为要执行的攻略手册。</block>
  <block id="69fa06239fd734936aac1af5250c7f57" category="list-text">这些变量将保持不变，但需要在变量 dst_cluster_ip 中设置 CVO 集群 IP 。</block>
  <block id="ec7445bbcbadd1f11fe1bc3e5e56eef9" category="list-text">计划作业模板。</block>
  <block id="ce0d20e65f0354847807516cbcc696f6" category="list-text">单击二进制和数据库复制攻略手册模板，然后单击顶部选项集的计划。</block>
  <block id="d9a6405dc4a6cd71f6d77c749070a5e6" category="list-text">单击添加，为二进制和数据库复制添加名称计划，在小时开始时选择开始日期 / 时间，选择您的本地时区以及运行频率。运行频率通常会更新 SnapMirror 复制。</block>
  <block id="2dc4dec75c83aeb010419dc2a02da40b" category="admonition">系统将为日志卷复制创建一个单独的计划，以便可以更频繁地进行复制。</block>
  <block id="cc335cb73dc47f7a9b404288e3b4330f" category="paragraph">ONTAP 和 CVO 设置</block>
  <block id="6bc14a28f101e9d80ecc643ef13ef7fb" category="list-text">输入名称 ontap/CVO 设置</block>
  <block id="a7244f663b97629084f004e6c89b4a75" category="list-text">选择作业类型；运行将根据攻略手册配置系统。</block>
  <block id="57344b3bd58c0e451513e303e45d49b7" category="list-text">为内部环境选择 ontap_setup.yml 攻略手册，或者选择 CVO_setup.yml 以复制到 CVO 实例。</block>
  <block id="41c1d72990c270d0221458749497c3e6" category="admonition">我们将使用此模板并将其复制到其他攻略手册中。</block>
  <block id="63c0320f73b5f4e528bbe1488acc5103" category="section-title">为 Oracle 数据库提供自动化数据保护</block>
  <block id="d798c6a829fee4b3d8316144e8769e91" category="paragraph">企业正在对其环境进行自动化，以提高效率，加快部署速度并减少手动操作。Ansible 等配置管理工具正在用于简化企业数据库操作。在本解决方案中，我们演示了如何使用 Ansible 通过 NetApp ONTAP 自动保护 Oracle 数据。通过使存储管理员，系统管理员和 DBA 能够一致快速地将数据复制到异地数据中心或公有云，您可以获得以下优势：</block>
  <block id="1d4694b7ed077df8b2c51d4ef956ce0c" category="list-text">缩短配置集群间复制， CVO 实例化和恢复 Oracle 数据库的时间</block>
  <block id="60bcf8682ddc3583a74e6cd2d95e1ccb" category="list-text">提供数据库恢复工作流，以便于测试灾难恢复场景。</block>
  <block id="7fa4d3428dbef9829f6325b288c071bc" category="section-title">在内部复制到内部复制</block>
  <block id="911a9e8dd85bfeeba31c1ed049e41e1c" category="list-text">在源和目标上创建集群间 LIF</block>
  <block id="2f4eb56dd9301fc33f559b4345b90eb3" category="list-text">建立集群和 SVM 对等关系</block>
  <block id="2b71f4136dce37491ef0f319f5d1fbd9" category="list-text">创建并初始化 Oracle 卷的 SnapMirror</block>
  <block id="20f4a46f5b12b0533f7a2268c4c2bf41" category="list-text">通过 AWX/Tower 为 Oracle 二进制文件，数据库和日志创建复制计划</block>
  <block id="6ef1c2ae7c9ca61a54d88de28349a772" category="list-text">还原目标上的 Oracle 数据库，并使数据库联机</block>
  <block id="f4ec61d9ffa147f621f854609523a0fb" category="section-title">在内部迁移到 AWS 中的 CVO</block>
  <block id="3f155aa6a9345b3e25f3bb44ecccfc0a" category="list-text">创建 AWS 连接器</block>
  <block id="1531cb3c2d4db27dcd3bfa2ad4711ec5" category="list-text">在 AWS 中创建 CVO 实例</block>
  <block id="2f159b717f78e9925b219e87cbd20f9a" category="list-text">将内部集群添加到 Cloud Manager</block>
  <block id="df16a1e23dbbcc2f19f07ab1af741617" category="list-text">在源上创建集群间 LIF</block>
  <block id="0679a51ae3a4071a6bd3dedbe97fd329" category="summary">此页面介绍了在 NetApp ONTAP 存储上部署 Oracle 数据保护的自动化方法。</block>
  <block id="22e3bbd761fbb7ae69b8035eb12f222d" category="paragraph">此解决方案设计为在 AWX/ 塔式环境中运行。</block>
  <block id="ad5310e9dcd8f367be2b92490488d86d" category="list-text">解决方案设计用于在私有云环境（内部到内部）和混合云（内部到公有 Cloud Cloud Volumes ONTAP （ CVO ））中运行</block>
  <block id="936c99ed52ca08a052ebf611285dd998" category="inline-link-macro">收集 CVO 和连接器部署的前提条件</block>
  <block id="ec329a9106131eb9bf99b0f9e67b0564" category="list-text">有关获取 CVO 数据保护所需密钥和令牌的详细说明，请访问 <block ref="e21f73de51752f791cddc773d1f38740" category="inline-link-macro-rx"></block></block>
  <block id="13716f12996b882bb4c7e0bd84c7c128" category="open-title">&lt;Strong class="bi"&gt; 内部部署 &lt;/Strong&gt; &lt;Strong&gt;|&lt;/Strong&gt;</block>
  <block id="72bd33cc372377848ab3bb360deb365e" category="cell">ONTAP 版本 9.8 及更高版本</block>
  <block id="3ca63226b942aff3abcf62934a91e382" category="cell">源上的现有 Oracle 环境以及目标上的等效 Linux 操作系统（灾难恢复站点或公有云）</block>
  <block id="6114118ecf4e8d86a2e7c80bfab462f6" category="open-title">&lt;strong class="bi"&gt;CVO&lt;/Strong&gt;</block>
  <block id="2f960df807c8ad51e74c447149eb2033" category="cell">* Cloud Manager/AWS*</block>
  <block id="571f37fae4494df03321c2abe1fcc053" category="cell">AWS 访问 / 机密密钥</block>
  <block id="7a5be8c4513f3bd0696db24a6bd977f4" category="cell">NetApp Cloud Manager 帐户</block>
  <block id="99e55608ac5f1697eb6804aaf586af09" category="cell">NetApp Cloud Manager 刷新令牌</block>
  <block id="3f9ec2a23fee1cafeb1a700de677caac" category="cell">攻略手册</block>
  <block id="1f959110c5104b300b1a3d5fe3ee80dc" category="cell">* ontap_setup*</block>
  <block id="b7ed1e5c864a764f83f035d7f4f774ee" category="cell">在源集群上创建集群间 LIF （可选）</block>
  <block id="73ddb5848c16203494697871a4e993cd" category="cell">在目标集群上创建集群间 LIF （可选）</block>
  <block id="04a35ce053d611d390fc192544fa4899" category="cell">创建集群和 SVM 对等关系</block>
  <block id="4605aea1d05aa2979e72d73dd2c51773" category="cell">创建目标 SnapMirror 并初始化指定的 Oracle 卷</block>
  <block id="0dd4c7b6672d8937b6eb899b454fb7fe" category="cell">* 复制 _cg</block>
  <block id="7187aaa97acef94360159347d76a84c9" category="cell">在 /etc/oratab 中为每个数据库启用备份模式</block>
  <block id="f9198142d6e5690166713858ae8a0cdd" category="cell">为 Oracle 二进制卷和数据库卷创建的快照</block>
  <block id="23ba14a0a5cf33c38faec5b66fff712e" category="cell">已更新 SnapMirror</block>
  <block id="114debcae141b96db77c72e8a1e8fadb" category="cell">关闭 /etc/oratab 中每个数据库的备份模式</block>
  <block id="682094861a79bcba0e0ab2e193198762" category="cell">* 。 ora_replication ； log*</block>
  <block id="1d03ae98454d1c807318a1e29a4e2736" category="cell">切换 /etc/oratab 中每个数据库的当前日志</block>
  <block id="47e4696811eedec695f727189503e8df" category="cell">为 Oracle 日志卷创建的快照</block>
  <block id="86836efae3e3d868a96ae69bcbc987ba" category="cell">* ora_recovery*</block>
  <block id="6ceab4515ef4144abed0f0ce5ed3038f" category="cell">中断 SnapMirror</block>
  <block id="a6066c717f63ac99226b48abb4cf1d85" category="cell">在目标上启用 NFS 并为 Oracle 卷创建接合路径</block>
  <block id="aa46cdc29b66725a1180f57d02f0cee3" category="cell">配置 DR Oracle 主机</block>
  <block id="dea9253f9b15f57a0c2161848a3c27a3" category="cell">挂载并验证 Oracle 卷</block>
  <block id="ee95819ff53983a149759d555a93ba4b" category="cell">恢复并启动 Oracle 数据库</block>
  <block id="5a6b57bc1fdf2f0e1259ed22f1d027a4" category="cell">* CVO_setup*</block>
  <block id="331c87cd495ffdc9cd55d8b3935a75f5" category="cell">对环境进行预检查</block>
  <block id="5f17c8d8d95282db12506044ba4d6ab9" category="cell">AWS 配置 /AWS 访问密钥 ID/ 机密密钥 / 默认区域</block>
  <block id="cef449920fe163cdd74231266cbdf23d" category="cell">创建 AWS 角色</block>
  <block id="85a4bcbc96cde90931ad369de96535b2" category="cell">在 AWS 中创建 NetApp Cloud Manager Connector 实例</block>
  <block id="abe14752834b641e86064c7214f6719c" category="cell">在 AWS 中创建 Cloud Volumes ONTAP （ CVO ）实例</block>
  <block id="c2a9449cd3b0ae879520f450b65b1621" category="cell">将内部源 ONTAP 集群添加到 NetApp Cloud Manager 中</block>
  <block id="fbb54d6efa6ca64af90fbe2289812be8" category="cell">在目标 CVO 上启用 NFS 并为 Oracle 卷创建接合路径</block>
  <block id="3ef6389d9b9aacdce331793dd2a96ce8" category="paragraph">为了简化自动化，我们已使用默认值预设了许多必需的 Oracle 参数。通常，无需更改大多数部署的默认参数。更高级的用户可以谨慎地更改默认参数。默认参数位于每个角色文件夹的默认目录下。</block>
  <block id="a98d844e94ad28c8e0fb089e005d6b9f" category="inline-link-macro">此处可查看 AWX/ 塔式服务器的详细流程</block>
  <block id="7e599865fd1cdad0e26add5715f65267" category="paragraph">准备就绪后，单击 <block ref="d28bc5520349bb0598caaa5132432326" category="inline-link-macro-rx"></block>。</block>
  <block id="47373f46adef617d17665b0b94be8f67" category="paragraph">计划日志复制攻略手册</block>
  <block id="8e43fbf8e210fdbb3e1d59ca59cde628" category="list-text">单击复制的模板上的 Edit Template ，然后将名称更改为 Restore and Recovery Playbook 。</block>
  <block id="42f2159b893bbf4b6bf098ba9a026a1c" category="list-text">选择 ora_recovery.yml 作为要执行的攻略手册。</block>
  <block id="0a3fe9b740fe79971ae2379eaec4822c" category="admonition">只有在准备好在远程站点还原数据库后，才会运行此攻略手册。</block>
  <block id="261e91a1afdfe1123497b1b9ba5ab3e1" category="section-title">AWX/ 塔式 Oracle 数据保护</block>
  <block id="db2b28449b6d868d910cd53527934988" category="list-text">提供第一个组的名称 oracle ，然后单击 Save 。</block>
  <block id="200e1fa09608b23de5cd04d22d3a5bdb" category="list-text">对名为 dr_oracle 的第二个组重复此过程。</block>
  <block id="1e29c17b60e9145858da82263315e402" category="list-text">选择已创建的 Oracle 组，转至主机子菜单，然后单击添加新主机。</block>
  <block id="250d5368537e295251f9ccf63f950087" category="list-text">提供源 Oracle 主机管理 IP 的 IP 地址，然后单击保存。</block>
  <block id="22dcd973cf7a10ed9d03c5b959e65807" category="list-text">必须对 dr_oracle 组重复此过程，并添加 DR/Destination Oracle 主机的管理 IP/ 主机名。</block>
  <block id="1a4eca6a53be80f21117669b80a5dbc8" category="admonition">下面介绍了如何使用 ONTAP 为内部部署或 AWS 上的 CVO 创建凭据类型和凭据。</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="open-title">内部</block>
  <block id="50d33cb309a9ea4bacb0a5541498b670" category="list-text">创建凭据类型。对于涉及 ONTAP 的解决方案，您必须配置凭据类型以匹配用户名和密码条目。</block>
  <block id="c048e95ab07253cc1cb87bef130c410b" category="list-text">将以下内容粘贴到 " 注入器配置 " 中，然后单击保存：</block>
  <block id="9302fe5c60a983a24bb8787c00db4862" category="list-text">为 ONTAP 创建凭据</block>
  <block id="0a0aab79fb5a20fa5f830947226ef87c" category="list-text">输入 ONTAP 凭据的名称和组织详细信息</block>
  <block id="81999e930ad44af27e84682c3ea1e750" category="list-text">选择上一步中创建的凭据类型。</block>
  <block id="1546222d368538c25b5704b5fcf160f5" category="list-text">在 Type Details 下，输入源集群和目标集群的用户名和密码。</block>
  <block id="c4be718383c8ca0aa17633d911fc38fd" category="list-text">单击保存。</block>
  <block id="39f6f9fe82cbf0c0970d13b6a043ad84" category="list-text">为 Oracle 创建凭据</block>
  <block id="30d4be106e7fb63befec4c8c7c815ad0" category="list-text">输入 Oracle 的名称和组织详细信息。</block>
  <block id="61d6c643401e4a602f3c8b4b6fc0a93c" category="list-text">如果需要为 dr_oracle 主机配置其他凭据，请重复此过程。</block>
  <block id="f7fc367b5de87581ac78fc80805439af" category="open-title">CVO</block>
  <block id="61efb6ce79debd57f1e5eb28b08f94ba" category="list-text">创建凭据类型。对于涉及 ONTAP 的解决方案，您必须配置凭据类型以匹配用户名和密码条目，我们还会为 Cloud Central 和 AWS 添加条目。</block>
  <block id="b95cd128bfca5d5c9181a46d0392c360" category="list-text">将以下内容粘贴到 "Injector Configuration" 中，然后单击 "Save ：</block>
  <block id="75f3f97810b5eef177a5355b86dabfd0" category="list-text">为 ontap/CVO/AWS 创建凭据</block>
  <block id="922922f515b0ac072e20128999512b50" category="list-text">为 Oracle 创建凭据（源）</block>
  <block id="7ebca140d5dcaa006aeda44b19cfc52e" category="list-text">输入 Oracle 主机的名称和组织详细信息</block>
  <block id="ca530facf78f2112c60ee838d85b9b5b" category="list-text">为 Oracle 目标创建凭据</block>
  <block id="063e8368b0de123266b00f2c88e317fb" category="list-text">输入 DR Oracle 主机的名称和组织详细信息</block>
  <block id="0d28c8cc8415971cf2cd02507176bf94" category="list-text">在 Type Details 下，输入 Username （ EC2-user ，或者如果您已对其进行了默认更改，请输入该用户名）和 SSH 私钥</block>
  <block id="cb8f433dfb62a17f7a02f4d7a8839b1c" category="list-text">选择正确的权限升级方法（ sudo ），然后根据需要输入用户名和密码。</block>
  <block id="791ef966f9be349751448b9066bdd8fa" category="list-text">输入 ... <block ref="1881636a0f344e587cc2202e2db4c5ac" category="inline-link-rx"></block> 作为源控制 URL 。</block>
  <block id="285a3bb8fb6f692046facadb3c0984cf" category="paragraph">需要运行四本单独的攻略手册。</block>
  <block id="37472723bc7712fedddee6d02e29228d" category="list-text">用于设置环境的攻略手册，内部部署或 CVO 。</block>
  <block id="5138c89250c5086accf2d1a5961c9b17" category="list-text">用于按计划复制 Oracle 二进制文件和数据库的攻略手册</block>
  <block id="3e552d6e5b2c316c63eb1fc2081d42a8" category="list-text">用于按计划复制 Oracle 日志的攻略手册</block>
  <block id="33f4f1514dc2ceb963af16685f4de58c" category="list-text">用于在目标主机上恢复数据库的攻略手册</block>
  <block id="17ae7167fac3c2364c6ad7b58819a920" category="open-title">ONTAP/CVO 设置</block>
  <block id="16f928d0ebd67060f6b3b2abf0481928" category="open-title">二进制卷和数据库卷的复制</block>
  <block id="b723f9a72bec39ac17d89e51ff0ba336" category="open-title">复制日志卷</block>
  <block id="048f2ee27b8617cb0e13b6a0b7da956f" category="list-text">单击复制的模板上的 Edit Template ，然后将名称更改为 Log Replication 攻略手册。</block>
  <block id="d4a86123c8e623e35eaa51ab9583e03b" category="list-text">选择 ora_replication logs.yml 作为要执行的攻略手册。</block>
  <block id="d6e504930da1d0732ea4162514a38e8e" category="list-text">单击日志复制攻略手册模板，然后单击顶部选项集的计划。</block>
  <block id="1c03188c731004905466903c2eb763c4" category="list-text">单击添加，为日志复制添加名称计划，选择开始日期 / 时间，选择本地时区和运行频率。运行频率通常会更新 SnapMirror 复制。</block>
  <block id="d23bfe090a9fd09613c7a6573f619c02" category="admonition">建议将日志计划设置为每小时更新一次，以确保恢复到上一个每小时更新。</block>
  <block id="f76dbca531ab83300165aacf97e1b7ff" category="open-title">还原和恢复数据库</block>
  <block id="b8a177e5fd059f33473cad4d1d073d38" category="list-text">内部生产 Oracle 数据库数据卷通过 NetApp SnapMirror 复制到二级数据中心的冗余 ONTAP 集群或公有云中的 Cloud Volume ONTAP 进行保护。在完全配置的灾难恢复环境中，二级数据中心或公有云中的恢复计算实例处于备用状态，可以在发生灾难时恢复生产数据库。备用计算实例通过在操作系统内核修补程序上运行准面更新或在一个锁定步骤中进行升级，与内部实例保持同步。</block>
  <block id="57d8ad774cb4fef3d53ee8836bfee761" category="list-text">在此解决方案演示中， Oracle 二进制卷会复制到目标并挂载到目标实例，以启动 Oracle 软件堆栈。与灾难发生时的最后一分钟全新安装 Oracle 相比，这种恢复 Oracle 的方法更有优势。它可以保证 Oracle 安装与当前内部生产软件安装和修补程序级别等完全同步。但是，根据 Oracle 软件许可的结构，这可能会对恢复站点上复制的 Oracle 二进制卷产生额外的软件许可影响，也可能不会产生额外的软件许可影响。建议用户在决定使用相同方法之前，先咨询其软件许可人员，以评估潜在的 Oracle 许可要求。</block>
  <block id="74eaa493ffed695592003e0844d93c46" category="list-text">目标位置的备用 Oracle 主机已配置 Oracle 前提条件配置。</block>
  <block id="0be4357ac224d44b11800179b23eb202" category="list-text">SnapMirrors 已损坏，卷可写并挂载到备用 Oracle 主机。</block>
  <block id="69504b415e8aad20e18beca0de96ab6a" category="list-text">在备用计算实例上挂载所有数据库卷后， Oracle 恢复模块将在恢复站点执行以下恢复和启动 Oracle 任务。</block>
  <block id="5e52a9563e31960cdf02c7b83e6495e7" category="list-text">同步控制文件：我们在不同的数据库卷上部署了重复的 Oracle 控制文件，以保护关键数据库控制文件。一个位于数据卷上，另一个位于日志卷上。由于数据卷和日志卷的复制频率不同，因此在恢复时它们将不同步。</block>
  <block id="26b9a788a0ef0527f25f68892b364d19" category="list-text">重新链接 Oracle 二进制文件：由于 Oracle 二进制文件已重新定位到新主机，因此需要重新链接。</block>
  <block id="b66ad18a7982f7c233e9d0af2f867856" category="list-text">恢复 Oracle 数据库：恢复机制从控制文件中检索 Oracle 日志卷中最后一个可用归档日志中的最后一个系统更改编号，并恢复 Oracle 数据库以重新处理在发生故障时能够复制到灾难恢复站点的所有业务事务。然后，数据库将在新的形式中启动，以在恢复站点执行用户连接和业务事务。</block>
  <block id="c4ff33edf6e94fb434fb59e4ad2c286b" category="inline-link-macro">采用 SnapCenter 的混合云数据库解决方案</block>
  <block id="fc25c016a8fb35a621842044a8d4f2e7" category="inline-link-macro">在混合云中自动化 Oracle 数据库基础架构</block>
  <block id="b9b07f10c0ce1735548942e3abaa3447" category="summary">此页面提供了有关通过 NetApp Cloud Manager 收集 CVO 和 Cloud Manager Connector 部署所需的刷新令牌和访问 / 机密密钥的详细信息。</block>
  <block id="bcc03f70ea2e77a98ddb6e8267e4892f" category="paragraph">要通过 AWX/Ansible 塔使用 Ansible 攻略手册配置 CVO 和连接器的自动部署，需要以下信息：</block>
  <block id="193fc1c355935356ecd5d07811792512" category="section-title">从 AWS 获取访问 / 机密密钥</block>
  <block id="60b6439418495e0d1821d169b7d4b885" category="list-text">要在 Cloud Manager 中部署 CVO 和 Connector ，我们需要 AWS 访问 / 机密密钥。通过启动 IAM -&gt; 用户 -&gt; 您的用户名 -&gt; 安全凭据 -&gt; 创建访问密钥，在 AWS 控制台中获取密钥。</block>
  <block id="ad1cc06192440312813c412c9cf08bc5" category="list-text">复制访问密钥并确保其安全，以便在 Connector 和 CVO 部署中使用。</block>
  <block id="4ba9f13f5b12512f3651d5ea2d3ffa05" category="admonition">如果您丢失了密钥，则可以创建另一个访问密钥并删除丢失的密钥</block>
  <block id="ad35fbaef240a8ec1f43e8a0d5e15099" category="image-alt">刷新令牌</block>
  <block id="89d8fe92eb33da3c73df38422c3fa73e" category="section-title">从 NetApp Cloud Central 获取刷新令牌</block>
  <block id="3d7e1d21530a3a98c74b0b7484c84516" category="list-text">使用您的帐户凭据登录到云中心帐户，网址为<block ref="ddbd83acb6424bbb7fa6878eff0976a1" category="inline-link-rx"></block></block>
  <block id="a95c6d24569073e45c394bcbd6a2c0e4" category="list-text">生成刷新令牌并将其保存以供部署使用。</block>
  <block id="ecd636681b83fa2697020594594aea14" category="section-title">正在获取客户端 ID</block>
  <block id="2a1ed6ca97aeb484a26d6e0d625af96b" category="list-text">访问 API 页面以复制客户端 ID<block ref="06324b77583872f7e211b3e7ec3f882f" category="inline-link-rx"></block>。</block>
  <block id="1093ef7993a1f3824edbf581bb54b571" category="list-text">单击右上角的 " 了解如何进行身份验证 " 。</block>
  <block id="622dcb1fafb9f30d36b32341e23ae7a0" category="list-text">从弹出的身份验证窗口中，如果您需要用户名 / 密码才能登录，请从常规访问复制客户端 ID 。使用 SSO 的联合用户应从 " 刷新令牌选项卡 " 复制客户端 ID 。</block>
  <block id="76525f0f34b48475e5ca33f71d296f3b" category="image-alt">客户端 ID</block>
  <block id="6090065e2462d5f96ebac132568bdf46" category="section-title">从 AWS 获取密钥对</block>
  <block id="294b903c23e96b98876b04f51502cec4" category="list-text">在 AWS 控制台中，搜索 "Key Pair" 并创建一个带有 "pem" 的密钥对。记住 key_pair 的名称，我们将使用它来部署连接器。</block>
  <block id="ddb20e807acdf5ddf189dd213ff6d0cf" category="image-alt">Key Pair</block>
  <block id="3ce1d7d6e1b4509256dd2574b6b5d290" category="section-title">正在获取帐户 ID</block>
  <block id="8f19980a36fbde35540547e8f630c9e5" category="list-text">在 Cloud Manager 中，单击 Account – &gt; Manage Accounts ，然后复制帐户 ID 以用于 AWX 的变量。</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">NetApp 混合云数据解决方案—基于客户用例的 Spark 和 Hadoop</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">用例 1 —备份 Hadoop 数据</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">用例 2 —从云到内部环境的备份和灾难恢复</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">用例 3 —对现有 Hadoop 数据启用 DevTest</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">用例 4 —数据保护和多云连接</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">用例 5 —加快分析工作负载的速度</block>
  <block id="ae270ffdc87820776fadfe121aa13143" category="sidebar">使用 NetApp AI 进行情感分析</block>
  <block id="f74720767a0bf20cfdb6bba5f215d795" category="sidebar">部署支持中心情感分析</block>
  <block id="3e9d3644ee18a66c51ddd16b668eaa5a" category="sidebar">自动化 Oracle 数据保护</block>
  <block id="82be90bcfc8fd03855e030edaa25583a" category="sidebar">适用于 AWX/ 塔式服务器的自动化 Oracle 数据保护</block>
  <block id="080e5221e660ab18a3746fe480956ebc" category="paragraph">在容器管理级别， Kubernetes 容器管理是一个不错的选择，完全上游版本（ Canonical ）或适用于企业部署的修改版本（ Red Hat ）均支持此功能。。 <block ref="8ff9014ec7345470e1bb9286d28496e4" category="inline-link-macro-rx"></block> 使用 NetApp Trident 和新添加的<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> 为数据科学家和数据工程师提供内置可追溯性，数据管理功能，接口和工具，以便与 NetApp 存储集成。Kubeflow 是适用于 Kubernetes 的 ML 工具包，可在 TensorFlow Serving 或 NVIDIA Triton 推理服务器等多个平台上提供额外的 AI 功能以及对型号版本控制和 KFServing 的支持。另一个选项是 NVIDIA EGX 平台，它可提供工作负载管理以及对支持 GPU 的 AI 推理容器目录的访问。但是，这些选项可能需要大量的精力和专业知识才能投入生产，并且可能需要第三方独立软件供应商（ ISV ）或顾问的协助。</block>
  <block id="fffa1b56750a0334993c90d5adc9912a" category="doc">TR-4798 ： NetApp AI 控制平台</block>
  <block id="68eff5f8d34b801d40ab55f098bc6478" category="inline-link-macro">请单击此处了解解决方案入门</block>
  <block id="e5dec240e8be4a30564a7e8ddc0d568a" category="list-text">准备就绪后，单击 <block ref="a171481e1cde5211da297c03090cb7ce" category="inline-link-macro-rx"></block>。</block>
  <block id="4d0c05180ba83e5c8a9bbac094c365e2" category="list-text">此自动化设置为运行三个阶段（安装， Oracle 二进制文件复制计划，数据库，日志和仅适用于日志的复制计划），以及第四个阶段以在灾难恢复站点恢复数据库。</block>
  <block id="675b1e5a01195fa5d419962701704b96" category="cell">在 Oracle EC2 实例上设置适当的交换空间，默认情况下，某些 EC2 实例使用 0 交换部署</block>
  <block id="68085bee9e04417d4d9e74101a357a22" category="list-text">在 Type Details 下，输入源集群和 CVO 集群， Cloud Central/Manager ， AWS 访问 / 机密密钥和 Cloud Central 刷新令牌的用户名和密码。</block>
  <block id="861503fb33ea04fecb13449e713e8ac6" category="admonition">运行恢复攻略手册之前，请确保您具备以下条件：确保它通过 /etc/oratab 和 /etc/oraInst.oc 从源 Oracle 主机复制到目标主机</block>
  <block id="72feee9e055adc523c4c9ca3c1453409" category="inline-link-macro">视频：使用 Astra Control 在 CI/CD 管道中保护数据</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">我们使用 NetApp StorageGRID 设置对生产和消费工作负载执行了三到四个节点的分层存储测试。</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">性能测试与可扩展性</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">当存储节点数量增加时，完成生产和消费模式操作所需的时间呈线性下降趋势。</block>
  <block id="544baf869b5baa766e8839cd33697872" category="paragraph"><block ref="544baf869b5baa766e8839cd33697872" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">根据 StorageGRID 节点的数量， S3 检索操作的性能呈线性增长。StorageGRID 最多支持 200 个 StorgeGRID 节点。</block>
  <block id="2cd319a657a7fccb8f747dab6f102dcc" category="paragraph"><block ref="2cd319a657a7fccb8f747dab6f102dcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">本节介绍此解决方案中使用的技术。</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">使用 Grid Manager 进行简单管理</block>
  <block id="a96dbd2aff4998074bc0ca48dc4817d5" category="paragraph"><block ref="a96dbd2aff4998074bc0ca48dc4817d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">管理全局分布的 PB 级对象存储库，例如图像，视频和记录。</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">监控网格节点和服务以确保对象可用性。</block>
  <block id="52134209a1824af49cd06b67ca3aedc7" category="list-text">使用信息生命周期管理（ ILM ）规则管理对象数据随时间的放置。这些规则用于控制在载入对象数据后该数据会发生什么情况，如何防止其丢失，对象数据的存储位置以及数据的存储时间。</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">监控系统内的事务，性能和操作。</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">信息生命周期管理策略</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">负载平衡器和端点配置</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">StorageGRID 中的管理节点提供了网格管理器 UI （用户界面）和 REST API 端点，用于查看，配置和管理 StorageGRID 系统，并可通过审核日志来跟踪系统活动。为了为 Confluent Kafka 分层存储提供高可用性的 S3 端点，我们实施了 StorageGRID 负载平衡器，该平衡器作为一项服务在管理节点和网关节点上运行。此外，负载平衡器还管理本地流量并与 GSLB （全局服务器负载平衡）进行通信，以帮助进行灾难恢复。</block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="section-title">Apache Kafka</block>
  <block id="d1675da945892e06b2f84c42c32b7074" category="paragraph"><block ref="d1675da945892e06b2f84c42c32b7074" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka 存储来自任意数量的进程的关键价值消息，这些进程称为 " 生产者 " 。可以将数据分区为不同主题中的不同分区。在分区中，消息严格按其偏移量（消息在分区中的位置）排序，并编制索引并随时间戳一起存储。其他称为使用者的进程可以从分区读取消息。对于流处理， Kafka 提供了流 API ，可用于写入使用 Kafka 数据的 Java 应用程序，并将结果写入 Kafka 。Apache Kafka 还可与外部流处理系统配合使用，例如 Apache Apex ， Apache Flink ， Apache Spark ， Apache Storm 和 Apache NiFi 。</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka 在一个或多个服务器（称为代理）组成的集群上运行，所有主题的分区分布在各个集群节点上。此外，分区会复制到多个代理。这种架构使 Kafka 能够以容错方式提供大量消息流，并使其能够取代一些传统消息传送系统，例如 Java 消息服务（ Java Message Service ， JMS ），高级消息队列协议（ Advanced Message Queuing Protocol ， AMQP ）等。自 0.11.0.0 版本以来， Kafka 提供了事务写入功能，可使用流 API 精确处理一次流。</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka 支持两种类型的主题：常规和压缩。可以为常规主题配置保留时间或空间限制。如果存在早于指定保留时间的记录，或者超出分区的绑定空间，则允许 Kafka 删除旧数据以释放存储空间。默认情况下，主题的保留时间为 7 天，但也可以无限期地存储数据。对于压缩主题，记录不会根据时间或空间限制过期。相反， Kafka 会将后续消息视为对具有相同密钥的旧消息的更新，并保证不会删除每个密钥的最新消息。用户可以通过使用特定密钥的空值编写所谓的 tombstone 消息来完全删除消息。</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Kafka 中有五个主要 API ：</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">* 生成程序 API-* 允许应用程序发布记录流。</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">* 使用者 API-* 允许应用程序订阅主题并处理记录流。</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">* 连接器 API" 。 * 执行可重复使用的生产者和使用者 API ，以便将这些主题链接到现有应用程序。</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">* 流 API 。 * 此 API 将输入流转换为输出并生成结果。</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">* 管理 API-* 用于管理 Kafka 主题，代理和其他 Kafka 对象。</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">消费者和生产者 API 基于 Kafka 消息传送协议构建，并在 Java 中为 Kafka 消费者和生产者客户端提供了参考实施。底层消息传送协议是一种二进制协议，开发人员可以使用该协议以任何编程语言编写自己的使用者或生产者客户端。这样便可解除 Kafka 对 Java 虚拟机（ JVM ）生态系统的锁定。可用的非 Java 客户端列表会保存在 Apache Kafka wiki 中。</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">为什么选择 Confluent ？</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">通过将历史数据和实时数据集成到一个统一的中央真相来源中， Confluent 可以轻松构建一个全新的现代化事件驱动型应用程序类别，获得通用数据管道，并充分扩展性，性能和可靠性，释放出强大的新用例。</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">Confluent 的用途是什么？</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">借助整合平台，您可以专注于如何从数据中获得业务价值，而不是担心底层机制，例如如何在不同系统之间传输或集成数据。具体而言， Confluent Platform 可简化将数据源连接到 Kafka 的过程，构建流式应用程序，以及保护，监控和管理 Kafka 基础架构。如今， Consfluent Platform 已广泛用于各行各业的各种用例，从金融服务，全渠道零售和自动驾驶汽车到欺诈检测， 微服务和物联网。</block>
  <block id="a4eaf48584aaa7df975a9275a8b4ee24" category="paragraph"><block ref="a4eaf48584aaa7df975a9275a8b4ee24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0693822e07a3206c53912f33e3d67758" category="section-title">Confluent 事件流技术概述</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Confluent Platform 的核心是<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block>一种最受欢迎的开源分布式流式平台。Kafka 的主要功能如下：</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">发布并订阅记录流。</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">以容错方式存储记录流。</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">处理记录流。</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">即装即用的 Confluent 平台还包括架构注册表， REST 代理，总共 100 多个预构建的 Kafka 连接器和 ksqlDB 。</block>
  <block id="55be5d4d3f7143137050de9374d03f6f" category="section-title">Confluent 平台企业功能概述</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">* 流畅控制中心 * 。一种基于 GUI 的系统，用于管理和监控 Kafka 。您可以通过它轻松管理 Kafka Connect ，以及创建，编辑和管理与其他系统的连接。</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">* Kubernetes 的 Confluent 。 * Kubernetes 的 Confluent 是 Kubernetes 的操作员。Kubernetes 操作员通过为特定平台应用程序提供独特的功能和要求，扩展了 Kubernetes 的业务流程功能。对于 Confluent Platform ，这包括大幅简化 Kubernetes 上 Kafka 的部署流程，并自动执行典型的基础架构生命周期任务。</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">* 连接 Kafka 的流畅连接器。 * 连接器使用 Kafka Connect API 将 Kafka 连接到数据库，密钥值存储，搜索索引和文件系统等其他系统。Confluent Hub 提供可下载的连接器，用于最常用的数据源和数据池，包括这些连接器经过全面测试且受支持的版本以及 Confluent 平台。有关更多详细信息，请参见<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>。</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">* 自平衡集群。 * 提供自动化负载平衡，故障检测和自我修复功能。它支持根据需要添加或停用代理，无需手动调整。</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">* 流畅集群链接。 * 直接将集群连接在一起，并通过链路网桥将主题从一个集群镜像到另一个集群。集群链接可简化多数据中心，多集群和混合云部署的设置。</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">* 流畅自动数据平衡器。 * 监控集群中的代理数量，分区大小，分区数量和导数。它允许您在集群中移动数据以创建均匀的工作负载，同时限制重新平衡流量，以便在重新平衡的同时最大限度地减少对生产工作负载的影响。</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">* 流畅复制器。 * 使在多个数据中心维护多个 Kafka 集群变得比以往任何时候都更轻松。</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">* 分层存储。 * 提供了使用您喜欢的云提供商存储大量 Kafka 数据的选项，从而减轻了运营负担并降低了成本。借助分层存储，您只能在需要更多计算资源时，才可以将数据保存在经济高效的对象存储和扩展代理上。</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">* 流畅的 jms 客户端。 * 流畅平台包括适用于 Kafka 的与 jms 兼容的客户端。此 Kafka 客户端使用 Kafka 代理作为后端，实施了 Jms 1.1 标准 API 。如果旧版应用程序使用的是 jms ，并且您希望将现有的 jms 消息代理替换为 Kafka ，则此功能非常有用。</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">* 流畅的 MQT 代理。 * 提供了一种从 MQT 设备和网关直接向 Kafka 发布数据的方法，而无需在中间使用 MQT 代理。</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">* 流畅安全插件。 * 流畅安全插件用于为各种流畅平台工具和产品添加安全功能。目前，可以为 Confluent REST 代理提供一个插件，用于对传入请求进行身份验证，并将经过身份验证的主体传播到 Kafka 请求。这样， Confluent REST 代理客户端便可利用 Kafka 代理的多租户安全功能。</block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">本文档介绍在 NetApp 存储控制器上使用 Kafka 的最佳实践准则。</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="doc">TR-4912 ：《采用 NetApp 的 Confluent Kafka 分层存储最佳实践指南》</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">我们已通过与 Kafka 的 Confluent Platform 的 NetApp StorageGRID 分层存储认证。</block>
  <block id="82dc8b1c8f1a6f08261f17b764e74bf4" category="paragraph"><block ref="82dc8b1c8f1a6f08261f17b764e74bf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">融合的分层存储配置</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">分层存储配置在 Kafka 中需要以下参数：</block>
  <block id="1ba0fc45020f864c62328d58df2351ef" category="paragraph"><block ref="1ba0fc45020f864c62328d58df2351ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">对象存储正确性测试</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">分层功能正确性测试</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">层提取基准测试</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">此测试验证了分层对象存储的读取性能，并检查了基准测试生成的区块在负载过重时的范围提取读取请求。在此基准测试中， Confluent 开发了自定义客户端来处理层提取请求。</block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">本文档提供了将 Kafka 与 NetApp 存储结合使用的最佳实践准则，包括 Confluent Kafka 认证测试，性能结果，调整， Kafka 连接器和自重新平衡功能。</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">什么是 Apache Kafka</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">S3-sink 参数详细信息</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">此测试基于自平衡集群功能，此功能可根据集群拓扑变化或负载不平衡自动重新平衡。</block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">本节将介绍从此认证中获得的经验教训。</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">最佳实践准则</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">当 seg.bytes 较高时，对象存储可提供更好的性能；我们测试了 512 MB 。</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">在 Kafka 中，为主题生成的每个记录的密钥或值的长度（以字节为单位）由 `lage.key.value` 参数控制。对于 StorageGRID ， S3 对象载入和检索性能已提高到更高值。例如， 512 字节提供了 5.8 GBps 检索， 1024 字节提供了 7.5 GBps S3 检索， 2048 字节提供了接近 10 Gbps 的值。</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">下图显示了基于 `length 。 key.value` 的 S3 对象载入和检索。</block>
  <block id="b50ee24368ac624f2816b9e550167cb9" category="paragraph"><block ref="b50ee24368ac624f2816b9e550167cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">本节介绍用于 Confluent 认证的硬件和软件。此信息适用于使用 NetApp 存储的 Kafka 部署。</block>
  <block id="f4e981d58b1468737da82402b3cce7f1" category="paragraph"><block ref="f4e981d58b1468737da82402b3cce7f1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="section-title">解决方案架构详细信息</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka 6.2 版</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">三个 Zookepers</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">五个代理服务器</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">一个 Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">一个控制中心</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux （ Ubuntu 18.04 ）</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">所有服务器</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 个 SG1000 （负载平衡器）</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 个 24 x 800 SSD</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">S3 协议</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15 台 Fujitsu PRIMERGY RX2540 服务器</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">每个均配备： * 2 个 CPU ，总共 16 个物理核心 * Intel Xeon * 256 GB 物理内存 * 100GbE 双端口</block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">在此设置中，我们将向您展示如何使用 Kafka S3 接收器连接器直接从 Kafka 读取和写入对象存储中的主题。在此测试中，我们使用了独立的 Consfluent 集群，但此设置适用于分布式集群。</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">从 Confluent 网站下载 Confluent Kafka 。</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">将软件包解压缩到服务器上的文件夹。</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">导出两个变量。</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">对于独立的 Confluent Kafka 设置，集群会在 ` /tmp` 中创建一个临时根文件夹。它还会创建 Zookeeper ， Kafka ，模式注册表， connect ， ksql-server ， 和控制中心文件夹，并从 ` $confuent_home` 复制其各自的配置文件。请参见以下示例：</block>
  <block id="fc1644d2d2819b87443b810d963409fa" category="list-text">配置 Zookeeper 。如果使用默认参数，则无需更改任何内容。</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">在上述配置中，我们更新了 `s服务器。xxx` 属性。默认情况下，您需要三个 zookepers 来选择 Kafka 领导者。</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">我们在 ` /tmp/confuent.406980/zookeeper /data` 中创建了一个 myid 文件，其唯一 ID 为：</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">我们使用 myid 文件的最后一个 IP 地址数。我们使用了 Kafka ， connect ， control-center ， Kafka ， Kafka-REST ， ksql-server 和模式注册表配置。</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">启动 Kafka 服务。</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">每个配置都有一个日志文件夹，可帮助您解决问题。在某些情况下，服务需要较长时间才能启动。确保所有服务均已启动且正在运行。</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">使用 `Confluent-hub` 安装 Kafka 连接。</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">您也可以使用 `Confluent-hub install conflientint/Kafka-connect-S3 ： 10.0.3` 来安装特定版本。</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">默认情况下， `confuentine-Kafka-connect-S3` 安装在 ` /data/confuent/confuent-6.2.0/share/confuent-hub-components/confuentine-Kafka-connect-S3` 中。</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">使用新的 `Confluentine-Kafka-connect-S3` 更新插件路径。</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">停止并重新启动 Consfluent 服务。</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">在 ` /root/.AWS/credentials` 文件中配置访问 ID 和机密密钥。</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">验证存储分段是否可访问。</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">为 S3 和存储分段配置 S3-sink 属性文件。</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">将一些记录导入到 S3 存储分段中。</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">加载 S3-sink 连接器。</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">检查 S3-sink 状态。</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">检查日志以确保 S3-sink 已准备好接受主题。</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">查看 Kafka 中的主题。</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">检查 S3 存储分段中的对象。</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">要验证内容，请运行以下命令将每个文件从 S3 复制到本地文件系统：</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Apache 归档</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">要打印记录，请使用 avro-tools-1.11.0.1.jar （可在中找到<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block>）。</block>
  <block id="9f4b95975f14f6481a322f453e05049c" category="sidebar">适用于 VMware vSphere 的 ONTAP 工具—产品安全</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Confluent Kafka 的最佳实践</block>
  <block id="4177c39712dda5976b0ba657b24af234" category="doc">在 Google Cloud 中部署 Cloud Volumes ONTAP （自行部署）</block>
  <block id="2839d8571363b149cc3fd9db82a7183d" category="paragraph">可以从在 GCVE 私有云环境中创建的 VM 挂载 Cloud Volumes ONTAP 共享和 LUN 。这些卷还可以挂载到 Linux 客户端和 Windows 客户端上，并且在通过 iSCSI 挂载时，可以在 Linux 或 Windows 客户端上以块设备的形式访问 LUN ，因为 Cloud Volumes ONTAP 支持 iSCSI ， SMB 和 NFS 协议。只需几个简单的步骤即可设置 Cloud Volumes ONTAP 卷。</block>
  <block id="3b020916a45973167bc70cb4517bd8c8" category="inline-link-macro">在系统之间设置数据复制</block>
  <block id="83f1904115d07e05de148ff5c69277db" category="paragraph">要将卷从内部环境复制到云以实现灾难恢复或迁移，请使用站点到站点 VPN 或云互连建立与 Google Cloud 的网络连接。将数据从内部复制到 Cloud Volumes ONTAP 不在本文档的讨论范围之内。要在内部系统和 Cloud Volumes ONTAP 系统之间复制数据，请参见 <block ref="17b5522e2d467cfa8e1eed2f77bb1eff" category="inline-link-macro-rx"></block>。</block>
  <block id="9eb931a836eecf8e743b47b449c70bc5" category="inline-link-macro">Cloud Volumes ONTAP 规模估算工具</block>
  <block id="165fc07e6910d8748be18ecaaab5392d" category="admonition">使用 ... <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> 以准确估算 Cloud Volumes ONTAP 实例的大小。此外，还可以监控内部性能，以用作 Cloud Volumes ONTAP 规模估算器中的输入。</block>
  <block id="a1d02afc571062ee1235156b645846f8" category="list-text">登录到 NetApp Cloud Central —此时将显示 Fabric View 屏幕。找到 Cloud Volumes ONTAP 选项卡，然后选择转到 Cloud Manager 。登录后，将显示 " 画布 " 屏幕。</block>
  <block id="52111b7d24cc23248fa9cf8138732943" category="paragraph"><block ref="52111b7d24cc23248fa9cf8138732943" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67b4a468763f61993484edb54b0d5eaa" category="list-text">在 Cloud Manager 的 " 画布 " 选项卡上，单击添加工作环境，然后选择 Google Cloud Platform 作为云以及系统配置的类型。然后，单击下一步。</block>
  <block id="da94c5003e26421e5282adb2dc7794bf" category="paragraph"><block ref="da94c5003e26421e5282adb2dc7794bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="956a76d4c71f02e39d36ada071ba66ca" category="list-text">提供要创建的环境的详细信息，包括环境名称和管理员凭据。完成后，单击 Continue 。</block>
  <block id="786bd072b9aad97a5bb9b71b8988a176" category="paragraph"><block ref="786bd072b9aad97a5bb9b71b8988a176" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f716cee2acaef077786ecfa7a3f8bfe7" category="list-text">选择或取消选择 Cloud Volumes ONTAP 部署的附加服务，包括数据感知与合规性或备份到云。然后，单击 Continue 。</block>
  <block id="03e0c2afea8f7c3aff4a53d66784f843" category="paragraph">提示：停用附加服务时，将显示验证弹出消息。可以在部署 CVO 后添加 / 删除附加服务，如果不需要，请考虑从一开始就取消选择这些附加服务，以避免成本。</block>
  <block id="d784fbb10e1bdb60322e86126fe6b77a" category="paragraph"><block ref="d784fbb10e1bdb60322e86126fe6b77a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faa5bffdcdb67efcb08e91a60de40950" category="list-text">选择一个位置，选择一个防火墙策略，然后选中此复选框以确认与 Google Cloud 存储的网络连接。</block>
  <block id="5eb45a43e8f46d401f435ef2b77fc946" category="paragraph"><block ref="5eb45a43e8f46d401f435ef2b77fc946" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f73472fc9b5e80548aa8910eb7b409d7" category="list-text">选择许可证选项：按需购买或自带许可证以使用现有许可证。在此示例中，使用了 freemium 选项。然后，单击 Continue 。</block>
  <block id="ef8c5ea172d5c008d091f693a2a4b4bd" category="paragraph"><block ref="ef8c5ea172d5c008d091f693a2a4b4bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e3f0304199574fcad7150c8cbc80cf" category="list-text">根据要部署在 AWS SDDC 上的 VMware 云上运行的 VM 上的工作负载类型，在多个预配置的软件包之间进行选择。</block>
  <block id="1cd93d1b6baa56bdec898225ef3fea89" category="paragraph">提示：将鼠标悬停在图块上可查看详细信息，或者单击更改配置来自定义 CVO 组件和 ONTAP 版本。</block>
  <block id="7498ab388fb0a7938d43af30f32657b5" category="paragraph"><block ref="7498ab388fb0a7938d43af30f32657b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="623ce055c6e7272198e998744efd8deb" category="list-text">在审核和批准页面上，查看并确认所做的选择。要创建 Cloud Volumes ONTAP 实例，请单击执行。</block>
  <block id="fcf4e1533222260897c2613078eae18e" category="paragraph"><block ref="fcf4e1533222260897c2613078eae18e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b8217eede1f57c19d7d36c1501891b" category="list-text">配置 Cloud Volumes ONTAP 后，它将在 " 画布 " 页面的工作环境中列出。</block>
  <block id="37030c826a75013cff1396c6351d33c0" category="paragraph"><block ref="37030c826a75013cff1396c6351d33c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="962c53cd54b0b3876e054c2fea4c4ff8" category="section-title">SMB 卷的其他配置</block>
  <block id="9af22b589cfa398b9a704f786d96a90d" category="list-text">准备好工作环境后，请确保为 CIFS 服务器配置了适当的 DNS 和 Active Directory 配置参数。要创建 SMB 卷，必须执行此步骤。</block>
  <block id="8f10b252acc74e058dc00a78e8c33250" category="paragraph">提示：单击菜单图标（ º ），选择高级以显示更多选项，然后选择 CIFS 设置。</block>
  <block id="0cd857f422db3bb835695ca4400e7afb" category="paragraph"><block ref="0cd857f422db3bb835695ca4400e7afb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c2efcf3ec5fbe68c5a418d6b0d5ed94" category="list-text">创建 SMB 卷的过程非常简单。在 " 画布 " 中，双击 Cloud Volumes ONTAP 工作环境以创建和管理卷，然后单击创建卷选项。选择适当的大小， Cloud Manager 选择包含的聚合或使用高级分配机制将其放置在特定聚合上。在此演示中，选择 CIFS/SMB 作为协议。</block>
  <block id="597899b3d186b1c50739aeb0a82a2094" category="paragraph"><block ref="597899b3d186b1c50739aeb0a82a2094" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e1a14aa082ec04534624b099e0a4bd9" category="list-text">配置卷后，卷将显示在卷窗格下。由于已配置 CIFS 共享，因此请为用户或组授予对文件和文件夹的权限，并验证这些用户是否可以访问此共享并创建文件。如果从内部环境复制卷，则不需要执行此步骤，因为文件和文件夹权限均会在 SnapMirror 复制过程中保留。</block>
  <block id="4cdd5a747f01838b94117ef6fb699278" category="paragraph">提示：单击卷菜单（ º ）可显示其选项。</block>
  <block id="368cd84bdda136cebde14eea38e8a0f2" category="paragraph"><block ref="368cd84bdda136cebde14eea38e8a0f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7a0ccac4888fc1553dadeee03d7e99" category="list-text">创建卷后，使用 mount 命令显示卷连接说明，然后从 Google Cloud VMware Engine 上的 VM 连接到共享。</block>
  <block id="92890420fd7a7668e3b04db90e8a2ff2" category="paragraph"><block ref="92890420fd7a7668e3b04db90e8a2ff2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5ee926d870d7b6e5ee68e0001a9db42" category="list-text">复制以下路径并使用映射网络驱动器选项将卷挂载到 Google Cloud VMware 引擎上运行的虚拟机上。</block>
  <block id="809f33612149b405423b98b77a13d18f" category="paragraph"><block ref="809f33612149b405423b98b77a13d18f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0895b43b6a4f7ded9ce501e420da7cae" category="paragraph">映射后，可以轻松访问该文件，并相应地设置 NTFS 权限。</block>
  <block id="2565b7a7d81a362c6b3fc5f32d83075b" category="paragraph"><block ref="2565b7a7d81a362c6b3fc5f32d83075b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="262a1d892164ab4100a969a952274934" category="section-title">将 Cloud Volumes ONTAP 上的 LUN 连接到主机</block>
  <block id="049f63d3d6479b8801f942e53b31cfd6" category="paragraph">要将 Cloud Volumes ONTAP LUN 连接到主机，请完成以下步骤：</block>
  <block id="2fc81fae057994bbe703cb2892b727c9" category="list-text">在 " 画布 " 页面上，双击 Cloud Volumes ONTAP 工作环境以创建和管理卷。</block>
  <block id="3a596dcd3d3dd43ed187aea6bea5842e" category="list-text">单击 "Add Volume" （添加卷） &gt;"New Volume" （新卷），然后选择 "iSCSI" ，然后单击 "Create Initiator Group" （单击 Continue （继续）。</block>
  <block id="b5f2af2dc909b8d634ef7e8dd729c0bc" category="paragraph"><block ref="99dce170472373a603dcc6cab1306eea" category="inline-image-macro-rx" type="image"></block>
<block ref="99eed8d2ce50ff339d9bff41a9fe9a51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4296bb5afd2416d05f951e9d3380e5e4" category="list-text">配置卷后，选择卷菜单（ º ），然后单击目标 IQN 。要复制 iSCSI 限定名称（ IQN ），请单击复制。设置从主机到 LUN 的 iSCSI 连接。</block>
  <block id="5bbe705670fa05ddb0b508acf301a379" category="paragraph">要对驻留在 Google Cloud VMware Engine 上的主机执行相同操作，请执行以下操作：</block>
  <block id="a730e43d2afac8730f77c3fab06bcdc0" category="list-text">RDP 到 Google Cloud VMware Engine 上托管的 VM 。</block>
  <block id="c4b994ff6c03cf45471392a32ff9809b" category="list-text">打开 iSCSI 启动程序属性对话框：服务器管理器 &gt; 信息板 &gt; 工具 &gt; iSCSI 启动程序。</block>
  <block id="beacd9a0aebca77f6cc20d5cab0fb37c" category="list-text">在发现选项卡中，单击发现门户或添加门户，然后输入 iSCSI 目标端口的 IP 地址。</block>
  <block id="c4ab0fc2a07f004fb45eacc91a07e22c" category="list-text">从目标选项卡中，选择已发现的目标，然后单击登录或连接。</block>
  <block id="4f04cc11e470becd190503a4cea0e217" category="list-text">选择启用多路径，然后选择计算机启动时自动还原此连接或将此连接添加到收藏目标列表。单击高级。</block>
  <block id="ed010f49a5a1ad0895131daffcd73a3c" category="admonition">Windows 主机必须与集群中的每个节点建立 iSCSI 连接。原生 DSM 会选择要使用的最佳路径。</block>
  <block id="88c7456aa49f0bfe0258958c4c42a153" category="paragraph"><block ref="88c7456aa49f0bfe0258958c4c42a153" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f2340e83f93b283dd5fc7023e4e72a2" category="paragraph">Storage Virtual Machine （ SVM ）上的 LUN 在 Windows 主机中显示为磁盘。主机不会自动发现添加的任何新磁盘。通过完成以下步骤触发手动重新扫描以发现磁盘：</block>
  <block id="d16c566049378cf49448803dfc6ab25d" category="list-text">打开 Windows 计算机管理实用程序：开始 &gt; 管理工具 &gt; 计算机管理。</block>
  <block id="b1babb2780a260f54d7e9f21602773df" category="list-text">在导航树中展开存储节点。</block>
  <block id="678149d88ae91abbb05c5df448a4e8af" category="list-text">单击磁盘管理。</block>
  <block id="35e2e6c4175353900be410088efcc1b9" category="list-text">单击操作 &gt; 重新扫描磁盘。</block>
  <block id="da663e5eac7f594bcac6564a22726142" category="paragraph"><block ref="da663e5eac7f594bcac6564a22726142" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8a056111a10f9e055d309c54e7ca2bb" category="paragraph">当新 LUN 首次由 Windows 主机访问时，它没有分区或文件系统。初始化 LUN ；也可以通过完成以下步骤使用文件系统格式化 LUN ：</block>
  <block id="8db13bd6122ee1a2b04931073cb808d7" category="list-text">启动 Windows 磁盘管理。</block>
  <block id="18e601e3f0e159e918f7adb9fd89fb99" category="list-text">右键单击 LUN ，然后选择所需的磁盘或分区类型。</block>
  <block id="605158a22ab35f7223fe6f37b0f761b7" category="list-text">按照向导中的说明进行操作。在此示例中，驱动器 F ：已挂载。</block>
  <block id="74edf50412d8a6c920ebdf456ca74d6f" category="paragraph"><block ref="74edf50412d8a6c920ebdf456ca74d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8bce76f68494174fa21e44b39be75e7" category="paragraph">在 Linux 客户端上，确保 iSCSI 守护进程正在运行。配置 LUN 后，请参见有关使用 Ubuntu 进行 iSCSI 配置的详细指南，作为示例。要进行验证，请从 shell 运行 lsblk cmd 。</block>
  <block id="5800551032817b82a3780efc5c365b61" category="paragraph"><block ref="5d8610d622621cfaf5f5af9098efada8" category="inline-image-macro-rx" type="image"></block>
<block ref="0e5aea74b7dab4389459e8f03d7961e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b88883556cc41d9ed2a47bd0cfe1bb4" category="section-title">在 Linux 客户端上挂载 Cloud Volumes ONTAP NFS 卷</block>
  <block id="3a676f5d05c6d1f36341948d03289c3f" category="paragraph">要从 Google Cloud VMware 引擎中的 VM 挂载 Cloud Volumes ONTAP （ DIY ）文件系统，请执行以下步骤：</block>
  <block id="99ff74a348250b7148d219f224bc40b4" category="paragraph">按照以下步骤配置卷</block>
  <block id="17d1d28660c0ff68f1ee26c3bc7c2e0d" category="list-text">在 Volumes （卷）选项卡中，单击 Create New Volume （创建新卷）。</block>
  <block id="6fa266ccf8c1f303a7ed67b355770afb" category="list-text">在 "Create New Volume" 页面上，选择卷类型：</block>
  <block id="8d7c2959a73ccf424e912497fa729dfa" category="paragraph"><block ref="8d7c2959a73ccf424e912497fa729dfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e89e2106ea79d032d48e99a6498e2584" category="list-text">在卷选项卡中，将鼠标光标置于卷上方，选择菜单图标（ º ），然后单击挂载命令。</block>
  <block id="1367b1db6f5a641c16b673b4f75f02de" category="paragraph"><block ref="1367b1db6f5a641c16b673b4f75f02de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8a4175c7cb7e059193f8bdcafc1395b0" category="list-text">单击复制。</block>
  <block id="e059ff9407d5207f003eae103b4c7a3a" category="list-text">连接到指定的 Linux 实例。</block>
  <block id="b3bcde31f03d76e154f81e6b5221b007" category="list-text">使用安全 Shell （ SSH ）在实例上打开一个终端，并使用相应的凭据登录。</block>
  <block id="42d35ecc4606c7783372ab3953fb10d6" category="list-text">使用以下命令为卷的挂载点创建一个目录。</block>
  <block id="2432c695bbc97e5283e213ba846e86dc" category="paragraph"><block ref="2432c695bbc97e5283e213ba846e86dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5cbcad6705273d58a27b5b92fdc1700" category="list-text">将 Cloud Volumes ONTAP NFS 卷挂载到上一步创建的目录。</block>
  <block id="f505f299a6f5e1e9f6b91adec6ef8f38" category="paragraph"><block ref="4aa22d1032194bb618fa2b2a8bbc5d82" category="inline-image-macro-rx" type="image"></block>
<block ref="73581b61100d82e506cc05faa5fc45c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f43b203ec7020e7ea0e408d9d67255fc" category="doc">使用 Azure VMware 解决方案（ AVS ）配置 Azure NetApp Files</block>
  <block id="f9a184882060f3e5a8b6045e2a53107f" category="paragraph">可以从 Azure VMware 解决方案 SDDC 环境中创建的虚拟机挂载 Azure NetApp Files 共享。由于 Azure NetApp Files 支持 SMB 和 NFS 协议，因此这些卷也可以挂载到 Linux 客户端并映射到 Windows 客户端。只需五个简单步骤即可设置 Azure NetApp Files 卷。</block>
  <block id="5bb6f16c69df9b9f54bddaaa5e32b415" category="paragraph">Azure NetApp Files 和 Azure VMware 解决方案必须位于同一 Azure 区域。</block>
  <block id="8c8b1c25fd4bcb4102a3a834f721ec3e" category="section-title">创建并挂载 Azure NetApp Files 卷</block>
  <block id="763b2af90e10e00124392e31d5792be5" category="paragraph">要创建和挂载 Azure NetApp Files 卷，请完成以下步骤：</block>
  <block id="e56fb44cec3cde26b63f919055458c3a" category="list-text">登录到 Azure 门户并访问 Azure NetApp Files 。使用 _az provider register -namespace Microsoft.NetApp – wait 命令验证对 Azure NetApp Files 服务的访问并注册 Azure NetApp Files 资源提供程序。注册完成后，创建一个 NetApp 帐户。</block>
  <block id="792c2610bbb56b5803bae91a54f34f51" category="inline-link-macro">Azure NetApp Files 共享</block>
  <block id="a7ad1b2194256789e815facefa65206d" category="paragraph">有关详细步骤，请参见 <block ref="8dd8f38a60f74263b1cf35e18285061e" category="inline-link-macro-rx"></block>。此页面将引导您逐步完成此过程。</block>
  <block id="710954ec785b2a7f67c2ef1c3f2f9d19" category="paragraph"><block ref="710954ec785b2a7f67c2ef1c3f2f9d19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe57bd1c78e967b463574e3089a42968" category="list-text">创建 NetApp 帐户后，使用所需的服务级别和大小设置容量池。</block>
  <block id="3928a91ce2a9b26c809bec745d6b9daf" category="paragraph">有关详细信息，请参见 <block ref="e7281cc99a6c9a39d5a16325a46f1f7c" category="inline-link-macro-rx"></block>。</block>
  <block id="7ffd44a691267afdf7cc1178ab6115f8" category="paragraph"><block ref="7ffd44a691267afdf7cc1178ab6115f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42e9b5ee697da49886fd18e89e6ab1af" category="inline-link-macro">Delegate a subnet to Azure NetApp Files</block>
  <block id="ee13d45546639cd210b35ce3665b6885" category="list-text">为 Azure NetApp Files 配置委派子网，并在创建卷时指定此子网。有关创建委派子网的详细步骤，请参见 <block ref="ad52de6b143679c946d36f9e4248f40c" category="inline-link-macro-rx"></block>。</block>
  <block id="70a08a2f18d96817bf63302571e62634" category="paragraph"><block ref="70a08a2f18d96817bf63302571e62634" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96501b128e8ffab4b107cd6ffa7da649" category="list-text">使用容量池刀片下的卷刀片添加 SMB 卷。确保在创建 SMB 卷之前已配置 Active Directory 连接器。</block>
  <block id="f676bcdffa60a69ff49ba9ffdbb2b912" category="paragraph"><block ref="f676bcdffa60a69ff49ba9ffdbb2b912" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9095b4995e678294045e2a1501d1db3" category="list-text">单击查看 + 创建以创建 SMB 卷。</block>
  <block id="e48925dc65abf32faa19c5d430cf6d6d" category="paragraph">如果应用程序是 SQL Server ，则启用 SMB 持续可用性。</block>
  <block id="be1613efbff068fd23ee511fe4e6dc51" category="paragraph"><block ref="be1613efbff068fd23ee511fe4e6dc51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2b999c81e324f553ec9720c334325ee" category="paragraph"><block ref="b2b999c81e324f553ec9720c334325ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe5eed95829ff2b525461ee72a9f3f23" category="inline-link-macro">Azure NetApp Files 的性能注意事项</block>
  <block id="2c5ce17dd48f2551465b828065fd8300" category="paragraph">要了解有关按大小或配额显示的 Azure NetApp Files 卷性能的详细信息，请参见 <block ref="ffec162f488d413e68dfe18d328e177e" category="inline-link-macro-rx"></block>。</block>
  <block id="bef7cec065f33ededdd1b50d74800b72" category="list-text">建立连接后，可以挂载此卷并将其用于应用程序数据。</block>
  <block id="8b3c17098d0d024937d60849b3bd8edb" category="paragraph">要完成此操作，请从 Azure 门户中单击卷刀片，然后选择要挂载的卷并访问挂载说明。复制路径并使用映射网络驱动器选项将卷挂载到 Azure VMware 解决方案 SDDC 上运行的虚拟机上。</block>
  <block id="413fcfe1d831f95cd95f8f3bb9030eec" category="paragraph"><block ref="413fcfe1d831f95cd95f8f3bb9030eec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e50c675280580c3249f58f2f3eefdb86" category="paragraph"><block ref="e50c675280580c3249f58f2f3eefdb86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13c8bc9575bbdc3a8a30021320abbd69" category="list-text">要在 Azure VMware 解决方案 SDDC 上运行的 Linux VM 上挂载 NFS 卷，请使用相同的过程。使用卷重新调整或动态服务级别功能来满足工作负载需求。</block>
  <block id="ff817c6ff423e680ddf0a8398efdfb5a" category="paragraph"><block ref="ff817c6ff423e680ddf0a8398efdfb5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da94ac228f6efdf07fe7e43b1441faf2" category="paragraph">有关详细信息，请参见 <block ref="ea07f7f3cbdf3d62072fbe16546616d3" category="inline-link-macro-rx"></block>。</block>
  <block id="29f8b77f5f7c79b566706e0d55c9de8b" category="doc">适用于 Amazon VMware Managed Cloud （ VMC ）的 NetApp 解决方案</block>
  <block id="7e0686a26bc7a91429819c2aeb7b414a" category="doc">适用于 Azure VMware 解决方案的 NetApp 解决方案（ AVS ）</block>
  <block id="4859596b2360db2dac4c6a687efe10d2" category="doc">在 AWS 中部署新的 Cloud Volumes ONTAP 实例（自行操作）</block>
  <block id="ddf355809a57f794eb4f9cff41a1ad86" category="paragraph">可以从 AWS SDDC 环境中的 VMware 云中创建的 VM 挂载 Cloud Volumes ONTAP 共享和 LUN 。这些卷还可以挂载在原生 AWS VM Linux Windows 客户端上，并且在通过 iSCSI 挂载时，可以在 Linux 或 Windows 客户端上以块设备的形式访问 LUN ，因为 Cloud Volumes ONTAP 支持 iSCSI ， SMB 和 NFS 协议。只需几个简单的步骤即可设置 Cloud Volumes ONTAP 卷。</block>
  <block id="091112e3dbffea1fef77b4b6bbcec4d3" category="paragraph">要将卷从内部环境复制到云以实现灾难恢复或迁移，请使用站点到站点 VPN 或 DirectConnect 与 AWS 建立网络连接。将数据从内部复制到 Cloud Volumes ONTAP 不在本文档的讨论范围之内。要在内部系统和 Cloud Volumes ONTAP 系统之间复制数据，请参见 <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>。</block>
  <block id="c4fab68ae07564acd6ecd9b911dfff79" category="admonition">使用 <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> 以准确估算 Cloud Volumes ONTAP 实例的大小。此外，还可以监控内部性能，以用作 Cloud Volumes ONTAP 规模估算器中的输入。</block>
  <block id="44ca838e7d04a1071dc78602ef005cb3" category="list-text">登录到 NetApp Cloud Central ；此时将显示 Fabric View 屏幕。找到 Cloud Volumes ONTAP 选项卡，然后选择转到 Cloud Manager 。登录后，将显示 " 画布 " 屏幕。</block>
  <block id="6b0e3e8cb8d190a2310f526f49f7908f" category="paragraph"><block ref="6b0e3e8cb8d190a2310f526f49f7908f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="613b8a42b8ee051cdae0288a52604a55" category="list-text">在 Cloud Manager 主页上，单击添加工作环境，然后选择 AWS 作为云以及系统配置的类型。</block>
  <block id="1ce9ef4a253b6301539d9cab4fca67b6" category="paragraph"><block ref="1ce9ef4a253b6301539d9cab4fca67b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1552a04c8237c4a2d938cca2db53683" category="list-text">提供要创建的环境的详细信息，包括环境名称和管理员凭据。单击 Continue （继续）。</block>
  <block id="525c0dbff313821edbeaa46a9b5d88dd" category="paragraph"><block ref="525c0dbff313821edbeaa46a9b5d88dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7191330ca38db1397356e7619c4baf63" category="paragraph"><block ref="7191330ca38db1397356e7619c4baf63" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5908a77615c1d6294f872ff6f0e9ec5c" category="list-text">在 HA 部署模式页面上，选择多个可用性区域配置。</block>
  <block id="e2dff93e99a18f3bbf601965a86556d3" category="paragraph"><block ref="e2dff93e99a18f3bbf601965a86556d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5eee77262911549d8a2fd262ee2a983d" category="list-text">在区域和 VPC 页面上，输入网络信息，然后单击继续。</block>
  <block id="94a6592c275cad51dc739b4ab70338db" category="paragraph"><block ref="94a6592c275cad51dc739b4ab70338db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6f20610782706f69940c617f7154ffe" category="list-text">在“ Connectivity and SSH Authentication ”（连接和 SSH 身份验证）页上、为 HA 对和调解器选择连接方法。</block>
  <block id="d121b588f00dfd906d6291024c708f8d" category="paragraph"><block ref="d121b588f00dfd906d6291024c708f8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a012735965bc67df3b6e4c64b7b894f" category="list-text">指定浮动 IP 地址，然后单击继续。</block>
  <block id="bc0e2f9513cce33557343a1867d4bdfb" category="paragraph"><block ref="bc0e2f9513cce33557343a1867d4bdfb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b2221e159f51173ae2b52e02587cc42" category="list-text">选择适当的路由表以包含指向浮动 IP 地址的路由，然后单击继续。</block>
  <block id="5486a792746fe5fbf546c327f6be2773" category="paragraph"><block ref="5486a792746fe5fbf546c327f6be2773" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e18f42f3f9ea4d4f2e8df33f334d9939" category="list-text">在数据加密页面上，选择 AWS 管理的加密。</block>
  <block id="143c5081e907e69e16f1df952eafae3e" category="paragraph"><block ref="143c5081e907e69e16f1df952eafae3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a25e3ac90ce2b5cc921531efdc5963e" category="list-text">选择许可证选项：按需购买或自带许可证以使用现有许可证。在此示例中，将使用按需购买选项。</block>
  <block id="e3750564d3942e5c1d3cec322e411d5e" category="paragraph"><block ref="e3750564d3942e5c1d3cec322e411d5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df531dd5efab87543ed07d56595eca08" category="list-text">根据要在 AWS SDDC 上的 VMware 云上运行的 VM 上部署的工作负载类型，在多个预配置的软件包之间进行选择。</block>
  <block id="30e80bd4d8d23ac64059627389a8b348" category="paragraph"><block ref="30e80bd4d8d23ac64059627389a8b348" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce4ab7c38fc244e8d1e30dd47a1c578d" category="paragraph"><block ref="ce4ab7c38fc244e8d1e30dd47a1c578d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc498db1b5b048e74d02bcfa90076dfe" category="paragraph"><block ref="bc498db1b5b048e74d02bcfa90076dfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8427c8fe11e3a00ca10a2cf45a96dd90" category="paragraph"><block ref="8427c8fe11e3a00ca10a2cf45a96dd90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31574a22471145d2a1ea069062aa95ec" category="list-text">选择要创建卷的 CVO 实例，然后单击创建卷选项。选择适当的大小， Cloud Manager 选择包含的聚合或使用高级分配机制将其放置在特定聚合上。在此演示中，选择 SMB 作为协议。</block>
  <block id="d657856abbf9bb39436a3f6f849251ea" category="paragraph"><block ref="d657856abbf9bb39436a3f6f849251ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="976543d01a4b5d38482c487005aadc68" category="list-text">配置卷后，此卷将显示在卷窗格下。由于已配置 CIFS 共享，因此您应向用户或组授予对文件和文件夹的权限，并验证这些用户是否可以访问此共享并创建文件。</block>
  <block id="eac2d4365044c30420d99e4450f5b3da" category="paragraph"><block ref="eac2d4365044c30420d99e4450f5b3da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ea4081e5d5395a0dd61744757f9abb9" category="list-text">创建卷后，使用 mount 命令从 AWS SDDC 主机中 VMware Cloud 上运行的虚拟机连接到共享。</block>
  <block id="7786302dcdbb8e27839c1d68acb8c3ba" category="list-text">复制以下路径并使用映射网络驱动器选项将卷挂载到 AWS SDDC 中 VMware Cloud 上运行的虚拟机上。</block>
  <block id="fff9636198d4c8106d5edeb1a72f789c" category="paragraph"><block ref="97606ae260ebd0d0acdf4aac70a2a0b5" category="inline-image-macro-rx" type="image"></block>
<block ref="b4382417b1dd50929cfd78b7e90bc2aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27c47ada1e7cb796a499ede048474b99" category="section-title">将 LUN 连接到主机</block>
  <block id="70ac69b194f074f8b2ce79ee769a0c96" category="paragraph">要将 Cloud Volumes ONTAP LUN 连接到主机，请完成以下步骤：</block>
  <block id="4a8c2e183609aa00cfce8401be26e193" category="list-text">在 Cloud Manager 的 " 画布 " 页面上，双击 Cloud Volumes ONTAP 工作环境以创建和管理卷。</block>
  <block id="298c5ecf2fc7c7ab04d3ff27df17c420" category="list-text">单击添加卷 &gt; 新建卷，选择 iSCSI ，然后单击创建启动程序组。单击 Continue （继续）。</block>
  <block id="a3f6544e066d08b352bdd873e84efd9f" category="paragraph"><block ref="d08d8d37d464a0090209067a27ccf9bf" category="inline-image-macro-rx" type="image"></block>
<block ref="dd9a8ac9d2dee64126f68f4ab9b10f3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6297ccc26d99397b36875f005bb1b800" category="list-text">配置卷后，选择卷，然后单击目标 IQN 。要复制 iSCSI 限定名称（ IQN ），请单击复制。设置从主机到 LUN 的 iSCSI 连接。</block>
  <block id="c5a9ec38aba893e2a0d701ba2f45a50e" category="paragraph">要对位于 AWS SDDC 上的 VMware Cloud 上的主机执行相同操作，请完成以下步骤：</block>
  <block id="2cbe60394fdca23a31c3a05a49aba035" category="list-text">RDP 到 AWS 上 VMware 云上托管的 VM 。</block>
  <block id="213e827694caf7236290f845284dcc05" category="list-text">从目标选项卡中，选择已发现的目标，然后单击登录或连接。</block>
  <block id="04d63507299c2b866ddad09b32b37fb3" category="list-text">选择启用多路径，然后选择计算机启动时自动还原此连接或将此连接添加到收藏目标列表。单击高级。</block>
  <block id="c11f54f9bd2797dc115ca9e98fb0116d" category="paragraph">SVM 中的 LUN 在 Windows 主机中显示为磁盘。主机不会自动发现添加的任何新磁盘。通过完成以下步骤触发手动重新扫描以发现磁盘：</block>
  <block id="733dc90ee8ecde5a3fe64fd837d0eec1" category="paragraph"><block ref="733dc90ee8ecde5a3fe64fd837d0eec1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b173d8aceed1850c1882fee5f7479d4" category="paragraph"><block ref="5b173d8aceed1850c1882fee5f7479d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1085f8441673a34397360c417066d18f" category="paragraph">在 Linux 客户端上，确保 iSCSI 守护进程正在运行。配置 LUN 后，请参阅有关适用于 Linux 分发版的 iSCSI 配置的详细指导。例如，可以找到 Ubuntu iSCSI 配置 <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>。要进行验证，请从 shell 运行 lsblk cmd 。</block>
  <block id="af16b968e0e3b3975cdcefb5cdd9858a" category="paragraph">要从 AWS SDDC 上 VMC 内的 VM 挂载 Cloud Volumes ONTAP （ DIY ）文件系统，请完成以下步骤：</block>
  <block id="9e770ba792bd4db694940294a77cccee" category="list-text">将适用于 NetApp ONTAP NFS 的 Amazon FSX 卷挂载到上一步创建的目录中。</block>
  <block id="2b9f5ac2397a7a0e82ca568de7f62512" category="paragraph"><block ref="c1b4b180fa34b46779c12a4e278fa487" category="inline-image-macro-rx" type="image"></block>
<block ref="cf487bf9f5a361811181e443893feb53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6120544c737d67dd31f47d101fe21a84" category="doc">在云提供商中配置虚拟化环境</block>
  <block id="f4f7adb7cbe18f2cdd82be75a52b0417" category="paragraph">此处详细介绍了如何在每个受支持的超大规模主机中配置虚拟化环境。</block>
  <block id="e647d88b9bd859d2c3e943c24b4fef00" category="paragraph">与内部部署一样，在 AWS 上规划 VMware Cloud 对于成功打造可随时投入生产的环境以创建 VM 和迁移至关重要。</block>
  <block id="162e9e1fd4657b8d9588a5ae8c8e6e66" category="paragraph">本节介绍如何在 AWS SDDC 上设置和管理 VMware Cloud ，并将其与连接 NetApp 存储的可用选项结合使用。</block>
  <block id="d6d7fade0a5d1cd7723c64125e595b08" category="paragraph">设置过程可细分为以下步骤：</block>
  <block id="389544cc8199f2ddd936397695d0dbe9" category="inline-link-macro">部署和配置适用于 AWS 的 VMware Cloud</block>
  <block id="b4f284d3b5bb40ee91901933b8f7ef5f" category="inline-link-macro">将 VMware Cloud 连接到 FSX ONTAP</block>
  <block id="00ce356ad004b72efc4b99389b52af63" category="paragraph">与内部部署一样，规划 Azure VMware 解决方案对于成功创建 VM 和迁移生产就绪环境至关重要。</block>
  <block id="491aa8f554f95207a4b7d47f89777e13" category="paragraph">本节介绍如何设置和管理 Azure VMware 解决方案并将其与连接 NetApp 存储的可用选项结合使用。</block>
  <block id="3d24cd3e433bf1992e011c9f92c3fab6" category="inline-link-macro">注册资源提供商并创建私有云</block>
  <block id="a1123889b6465e93a2209c2a0ca667ef" category="inline-link-macro">连接到新的或现有的 ExpressRoute 虚拟网络网关</block>
  <block id="ae1764c7cb70aed2d4548c424d7bf34a" category="inline-link-macro">验证网络连接并访问私有云</block>
  <block id="9883d049f97d69a9f2326d61585d8fbe" category="paragraph">与内部部署一样，规划 Google Cloud VMware Engine （ GCVE ）对于成功创建虚拟机和迁移可随时投入生产的环境至关重要。</block>
  <block id="6ad49d2b544134f2192d1612a572bdd6" category="paragraph">本节介绍如何设置和管理 GCVE ，并将其与连接 NetApp 存储的可用选项结合使用。</block>
  <block id="a74a86037d1564ce62843a1252f6ad37" category="admonition">来宾存储是将 Cloud Volumes ONTAP 和云卷服务连接到 GCVE 的唯一受支持方法。</block>
  <block id="11a31c6d83a723b3ea9c348c22e86238" category="inline-link-macro">部署和配置 GCVE</block>
  <block id="3e5cc29621d2619be0d7b1569da6909c" category="inline-link-macro">启用对 GCVE 的私有访问</block>
  <block id="4dab2f9796b0af6304d00e21e2b9dfb4" category="inline-link-macro">基于 AWS 的 VMware Cloud</block>
  <block id="02b412692a538ee9dc2534f0f9c73dc1" category="paragraph"><block ref="560d5b2cd40977bd7b77b31d7088f657" category="inline-link-macro-rx"></block> 为 AWS 生态系统中基于 VMware 的工作负载提供 Cloud 原生体验。每个 VMware 软件定义的数据中心（ SDDC ）均在 Amazon Virtual Private Cloud （ VPC ）中运行，并提供完整的 VMware 堆栈（包括 vCenter Server ）， NSX-T 软件定义的网络连接， vSAN 软件定义的存储以及一个或多个 ESXi 主机，这些主机可为您的工作负载提供计算和存储资源。</block>
  <block id="dc77b78f59a0c38a9a2e8927dc05e916" category="paragraph">本节介绍如何在 AWS 上设置和管理 VMware Cloud ，并将其与适用于 NetApp ONTAP 的 Amazon FSX 和 / 或在 AWS 上使用子系统内存储的 Cloud Volumes ONTAP 结合使用。</block>
  <block id="3712f34e1b7039d6d9bfb255ecc54445" category="paragraph">设置过程可分为三部分：</block>
  <block id="f54d8dbbc1cb20fd37a59a4563644ef8" category="inline-link-macro">Amazon Web Services 帐户</block>
  <block id="4ca1486cd3276884e41ad4b36080c10b" category="list-text">注册 <block ref="ab3390028f6599a1b73b747febbf672d" category="inline-link-macro-rx"></block>。</block>
  <block id="020e995219c3fad42714462fc9368253" category="inline-link-macro">我的 VMware</block>
  <block id="4f87cd22b54abb602d4264ede77c75fd" category="list-text">注册 <block ref="6fb1d438d7363efa930c55af527a6c23" category="inline-link-macro-rx"></block> 帐户。</block>
  <block id="252c0d3625c410f643362d13f1e35681" category="paragraph">您需要一个 AWS 帐户才能开始使用，前提是尚未创建一个 AWS 帐户。无论新的还是现有的，您都需要在帐户中拥有管理权限才能执行此操作步骤中的许多步骤。请参见此内容 <block ref="d01b332d778720bc2fe2a9a15e6ba01d" category="inline-link-macro-rx"></block> 有关 AWS 凭据的详细信息。</block>
  <block id="e1ed167660991d514f55d806a323f3b5" category="paragraph">要访问 VMware 的云产品组合（包括基于 AWS 的 VMware Cloud ），您需要 VMware 客户帐户或 My VMware 帐户。如果尚未创建 VMware 帐户，请创建此帐户 <block ref="aefb6f511cceca70505b3e5bf76155fe" category="inline-link-macro-rx"></block>。</block>
  <block id="60fa505f14fb504e941cbc61b74d644a" category="section-title">在 VMware Cloud 中配置 SDDC</block>
  <block id="6d931b72d8efc3fd87b7fdd5127cbba7" category="paragraph">配置 VMware 帐户并执行适当的规模估算后，部署软件定义的数据中心显然是使用 VMware Cloud on AWS 服务的下一步。要创建 SDDC ，请选择要托管它的 AWS 区域，为 SDDC 指定一个名称，并指定希望 SDDC 包含的 ESXi 主机数。如果您还没有 AWS 帐户，则仍可以创建一个包含单个 ESXi 主机的入门级配置 SDDC 。</block>
  <block id="7e70ad389301fa9d8936c18cefd85b53" category="list-text">使用现有或新创建的 VMware 凭据登录到 VMware Cloud Console 。</block>
  <block id="28570a642842f2bfa7db5cc3679fd904" category="paragraph"><block ref="28570a642842f2bfa7db5cc3679fd904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53722f60844c899c63607413f74e8dd8" category="list-text">配置 AWS 区域，部署和主机类型以及 SDDC 名称：</block>
  <block id="5ec07ba481e6291d3af5e3ca61f27f57" category="paragraph"><block ref="5ec07ba481e6291d3af5e3ca61f27f57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5c464b97b208b8c43e9fdd315c80793" category="list-text">连接到所需的 AWS 帐户并执行 AWS Cloud Formation 堆栈。</block>
  <block id="b6822d593b3a1b683cb4e513b210c080" category="paragraph"><block ref="941b74b5e4d054f44fb05f89bfb30732" category="inline-image-macro-rx" type="image"></block>
<block ref="5ca301c5ba248bc9f9566d74470fcc6b" category="inline-image-macro-rx" type="image"></block>
<block ref="54108005ae53e37fa06b081374d6ea43" category="inline-image-macro-rx" type="image"></block>
<block ref="9f7f4a317cf9d46aa6a2aa8f441279ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59e9afc055ce73e7e6154ea7609eec59" category="admonition">此验证使用单主机配置。</block>
  <block id="3f68cef60baccc27cfef6b618e56f809" category="list-text">选择所需的 AWS VPC 以连接 VMC 环境。</block>
  <block id="49e131b27a342d4970e86a31a127d41c" category="paragraph"><block ref="49e131b27a342d4970e86a31a127d41c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="102a37b9412553c4ae6b25a174592fbb" category="list-text">配置 VMC 管理子网；此子网包含 vCenter ， NSX 等 VMC 管理的服务。请勿选择与任何其他需要连接到 SDDC 环境的网络重叠的地址空间。最后，请遵循下面标注的 CIDR 大小建议。</block>
  <block id="0e8db488f9554136a65dd18025db8cf0" category="paragraph"><block ref="0e8db488f9554136a65dd18025db8cf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a541610269aad8edaf8defd851246b08" category="list-text">查看并确认 SDDC 配置，然后单击 Deploy the SDDC 。</block>
  <block id="a8246981b8dc3e6123523500b3b1371d" category="paragraph"><block ref="a8246981b8dc3e6123523500b3b1371d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bb7bef7f28887197cfca7059ef2d6d3" category="paragraph">完成部署过程通常需要大约两个小时。</block>
  <block id="e9dcc1b6680c77f105c83d040009d685" category="paragraph"><block ref="e9dcc1b6680c77f105c83d040009d685" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79b6ae1d041f5cd8b33d3f351b301275" category="list-text">完成后， SDDC 即可使用。</block>
  <block id="9013490d3a116eed1c849197a6c8aac0" category="paragraph"><block ref="9013490d3a116eed1c849197a6c8aac0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e149dd16e33c6137fe08782e96c9b226" category="inline-link-macro">从 VMC 控制台部署 SDDC</block>
  <block id="086760513a416fbc6578703211523314" category="paragraph">有关 SDDC 部署的分步指南，请参见 <block ref="7279ebe13e8b8c4ee89b8961f2bf1157" category="inline-link-macro-rx"></block>。</block>
  <block id="1d583a1a8ff1ca8ae3360c7e33ecd984" category="doc">在 Azure 中部署新 Cloud Volumes ONTAP</block>
  <block id="ed1019c297fadb83e87437230788320c" category="paragraph">可以从 Azure VMware 解决方案 SDDC 环境中创建的 VM 挂载 Cloud Volumes ONTAP 共享和 LUN 。这些卷也可以挂载到 Linux 客户端和 Windows 客户端上，因为 Cloud Volumes ONTAP 支持 iSCSI ， SMB 和 NFS 协议。只需几个简单的步骤即可设置 Cloud Volumes ONTAP 卷。</block>
  <block id="e9cac40069a313b824541cda06c18a06" category="paragraph">要将卷从内部环境复制到云以实现灾难恢复或迁移，请使用站点到站点 VPN 或 ExpressRoute 与 Azure 建立网络连接。将数据从内部复制到 Cloud Volumes ONTAP 不在本文档的讨论范围之内。要在内部系统和 Cloud Volumes ONTAP 系统之间复制数据，请参见 <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>。</block>
  <block id="1563f27024f7b2b0a96be687f878206d" category="paragraph"><block ref="1563f27024f7b2b0a96be687f878206d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f067fbf4a3196796318f7e878eaa2a3" category="list-text">在 Cloud Manager 主页上，单击添加工作环境，然后选择 Microsoft Azure 作为云以及系统配置的类型。</block>
  <block id="e59c8066b7736d6ede98e2b57d619b60" category="paragraph"><block ref="e59c8066b7736d6ede98e2b57d619b60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21568dd1e2a5acafeee9d119cd012876" category="list-text">在创建第一个 Cloud Volumes ONTAP 工作环境时， Cloud Manager 会提示您部署连接器。</block>
  <block id="4c3665ca095a8a103c69fac1ac46fb59" category="paragraph"><block ref="4c3665ca095a8a103c69fac1ac46fb59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54ae357a0d5e74ebab86e52641490fc0" category="list-text">创建连接器后，更新详细信息和凭据字段。</block>
  <block id="9b971596a6ee599483fd04c84d2ce18d" category="paragraph"><block ref="9b971596a6ee599483fd04c84d2ce18d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf5341803b0061ef190495343f39fa02" category="list-text">提供要创建的环境的详细信息，包括环境名称和管理员凭据。为 Azure 环境添加资源组标记作为可选参数。完成后，单击 Continue 。</block>
  <block id="350a5c2219e5e14fd23dda8372344842" category="paragraph"><block ref="350a5c2219e5e14fd23dda8372344842" category="inline-image-macro-rx" type="image"></block></block>
  <block id="11728d9ffc9e6944adf4891d5543e154" category="paragraph"><block ref="11728d9ffc9e6944adf4891d5543e154" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ee060e03da823e605453fbfa27743d77" category="list-text">配置 Azure 位置和连接。选择要使用的 Azure 区域，资源组， vNet 和子网。</block>
  <block id="4549d76a3daf0d322686b6d4f6fb1490" category="paragraph"><block ref="4549d76a3daf0d322686b6d4f6fb1490" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1c88093dde70f0165ade30b74c908ad" category="list-text">选择许可证选项：按需购买或自带许可证以使用现有许可证。在此示例中，使用按需购买选项。</block>
  <block id="10085b1c84507f0da366d741a248d728" category="paragraph"><block ref="10085b1c84507f0da366d741a248d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2c782d387cdd1de07d0119c2794edc8" category="list-text">在可用于各种工作负载类型的多个预配置软件包之间进行选择。</block>
  <block id="942b902e3715b75e8e6257349bbe93ff" category="paragraph"><block ref="942b902e3715b75e8e6257349bbe93ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c7055bfbaac9b0236d0bedccfb616d0" category="list-text">接受有关激活 Azure 资源支持和分配的两个协议。要创建 Cloud Volumes ONTAP 实例，请单击 " 转到 " 。</block>
  <block id="c19dadb8117ac0d88e543accbb1c1096" category="paragraph"><block ref="c19dadb8117ac0d88e543accbb1c1096" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6bb322a7578acfb8670b3ce8bc96fc9" category="paragraph"><block ref="b6bb322a7578acfb8670b3ce8bc96fc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02cbbc24385dbe83fb42a1bd0c5668da" category="paragraph"><block ref="02cbbc24385dbe83fb42a1bd0c5668da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d923f79d8112841c7df8503e86f0af4a" category="list-text">创建 SMB 卷的过程非常简单。选择要创建卷的 CVO 实例，然后单击创建卷选项。选择适当的大小， Cloud Manager 选择包含的聚合或使用高级分配机制将其放置在特定聚合上。在此演示中，选择 SMB 作为协议。</block>
  <block id="a74d409c32c4bc504768c6a7607fc409" category="paragraph"><block ref="a74d409c32c4bc504768c6a7607fc409" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8923d310a6b50c677ed6f68410181b46" category="paragraph"><block ref="8923d310a6b50c677ed6f68410181b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="776a8d832701253eb40b056e68086fcd" category="list-text">创建卷后，使用 mount 命令从 Azure VMware 解决方案 SDDC 主机上运行的虚拟机连接到共享。</block>
  <block id="70307f46aa9c37929516c971f3445caa" category="list-text">复制以下路径并使用映射网络驱动器选项将卷挂载到 Azure VMware 解决方案 SDDC 上运行的虚拟机上。</block>
  <block id="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="paragraph"><block ref="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d1f50043685559ea05d7c21ae5a6d8a" category="paragraph"><block ref="1d1f50043685559ea05d7c21ae5a6d8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e7b38e3108ed39835e616f3a8eef4d9" category="paragraph">要将 LUN 连接到主机，请完成以下步骤：</block>
  <block id="06fcf6729491b5106094916e154fb565" category="paragraph"><block ref="06fcf6729491b5106094916e154fb565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7af0094f03c81886be499600b8563647" category="paragraph">要对 Azure VMware 解决方案 SDDC 上的主机执行相同操作，请执行以下操作：</block>
  <block id="640e587a72f6b61dc8d20a6de477db96" category="list-text">RDP 到 Azure VMware 解决方案 SDDC 上托管的虚拟机。</block>
  <block id="2d5b864b177738fa7a03f083ae03d2a3" category="paragraph">* 注： * Windows 主机必须与集群中的每个节点建立 iSCSI 连接。原生 DSM 会选择要使用的最佳路径。</block>
  <block id="829bd9f13853ee7a86f5805c316df650" category="paragraph"><block ref="829bd9f13853ee7a86f5805c316df650" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d378c726809748df2090ec116c7232b4" category="paragraph"><block ref="d378c726809748df2090ec116c7232b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b3a58a7b9961d5d214b65da735d2f89" category="list-text">按照向导中的说明进行操作。在此示例中，驱动器 E ：已挂载</block>
  <block id="586f9ee0f7d5544a894ea05b9df312d7" category="paragraph"><block ref="586f9ee0f7d5544a894ea05b9df312d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ff716a75c3423262418c90aad971f10" category="paragraph"><block ref="6ff716a75c3423262418c90aad971f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e3fe132749fe21d23cf75f00317a6fe" category="doc">在 AWS 上为适用于 NetApp ONTAP 的 Amazon FSX 配置 VMware Cloud</block>
  <block id="5f19d821dc2e2e3a8e9418909df59733" category="paragraph">Amazon FSX for NetApp ONTAP 文件共享和 LUN 可以从 AWS 上的 VMware Cloud 的 VMware SDDC 环境中创建的 VM 挂载。此外，还可以使用 NFS 或 SMB 协议在 Linux 客户端上挂载这些卷并将其映射到 Windows 客户端上，通过 iSCSI 挂载 LUN 时，可以在 Linux 或 Windows 客户端上以块设备的形式访问这些 LUN 。可通过以下步骤快速设置适用于 NetApp ONTAP 文件系统的 Amazon FSX 。</block>
  <block id="190b27040d3191ccf35bdb35221f0682" category="admonition">适用于 NetApp ONTAP 的 Amazon FSx 和基于 AWS 的 VMware Cloud 必须位于同一可用性区域中，才能提高性能并避免在可用性区域之间传输数据。</block>
  <block id="f8caa19e45e4a42ea7bc10cad5d49ae8" category="section-title">创建并挂载适用于 ONTAP 卷的 Amazon FSX</block>
  <block id="e765d7d83fde51af5391c87cc45dccf2" category="paragraph">要创建和挂载适用于 NetApp ONTAP 的 Amazon FSX 文件系统，请完成以下步骤：</block>
  <block id="43935f267f64b4ca1a3f1803272df64b" category="inline-link-macro">Amazon FSX 控制台</block>
  <block id="4d33567207f0232b86c9bec4b4f38d45" category="list-text">打开 <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block> 并选择创建文件系统以启动文件系统创建向导。</block>
  <block id="df08dda7dc18ddb7de0e9ad5001a9f04" category="list-text">在选择文件系统类型页面上，选择适用于 NetApp ONTAP 的 Amazon FSx ，然后选择下一步。此时将显示创建文件系统页面。</block>
  <block id="c40ea60211b89b2179fe7a947527ff66" category="paragraph"><block ref="c40ea60211b89b2179fe7a947527ff66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f29804f0e866cb47ba2fa233a71a54fd" category="list-text">在网络部分中，对于虚拟私有云（ Virtual Private Cloud ， VPC ），选择适当的 VPC 和首选子网以及路由表。在这种情况下，将从下拉列表中选择 vmcfsx2.vPC 。</block>
  <block id="628892e49fa967795d4d8d3269c5bb31" category="paragraph"><block ref="628892e49fa967795d4d8d3269c5bb31" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf9c04e1d81f05e344db236ac47ea588" category="list-text">对于创建方法，请选择标准创建。您也可以选择 " 快速创建 " ，但本文档使用 " 标准创建 " 选项。</block>
  <block id="e3c13c0fe612a941f86617c0ad730fca" category="paragraph"><block ref="e3c13c0fe612a941f86617c0ad730fca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e47c53bc440aebf2328e497b46953118" category="paragraph"><block ref="e47c53bc440aebf2328e497b46953118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed02b1594feb57e5c5c1ca0678086dd" category="list-text">在安全性和加密部分中，对于加密密钥，选择用于保护文件系统空闲数据的 AWS 密钥管理服务（ AWS KMS ）加密密钥。对于文件系统管理密码，输入 fsxadmin 用户的安全密码。</block>
  <block id="450514d9ec3a47df8e580605e80579b7" category="paragraph"><block ref="450514d9ec3a47df8e580605e80579b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b969656105cc9174e398fa5754382d5b" category="list-text">在虚拟机中，并指定与 vsadmin 结合使用的密码，以便使用 REST API 或 CLI 管理 ONTAP 。如果未指定密码，则可以使用 fsxadmin 用户来管理 SVM 。在 Active Directory 部分中，确保将 Active Directory 加入 SVM 以配置 SMB 共享。在默认 Storage Virtual Machine 配置部分中，在此验证中提供存储的名称， SMB 共享使用自管理的 Active Directory 域进行配置。</block>
  <block id="0b0a8d3b6da586b1c3d7ace81f086743" category="paragraph"><block ref="0b0a8d3b6da586b1c3d7ace81f086743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89a8b582feabb26f60740f7b0a57aaef" category="list-text">在默认卷配置部分中，指定卷名称和大小。这是一个 NFS 卷。对于存储效率，请选择启用以启用 ONTAP 存储效率功能（数据压缩，重复数据删除和数据缩减），或者选择禁用以禁用这些功能。</block>
  <block id="2cfdc5814e94a8d05a802a6b639158b7" category="paragraph"><block ref="2cfdc5814e94a8d05a802a6b639158b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59ed30f46b9afae4f90b77ac3ed74f8e" category="list-text">查看创建文件系统页面上显示的文件系统配置。</block>
  <block id="08ef5aaea85c8112d5d0e368443ee4fe" category="list-text">单击创建文件系统。</block>
  <block id="d385818e8551a5f93e9591daf3cf7c22" category="paragraph"><block ref="aae4a315cf943820b378b71447a7994a" category="inline-image-macro-rx" type="image"></block>
<block ref="e34db9249abae41534adba1bed16b8d1" category="inline-image-macro-rx" type="image"></block>
<block ref="f1c6728d54b85d98dd49bf5dc91e4f97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f5cc47067a5c4b536ab91f1a843de82" category="inline-link-macro">适用于 NetApp ONTAP 的 Amazon FSX 入门</block>
  <block id="e37ec80b6a23f377fd957d8c83c7a7b5" category="paragraph">有关更多详细信息，请参见 <block ref="01eec31289b39ab7b89a00515912c371" category="inline-link-macro-rx"></block>。</block>
  <block id="af62c8c40f4b51eaee5cfbcfdb7bffaa" category="paragraph">按上述方式创建文件系统后，使用所需的大小和协议创建卷。</block>
  <block id="5eb9e90ab2c5435bcefd918c8c8a7304" category="list-text">打开 <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block>。</block>
  <block id="4cdc643691b84580850903954cdca1d1" category="list-text">在左侧导航窗格中，选择文件系统，然后选择要为其创建卷的 ONTAP 文件系统。</block>
  <block id="05c0eed2abbd9c20871b6af0eb7b1e38" category="list-text">选择卷选项卡。</block>
  <block id="511e546bcb3da3ea3db700200e857ebf" category="list-text">选择创建卷选项卡。</block>
  <block id="328a4173ff8b40f0204a78c6a579b01e" category="list-text">此时将显示创建卷对话框。</block>
  <block id="b1734fefd5bf5fc9e481a277d683ca10" category="paragraph">出于演示目的，本节创建了一个 NFS 卷，可以轻松地挂载在 AWS 上的 VMware 云上运行的 VM 上。nfsdemovol01 创建如下：</block>
  <block id="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="paragraph"><block ref="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72e172d843c1baf9acb881337f0bb2cc" category="section-title">在 Linux 客户端上挂载 FSX ONTAP 卷</block>
  <block id="682dccf32ec3d6c1e1ca2548a43c4245" category="paragraph">挂载上一步中创建的 FSX ONTAP 卷。在 AWS SDDC 上 VMC 中的 Linux VM 中，完成以下步骤：</block>
  <block id="a8dc83c93fa2350d1419b44103864f2c" category="list-text">使用安全 Shell （ SSH ）在实例上打开一个终端，并使用相应的凭据登录。</block>
  <block id="454d9d1fe6ad680e393543d5e7b11669" category="list-text">使用以下命令为卷的挂载点创建一个目录：</block>
  <block id="6631f82f4a955cf7fe5644adadf79e47" category="paragraph"><block ref="6631f82f4a955cf7fe5644adadf79e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2774f9046ee4873805e1f044fa12fe85" category="list-text">执行后，运行 df 命令以验证挂载。</block>
  <block id="d06051412d6da4495ca1a69429ea4fdf" category="paragraph"><block ref="d06051412d6da4495ca1a69429ea4fdf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0927b028b8b35cb7421cd2d29ebac0ab" category="section-title">将 FSX ONTAP 卷连接到 Microsoft Windows 客户端</block>
  <block id="49a305dd021166bf8a508fb51b3fce24" category="paragraph">要管理和映射 Amazon FSX 文件系统上的文件共享，必须使用共享文件夹图形用户界面。</block>
  <block id="0f51d6ad9d95d24bf6d5b0e18d947382" category="list-text">打开 " 开始 " 菜单，然后使用以管理员身份运行来运行 fsmgmt.msc 。这样将打开共享文件夹 GUI 工具。</block>
  <block id="0186f9c0fa21b0c8ab82fadf036afe8f" category="list-text">单击操作 &gt; 所有任务，然后选择连接到另一台计算机。</block>
  <block id="f5cf362d19da392bad46d1cb4bbea453" category="list-text">对于另一台计算机，输入 Storage Virtual Machine （ SVM ）的 DNS 名称。例如，在此示例中使用了 FSXSMBTESTING01.FSXTESTING.local 。</block>
  <block id="882da317003fa80717e3939e41c5aa32" category="admonition">TP 可在 Amazon FSX 控制台上找到 SVM 的 DNS 名称，选择 Storage Virtual Machine ，选择 SVM ，然后向下滚动到端点以查找 SMB DNS 名称。单击确定。Amazon FSX 文件系统将显示在共享文件夹列表中。</block>
  <block id="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="paragraph"><block ref="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd517d0d40877562e2dae460910a5260" category="list-text">在共享文件夹工具中，选择左窗格中的共享以查看 Amazon FSX 文件系统的活动共享。</block>
  <block id="e4fb530e581118e4aa66166f33242547" category="paragraph"><block ref="e4fb530e581118e4aa66166f33242547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b994a2e22edf9cb0de792e6a494da514" category="list-text">现在，选择一个新共享并完成创建共享文件夹向导。</block>
  <block id="9630a309cdca9ed17b688fe15c03a200" category="paragraph"><block ref="f821d910b54d4df166bfb6c9a0fbeac1" category="inline-image-macro-rx" type="image"></block>
<block ref="1456921fb33e6c835f2ea077607c478a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed3796b20dc1d1a4f1756d0cb0f45489" category="inline-link-macro">创建 SMB 共享</block>
  <block id="dc77f3b6074a456c2be3f16b862db081" category="paragraph">要了解有关在 Amazon FSX 文件系统上创建和管理 SMB 共享的详细信息，请参见 <block ref="a85495f11ff3e696252abf798d30d57d" category="inline-link-macro-rx"></block>。</block>
  <block id="470140537c670eb8edb32bf6e8b2bad5" category="list-text">建立连接后，可以连接 SMB 共享并将其用于应用程序数据。为此，请复制共享路径并使用映射网络驱动器选项将卷挂载到 AWS SDDC 上在 VMware Cloud 上运行的虚拟机上。</block>
  <block id="0542af5401c04588abf9b665f31829b6" category="paragraph"><block ref="0542af5401c04588abf9b665f31829b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6c5856c2845517bb6408529fb90b57e" category="section-title">使用 iSCSI 将适用于 NetApp ONTAP LUN 的 FSX 连接到主机</block>
  <block id="716fd43b3bc7735b075d056d4ac18dc4" category="paragraph">FSX 的 iSCSI 流量通过上一节提供的路由遍历 VMware Transit Connect/AWS Transit Gateway 。要在适用于 NetApp ONTAP 的 Amazon FSX 中配置 LUN ，请按照找到的文档进行操作 <block ref="70da71f7286decf7407c5db884b5344a" category="inline-link-macro-rx"></block>。</block>
  <block id="32139f76f200f13f9078d49f80c95815" category="paragraph">在 Linux 客户端上，确保 iSCSI 守护进程正在运行。配置 LUN 后，请参见有关使用 Ubuntu 配置 iSCSI 的详细指南（示例） <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>。</block>
  <block id="102b54837bec429c2bc9f3f9fee8a857" category="paragraph">本文介绍了如何将 iSCSI LUN 连接到 Windows 主机：</block>
  <block id="29980d065df6792c6cf2015646e8744d" category="section-title">在适用于 NetApp ONTAP 的 FSX 中配置 LUN ：</block>
  <block id="6da38655de350d44c878e17adb0fd12c" category="list-text">使用 ONTAP 文件系统的 FSX 管理端口访问 NetApp ONTAP 命令行界面。</block>
  <block id="6f8dec9d607d68b3712504d90548dc7f" category="list-text">按照规模估算输出所示，使用所需大小创建 LUN 。</block>
  <block id="c31d63ac510efc7c433e07d70ef0a11a" category="paragraph">在此示例中，我们创建了一个大小为 5G （ 5368709120 ）的 LUN 。</block>
  <block id="e3de6fee1eaf0d0777dc125d42255a4b" category="list-text">创建必要的 igroup 以控制哪些主机可以访问特定 LUN 。</block>
  <block id="8c92602adf53776d90c46162f150dd3c" category="paragraph">此时将显示两个条目。</block>
  <block id="e71def0bc16c2989d418764ced77c368" category="list-text">使用以下命令将 LUN 映射到 igroup ：</block>
  <block id="fd29357379ec9a1916e7512ba9cba2d5" category="list-text">将新配置的 LUN 连接到 Windows VM ：</block>
  <block id="15bea41b01d7287439a04eb0c57a5ef5" category="paragraph">要将新 LUN 连接到 AWS SDDC 上 VMware 云上的 Windows 主机，请完成以下步骤：</block>
  <block id="eabaddae6242a6352bd11a6bdf29b55a" category="list-text">RDP 到 AWS SDDC 上 VMware Cloud 上托管的 Windows VM 。</block>
  <block id="debd85c1c5da22a2c5e207ae0ad4b91a" category="list-text">导航到服务器管理器 &gt; 信息板 &gt; 工具 &gt; iSCSI 启动程序以打开 iSCSI 启动程序属性对话框。</block>
  <block id="43237019bec64292757878b08a9d1a63" category="list-text">选择启用多路径，然后选择 " 计算机启动时自动还原此连接 " 或 " 将此连接添加到收藏目标列表 " 。单击高级。</block>
  <block id="6aa775ce454f9bfcd13c7e20b90531e7" category="paragraph"><block ref="6aa775ce454f9bfcd13c7e20b90531e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc2a4ed37392086accdd3db98b75509" category="paragraph">Storage Virtual Machine （ SVM ）上的 LUN 在 Windows 主机中显示为磁盘。主机不会自动发现添加的任何新磁盘。通过完成以下步骤触发手动重新扫描以发现磁盘：</block>
  <block id="3ba2e4c8502f30b8e6d44fc88ebe784a" category="paragraph"><block ref="3ba2e4c8502f30b8e6d44fc88ebe784a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="405bdc4379d9776fbda741356a79c543" category="paragraph">当新 LUN 首次由 Windows 主机访问时，它没有分区或文件系统。通过完成以下步骤初始化 LUN ，并可选择使用文件系统格式化 LUN ：</block>
  <block id="848c01bbaad78639e22ba05626884091" category="paragraph"><block ref="848c01bbaad78639e22ba05626884091" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e1c36a2c24e0aaf7844ec890c15e430" category="paragraph">了解主要超大规模提供商中的 NetApp 存储支持组合。</block>
  <block id="6a3b9d31df0a58cc23207c2af925ef0f" category="paragraph">要使用 Azure VMware 解决方案，请先在标识的订阅中注册资源提供程序：</block>
  <block id="58c59ab4d5d488609913efa7b1daaa31" category="list-text">登录到 Azure 门户。</block>
  <block id="5d704d400396fefbe3427ee665a0ec16" category="list-text">在 Azure 门户菜单上，选择所有服务。</block>
  <block id="eff35df9bedc80337261af1399e526a2" category="list-text">在所有服务对话框中，输入订阅，然后选择订阅。</block>
  <block id="41825376d695df481d13f37e3e1587db" category="list-text">要查看此订阅，请从订阅列表中选择此订阅。</block>
  <block id="4d3e5a69b8f8c0bec64cf18db73fff95" category="list-text">选择资源提供程序，然后在搜索中输入 microsoft.AVS 。</block>
  <block id="2bf384915bc11a9360bdf9792dc43bf3" category="list-text">如果资源提供程序未注册，请选择注册。</block>
  <block id="0b4b8a7bf2e1e647f3be6dde423b9b79" category="paragraph"><block ref="0b4b8a7bf2e1e647f3be6dde423b9b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb08f4992bb541aec19da4c688d0239" category="paragraph"><block ref="bdb08f4992bb541aec19da4c688d0239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="382da60e8008eed186472cc1a3c3ca37" category="list-text">注册资源提供程序后，使用 Azure 门户创建 Azure VMware 解决方案私有云。</block>
  <block id="397065cbdc87787d17122a18f5c5088d" category="list-text">选择创建新资源。</block>
  <block id="39d2b5824a6dce05a74b5a60d5769656" category="list-text">在 Search the Marketplace 文本框中，输入 Azure VMware 解决方案并从结果中选择它。</block>
  <block id="d090262ac8690f612cbc8bd5fc83b11c" category="list-text">在 Azure VMware 解决方案页面上，选择创建。</block>
  <block id="4a62c7a4f3f3f4a3927621c33c12bb63" category="list-text">在基础选项卡的字段中输入值，然后选择查看 + 创建。</block>
  <block id="2a01d572b1447155c310cabafac3fae9" category="paragraph">注释：</block>
  <block id="7c1ec568c35f8a03d9cfd64b465a4e4f" category="list-text">要快速入门，请在规划阶段收集所需信息。</block>
  <block id="d61ffacba4094067e86b90bcf3739fcf" category="list-text">选择现有资源组或为私有云创建新资源组。资源组是部署和管理 Azure 资源的逻辑容器。</block>
  <block id="81d6141ddb9ac3b3888dce83fbf00cf6" category="list-text">确保 CIDR 地址是唯一的，不会与其他 Azure 虚拟网络或内部网络重叠。CIDR 表示私有云管理网络，并用于 vCenter Server 和 NSX-T Manager 等集群管理服务。NetApp 建议使用 22 地址空间。在此示例中，使用了 10.21.0.0/22 。</block>
  <block id="266811324b3ca32d24624ba571c07de8" category="paragraph"><block ref="266811324b3ca32d24624ba571c07de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd710e77504d5568fd5079361107a7eb" category="paragraph">配置过程大约需要 4 – 5 小时。此过程完成后，通过从 Azure 门户访问私有云来验证部署是否成功。部署完成后，系统将显示状态 " 成功 " 。</block>
  <block id="411f20742da0d4f8cdc568d7aee8fab3" category="paragraph">Azure VMware 解决方案私有云需要 Azure 虚拟网络。由于 Azure VMware 解决方案不支持内部 vCenter ，因此需要执行其他步骤才能与现有内部环境集成。此外，还需要设置 ExpressRoute 电路和虚拟网络网关。在等待集群配置完成时，创建新的虚拟网络或使用现有虚拟网络连接到 Azure VMware 解决方案。</block>
  <block id="aa86eba8b2b706f81a805eb35b834541" category="paragraph"><block ref="aa86eba8b2b706f81a805eb35b834541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7714bc43e9a27f2c98a38e6b6d7f3d8" category="doc">适用于公有云提供商的 NetApp 存储选项</block>
  <block id="8db50e5729f7a5d770aaceef947a2982" category="paragraph">了解 NetApp 在三大超大规模提供商中作为存储的各种选项。</block>
  <block id="60ce80493de8468bdfd597af1c219a9f" category="paragraph">AWS 支持以下配置中的 NetApp 存储：</block>
  <block id="5f18b04dd7d7089a2177c4c930d8d57f" category="paragraph">Azure 支持以下配置中的 NetApp 存储：</block>
  <block id="74eb4c6138d4b8cd8399b01966c5af28" category="section-title">适用于 GCP 的 NetApp 存储选项</block>
  <block id="8f08ff97ca555f50f0d05fdf950a0568" category="paragraph">Google Cloud 支持以下配置中的 NetApp 存储：</block>
  <block id="5c2d9a62bb25b00981f59e22e27bfd17" category="doc">验证连接到 Azure VMware 解决方案私有云的网络和访问权限</block>
  <block id="40228f700f5965975e4aff8c6c2ff4b3" category="paragraph">Azure VMware 解决方案不允许您使用内部 VMware vCenter 管理私有云。而是需要跳转主机才能连接到 Azure VMware 解决方案 vCenter 实例。在指定资源组中创建一个跳转主机，然后登录到 Azure VMware 解决方案 vCenter 。此跳转主机应是为连接而创建的同一虚拟网络上的 Windows VM ，并应提供对 vCenter 和 NSX Manager 的访问权限。</block>
  <block id="d88c36b93ae5dcb2646d56c57f27bf0e" category="paragraph"><block ref="d88c36b93ae5dcb2646d56c57f27bf0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44f5524c6ac4144dbabf7a4d365b837b" category="paragraph">配置虚拟机后，使用 Connect 选项访问 RDP 。</block>
  <block id="443f53614721177f7c44df93d426a919" category="paragraph"><block ref="443f53614721177f7c44df93d426a919" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36cb4e54805ffde727ffbc809183608e" category="paragraph">使用云管理员用户从此新创建的跳转主机虚拟机登录到 vCenter 。要访问凭据，请转到 Azure 门户并导航到身份（位于私有云中的 Manage 选项下）。可以从此处复制私有云 vCenter 和 NSX-T Manager 的 URL 和用户凭据。</block>
  <block id="9620acd59a8e7ad0f318754391c40c4e" category="paragraph"><block ref="9620acd59a8e7ad0f318754391c40c4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73d88630b730fa00c46338a0aef4c2d3" category="paragraph">在 Windows 虚拟机中，打开浏览器并导航到 vCenter Web 客户端 URL <block ref="2db127a24dc88638a76677b404bda5a4" category="inline-link-rx"></block> 并使用管理员用户名 * cloudadmin@vsphere.local* 并粘贴复制的密码。同样，也可以使用 Web 客户端 URL 访问 NSX-T 管理器 <block ref="bb142e18a679100de3817fcefaa25b07" category="inline-link-rx"></block> 并使用管理员用户名并粘贴复制的密码以创建新分段或修改现有分层网关。</block>
  <block id="4a6e0ba5b4d42fb0f658bdfdbbea32fc" category="admonition">对于配置的每个 SDDC ， Web 客户端 URL 都不同。</block>
  <block id="49848931415b32db238a2dd1daddf3a7" category="paragraph"><block ref="49848931415b32db238a2dd1daddf3a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f65f698ac6bac1ada03193e1cdabb8" category="paragraph"><block ref="87f65f698ac6bac1ada03193e1cdabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec3eeb836273dbc92b27ce718a90b212" category="inline-link-macro">将内部环境与 Azure VMware 解决方案建立对等关系</block>
  <block id="097529edf2feb9ed1237427eaa3b2599" category="paragraph">现在， Azure VMware 解决方案 SDDC 已部署和配置。利用 ExpressRoute Global Reach 将内部环境连接到 Azure VMware 解决方案私有云。有关详细信息，请参见 <block ref="29749340a5d7bf5df1867a3f2d2723a1" category="inline-link-macro-rx"></block>。</block>
  <block id="ae6569fd64694b91a054cbdfdfef84d2" category="paragraph">要创建新的 Azure 虚拟网络（ vNet ），请选择 Azure vNet Connect 选项卡。或者，您也可以使用创建虚拟网络向导从 Azure 门户手动创建一个：</block>
  <block id="34b04201ae997eaabb6802b04d5c1708" category="list-text">转到 Azure VMware 解决方案私有云，然后在管理选项下访问连接。</block>
  <block id="da40ae630b63a930be4e1230efc306e1" category="list-text">选择 Azure vNet Connect 。</block>
  <block id="40292c219898a1253befc6301234575a" category="list-text">要创建新的 vNet ，请选择 Create New 选项。</block>
  <block id="f98e10d9ba9ac83ac2adeacde774d051" category="paragraph">通过此功能，可以将 vNet 连接到 Azure VMware 解决方案私有云。vNet 可通过自动创建所需组件（例如跳转盒， Azure NetApp Files 等共享服务和 Cloud Volume ONTAP ）并通过 ExpressRoute 在 Azure VMware 解决方案中创建的私有云来实现此虚拟网络中的工作负载之间的通信。</block>
  <block id="0314a97a9eb0aae73531717ef45ad195" category="paragraph">* 注意： * vNet 地址空间不应与私有云 CIDR 重叠。</block>
  <block id="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="paragraph"><block ref="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="inline-image-macro-rx" type="image"></block></block>
  <block id="206843027dd7ebe90f425f9ee4765a01" category="list-text">提供或更新新 vNet 的信息，然后选择确定。</block>
  <block id="26c6d54522f3fd79684f463116e9634b" category="paragraph"><block ref="26c6d54522f3fd79684f463116e9634b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="027524e66bad6099279342bf8d8f6dd4" category="paragraph">将在指定的订阅和资源组中创建具有提供的地址范围和网关子网的 vNet 。</block>
  <block id="5ecf2fb7501138eaa14be97a59d2a773" category="inline-link-macro">在 Azure 中为 VMware 私有云配置网络连接</block>
  <block id="5da6ff60860f48de7bb7f4467c28f26f" category="admonition">如果您手动创建 vNet ，请创建一个虚拟网络网关，并将相应的 SKU 和 ExpressRoute 作为网关类型。部署完成后，使用授权密钥将 ExpressRoute 连接到包含 Azure VMware 解决方案私有云的虚拟网络网关。有关详细信息，请参见 <block ref="4807c1aea8c93bde3104bd4ecfa22a07" category="inline-link-macro-rx"></block>。</block>
  <block id="d77d7a022616e70a9987aa0974241779" category="paragraph">配置私有云后，配置对私有云的私有访问，以实现高吞吐量和低延迟的数据路径连接。</block>
  <block id="256431e41a96deb49bcd86b1ca56393e" category="inline-link-macro">GCP 文档</block>
  <block id="e4cf8d7f33a9dafc85be0439cd8fbc4d" category="paragraph">这将确保运行 Cloud Volumes ONTAP 实例的 VPC 网络能够与 GCVE 私有云进行通信。要执行此操作，请按照 <block ref="9cd64b8fb1b43e7f674c1b78b2a86f74" category="inline-link-macro-rx"></block>。对于云卷服务，通过在租户主机项目之间执行一次性对等操作，在 VMware 引擎和 Cloud Volumes Service 之间建立连接。有关详细步骤，请按照此步骤进行操作 <block ref="04a9f04edfdd7b0a53da57f015378c5a" category="inline-link-macro-rx"></block>。</block>
  <block id="e6945148d9a888e52db99c5ebce86868" category="paragraph"><block ref="e6945148d9a888e52db99c5ebce86868" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3eb3a1c6330fe124fc0706cbdd91df" category="paragraph">使用 CloudOwner@gve.local 用户登录到 vCenter 。要访问凭据，请转到 VMware 引擎门户，转到资源并选择相应的私有云。在基本信息部分中，单击 vCenter 登录信息（ vCenter Server ， HCX Manager ）或 NSX-T 登录信息（ NSX Manager ）的查看链接。</block>
  <block id="6f32389268763bedb9e6716b5f0973d0" category="paragraph"><block ref="6f32389268763bedb9e6716b5f0973d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ec2407381a4f65d228483b566b6907f" category="paragraph">在 Windows 虚拟机中，打开浏览器并导航到 vCenter Web 客户端 URL <block ref="d325f0342d122dda054a3ca8b0c44019" category="inline-link-rx"></block> 并使用 admin 用户名 CloudOwner@gve.local 并粘贴复制的密码。同样，也可以使用 Web 客户端 URL 访问 NSX-T 管理器 <block ref="c694eb5be92097a8fdea8cdda0ad5ea5" category="inline-link-rx"></block> 并使用管理员用户名并粘贴复制的密码以创建新分段或修改现有分层网关。</block>
  <block id="3a9cff0eb1abb119c1c264dbfff216f6" category="paragraph">要从内部网络连接到 VMware Engine 私有云，请利用云 VPN 或 Cloud Interconnect 实现适当的连接，并确保所需端口处于打开状态。有关详细步骤，请按照此步骤进行操作 <block ref="6fe8ac83365e22e24c5c8eb9edc2d548" category="inline-link-macro-rx"></block>。</block>
  <block id="b433f901707e7fd0f6d64371dfca4af9" category="paragraph"><block ref="b433f901707e7fd0f6d64371dfca4af9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="989afab9e0dfcc6d523ddb1d23145834" category="paragraph"><block ref="989afab9e0dfcc6d523ddb1d23145834" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c0dd0de38e3c9e55ef5f52e46641376" category="doc">使用 VMware 引擎配置 Cloud Volumes Service</block>
  <block id="8e12272d11d90cdb919c737591f398f6" category="paragraph">可以从 VMware 引擎环境中创建的 VM 挂载 Cloud Volumes Service 共享。由于 Cloud Volumes Service 支持 SMB 和 NFS 协议，因此这些卷也可以挂载到 Linux 客户端并映射到 Windows 客户端。可以通过简单的步骤设置 Cloud Volumes Service 卷。</block>
  <block id="992031e7435f44536a649bfc9de30683" category="paragraph">Cloud Volume Service 和 Google Cloud VMware Engine 私有云必须位于同一区域。</block>
  <block id="a0c391dc49c440fc9962168353cedde3" category="inline-link-macro">指南</block>
  <block id="e9676faeb0b33249abc3a47d95e55ed8" category="paragraph">要从 Google 云市场购买，启用和配置适用于 Google Cloud 的 NetApp Cloud Volumes Service ，请按照以下详细信息进行操作 <block ref="c9eb1a9870bc9f20357f50bf16ec5704" category="inline-link-macro-rx"></block>。</block>
  <block id="84c877bb77a313d307054a0824ffff03" category="section-title">创建一个 CVS NFS 卷到 GCVE 私有云</block>
  <block id="1ec5bbc38708de3f8cfad6d6ca608742" category="paragraph">要创建和挂载 NFS 卷，请完成以下步骤：</block>
  <block id="ca5470246976d59ea6a32d3e2094059d" category="list-text">从 Google 云控制台中的合作伙伴解决方案访问 Cloud Volumes 。</block>
  <block id="45ab48bbbad4380f09ef6b41f9eb8f8a" category="paragraph"><block ref="45ab48bbbad4380f09ef6b41f9eb8f8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46577653160772df2b1548b726d7c9ce" category="list-text">在 Cloud Volumes Console 中，转到 Volumes 页面，然后单击 Create 。</block>
  <block id="4a43547530a8ef079adc80160de3dde9" category="paragraph"><block ref="4a43547530a8ef079adc80160de3dde9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="825700271a3acfeaf96fa0bfb5f15b65" category="list-text">在创建文件系统页面上，根据成本分摊机制的需要指定卷名称和计费标签。</block>
  <block id="8a81559c79124aa1a1cd2093faed73ee" category="paragraph"><block ref="8a81559c79124aa1a1cd2093faed73ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4bbe773302576667095a132b75c48fc" category="list-text">选择相应的服务。对于 GCVE ，请选择 CVS-Performance 和所需的服务级别，以根据应用程序工作负载要求提高延迟和性能。</block>
  <block id="184fe9f42c4d5eaab1cc6079778040c2" category="paragraph"><block ref="184fe9f42c4d5eaab1cc6079778040c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492d6cb3c36c984d9f52d9461c5b69b" category="list-text">为卷和卷路径指定 Google Cloud 区域（卷路径必须在项目中的所有云卷之间是唯一的）</block>
  <block id="594c2b024401023acd7deae8f3cb8ceb" category="paragraph"><block ref="594c2b024401023acd7deae8f3cb8ceb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4b0697a6c38463b0b06d7dc66b16b74" category="list-text">选择卷的性能级别。</block>
  <block id="aebc437f9bb3656c19ecebe1becc99fa" category="paragraph"><block ref="aebc437f9bb3656c19ecebe1becc99fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd9c26fe6b5f33ab2b0002050ff831d8" category="list-text">指定卷的大小和协议类型。在此测试中，将使用 NFSv3 。</block>
  <block id="e5ba61d9c8c666d452e9e78256762019" category="paragraph"><block ref="e5ba61d9c8c666d452e9e78256762019" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3a8099bd03f7da2c641e049e354ea1" category="list-text">在此步骤中，选择可从中访问卷的 VPC 网络。确保已建立 VPC 对等关系。</block>
  <block id="d3dba730ef6d3f046910d94696ca086d" category="paragraph">提示：如果尚未建立 VPC 对等关系，则会显示一个弹出按钮，用于指导您完成对等命令。打开 Cloud Shell 会话并执行相应的命令，将您的 VPC 与 Cloud Volumes Service 生产者建立对等关系。如果您决定事先准备 VPC 对等关系，请参见以下说明。</block>
  <block id="ecf942f7df1f072f5910afb3fa45f36e" category="paragraph"><block ref="ecf942f7df1f072f5910afb3fa45f36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ed1352ea98f362074fa7855ec6bb89c" category="list-text">通过添加相应的规则来管理导出策略规则，然后选中相应 NFS 版本对应的复选框。</block>
  <block id="3ae650d16c298e2f5dc9e005a2f8934a" category="paragraph">注意：除非添加导出策略，否则无法访问 NFS 卷。</block>
  <block id="2f6d29a5c21fb51bb181c4b97241a955" category="paragraph"><block ref="2f6d29a5c21fb51bb181c4b97241a955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a194552e035de341a4a7c99a1c687956" category="list-text">单击保存以创建卷。</block>
  <block id="fe18028768c2ffc16d5cb32aa5b70d5b" category="paragraph"><block ref="fe18028768c2ffc16d5cb32aa5b70d5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3588b0992732355d67655af9f6450c5d" category="section-title">将 NFS 导出挂载到在 VMware 引擎上运行的 VM</block>
  <block id="87397baf86d56e19a3bdac712966da5d" category="paragraph">在准备挂载 NFS 卷之前，请确保专用连接的对等状态列为 "Active" 。状态为 "Active" 后，请使用 mount 命令。</block>
  <block id="c9f09539bbf502703a4f5e2d480a5972" category="paragraph">要挂载 NFS 卷，请执行以下操作：</block>
  <block id="726f902a0b5536d71345114fb942d81b" category="list-text">在 Cloud Console 中，转至 Cloud Volumes &gt; Volumes 。</block>
  <block id="1feaf778ab1cf141cf92a316d53e1365" category="list-text">转到卷页面</block>
  <block id="76d2df71caae5e1ec3f81822829504f5" category="list-text">单击要挂载 NFS 导出的 NFS 卷。</block>
  <block id="4fc82f44f951748bf462898e43d08054" category="list-text">向右滚动，在显示更多下，单击挂载说明。</block>
  <block id="692afb2fddb72a6cfc89dd1df12945ab" category="paragraph">要从 VMware VM 的子操作系统中执行挂载过程，请执行以下步骤：</block>
  <block id="2c7df76595ada01b5b08659283021aa7" category="list-text">对虚拟机使用 SSH 客户端和 SSH 。</block>
  <block id="2b64d099377e2935e786009804205feb" category="list-text">在实例上安装 NFS 客户端。</block>
  <block id="d8aa2b3304fc65e5fd1cae735194aef6" category="list-text">在 Red Hat Enterprise Linux 或 SUSE Linux 实例上：</block>
  <block id="d610fa6d370a8d35fb4c26359f086aa0" category="list-text">在 Ubuntu 或 Debian 实例上：</block>
  <block id="9bc2e27c16ca55bfc1a7ba94b91a21dc" category="list-text">在实例上创建新目录，例如 "/nimCVSNFSol01" ：</block>
  <block id="9e21b9d85251decc0982b75506826828" category="paragraph"><block ref="9e21b9d85251decc0982b75506826828" category="inline-image-macro-rx" type="image"></block></block>
  <block id="174714918db1cc87ef113e3087cba5da" category="list-text">使用相应的命令挂载卷。以下是实验室命令示例：</block>
  <block id="1ec7767a139a3f95923511d7bf547a6c" category="paragraph"><block ref="811572ed35d4b134bc0d7769dd80ab6c" category="inline-image-macro-rx" type="image"></block>
<block ref="b780e126200cb608d0de968e965e9c71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3df234dd2e63d779a2d017bb1ef3375d" category="section-title">创建 SMB 共享并将其挂载到在 VMware 引擎上运行的 VM</block>
  <block id="400db805dd1f9fc929e5bf72fafb1661" category="paragraph">对于 SMB 卷，请确保在创建 SMB 卷之前已配置 Active Directory 连接。</block>
  <block id="94f9379544859ae4d8990b84731870aa" category="paragraph"><block ref="94f9379544859ae4d8990b84731870aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c62a73033a0e9f64b5b2b311ded0cc5" category="paragraph">建立 AD 连接后，创建具有所需服务级别的卷。除了选择适当的协议之外，这些步骤与创建 NFS 卷类似。</block>
  <block id="228ba1c797822b63cd7c6f54ca40b87e" category="paragraph"><block ref="228ba1c797822b63cd7c6f54ca40b87e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54cd15dd2d6121aa16f0b4b87b46ef2a" category="list-text">选择相应的服务。对于 GCVE ，请选择 CVS-Performance 和所需的服务级别，以根据工作负载要求提高延迟和性能。</block>
  <block id="b8eb8307790a9b22c2f6997c097b344e" category="paragraph"><block ref="b8eb8307790a9b22c2f6997c097b344e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb91d5f8a608e41cd1f217e30a536437" category="paragraph"><block ref="cb91d5f8a608e41cd1f217e30a536437" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e5a0a3c08f102d8c49c1d811b71d97f" category="paragraph"><block ref="7e5a0a3c08f102d8c49c1d811b71d97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d1a06f98a1c133a8a0c74cc4222e23b" category="list-text">指定卷的大小和协议类型。在此测试中，使用 SMB 。</block>
  <block id="6eb5a9152f38c77efc6d14902aa7dec8" category="paragraph"><block ref="6eb5a9152f38c77efc6d14902aa7dec8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">说明</block>
  <block id="15adcf662b8b92c623f4256a65f605ed" category="paragraph">提示：如果尚未建立 VPC 对等关系，则会显示一个弹出按钮，用于指导您完成对等命令。打开 Cloud Shell 会话并执行相应的命令，将您的 VPC 与 Cloud Volumes Service 生产者建立对等关系。如果您决定事先准备 VPC 对等关系，请参见以下内容 <block ref="3b4469537a7b14dcfd28e3d301600ff6" category="inline-link-macro-rx"></block>。</block>
  <block id="7f88d48c3b0283642fe6b1f3f061d0fd" category="paragraph"><block ref="7f88d48c3b0283642fe6b1f3f061d0fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ac40323c41c29fb75f6e19c4c683e47" category="paragraph"><block ref="8ac40323c41c29fb75f6e19c4c683e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4990031dcfbd871d95ce4ae0321e7156" category="paragraph">要挂载 SMB 卷，请执行以下操作：</block>
  <block id="fd78728be3a82142558c815267b8daa0" category="list-text">单击要映射 SMB 共享的 SMB 卷。</block>
  <block id="58dc78a5cd30078188f7c605e636a975" category="paragraph">要从 VMware VM 的 Windows 子操作系统中执行挂载过程，请执行以下步骤：</block>
  <block id="3dcb4e26f80951bdb3beeb0a03a3ba83" category="list-text">单击 "Start （开始） " 按钮，然后单击 "Computer" （计算机）。</block>
  <block id="202bba1ab43a099f57e49b350eb2ad1a" category="list-text">单击映射网络驱动器。</block>
  <block id="7dea65bdd8e9fbcd8a5b7249c71e1f0b" category="list-text">在驱动器列表中，单击任何可用的驱动器盘符。</block>
  <block id="695179e494f30a851f80409f824a80f8" category="list-text">在文件夹框中，键入：</block>
  <block id="2653f3365feaf0a8bf80106cba1b9ad8" category="paragraph"><block ref="2653f3365feaf0a8bf80106cba1b9ad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cd95358048d9f5d18cf70f66126e1e7" category="paragraph">要在每次登录到计算机时进行连接，请选中登录时重新连接复选框。</block>
  <block id="7968f043139de8ff0e5df4451c437426" category="list-text">单击完成。</block>
  <block id="8902b5e2f0c169ccf7ad8b5c335531e5" category="paragraph"><block ref="8902b5e2f0c169ccf7ad8b5c335531e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="415be703c228d9c6838b18850a1d9f31" category="paragraph">大多数 IT 组织都采用混合云优先的方法。这些组织处于转型阶段，客户正在评估其当前 IT 环境，然后根据评估和发现练习将工作负载迁移到云。</block>
  <block id="346972233965e89cf5b17c3907b35f86" category="paragraph">客户迁移到云的因素包括弹性和突发，数据中心退出，数据中心整合，寿命终结情形，合并， 采集等。迁移的原因可能因组织及其各自的业务优先级而异。迁移到混合云时，在云中选择合适的存储对于充分发挥云部署和弹性的潜能非常重要。</block>
  <block id="0c4a16ed987359b14dc407a858d1a78e" category="section-title">公有云中的 VMware 云选项</block>
  <block id="9789f0612fda153726aa8ad87265e4b9" category="section-title">Azure VMware 解决方案</block>
  <block id="d788a5499d320b05602a6a0805c81403" category="image-alt">AVS</block>
  <block id="c7b818b90803789a74058cfb4396383d" category="paragraph">Azure VMware 解决方案是一种混合云服务，支持在 Microsoft Azure 公有云中实现完全正常运行的 VMware SDDC 。Azure VMware 解决方案是由 Microsoft 全面管理和支持的第一方解决方案，由 VMware 利用 Azure 基础架构进行验证。这意味着，在部署 Azure VMware 解决方案时，客户可以获得用于计算虚拟化的 VMware ESXi ，用于超融合存储的 vSAN ， 和 NSX 实现网络连接和安全性，同时充分利用 Microsoft Azure 的全球影响力，一流的数据中心设施以及邻近丰富的原生 Azure 服务和解决方案生态系统的优势。</block>
  <block id="22b0614f106e2b7c956c60c8fc0d35c3" category="image-alt">VMC</block>
  <block id="8641a2440fc22db60ec877f3a8946fa2" category="paragraph">基于 AWS 的 VMware 云通过优化对原生 AWS 服务的访问，将 VMware 企业级 SDDC 软件引入 AWS 云。VMware Cloud on AWS 由 VMware Cloud Foundation 提供支持，它将 VMware 的计算，存储和网络虚拟化产品（ VMware vSphere ， VMware vSAN 和 VMware NSX ）与 VMware vCenter Server 管理相集成，并经过优化，可在专用的弹性裸机 AWS 基础架构上运行。</block>
  <block id="8cb69aa5b1609d0a39f0fcd576c07df6" category="section-title">Google Cloud VMware 引擎</block>
  <block id="5292de1147a4b3a1d5c63d057c4b0096" category="image-alt">gcve</block>
  <block id="1ffd600a1d8e07fe3b4bca16ae02167c" category="paragraph">Google Cloud VMware Engine 是一款基础架构即服务（ Infrastructure-as-a-Service ， IaaS ）产品，基于 Google Cloud 高性能可扩展基础架构和 VMware Cloud Foundation 堆栈（ VMware vSphere ， vCenter ， vSAN 和 NSX-T ）构建此服务支持快速迁移到云，将现有 VMware 工作负载从内部环境无缝迁移或扩展到 Google Cloud Platform ，而无需花费成本，精力或风险来重新构建应用程序或重新调整操作。这是一项由 Google 销售和支持的服务，与 VMware 密切合作。</block>
  <block id="3310d189628fa6ef843aac57894a6db2" category="admonition">SDDC 私有云和 NetApp Cloud Volumes 主机代管功能可提供最佳性能，并将网络延迟降至最低。</block>
  <block id="c771fce16e2ba5df07df53cc5ab0748f" category="section-title">您知道吗？</block>
  <block id="8bba30129de0461b328be1e49f02b4d9" category="paragraph">无论使用何种云，在部署 VMware SDDC 时，初始集群都包括以下产品：</block>
  <block id="7110e7a8682a9bc1c7105b83fe0cd9ea" category="list-text">用于计算虚拟化的 VMware ESXi 主机，以及用于管理的 vCenter Server 设备</block>
  <block id="7d7a80e207de2136f4f19820758703fc" category="list-text">VMware vSAN 超融合存储，整合了每个 ESXi 主机的物理存储资产</block>
  <block id="d2852e9d73c0ef81033c835719128b81" category="list-text">VMware NSX 用于虚拟网络连接和安全性，并使用 NSX Manager 集群进行管理</block>
  <block id="afb91ca7e7763c77e44a41cb5ad0f78b" category="paragraph">对于计划托管存储密集型工作负载并在任何云托管的 VMware 解决方案上横向扩展的客户，默认的超融合基础架构要求扩展应同时位于计算和存储资源上。</block>
  <block id="fdb27bea654a8d874baecced2be84a1b" category="paragraph">通过与 Azure NetApp Files ，适用于 NetApp ONTAP 的 Amazon FSx ，适用于所有三种主要超大规模云产品的 Cloud Volumes ONTAP 以及适用于 Google Cloud 的 Cloud Volumes Service 等 NetApp Cloud Volumes 相集成，客户现在可以选择单独扩展其存储。 并且仅根据需要向 SDDC 集群添加计算节点。</block>
  <block id="a752c3529f0285d457f3b33b3c80d9a4" category="list-text">VMware 不建议使用不平衡的集群配置，因此扩展存储意味着添加更多主机，这意味着 TCO 增加。</block>
  <block id="c231690c8e9fabbd819ec1805becb157" category="list-text">无法提供多个性能层来满足应用程序要求，性能和成本要求。</block>
  <block id="5d4c92ddd5fe9a6044b25c17d3368207" category="list-text">很容易达到基于集群主机构建的 vSAN 的存储容量限制。使用 NetApp Cloud Volumes 扩展存储以托管活动数据集或将较冷的数据分层到永久性存储。</block>
  <block id="c1cf68955de5fa20274b29fa4a2a863f" category="paragraph">Azure NetApp Files ，适用于 NetApp ONTAP 的 Amazon FSx ， Cloud Volumes ONTAP （在所有三个主要超大规模企业中均有提供）和适用于 Google Cloud 的 Cloud Volumes Service 可与子虚拟机结合使用。此混合存储架构由一个 vSAN 数据存储库组成，用于存放子操作系统和应用程序二进制数据。应用程序数据通过基于子系统的 iSCSI 启动程序或 NFS/SMB 挂载连接到 VM ，这些启动程序或挂载可分别直接与适用于 NetApp ONTAP 的 Amazon FSx ， Cloud Volume ONTAP ， Azure NetApp Files 和适用于 Google Cloud 的 Cloud Volumes Service 进行通信。此配置可让您轻松克服存储容量方面的挑战，就像使用 vSAN 一样，可用空间取决于可宽空间和所使用的存储策略。</block>
  <block id="1a5208bfffc624ccf99dfcbbf2078050" category="paragraph">我们来考虑一下 AWS 上的 VMware Cloud 上的三节点 SDDC 集群：</block>
  <block id="fab7fb31baaec1ccac4fe688e1a4c5d4" category="list-text">三节点 SDDC 的总原始容量 = 31.1TB （每个节点大约 10 TB ）。</block>
  <block id="ca189b47c3a1dfe1adbd1519688e4cc8" category="list-text">在添加其他主机之前要保留的可宽空间 = 25% = （ .25 x 31.1TB ） = 7.6 TB 。</block>
  <block id="999b2c719df3f3e524bb10fb76521726" category="list-text">可宽空间扣除后的可用原始容量 = 23.4TB</block>
  <block id="2e1f3b31385d3304e1cda70b9cd8ed4c" category="list-text">有效可用空间取决于应用的存储策略。</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">例如：</block>
  <block id="2f5e6d9b0a4708c4d137ba14ac704a7b" category="list-text">RAID 0 = 有效可用空间 = 23.4TB （可用原始容量 /1 ）</block>
  <block id="df6b502d4d7283ef27d3821b69836c2d" category="list-text">RAID 1 = 有效可用空间 = 11.7TB （可用原始容量 /2 ）</block>
  <block id="921c660c11d4880048f3ef723f079e17" category="list-text">RAID 5 = 有效可用空间 = 17.5 TB （可用原始容量 /1.33 ）</block>
  <block id="e3bdc3102c3de4f73860c229550bc6f4" category="paragraph">因此，使用 NetApp Cloud Volumes 作为子系统连接的存储有助于扩展存储和优化 TCO ，同时满足性能和数据保护要求。</block>
  <block id="571c0d425ce03c2532e7d9f34ca87cb1" category="section-title">需要记住的要点</block>
  <block id="8e6eaed3852a3b311ab6ed1b8b6fc239" category="list-text">在混合存储模型中，将第 1 层或高优先级工作负载放置在 vSAN 数据存储库上，以满足任何特定延迟要求，因为它们是主机本身的一部分且位于邻近位置。对事务处理延迟可接受的任何工作负载 VM 使用来宾机制。</block>
  <block id="d3c0fd4b510310b9bd00463208eade94" category="list-text">测试显示，从相应 SDDC 访问存储时会出现 2 到 4 毫秒的额外延迟。在映射存储时，将此额外延迟考虑到应用程序要求。</block>
  <block id="b83cf0bc9b65a0fcd5f49d4c96dceea8" category="list-text">要在测试故障转移和实际故障转移期间挂载来宾连接的存储，请确保重新配置 iSCSI 启动程序，更新 SMB 共享的 DNS 以及在 fstab 中更新 NFS 挂载点。</block>
  <block id="1b4048870ed334dbc2e7d6f09a814188" category="list-text">确保已在 VM 中正确配置来宾系统内 Microsoft 多路径 I/O （ MPIO ），防火墙和磁盘超时注册表设置。</block>
  <block id="00b23e82efc2ec82b134496e575a934c" category="section-title">NetApp 云存储的优势</block>
  <block id="80def6ec4d999fc4d082800c8c33f6ec" category="paragraph">NetApp 云存储具有以下优势：</block>
  <block id="2e594db552f7cd9c7f02d87507dbb471" category="list-text">通过独立于计算扩展存储，提高计算到存储的密度。</block>
  <block id="479f9f236fc4cffa74f2e94b654bbeeb" category="list-text">可用于减少主机数量，从而降低总 TCO 。</block>
  <block id="108dd736471686a2b8b87154d73cbc5b" category="list-text">计算节点故障不会影响存储性能。</block>
  <block id="a85e0a264279b851fbcec367c181932e" category="list-text">借助 Azure NetApp Files 的卷重塑和动态服务级别功能，您可以根据稳定状态工作负载进行规模估算，从而防止过度配置，从而优化成本。</block>
  <block id="4e24ca7789e0b9320e302b8efa2caf9f" category="list-text">Cloud Volumes ONTAP 的存储效率，云分层和实例类型修改功能可以提供最佳的存储添加和扩展方式。</block>
  <block id="d7a87fa8fc914cf57f38eff05d53faa2" category="list-text">防止过度配置存储资源仅在需要时添加。</block>
  <block id="940eacbcb0faa8c3b1e0d995c154f693" category="list-text">通过高效的 Snapshot 副本和克隆，您可以快速创建副本，而不会对性能造成任何影响。</block>
  <block id="a9e4a9fcd1f9bf0a9d0d0b2c0f198db5" category="list-text">通过从 Snapshot 副本快速恢复来帮助解决勒索软件攻击。</block>
  <block id="caf9b805c37cab661d4e3a26b7f71109" category="list-text">提供基于增量块传输的高效区域灾难恢复以及跨区域的集成备份块级别，从而提供更好的 RPO 和 RTO 。</block>
  <block id="658fb5ef00749e8af5a974f612adea9b" category="section-title">假设</block>
  <block id="a9e63f2a8549d717b777806268a0c0cb" category="list-text">已启用 SnapMirror 技术或其他相关数据迁移机制。从内部环境到任何超大规模云，有许多连接选项可供选择。使用适当的路径并与相关网络团队合作。</block>
  <block id="478a13ed02b948c9cfd89a6197062012" category="admonition">请联系 NetApp 解决方案架构师和相应的超大规模云架构师来规划和估算存储以及所需数量的主机。NetApp 建议先确定存储性能要求，然后再使用 Cloud Volumes ONTAP 规模估算器以正确的吞吐量最终确定存储实例类型或相应的服务级别。</block>
  <block id="c748546b5854ecb146d9caa41d781bdb" category="section-title">详细的架构</block>
  <block id="1a8ac44404b1e5888d83801ac116ff66" category="inline-image-macro">企业混合云架构</block>
  <block id="855b05f645c80247a3f11392cab187c2" category="paragraph"><block ref="855b05f645c80247a3f11392cab187c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd558e50adcdcb0d667a4790f70f75a9" category="paragraph">要在 GCP 上配置 GCVE 环境，请登录到 GCP 控制台并访问 VMware 引擎门户。</block>
  <block id="fb33f758c28f8ef8d56e41f74b4c47ab" category="paragraph">单击 " 新建私有云 " 按钮，然后输入所需的 GCVE 私有云配置。在 " 位置 " 上，确保在部署 CVS/CVO 的同一区域 / 区域部署私有云，以确保最佳性能和最低延迟。</block>
  <block id="63b31ca49de01854f780d1e1722cd1c1" category="paragraph">前提条件：</block>
  <block id="d79b0ab3cbae1dcd79007a97d26af5b1" category="list-text">设置 VMware 引擎服务管理员 IAM 角色</block>
  <block id="72a7f08f840ab91a28a2558393971c47" category="inline-link-macro">启用 VMware 引擎 API 访问和节点配额</block>
  <block id="a88d670b04af96a871dad56001e8f742" category="list-text">确保 CIDR 范围不会与任何内部或云子网重叠。CIDR 范围必须为 /27 或更高。</block>
  <block id="33d7d6c631c2d2cb3608445ef761fe16" category="paragraph"><block ref="33d7d6c631c2d2cb3608445ef761fe16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65bdc0673006b33d0c876e18a9a98787" category="paragraph">注意：创建私有云可能需要 30 分钟到 2 小时。</block>
  <block id="44f55a60cc8f70d1e10efc62b75eeddc" category="doc">适用于超大规模云提供商的 VMware 的 NetApp 解决方案</block>
  <block id="f21c97f5b239021bb3f13d148516abb4" category="paragraph">选择您的云，让 NetApp 完成其余工作！</block>
  <block id="c1304f98c6be845a236d7a27951ece4f" category="paragraph"><block ref="c1304f98c6be845a236d7a27951ece4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca4ac823f3f130f3c78d6ac26ba9f46b" category="admonition">要查看特定超大规模提供商的功能，请单击该超大规模提供商的相应选项卡。</block>
  <block id="addac5e706b2148d9c7b3bbe2d2fcdde" category="paragraph">从以下选项中选择，跳至所需内容部分：</block>
  <block id="06262015df4851b380189212274a0e3e" category="inline-link-macro">超大规模部署中的 VMware</block>
  <block id="7f08237a127b62af444f720f15216cee" category="list-text"><block ref="7f08237a127b62af444f720f15216cee" category="inline-link-macro-rx"></block></block>
  <block id="c774c23e9a97e08bfa096f1cbf18cc17" category="inline-link-macro">NetApp 存储选项</block>
  <block id="d3fc27ff58dc3a0d839a16af858e7999" category="list-text"><block ref="d3fc27ff58dc3a0d839a16af858e7999" category="inline-link-macro-rx"></block></block>
  <block id="833413440fbbe13837d8b58256cfba65" category="paragraph">与内部部署一样，规划基于云的虚拟化环境对于成功创建 VM 和迁移生产就绪环境至关重要。</block>
  <block id="94772ee4b241fe0706c3aaef6e3a4505" category="inline-link-macro">支持的 NetApp 存储选项</block>
  <block id="67b586cdf9703ba67abe711415768cc0" category="paragraph">请访问 <block ref="01a9bd21bfc714c8dec8aabc5b88eda7" category="inline-link-macro-rx"></block> 有关详细信息 ...</block>
  <block id="8a69f1bae52e494c6960f92a27390dcf" category="paragraph">要将 VMware Cloud 连接到 FSX ONTAP ，请完成以下步骤：</block>
  <block id="7ca6fbd8bbb6725fab7413e4179738f6" category="list-text">完成 VMware Cloud 部署并连接到 AWS VPC 后，您必须将适用于 NetApp ONTAP 的 Amazon FSx 部署到新的 VPC 中，而不是原始连接的 VPC 中（请参见下面的屏幕截图）。如果在连接的 VPC 中部署了 FSX （ NFS 和 SMB 浮动 IP ），则无法访问它。请注意， Cloud Volumes ONTAP 等 iSCSI 端点在连接的 VPC 上运行正常。</block>
  <block id="da6646a18f048724eb432bf61285ca7f" category="paragraph"><block ref="da6646a18f048724eb432bf61285ca7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85dd65f7163e587c050ea8931a368ae" category="list-text">在同一地区部署一个额外的 VPC ，然后将适用于 NetApp ONTAP 的 Amazon FSx 部署到新的 VPC 中。</block>
  <block id="c78834afa7d24e921aa4d756d0a6409f" category="paragraph">通过在 VMware Cloud 控制台中配置 SDDC 组，可以使用所需的网络配置选项连接到部署了 FSX 的新 VPC 。在第 3 步中，验证是否已选中 " 为组配置 VMware Transit Connect 将在每个附件和数据传输中产生费用 " ，然后选择创建组。完成此过程可能需要几分钟时间。</block>
  <block id="f91a2b452c63b5ccfcb4c39c2957c74e" category="paragraph"><block ref="ca83e0582a449c1b4399270025e1cc4a" category="inline-image-macro-rx" type="image"></block>
<block ref="9232dff72050e533bd1e173e5a0dd48c" category="inline-image-macro-rx" type="image"></block>
<block ref="5a108f597862e683ab9463f7c3ba6df6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fae60fbb10da5c3df46ec8ae03cd29b5" category="inline-link-macro">连接外部 VPC 的说明</block>
  <block id="784ad3266f853af20763bb78f5eec87a" category="list-text">将新创建的 VPC 附加到刚刚创建的 SDDC 组。选择外部 VPC 选项卡，然后按照进行操作 <block ref="19928d01a63fe78e1303b296c2046666" category="inline-link-macro-rx"></block> 组。完成此过程可能需要 10 到 15 分钟。</block>
  <block id="14466a85376e8776f891db4cb3c38c6c" category="paragraph"><block ref="dd1eb585a08c833cec9544c048af36b6" category="inline-image-macro-rx" type="image"></block>
<block ref="38542de5661e382aba9345fe6e5a991b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8acea1c4fcca87631ca127e2bc757f13" category="inline-link-macro">AWS 传输网关</block>
  <block id="77508ef16874a250b66be2f90fc59918" category="list-text">在外部 VPC 过程中，系统会通过 AWS 控制台通过资源访问管理器提示您访问新的共享资源。共享资源为 <block ref="ccce2323414354d76e9cea0c1df9221b" category="inline-link-macro-rx"></block> 由 VMware Transit Connect 管理。</block>
  <block id="ac81300f843e6b91377e64a8edb819c2" category="paragraph"><block ref="63de05888c0a11205c33fd560dba3bc5" category="inline-image-macro-rx" type="image"></block>
<block ref="0455c56bd9863ddfae4079b5aabd42e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf415daee6d6f894a54f025534ba071" category="list-text">创建传输网关附件。</block>
  <block id="e222d36183b455bb51f289144826c239" category="paragraph"><block ref="e222d36183b455bb51f289144826c239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b6693c4eff7f7923c59277702b441a9" category="list-text">返回 VMC 控制台，接受 VPC 连接。完成此过程大约需要 10 分钟。</block>
  <block id="64d5d06ed03c085c4f5ce23ff6eeddac" category="paragraph"><block ref="64d5d06ed03c085c4f5ce23ff6eeddac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9b85dc0e557eb865bfa9ae84e251623" category="list-text">在外部 VPC 选项卡中，单击路由列中的编辑图标，然后添加以下所需的路由：</block>
  <block id="ae6434a5ebe0bad2f978fef8e0ed9efe" category="inline-link-macro">浮动 IP</block>
  <block id="06651ace1eab88d681ca9a8852bf26e2" category="list-text">适用于 NetApp ONTAP 的 Amazon FSX 的浮动 IP 范围的路由 <block ref="14a98976d888daccbd07561411cfd6fa" category="inline-link-macro-rx"></block>。</block>
  <block id="5e16e681111a1a5b2dc805d69827532f" category="list-text">Cloud Volumes ONTAP 的浮动 IP 范围的路由（如果适用）。</block>
  <block id="efffbab523616433e2c1ea67cbcaab53" category="list-text">新创建的外部 VPC 地址空间的路由。</block>
  <block id="daa8a39ba75e8ac01fd26d579ce35fd9" category="paragraph"><block ref="daa8a39ba75e8ac01fd26d579ce35fd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="853349bb92eccb477b47eef3b8a5d9e2" category="inline-link-macro">防火墙规则</block>
  <block id="499ca5dd26dbcc4c89a04ac771b316a6" category="inline-link-macro">详细步骤</block>
  <block id="14c6314f2ae331d7f9a01ac04a75cd2b" category="list-text">最后，允许双向流量 <block ref="0756551700fd3215666355892b2f3692" category="inline-link-macro-rx"></block> 用于访问 FSX/CVO 。请按照以下说明操作 <block ref="583f77470215de8611ddf3fba5fc6512" category="inline-link-macro-rx"></block> SDDC 工作负载连接的计算网关防火墙规则。</block>
  <block id="098b98cba4d6766e7de663adf0fdabb0" category="paragraph"><block ref="098b98cba4d6766e7de663adf0fdabb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f4480b9caed7d956fd6071b4cce03b9" category="list-text">为管理和计算网关配置防火墙组后，可以按如下方式访问 vCenter ：</block>
  <block id="f1c1b29fad3f2bdb9d8d054686b86542" category="paragraph"><block ref="f1c1b29fad3f2bdb9d8d054686b86542" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8b86f112029b19bf6451ba4624a4090" category="paragraph">下一步是验证是否已根据您的需求配置 Amazon FSX ONTAP 或 Cloud Volumes ONTAP ，以及是否已配置卷以从 vSAN 卸载存储组件以优化部署。</block>
  <block id="e7441dbfabeaebba75ddd1bf2bcf25e9" category="section-title">用例 1 ：优化存储</block>
  <block id="b9a8c3d27aa6638e02992c8b76fea769" category="paragraph">在使用 RVtools 输出执行规模估算练习时，显而易见，功率（ vCPU/vMem ）与存储是并行的。企业往往会发现自己处于存储空间所需的驱动器大小远远超出所需的容量的情况。</block>
  <block id="cb575e0b8e023ca0a1789ea03bdb86fd" category="paragraph">通过集成 NetApp Cloud Volumes ，企业可以通过简单的迁移方法实现基于 vSphere 的 Cloud 解决方案，无需重新整合，无需 IP 更改，也无需架构更改。此外，通过这种优化，您可以扩展存储占用空间，同时将主机数量保持在 vSphere 所需的最低水平，但不会更改可用的存储层次结构，安全性或文件。这样，您可以优化部署并将总 TCO 降低 35 – 45% 。通过这种集成，您还可以在几秒钟内将存储从热存储扩展到生产级性能。</block>
  <block id="9ae8084cfbf8c00bc50891fe51bb70b4" category="section-title">用例 2 ：云迁移</block>
  <block id="40c30ee45ee11e766ec77dfd0d98cef0" category="paragraph">企业面临着将应用程序从内部数据中心迁移到公有云的压力，原因有多种：即将到期的租约；从资本支出（ capex ）支出迁移到运营支出（ opex ）支出的财务指令；或者只是自上而下的要求，将所有内容迁移到云。</block>
  <block id="4744ec437cce262edc7110652b69ab21" category="paragraph">速度至关重要时，只有简化的迁移方法才可行，因为要适应云的特定 IaaS 平台，重新整合和重构应用程序的速度缓慢且成本高昂，通常需要数月时间。将 NetApp Cloud Volumes 与为子系统连接的存储（包括 RDM 以及应用程序一致的 Snapshot 副本和 HCX ）提供的高效带宽 SnapMirror 复制相结合，从而实现云特定的迁移（例如 Azure Migrate ）或用于复制 VM 的第三方产品），这种过渡比依赖耗时的 I/O 筛选器机制更容易。</block>
  <block id="d393e254c1adb8df50cfc41394c68645" category="section-title">用例 3 ：数据中心扩展</block>
  <block id="90c724dd3ba1ec0f533f7fb73a10323a" category="paragraph">当数据中心因季节性需求峰值或仅仅是稳定的有机增长而达到容量限制时，迁移到云托管的 VMware 以及 NetApp Cloud Volumes 是一项轻松的解决方案。利用 NetApp Cloud Volumes ，可以跨可用性区域提供高可用性并提供动态扩展功能，从而轻松创建，复制和扩展存储。利用 NetApp Cloud Volumes 可以消除对延伸型集群的需求，从而最大限度地减少主机集群容量。</block>
  <block id="0b95336d0f31a3bd4775f96c750bb9bc" category="section-title">用例 4 ：灾难恢复到云</block>
  <block id="c2aee451a27e7cf3993f462ee5b760e9" category="paragraph">在传统方法中，如果发生灾难，则复制到云的 VM 需要先转换到云自己的虚拟机管理程序平台，然后才能还原，而不是在危机期间处理的任务。</block>
  <block id="772dec0515d132f26bfa87cb31b5758d" category="paragraph">通过使用内部 SnapCenter 和 SnapMirror 复制以及公有云虚拟化解决方案将 NetApp Cloud Volumes 用于子系统连接的存储，可以设计一种更好的灾难恢复方法，以便在完全一致的 VMware SDDC 基础架构上恢复 VM 副本以及云专用恢复工具（例如 Azure Site Recovery ）或 Veeam 等第三方工具。此外，您还可以通过此方法快速执行灾难恢复演练并从勒索软件中恢复。这样，您还可以通过按需添加主机来扩展到完全生产环境，以供测试或在灾难期间使用。</block>
  <block id="24d0e6ab8003b406cf7e3f42363acbf5" category="section-title">用例 5 ：应用程序现代化</block>
  <block id="59e56fb67c730af04acf8a13665cadb3" category="paragraph">应用程序进入公有云后，企业将希望利用数百种功能强大的云服务来实现现代化和扩展。借助 NetApp Cloud Volumes ，现代化过程非常简单，因为应用程序数据不会锁定在 vSAN 中，并允许数据在包括 Kubernetes 在内的各种用例中移动。</block>
  <block id="eea420abccd820355b4bddd3524ae083" category="paragraph">无论您是以全云还是混合云为目标， NetApp Cloud Volumes 都可以提供出色的选项来部署和管理应用程序工作负载以及文件服务和块协议，同时通过将数据需求无缝地迁移到应用程序层来降低 TCO 。</block>
  <block id="cd51ff9774803e84c79e8ab19bb7ffd2" category="paragraph">无论使用何种情形，都可以选择您最喜欢的云 / 超大规模云提供商以及 NetApp Cloud Volumes ，快速实现云优势，跨内部和多个云实现一致的基础架构和运营，工作负载的双向可移植性以及企业级容量和性能。</block>
  <block id="2993778cba8ea9a69af4ff9dc7e18fb8" category="paragraph">这是用于连接存储的熟悉过程。请记住，这只是数据位置随新名称而变化；工具和流程都保持不变， NetApp Cloud Volumes 有助于优化整体部署。</block>
  <block id="5f1bd6ade489565bebba9a771b93fe70" category="paragraph">概述在规划混合云或云优先部署时对 IT 组织至关重要的使用情形。</block>
  <block id="0812fc943ecbd9a54d88fb25729d0aa5" category="section-title">常见使用情形</block>
  <block id="f136615e6f2c1b330afb72bf4a45b4a4" category="paragraph">使用情形包括：</block>
  <block id="3481fb80f122383c65ff8c6c8fd8c943" category="list-text">灾难恢复，</block>
  <block id="4127bac8297e2af8866315910651ce47" category="list-text">在数据中心维护期间托管工作负载， * 快速激增，需要额外的资源，但不能满足本地数据中心的配置要求。</block>
  <block id="20b1c73b5938d2d878aa1d96fee7f1b2" category="list-text">VMware 站点扩展，</block>
  <block id="5fe13b2b805496310dbaa281d7325877" category="list-text">快速迁移到云，</block>
  <block id="b278a6d011d590bb350b9cb81c21a732" category="list-text">开发 / 测试，和</block>
  <block id="bc262005b263505cc0464e05c4324687" category="section-title">IT 发展历程中的一个过程</block>
  <block id="cfdb9aabb4aedf8cad2e330ba5a516a3" category="paragraph">大多数企业都在经历转型和现代化之旅。在这一过程中，各家公司正在尝试利用现有的 VMware 投资，同时利用云优势并探索尽可能无缝地迁移过程的方法。这种方法将使他们的现代化工作变得非常简单，因为数据已经在云中。</block>
  <block id="0362604333fcf179ebf8b873f8f8c0ec" category="paragraph">我们来考虑一下这种情况：</block>
  <block id="b401aa039e47ba98bfaca10532e40d08" category="paragraph">客户只需要五台主机来满足 CPU 和内存需求，但需要大量存储需求，并需要 12 台主机来满足存储需求。这一要求最终确实会让财务规模大得多，因为他们只需要增加存储即可购买额外的动力。</block>
  <block id="7c25e9d8a9748905f5d456e20a93b413" category="paragraph">在规划云采用和迁移时，始终需要评估最佳方法并采取最简单的方法来减少总投资。对于任何应用程序迁移，最常见且最简单的方法是重新托管（也称为提升和移动），在这种情况下不会进行虚拟机（ VM ）或数据转换。在将 NetApp Cloud Volumes 与 VMware 软件定义的数据中心（ SDDC ）结合使用的同时，还可以作为 vSAN 的补充，从而提供一个轻松的升降和移动选项。</block>
  <block id="e673b6ab6c5649a4df8e874aaa9017b9" category="sidebar">支持的配置</block>
  <block id="5d7b876a73a9025080fbf6dd921d1fdd" category="sidebar">数据迁移和数据保护</block>
  <block id="9b699c59be5ba510cd9c430a31843b23" category="sidebar">数据迁移</block>
  <block id="ef55a9d1028eac237813e753d20134df" category="sidebar">适用于公有云的 VMware</block>
  <block id="27c378e12a7c59dc5aa13b13cc6cecff" category="sidebar">基于超大规模云的 VMware Cloud</block>
  <block id="452b0b090c1c37a0d467a8df764fd81f" category="sidebar">超大规模云中的 NetApp 存储</block>
  <block id="2190ab0d2f6281b2f3a73e0fc8e1f560" category="sidebar">总结和结论</block>
  <block id="75fcfea0185575f935a7f5f149efd8ca" category="sidebar">VMware Hybrid Cloud 用例</block>
  <block id="e251010eb0cac5793d760ab2e5f51473" category="sidebar">用例概述</block>
  <block id="6f4bb0fa6fee4cf4ae1b8b1fc16e17cb" category="sidebar">传统 NetApp HCI 解决方案</block>
  <block id="4a7272ea95323d5fef2e377b91b5f16d" category="inline-link-macro">FSX ONTAP 作为子系统连接的存储</block>
  <block id="3017a9031d66c55b0258c102decfd1b9" category="inline-link-macro">Cloud Volumes ONTAP （ CVO ）作为子系统连接的存储</block>
  <block id="1ffaf40c19facb6829b48b667d1dcaa3" category="inline-link-macro">Azure NetApp Files （ ANF ）作为子系统连接的存储</block>
  <block id="9bb210767ccb9c085c816c82f3b6b1cb" category="inline-link-macro">Cloud Volumes Service （ CVS ）作为子系统连接的存储</block>
  <block id="712d83d9ce8f26363e9bfd1cba104b88" category="sidebar">NetApp E 系列和 Commvault 数据平台 V11</block>
  <block id="aa8156dc9f7aa240e4f412f2f5fedaf5" category="sidebar">使用 Veeam Backup Replication 9.5 的 E 系列和 EF 系列参考架构和存储最佳实践</block>
  <block id="74e4bedcc2ff5b37a8770caa0ef72975" category="sidebar">使用 NetApp E 系列存储部署 Veritas NetBackup</block>
  <block id="029f60716c50acd9acf9ce4a9394c91a" category="sidebar">采用适用于多租户基础架构的 HyTrust 的 FISMA 的 NIST 安全控制</block>
  <block id="e63695c4dea40eefb2ef481c7b242192" category="open-title">所有更改</block>
  <block id="6fb2815b4c371ee082a84cc14539d4cb" category="open-title">企业级应用程序</block>
  <block id="fb0ad99371abb3d02d60add8160c6dd9" category="section-title">使用 NetApp Cloud Manager 对 CVO 和 Connector 进行 AWS 身份验证的要求</block>
  <block id="5edbe8c55546db896b55871b44a39263" category="cell">* 日期 *</block>
  <block id="12cd1425f32ad289dba28e35ae9096fb" category="cell">* 解决方案区域 *</block>
  <block id="b96941ac46daa357b1782f017746a57b" category="cell">* 变更问题描述 *</block>
  <block id="f63616bb6a8255ed08089231c746f285" category="cell">2021 年 6 月 12 日</block>
  <block id="16784caec2e047ddf59bd5a51bd35a73" category="cell">2021年11月15日</block>
  <block id="1c20ad7a11d1c2856906d55171b50126" category="cell">向 NVA-1160 添加了一个新的视频演示：使用 Astra Control 在 CI/CD 管道中保护数据</block>
  <block id="5cdb842b21b9f980df2b3ab63ee9a9e6" category="cell">新内容： Confluent Kafka 的最佳实践</block>
  <block id="38562890365e144b467ec2813a6377f2" category="cell">2021 年 2 月 11 日</block>
  <block id="dfd39862c9cc158ad7b0e4e1e9a3024a" category="cell">2021 年 10 月 29 日</block>
  <block id="e7c456cd85cc15bd3faf7b65c0833d3e" category="cell">新内容： TR-4657 — NetApp 混合云数据解决方案： SPARK 和 Hadoop</block>
  <block id="815425a7766095190649a3f9ecbc1828" category="cell">2021年10月26日</block>
  <block id="8493c4f1797303a6de2524a60adcf058" category="cell">2021年10月18日</block>
  <block id="ade15f89ccc27958a743a992cea8c574" category="cell">TR-4908 —采用 SnapCenter 的混合云数据库解决方案</block>
  <block id="622eda32248f1c4d1fc31dd78ec74c4a" category="cell">2021年10月14日</block>
  <block id="f6ecd264493db5fac4b21f19be4eb69d" category="cell">添加了 NetApp 与 VMware VCF 博客系列的第 1-4 部分</block>
  <block id="83a11da06ed8a3e338b5e8d2991cae0c" category="cell">2021年10月4日</block>
  <block id="c95696f6146a5b8b56c74d4349687ec6" category="cell">添加了一个新的视频演示：使用 Astra 控制中心将工作负载迁移到 NVA-1160</block>
  <block id="4f41bdb2ec81835b66ffbbd18feea656" category="cell">2021 年 9 月 23 日</block>
  <block id="32ff1e0d02ec482c64fdac1af2a49372" category="cell">新内容： NetApp XCP 最佳实践</block>
  <block id="42246d8ef9280d19cf1326197310630a" category="cell">2021 年 9 月 21 日</block>
  <block id="10c87c454d38afc0644c8c1fb75fa524" category="cell">适用于 VMware vSphere 管理员的新内容或 ONTAP ， VMware vSphere 自动化</block>
  <block id="faaef04f2f0bb7bed9504fc3d357ba59" category="cell">2021年9月9日</block>
  <block id="80245b1f322b07a9fcd385bb375d8182" category="cell">将 F5 BIG-IP 负载平衡器与 OpenShift 的集成添加到 NVA-1160 中</block>
  <block id="023cd4d7ed373df0d803d414e2e452bf" category="cell">2021年8月5日</block>
  <block id="afb6b7f715f1bf6492efb8f3c279ddd7" category="cell">为基于 Red Hat OpenShift 的 NetApp Astra 控制中心 NVA-1160 增加了新的技术集成</block>
  <block id="2cd99fd0d69d62395a72dc7d4684299c" category="cell">2021 年 7 月 21 日</block>
  <block id="e88b179e97a156d13d1c9c4163513205" category="cell">2021 年 2 月 7 日</block>
  <block id="9f99e3ea14c0a44dde0fd7db13fa3bef" category="cell">TR-4897 — Azure NetApp Files 上的 SQL Server ： Real Deployment 视图</block>
  <block id="83d39ff0c36403ca3e183af9ca091a71" category="cell">2021 年 6 月 16 日</block>
  <block id="2891cb0fe31606ff172d0be4ec81732f" category="cell">添加了一个新的视频演示《安装 OpenShift 虚拟化：采用 NetApp 的 Red Hat OpenShift 》</block>
  <block id="77d29c989f99997794df55b2d9053ae8" category="cell">添加了一个新的视频演示：使用 OpenShift 虚拟化部署虚拟机：使用 NetApp 部署 Red Hat OpenShift</block>
  <block id="fab25e19f7e186358ed7f1268e7af3b4" category="cell">2021 年 6 月 14 日</block>
  <block id="96da300b5faf4ae3a5ca09afabba4273" category="cell">添加了解决方案：基于 Azure NetApp Files 的 Microsoft SQL Server</block>
  <block id="67c877d4abd9acdbb0fa62c3720b6d60" category="cell">2021年6月11日</block>
  <block id="a14851e0e2cb4c8e9176cdea01500288" category="cell">新增了一个视频演示：使用 Astra Trident 和 SnapMirror 将工作负载迁移到 NVA-1160</block>
  <block id="c5d2015481e39976c67e40778a449a2d" category="cell">2021年6月9日</block>
  <block id="c4aad26d0bd9fb92610a1b5b3390bd46" category="cell">在采用 NetApp 的 Red Hat OpenShift 上的 NVA-1160 —适用于 Kubernetes 的高级集群管理中添加了一个新的用例</block>
  <block id="53977250e4a69cab3688fcbede8fb73a" category="cell">2021 年 5 月 28 日</block>
  <block id="9c23aa040a3dc51dbbf59463247f4fec" category="cell">为 NVA-1160 — NetApp ONTAP 的 OpenShift 虚拟化添加了一个新的用例</block>
  <block id="c02e5ac689072495b8af780302105253" category="cell">2021 年 5 月 27 日</block>
  <block id="f5abcac882b8caa17d3af1c14144f503" category="cell">为 NVA-1160-OpenShift 上的多租户添加了一个新的用例，其中包含 NetApp ONTAP</block>
  <block id="3202abe9084b2d9ec5b0b162721978e7" category="cell">2021 年 5 月 26 日</block>
  <block id="d58aa75910c54a80c6ba4de7e7f6949f" category="cell">添加了 NVA-1160 —采用 NetApp 的 Red Hat OpenShift</block>
  <block id="a0be3ecb819e8e7215f946964346f547" category="cell">2021 年 5 月 25 日</block>
  <block id="95a74db23b085df59ef6412199e9e791" category="cell">添加了博客：在 Red Hat OpenShift 上安装 NetApp Trident —如何解决 Docker ‘的 " 所有请求 " 问题描述！</block>
  <block id="2dec0489948dbe7f63f68743a085e98c" category="cell">2021 年 5 月 19 日</block>
  <block id="0db377921f4ce762c62526131097968f" category="cell">常规</block>
  <block id="9045bfbeff51b83f9752fe549021a181" category="cell">添加了指向 FlexPod 解决方案的链接</block>
  <block id="0a40e3c91a3a55c9a37428c6d194d0e5" category="cell">AI</block>
  <block id="af3192eaae3cb09641db4adcc45ed625" category="cell">将 AI 控制平面解决方案从 PDF 转换为 HTML</block>
  <block id="8ff5be8d16e86e5284f8ba8a3428459a" category="cell">2021 年 5 月 17 日</block>
  <block id="a88789a4f83f213b256b57eb0884fd1d" category="cell">已将解决方案反馈磁贴添加到主页</block>
  <block id="027fb9451c491d9dcfb7db05f552788d" category="cell">2021年5月11日</block>
  <block id="3e62d5f1a7f1b6907ad1ecaf11282dac" category="cell">增加了在 NFS 上自动部署 Oracle 19c for ONTAP 的功能</block>
  <block id="d2422eca0ff6f19afb6e1206b15fbe01" category="cell">2021 年 10 月 5 日</block>
  <block id="85c96a5f13e6dea61e003704f8d456e2" category="cell">新视频：如何在 NetApp 和 VMware Tanzu Basic 中使用 VVOL ，第 3 部分</block>
  <block id="29e9b684dbbdf5cc1828da82a146781d" category="cell">2021 年 6 月 5 日</block>
  <block id="508db167da7d74fc86c3f8024ce04558" category="cell">添加了指向 FlexPod 数据中心上使用 Cisco UCS 和基于 FC 的 NetApp AFF A800 的 Oracle 19c RAC 数据库的链接</block>
  <block id="85fbf94a3ecf9a3af4a93f80a3681fe1" category="cell">2021 年 5 月 5 日</block>
  <block id="608f33919f16e9a23bd532ad6bcf480a" category="cell">添加了 FlexPod Oracle NVA （ 1155 ）和自动化视频</block>
  <block id="4dc6e14d2ad9dafd2cd72f8c77d22bea" category="cell">2021 年 3 月 5 日</block>
  <block id="3d21a9c32818fc58b044121ce91e053c" category="cell">桌面虚拟化</block>
  <block id="4174d4c17e4b11e07d8dd581e16ba56c" category="cell">添加了指向 FlexPod 桌面虚拟化解决方案的链接</block>
  <block id="b3cae16f1f895f4f9ceae98617a3bf0d" category="cell">2021年4月30日</block>
  <block id="2764512d2fc00264d149a6142151aa1a" category="cell">视频：如何在 NetApp 和 VMware Tanzu Basic 中使用 VVOL ，第 2 部分</block>
  <block id="4996fa0acf5cc54e889a50e9bdd2e56b" category="cell">2021 年 4 月 26 日</block>
  <block id="9c5316849ca2429400f8979f0ee0d963" category="cell">新增博客：《将 VMware Tanzu 与 ONTAP 结合使用，加快 Kubernetes 之旅》</block>
  <block id="911da11d01e00e9aa94c5b03b2e6e2cc" category="cell">2021 年 6 月 4 日</block>
  <block id="06cfdb63e0660d09f203a21e28520a1e" category="cell">添加了 " 关于此存储库 "</block>
  <block id="32edd80de3642c58e1a05df5f3e458e1" category="cell">2021 年 3 月 31 日</block>
  <block id="bbb1c8f8182403001f2e1f69085ca2ad" category="cell">添加了 TR-4886 — AI 在边缘推理：采用联想 ThinkSystem 解决方案设计的 NetApp ONTAP</block>
  <block id="d61c9a3748e1dd56535fbdaaa3e39eab" category="cell">2021 年 3 月 29 日</block>
  <block id="8575a367028bec3e86e25b102a8dced1" category="cell">添加了 NVA-1157 — NetApp Storage 解决方案中的 Apache Spark 工作负载</block>
  <block id="8f10e64b04f6cc56cf66fd4f4eb0f4d9" category="cell">2021 年 3 月 23 日</block>
  <block id="7998f8ad3cabe02af607385cae780ce1" category="cell">视频：如何在 NetApp 和 VMware Tanzu Basic 中使用 VVOL ，第 1 部分</block>
  <block id="f86fe8ec70f2003923e4000589747208" category="cell">2021年3月9日</block>
  <block id="eea51e9c0dffabdea48ada8f53bbf0f5" category="cell">添加了 E 系列内容；按类别分类的 AI 内容</block>
  <block id="0b218fa381bfd1c86fff15d165ab23a0" category="cell">2021 年 4 月 3 日</block>
  <block id="932af944058a758da919ca59d1af640b" category="cell">新内容： NetApp 解决方案自动化入门</block>
  <block id="4be9c930c1a8a198115d499cb3223d9e" category="cell">2021 年 2 月 18 日</block>
  <block id="0c560038af98c5401dd10202e7937acd" category="cell">添加了 TR-4597 —适用于 ONTAP 的 VMware vSphere</block>
  <block id="aa1c3ec5e6dcfb94555ff987f061f1a0" category="cell">2021 年 2 月 16 日</block>
  <block id="3ecf1285a084b58473a7873e3f33e74a" category="cell">为 AI Edge 推理添加了自动化部署步骤</block>
  <block id="8138d0c3e613508050b6fec12c4322c7" category="cell">2021 年 3 月 2 日</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="cell">SAP</block>
  <block id="91171755730ad15e6d79b5cb6682a8f1" category="cell">为所有 SAP 和 SAP HANA 内容添加了登录页面</block>
  <block id="e5099bd65458f8a8556c830ac4759296" category="cell">2021年2月1日</block>
  <block id="09689218a7f330554f4e28a18e9e14a6" category="cell">采用 NetApp VDS 的 VDI ，为 GPU 节点添加了内容</block>
  <block id="c487c48f1528e49e3cb129fdbdd79990" category="cell">2021年1月6日</block>
  <block id="868f7f9e78f90bcf0597030ffefd449b" category="cell">全新解决方案：采用 NVIDIA DGX A100 系统和 Mellanox 系列以太网交换机的 NetApp ONTAP AI （设计和部署）</block>
  <block id="0663765430d1ca93138f13429aef7c37" category="cell">2020年12月22日</block>
  <block id="a4aae8f8849c453c6c67080c5d013301" category="cell">NetApp 解决方案存储库的初始版本</block>
  <block id="18a2eb3f7faf7c44e3062e78cbeff089" category="inline-link-macro">SAP 解决方案存储库</block>
  <block id="412b2ee09f2fbaf8cddb69ee6fe43a2e" category="admonition">有关 SAP 和 SAP HANA 更新的详细信息，请参阅中每个解决方案的 " 更新历史记录 " 内容 <block ref="c4ed54a973fb1aa472c2443732d93c13" category="inline-link-macro-rx"></block>。</block>
  <block id="b98a6acc7ef428f1ae11e5177447df8c" category="paragraph">对于云，如果内部和云之间的连接为直接连接（ AWS ）， ExpressRoute （ Azure ）或云互连（ GCP ），则可以遵循类似的内部迁移工作流。</block>
  <block id="76e3e2a4e56301dafc50613d96fd624e" category="section-title">部署步骤— NAS</block>
  <block id="62e9f0426675b856daf874c75830c213" category="inline-link-macro">XCP 的前提条件。</block>
  <block id="4f6583b152ef684b4492414bcdcdf877" category="list-text">满足一节中详细介绍的前提条件 <block ref="958d961a425946e5195ca036cea97fab" category="inline-link-macro-rx"></block></block>
  <block id="0957326f089aaf98a5b7b9110a2675cd" category="section-title">部署步骤— HDFS/MapRFS 数据迁移</block>
  <block id="1f43fc63f63aad0b707e06b0753182a1" category="paragraph">在本节中，我们将讨论名为 Hadoop 文件系统数据传输到 NAS 的新 XCP 功能，此功能可将数据从 HDFS/MapRFS 迁移到 NFS ，反之亦然。</block>
  <block id="368666825ffae5710ab122fb63937cee" category="paragraph">对于 MapRFS/HDFS 功能，您必须在非 root 用户环境中执行以下操作步骤。通常，非 root 用户为 HDFS ， mapr 或有权更改 HDFS 和 MapRFS 文件系统的用户。</block>
  <block id="9adbc05b1436b3e8962253577f1e6441" category="list-text">在命令行界面或用户的 .bashrc 文件中设置 CLASSPATH ， Hadoot_home ， NHDFS_libjvm_path ， lb_library_path 和 NHDFS_LIBHDFS_path 变量以及 `XCP` 命令。</block>
  <block id="2a0eda7a7937e303f9e18a57a033fcb8" category="list-text">NHDFS_LIBHDFS_path 指向 libhdfs.so 文件。此文件提供了 HDFS API ，用于在 Hadoop 分发版中交互和操作 HDFS/MapRFS 文件和文件系统。</block>
  <block id="13682a0461e750a2dfb4e86c2ddc1165" category="list-text">NHDFS_libjvm_path 指向 libjvm.so 文件。这是位于 JRE 位置的共享 Java 虚拟机库。</block>
  <block id="60ce276a5dde3f2d2e92b1986a2eb339" category="list-text">类路径指向使用（ Hadoop classpath – glob ）值的所有 JAR 文件。</block>
  <block id="84cbf778b2572cae5eba01d0ca330078" category="list-text">LD_library_path 指向 Hadoop 原生库文件夹位置。</block>
  <block id="68207eb9f168add2309e88b5223d57c6" category="paragraph">请根据 Cloudera 集群查看以下示例。</block>
  <block id="91328810a5559a740f522f4c5a1da5f1" category="paragraph">在此版本中，我们支持 XCP 扫描，复制和验证操作以及从 HDFS 到 NFS 的数据迁移。您可以从数据湖集群单个工作节点和多个工作节点传输数据。在 1.8 版中， root 用户和非 root 用户可以执行数据迁移。</block>
  <block id="dee4c2c7e685015e9f3cc1ad197f3ab5" category="section-title">部署步骤—非 root 用户将 HDFS/MaprFS 数据迁移到 NetApp NFS</block>
  <block id="5983f77acc016b8138698b32b0ab0405" category="list-text">按照 " 部署步骤 " 一节中的 1-9 步骤中所述的步骤进行操作。</block>
  <block id="c2765e27844a39bfc897cb964eec8711" category="list-text">在以下示例中，用户将数据从 HDFS 迁移到 NFS 。</block>
  <block id="e6f549e8013d1f24b8756cd11ff3083e" category="list-text">在 HDFS 中创建文件夹和文件（使用 `Hadoop FS -copyFromLocal` ）。</block>
  <block id="2433ce85404dd68893a2e4abb99843e4" category="list-text">检查 HDFS 文件夹中的权限。</block>
  <block id="befab6065ddb441f0b260ac75a8e84c8" category="list-text">在 NFS 中创建文件夹并检查权限。</block>
  <block id="02341ea695e862c3a2d89461b1b8bf37" category="list-text">使用 XCP 将文件从 HDFS 复制到 NFS 并检查权限。</block>
  <block id="46742b2c1e11cf6a3e230ec3da7e6800" category="admonition">有关 XCP 文件分析的高级架构，统计信息视图等基于图形用户界面的信息板视图以及文件分发视图详细信息，请参见博客文章<block ref="924a0428223d35821b584a5368c0e3e5" category="inline-link-rx"></block>。</block>
  <block id="21bd6427119f8d9a06a7c5bce95d28ac" category="paragraph">XCP 1.6 中用于自定义图形的 GUI 有限。要创建所需的图形，您可以使用命令行界面使用匹配的筛选器运行 `XCP` scan 命令。请参见以下示例。</block>
  <block id="7e9b65699b01d35aeff9dc16008da7a5" category="paragraph">XCP 复制和同步操作测试使用的测试平台与部署时使用的测试平台相同。我们创建了 100 万个文件，其中包括三组 8 K ， 16 K 和 1 MB 文件，并实时执行了更改。XCP 同步功能在文件级别执行从源到目标的差异增量更新。增量更新操作是以下四项操作中的一项或多项：重命名现有文件和文件夹，将数据附加到现有文件，删除文件和文件夹，以及添加其他硬链接，软链接和多链接。出于测试目的，我们重点关注重命名，附加，删除和链接操作。换言之，重命名，附加和删除等修改操作对 100 万个文件执行的更改率为 10% 到 90% 。</block>
  <block id="f599c9e924e3b854abd0ab58126fed43" category="paragraph">与以前的版本相比， XCP 1.6.3 和 1.7 提高了性能。下一节显示了对于 100 万个文件的 8 K ， 16 K 和 1 MB 大小， XCP 1.6.3 和 1.7 之间的同步性能比较。</block>
  <block id="b53776fdc2fd9fc721aaa6f03fd3d6a0" category="paragraph">下图显示了 XCP 1.6.3 与 1.7 （ 8 K 大小为 100 万个文件）的 XCP 同步性能结果。</block>
  <block id="5b201508f1de849d630f98c0001fdc29" category="paragraph">下图显示了 XCP 1.6.1 与 1.5 的 XCP 同步性能结果，其中 1 MB 大小的文件为 100 万个。</block>
  <block id="61b90da0c91ea6cb7c16bfaca41b4920" category="paragraph">根据此性能验证结果， NetApp 建议在内部和云端迁移数据时使用 XCP 1.7 。</block>
  <block id="d0ecdc77c2c944d380e9fef0e01eb119" category="paragraph">这是使用 ` -fmt` 命令的自定义报告。它会扫描所有目录，并将目录的名称，路径和大小转储到 CSV 文件中。您可以从电子表格应用程序对大小列进行排序。</block>
  <block id="1c026a57d7676d346dd0d44a2f595c1d" category="list-text">* 扫描。 * 提供 NAS 和 MapR/HDFS 数据的高级布局。</block>
  <block id="6b2c974b2ada5fba492b8dcda598b1f9" category="paragraph">下图显示了 GUI 中的 NetApp XCP 文件分析通信。</block>
  <block id="2d3aa3941d30870beb3abde613ce14b1" category="paragraph">XCP 1.7 中提供的实时源迁移支持允许从正在使用的数据源（读写活动）进行迁移。XCP 会删除迁移作业期间正在使用的文件，例如正在运行复制和同步，跳过的文件信息会捕获到 XCP 日志中。</block>
  <block id="b9611b870758eac97bd0c3bcb3fc8026" category="list-text">为每个 Azure NetApp 卷或云中的 Cloud Volume Service （高级服务级别）为 XCP 目录在内部创建一个 NFS 共享。</block>
  <block id="7d131526ee2a04107bbc50d52a29a7d7" category="cell">2021 年 12 月 21 日</block>
  <block id="c65463900a520919b522c30b6256e475" category="cell">添加了一个新的视频演示：利用 NetApp Astra Control 执行事后分析并将应用程序还原到 NVA-1160</block>
  <block id="5df9589990c71ed42c69a8bcc053d0d4" category="inline-link-macro">视频：利用 NetApp Astra Control 执行数据剖析和恢复应用程序</block>
  <block id="bc42bbaf219349a2ba37dfd4709b2003" category="doc">利用 NetApp Astra Control 执行数据剖析和恢复应用程序</block>
  <block id="10b5b21ed1ee90eca305b558caf7d03b" category="open-title">迁移</block>
  <block id="07b0eade4402d209b5dbe587a8ad3f6f" category="doc">在 AWS 上部署和配置虚拟化环境</block>
  <block id="a724b4fc4c5f79672a5c572466d5e001" category="doc">适用于 Azure 的 NetApp 子系统连接存储选项</block>
  <block id="ae295ef15cb155f8a1af7d255e34298d" category="doc">适用于 AWS 的 NetApp 子系统连接存储选项</block>
  <block id="ade1814101b0113034e0f446307b3db3" category="doc">适用于 Google Cloud Platform GCVE 的 NetApp 功能</block>
  <block id="6eb516b97eae0ab93b8d6aab35fbb764" category="section-title">适用于 GCVE 的 NetApp 存储选项</block>
  <block id="1d8249c60cae81d82fc5bfb80167babc" category="list-text">只能使用一个 vSAN 环境。因此，所有存储流量都将直接与生产工作负载竞争。</block>
  <block id="63b9fbe67e7dd9b9f7623683244cb7f8" category="doc">适用于 Azure AVS 的 NetApp 功能</block>
  <block id="1f0a2077c33b91b3daaaea05c7fadc07" category="section-title">在 Azure 中配置 AVS</block>
  <block id="cdac9a2e7f1dc52240712d4a191378e8" category="section-title">适用于 AVS 的 NetApp 存储选项</block>
  <block id="cf3ac5a0dae3780b356e57c121b3eab0" category="doc">在 Google Cloud Platform （ GCP ）上部署和配置虚拟化环境</block>
  <block id="ba756c1a2b93ad97a639914aae828a16" category="doc">适用于 AWS VMC 的 NetApp 功能</block>
  <block id="8658ccb747e94ac624861f5761a34716" category="section-title">在 AWS 中配置 VMC</block>
  <block id="e9f84da32eb512bd768458a738ed8aa6" category="section-title">适用于 VMC 的 NetApp 存储选项</block>
  <block id="bb01fec2870d3f698517f8471454637b" category="doc">在 Azure 上部署和配置虚拟化环境</block>
  <block id="c9b6ad26821d78c27282a65584d5f485" category="summary">NetApp 为内部和云端的强大虚拟化环境提供了许多最佳实践和解决方案。</block>
  <block id="ba64ee63cc4950b57bfb868fabec0db3" category="doc">NetApp 虚拟化解决方案</block>
  <block id="c775b248c55d253008c58d1ecd60e66f" category="doc">最终用户计算（ EUC ） / 虚拟桌面基础架构 (VDI) 解决方案</block>
  <block id="599725d881295777d3740ac33e953ced" category="paragraph">无论您是在内部还是在云中部署虚拟桌面， NetApp 都可以提供各种 EUC 或 VDI 解决方案来满足您的需求。</block>
  <block id="75fc33fcc3ef968fd3bf30c8da19bf9b" category="section-title">NetApp 虚拟桌面服务（ Virtual Desktop Services ， VDS ）</block>
  <block id="0593c3151fa252cdb4e997dd1255c608" category="paragraph">NetApp 虚拟桌面服务（ Virtual Desktop Service ， VDS ）可在主要公有云以及私有云中编排远程桌面服务（ Remote Desktop Services ， RDS ）。</block>
  <block id="3b96d802308faf1d6ff7e5563ea3d29b" category="paragraph">适用于 VDS 的可用解决方案：</block>
  <block id="2ccf8775db4706ac42c0a600eca82163" category="list-text"><block ref="2ccf8775db4706ac42c0a600eca82163" category="inline-link-macro-rx"></block></block>
  <block id="d4a0768ddf4ac449658ace06000fa76e" category="section-title">VMware Horizon 的最终用户计算</block>
  <block id="959f3d9cc20e0e9bfbc01c2d36cdc894" category="paragraph">NetApp 已针对 VMware Horizon 验证了涵盖多种计算配置的架构。可用的解决方案包括：</block>
  <block id="01606c27121f18cf231b4700ddf252e1" category="list-text"><block ref="01606c27121f18cf231b4700ddf252e1" category="inline-link-macro-rx"></block></block>
  <block id="4e5b466ff852e362d888b555cdcf62b7" category="list-text"><block ref="4e5b466ff852e362d888b555cdcf62b7" category="inline-link-macro-rx"></block></block>
  <block id="06e0780100d16763670aed1df8526b2e" category="list-text"><block ref="06e0780100d16763670aed1df8526b2e" category="inline-link-macro-rx"></block></block>
  <block id="128fc080215971e783f68c8be31bd85d" category="list-text"><block ref="128fc080215971e783f68c8be31bd85d" category="inline-link-macro-rx"></block></block>
  <block id="bf647454e36069fd16f1a7a35cf6a865" category="sidebar">入门</block>
  <block id="624e816c7f229d54827ad7bc018eb8da" category="sidebar">支持的存储选项</block>
  <block id="40d267fad784266cb59c36d76573e7c6" category="sidebar">基于 AWS 的 NetApp （ VMC ）</block>
  <block id="e7060d0555f178d672a4197df38e1d39" category="sidebar">配置虚拟化环境</block>
  <block id="a64cd881ec955d17faa5e396a891e1e6" category="sidebar">基于 Azure 的 NetApp （ AVS ）</block>
  <block id="d1b0ccc0fc426266cf228929d5424ce4" category="sidebar">基于 Google Cloud Platform 的 NetApp （ GCVE ）</block>
  <block id="690359e9e894d87f3144da561090e3f0" category="sidebar">NetApp ONTAP 为 VMware vSphere 管理员带来的优势</block>
  <block id="07a2344d318341cbbdb1983d22dc80f0" category="sidebar">安全数据保护</block>
  <block id="10e5369e04057873bcce3de87e2c6187" category="sidebar">采用 NetApp ONTAP 9 的 VMware Site Recovery Manager （ SRM ）</block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">我们使用 NetApp StorageGRID 设置对生产者和使用者工作负载执行了三到四个节点的分层存储测试。根据我们的测试，完成时间和性能结果与 StorageGRID 节点数成正比。StorageGRID 设置至少需要三个节点。</block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID 是一款高性能，经济高效的对象存储平台。通过使用分层存储，存储在代理的本地存储或 SAN 存储中的 Confluent Kafka 上的大部分数据将卸载到远程对象存储。此配置可通过减少重新平衡，扩展或缩减集群或更换故障代理所需的时间和成本，显著改善运营。对象存储在管理对象存储层上的数据方面发挥着重要作用，因此选择合适的对象存储非常重要。</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID 采用基于节点的分布式网格架构，提供智能的策略驱动型全局数据管理。它通过其无处不在的全局对象命名空间以及复杂的数据管理功能，简化了对数 PB 的非结构化数据和数十亿个对象的管理。单次调用对象访问可扩展到各个站点，并简化高可用性架构，同时确保无论站点或基础架构是否中断，都能持续访问对象。</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">多租户支持在同一网格中安全地处理多个非结构化云和企业数据应用程序，从而提高 NetApp StorageGRID 的 ROI 并增加其用例。您可以使用元数据驱动型对象生命周期策略创建多个服务级别，以优化多个地理位置的持久性，保护，性能和位置。用户可以调整数据管理策略并监控和应用流量限制，以便在不断变化的 IT 环境中需求发生变化时无中断地与数据环境重新对齐。</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID 网格管理器是一个基于浏览器的图形界面，可用于在一个管理平台中跨全球分布位置配置，管理和监控 StorageGRID 系统。</block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">您可以使用 StorageGRID 网格管理器界面执行以下任务：</block>
  <block id="a1d8b1b1990901cd5a97dd0f3dee2da9" category="inline-link-macro">ILM 策略</block>
  <block id="37e0a993cc0a3c5aacb623e412befc5b" category="inline-link-macro">ILM 规则</block>
  <block id="0beeefc6ac257658ea119788351ad268" category="paragraph">StorageGRID 具有灵活的数据管理策略，其中包括保留对象的副本以及使用 2+1 和 4+2 等 EC （纠删编码）方案来存储对象，具体取决于特定的性能和数据保护要求。随着工作负载和要求随时间的变化， ILM 策略也往往会随时间的变化而变化。修改 ILM 策略是一项核心功能，可使 StorageGRID 客户快速轻松地适应不断变化的环境。请检查 <block ref="b2ddd4069e5288685e27e7989fb1a613" category="inline-link-macro-rx"></block> 和 <block ref="7593bc4c70a5537fc14593339f7e6540" category="inline-link-macro-rx"></block> 在 StorageGRID 中设置。</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712 ， SG5760 ， SG6060 或 SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID 可通过添加更多存储节点来扩展性能，这些节点可以是 VM ，裸机或专门构建的设备，如 <block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block>。在我们的测试中，使用 SGF6024 设备时，使用最小大小的三节点网格，超出了 Apache Kafka 的主要性能要求。随着客户通过更多代理扩展 Kafka 集群，他们可以添加更多存储节点以提高性能和容量。</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">StorageGRID 中的流量分类</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID 具有内置的 QoS 功能。流量分类策略有助于监控来自客户端应用程序的不同类型的 S3 流量。然后，您可以创建并应用策略，根据传入 / 输出带宽，读 / 写并发请求数或读 / 写请求率对此流量施加限制。</block>
  <block id="611f69baa46f691eeeb33645e83f0fcb" category="paragraph">Apache Kafka 是一种使用 Java 和 Scala 编写的流处理的软件总线框架实施。它旨在提供一个统一的高吞吐量，低延迟平台来处理实时数据馈送。Kafka 可以连接到外部系统，以便通过 Kafka Connect 导出和导入数据，并提供 Kafka 流，这是一个 Java 流处理库。Kafka 使用基于 TCP 的二进制协议，该协议针对效率进行了优化，并依赖于 " 消息集 " 抽象，该抽象概念可将消息自然分组在一起，从而降低网络往返开销。这样可以实现更大的顺序磁盘操作，更大的网络数据包和连续的内存块，从而使 Kafka 能够将突发的随机消息写入流转变为线性写入。下图显示了 Apache Kafka 的基本数据流。</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Apache Kafka 用例</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka 在消息传送，网站活动跟踪，指标，日志聚合，流处理， 事件源和提交日志记录。</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka 提高了吞吐量，内置分区，复制和容错功能，使其成为大规模消息处理应用程序的良好解决方案。</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka 可以在跟踪管道中重建用户的活动（页面视图，搜索），并将其作为一组实时发布订阅源。</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka 经常用于运行监控数据。其中包括汇总分布式应用程序的统计信息，以生成集中式运营数据源。</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">许多人使用 Kafka 代替日志聚合解决方案。日志聚合通常从服务器中收集物理日志文件，并将其置于中央位置（例如文件服务器或 HDFS ）进行处理。Kafka 可对文件详细信息进行抽象，并将日志或事件数据更清晰地抽象为一个消息流。这样可以降低延迟处理，并更轻松地支持多个数据源和分布式数据使用。</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Kafka 的许多用户会在由多个阶段组成的处理管道中处理数据，在这些阶段中，原始输入数据会从 Kafka 主题中使用，然后进行聚合，丰富或转换为新主题，以供进一步使用或进行后续处理。例如，用于推荐新闻文章的处理管道可能会从 rss 源中搜寻文章内容并将其发布到 " 文章 " 主题。进一步处理可能会使此内容规范化或进行重复数据删除，并将经过清理的文章内容发布到新主题中，最终处理阶段可能会尝试向用户推荐此内容。此类处理管道会根据各个主题创建实时数据流图形。</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">事件源化是一种应用程序设计模式，其状态更改将记录为按时间顺序排列的记录序列。Kafka 支持存储的非常大的日志数据，因此它是以这种模式构建的应用程序的理想后端。</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka 可以用作分布式系统的一种外部提交日志。此日志有助于在节点之间复制数据，并充当故障节点恢复数据的重新同步机制。Kafka 中的日志缩减功能有助于支持此用例。</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="section-title">两者结合</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent Platform 是一款企业就绪平台，为 Kafka 提供了高级功能，旨在帮助加快应用程序开发和连接速度，通过流处理实现转型，大规模简化企业运营并满足严格的架构要求。Confluent 由 Apache Kafka 的原始创建者构建，通过企业级功能扩展了 Kafka 的优势，同时消除了 Kafka 的管理或监控负担。如今，《财富》 100 强企业中有 80% 以上的企业都采用数据流技术，其中大多数企业都采用了流畅技术。</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">下图显示了 Confluent Kafka 平台的组件。</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka 是一个社区分布的事件流式平台，能够每天处理数万亿次的事件。Kafka 最初是一个消息队列，它基于分布式提交日志的抽象化。自从 2011 年由 LinkedIn 创建和开源以来， Kafka 已从消息队列发展为成熟的事件流式平台。Confluent 将 Apache Kafka 与 Confluent Platform 一起分发。Confluent 平台为 Kafka 提供了更多的社区和商业功能，旨在增强大规模生产中操作员和开发人员的流式体验。</block>
  <block id="e1c012d650a6912ddb72ab0ee914d169" category="paragraph">本文档通过提供以下内容介绍在 NetApp 的对象存储产品上使用 Confluent 分层存储的最佳实践准则：</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">与 NetApp 对象存储— NetApp StorageGRID 相结合的验证</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">分层存储性能测试</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">在 NetApp 存储系统上使用 Confluent 的最佳实践准则</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">为什么选择 Confluent 分层存储？</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">本篇文章由 Confluent 提供</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">对于许多应用程序来说， Confuent 已成为默认的实时流式平台，尤其是对于大数据，分析和流式工作负载。通过分层存储，用户可以将计算与 Confluent 平台中的存储分开。它可以提高数据存储的成本效益，使您能够存储几乎无限数量的数据并按需扩展工作负载，并使数据和租户重新平衡等管理任务变得更加轻松。与 S3 兼容的存储系统可以利用所有这些功能在一个位置实现数据的民主化，从而无需复杂的数据工程。有关为什么应为 Kafka 使用分层存储的详细信息，请查看 <block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block>。</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">为什么要使用 NetApp StorageGRID 进行分层存储？</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID 是 NetApp 行业领先的对象存储平台。StorageGRID 是一款基于对象的软件定义存储解决方案，支持行业标准对象 API ，包括 Amazon Simple Storage Service （ S3 ） API 。StorageGRID 可大规模存储和管理非结构化数据，以提供安全，持久的对象存储。内容放置在合适的位置，合适的时间和合适的存储层上，从而优化工作流并降低全球分布式富媒体的成本。</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">StorageGRID 最大的竞争优势是其信息生命周期管理（ ILM ）策略引擎，该引擎支持策略驱动型数据生命周期管理。策略引擎可以使用元数据管理数据在其生命周期内的存储方式，以便在数据老化时对性能进行初始优化并自动优化成本和持久性。</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">启用 Confluent 分层存储</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">分层存储的基本理念是，将数据存储任务与数据处理任务分开。通过这种分离，数据存储层和数据处理层独立扩展变得更加容易。</block>
  <block id="e963c7bc15c18e21f60a9969d876e3e8" category="paragraph">适用于 Confluent 的分层存储解决方案必须与两个因素相抗衡。首先， IT 必须解决或避免常见的对象存储一致性和可用性属性，例如列表操作不一致以及偶尔出现的对象不可用性。其次， IT 必须正确处理分层存储与 Kafka 的复制和容错模型之间的交互，包括 zombie 领导者继续分层偏移范围的可能性。NetApp 对象存储可提供一致的对象可用性和 HA 模式，从而使陈旧的存储可用于分层偏移范围。NetApp 对象存储可提供一致的对象可用性和 HA 模式，使陈旧的存储可用于分层偏移范围。</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">借助分层存储，您可以使用高性能平台在流式数据末尾附近进行低延迟读写，还可以使用 NetApp StorageGRID 等更便宜且可扩展的对象存储来进行高吞吐量历史读取。我们还提供了适用于采用 NetApp 存储控制器的 Spark 的技术解决方案，详细信息请参见此处。下图显示了 Kafka 如何融入实时分析管道。</block>
  <block id="c7e421673ed217d2262c482dc24d0995" category="paragraph"><block ref="c7e421673ed217d2262c482dc24d0995" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66b784e6401c98dcf152747d22976bf7" category="paragraph">下图展示了 NetApp StorageGRID 如何成为 Confluent Kafka 的对象存储层。</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">冲突验证</block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">我们使用 NetApp StorageGRID 中的 Confluent Platform 6.2 分层存储执行了验证。NetApp 和 Confluent 团队共同执行了此验证，并运行了验证所需的测试用例。</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Confuent Platform 设置</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">我们使用以下设置进行验证。</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">为了进行验证，我们使用了三个 Zookeepers ，五个代理，五个测试脚本执行服务器，命名为 Tools 服务器，该服务器具有 256 GB RAM 和 16 个 CPU 。对于 NetApp 存储，我们使用的是带有四个 SGF6024 的 SG1000 负载平衡器的 StorageGRID 。存储和代理通过 100GbE 连接进行连接。</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">下图显示了用于 Confluent 验证的配置的网络拓扑。</block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">工具服务器充当向 Confluent 节点发送请求的应用程序客户端。</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">为了进行验证，我们将 StorageGRID 与 HTTP 协议结合使用，但 HTTPS 也有效。访问密钥和机密密钥存储在 `confuent.tier.s3.cred.file.path` 参数中提供的文件名中。</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">NetApp 对象存储— StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">我们在 StorageGRID 中配置了单站点配置以进行分层。</block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">验证测试</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">我们已完成以下五个测试案例以进行验证。这些测试将在 Trogdor 框架上执行。前两项是功能测试，其余三项是性能测试。</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">此测试将根据分层存储的需求确定对象存储 API 上的所有基本操作（例如 GET ， PUT 或 DELETE ）是否运行良好。这是一项基本测试，每个对象存储服务都应在以下测试之前通过。这是一项自信的测试，无论通过还是失败。</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">此测试可确定端到端分层存储功能是否运行良好，并通过或失败的自信测试。此测试将创建一个测试主题，默认情况下，此主题会配置为启用分层并大幅减小热设置大小。它会为新创建的测试主题生成一个事件流，并等待代理将这些分段归档到对象存储，然后使用事件流并验证已使用的流是否与生成的流匹配。生成给事件流的消息数量是可配置的，这样用户可以根据测试需求生成足够大的工作负载。减小的热集大小可确保活动分段之外的使用者提取仅从对象存储提供；这有助于测试对象存储的读取是否正确。我们执行此测试时，无论是否注入了对象存储故障。我们通过在 StorageGRID 中的一个节点中停止服务管理器服务并验证端到端功能是否适用于对象存储来模拟节点故障。</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">生产 - 使用工作负载基准测试</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">此测试会通过归档区块在对象存储上间接生成写入工作负载。读取工作负载（区块读取）是在使用者组提取区块时从对象存储生成的。此工作负载由测试脚本生成。此测试检查了并行线程中对象存储上的读写性能。与分层功能正确性测试一样，我们测试了是否存在对象存储故障注入。</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">保留工作负载基准测试</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">此测试检查了在主题保留工作负载繁重的情况下对象存储的删除性能。保留工作负载是使用测试脚本生成的，该脚本会与测试主题并行生成许多消息。本测试主题使用主动式基于大小和基于时间的保留设置进行配置，此设置会导致从对象存储中持续清除事件流。然后，这些区块会归档。这导致代理在对象存储中删除了大量内容，并收集了对象存储删除操作的性能。</block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">本文档提供了将 Confluent 分层存储与 NetApp 存储结合使用的最佳实践准则，其中包括验证测试，分层存储性能结果，调整， Confluent S3 连接器以及自平衡功能。考虑到 ILM 策略，具有多个验证性能测试的流畅性能以及行业标准 S3 API ， NetApp StorageGRID 对象存储是流畅分层存储的最佳选择。</block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">在 Confluent 平台中提供无限存储</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">融合分层存储—最佳实践和规模估算</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">适用于 Confluent Platform 的 Amazon S3 Sink Connector</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Kafka 规模估算</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">StorageGRID 规模估算</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Kafka 用例</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">在融合平台 6.0 中实现自我平衡的 Kafka 集群</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">融合的自平衡集群</block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">如果您以前管理过 Kafka 集群，则可能会熟悉手动将分区重新分配给不同代理所带来的挑战，以确保在集群中平衡工作负载。对于部署了大型 Kafka 的组织来说，重新配置大量数据可能会令人望而生畏，繁琐且存在风险，尤其是在集群上构建任务关键型应用程序时。但是，即使对于最小型的 Kafka 使用情形，该过程也非常耗时，并且容易出现人为错误。</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">在我们的实验室中，我们测试了 Confluent 自平衡集群功能，该功能可根据集群拓扑变化或负载不平衡自动重新平衡。当节点故障或扩展节点需要在代理之间重新平衡数据时， Confluent 重新平衡测试有助于测量添加新代理的时间。在典型的 Kafka 配置中，要重新平衡的数据量会随着集群的增长而增加，但在分层存储中，重新平衡仅限于少量数据。根据我们的验证，在典型的 Kafka 架构中，分层存储的重新平衡需要几秒或几分钟的时间，并且随着集群的增长而线性增长。</block>
  <block id="c9e4cfc44588cc591252c88cad0a3a09" category="paragraph">在自平衡集群中，分区重新平衡完全自动化，可优化 Kafka 的吞吐量，加快代理扩展速度并减少运行大型集群的操作负担。在稳定状态下，自平衡集群会监控代理之间的数据偏差，并持续重新分配分区以优化集群性能。在纵向或横向扩展平台时，自平衡集群会自动识别是否存在新代理或删除旧代理，并触发后续分区重新分配。这样，您就可以轻松添加和停用代理，从而从根本上提高 Kafka 集群的弹性。这些优势不需要任何人工干预，复杂的数学运算，也不需要分区重新分配通常会带来人为错误的风险。因此，完成数据重新平衡所需的时间远远少于完成时间，您可以自由地专注于价值更高的事件流式项目，而无需持续监控集群。</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">规模估算</block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Kafka 规模估算可通过四种配置模式来执行：简单，精细，反向和分区。</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">简单</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">简单模式适用于首次使用 Apache Kafka 的用户或早期使用情形。对于此模式，您可以提供吞吐量 MBps ，读取扇出，保留和资源利用率百分比等要求（默认为 60% ）。您还可以进入内部环境（裸机， VMware ， Kubernetes 或 OpenStack ）或云。根据这些信息， Kafka 集群的规模估算可提供代理， zookeeper ， Apache Kafka Connect 工作人员，架构注册表， REST 代理， ksqlDB 和 Confluent 控制中心所需的服务器数量。</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">对于分层存储，请考虑采用粒度配置模式来估算 Kafka 集群的规模。粒度模式适用于经验丰富的 Apache Kafka 用户或定义明确的用例。本节介绍了针对生产者，流处理器和使用者的规模估算。</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">生产者</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">要描述 Apache Kafka 的生成方（例如原生客户端， REST 代理或 Kafka 连接器），请提供以下信息：</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">* 名称 * Spark 。</block>
  <block id="0ae6d6b48753e01bf1ae73bb86ee6276" category="list-text">* 生成方类型。 * 应用程序或服务，代理（ REST ， MQT ，其他）和现有数据库（ RDBMS ， NoSQL ，其他）。您也可以选择 " 我不知道 " 。</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">* 平均吞吐量 * ，以每秒事件数（例如 1 ， 000 ， 000 ）表示。</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">* 峰值吞吐量 * ，以每秒事件数（例如 4 ， 000 ， 000 ）表示。</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">* 平均消息大小 * ，以字节为单位，未压缩（最大 1 MB ；例如 1000 ）。</block>
  <block id="dd6d45bc2ad71619bde2260f1776e9b2" category="list-text">* 消息格式。 * 选项包括 Avro ， JSON ，协议缓冲区，二进制文件，文本， " 我不知道 " 等。</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">* 复制因子。 * 选项包括 1 ， 2 ， 3 （ Confluent 建议）， 4 ， 5 ， 或 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">* 保留时间 * 一天（例如）。您希望将数据存储在 Apache Kafka 中多长时间？输入 -1 并输入任意单位，持续时间不受限制。计算器假定保留时间为 10 年，以实现无限保留。</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">选中 " 启用分层存储以减少代理数量并允许无限存储？ " 复选框</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">启用分层存储后，保留字段将控制存储在代理本地的热数据集。归档保留字段用于控制数据在归档对象存储中的存储时间。</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">* 归档存储保留。 * 一年（例如）。您希望将数据存储在归档存储中多长时间？输入 -1 并输入任意单位，持续时间不受限制。计算器假定保留 10 年以实现无限保留。</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">* 增长乘数 * 1 （例如）。如果此参数的值基于当前吞吐量，请将其设置为 1 。要根据其他增长调整大小，请将此参数设置为增长乘数。</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">* 生产商实例数。 * 10 （例如）。将运行多少个生产商实例？要将 CPU 负载纳入规模估算计算，需要使用此输入。如果值为空，则表示 CPU 负载未计入计算中。</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">根据此示例输入，规模估算对生成方具有以下影响：</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">未压缩字节的平均吞吐量： 1 Gbps 。未压缩字节的峰值吞吐量： 4 Gbps 。以压缩字节为单位的平均吞吐量： 400 Mbps 。以压缩字节为单位的峰值吞吐量： 1.6 GBps 。此值基于默认 60% 的压缩率（您可以更改此值）。</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">所需的总代理热设置存储： 31 ， 104 TB ，包括复制，已压缩。所需的代理外归档存储总量： 378 ， 432 TB ，已压缩。使用 ... <block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> 用于 StorageGRID 规模估算。</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">流处理器必须描述其应用程序或服务，这些应用程序或服务会使用 Apache Kafka 中的数据并生成回 Apache Kafka 。大多数情况下，这些数据存储库内置在 ksqlDB 或 Kafka 流中。</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">* 名称 * 。 * Spark 流式传输器。</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">* 处理时间。 * 此处理器处理单条消息需要多长时间？</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 毫秒（简单，无状态转换） [ 示例 ] ， 10 毫秒（有状态内存操作）。</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100 毫秒（有状态网络或磁盘操作）， 1000 毫秒（第三方 REST 调用）。</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">我已对该参数进行了基准测试，并确切了解它需要多长时间。</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">* 输出保留 * 1 天（示例）。流处理器会将其输出返回到 Apache Kafka 。您希望将此输出数据存储在 Apache Kafka 中多长时间？输入 -1 并输入任意单位，持续时间不受限制。</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">选中 " 启用分层存储以减少代理数量并允许无限存储？ " 复选框</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">* 归档存储保留。 * 1 年（例如）。您希望将数据存储在归档存储中多长时间？输入 -1 并输入任意单位，持续时间不受限制。计算器假定保留 10 年以实现无限保留。</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">* 输出直通百分比 * 100 （例如）。流处理器会将其输出返回到 Apache Kafka 。多少百分比的入站吞吐量将输出回 Apache Kafka ？例如，如果入站吞吐量为 20Mbps ，而此值为 10 ，则输出吞吐量将为 2Mbps 。</block>
  <block id="d1a6a4732f959b58cd8c77edcf10b31b" category="list-text">从哪些应用程序读取此数据？选择 "Spark " ，即在基于生产商类型的规模估算中使用的名称。根据上述输入，估算流处理程序实例和主题分区估计值时可能会产生以下影响：</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">此流处理器应用程序需要以下数量的实例。传入的主题可能也需要这么多分区。请联系 Confluent 以确认此参数。</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">1 ， 000 表示平均吞吐量，无增长乘数</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">4 ， 000 表示峰值吞吐量，无增长乘数</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1 ， 000 表示使用增长乘数的平均吞吐量</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">4 ， 000 表示峰值吞吐量，并使用增长乘数</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">使用者</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">请描述您使用 Apache Kafka 中的数据而不生成回 Apache Kafka 的应用程序或服务，例如原生客户端或 Kafka 连接器。</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">* 名称 * 。 * Spark 使用者。</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">* 处理时间。 * 此使用者需要多长时间处理一条消息？</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 毫秒（例如，日志记录等简单无状态任务）</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 毫秒（快速写入数据存储库）</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 毫秒（写入数据存储库的速度较慢）</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000 毫秒（第三方 REST 调用）</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">已知持续时间的其他一些基准流程。</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">* 使用者类型。 * 应用程序，代理或接收到现有数据存储库（ RDBMS ， NoSQL ，其他）。</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">从哪些应用程序读取此数据？将此参数与先前确定的生成方和流规模估算相连接。</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">根据上述输入，您必须确定使用者实例的规模估算和主题分区估算。使用者应用程序需要以下数量的实例。</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">2 ， 000 表示平均吞吐量，无增长乘数</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">峰值吞吐量为 8 ， 000 ，无增长乘数</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">2 ， 000 表示平均吞吐量，包括增长乘数</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">8 ， 000 表示峰值吞吐量，包括增长乘数</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">传入主题可能也需要此数量的分区。请联系 Confluent 进行确认。</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">除了对生产者，流处理器和使用者的要求之外，您还必须满足以下附加要求：</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">* 重建时间。 * 例如， 4 小时。如果 Apache Kafka 代理主机发生故障，其数据丢失，并且配置了新主机来更换发生故障的主机，则新主机必须自行重建多快？如果此值未知，请将此参数留空。</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">* 资源利用率目标（百分比）。 * 例如 60 。您希望主机在平均吞吐量期间的利用率如何？除非您使用的是 Confluent 自平衡集群，否则 Confuent 建议使用 60% 的利用率，在这种情况下，利用率可能会更高。</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">描述您的环境</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">* 您的集群将在什么环境中运行？ * Amazon Web Services ， Microsoft Azure ， Google 云平台，内部裸机，内部部署 VMware ， 内部使用 OpenStack 还是内部使用 Kubernates ？</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">* 主机详细信息。 * 核心数： 48 （例如），网卡类型（ 10GbE ， 40GbE ， 16GbE ， 1GbE 或其他类型）。</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">* 存储卷。 * 主机： 12 （例如）。每个主机支持多少个硬盘驱动器或 SSD ？因此，建议每个主机配置 12 个硬盘驱动器。</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">* 存储容量 / 卷（以 GB 为单位）。 * 1000 （例如）。单个卷可以存储多少 GB 的存储？这两者建议使用 1 TB 磁盘。</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">* 存储配置。 * 如何配置存储卷？Confuent 建议使用 RAID10 来利用所有 Confluent 功能。JBOD ， SAN ， RAID 1 ， RAID 0 ， RAID 5 ， 此外，还支持其他类型。</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">* 单卷吞吐量（ MBps ）。 * 125 （例如）。单个存储卷的每秒读取或写入速度（以 MB/ 秒为单位）有多快？Confuent 建议使用标准硬盘驱动器，这些驱动器的吞吐量通常为 125 MBps 。</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">* 内存容量（ GB ） .* 64 （例如）。</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">确定环境变量后，选择调整集群大小。根据上述示例参数，我们确定了以下 Confluent Kafka 规模估算：</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">* Apache Kafka.* 代理计数： 22 。您的集群受存储限制。请考虑启用分层存储以减少主机数量并允许无限存储。</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">* Apache zookeeper 。 * 计数： 5 ； Apache Kafka Connect Worker ：计数： 2 ；架构注册表：计数： 2 ； REST 代理：计数： 2 ； ksqlDB ：计数： 2 ； Confluent Control Center ：计数： 1 。</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">对平台团队使用反向模式，而不考虑使用情形。使用分区模式计算单个主题所需的分区数。请参见<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> 用于根据反向和分区模式进行规模估算。</block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">根据我们的验证， S3 对象存储对于 Confluent 来说是保留数据的最佳选择。</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">我们可以使用高吞吐量 SAN （尤其是 FC ）来保留代理热数据或本地磁盘，因为在 Confluent 分层存储配置中， 代理数据目录中保留的数据大小取决于数据移动到对象存储时的区块大小和保留时间。</block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">* Kafka 调整。 * 要提高分层存储的性能，您可以增加 TierFetcherNumThreads 和 TierArchiverNumThreads 。一般情况下，您需要增加 TierFetcherNumThreads 以匹配物理 CPU 核数，并将 TierArchiverNumThreads 增加到 CPU 核数的一半。例如，在服务器属性中，如果您的计算机具有八个物理核心，请将 confuent.tier.fetcher.num.threads = 8 ，而将 confuent.tier.archiver.num.threads = 4 。</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">* 主题删除的时间间隔。 * 删除主题后，不会立即开始删除对象存储中的日志段文件。而是在删除这些文件之前，有一个默认值为 3 小时的时间间隔。您可以修改配置 confluent.tier.topic.delete.check.interval.ms 以更改此间隔的值。如果删除某个主题或集群，也可以手动删除相应存储分段中的对象。</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">* 分层存储内部主题上的 ACL 。 * 建议内部部署的最佳实践是，在分层存储使用的内部主题上启用 ACL 授权者。设置 ACL 规则，以便仅允许代理用户访问此数据。这样可以保护内部主题的安全，并防止对分层存储数据和元数据进行未经授权的访问。</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">将用户 ` &lt;Kafka&gt;` 替换为部署中的实际代理主体。</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">例如，命令 `confuent-tier-state` 会在内部主题上为分层存储设置 ACL 。目前，只有一个内部主题与分层存储相关。此示例将创建一个 ACL ，为内部主题上的所有操作提供主体 Kafka 权限。</block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">本节介绍了用于 Confluent 验证的硬件和软件。此信息适用于使用 NetApp 存储部署 Confluent Platform 。下表介绍了经过测试的解决方案架构和基本组件。</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">五个工具服务器</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">适用于分层存储的 NetApp StorageGRID</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">StorageGRID 软件</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 个 SGF6024</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 个 100GbE （代理和 StorageGRID 实例之间的网络连接）</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">融合 S3 连接器</block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Amazon S3 Sink Connector 以 Avro ， JSON 或字节格式将数据从 Apache Kafka 主题导出到 S3 对象。Amazon S3 Sink Connector 会定期轮询 Kafka 中的数据，然后将其上传到 S3 。分区程序用于将每个 Kafka 分区的数据拆分为多个区块。每个数据区块都表示为 S3 对象。密钥名称会对主题， Kafka 分区以及此数据块的起始偏移进行编码。</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">融合的自重新平衡集群</block>
  <block id="a02c6dbd226d5506c1b4b07f6d383615" category="list-text">使用 ` 并行` 选项的 XCP 副本基于 CPU 数量。默认的并行线程数（七个）有时足以执行大多数 XCP 数据传输和迁移操作。默认情况下，对于 XCP Windows ，并行进程数等于 CPU 数。` 并行` 选项的最大数量应小于或等于核心数量。</block>
  <block id="740950b0e27cdd5def3c4295d5840851" category="list-text">10GbE 是数据传输的良好开端。但是，我们使用 25GbE 和 100GbE 进行了测试，这两种配置可提供更好的数据传输，并建议用于大型文件大小的数据传输。</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam ， Joseph Kandatilparambil ， NetApp Rankesh Kumar ， Confluent</block>
  <block id="b583dc49832a978014ef0d14fe7ef1ce" category="paragraph">详细了解 NetApp 为每个超大规模企业提供的 VMware 环境解决方案—从迁移工作流，扩展 / 扩展到云，备份 / 还原和灾难恢复。</block>
  <block id="bf3f0fd9ec5faf81793c3abc5e3b9127" category="admonition">此适用场景子系统仅连接存储。</block>
  <block id="8ad188089680179dea816084001d7bf0" category="sidebar">借助 E 系列和 BeeGFS 实现 AI 和分析工作流的数据移动</block>
  <block id="120c02d2aa6cda1e3b75902fb4fc0b53" category="doc">混合云，桌面虚拟化和容器解决方案的新增功能</block>
  <block id="9db3527848e891e0a9340c443515e770" category="doc">开始使用 NetApp 和 VMware</block>
  <block id="c4c3630750312520bc4b93c16056bfd7" category="doc">采用 NVIDIA 的 NetApp EF 系列 AI</block>
  <block id="e6ee072aeeb0647d8c0cfe75e4cde51d" category="paragraph">NetApp 和 NVIDIA EF 系列 AI 融合基础架构解决方案概述。</block>
  <block id="f512fcc18626023378bfe28dce07116d" category="list-text"><block ref="f512fcc18626023378bfe28dce07116d" category="inline-link-macro-rx"></block></block>
  <block id="ae02a3224f15623423f197426c44a26d" category="list-text"><block ref="ae02a3224f15623423f197426c44a26d" category="inline-link-macro-rx"></block></block>
  <block id="8ce1a272bf4c47418ea6d69083f2df4f" category="inline-link-macro">BeeGFS 部署指南</block>
  <block id="7991adac41b3f0e292dee61e87c39052" category="list-text"><block ref="7991adac41b3f0e292dee61e87c39052" category="inline-link-macro-rx"></block></block>
  <block id="9d2ca817bb7dd69d6f7dc09932a53524" category="summary">NetApp 人工智能解决方案是一组战略和技术解决方案，用于展示 NetApp 存储在整个 AI/ML 领域的功能。</block>
  <block id="b54a1e289898cf21f63715dfe64025b7" category="doc">NetApp 人工智能解决方案</block>
  <block id="4618b9225719de309c0b0f5aa4718c7b" category="paragraph">NetApp 和 NVIDIA 的 ONTAP AI 融合基础架构解决方案概述。</block>
  <block id="ab9d770eb05e7725141740f508566fce" category="section-title">采用 NVIDIA DGX A100 系统的 NetApp ONTAP AI</block>
  <block id="7c962be0dc8fdf28c1c4279fe5256a22" category="section-title">采用 NVIDIA DGX A100 系统和 Mellanox 频谱以太网交换机的 NetApp ONTAP AI</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">英语</block>
  <block id="37ce0afb395b0346118a74c4f05f20a7" category="list-text"><block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block>f ：@fact_soultion_mktg=[AI ，分析，人工智能 ]++[AI 博客， NetApp.com 上 ]</block>
  <block id="191ea533aa1478d35c965840430fbfe6" category="summary">NetApp 现代数据分析解决方案是一组战略和技术功能，用于展示 NetApp 存储在整个 AI 领域的功能。</block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="doc">NetApp 现代数据分析解决方案</block>
  <block id="22169240c9a4c0ab61a4ed13c981c5ef" category="sidebar">适用于 AI 工作负载的融合基础架构</block>
  <block id="8508ab1994a5679882beb6400778e8ba" category="sidebar">采用 NVIDIA 的 EF 系列 AI</block>
  <block id="ec820f861118408d42b077dbf109f374" category="sidebar">采用 NetApp E 系列存储的 IBM Spectrum Scale</block>
  <block id="b63ada7ec650c01320cddeda05deb779" category="sidebar">边缘人工智能推理—采用联想 ThinkSystem 的 NetApp</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">适用于 AI 的 NetApp ONTAP 和联想 ThinkSystem SR670</block>
  <block id="e5c3eeefe82172631e21562a8d3672a5" category="sidebar">适用于 AI 的 NetApp AFF A800 和 Fujitsu 服务器 PRIMERGY GX2570 M5</block>
  <block id="2fa3e2a0ff5682666455eed0a7b1b569" category="sidebar">数据湖和数据管道</block>
  <block id="6ac39037a7efa2708d15c0e0e20fb188" category="sidebar">适用于自主驾驶工作负载的 StorageGRID 数据湖</block>
  <block id="eeb4980c2a89f07abf1a0b927066b23c" category="sidebar">借助 E 系列和适用于 AI 的 BeeGFS 实现数据移动</block>
  <block id="13f985aafb32ac9e387186e5a437f96e" category="sidebar">采用数据缓存的混合云 AI</block>
  <block id="ac82c7a9ef13f3b604553ccfe1a5bd76" category="sidebar">支持和管理</block>
  <block id="3cd04d0e6cf45786c9e94148f213b537" category="sidebar">适用于 AI 管道和工作空间访问的 NetApp AI 控制平台</block>
  <block id="447e8e0102d91009c125adb678cd7fb5" category="sidebar">与 Iguazio 的 MLRun 管道</block>
  <block id="71e6eb0dc5951ca93effe179d000f534" category="sidebar">情感分析</block>
  <block id="cfff43e76ea0e95d290a279bdb279a2e" category="sidebar">点击率预测— Azure 中的分布式培训</block>
  <block id="29931fafbbc65eabe1029aee9a3a5a85" category="sidebar">车道检测— Azure 中的分布式培训</block>
  <block id="7656ac1f9ee1e1763f07a285578d922a" category="sidebar">使用 NVIDIA JarVis 的对话 AI</block>
  <block id="8f0148532a5b5382ec4f005c8a96a4fa" category="sidebar">自动驾驶</block>
  <block id="f869ce5572b45e50fe014954c4248d60" category="sidebar">医疗保健—诊断成像</block>
  <block id="951b9c6690c2a4c1228ada2a9980d5a8" category="sidebar">信用卡欺诈检测</block>
  <block id="f0b83f1f7d211bfb4e278dafd2d6b4fa" category="sidebar">采用 NetApp Storage 解决方案的 Apache Spark 工作负载</block>
  <block id="6bf79bc16e8a34cf5698aabd27cecef1" category="sidebar">现代数据分析解决方案简介</block>
  <block id="cd47dd01745339787e4c7300389401f2" category="sidebar">最佳实践</block>
  <block id="1bd369d8fc8172d625ac41a1815aa09d" category="sidebar">Confluent Kafka 的最佳实践</block>
  <block id="3ed3645b4e41749082a0692a758a3132" category="sidebar">混合云解决方案— Spark 和 Hadoop 用例</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">博客：使用 XCP 将数据从数据湖和 HPC 迁移到 ONTAP NFS</block>
  <block id="9cb9fe27a24f987a1889d5fc1d5d139e" category="sidebar">《采用 NetApp E 系列的 BeeGFS 部署指南》</block>
  <block id="d064ecad73d9352507092f40af924057" category="cell">2022 年 2 月 2 日</block>
  <block id="c0598da0ea2338576f8d67854c56e3f6" category="cell">创建登录页面，以便更好地组织 AI 和现代数据分析的内容</block>
  <block id="84c45df200c907852c1e92875618b432" category="cell">2022 年 1 月 22 日</block>
  <block id="b385810d0a927b9d15a69218e3fb38c4" category="cell">添加了 TR ：使用 E 系列和 BeeGFS 移动数据以实现 AI 和分析工作流</block>
  <block id="89d5e6802ef5a3ae4296f49d4d6bc447" category="sidebar">其他资源</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">博客： Apache Spark 在 NetApp 数据分析平台上扮演着重要角色</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV ：大数据分析播放列表</block>
  <block id="0a2866cc3e2ba203c7e2e3ebeca395be" category="sidebar">SAP 与基于 UNIX 的 Oracle 以及 NFS 与 NetApp 集群模式 Data ONTAP</block>
  <block id="4e36e97d23b00520e4b573859ee4cb26" category="list-text"><block ref="4e36e97d23b00520e4b573859ee4cb26" category="inline-link-macro-rx"></block></block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">在此验证中，我们使用四台服务器作为网络共享磁盘（ Network Shared Disk ， NSD ）服务器来为 GPFS 提供物理磁盘。在 NSD 磁盘上创建了 GPF ，以便将其导出为 NFS 导出，以便 NFS 客户端可以访问它们，如下图所示。我们使用 XCP 将数据从 GPFS 导出的 NFS 复制到 NetApp NFS 卷。</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">从 GPF 到 NetApp ONTAP NFS</block>
  <block id="9a1bdf4376c8448278cf38263e4da8c7" category="paragraph"><block ref="9a1bdf4376c8448278cf38263e4da8c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">GPF 要点</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">GPFS 中使用以下节点类型：</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">* 管理节点。 * 指定一个可选字段，其中包含管理命令用于在节点之间进行通信的节点名称。例如，管理节点 `mastr-51.netapp.com` 可以将网络检查传递给集群中的所有其他节点。</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">* 仲裁节点。 * 确定节点是否包含在从中派生仲裁的节点池中。您至少需要一个节点作为仲裁节点。</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">* 管理器节点。 * 表示节点是否属于可从中选择文件系统管理器和令牌管理器的节点池。最好将多个节点定义为管理节点。您指定为管理器的节点数取决于工作负载和您拥有的 GPFS 服务器许可证数。如果您运行的是大型并行作业，则与支持 Web 应用程序的四节点集群相比，您可能需要更多的管理节点。</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">* NSD 服务器。 * 用于准备每个物理磁盘以用于 GPFS 的服务器。</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">* 协议节点。 * 通过任何安全 Shell （ SSH ）协议与 NFS 直接共享 GPFS 数据的节点。此节点需要 GPFS 服务器许可证。</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">GPFS ， NFS 和 XCP 的操作列表</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">本节提供了创建 GPFS ，将 GPFS 导出为 NFS 导出以及使用 XCP 传输数据的操作列表。</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">创建 GPFS</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">要创建 GPFS ，请完成以下步骤：</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">在其中一台服务器上下载并安装 Linux 版本的频谱级数据访问。</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">在所有节点中安装前提条件包（例如 chef ），并在所有节点中禁用安全增强型 Linux （ SELinux ）。</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">设置安装节点并将管理节点和 GPFS 节点添加到集群定义文件中。</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">添加管理器节点，仲裁节点， NSD 服务器和 GPFS 节点。</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">添加 GUI ，管理和 GPFS 节点，并根据需要添加额外的 GUI 服务器。</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">添加另一个 GPFS 节点并检查所有节点的列表。</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">指定要在集群定义文件中的所有 GPFS 节点上设置的集群名称，配置文件，远程 shell 二进制文件，远程文件副本二进制文件和端口范围。</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">查看 GPFS 配置设置并添加其他管理节点。</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">禁用数据收集并将数据包上传到 IBM 支持中心。</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">启用 NTP 并在安装之前预检查配置。</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">配置，创建和检查 NSD 磁盘。</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">创建 GPFS 。</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">挂载 GPFS 。</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">验证 GPFS 并为其提供所需的权限。</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">运行 `dd` 命令，验证 GPFS 读写。</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">将 GPFS 导出到 NFS</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">要将 GPFS 导出到 NFS ，请完成以下步骤：</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">通过 ` /etc/exports` 文件将 GPFS 导出为 NFS 。</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">安装所需的 NFS 服务器软件包。</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">启动 NFS 服务。</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">列出 GPFS 中的文件以验证 NFS 客户端。</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">配置 NFS 客户端</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">要配置 NFS 客户端，请完成以下步骤：</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">通过 ` /etc/exports` 文件将 GPFS 导出为 NFS 。</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">启动 NFS 客户端服务。</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">通过 NFS 协议在 NFS 客户端上挂载 GPFS 。</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">验证 NFS 挂载文件夹中的 GPFS 文件列表。</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">使用 XCP 将数据从 GPFS 导出的 NFS 移动到 NetApp NFS 。</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">验证 NFS 客户端上的 GPFS 文件。</block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">本节详细介绍了使用 NetApp XCP 配置 GPFS 并将数据移动到 NFS 所需的步骤。</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">从 GPF 到 NFS 详细步骤</block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">配置 GPFS</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">在其中一台服务器上下载并安装适用于 Linux 的 Spectrum Scale Data Access 。</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">在所有节点上安装前提条件包（包括 chef 和内核标头）。</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">在所有节点中禁用 SELinux 。</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">设置安装节点。</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">将管理节点和 GPFS 节点添加到集群定义文件中。</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">添加管理器节点和 GPFS 节点。</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">添加仲裁节点和 GPFS 节点。</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">添加 NSD 服务器和 GPFS 节点。</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">添加 GUI ，管理和 GPFS 节点。</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">添加另一个 GUI 服务器。</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">添加另一个 GPFS 节点。</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">验证并列出所有节点。</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">在集群定义文件中指定集群名称。</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">指定配置文件。</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">指定 GPFS 要使用的远程 shell 二进制文件；使用 ` -r 参数` 。</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">指定 GPFS 要使用的远程文件副本二进制文件；使用 ` -rc 参数` 。</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">指定要在所有 GPFS 节点上设置的端口范围；使用 ` -e 参数` 。</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">查看 GPFS 配置设置。</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">添加管理节点。</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">启用 NTP 。</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">安装前预检查配置。</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">配置 NSD 磁盘。</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">创建 NSD 磁盘。</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">检查 NSD 磁盘状态。</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">检查 GPFS 并为其提供所需的权限。</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">运行 `dd` 命令检查 GPFS 读写。</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">要将 GPFS 导出到 NFS ，请完成以下步骤：</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">列出 GPFS 中的文件以验证 NFS 客户端。</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">配置 NFS 客户端</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">在 NFS 客户端中安装软件包。</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">验证 NFS 挂载文件夹中的 GPFS 文件列表。</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">使用 XCP 将数据从 GPFS 导出的 NFS 移动到 NetApp NFS 。</block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">本节介绍此解决方案的业务优势。</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">业务优势</block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">将数据从大数据分析迁移到 AI 具有以下优势：</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">能够从不同的 Hadoop 文件系统和 GPFS 中提取数据到统一的 NFS 存储系统中</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">一种与 Hadoop 集成的自动化数据传输方式</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">降低从 Hadoop 文件系统移动数据的库开发成本</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">通过使用 NIPAM 从单个数据源聚合多个网络接口的吞吐量实现最高性能</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">按计划和按需传输数据的方法</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">使用 ONTAP 数据管理软件为统一 NFS 数据提供存储效率和企业管理功能</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">使用 Hadoop 数据传输方法实现数据移动零成本</block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">本节详细介绍了使用 NetApp XCP 将 MapR-FS 数据移动到 ONTAP NFS 中所需的步骤。</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FS 到 ONTAP NFS</block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">为每个 MapR 节点配置三个 LUN ，并为所有 MapR 节点授予 LUN 所有权。</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">在安装期间，为 MapR 集群磁盘选择新添加的 LUN 以用于 MapR-FS 。</block>
  <block id="f7dc1a091cd04b392f9a99c5390b9ce2" category="inline-link">MapR 6.1 文档</block>
  <block id="24cb5309ea8c5a7c3244adf133110ecf" category="list-text">根据安装 MapR 集群<block ref="a38d60fa0425a18b5925139ceca806ea" category="inline-link-rx"></block>。</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">使用 `Hadoop JAR xxx` 等 MapReduce 命令检查基本 Hadoop 操作。</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">将客户数据保留在 MapR-FS 中。例如，我们使用 Teragen 在 MapR-FS 中生成了大约 1 TB 的样本数据。</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">将 MapR-FS 配置为 NFS 导出。</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">在所有 MapR 节点上禁用 nlockmgr 服务。</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">从 ` /opt/mapr/conf/exports` 文件中所有 MapR 节点上的 MapR-FS 导出特定文件夹。导出子文件夹时，请勿使用不同的权限导出父文件夹。</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">刷新 MapR-FS NFS 服务。</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">将虚拟 IP 范围分配给 MapR 集群中的特定服务器或一组服务器。然后， MapR 集群会为特定服务器分配一个 IP 以进行 NFS 数据访问。这些 IP 可实现高可用性，这意味着，如果具有特定 IP 的服务器或网络出现故障，则可以使用 IP 范围内的下一个 IP 进行 NFS 访问。</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">如果要从所有 MapR 节点提供 NFS 访问，则可以为每个服务器分配一组虚拟 IP ，并使用每个 MapR 节点的资源进行 NFS 数据访问。</block>
  <block id="fa6899b17d5e71a360316c355d34c8b3" category="paragraph"><block ref="fa6899b17d5e71a360316c355d34c8b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb6de965ede92bf8bb036bb8fea6eba" category="paragraph"><block ref="8cb6de965ede92bf8bb036bb8fea6eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="031b138609c608ed553a74b2a1c439e1" category="paragraph"><block ref="031b138609c608ed553a74b2a1c439e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">检查在每个 MapR 节点上分配的虚拟 IP ，并使用它们进行 NFS 数据访问。</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">使用分配的虚拟 IP 挂载 NFS 导出的 MapR-FS 以检查 NFS 操作。但是，使用 NetApp XCP 进行数据传输时，不需要执行此步骤。</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">配置 NetApp XCP 以将数据从 MapR-FS NFS 网关传输到 ONTAP NFS 。</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">配置 XCP 的目录位置。</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">将此许可证文件复制到 ` /opt/netapp/xFiles/XCP/` 。</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">使用 `XCP activate` 命令激活 XCP 。</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">检查 NFS 导出的源。</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">使用 XCP 从多个 MapR 节点从多个源 IP 和多个目标 IP （ ONTAP LIF ）传输数据。</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">检查存储控制器上的负载分布。</block>
  <block id="ca79886b03835c933143f8eb102ac932" category="list-text">NetApp 原位分析模块最佳实践</block>
  <block id="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link"><block ref="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link-rx"></block></block>
  <block id="026671d583a546d6b62291e018f78bf7" category="paragraph"><block ref="026671d583a546d6b62291e018f78bf7" category="inline-link-rx"></block></block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">《 NetApp FlexGroup 卷最佳实践和实施指南》</block>
  <block id="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link"><block ref="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link-rx"></block></block>
  <block id="f473bc55fb079f0338493530316efc6f" category="paragraph"><block ref="f473bc55fb079f0338493530316efc6f" category="inline-link-rx"></block></block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">版本 3.0</block>
  <block id="4b3608ccf8a7154699127b487cc49627" category="paragraph">本文档介绍如何从大数据分析和高性能计算（ HPC ）系统中移动数据，以便将其用于人工智能（ AI ）工作流。AI 通常通过 NFS 导出处理 NFS 数据。但是，您的 AI 数据可能位于大数据分析和高性能计算（ HPC ）平台中。这可以是 Hadoop 分布式文件系统（ HDFS ），二进制大型对象（ Blob ）， S3 存储或 IBM 的通用并行文件系统（ GPFS ）。在本文档中，我们将介绍如何使用 Hadoop 本机命令， NetApp 原位分析模块（ NIPAM ）和 NetApp XCP 将数据从大数据分析平台和 GPFS 移动到 NFS 。本文档还讨论了将数据从大数据和 HPC 迁移到 AI 的业务优势。</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">此页面讨论了客户尝试从用于 AI 操作的大数据分析中访问数据时可能面临的挑战。</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="doc">客户面临的挑战</block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">客户在尝试从 AI 运营的大数据分析中访问数据时可能会面临以下挑战：</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">客户数据位于数据湖存储库中。数据湖可以包含不同类型的数据，例如结构化数据，非结构化数据，半结构化数据，日志数据以及计算机到计算机数据。所有这些数据类型都必须在 AI 系统中进行处理。</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">AI 与 Hadoop 文件系统不兼容。典型的 AI 架构无法直接访问 HDFS 和 HCFS 数据，必须将这些数据移至 AI 可理解的文件系统（ NFS ）。</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">将数据湖数据迁移到 AI 通常需要专门的流程。数据湖中的数据量可能非常大。客户必须采用高效，高吞吐量且经济高效的方式将数据迁移到 AI 系统中。</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">正在同步数据。如果客户希望在大数据平台和 AI 之间同步数据，有时通过 AI 处理的数据可以与大数据结合使用进行分析处理。</block>
  <block id="2ea9ecb649c5974bc03036a15d95f5bf" category="summary">适用于 AI 的数据移动工具解决方案基于客户处理 AI 操作中的 Hadoop 数据的需求。NetApp 使用 NIPAM 将数据从 HDFS 移动到 NFS 。在一个使用情形中，客户需要将数据移动到内部的 NFS ，而另一客户则需要将数据从 Windows Azure 存储 Blob 移动到 Cloud Volumes Service ，以便处理云中 GPU 云实例中的数据。</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">适用于 AI 的数据移动工具解决方案</block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">下图显示了数据移动程序解决方案的详细信息。</block>
  <block id="27f83ed51cc554467134084d77b0e050" category="paragraph"><block ref="27f83ed51cc554467134084d77b0e050" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">要构建数据移动程序解决方案，需要执行以下步骤：</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN 可提供 HDFS ， NAS 可通过 NIPAM 为生产数据湖集群提供 NFS 卷。</block>
  <block id="0fad6dd0225bf5a5e9c668c30ea5d38a" category="list-text">客户的数据位于 HDFS 和 NFS 中。NFS 数据可以是来自其他应用程序的生产数据，用于大数据分析和 AI 操作。</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">NetApp FlexClone 技术可创建生产 NFS 卷的克隆并将其配置到内部的 AI 集群。</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">使用 NIPAM 和 `Hadoop distcp` 命令将来自 HDFS SAN LUN 的数据复制到 NFS 卷中。NIPAM 使用多个网络接口的带宽传输数据。此过程可缩短数据复制时间，以便传输更多数据。</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">这两个 NFS 卷都配置到 AI 集群以执行 AI 操作。</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">要使用云中的 GPU 处理内部 NFS 数据， NFS 卷会采用 NetApp SnapMirror 技术镜像到 NetApp 私有存储（ NPS ），并挂载到云服务提供商的 GPU 。</block>
  <block id="c590e653cde69438d43731b18edd533c" category="list-text">客户希望通过云服务提供商提供的 GPU 处理 EC2/EMR ， HDInsight 或 DataProc 服务中的数据。Hadoop 数据移动工具可通过 NIPAM 和 `Hadoop distcp` 命令将数据从 Hadoop 服务移动到 Cloud Volumes 服务。</block>
  <block id="8cae7d7989a25f83bf9df9952b16ed2b" category="list-text">Cloud Volumes Service 数据通过 NFS 协议配置到 AI 。通过 AI 处理的数据除了通过 NIPAM ， SnapMirror 和 NPS 发送到 NVIDIA 集群之外，还可以发送到内部位置进行大数据分析。</block>
  <block id="980894bd0921c687decdf218e89107e2" category="paragraph">在这种情况下，客户在远程位置的 NAS 系统中有大量文件计数数据，这是在内部 NetApp 存储控制器上进行 AI 处理所需的。在这种情况下，最好使用 XCP 迁移工具以更快的速度迁移数据。</block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">在大数据集群中，数据存储在 HDFS 或 HCFS 中，例如 MapR-FS ， Windows Azure Storage Blob ， S3 或 Google 文件系统。我们使用 HDFS ， MapR-FS 和 S3 作为源进行了测试，以便在 NIPAM 的帮助下，使用源中的 hadoop distcp 命令将数据复制到 NetApp ONTAP NFS 导出。</block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">在大数据集群中，数据存储在 HDFS 或 HCFS 中，例如 MapR-FS ， Windows Azure Storage Blob ， S3 或 Google 文件系统。我们使用 HDFS ， MapR-FS 和 S3 作为源执行了测试，以便在 NIPAM 的帮助下，使用源中的 `Hadoop distcp` 命令将数据复制到 NetApp ONTAP NFS 导出。</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">下图显示了从运行 HDFS 存储的 Spark 集群到 NetApp ONTAP NFS 卷的典型数据移动，以便 NVIDIA 可以处理 AI 操作。</block>
  <block id="d824b1bb9493b5a6c5a2e74871468633" category="paragraph"><block ref="d824b1bb9493b5a6c5a2e74871468633" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">`hadoop distcp` 命令使用 MapReduce 程序复制数据。NIPAM 可与 MapReduce 结合使用，在复制数据时充当 Hadoop 集群的驱动程序。NIPAM 可以在多个网络接口之间分布负载，以便进行一次导出。在将数据从 HDFS 或 HCFS 复制到 NFS 时，此过程会通过在多个网络接口之间分布数据来最大程度地提高网络吞吐量。</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">不支持 NIPAM ，也不会通过 MapR 认证。</block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">本白皮书提供了使用 NetApp XCP 和 NIPAM 将大数据分析数据和 HPC 数据迁移到 AI 的准则。我们还讨论了将数据从大数据和 HPC 迁移到 AI 的业务优势。</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732 ：大数据分析数据到人工智能</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">本文档介绍如何将大数据分析数据和 HPC 数据迁移到 AI 。AI 通过 NFS 导出处理 NFS 数据，而客户通常将其 AI 数据存储在 HDFS ， Blob 或 S3 存储等大数据分析平台以及 GPFS 等 HPC 平台中。本白皮书提供了使用 NetApp XCP 和 NIPAM 将大数据分析数据和 HPC 数据迁移到 AI 的准则。我们还讨论了将数据从大数据和 HPC 迁移到 AI 的业务优势。</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">概念和组件</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">大数据分析存储</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">大数据分析是 HDFS 的主要存储提供商。客户通常使用与 Hadoop 兼容的文件系统（ HCFS ），例如 Windows Azure Blob Storage ， MapR 文件系统（ MapR-FS ）和 S3 对象存储。</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">常规并行文件系统</block>
  <block id="432f31a1b9dc5a8ef1f048ea3f4f98c8" category="paragraph">IBM 的 GPFS 是一种企业级文件系统，可替代 HDFS 。利用 GPF ，应用程序可以灵活地确定块大小和复制布局，从而提供良好的性能和效率。</block>
  <block id="2aff401779cc49866458a642f15c0181" category="inline-link">TR-4382 ： NetApp 原位分析模块。</block>
  <block id="ae1165a7ed0006d2dae65ea849898810" category="paragraph">NetApp 原位分析模块（ NIPAM ）可作为 Hadoop 集群访问 NFS 数据的驱动程序。它包含四个组件：连接池， NFS InputStream ，文件句柄缓存和 NFS OutputStream 。有关详细信息，请参见<block ref="aedae5b2590b798973be1ab298f44ab7" category="inline-link-rx"></block></block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Hadoop 分布式副本</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop 分布式副本（ DistCp ）是一种分布式副本工具，用于执行大型集群间和集群内应对任务。此工具使用 MapReduce 进行数据分发，错误处理和报告。它会扩展文件和目录列表，并输入这些文件和目录以映射任务，从而从源列表复制数据。下图显示了 HDFS 和非 HDFS 中的 DistCp 操作。</block>
  <block id="1a76b3e0f1199267d461c961d30d07a5" category="paragraph"><block ref="1a76b3e0f1199267d461c961d30d07a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp 可在两个 HDFS 系统之间移动数据，而无需使用其他驱动程序。NetApp 为非 HDFS 系统提供了驱动程序。对于 NFS 目标， NIPAM 提供了用于复制数据的驱动程序， Hadoop DistCp 在复制数据时使用这些数据与 NFS 目标进行通信。</block>
  <block id="05fc55cae9e8b2a7fb40e978e4971707" category="paragraph">NetApp Cloud Volumes Service 是一种性能极高的云原生文件服务。此服务可通过快速启动和关闭资源并使用 NetApp 功能来提高工作效率并减少员工停机时间，帮助客户加快产品上市速度。Cloud Volumes Service 是灾难恢复和备份到云的理想替代方案，因为它可以减少数据中心的整体占用空间，并减少原生公有云存储的使用量。</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP 是一款客户端软件，可实现快速可靠的任意到 NetApp 和 NetApp 到 NetApp 数据迁移。此工具用于将大量非结构化 NAS 数据从任何 NAS 系统复制到 NetApp 存储控制器。XCP 迁移工具使用多核多通道 I/O 流式引擎，可以并行处理多个请求，例如数据迁移，文件或目录列表以及空间报告。这是默认的 NetApp 数据迁移工具。您可以使用 XCP 将数据从 Hadoop 集群和 HPC 复制到 NetApp NFS 存储。下图显示了使用 XCP 从 Hadoop 和 HPC 集群到 NetApp NFS 卷的数据传输。</block>
  <block id="cd7e68aa30250a331c260fee49ff230e" category="paragraph"><block ref="cd7e68aa30250a331c260fee49ff230e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">对于此解决方案， NetApp 验证了将数据从数据湖（ HDFS ）和 MapR 集群数据迁移到 ONTAP NFS 的过程。数据驻留在 MapR-FS 和 HDFS 中。NetApp XCP 引入了一项新功能，可将数据从分布式文件系统（例如 HDFS 和 MapR-FS ）直接迁移到 ONTAP NFS 。</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS 和 MapR-FS 到 ONTAP NFS</block>
  <block id="4581f9b32af32647aa31b2f9d57f6f1f" category="paragraph"><block ref="4581f9b32af32647aa31b2f9d57f6f1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">客户为什么要从 HDFS 和 MapR-FS 迁移到 NFS ？</block>
  <block id="b075c8e6a9009d582333c59e237e3646" category="paragraph">大多数 Hadoop 分发软件包（例如 Cloudera 和 Hortonworks ）都使用 HDFS ，而 MapR 分发软件包使用自己的文件系统 Mapr-FS 来存储数据。HDFS 和 MapR-FS 数据为数据科学家提供了宝贵的见解，可用于机器学习（ ML ）和深度学习（ DL ）。HDFS 和 MapR-FS 中的数据不会共享，这意味着它不能由其他应用程序使用。客户正在寻找共享数据，尤其是在银行领域，客户的敏感数据由多个应用程序使用。最新版本的 Hadoop （ 3.x 或更高版本）支持 NFS 数据源，无需其他第三方软件即可访问该数据源。借助新的 NetApp XCP 功能，可以将数据直接从 HDFS 和 MapR-FS 移动到 NetApp NFS ，以便访问多个应用程序</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">我们在 Amazon Web Services （ AWS ）中进行了测试，以便将数据从 MapR-FS 传输到 NFS ，以便对 12 个 MAPR 节点和 4 个 NFS 服务器进行初始性能测试。</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">Size</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">vCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">内存</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">网络</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">NFS 服务器</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488 GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8 个 7500 NVMe SSD</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">MapR 节点</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12 个大型</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384 GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4 个 7500 NVMe SSD</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">根据初始测试，我们获得了 20 Gbps 的吞吐量，并且能够每天传输 2 PB 的数据。</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link">TR-4863 ： TR-4863 ：《 NetApp XCP 最佳实践指南—数据移动，文件迁移和分析》</block>
  <block id="6371d61614d0beaedb75e85d2c297d8f" category="paragraph">有关在不将 HDFS 导出到 NFS 的情况下进行 HDFS 数据迁移的详细信息，请参见中的 " 部署步骤 - NAS" 一节<block ref="6a602f6a965c96a94215a45f0077e771" category="inline-link-rx"></block>。</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">大数据分析数据到人工智能</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">从 GPF 到 NFS —详细步骤</block>
  <block id="75afdb5cd8c025ed0681bdb302fcdcda" category="cell">在 NVA-1160 中增加了新的章节：通过 OperatorHub 和 Ansible 安装 Astra 控制中心</block>
  <block id="593fdc7a2167cd2ada3e71219ceb0ecb" category="paragraph">有关详细信息，请访问 Astra Trident 网站<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>。</block>
  <block id="3d930ae98e9d9fc9a418d6b8e5e5639f" category="cell">21.12.60</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="2bb7e89d50aed884078c4b7857f5bb39" category="cell">4.6 EUS ， 4.7 ， 4.8</block>
  <block id="1e90637438eb06672159d2998d220e86" category="open-title">使用 OperatorHub</block>
  <block id="bff0144772c74d96da07b6ccefb79f96" category="list-text">登录到 NetApp 支持站点并下载最新版本的 NetApp Astra 控制中心。为此，您需要在 NetApp 帐户中附加许可证。下载完 tarball 后，将其传输到管理工作站。</block>
  <block id="baac643870c95006b4243d078606a15d" category="list-text">开始安装之前，请将 Astra Control Center 映像推送到映像注册表。您可以选择使用 Docker 或 Podman 执行此操作，此步骤将提供这两者的说明。</block>
  <block id="455cbd59356abfa16dcf7666d4ae6c2b" category="list-title">Podman</block>
  <block id="ee9b41d8a22021826def077c661525f4" category="list-text">使用非公共信任的私有映像注册表时，请将映像注册表 TLS 证书上传到 OpenShift 节点。为此，请使用 TLS 证书在 OpenShift-config 命名空间中创建一个配置映射，并将其修补到集群映像配置中以使此证书可信。</block>
  <block id="9c656c969a87783fcf4b94b721f34bc9" category="list-text">为 Astra 控制中心创建命名空间 `NetApp-Acc-operator` 。</block>
  <block id="788e8355bdd3a21f3a9017a0610940f4" category="list-text">使用 cluster-admin 访问权限登录到 Red Hat OpenShift GUI 控制台。</block>
  <block id="3d68b5654b778f026ac691bc6ed70cc5" category="list-text">导航到 Operators &gt; OperatorHub 并搜索 Astra 。</block>
  <block id="dc7add750562c445f72d8d016a79ae29" category="list-text">选择 `NetApp-Acc-operator` Tile ，然后单击 `Install` 。</block>
  <block id="c80be3093b470ca8092538e58a261952" category="image-alt">Accc 运算符图块</block>
  <block id="c65c283737dc37cea2358a91588ff272" category="list-text">在 Install Operator 屏幕上，接受所有默认参数，然后单击 `Install` 。</block>
  <block id="3677d31e24a1853c961f3f1a9a39a1d6" category="image-alt">会计操作员详细信息</block>
  <block id="ba14525c4ccc9b2f692d062104885b19" category="image-alt">附件操作员等待安装</block>
  <block id="fea3120ff933c367a5882d58dbbe8a08" category="list-text">操作员安装成功后，导航到单击 `View Operator` 。</block>
  <block id="a573acc0621ea72a06ce987a341768bf" category="image-alt">附件操作员安装完成</block>
  <block id="f99196bf6b988223fab800f28cf0323c" category="list-text">然后在运算符中单击 Astra Control Center 图块中的 `Create Instance` 。</block>
  <block id="11f7c569d04eecd142ba5989efcc2da3" category="image-alt">创建 Acc 实例</block>
  <block id="02780e148f03f25db76204c23985d753" category="list-text">填写 `Create AstraControlCenter` Form 字段，然后单击 `Create` 。</block>
  <block id="e31f3b85c5179d88bcf0629842c5342f" category="list-text">也可以编辑 Astra Control Center 实例名称。</block>
  <block id="3336a2124154da151aecfe1809d7c821" category="list-text">也可以启用或禁用自动支持。建议保留自动支持功能。</block>
  <block id="14ddbb7fd85c2907073b06492b95191b" category="list-text">输入 Astra 控制中心的 FQDN 。</block>
  <block id="fbcd656fecc902b1994e346dc0627266" category="list-text">输入 Astra 控制中心版本；默认情况下会显示最新版本。</block>
  <block id="311a20c50b8e2d72cf9b31eb6339bff4" category="list-text">输入 Astra 控制中心的帐户名称和管理员详细信息，例如名字，姓氏和电子邮件地址。</block>
  <block id="163e6534daeb1cbd7c56b20a9477802f" category="list-text">输入卷回收策略，默认值为 Retain 。</block>
  <block id="5863d7f52b409374d0d80b1bcbba68fd" category="list-text">在映像注册表中，输入注册表的 FQDN 以及在将映像推送到注册表时提供的组织名称（在此示例中为 `astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra` ）</block>
  <block id="95279718d2829cd5ed7772d6f0a77ca9" category="list-text">如果您使用的注册表需要进行身份验证，请在映像注册表部分输入机密名称。</block>
  <block id="b8f9ae819a2d6559f55aed837fdc2a47" category="list-text">为 Astra 控制中心资源限制配置扩展选项。</block>
  <block id="3b489b9fd690a8cdf710454d0ccb5288" category="list-text">如果要将 PVC 放置在非默认存储类上，请输入存储类名称。</block>
  <block id="6b9265a82fa5bd326052ec55e040a54a" category="list-text">定义 CRD 处理首选项。</block>
  <block id="90aa5928482975bc6ff56f0eaf052451" category="open-title">自动化的〔可逆〕</block>
  <block id="b8571b33af3335fed61ab0d7985d007f" category="list-text">克隆托管 Ansible 内容的 GitHub 存储库。</block>
  <block id="5ed95667cae604c0ddee2dbf04f423fe" category="list-text">登录到 NetApp 支持站点并下载最新版本的 NetApp Astra 控制中心。为此，您需要在 NetApp 帐户中附加许可证。下载完 tarball 后，将其传输到工作站。</block>
  <block id="6238d4091e12ffa6643c0dc68d72ceab" category="list-text">创建或获取对要安装 Astra 控制中心的 OpenShift 集群具有管理员访问权限的 kubeconfig 文件。</block>
  <block id="b736c713f352ab43e7543fda4589e96f" category="list-text">将目录更改为 na_astera_control_suite 。</block>
  <block id="4f31682e7040024757006eed6ba0344a" category="list-text">编辑 vars/vars.yml 文件并使用所需信息填充变量。</block>
  <block id="8d1e5f9175948d3e6f932794744cde16" category="section-title">安装后步骤</block>
  <block id="8b70487815961b708f216595f5817311" category="paragraph">最新版 Astra Trident 于 2022 年 1 月发布。已测试的 Trident 版本的支持列表，可在该支持列表中找到 Kubernetes 分发版本<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>。</block>
  <block id="b5d9e69ac9444a6a1cfd78cf106c057e" category="list-text">将安装归档下载到管理工作站并提取内容。Trident 的当前版本为 22.01 ，可以下载<block ref="defadeb91446b93776c7f5696677985c" category="inline-link-rx"></block>。</block>
  <block id="89c771069f269704306d4ca7b118cc7d" category="paragraph">但是，对于 NFSv3 ，客户端和服务器之间没有协商并发的机制。因此，客户端的最大 SUNRPC 插槽表条目数必须与服务器上支持的值手动同步，以确保 NFS 连接的最佳性能，而服务器不必减小连接的窗口大小。</block>
  <block id="9c2d7353683234845149cb6710dc11f8" category="paragraph">对于 ONTAP ，支持的最大 SUNRPC 插槽表条目数为 128 ，即 ONTAP 一次可以处理 128 个并发 NFS 请求。但是，默认情况下，每个连接的 Red Hat CoreOS/Red Hat Enterprise Linux 最多包含 65 ， 536 个 SUNRPC 插槽表条目。我们需要将此值设置为 128 ，可以在 OpenShift 中使用计算机配置操作员（ Machine Config Operator ， MCO ）来完成此操作。</block>
  <block id="88cd6afaae477b942c9ab5d396e43cfb" category="paragraph">要修改 OpenShift 工作节点中的最大 SUNRPC 插槽表条目，请完成以下步骤：</block>
  <block id="e7a7478f209d8b5dcaf38a593ce749b3" category="list-text">创建 MCO 后，需要在所有工作节点上应用此配置并逐个重新启动。整个过程大约需要 20 到 30 分钟。使用 `oc get MCP` 验证是否应用了计算机配置，并确保已更新员工的计算机配置池。</block>
  <block id="068d2023b916134a0573aaad841124e4" category="paragraph">要配置工作节点以运行 iSCSI 服务，请完成以下步骤：</block>
  <block id="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link"><block ref="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link-rx"></block></block>
  <block id="086fce5f74cc93b0516aadec33636e09" category="paragraph"><block ref="086fce5f74cc93b0516aadec33636e09" category="inline-link-rx"></block></block>
  <block id="0611f127a7e1e7ef5bbd782030c2e34a" category="paragraph">在 NetApp ONTAP 上为不同项目创建不同的 SVM 之后，必须将每个 SVM 映射到不同的 Trident 后端。Trident 上的后端配置会将永久性存储分配给 OpenShift 集群资源，并且需要将 SVM 的详细信息映射到。此驱动程序至少应为后端的协议驱动程序。或者，您也可以通过它定义如何在存储上配置卷，并设置卷大小或聚合使用量等限制。有关 Trident 后端定义的详细信息，请参见<block ref="47a77763732c6cebe093a4a4d61aaa5b" category="inline-link-rx"></block>。</block>
  <block id="891c9b8b0ce367c5e377a1ec23199619" category="paragraph">配置 Trident 后端后，下一步是配置 StorageClasses 。配置与后端相同数量的存储类，为每个存储类提供访问权限，以便仅在一个后端启动卷。在定义存储类时，我们可以使用 storagePools 参数将 StorageClass 映射到特定的 Trident 后端。可以找到用于定义存储类的详细信息<block ref="1266deb20a7d7c4814b1225e5e572606" category="inline-link-rx"></block>。因此，从 StorageClass 到 Trident 后端存在一对一映射，这种映射可指向一个 SVM 。这样可以确保通过分配给该项目的 StorageClass 处理的所有存储请求仅由专用于该项目的 SVM 处理。</block>
  <block id="b09383080793dfb527084933760af6ed" category="paragraph"><block ref="b09383080793dfb527084933760af6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f372cf1de9e60f6875a0b24a5c28b07" category="list-text">输入快照详细信息，单击下一步，然后单击 Snapshot 。创建快照大约需要一分钟，在成功创建快照后，状态将变为可用。</block>
  <block id="42dd75b4fbc849903d5d179a8e68d570" category="paragraph"><block ref="42dd75b4fbc849903d5d179a8e68d570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0929177ba68c50d4dd73a2a3311ac885" category="paragraph"><block ref="0929177ba68c50d4dd73a2a3311ac885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f789c3d3aacfbd2d2f99ba395ddb8bc5" category="list-text">输入备份详细信息，选择用于保存备份文件的对象存储分段，单击下一步，查看详细信息后，单击备份。根据应用程序和数据的大小，备份可能需要几分钟的时间，备份成功完成后，备份状态将变为可用。</block>
  <block id="4ba6af660a8dd39dc1d12fb6ee80ba81" category="paragraph"><block ref="4ba6af660a8dd39dc1d12fb6ee80ba81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b1fda3b0f36b6fd708a9871e1c19c50" category="section-title">还原应用程序</block>
  <block id="344aed2ab37311beed01bbd40d93caed" category="paragraph">只需按一个按钮，即可将应用程序还原到同一集群中的原始命名空间或远程集群，以实现应用程序保护和灾难恢复。</block>
  <block id="8ac352fe46a0c45e744688191b7df581" category="list-text">要还原应用程序，请导航到应用程序 &gt; 受管选项卡，然后单击相关应用程序。单击应用程序名称旁边的下拉菜单，然后单击 `Restore` 。</block>
  <block id="84eb14028ce6ae6f2bf17b71ebe50c69" category="paragraph"><block ref="84eb14028ce6ae6f2bf17b71ebe50c69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b33d7fda666bdb32a2be1f3783106a3c" category="list-text">输入还原命名空间的名称，选择要将其还原到的集群，然后选择是要从现有快照还是从应用程序的备份还原它。单击下一步。</block>
  <block id="7bbb08271e6b60bc55d6817c7e100528" category="paragraph"><block ref="7bbb08271e6b60bc55d6817c7e100528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9242e3e5428d2ddbd81dece3073767a" category="list-text">在查看窗格中，输入 `restore` ，然后在查看详细信息后单击 Restore 。</block>
  <block id="7d6d73878ae09dbfd1e5ee7a0ecab66c" category="inline-image-macro">Astra 控制中心还原审核</block>
  <block id="b862f033546ae8bdc1bb091ad8b57023" category="paragraph"><block ref="b862f033546ae8bdc1bb091ad8b57023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b86c631d7b3beb0163beee546245df6" category="list-text">当 Astra 控制中心在选定集群上还原应用程序时，新应用程序将进入还原状态。在 Astra 安装并检测到应用程序的所有资源后，该应用程序将进入可用状态。</block>
  <block id="81d066be6d2211bf186bc1960361d8e3" category="paragraph"><block ref="81d066be6d2211bf186bc1960361d8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4600d44abb914105737c3d4a802b87c" category="section-title">克隆应用程序</block>
  <block id="5394f3451a07ae7dbe101ceb0725a004" category="paragraph">您可以将应用程序克隆到发起集群或远程集群，以进行开发 / 测试或应用程序保护和灾难恢复。在同一个存储后端的同一集群中克隆应用程序时，会使用 NetApp FlexClone 技术，从而可以即时克隆 PVC 并节省存储空间。</block>
  <block id="04783413cee5e3c613efc7939cea3560" category="list-text">要克隆应用程序，请导航到应用程序 &gt; 受管选项卡，然后单击相关应用程序。单击应用程序名称旁边的下拉菜单，然后单击克隆。</block>
  <block id="1cfafd65804d582aac709fefcd3e60cd" category="paragraph"><block ref="1cfafd65804d582aac709fefcd3e60cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="654c7a62842024ed8e405ed0ac9c4377" category="list-text">输入新命名空间的详细信息，选择要将其克隆到的集群，然后选择是要从现有快照，备份还是应用程序的当前状态克隆该命名空间。查看详细信息后，单击下一步并单击审阅窗格时克隆。</block>
  <block id="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="paragraph"><block ref="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60bae26bb7c1e8711f1e39a45fc7b6c7" category="paragraph"><block ref="60bae26bb7c1e8711f1e39a45fc7b6c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d656f81a685df3697a812158d0bd2f21" category="paragraph">NetApp Astra Trident 是一款开源且完全受支持的存储编排程序，适用于容器和 Kubernetes 分发版，包括 Red Hat OpenShift 。有关详细信息，请访问 Astra Trident 网站<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>。</block>
  <block id="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="list-text"><block ref="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="inline-link-macro-rx"></block></block>
  <block id="ea1c9e7b76d8b7cc203b9f6a9633e241" category="list-text"><block ref="ea1c9e7b76d8b7cc203b9f6a9633e241" category="inline-link-macro-rx"></block></block>
  <block id="4105298f144b4b0e636460eede523df0" category="inline-link-macro">通过 Ansible 自动安装 Astra 控制中心</block>
  <block id="64295ddd382f7876d307bac08ad539fe" category="cell"><block ref="64295ddd382f7876d307bac08ad539fe" category="inline-link-macro-rx"></block></block>
  <block id="bd6059cd679908cdb2d015167d51a3fe" category="cell"><block ref="bd6059cd679908cdb2d015167d51a3fe" category="inline-link-macro-rx"></block></block>
  <block id="6dc07ae6ad84b77b5d06f9d3fff5b819" category="cell"><block ref="6dc07ae6ad84b77b5d06f9d3fff5b819" category="inline-link-macro-rx"></block></block>
  <block id="e32276e1eed6ff0e76971afd985cea2d" category="cell"><block ref="e32276e1eed6ff0e76971afd985cea2d" category="inline-link-macro-rx"></block></block>
  <block id="77697d49d0c6b79e2642435a36c8c1e0" category="cell"><block ref="77697d49d0c6b79e2642435a36c8c1e0" category="inline-link-macro-rx"></block></block>
  <block id="60f031c992a9c99aa5413bddb0ecc644" category="cell"><block ref="60f031c992a9c99aa5413bddb0ecc644" category="inline-link-macro-rx"></block></block>
  <block id="13a82ffd84cedcd28833f58d716b4c3c" category="cell"><block ref="13a82ffd84cedcd28833f58d716b4c3c" category="inline-link-macro-rx"></block></block>
  <block id="74d542ee52cd8400c9b9307ed9a99c12" category="list-text">Astra DevOps 用例：</block>
  <block id="3da7df001d5e1f907d2527f52c6ccc00" category="inline-link-macro">借助 NetApp Astra Control ，可以轻松地将保护功能集成到 Kubernetes CI/CD 管道中</block>
  <block id="3f1cbb7eb907b7cb7f46877360d4a588" category="list-text"><block ref="3f1cbb7eb907b7cb7f46877360d4a588" category="inline-link-macro-rx"></block></block>
  <block id="fa4bd1682f261cdd55edf3e8e7dbfef6" category="inline-link-macro">采用 NetApp 的 DevOps ：使用 Astra Control 执行事后分析并还原您的应用程序</block>
  <block id="1188d1aaa4a5f54ec1dab3da3576377a" category="list-text"><block ref="1188d1aaa4a5f54ec1dab3da3576377a" category="inline-link-macro-rx"></block></block>
  <block id="ce932b248d7f57bcada97c64dd7429a7" category="inline-link-macro">NetApp Astra 控制中心：应用程序数据管理的便捷按钮</block>
  <block id="0d47bfb381dd96470ac538b5a112db04" category="list-text"><block ref="0d47bfb381dd96470ac538b5a112db04" category="inline-link-macro-rx"></block></block>
  <block id="6546814199e52492fa0efe5fbff08d5a" category="paragraph">此解决方案 支持 SnapCenter 当前支持的所有数据库，但此处仅展示了 Oracle 和 SQL Server 数据库。此解决方案已通过虚拟化数据库工作负载的验证，但也支持裸机工作负载。</block>
  <block id="f2a59783d2b5c7be84fec0d6de7a5ae9" category="cell">2022 年 8 月 3 日</block>
  <block id="eab6f1cc9736be0f5d62999f998bf36a" category="cell">添加了一个新的视频演示：使用 Astra Control 和 NetApp FlexClone 技术加速软件开发</block>
  <block id="5df42c63d444f6e9e40d96be8f17ac6f" category="cell">2022 年 3 月 1 日</block>
  <block id="9fe0dbff6457627765d03955bd1659be" category="inline-link-macro">视频：借助 Astra Control 和 NetApp FlexClone 技术加快软件开发速度</block>
  <block id="a0eaa75e3e2b8c6220db02697d4acf1f" category="cell"><block ref="a0eaa75e3e2b8c6220db02697d4acf1f" category="inline-link-macro-rx"></block></block>
  <block id="d5ca81c242aff843ea151d778578cbfc" category="admonition">如果您的注册表使用的是不可信的证书，请编辑 shell 脚本并对 podman 推送命令 `podman 推送 $registry/$ （ echo $astraImage ` s/`^^` ………………………………………………………………………………………………………………………………………………</block>
  <block id="b4360d9dcce9e932e3b5b09fdc524745" category="list-text"><block ref="b4360d9dcce9e932e3b5b09fdc524745" category="inline-link-macro-rx"></block></block>
  <block id="fdab91853bf925f2256c6d39ec3f5351" category="section-title">在 GCP 中配置 GCVE</block>
  <block id="9e98cd6f2c1243193cfc50a29bbe3bd4" category="list-text"><block ref="9e98cd6f2c1243193cfc50a29bbe3bd4" category="inline-link-macro-rx"></block></block>
  <block id="553bafb094b811158ae732981f2dbb4e" category="list-text"><block ref="553bafb094b811158ae732981f2dbb4e" category="inline-link-macro-rx"></block></block>
  <block id="202373c4c91793dc8fb54647ff8a2241" category="list-text"><block ref="202373c4c91793dc8fb54647ff8a2241" category="inline-link-macro-rx"></block></block>
  <block id="9597c351929448a6eea4162c4f4a80db" category="list-text"><block ref="9597c351929448a6eea4162c4f4a80db" category="inline-link-macro-rx"></block></block>
  <block id="169210ceac9b94f0632cd1182961e949" category="open-title">CVO 单节点部署</block>
  <block id="610db6bf34b03f7873afe01d4eec8e58" category="paragraph">本节包含各种 Terraform 配置文件，用于在 AWS （ Amazon Web Services ）上部署 / 配置单节点 NetApp CVO （ Cloud Volumes ONTAP ）。</block>
  <block id="4a537f87e89ac00b1276af84fa6f2da9" category="paragraph">Terraform 文档：<block ref="e2ea72ce6afb985e72624e098135e8e1" category="inline-link-rx"></block></block>
  <block id="c69eb42cd732c6d937af674afc73ba24" category="paragraph">要运行此模板，请执行以下操作：</block>
  <block id="0b2fc5bb85de930f6b1d839951f8df6d" category="list-text">克隆存储库。</block>
  <block id="6f5cc42a3e67b7edb3a2d4b86ebfae01" category="list-text">导航到所需文件夹</block>
  <block id="71046100fbc383dd8cd1cdd6160f6d6d" category="list-text">从 CLI 配置 AWS 凭据。</block>
  <block id="4a4f9b0378c89fa21da9e5528c8a7f47" category="list-text">AWS 访问密钥 ID [ 无 ] ：访问密钥</block>
  <block id="6bbb2ea6e07d16e69748545bf2ee6a6d" category="list-text">AWS 机密访问密钥 [ 无 ] ： secretkey</block>
  <block id="7a31be9d48b53cd82a7160af0cd58fbe" category="list-text">默认区域名称 [ 无 ] ： us-west-2</block>
  <block id="276bf14207394167e2ed4e3eed448680" category="list-text">默认输出格式 [ 无 ] ： JSON</block>
  <block id="dd08960caafad89635926c55a0efd3a4" category="list-text">更新 `vars/AWS_CVO_single 节点 _deployment.tfvar` 中的变量值</block>
  <block id="e962d97debd0a377828855d79b5ccf66" category="admonition">您可以通过将变量 "AWS_connector_deploy_bool" 值设置为 true/false 来选择部署连接器。</block>
  <block id="88cefa0997a2272107223ee543b114db" category="list-text">初始化 Terraform 存储库以安装所有前提条件并准备部署。</block>
  <block id="046372e4315eccae02c5be2caaac1ac5" category="list-text">使用 terraform validate 命令验证 terraform 文件。</block>
  <block id="144930ffd88cabf8795c7d4a6698e4ac" category="list-text">运行此配置以预览部署所需的所有更改。</block>
  <block id="50a325adfbe874e5e14b044244efa49e" category="list-text">运行部署</block>
  <block id="3125f7b5833c80fbd03966accb540bf8" category="paragraph">删除部署</block>
  <block id="58c9aaf9cf3d4d0215afe012b77aa1bc" category="paragraph">`连接器`</block>
  <block id="251861170f071d1ebe67b948f5026905" category="paragraph">用于 CVO 部署的 NetApp AWS 连接器实例的 Terraform 变量。</block>
  <block id="496ee322ba138fdbc777e5ab2e30145e" category="cell">* 名称 *</block>
  <block id="7464a7978b1ad9e7f36e5f0181e97eb5" category="cell">* 类型 *</block>
  <block id="22d8f94f4a088cb8d7c83ec5f44a03af" category="cell">* AWS 连接器 _deploy_Bool*</block>
  <block id="c26f15e86e3de4c398a8273272aba034" category="cell">池</block>
  <block id="95ab4e4a16c4f585ede4d3c63167c1ee" category="cell">（必需）检查连接器部署。</block>
  <block id="e15fa495ec49ba53e0ba45d555c24027" category="cell">* AWS 连接器名称 *</block>
  <block id="27118326006d3829667a400ad23d5d98" category="cell">string</block>
  <block id="5548283861d04af602b7193306751df7" category="cell">（必需） Cloud Manager Connector 的名称。</block>
  <block id="8c3a0cf46a98725e12d666e2e13dc06d" category="cell">* AWS 连接器区域 *</block>
  <block id="efb4f51f6b08f54633b02a06b94210f2" category="cell">（必需）要创建 Cloud Manager Connector 的区域。</block>
  <block id="358040941579fe064f522f5b1eac2a33" category="cell">* AWS 连接器 _key_name*</block>
  <block id="5c2f4db5972ecd2062c5f449f09c661f" category="cell">（必需）要用于 Connector 实例的密钥对的名称。</block>
  <block id="0e46676177a5b007dfeefb6ada2b65af" category="cell">* AWS 连接器公司 *</block>
  <block id="a7f1f5d73f372170ea283996e464af43" category="cell">（必需）用户公司的名称。</block>
  <block id="9b9081642589bb52bb20161632edc5a6" category="cell">* AWS 连接器 _instance_type*</block>
  <block id="ddd1c9b22f94863b3de9a1b551188553" category="cell">（必需）实例的类型（例如 T3.xlarge ）。至少需要 4 个 CPU 和 16 GB 内存。</block>
  <block id="f8a700002db36fadde1ab9526f2cf8c3" category="cell">* AWS 连接器 _subnet_id*</block>
  <block id="76788966b37b9b0df0b8ed78ad67eea9" category="cell">（必需）实例的子网 ID 。</block>
  <block id="fafb089eb14a5fe730cfadfd7bed4b4f" category="cell">* AWS 连接器 _security_group_id*</block>
  <block id="52df26383575ad500acf38cc3df88e36" category="cell">* AWS 连接器 _iam_instance_profile_name*</block>
  <block id="59409115b42184ffa519bd9aa24b6816" category="cell">（必需） Connector 实例配置文件的名称。</block>
  <block id="8953ca5d18d5f2c4a85fdfe10d30a002" category="cell">* AWS 连接器帐户 ID *</block>
  <block id="bba7484e58b18e8edafdbe619961f73f" category="cell">（可选） Connector 要关联的 NetApp 帐户 ID 。如果未提供， Cloud Manager 将使用第一个帐户。如果不存在任何帐户， Cloud Manager 将创建一个新帐户。您可以在 Cloud Manager 的帐户选项卡中找到帐户 ID ，网址为<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>。</block>
  <block id="1918f44c178eed586b6fa7d6739af317" category="cell">* AWS 连接器 _public_ip_bool*</block>
  <block id="a4472307f162bdf147f02784bf81ab9d" category="cell">（可选）指示是否将公有 IP 地址与实例关联。如果未提供，则关联将根据子网的配置完成。</block>
  <block id="9fb01bbff06d549bce01928fa2f7784c" category="paragraph">`s单节点实例`</block>
  <block id="d166b6e004666a5a8daa6db1c3cf1a13" category="paragraph">单个 NetApp CVO 实例的 Terraform 变量。</block>
  <block id="19afa3a1ac092d450f21236f1973c705" category="cell">* CVO_NAME*</block>
  <block id="59935a520838700b451a3757f31fd4ac" category="cell">（必需） Cloud Volumes ONTAP 工作环境的名称。</block>
  <block id="ff855355eebbbfbd54d2734a61c43fd4" category="cell">* CVO_地区 *</block>
  <block id="b50ada32f992aba9f7055658a79132f2" category="cell">（必需）要创建工作环境的区域。</block>
  <block id="0e9b90f836062c3007935370ef18245f" category="cell">* CVO_subnet_id*</block>
  <block id="6c7cb9b4623284c101253ed002625e53" category="cell">（必需）要创建工作环境的子网 ID 。</block>
  <block id="a99ec45accc4987a7eb2eff5219f96b3" category="cell">* CVO_VPC_ID*</block>
  <block id="a179f6c6854fc89c6f118f4d8c201cad" category="cell">（可选）要创建工作环境的 VPC ID 。如果未提供此参数，则 VPC 将使用提供的子网 ID 进行计算。</block>
  <block id="26ff13994e5fbad1e11fc231bc73a5b6" category="cell">* CVO_SVM_password*</block>
  <block id="c82a889260bdc28c6136ddc6639a4f2e" category="cell">（必需） Cloud Volumes ONTAP 的管理员密码。</block>
  <block id="3815749b59fbccfa0077df4f90c8aa1e" category="cell">* CVO_writing_speed_state*</block>
  <block id="e382698236dcb1567d375a4be3b12c2f" category="cell">（可选） Cloud Volumes ONTAP 的写入速度设置： "Normal" ， "high" 。默认值为 "Normal" 。</block>
  <block id="197b0ef64aabdc02a240f3f472eb4da2" category="open-title">CVO HA 部署</block>
  <block id="a082a9d97b4465f73e12cde3444a5296" category="paragraph">本节包含各种 Terraform 配置文件，用于在 AWS （ Amazon Web Services ）上以高可用性对部署 / 配置 NetApp CVO （ Cloud Volumes ONTAP ）。</block>
  <block id="b31736be0fe5e59cc4905aa080c9ab16" category="list-text">更新 `vars/AWS_CVO_ha_deployment.tfvars` 中的变量值。</block>
  <block id="ff8f4d628633e3ceb42dcca91ef2948e" category="paragraph">`HA 对`</block>
  <block id="f7fbe4e66ae4cece99ae14a24f1c44ef" category="paragraph">HA 对中 NetApp CVO 实例的 Terraform 变量。</block>
  <block id="018a56af12514193b08f44d59f92fe83" category="cell">* CVO_is_ha*</block>
  <block id="93d83a3a243548e55fb126d283923435" category="cell">（可选）指示工作环境是否为 HA 对。默认值为 false 。</block>
  <block id="cea330e4ead03fcfec439b1f44be7c07" category="cell">* CVO_Node1_subnet_id*</block>
  <block id="3a0cbf54e2a847cd873a45840f9965f5" category="cell">（必需）要创建第一个节点的子网 ID 。</block>
  <block id="d5d3a5e1275b1995e05472c7bfbcb53f" category="cell">* CVO_Node2_subnet_id*</block>
  <block id="5691678a4c059b3a4ebad0f4c6bf6bb5" category="cell">（必需）要创建第二个节点的子网 ID 。</block>
  <block id="4377aa272f4cf89d4bbd39432ffb3b0e" category="cell">* CVO_failover_mode*</block>
  <block id="9d76030e2a28826bff45ea1dff4d6920" category="cell">（可选）对于 HA ， HA 对的故障转移模式为： ["PrivateIP" ， "FlatingIP"] 。"PrivateIP" 用于单个可用性区域， "FlatingIP" 用于多个可用性区域。</block>
  <block id="80c8a57adaed641642cd870951a1d4ed" category="cell">* CVO_mediate_subnet_id*</block>
  <block id="49ef0197555436f78dd87f582e510523" category="cell">（可选）对于 HA ，是调解器的子网 ID 。</block>
  <block id="3efb524d034b1e223cb9d31a64f9bbc4" category="cell">* CVO_mediate_key_pair_name*</block>
  <block id="224733036290c1421bed8ad8de688956" category="cell">（可选）对于 HA ，是调解器实例的密钥对名称。</block>
  <block id="069dcc590a2acf756e6ca7f92d7d8355" category="cell">* CVO_cluster_floating_IP*</block>
  <block id="6325a8aefd56c67fab1d0d83b4cb8a2e" category="cell">（可选）对于 HA FlatingIP ，为集群管理浮动 IP 地址。</block>
  <block id="618070e07e603612f24fa88a7ab583a8" category="cell">* CVO_data_float_IP*</block>
  <block id="d8abdbcf87e3308c6a8e731ef574625c" category="cell">（可选）对于 HA FlatingIP ，是数据浮动 IP 地址。</block>
  <block id="f115ec8cf476ea0198405ca27346e423" category="cell">* CVO_data_float_IP2*</block>
  <block id="754296c6c8a8cf70377730f6f126f24a" category="cell">* CVO_SVM_floating_IP*</block>
  <block id="797d132b963a11de245eae1725911bfe" category="cell">（可选）对于 HA FlatingIP ，为 SVM 管理浮动 IP 地址。</block>
  <block id="418ba9c064c1fb64b11195c729d6a8b1" category="cell">* CVO_route_table_IDS*</block>
  <block id="4ee29ca12c7d126654bd0e5275de6135" category="cell">列表</block>
  <block id="671a800e3791f7531a319e8b81e97c44" category="cell">（可选）对于 HA FlatingIP ，将使用浮动 IP 更新的路由表 ID 列表。</block>
  <block id="5d4a46c0a4567f819ba5935256b18297" category="open-title">FSX 部署</block>
  <block id="d43e39ffb05b35b72664b10dd8b8eb09" category="paragraph">本节包含用于在 AWS （ Amazon Web Services ）上部署 / 配置 NetApp ONTAP FSX 的各种 Terraform 配置文件。</block>
  <block id="171cc8e4954beec5176905189f71a708" category="list-text">默认输出格式 [ 无 ] ：</block>
  <block id="cbc2cee2851524f322f8d71e55d32a64" category="list-text">更新 `vars/AWS_FSx_deployment.tfvars` 中的变量值</block>
  <block id="05bf1719b762d4d80bcb0e545b3db1d2" category="paragraph">NetApp AWS 连接器实例的 Terraform 变量。</block>
  <block id="618716470abe9536903f3c6781c4ac81" category="paragraph">`FSX 实例`</block>
  <block id="5869d95322d3c435fd999596f0cf2303" category="paragraph">NetApp ONTAP FSX 实例的 Terraform 变量。</block>
  <block id="c64f672849455d583204c525f5ea39ad" category="cell">* FSx_name*</block>
  <block id="af87bb54b839634f865f7bd7e2be203a" category="cell">* FSx_Region</block>
  <block id="02a52209be6996bc01fd629ac6a5b472" category="cell">* FSx_primary_subnet_id*</block>
  <block id="5dcd0d05819e117f52d439bebd6d2b42" category="cell">（必需）要创建工作环境的主子网 ID 。</block>
  <block id="0531247f461759a809214a03ea2f5f74" category="cell">* FSx_secondary 子网 _id*</block>
  <block id="b2184e9a131868dbc2332805652a0f02" category="cell">（必需）要创建工作环境的二级子网 ID 。</block>
  <block id="a333cc205644905efae2cf71519da619" category="cell">* FSx_account_id*</block>
  <block id="323c4fdc16ad2dd9e846afbcd4b69b10" category="cell">（必需） FSX 实例将与之关联的 NetApp 帐户 ID 。如果未提供， Cloud Manager 将使用第一个帐户。如果不存在任何帐户， Cloud Manager 将创建一个新帐户。您可以在 Cloud Manager 的帐户选项卡中找到帐户 ID ，网址为<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>。</block>
  <block id="7355bef79bff8e33a86af33fe4dcca8e" category="cell">* FSx_worklan_id*</block>
  <block id="97377fef3f33f9c8d1fb21c0d81cdf92" category="cell">（必需）工作环境中 Cloud Manager 工作空间的 ID 。</block>
  <block id="ab77fdca353b13807c947d554712d8eb" category="cell">* FSx_admin_password*</block>
  <block id="c4bd49cb0034d697fd71cae233c3966c" category="cell">* FSx_throughput ： capacity*</block>
  <block id="e1ae53e33bf94a13f7d73cf885059ea6" category="cell">（可选）吞吐量的容量。</block>
  <block id="011dda542c81d29bda593f0cf6fafdfa" category="cell">* FSx_storage_capacity_size*</block>
  <block id="16b74c686b794890297f7ff7a9c98c9f" category="cell">（可选）第一个数据聚合的 EBS 卷大小。对于 GB ，单位可以是： 100 或 500] 。对于 TB ，此单位可以是： 1 ， 2 ， 4 ， 8 ， 16] 。默认值为 "1"</block>
  <block id="da7d44d0ad606f586a3b1f567c8502d6" category="cell">* FSx_storage_capacity_size_unit*</block>
  <block id="5ec54d3d7d1db9fbf915daed12667b29" category="cell">（可选） ["GB" 或 "TB"] 。默认值为 "TB" 。</block>
  <block id="07cc738168b47a86b740bc01e210b442" category="cell">* FSx_cloudmanager_AWS_credential 名称 *</block>
  <block id="48dbb4d925fe4a46f28c0a8466a2f628" category="cell">（必需） AWS 凭据帐户名称。</block>
  <block id="2fbb88fe90f9183c7eab541bc808795f" category="summary">此页面介绍了使用 Terraform 在云提供商（ AWS ， Azure ， GCP ）上部署 NetApp 卷的自动化方法。</block>
  <block id="8eece2f5500ed61d5d5d24d6b8cc6da5" category="doc">通过 Terraform 实现 Cloud Volumes Automation</block>
  <block id="e11da9afe91d381489a365c86cc614ab" category="section-title">前提条件</block>
  <block id="95332f844502bac70e3783f2d906688c" category="list-text">Terraform &gt;= 0.13</block>
  <block id="82410a61f302c6bdce619218d5036674" category="list-text">Cloud Manager 帐户</block>
  <block id="77913a2ff2c55b56fd6d981e7d7d2303" category="list-text">云提供商帐户— AWS ， Azure</block>
  <block id="8fdcd620b2871b4f496213f43c8ee21f" category="list-text">主机（ Terraform 支持的任何操作系统）</block>
  <block id="e5da768f23935e9c380799d86e27d695" category="section-title">提供程序文档</block>
  <block id="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-macro"><block ref="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-rx"></block></block>
  <block id="b78f34c8bc7d03e88e2a6d7d8907ef93" category="paragraph">有关适用于 Cloud Manager 的 Terraform Provider 的文档，请访问： <block ref="05e9b3cbe087530696c6230448ff6b71" category="inline-link-macro-rx"></block></block>
  <block id="ef335030cde4c62e318574aa31ee49f7" category="section-title">控制提供程序版本</block>
  <block id="cc6d892dc2fbac39a7a00c3d822275b8" category="paragraph">请注意，您也可以控制提供程序版本。这由 Terraform 配置中的 required_providers 块控制。</block>
  <block id="bf4e80680b83752f1f57ca7d4e99d09b" category="paragraph">语法如下：</block>
  <block id="c26cc3bad4e19f3604486c6e2d4dee15" category="paragraph">阅读有关提供程序版本控制的更多信息。</block>
  <block id="c335a311e2b771c143fbe09512d98021" category="section-title">运行特定模块</block>
  <block id="0d6f6c74055e04156e36ddb127070a54" category="open-title">ANF</block>
  <block id="3f5bad999be275e4e9cf0728a13bf09c" category="paragraph">本节包含用于在 Azure 上部署 / 配置 ANF （ Azure NetApp Files ）卷的各种 Terraform 配置文件。</block>
  <block id="61d66a29b98e4203b3fc2ea2884a6c5f" category="paragraph">Terraform 文档：<block ref="745f55dd9f8ecc62d59e6b03ca9efbb7" category="inline-link-rx"></block></block>
  <block id="369baedac810ebc745ed2edf7754972b" category="list-text">登录到 Azure 命令行界面（必须安装 Azure 命令行界面）。</block>
  <block id="443ff7602b19f9692863937e763e1ad2" category="list-text">更新 `vars/azure_anf.tfvars` 中的变量值。</block>
  <block id="95f6ca118177fad8a1dd7e7abb74ce56" category="admonition">您可以选择使用现有的 vnet 和子网部署 ANF 卷，方法是将变量 "vnet_creation_bool" 和 "subnet_creation_bool" 值设置为 false 并提供 "subnet_id_for_anf_vol" 。您也可以将这些值设置为 true 并创建新的 vnet 和子网，在这种情况下，子网 ID 将自动从新创建的子网中获取。</block>
  <block id="cb01f53471a55574a36eafb375d9493a" category="paragraph">单个 NetApp ANF 卷的 Terraform 变量。</block>
  <block id="98bcef9bf5f44342e688bc29fb3fcbca" category="cell">* AZ 位置 *</block>
  <block id="4b05afb76d83065313c3740cd392a5ca" category="cell">（必需）指定资源所在的受支持 Azure 位置。更改后，系统将强制创建新资源。</block>
  <block id="861c040d5ed0212e4bc2aa4f92a2b861" category="cell">* AZ 前缀 *</block>
  <block id="e6f149d38df85bed35faeca44370c01c" category="cell">（必需）应在其中创建 NetApp 卷的资源组的名称。更改后，系统将强制创建新资源。</block>
  <block id="7aa7ec2fc803d9041e6dfd5e142dcd23" category="cell">* 空格 _vnet_address_space*</block>
  <block id="c8b090fd446e4181ed79e8e50bed7b91" category="cell">（必需）新创建的 Vnet 用于 ANF 卷部署的地址空间。</block>
  <block id="c5b9420927a71e0bcd6f4c621c66910f" category="cell">* AZ 子网地址前缀 *</block>
  <block id="94c126b468fd9c408abdff2cccd827a4" category="cell">（必需）新创建的 Vnet 要用于 ANF 卷部署的子网地址前缀。</block>
  <block id="3c3133cb45a10a4ec442a4589636bfe1" category="cell">* 。 as_volume_path*</block>
  <block id="c8fb8ccec1ede566cac7b410b7623186" category="cell">（必需）卷的唯一文件路径。用于创建挂载目标。更改后，系统将强制创建新资源。</block>
  <block id="5e51835c1dd28fa3cab3636a6beb8016" category="cell">* AZ 容量池大小 *</block>
  <block id="a0faef0851b4294c06f2b94bb1cb2044" category="cell">整型</block>
  <block id="32c4a6ca695ae0fd3f41efe5ab8d3ffc" category="cell">* 。 as_vnet_creation_bool*</block>
  <block id="27226c864bac7454a8504f8edb15d95b" category="cell">布尔值</block>
  <block id="55a1cc8d235c0ca9bd0cf384e2db1fb2" category="cell">（必需）如果要创建新的 vnet ，请将此布尔值设置为 `true` 。将其设置为 `false` 以使用现有 vnet 。</block>
  <block id="be85fde9f0fcdf86be8ede4b5939a9bf" category="cell">* AZ-subnet_creation_bool*</block>
  <block id="4b079d5e017c7403047fbbd37df93368" category="cell">（必需）将此布尔值设置为 `true` 以创建新子网。将其设置为 `false` 可使用现有子网。</block>
  <block id="bb74e9c4e24089c59a6af0a7a016b586" category="cell">* AZ-subnet_id_for_anf_vol*</block>
  <block id="52c0fe6a129fdcf33be82680a15b2d37" category="cell">（必需）在您决定使用现有子网时，请注明子网 ID ，方法是将 `ssubnet_creation_bool` 设置为 true 。如果设置为 false ，请将其保留为默认值。</block>
  <block id="8376cf4b94c63b51d5e0113c299a75a0" category="cell">* AZ-NetApp_Pool_service_level*</block>
  <block id="061fce6317efb41fcda88b5333cb0cc2" category="cell">（必需）文件系统的目标性能。有效值包括 `Premium` ， `Standard` 或 `超高` 。</block>
  <block id="cd145efde532a4a27c5b6687f4b5f1c0" category="cell">* AZ-NetApp_vol_service_level*</block>
  <block id="d655c67b837d5b3363d556955802b670" category="cell">* AZ-NetApp_vol_protocol*</block>
  <block id="9e2a44ac250e0b60bce77fba70ebfd70" category="cell">（可选）以列表形式表示的目标卷协议。支持的单个值包括 `CIFS` ， `NFSv3` 或 `NFSv4.1` 。如果未定义参数，则默认为 `NFSv3` 。更改后，系统将强制创建新资源并丢失数据。</block>
  <block id="cac15590a2775bfeaf5f70c36186a840" category="cell">* AZ-NetApp_vol_security_style*</block>
  <block id="80f43a817b6716a1a82af5fe18f178cd" category="cell">（可选）卷安全模式，可接受的值为 `Unix` 或 `NTFS` 。如果未提供此参数，则创建的单协议卷默认为 `Unix` （如果为 `NFSv3` 或 `NFSv4.1` volume ）；如果为 `CIFS` ，则默认为 `NTFS` 。在双协议卷中，如果未提供此参数，其值将为 `NTFS` 。</block>
  <block id="b095a46d015fe5581a97472eedb3e645" category="cell">* AZ-NetApp_vol_storage_quot*</block>
  <block id="aaff31e02103a31c6f08943798a84789" category="cell">（必需）文件系统允许的最大存储配额，以 GB 为单位。</block>
  <block id="7bc40f4d4f846e8c7177d752ac52b775" category="open-title">ANF 数据保护</block>
  <block id="56978261632f1f36ad5f3f3ea6d2cb4b" category="paragraph">本节包含用于在 Azure 上部署 / 配置具有数据保护的 ANF （ Azure NetApp Files ）卷的各种 Terraform 配置文件。</block>
  <block id="9b3e184737a0a337479622611ba072b7" category="list-text">更新 `vars/azure_anf_data_protection.tfvars` 中的变量值。</block>
  <block id="bf052e3d77cd2cde5fa905542df51c46" category="paragraph">`ANF 数据保护`</block>
  <block id="17745d8782266e5f08c77485447c8727" category="cell">* AZ 备选位置 *</block>
  <block id="3bfeadf4c47a658ca94a6066aee32aaa" category="cell">（必需）要创建二级卷的 Azure 位置</block>
  <block id="2558355ccfd79f11c2c7771d473c28a9" category="cell">* 空格 _vnet_primary_address_space*</block>
  <block id="cc551875f8711aaffc6141f504677c0b" category="cell">（必需）新创建的 Vnet 用于 ANF 主卷部署的地址空间。</block>
  <block id="ea5f0cd471c631d7531bb7fd3b5bac8a" category="cell">* 空格 _vnet_secondary 地址空间 *</block>
  <block id="fffcb59495331e54049ce33d3dcdf943" category="cell">（必需）新创建的 Vnet 用于 ANF 二级卷部署的地址空间。</block>
  <block id="88220764f0745e8a07a6578ee5a34962" category="cell">* AZ-subnet_primary_address_prefix*</block>
  <block id="02b00c599f6c249474a4fa82513b5ae3" category="cell">（必需）新创建的 Vnet 要用于 ANF 主卷部署的子网地址前缀。</block>
  <block id="1bef049d5f330664e35cad0a064c3b9c" category="cell">* AZ-subnet_secondary 地址前缀 *</block>
  <block id="1b60506e52e47ecc443e5be52dca93d7" category="cell">（必需）新创建的 Vnet 要用于 ANF 二级卷部署的子网地址前缀。</block>
  <block id="897362b63a34b0eb8e1453709c1f8403" category="cell">* AZ-volume_path_primary_*</block>
  <block id="1240d8345e0d2e3e79133040103d900c" category="cell">（必需）主卷的唯一文件路径。用于创建挂载目标。更改后，系统将强制创建新资源。</block>
  <block id="b9dd6d654f6dd5777451c38ccbb3a90f" category="cell">* AZ 卷路径二级 *</block>
  <block id="2d48913a4e9f87154afa26a5629292ac" category="cell">（必需）二级卷的唯一文件路径。用于创建挂载目标。更改后，系统将强制创建新资源。</block>
  <block id="06c1e84417c5bf369b90b26dd5249917" category="cell">* AZ-Capacity_Pool_size_primary_*</block>
  <block id="3d618d26614058ac7e5a064cbe202b90" category="cell">* AZ 容量池大小二级 *</block>
  <block id="900391b8f681698a00a1d7681c809eae" category="cell">* 。 as_vnet_primary_creation_bool*</block>
  <block id="ee71ed057be46b5303595075681242b3" category="cell">（必需）如果要为主卷创建新的 vnet ，请将此布尔值设置为 `true` 。将其设置为 `false` 以使用现有 vnet 。</block>
  <block id="1f3233bfcd515798625102d02489c9c2" category="cell">* 。 as_vnet_secondary _creation_bool*</block>
  <block id="8a5a92fb6843cb45a9752dac34d8056a" category="cell">（必需）如果要为二级卷创建新的 vnet ，请将此布尔值设置为 `true` 。将其设置为 `false` 以使用现有 vnet 。</block>
  <block id="0276da5ab0cbfd3afccac3236ff88906" category="cell">* AZ-subnet_primary_creation_bool*</block>
  <block id="ba2f66ccca4d07fb389900a4c72596a7" category="cell">（必需）将此布尔值设置为 `true` ，为主卷创建新子网。将其设置为 `false` 可使用现有子网。</block>
  <block id="78a2830c902a8a1eb6bbedc95b8e859d" category="cell">* AZ-subnet_secondary _creation_bool*</block>
  <block id="1b869ff43f405cb5056d067f1ce0ea2c" category="cell">（必需）将此布尔值设置为 `true` ，为二级卷创建新子网。将其设置为 `false` 可使用现有子网。</block>
  <block id="004f2f461ceadcb0d344b03f2f00c53d" category="cell">* AZ 主子网 ID for_anf_vol*</block>
  <block id="387a4516572f71aa24490f3bbfc695ef" category="cell">（必需）在您决定使用现有子网时，请注明子网 ID ，方法是将 `ssubnet_primary_creation_bool` 设置为 true 。如果设置为 false ，请将其保留为默认值。</block>
  <block id="2e9685846dda27855273fdf064f9e6ab" category="cell">* AZ 二级子网 id_for_anf_vol*</block>
  <block id="bf5c8bfc6d7cc2d5fe6e7931244a30eb" category="cell">（必需）在您决定使用现有子网时，请注明子网 ID ，方法是将 `ssubnet_secondary _creation_bool` 设置为 true 。如果设置为 false ，请将其保留为默认值。</block>
  <block id="ac839f935b4bbb6bed9bda28a8e642c6" category="cell">* AZ-NetApp_Pool_service_level_primary_*</block>
  <block id="8cb34f1d64a5bf358b0d3a349ca5bc2f" category="cell">* AZ-NetApp_Pool_service_level_secondary *</block>
  <block id="7ad9306273877be4925eef5c298c8082" category="cell">* AZ-NetApp_vol_service_level_primary_*</block>
  <block id="5614656fa00c06faf1c3484531a679a9" category="cell">* AZ-NetApp_vol_service_level_secondary *</block>
  <block id="4f517398039e7c48806d41487b9419bc" category="cell">* AZ-NetApp_vol_protocol_primary_*</block>
  <block id="82b777cb90770b16388fa42e12e046ab" category="cell">* AZ-NetApp_vol_protocol_secondary *</block>
  <block id="59783d86d863461df5e6d03ac2bb42df" category="cell">* AZ-NetApp_vol_storage_quota_primary_*</block>
  <block id="de8fa216337d1b3497efb08ceeb2ba75" category="cell">* AZ-NetApp_vol_storage_quota_secondary *</block>
  <block id="0b11ea56e0e5211214ff431c4e076717" category="cell">* AZ DP 复制频率 *</block>
  <block id="79ce3fc5fe45b145bb343376fe5351b9" category="cell">（必需）复制频率，支持的值为 `10 分钟` ， `每小时` ， `dy` ，值区分大小写。</block>
  <block id="c623b4e11f7cb20ff0b7c24a72d3f0ef" category="open-title">ANF 双协议</block>
  <block id="d25220d03f7afcb6f5edcbc46e369d45" category="paragraph">本节包含各种 Terraform 配置文件，用于部署 / 配置在 Azure 上启用了双协议的 ANF （ Azure NetApp Files ）卷。</block>
  <block id="9568461c901e88398bed16e11ad813d3" category="list-text">更新 `vars/azure_anf_dual_protocol.tfvars` 中的变量值。</block>
  <block id="d263b475ab751de671d08455b33997c1" category="paragraph">启用了双协议的单个 ANF 卷的 Terraform 变量。</block>
  <block id="b183512797a1d9ea69a8dab9e27df52c" category="cell">* AZ-NetApp_vol_Protocol1*</block>
  <block id="20fd02f6a193c7aeaee651654a332933" category="cell">（必需）以列表形式表示的目标卷协议。支持的单个值包括 `CIFS` ， `NFSv3` 或 `NFSv4.1` 。如果未定义参数，则默认为 `NFSv3` 。更改后，系统将强制创建新资源并丢失数据。</block>
  <block id="cc032be5baf5b9484eb2d659f4e314c6" category="cell">* AZ-NetApp_vol_protocol2*</block>
  <block id="910944ff76e7b2acfc482a34501df6f5" category="cell">* AZ-SMB_server_username*</block>
  <block id="152372e48ac8f85f2e4908c5a1489a78" category="cell">（必需）用于创建 ActiveDirectory 对象的用户名。</block>
  <block id="239e5edf090c4c70025b340f651694cc" category="cell">* AZ-SMB_server_password*</block>
  <block id="7b05e834084d190fe540481374f4fe0d" category="cell">（必需）用于创建 ActiveDirectory 对象的用户密码。</block>
  <block id="4e2be381ec92158458ceef11bdf41ef7" category="cell">* AZ-SMB_server_name*</block>
  <block id="533dd582bfe3528b9b6ae4ff1889bd8f" category="cell">（必需）用于创建 ActiveDirectory 对象的服务器名称。</block>
  <block id="f17c01535ba9f04720700d5e0d17172a" category="cell">* AZ-SMB_DNS_servers*</block>
  <block id="e70256203c6e23fcee3efa8d56fcfa85" category="cell">（必需）用于创建 ActiveDirectory 对象的 DNS 服务器 IP 。</block>
  <block id="bdf618611712c6caa6fd0340470ee9f2" category="open-title">来自 Snapshot 的 anf 卷</block>
  <block id="174e6e8f24023c93c7c470267f4c2376" category="paragraph">本节包含用于从 Azure 上的 Snapshot 部署 / 配置 ANF （ Azure NetApp Files ）卷的各种 Terraform 配置文件。</block>
  <block id="215d5ed09cbe3ca5b10c6d616024053a" category="list-text">更新 `vars/azure_anf_volume_from_snapshot.tfvars` 中的变量值。</block>
  <block id="a753ff452c91c6e4de63b907e8253e05" category="paragraph">使用 snapshot 的单个 ANF 卷的 Terraform 变量。</block>
  <block id="57bd49c8f9a43967f48ec8f1f3ca2846" category="cell">* 。 as_snapshot_id*</block>
  <block id="ff461cb79e6adda28ae488782f0da97f" category="cell">（必需）用于创建新 ANF 卷的 Snapshot ID 。</block>
  <block id="04107ff6b0460381c55ff620a1021254" category="list-text">更新 `vars\azure_CVO_single 节点 _deployment.tfvars` 中的变量。</block>
  <block id="73b95097cc4819b49af28734c8da85f9" category="paragraph">单节点 Cloud Volumes ONTAP （ CVO ）的 Terraform 变量。</block>
  <block id="3226e634f46cb19ab313171144dd34bd" category="cell">* 刷新令牌 *</block>
  <block id="d687ff26916f17fd879c87b138961b29" category="cell">（必需） NetApp Cloud Manager 的刷新令牌。这可以从 NetApp Cloud Central 生成。</block>
  <block id="2c64afa8a46290b632eba256c644932c" category="cell">* AZ 连接器名称 *</block>
  <block id="3eb8706ea09733709f78eddf34865fc5" category="cell">* AZ 连接器位置 *</block>
  <block id="758699b195f5916d500521462cf30da9" category="cell">（必需）创建 Cloud Manager Connector 的位置。</block>
  <block id="1fab22f54c2298a6c193e9dbf02a5f40" category="cell">* AZ 连接器 _subscription_id*</block>
  <block id="3eaa20b60039584fbaada041b1e9c27b" category="cell">（必需） Azure 订阅的 ID 。</block>
  <block id="15a22866556f3e50073015243ddd7953" category="cell">* AZ 连接器公司 *</block>
  <block id="d6da30a455e4a736b78aebafd5a574ec" category="cell">* AZ 连接器 _resource_group*</block>
  <block id="7869ff24b2017b68dfcffe9346969d04" category="cell">（必需） Azure 中要创建资源的资源组。</block>
  <block id="9ddf31c7bd196ef12b5afc14819332ae" category="cell">* AZ 连接器 _subnet_id*</block>
  <block id="a41a332f5c3dda90835d004d4471e0a8" category="cell">（必需）虚拟机的子网名称。</block>
  <block id="dabe6b258248c0eefb5e7f8ef812c828" category="cell">* AZ 连接器 _vnet_id*</block>
  <block id="5209c2acb9f23446cfa41482e2ff8ee2" category="cell">（必需）虚拟网络的名称。</block>
  <block id="d00bbff7436422db546132791ca30dd2" category="cell">* AZ 连接器 _network_security_group_name*</block>
  <block id="b5033b19e9c2388be995930fb1c49365" category="cell">（必需）实例的安全组名称。</block>
  <block id="54dee4dedf4b10ae9a250e887c349324" category="cell">* AZ 连接器 _associate_public_ip_address*</block>
  <block id="c954a4a98e68d0734dcd6d7ad00db3f5" category="cell">（必需）指示是否将公有 IP 地址与虚拟机关联。</block>
  <block id="d363651cb914dfbc47f512db8ce8a9c0" category="cell">* AZ 连接器帐户 ID *</block>
  <block id="53b73bbe0bca0a3d51fbda15ecc058db" category="cell">（必需） Connector 要关联的 NetApp 帐户 ID 。如果未提供， Cloud Manager 将使用第一个帐户。如果不存在任何帐户， Cloud Manager 将创建一个新帐户。您可以在 Cloud Manager 的帐户选项卡中找到帐户 ID ，网址为<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>。</block>
  <block id="b851f892237fb399ca9999caee142ccf" category="cell">* AZ-Connector_admin_password*</block>
  <block id="aa98915ce83ffe89562020e5b4d9a376" category="cell">（必需） Connector 的密码。</block>
  <block id="1b9c1e319401f16966d7280c81cdc8dc" category="cell">* AZ-Connector_admin_username*</block>
  <block id="e0f32faffed9caaca61e86caae050f17" category="cell">（必需） Connector 的用户名。</block>
  <block id="425624e10c5de04d471a55e4a8b35e31" category="cell">* AZ-CVO_NAME*</block>
  <block id="52ebf6980a494c352ee150c2b801af6e" category="cell">* AZ-CVO_OITE*</block>
  <block id="8da06548b40415fd473a86a6dba80f82" category="cell">* AZ-CVO_subnet_id*</block>
  <block id="f71ced0388b772479b4e5fba15c83077" category="cell">* AZ-CVO_vnet_id*</block>
  <block id="7d2219b61301dda6352db570bb7c5034" category="cell">* AZ-CVO_vnet_resource_group*</block>
  <block id="fecf56abdc6b5472c8da399cad7791b3" category="cell">（必需） Azure 中与虚拟网络关联的资源组。</block>
  <block id="c63d2e90acb0448db277b1b5b8a8d1fa" category="cell">* AZ-CVO_data_encryption_type*</block>
  <block id="e472a1445850887a7f62ae832b27693a" category="cell">（必需）工作环境要使用的加密类型： [`Azure` ， `none` ] 。默认值为 `Azure` 。</block>
  <block id="a09db82d06138c721102bb24bf44745c" category="cell">* AZ-CVO_storage_type*</block>
  <block id="0f0f84813d06e378040fbcf33a733c2c" category="cell">（必需）第一个数据聚合的存储类型：`Premium_LRS` ， `Standard_LRS` ， `StandardSSD_LRS` 。默认值为 `Premium_LRS`</block>
  <block id="2dc6453586c69ea950eec68d5ac9658c" category="cell">* AZ-CVO_SVM_password*</block>
  <block id="404c8599d393a19d0cd6354f8b6ae58c" category="cell">* AZ-CVO_workspace ID</block>
  <block id="ec0d845babe316d32a485960e8788bd0" category="cell">（必需）要部署 Cloud Volumes ONTAP 的 Cloud Manager 工作空间的 ID 。如果未提供， Cloud Manager 将使用第一个工作空间。您可以从上的 " 工作空间 " 选项卡中找到此 ID<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>。</block>
  <block id="868f934d26dc5bf64ab570c48f38be79" category="cell">* AZ-CVO_capacity_tier*</block>
  <block id="e8dcbe7d10f08e94b9057a584009a175" category="cell">（必需）是否为第一个数据聚合启用数据分层：`Blob` ， `none` 。默认值为 `BLOB` 。</block>
  <block id="25390bc170c676096ec93edd61a5dca6" category="cell">* AZ-CVO_writing_speed_state*</block>
  <block id="b632952868dfa1143652e0c226514318" category="cell">（必需） Cloud Volumes ONTAP 的写入速度设置： [`normal` ， `high` ] 。默认值为 `normal` 。此参数与 HA 对无关。</block>
  <block id="52742ffdac7415fc1d35c1a6d0d9fb7a" category="cell">* AZ-CVO_ontap_version*</block>
  <block id="90e696b73ff714675fc926a955cc68e1" category="cell">（必需）所需的 ONTAP 版本。如果 "use_latest_version" 设置为 true ，则忽略此参数。默认情况下使用最新版本。</block>
  <block id="39a41303384652e186a359e5d96e8014" category="cell">* AZ-CVO_instance_type*</block>
  <block id="fb03bbd04a925d04740ba3d3eae2e8b6" category="cell">（必需）要使用的实例类型，具体取决于您选择的许可证类型： Explore ： `Standard_DS3_v2` ， Standard ： `Standard_DS4_v2 ， Standard_DS13_v2 ， Standard_L8s_v2` ， Premium ： `Standard_DS5_v2` ， `S` tandard_DS4_v2 ，适用于所有实例类型： BYOL_14 。有关更多受支持的实例类型，请参见《 Cloud Volumes ONTAP 发行说明》。默认值为 `Standard_DS4_v2` 。</block>
  <block id="c0abbc4097de55ad558bd265d5e19b2e" category="cell">* AZ-CVO_LICENSE_TYPE *</block>
  <block id="337fb3a0d6e4f27fa4187c6e10b9d41b" category="cell">（必需）要使用的许可证类型。对于单个节点：`azure-cot-explore-paygo` ， `azure-cot-standard-paygo` ， `azure-cot-premy-paygo` ， `azure-cot-premy-BYOL` ， `capacity-paygo` 。对于 HA ：`azure-ha-cot-standard-paygo` ， `azure-ha-cot-premy-paygo` ， `azure-ha-cot-premy-BYOL` ， `ha-capacity-paygo` 。默认值为 `azure-cot-standard-paygo` 。在选择 Bring your own License type capacity-based 或 Freemium 后，请对 HA 使用 `capacity-paygo` 或 `ha-capacity-paygo` 。在选择 Bring Your Own License type Node-Based 后，请使用 `azure-cot-premy-BYOL` 或 `azure-ha-cot-premy-BYOL` for HA 。</block>
  <block id="5e952a0432dfc8995121e15b76aa554a" category="cell">* AZ-CVO_NSS_account*</block>
  <block id="c3ae78309504c231f8afd5bc3790d119" category="cell">（必需）用于此 Cloud Volumes ONTAP 系统的 NetApp 支持站点帐户 ID 。如果许可证类型为 BYOL 且未提供 NSS 帐户，则 Cloud Manager 会尝试使用第一个现有 NSS 帐户。</block>
  <block id="e7e63db47174977525dadf7a52fc6b39" category="cell">* AZ 租户 ID *</block>
  <block id="66093475775d81b74da52f4377ff5ce5" category="cell">（必需）在 Azure 中注册的应用程序 / 服务主体的租户 ID 。</block>
  <block id="7934d010494793aec0f365d710cdf720" category="cell">* AZ 应用程序 ID *</block>
  <block id="587bfaa720a64e832c9eef635797e8d8" category="cell">（必需）在 Azure 中注册的应用程序 / 服务主体的应用程序 ID 。</block>
  <block id="67830019a9948cfd51759684b5f8a262" category="cell">* AZ-application_key*</block>
  <block id="56d6515673e3c08156696c47a943c020" category="cell">（必需）在 Azure 中注册的应用程序 / 服务主体的应用程序密钥。</block>
  <block id="522a4529185faee9fa34a9398ab7263f" category="list-text">更新 `vars\azure_CVO_ha_deployment.tfvars` 中的变量。</block>
  <block id="e2da3e968f76091801635ce624569dcb" category="paragraph">`HA 对实例`</block>
  <block id="86ed32721429fbcc7b5e123836e3ebcd" category="paragraph">HA 对 Cloud Volumes ONTAP （ CVO ）的 Terraform 变量。</block>
  <block id="72170ff3a9ca936d7855297f0bbd1eeb" category="cell">（必需）要使用的实例类型，具体取决于您选择的许可证类型： Explore ： `Standard_DS3_v2` ， Standard ： `Standard_DS4_v2 ， Standard_DS13_v2 ， Standard_L8s_v2` ， Premium ： `Standard_DS5_v2` ， `standard_DS14_v2` ， BYOL ：为 PayGo 定义的所有实例类型。有关更多受支持的实例类型，请参见《 Cloud Volumes ONTAP 发行说明》。默认值为 `Standard_DS4_v2` 。</block>
  <block id="b515d8e49b6ef626aa91dbd970708132" category="cell">（必需）要使用的许可证类型。对于单个节点：`azure-cot-explore-paygo ， azure-cot-standard-paygo ， azure-cot-premy-paygo ， azure-cot-premy-BYOL ， capacity-paygo` 。HA ：`azure-ha-cot-standard-paygo ， azure-ha-cot-premy-paygo ， azure-ha-cot-premy-BYOL ， ha-capacity-paygo` 。默认值为 `azure-cot-standard-paygo` 。在选择 Bring your own License type capacity-based 或 Freemium 后，请对 HA 使用 `capacity-paygo` 或 `ha-capacity-paygo` 。在选择 Bring Your Own License type Node-Based 后，请使用 `azure-cot-premy-BYOL` 或 `azure-ha-cot-premy-BYOL` for HA 。</block>
  <block id="728aafab2377ad85ce4ae3f6a4b3dd33" category="cell">（必需）实例的安全组 ID ，可以提供多个安全组，并以 " ， " 分隔。</block>
  <block id="0db20ddc31a427cc02802395aa53db7f" category="cell">（必需）以 TB 为单位提及的容量池大小。</block>
  <block id="c47acd947f63c78f7729c5c176778d53" category="paragraph">启用了数据保护的单个 ANF 卷的 Terraform 变量。</block>
  <block id="ca7ce11916c29a2c94b4fd33dc0b6313" category="paragraph">本节包含用于在 Azure 上部署 / 配置单节点 CVO （ Cloud Volumes ONTAP ）的各种 Terraform 配置文件。</block>
  <block id="7bd8d7a58d3957cf7697ceb3467bffae" category="cell">（必需）创建工作环境的位置。</block>
  <block id="a5ab436e757f5af2106d5ed5e5dd9df0" category="cell">（必需） Cloud Volumes ONTAP 系统的子网名称。</block>
  <block id="353190ef77d18ad13aeb6b4f0f3ddd66" category="paragraph">本节包含用于在 Azure 上部署 / 配置 CVO （ Cloud Volumes ONTAP ） HA （高可用性）的各种 Terraform 配置文件。</block>
  <block id="3adefdd7d79d9a7c848b2dd81fd4feff" category="paragraph">本节包含各种 Terraform 配置文件，用于在 GCP （ Google 云平台）上部署 / 配置单节点 NetApp CVO （ Cloud Volumes ONTAP ）。</block>
  <block id="b05dddcb6f00ee8dba8395d241b9d24d" category="list-text">将 GCP 身份验证密钥 JSON 文件保存在目录中。</block>
  <block id="44b4381353a1686f5b81f73f018d336c" category="list-text">更新 `vars/gcp_CVO_single 节点 _deployment.tfvar` 中的变量值</block>
  <block id="2ac544064187c52d64d3eec81700dd42" category="admonition">您可以通过将变量 "gcp_connector_deploy_bool" 值设置为 true/false 来选择部署连接器。</block>
  <block id="283162995c6eba560352663fa7cafbb3" category="paragraph">用于 CVO 部署的 NetApp GCP 连接器实例的 Terraform 变量。</block>
  <block id="c0b4a62bb4903159c66ef5fd828dbb35" category="cell">* gcp_connector_deploy_bool*</block>
  <block id="3448a02a5105e0eeb2a6243836814f36" category="cell">* GCP_connector_name*</block>
  <block id="982137a628765a4ede6a620653ab8bf6" category="cell">* GCP_connector_project_id*</block>
  <block id="816194da363b92545a1114d46c4943f1" category="cell">（必需）要创建连接器的 GCP project_id 。</block>
  <block id="49a94de7b7e8762f961e471d657496eb" category="cell">* GCP_connector_zone*</block>
  <block id="ff9633a62f1e60af63fc951afd6966bc" category="cell">（必需）要创建连接器的 GCP 分区。</block>
  <block id="c667eb31817317b5455e6a8883f4664a" category="cell">* GCP_connector_company_*</block>
  <block id="9d1203849926481ebb6be1fb1d6ec3de" category="cell">* GCP_connector_service_account_email *</block>
  <block id="d4a302e18b412231fe06e54e038aed80" category="cell">（必需）连接器实例的 service_account 的电子邮件。此服务帐户用于允许 Connector 创建云卷 ONTAP 。</block>
  <block id="0e3852268e0e5a3a486b8fcf6e3ae1c1" category="cell">* GCP_connector_service_account_path*</block>
  <block id="f863e677d176e63d3642e53ae6b336b5" category="cell">（必需） service_account JSON 文件的本地路径，用于 GCP 授权。此服务帐户用于在 GCP 中创建连接器。</block>
  <block id="cfd7e4961aa34c5626712429d469ed18" category="cell">* gcp_connector_account_id*</block>
  <block id="231d57c65fc42941f6a520976dc80ec3" category="cell">（可选） Connector 要关联的 NetApp 帐户 ID 。如果未提供， Cloud Manager 将使用第一个帐户。如果不存在任何帐户， Cloud Manager 将创建一个新帐户。您可以在 Cloud Manager 的帐户选项卡中找到帐户 ID ，网址为<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>。</block>
  <block id="9ea10c86ddbbfa93db9af98d0a38e7d7" category="paragraph">GCP 上单个 NetApp CVO 实例的 Terraform 变量。</block>
  <block id="9d8a021dcdac02b1cffc5ee14bc79241" category="cell">* GCP_CVO_NAME*</block>
  <block id="bc023aad2be985e1a3252a959cb2c43b" category="cell">* GCP_CVO_project_id*</block>
  <block id="c7a61709c9cf6aa90f854f8e30110412" category="cell">（必需） GCP 项目的 ID 。</block>
  <block id="6f74a6834cfd9c72b6694ae9ecb7f332" category="cell">* GCP_CVO_Zone*</block>
  <block id="dea2d3525e8ec98bbd9a7931a8ed9921" category="cell">（必需）要创建工作环境的区域的区域。</block>
  <block id="2c09e34e29e9c5f65d5d8ac921fd8105" category="cell">* GCP_CVO_GCP_SERVICE_account*</block>
  <block id="77853ddcc7178537c8d9c0301b71c991" category="cell">（必需） GCP_SERVICE_account 电子邮件，以便将冷数据分层到 Google Cloud Storage 。</block>
  <block id="ffb5588c947a413a01016a81af9ddbc7" category="cell">* GCP_CVO_SVM_password*</block>
  <block id="9507c3b760db1c7e6c8d1674933449e4" category="cell">* GCP_CVO_workspace ID</block>
  <block id="4efb152d95f2b6b19ca1387a26e8f750" category="cell">（可选）要部署 Cloud Volumes ONTAP 的 Cloud Manager 工作空间的 ID 。如果未提供， Cloud Manager 将使用第一个工作空间。您可以从上的 " 工作空间 " 选项卡中找到此 ID<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>。</block>
  <block id="7cbf1746ddada50a540811a75b633bfa" category="cell">* GCP_CVO_LICENSE_TYPE *</block>
  <block id="108ccbda23ae580baf5fb86c14613837" category="cell">（可选）要使用的许可证类型。对于单个节点： "capacity-payge" ， "gcp-cot-explore-payge" ， "gcp-cot-standard-payge" ， "gcp-cot-premy-payge" ， "gcp-cot-premy-BYOL" ， 对于 HA ： "ha-capacity-payge" ， "gcp-ha-cot-explore-payge" ， "gcp-ha-cot-standard-payge" ， "gcp-ha-cot-premy-payge" ， "gcp-ha-cot-premy-BYOL" 。对于单个节点，默认值为 "capacity-payGo" ，对于 HA ，默认值为 "ha-capacity-payGo" 。</block>
  <block id="ec6c16de8b82f3fc6c55f03f1d9a0848" category="cell">* GCP_CVO_capacity_package_name*</block>
  <block id="564565c1364213fe3ffcef055b61947b" category="cell">（可选）容量包名称： [' 基本 ' ， ' 专业 ' ， 'Freemi'] 。默认值为 " 基本 " 。</block>
  <block id="ac245610a2b7e434b78946f9ab069afe" category="paragraph">本节包含各种 Terraform 配置文件，用于在 GCP （ Google 云平台）上以高可用性对部署 / 配置 NetApp CVO （ Cloud Volumes ONTAP ）。</block>
  <block id="00c7a940cc525046dc63cee112a8ef2d" category="list-text">更新 `vars/gcp_CVO_ha_deployment.tfvars` 中的变量值。</block>
  <block id="657426021b9624d6c24fae901c9998c1" category="paragraph">GCP 上 HA 对中 NetApp CVO 实例的 Terraform 变量。</block>
  <block id="2a20062f50c253ff821e16ab60e9bd71" category="cell">* GCP_CVO_is_ha*</block>
  <block id="c7d1d567eb3eec5faac1c3efbf5c63d6" category="cell">* GCP_CVO_Node1_Zone*</block>
  <block id="2cb70db8c1982b17ac705ceace5b64ae" category="cell">（可选）节点 1 的分区。</block>
  <block id="b231cdca0a533a8afcbf95810dcdd937" category="cell">* GCP_CVO_Node2_Zone*</block>
  <block id="2aad8f424dde09a3fb42570367a156de" category="cell">（可选）节点 2 的分区。</block>
  <block id="7dd3bb55d8d71efcb06fc86bbb29993a" category="cell">* GCP_CVO_mediate_zone*</block>
  <block id="767c5594dfa391fbb74bd9360557a0a8" category="cell">（可选）用于调解器的分区。</block>
  <block id="4ecd0da4e352bb336bd4c5925e627fbb" category="cell">* GCP_CVO_VPC_ID*</block>
  <block id="0a49d29112682612dc74e881a68deed0" category="cell">（可选） VPC 的名称。</block>
  <block id="eedae790807f6f5998c1d5b2eccfcf91" category="cell">* GCP_CVO_subnet_id*</block>
  <block id="dbb13624053bb884443eb3a8a891a35e" category="cell">（可选） Cloud Volumes ONTAP 的子网名称。默认值为： "default" 。</block>
  <block id="5fbbd2383d042b5ab01878b936e467ff" category="cell">* GCP_CVO_vpc0_node_and_data_connection*</block>
  <block id="24239aec58a00d53d32147d2e71cca4d" category="cell">（可选） NIC1 的 VPC 路径，节点和数据连接所需。如果使用共享 VPC ，则必须提供 netwrok_project_id 。</block>
  <block id="b1dd5e2b134fc3db50406e05c7ae6c38" category="cell">* GCP_CVO_vpc1_cluster_connectivity*</block>
  <block id="714e5d0cdfde4cbf4df83df266c672e7" category="cell">（可选） NIC2 的 VPC 路径，集群连接所需。</block>
  <block id="f8d315b03e4b926495b923dfe4b49b23" category="cell">* GCP_CVO_vpc2_ha_connectivity*</block>
  <block id="5c144c2c76f5d988024f4d7398060d71" category="cell">（可选） NIC3 的 VPC 路径， HA 连接所需。</block>
  <block id="1366961106ddc181e83c467cf5559a14" category="cell">* GCP_CVO_vpc3_data_replication *</block>
  <block id="b4be5ce15bf4e51acd3167c47e79955f" category="cell">（可选） NIC4 的 VPC 路径，数据复制所需。</block>
  <block id="065308400ba1fac48f2ca62781d79dff" category="cell">* GCP_CVO_subnet0_node_and_data_connection*</block>
  <block id="2a33bb449fd47fa1f379b60f3e1473ca" category="cell">（可选） NIC 1 的子网路径，节点和数据连接需要此路径。如果使用共享 VPC ，则必须提供 netwrok_project_id 。</block>
  <block id="da8a35439720c0bc705f001b954bd61e" category="cell">* GCP_CVO_subnet1_cluster_connectivity*</block>
  <block id="01b515c3b8d74ae94df6572b47a3f06d" category="cell">（可选） NIC 2 的子网路径，集群连接所需。</block>
  <block id="7ea43f4ca8d2a868f20df11b9e0b39b2" category="cell">* GCP_CVO_subnet2_ha_connectivity*</block>
  <block id="a35bd275122015b3834d13c0dc72b87f" category="cell">（可选） NIC3 的子网路径， HA 连接所需。</block>
  <block id="16c5273854a933d221200af8f06d106a" category="cell">* GCP_CVO_subnet3_data_replication *</block>
  <block id="b36fab455a4e11803791a090935906af" category="cell">（可选） NIC4 的子网路径，数据复制所需。</block>
  <block id="e69179170f564daf56d8694c1c5d35fe" category="cell">* GCP_CVO_GCP_volume_size*</block>
  <block id="eb01714b284e762b9c44adfa5575690c" category="cell">（可选）第一个数据聚合的 GCP 卷大小。对于 GB ，单位可以是： 100 或 500] 。对于 TB ，此单位可以是： 1 ， 2 ， 4 ， 8 。默认值为 "1" 。</block>
  <block id="4c767d9b6ddddf4abeaece5590c0b101" category="cell">* GCP_CVO_GCP_volume_size_unit*</block>
  <block id="944ce323a5a1ffb09543fd409911cc88" category="open-title">CVS 卷</block>
  <block id="ffcc65b297748299934a184d39035ae4" category="paragraph">本节包含用于在 GCP （ Google Cloud Platform ）上部署 / 配置 NetApp CVS （ Cloud Volumes Services ）卷的各种 Terraform 配置文件。</block>
  <block id="732c3eabba1449281a4fddb59dbddcac" category="paragraph">Terraform 文档：<block ref="35b7d5c9a11899e5d5e07079551e8cef" category="inline-link-rx"></block></block>
  <block id="d203294ba4c28418657d90a7f8a7510d" category="list-text">更新 `vars/gcp_cvs_volume.tfvars` 中的变量值。</block>
  <block id="40686c9084c59387baf48000dd09e6ab" category="paragraph">`CVS 卷`</block>
  <block id="3efdf9b0e7f4af483444f271367d6361" category="paragraph">NetApp GCP CVS 卷的 Terraform 变量。</block>
  <block id="0ffdc0b2b4889601b216ab5087650d46" category="cell">* GCP_CVS_NAME*</block>
  <block id="8ff48dd93ed73eb9adc26090e58ed80b" category="cell">（必需） NetApp CVS 卷的名称。</block>
  <block id="b6759cef3cfc5890deb6a790f73c8b79" category="cell">* GCP_CVS_project_id*</block>
  <block id="b0257576709acc899b5376a171c3cd98" category="cell">（必需）要创建 CVS 卷的 GCP project_id 。</block>
  <block id="447b0e81ae249b907128b7ea83e045c5" category="cell">* GCP_CVS_GCP_service_account_path*</block>
  <block id="820ecb1b7a653c1e2dece0176d15eaed" category="cell">（必需） service_account JSON 文件的本地路径，用于 GCP 授权。此服务帐户用于在 GCP 中创建 CVS 卷。</block>
  <block id="6cb8bdefdf91cd2d80f6d9849de25fb8" category="cell">* GCP_CVS_EORG*</block>
  <block id="ec9461de174e3ad866c58b577c94034b" category="cell">（必需）要创建 CVS 卷的 GCP 区域。</block>
  <block id="fc944aa114b94de895d84f5375000c0b" category="cell">* GCP_CVS_NETWORK*</block>
  <block id="23a1cb77eeeabfd36bbab18e5de9f0dc" category="cell">（必需）卷的网络 VPC 。</block>
  <block id="31681a1878caf611cea11e159a4fc1aa" category="cell">* GCP_CVS_SIZE *</block>
  <block id="6f84d4d0c83121512056657a2dc0e808" category="cell">（必需）卷大小介于 1024 到 102400 之间（含 GiB ）。</block>
  <block id="5c1eb3efe4738cb21efadc992aeeef81" category="cell">* GCP_CVS_volume_path*</block>
  <block id="bacdc6093d23e2f886b0cb0609418030" category="cell">（可选）卷的卷路径名称。</block>
  <block id="0467ee670bdb8fff57da77368d6d5385" category="cell">* GCP_CVS_protocol_Types*</block>
  <block id="b91db1bd1a57ea4c9953036d82a63e95" category="cell">（必需）卷的 protocol_type 。对于 NFS ，请使用 "NFSv3" 或 "NFSv4" ，对于 SMB ，请使用 "CIFS" 或 "MB" 。</block>
  <block id="7dcf4233280fcc0e80d2c5b8ce82af91" category="paragraph">NetApp SnapCenter 软件是一款易于使用的企业平台，可安全地协调和管理应用程序，数据库和文件系统之间的数据保护。</block>
  <block id="7dc8c97b0d6d3055290baa0eb36dbfa5" category="paragraph">您可以使用适用于 VMware vSphere 的 SnapCenter 插件对 VM 执行备份，还原和连接操作，并对直接在 VMware vCenter 中向 SnapCenter 注册的数据存储库执行备份和挂载操作。</block>
  <block id="00389b40803806e30e1877e1a0469e22" category="inline-link">适用于 VMware vSphere 的 NetApp SnapCenter 插件概述</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22.</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443.</block>
  <block id="d56302f459af314c7996db681d5b4696" category="cell">2022年3月29日</block>
  <block id="ee0b2b1b7d5e8eb309b29d0051f84d0c" category="cell">添加了一个新的TR：DevOps with NetApp Astra</block>
  <block id="a32ca451a300bb4e3c6b19cb1592126a" category="inline-link-macro">借助NetApp Astra实现DevOps</block>
  <block id="73677e8d319e77c91f647e668e868ecb" category="paragraph">有关详细信息、请访问OpenShift网站<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>。</block>
  <block id="f582083d849d313b57029bcb7e14f0b5" category="paragraph">有关详细信息、请访问NetApp网站<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>。</block>
  <block id="8fe0ec287a8d48a38a4f1454d62282f5" category="paragraph">NetApp Astra控制中心为部署在内部环境中并采用值得信赖的NetApp数据保护技术的有状态Kubernetes工作负载提供丰富的存储和应用程序感知型数据管理服务。</block>
  <block id="54fe0fc00087535e613994102131f164" category="paragraph">Astra Trident是一款开源且完全受支持的存储编排程序、适用于｛K8s_distribution_name｝等容器和Kubernetes分发版。</block>
  <block id="8f98c507505a202b216bb930f143954d" category="paragraph">NetApp拥有多个存储平台、这些平台均已通过Astra Trident和Astra Control的认证、可用于为容器化应用程序配置、保护和管理数据。</block>
  <block id="1268e1be2d69bcbe60fed1b018c4c7be" category="list-text">NetApp Element 存储系统可在高度可扩展的环境中涵盖基于块的(iSCSI)用例。</block>
  <block id="c64f419c58469b610f6840042d2d188c" category="admonition">NetApp产品组合中的每个存储系统都可以简化内部站点和云之间的数据管理和移动、从而使您的数据位于应用程序所在位置。</block>
  <block id="8d866fd138999801041cd8ebf044c39f" category="paragraph">以下页面介绍了有关已在｛Solution _name｝解决方案 中验证的NetApp存储系统的追加信息 ：</block>
  <block id="31190025c7f2a3470ada77c7c360ad75" category="list-text"><block ref="31190025c7f2a3470ada77c7c360ad75" category="inline-link-macro-rx"></block></block>
  <block id="15155104ed4dffb0c6f48a716c490eb6" category="list-text"><block ref="15155104ed4dffb0c6f48a716c490eb6" category="inline-link-macro-rx"></block></block>
  <block id="8bd43c9f55116966ac61fd08aa3cd4bf" category="list-text">与公有 云无缝集成、用于分层和保护数据。ONTAP 还提供强大的数据保护功能，使其在任何环境中脱颖而出：</block>
  <block id="d06c8b79097ede1a26446d68bec0ca39" category="paragraph">有关 ONTAP 的详细信息，请参见<block ref="b961dc88c1ac3ab8c78f9fff5ef05edb" category="inline-link-rx"></block>。</block>
  <block id="a95908309fdc4765216365a8dc7d2561" category="paragraph">这两个系统均由NetApp ONTAP 数据管理软件提供支持、NetApp数据管理软件是业内最先进的数据管理软件、可用于简化、高度可用的云集成存储管理、可为您的Data Fabric需求提供企业级的速度、效率和安全性。</block>
  <block id="158de41b0c768154e1c26d384097971b" category="paragraph">ONTAP Select 是 NetApp ONTAP 的软件定义部署，可以部署到您环境中的虚拟机管理程序上。它可以安装在VMware vSphere或KVM上、并提供基于硬件的ONTAP 系统的完整功能和体验。</block>
  <block id="87517df6852cb879fffc1e5811e773eb" category="paragraph">NetApp提供了许多产品、可帮助您编排、管理、保护和迁移有状态容器化应用程序及其数据。</block>
  <block id="a4d4eca64bc27dfd5dc959bc05745797" category="paragraph"><block ref="a4d4eca64bc27dfd5dc959bc05745797" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c60042e38b748289146bd910731af5f0" category="paragraph">NetApp Astra Control可为采用NetApp数据保护技术的有状态Kubernetes工作负载提供丰富的存储和应用程序感知型数据管理服务。Astra 控制服务可用于在云原生 Kubernetes 部署中支持有状态工作负载。Astra控制中心可在｛K8s_distribution_name｝等企业Kubernetes平台的内部部署中支持有状态工作负载。有关详细信息，请访问 NetApp Astra Control 网站<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>。</block>
  <block id="40de36ed0c5ebc385749ac6095c24949" category="paragraph">NetApp Astra Trident是一款开源且完全受支持的存储编排程序、适用于｛K8s_distribution_name｝等容器和Kubernetes分发版。有关详细信息，请访问 Astra Trident 网站<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>。</block>
  <block id="ccbb3765ebd50818c2e13a7aba362360" category="paragraph">以下页面介绍了有关已在｛Solution _name｝解决方案 中验证用于应用程序和永久性存储管理的NetApp产品的追加信息 ：</block>
  <block id="9dc16d6a3e39a8a9654ccfa622d163cf" category="list-text"><block ref="9dc16d6a3e39a8a9654ccfa622d163cf" category="inline-link-macro-rx"></block></block>
  <block id="65b4726a91c7e38728e01572140c82b3" category="list-text"><block ref="65b4726a91c7e38728e01572140c82b3" category="inline-link-macro-rx"></block></block>
  <block id="61e8a38bc32bac1a07ee434aa2849ff7" category="paragraph">NetApp Astra控制中心可以安装在｛K8s_distribution_name｝集群上、该集群已部署Astra Trident存储编排程序并为其配置存储类和NetApp ONTAP 存储系统的后端。</block>
  <block id="ca272f711326de89f484505d0ad670ab" category="paragraph">有关Astra Trident的详细信息、请参见 <block ref="fdebacf9b174a956e59f11468f6dd03c" category="inline-link-macro-rx"></block>。</block>
  <block id="c46717c86eab6ada72e202311e47bf46" category="paragraph">在云互联环境中， Astra 控制中心使用 Cloud Insights 提供高级监控和遥测功能。在没有Cloud Insights 连接的情况下、可以使用有限的监控和遥测功能(相当于7天的指标)、并通过开放式指标端点导出到Kubernetes原生 监控工具(Prometheus和Grafana)。</block>
  <block id="b5348ca8ff6fec2e5b760e7176813e60" category="paragraph">除了已付费版本的 Astra 控制中心之外，还提供 90 天评估许可证。评估版可通过电子邮件和社区Slack渠道获得支持。客户可以访问这些资源、其他知识库文章以及产品支持信息板上提供的文档。</block>
  <block id="8b05a70d35504af755eb73a78fd137f0" category="paragraph">要了解有关Astra产品组合的更多信息、请访问 <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>。</block>
  <block id="82c67e38528d52fd46de6b6ba7370337" category="paragraph">Astra Trident具有快速的开发周期、与Kubernetes一样、每年发布四次。</block>
  <block id="ed42e52f359216f47260ed1d21ef331c" category="paragraph">从 20.04 版开始， Trident 设置由 Trident 操作员执行。操作员可以简化大规模部署、并提供额外的支持、包括为在Trident安装过程中部署的Pod提供自我修复。</block>
  <block id="ef55276f0238c6b1a3f893bc026b5644" category="summary">NetApp容器解决方案是许多基于Kubernetes的常用容器编排程序的经过验证的部署、它们与NetApp存储管理系统和软件集成在一起。</block>
  <block id="d56bc5e4affc2f557b7bb79afe47b1be" category="doc">NetApp容器解决方案</block>
  <block id="6fd40b989d7667b2025880aec23fdf21" category="paragraph">本参考文档对NetApp验证的Google Cloud Anthos在多个不同数据中心环境中的部署进行了验证。同时，还详细介绍了如何利用 Astra Trident 存储编排程序管理永久性存储，以及利用 NetApp Astra 控制中心管理和保护有状态应用程序，从而实现与 NetApp 存储系统的存储集成。最后，我们还探讨并记录了许多解决方案验证和实际使用情形。</block>
  <block id="7768400c23564e6141f156e229944614" category="summary">Anthos将开发和IT运营统一到一个平台上、以便跨内部和混合云基础架构一致地构建、部署和管理应用程序。Anthos以虚拟或裸机格式将GKEKubernetes集群直接引入数据中心环境。</block>
  <block id="346f4310b75e0cc51fdf8a1db6149978" category="doc">Anthos概述</block>
  <block id="89ef90a5be38c2b656627392eee1a2a9" category="paragraph">采用NetApp的Anthos是一款经验证的最佳混合云架构、用于以可靠的方式部署内部Google Kubernetes Engine (GKEE)环境。本《经验证的NetApp架构参考文档》既可作为设计指南、也可作为部署在裸机和虚拟环境中的采用NetApp解决方案 的Anthos的部署验证。本文档所述的架构已通过NetApp和Google Cloud的主题专家的验证、可提供在企业数据中心环境中运行Anthos的优势。</block>
  <block id="72efb373513d77a08aa5dd7e375a418f" category="section-title">Anthos</block>
  <block id="5b1a0b45a2d6518143a0c9b299e736b4" category="paragraph">Anthos是一款混合云Kubernetes数据中心解决方案 、支持企业构建和管理现代混合云基础架构、同时采用专注于应用程序开发的敏捷工作流。基于 VMware 的 Anthos 是一种基于开源技术的解决方案，在基于 VMware vSphere 的基础架构中在内部运行，该基础架构可以与 Google Cloud 中的 Anthos GKEE 进行连接和互操作。通过采用容器，服务网状和其他转型技术，企业可以在本地和基于云的环境中体验一致的应用程序开发周期和可随时投入生产的工作负载。下图展示了 Anthos 解决方案以及内部数据中心中的部署如何与云中的基础架构互连。</block>
  <block id="ed4b514e0a9558c7acbec81ecc5fe0e1" category="list-text">* 适用于 Kubernetes 应用程序的 Google Cloud Marketplace 。 * 一个精心设计的容器应用程序目录，可用于轻松部署。</block>
  <block id="b2f70465e1ea6dcdc0843dc8ed3b7f55" category="list-text">* 迁移 for Anthos.* 将物理服务和 VM 从内部环境自动迁移到云。</block>
  <block id="52bc26b321a0b4cd1f91f7961a0783c8" category="list-text">* Stackdriver.* Google 提供的管理服务，用于记录和监控云实例。</block>
  <block id="9d1fde4a5ff757f9279ca3b948ce8cb2" category="paragraph"><block ref="9d1fde4a5ff757f9279ca3b948ce8cb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4777b2291cea091fd5877d9051ff1a3" category="section-title">Anthos的部署方法</block>
  <block id="0b7914a951055f790f36ed2e8e90bf01" category="section-title">VMware上的Anthos集群</block>
  <block id="1702288bedca391f972e58fc0561e9ed" category="paragraph">部署到VMware vSphere环境中的Anthos集群可以轻松地部署、维护和快速扩展大多数最终用户Kubernetes工作负载。</block>
  <block id="6f2ed4f8e4ebad80d7a306a0dc285156" category="paragraph">有关在NetApp中部署的VMware上的Anthos集群的详细信息、请访问页面 <block ref="2f8f1280f6424b00276dc85d82fdb14f" category="inline-link-macro-rx"></block>。</block>
  <block id="45a6d5427a773bd692ba6faf09ae9200" category="paragraph">部署在裸机服务器上的Anthos集群不受硬件限制、您可以选择针对您的个性化使用情形进行优化的计算平台。</block>
  <block id="00d32067724b7191cb5b0ffaf99cc3fe" category="list-text">运行 `kubectl` 命令以创建存储类。</block>
  <block id="36a95a56c85c06906ce9ed37f6c88bbe" category="list-text">发出 `kubectl` 命令创建 PVC 。根据所创建的后备卷的大小，创建可能需要一些时间，因此您可以在该过程完成后进行观察。</block>
  <block id="f9d11737e933d637293dde1af50cc17c" category="inline-link-macro">本文档</block>
  <block id="8e6bdc78726b4f56217f2db215176c4c" category="paragraph">有关安装和配置 Astra Trident 以支持 Astra 控制中心的信息，请参见 <block ref="a26f48e8d5c30c46f5b177e7942c3e6b" category="inline-link-macro-rx"></block>。</block>
  <block id="5a45cefd7ffdd292bbc23212059fae63" category="paragraph">在云互联环境中， Astra 控制中心使用 Cloud Insights 提供高级监控和遥测功能。在没有Cloud Insights 连接的情况下、可以使用有限的监控和遥测(7天的指标)、并通过开放式指标端点导出到Kubernetes原生 监控工具(Prometheus和Grafana)。</block>
  <block id="f7606168abf643ab18d0fa39eaf87445" category="admonition">最佳做法是、每个OpenShift安装在一个站点上都要有一个专用的SVM用于永久性存储。多站点部署需要额外的存储系统。</block>
  <block id="cdcf8f111b01a0c0037e638c481f80b0" category="admonition">Docker安装的Docker版本必须大于20.10、而Podman安装的Podman版本必须大于3.0。</block>
  <block id="bcd2576f09ac9988bca57ac067028342" category="section-title">安装后步骤</block>
  <block id="f1712afd3ab64493ad6802bfa9e5be87" category="list-text">检查`Acc-operator-controller-manager`日志以验证安装是否已完成。</block>
  <block id="da44b5941c7cfd27a6f5686a3168f332" category="list-text">首次使用CRD中提供的管理员电子邮件地址登录到Astra控制中心图形用户界面时、应更改密码。</block>
  <block id="d46a5e1e10f8a4a33306d0696cef14f5" category="summary">本参考文档对部署在多数据中心环境中且经过NetApp和我们的工程合作伙伴验证的NetApp解决方案 中的Anthos进行了部署验证。</block>
  <block id="9d171bf7d3d65afb2e7e56d43b4b9ed5" category="doc">NVA-1165：采用NetApp的Anthos</block>
  <block id="9b3053daf2ec8e22b4a577982f08f107" category="paragraph">采用NetApp解决方案 的Anthos旨在为客户提供卓越的价值、其使用情形如下：</block>
  <block id="cbc828fed325d3834b2bf3b1f2b5e639" category="inline-link">kubevirt</block>
  <block id="341508ebeee3f32bbf4f6fee6cb456a0" category="list-text">将企业级容器和虚拟化工作负载的强大功能与几乎部署在vSphere上或裸机上的Anthos相结合<block ref="3149dc0a8051bd1d167afbb1fe9775d9" category="inline-link-rx"></block>。</block>
  <block id="de800fedc3b1bf6c4cf497db01ca193d" category="list-text">与NetApp存储和适用于Kubernetes的开源存储编排程序Astra Trident结合使用时、真实的配置和用例重点介绍了Anthos功能。</block>
  <block id="22acab0d08b6253aa6c7d6be2fd3f4d3" category="paragraph">采用NetApp解决方案 的Anthos包含以下主要组件：</block>
  <block id="c6e52ea38355d1c4527e874a4c673b5b" category="section-title">Prem上的Anthos</block>
  <block id="385c65f480dfcbc7cb530a2c6c807ae9" category="paragraph">Prem上的Anthos是一款完全受支持的企业级Kubernetes平台、可以部署在VMware vSphere虚拟机管理程序中或您选择的裸机基础架构上。</block>
  <block id="b73ed4ba665437210c3da7d43d6618bf" category="paragraph">Astra Trident是一款开源且完全受支持的存储编排程序、适用于容器和Kubernetes分发软件(包括Anthos)。</block>
  <block id="87f76f310cf20e85a098d49fa77367e5" category="cell">VMware上的Anthos集群</block>
  <block id="bdca6efb043178ef172612dd1e173dde" category="cell">1.10</block>
  <block id="5b9abd64aa4865a31820ebec932e54f2" category="section-title">Anthos Ready存储合作伙伴计划。</block>
  <block id="02046ad0e82ff27f6e1774aa588fd853" category="cell">部署类型</block>
  <block id="1552eec8291d257c4b855dcfa425d802" category="cell">存储系统</block>
  <block id="6a5025e8000765df098a91023b66544a" category="cell">Astra Trident版本</block>
  <block id="888a77f5ac0748b6c8001822417df8b6" category="cell">协议</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="cell">VMware</block>
  <block id="955ddf0f7e289ee80cdea4b5324b620d" category="cell">22.01</block>
  <block id="c07ee5debf5f3a3fef16c1ee5e8e4942" category="cell">NAS</block>
  <block id="e5db66c80967b6fa50a1eede0ce50e2f" category="cell">Multiwriter、卷扩展、快照</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="cell">SAN</block>
  <block id="4c606f506efd3b3bef3499e3342b5933" category="cell">原始块、卷扩展、快照</block>
  <block id="a2da3c930443e5d1421caec9ee18a376" category="cell">裸机</block>
  <block id="ddffa1813009160db4406c9ef143dd1e" category="section-title">NetApp 存储集成</block>
  <block id="de3b8bd79707b5ac064727a07d81d808" category="paragraph">在裸机上使用Anthos与硬件无关的功能、让您可以选择一个针对您的个性化使用情形进行优化的计算平台、同时还可以获得许多其他优势。</block>
  <block id="b872ec62b57abae84b75461c58e0a0a7" category="list-text">*自带服务器。*您可以使用与现有基础架构匹配的服务器来降低资本支出和管理成本。</block>
  <block id="2c912ca37607e38556f15eebae425241" category="paragraph">Google Cloud会定期通过其Anthos Ready平台合作伙伴计划请求更新对包含新版本Anthos的合作伙伴服务器平台的验证。您可以找到当前已验证的服务器平台以及支持的Anthos版本的列表<block ref="3b2369e07f297fb9367d6c18ca70e2ac" category="inline-link-rx"></block>。</block>
  <block id="6a655d9810c4c5ea4ab7a5520d43ca6f" category="paragraph">下表列出了已由NetApp和NetApp合作伙伴工程师针对裸机部署中的Anthos验证进行测试的服务器平台。</block>
  <block id="c0bd7654d5b278e65f21cf4e9153fdb4" category="cell">制造商</block>
  <block id="529a05ca6c1263aab080ec4f20754411" category="cell">创建</block>
  <block id="7b1d1185b835814de783483f686e9825" category="cell">Cisco</block>
  <block id="21f20abdc637c3f2ef02355079dac15d" category="cell">UCS</block>
  <block id="8746d13b8a20e92a40041de84ef0df6f" category="cell">B200 M5</block>
  <block id="3cd9b23ed31110b2ebcbcc8c9a1dc8c0" category="cell">HPE</block>
  <block id="dcaa84314614529edc3d258cff7f565a" category="cell">使用</block>
  <block id="76cca00a6b1e58467cea8165c904fe4f" category="cell">DL360</block>
  <block id="c5c8661ff74179fd251af29468f2ee7d" category="paragraph">下表列出了NetApp和我们的合作伙伴用来验证解决方案 的Linux操作系统。</block>
  <block id="b8e7b465df7c5979dc731d06e84ce2cf" category="cell">版本。</block>
  <block id="97f1ca2cfbf4529686b9719bf26e07c0" category="cell">Anthos版本</block>
  <block id="6762f053abca7510f6648c71492724a7" category="cell">8/4.</block>
  <block id="26181b11798a17989dc697461dc3e9d0" category="section-title">其他硬件</block>
  <block id="629f0a0ce45378aa8d3f93d405eb19cc" category="paragraph">为了在裸机上完成Anthos作为经过全面验证的解决方案 的部署、NetApp和我们的合作伙伴工程师已经对用于网络连接和存储的其他数据中心组件进行了测试。</block>
  <block id="9e5fa7e53550abb6c768c926e7888df7" category="paragraph">下表提供了有关这些附加基础架构组件的信息。</block>
  <block id="b763f3ad097c7d9beb9849be170a627a" category="cell">硬件名称</block>
  <block id="8c692721fdfc559bf4689567aa48fb47" category="cell">Nexus</block>
  <block id="5cb4ead83aaa15a241ef0e8c36f0678c" category="cell">C9336C-x2</block>
  <block id="8bb152d8bbc90b878b63c05b6b953334" category="section-title">其他软件</block>
  <block id="effae9170216f08fb6cb3265a4cae9cc" category="paragraph">下表列出了在验证环境中部署的其他软件版本。</block>
  <block id="91c8cbe28b4928f6ea19ea8d1894623a" category="cell">软件名称</block>
  <block id="604081aa29d106416ce93ba7c42a41e3" category="cell">NXOS</block>
  <block id="55e62f54b487de5f2a89d645f80d77b4" category="cell">9.3 （ 5 ）</block>
  <block id="e0f2ed66fa5adfb40b7738ba72a899c9" category="paragraph">在NetApp和我们在全球技术(World Wide Technology、WWT)的合作伙伴团队执行Anthos Ready平台验证期间、我们根据下图构建了实验室环境、该环境允许我们测试每种服务器类型、操作系统、网络设备、 和部署在解决方案 中的存储系统。</block>
  <block id="c7a2b443f8714e7071c1d55a3bd2715f" category="section-title">基础架构支持资源</block>
  <block id="f8f0e385abfb7fc517b1b9b4e9e8d19e" category="paragraph">在裸机上部署Anthos之前、应具备以下基础架构：</block>
  <block id="957478b81604fc0a340d863f3b89a2da" category="summary">NetApp拥有多个存储平台、这些平台已通过Trident Storage Orchestrator的认证、可为部署在Anthos上的应用程序配置存储。</block>
  <block id="0c5e049b7be7649501696f84472d6820" category="paragraph"><block ref="0c5e049b7be7649501696f84472d6820" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e2719bf8f96a980f38256b7a4060368" category="list-text">要使用Ansible攻略手册部署Astra控制中心、您必须安装装有Ansible的Ubuntu或RHEL计算机。按照所述按照操作步骤 进行操作<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> 适用于Ubuntu和<block ref="94346839427703f278bfb2bc5962a814" category="inline-link-rx"></block> 对于 RHEL 。</block>
  <block id="bf98d9390f43e942cd74d874e3bf6d68" category="list-text">将目录更改为`na_astera_control_suite`。</block>
  <block id="cfcf9f0f05f9790927b65e14214edc6e" category="list-text">运行攻略手册以部署 Astra 控制中心。对于某些配置、此攻略手册需要root特权。</block>
  <block id="3c0e37ba6fc2025cda3b9ec88b955aab" category="paragraph">如果运行该攻略手册的用户为root或配置了无密码sudo、请运行以下命令运行该攻略手册。</block>
  <block id="6b682acdf6e246de63c54d6f90044faa" category="paragraph">如果用户配置了基于密码的sudo访问权限、请运行以下命令以运行攻略手册、然后输入sudo密码。</block>
  <block id="bbdfa4f0841eb6d317a11ae76992b8b8" category="summary">本节专门介绍要使用NetApp部署自定义Anthos的用户的负载平衡器选项。</block>
  <block id="b935e49429349d1edf159cd09a0b8ff5" category="paragraph">以下页面提供了有关负载平衡器选项的追加信息 、这些选项已在采用NetApp解决方案 的Anthos中进行验证：</block>
  <block id="f1bcd982a417f561201a3262b52a84d7" category="list-text">* NetApp SnapLock。*将不可重写数据写入指定时间段内无法覆盖或擦除的特殊卷、从而高效管理这些数据。</block>
  <block id="678cbe37bb872d145128736b4650ef68" category="paragraph">NetApp提供强大的全闪存(AFF)和横向扩展混合(FAS)存储平台、这些平台专为低延迟性能、集成数据保护和多协议支持量身定制。</block>
  <block id="a150469d40f75f1df1e87a9558f50769" category="paragraph">这两个系统均由NetApp ONTAP 数据管理软件提供支持。NetApp数据管理软件是业内最先进的数据管理软件、可提供高度可用的云集成简化存储管理、可提供您的Data Fabric所需的企业级速度、效率和安全性。</block>
  <block id="a9b90f3200d3b94ea47e85db3a435816" category="paragraph">有关NetApp AFF 和FAS 平台的详细信息、请单击<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>。</block>
  <block id="7bfa2a7b059f09c3a772620888e93ef4" category="list-text">输入备份详细信息、选择用于保存备份文件的对象存储分段、然后单击下一步。查看详细信息后、单击备份。根据应用程序和数据的大小、备份可能需要几分钟的时间。备份成功完成后、备份状态将变为可用。</block>
  <block id="bf6a757407fc5616f49930e56f86f233" category="list-text">要克隆应用程序、请导航到应用程序&gt;受管选项卡、然后单击相关应用程序。单击应用程序名称旁边的下拉菜单，然后单击克隆。</block>
  <block id="9b6757a6af2937cac7096646ee8dedb8" category="paragraph">F5 BIG-IP是一款应用程序交付控制器(Application Delivery Controller、AD)、可提供一系列高级的生产级流量管理和安全服务、例如L4-L7负载平衡、SSL/TLS卸载、DNS、防火墙等。这些服务可显著提高应用程序的可用性、安全性和性能。</block>
  <block id="402c558f65f9d58557e4d79511d71f01" category="paragraph">F5 BIG-IP是第一款随Anthos On-Prem提供的捆绑式负载平衡器解决方案、并在许多采用NetApp解决方案 的Anthos Ready合作伙伴早期验证中使用。</block>
  <block id="b662a8c121a377d9111fe64265c8d819" category="paragraph">此解决方案 可利用VMware vSphere中部署的虚拟设备。F5 BIG-IP 虚拟设备的网络连接可以根据您的网络环境配置为双武装或三武装配置。本文档中的部署基于双武装配置。有关配置用于Anthos的虚拟设备的更多详细信息、请参见<block ref="f18a28d0c935319437c4d1b1e33e5728" category="inline-link-rx"></block>。</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">Type</block>
  <block id="37f438df6a6d5ba4c17ef8ca58562f00" category="cell">F5</block>
  <block id="90524e294c6b7accf9b320977f3f5baa" category="cell">BIG-IP VE</block>
  <block id="bc75f10c94df92e80198364d879456ab" category="cell">15.0.1-0.0.11</block>
  <block id="c2c889e06ea18c0e72996bc4b43c8115" category="cell">16.1.0-0.0.19</block>
  <block id="674751c31a2db2596bf7788e2953b80f" category="paragraph">要安装F5 BIG-IP、请完成以下步骤：</block>
  <block id="ee5cd6f83412e93266bf30ff048db6ff" category="list-text">从 F5 下载虚拟应用程序 Open Virtual Appliance （ OVA ）文件<block ref="cafae381bde5e2381c6df42a3aa937c6" category="inline-link-rx"></block>。</block>
  <block id="fff9995f30a825c5d3e5709e7b78117a" category="admonition">要下载此设备，用户必须向 F5 注册。他们为 Big IP Virtual Edition 负载平衡器提供 30 天的演示许可证。NetApp 建议为设备的生产部署提供永久 10 Gbps 许可证。</block>
  <block id="1a104d04970b6b80d8cf31f554404f4d" category="list-text">右键单击基础架构资源池、然后选择Deploy OVF Template。此时将启动一个向导，用于选择您刚刚在步骤 1 中下载的 OVA 文件。单击下一步。</block>
  <block id="fdf7304b13d736c791bc745a330e7309" category="image-alt">部署大 IP 设备</block>
  <block id="fbd07b7802c1a124a9359b27b9f46968" category="list-text">通过向导显示的下一个屏幕，您可以自定义要在环境中使用的虚拟网络。选择 VM_Network 作为外部字段，然后选择 Management_Network 作为管理字段。内部和 HA 用于 F5 BIG-IP 设备的高级配置，但未进行配置。这些参数可以单独使用，也可以配置为连接到非基础架构的分布式端口组。单击下一步。</block>
  <block id="93353313944577e80d34c3d9491db6ce" category="list-text">查看设备的摘要屏幕，如果所有信息都正确，请单击完成开始部署。</block>
  <block id="68b984a73f20c874fb80feeaa4621109" category="list-text">部署虚拟设备后，右键单击该设备并将其启动。它应在管理网络上收到 DHCP 地址。此设备基于Linux、并且已部署VMware Tools、因此您可以在vSphere客户端中查看它接收的DHCP地址。</block>
  <block id="d92e443c00989a23096c72b760af7de8" category="list-text">打开 Web 浏览器，然后使用上一步中的 IP 地址连接到设备。默认登录名称为 admin/admin ，首次登录后，设备会立即提示您更改管理员密码。然后，它将返回一个屏幕，您必须使用新凭据登录到该屏幕。</block>
  <block id="dbe135d0d5ae1eb2c137c81f0ce0bdfb" category="image-alt">Big-IP 配置</block>
  <block id="bdb0e3e1ff63b6d5f08545e207448035" category="list-text">第一个屏幕将提示用户完成设置实用程序。单击下一步启动实用程序。</block>
  <block id="8523c09995ae3cfb4593cd6c4e09029f" category="list-text">下一屏幕将提示您激活设备的许可证。单击激活开始。在下一页出现提示时，粘贴注册下载时收到的 30 天评估许可证密钥或购买设备时获得的永久许可证。单击下一步。</block>
  <block id="38d2bfb14ed98f122ce9d9b9cdb2a127" category="admonition">要使设备执行激活，在管理界面上定义的网络必须能够访问 Internet 。</block>
  <block id="6ba845d7cd0e966d0a2a21209623a5b4" category="list-text">在下一屏幕中，将显示最终用户许可协议（ EULA ）。如果许可证中的条款可接受，请单击 Accept 。</block>
  <block id="c14be37e927625fe613c8c559de70df1" category="list-text">下一个屏幕将计算经过的时间，以验证迄今为止所做的配置更改。单击 Continue 以恢复初始配置。</block>
  <block id="3c3d807fce3ffcb905b00324d2f7e2b9" category="list-text">此时将关闭配置更改窗口，设置实用程序将显示资源配置菜单。此窗口列出了当前已获得许可的功能以及虚拟设备和每个正在运行的服务的当前资源分配。</block>
  <block id="117c183bcbd703e6b0520f843e971c9b" category="list-text">单击左侧的平台菜单选项可对平台进行其他修改。修改包括设置使用 DHCP 配置的管理 IP 地址，设置主机名和设备安装所在的时区以及保护设备免受 SSH 访问。</block>
  <block id="fad130ca7ff2a3734a8b7547b3ebc404" category="list-text">接下来，单击网络菜单，在此可以配置标准网络功能。单击下一步开始标准网络配置向导。</block>
  <block id="37f1b31abf7679b5f5e495d8796a48a7" category="admonition">此页面中的"Self IP Address"、"Networkmask"和"浮动IP地址"空格可以使用不可路由的IP作为占位符。如果要部署三种配置，也可以为其填充一个内部网络，该网络已配置为虚拟子系统的分布式端口组。要继续使用向导，必须完成这些操作。</block>
  <block id="c3966f18c8da763e8d9f315b3e44811e" category="list-text">在下一页中，如果要在环境中部署多个虚拟设备，则可以配置内部 HA 网络。要继续操作，您必须填写 Self-IP Address 和 Netmask 字段，并且必须选择 interface 1.3 作为 VLAN 接口，此接口将映射到 OVF 模板向导定义的 HA 网络。</block>
  <block id="0d469ac29aab926968093104ad6265df" category="list-text">下一页用于配置 NTP 服务器。然后单击下一步继续进行 DNS 设置。DHCP 服务器应已填充 DNS 服务器和域搜索列表。单击下一步接受默认值并继续。</block>
  <block id="97a60c27b370d45c17075cff06f473a3" category="list-text">在向导的其余部分中，单击 " 下一步 " 继续进行高级对等设置，本文档不会介绍此设置的配置。然后单击完成退出向导。</block>
  <block id="0953ce81fac634b21f33efe8dee24c28" category="list-text">为环境中部署的 Anthos 管理集群和每个用户集群创建单独的分区。单击左侧菜单中的 System ，导航到 Users ，然后单击分区列表。</block>
  <block id="616e4c989df3c842830310568b54cee6" category="section-title">与Anthos集成</block>
  <block id="c0018d5f0e0d9decd39a8059cc2bc473" category="paragraph">本页提供的示例包括解决方案 对NetApp的Anthos进行的验证和使用情形。</block>
  <block id="fdd1d4ba64f526087e6e49e35a884fbd" category="summary">本节专门介绍实际用户在将此解决方案 部署到生产环境中时可能需要执行的自定义设置、例如部署自定义负载平衡器实例。</block>
  <block id="90f687894749dad073416489141eb43f" category="list-text">NetApp Astra Trident文档</block>
  <block id="7cfc9495aac39bbaa5defc76b7f4e8db" category="list-text">VMware上的Anthos集群文档</block>
  <block id="9ee8ef3c59727b8b17070caf87743214" category="list-text">Anthos on裸机文档</block>
  <block id="bc10096da41c680de98ecf3f1def7d17" category="inline-link"><block ref="bc10096da41c680de98ecf3f1def7d17" category="inline-link-rx"></block></block>
  <block id="d642746f7d7a37b7cb340d9a62d751a5" category="paragraph"><block ref="d642746f7d7a37b7cb340d9a62d751a5" category="inline-link-rx"></block></block>
  <block id="10a641cf7647f6970bad748b52bb253b" category="paragraph"><block ref="10a641cf7647f6970bad748b52bb253b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f640668ae5a8fc28f807fe0d6b9128b" category="paragraph">这样，如果节点发生故障后又发生卷重新分布，则除了注销和登录并重定向到新位置之外，对主机连接不会产生任何影响。通过 iSCSI 登录重定向， NetApp Element 软件集群是一种自我修复型横向扩展架构，能够实现无中断升级和操作。</block>
  <block id="206188ac4e8ec83453b82a36311f1a25" category="paragraph">VMware上的Anthos集群是Google Kubernetes Engine的扩展、部署在最终用户的私有数据中心中。企业可以部署设计用于在内部Kubernetes集群中Google Cloud容器中运行的相同应用程序。VMware上的Anthos集群可以部署到数据中心的现有VMware vSphere环境中、这样可以节省资本支出、并加快部署和扩展操作的速度。</block>
  <block id="b107e7085d2931bbe4118d8c5eed9643" category="paragraph">在VMware上部署Anthos集群包括以下组件：</block>
  <block id="348ed6380fe1c4753877d1f13d95d39a" category="paragraph">VMware上的Anthos集群具有以下优势：</block>
  <block id="cf97925041bebbd35543bc4fc24fa499" category="list-text">*高级多租户。*可以为每个最终用户分配自己的用户集群、并使用其自身开发环境所需的虚拟资源进行部署。</block>
  <block id="a6c34625dcf8367e84732b5219f81cb7" category="list-text">*先开发再发布。*可以在开发应用程序时使用内部部署、这样可以在本地数据中心的隐私环境下测试应用程序、然后再在云中公开发布。</block>
  <block id="4418ae814387892bd88d45091a182234" category="list-text">* vSphere高可用性。*为避免主机发生故障时发生中断、VMware vSphere允许将主机集群化并配置为高可用性。由于主机故障而中断的 VM 不久将在集群中的其他主机上重新启动，从而还原服务。</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="section-title">操作系统</block>
  <block id="23d300c91b3d48f94c1e7f5953ad3e5e" category="cell">7.0U3.</block>
  <block id="89f7e5d7117ac9eb1ece116273f5f012" category="paragraph">为了完成将Anthos作为经过全面验证的解决方案 与NetApp结合使用的部署、NetApp和我们的合作伙伴工程师已经对用于网络连接和存储的其他数据中心组件进行了测试。</block>
  <block id="fe02a8fc8838381700e175498b8e1db0" category="cell">Mellanox</block>
  <block id="dd4a9a41d8672c9659041812469e1df2" category="paragraph">下表列出了在验证环境中部署的软件版本。</block>
  <block id="da0d53141f6343167596fe8598964773" category="cell">软件名称</block>
  <block id="13d18f8604b3585f7ab88b87766a8d38" category="paragraph">在部署Anthos之前、应具备以下基础架构：</block>
  <block id="92b7a761f185f74bf3bf9d2229c67a28" category="list-text">如果集群需要动态扩展、则可以使用DHCP服务器按需提供网络地址租约。</block>
  <block id="8256d4d5c73a64213343972bedd38f45" category="section-title">将Anthos部署到至少包含三个节点的ESXi集群</block>
  <block id="150754dbd257c09eef8557a399e5ebc2" category="paragraph">通过启用VM和主机关联性、可以在多个虚拟机管理程序节点之间分布Anthos集群节点。</block>
  <block id="659aed3f7f249a658860ff0d51cdef11" category="paragraph">要配置关联组、请参见以下适用于您的VMware vSphere版本的链接。</block>
  <block id="bfe724d354657c9ac5cef22bd231f66f" category="inline-link">vSphere 7.0文档：使用DRS关联性规则</block>
  <block id="10c2b11d36730909ac14bcf903f9c456" category="paragraph"><block ref="0817a5be4b4f4733045646ef5cffc66c" category="inline-link-rx"></block>。<block ref="211975e132e07e8f3a0d0d18ff3759e5" category="inline-link-rx"></block>。</block>
  <block id="306235ad6a87783a223e0ba03145dc12" category="doc">创建私有映像注册表</block>
  <block id="56a0195518edf56f84e2b789302cf485" category="paragraph">本操作步骤 介绍了如何创建私有映像注册表、该注册表由Astra Trident和NetApp ONTAP 提供的永久性卷提供支持。</block>
  <block id="13bb7c6596c212587d7a35708de351f2" category="admonition">Astra 控制中心需要注册表来托管 Astra 容器所需的映像。以下部分介绍了在Red Hat OpenShift集群上设置专用注册表以及推送支持安装Astra控制中心所需的映像的步骤。</block>
  <block id="83806e2d09a78bbe33b3e817a88df12b" category="list-text">如果您对传入操作员OpenShift注册表路由使用默认TLS证书、则可以使用以下命令提取TLS证书：</block>
  <block id="6714b6fa43a8d03bcbfeb657bd27788d" category="list-text">OpenShift 内部注册表由身份验证控制。所有OpenShift用户都可以访问OpenShift注册表、但登录用户可以执行的操作取决于用户权限。</block>
  <block id="489c81c1a0ec76cf6ab9a12890120550" category="list-text">要将其修补到服务帐户、请运行以下命令：</block>
  <block id="ec0c98e5e0be835a1df04b40b6c8e96c" category="list-text">要从OpenShift节点以外的工作站推送或拉取映像、请完成以下步骤：</block>
  <block id="872c01365a01300e2a8a772cd65e51b1" category="summary">此页面详细介绍了seesaw负载平衡器的安装和配置说明。</block>
  <block id="1ffbf83c6ff924ed568f0f88c922ac88" category="paragraph">此页面列出了seesaw受管负载平衡器的安装和配置说明。</block>
  <block id="aa2bdb165616b7814c712fd55ecd1ce8" category="paragraph">以下文本是GKE-Admin集群分区配置的示例。需要取消注释和修改的值以粗体文本显示在下方：</block>
  <block id="b7e1a8e2925f8cb0b4f88b8532edd6d7" category="admonition">此文件提供负载平衡器为底层集群提供的网络的网关和网络掩码、以及为运行负载平衡器而部署的虚拟机的管理IP和主机名。</block>
  <block id="5137c3284aa2dc8893ef670919f28a5f" category="list-text">开始安装之前，请将 Astra Control Center 映像推送到映像注册表。您可以选择使用 Docker 或 Podman 执行此操作，此步骤将提供这两者的说明。</block>
  <block id="123a55fe7e6f2398763a03f409e2c1de" category="admonition">或者、您也可以创建服务帐户、分配注册表编辑器和/或注册表查看器角色(取决于您是否需要推/拉访问)、并使用服务帐户的令牌登录到注册表。</block>
  <block id="a917b1e998a1fed8ddebd661c3ff12b3" category="list-text">创建Shell脚本文件并将以下内容粘贴到其中。</block>
  <block id="f2f27bc59d06be1e1f58b94160cf9949" category="admonition">如果您使用`kubeadmin`用户登录到专用注册表、请使用令牌而非密码-`docker login -u Ocp-user -p token astra-registry.apps.ocp-vmw.cie.netapp.com`。</block>
  <block id="61dbdb9822ed0d400254915ff02a4ee9" category="admonition">或者、您也可以创建服务帐户、分配注册表编辑器和/或注册表查看器角色(取决于您是否需要推/拉访问)、并使用服务帐户的令牌登录到注册表。</block>
  <block id="37a5c97f291196f8c672c75798a29beb" category="admonition">如果您使用的是包含传入操作员的默认 TLS 证书的 OpenShift 内部注册表和路由，则仍需要按照上一步将这些证书修补到路由主机名。要从入口运算符提取证书、您可以使用命令`oc extract secret/router -ca -keys=tls.crt -n OpenShift-Inuse-operator`。</block>
  <block id="08e6bc541e2517b4105b8ac0ccbfe0f3" category="list-text">使用凭据创建一个密钥、以登录到`NetApp-Acc-operator`命名空间中的映像注册表。</block>
  <block id="e1e6f0b52690f367570b6c16ddf92d98" category="list-text">选择`NetApp-Acc-operator`区块、然后单击安装。</block>
  <block id="1c17ca035fc060e6a6c77e025e8f27a1" category="list-text">在Install Operator屏幕上、接受所有默认参数、然后单击Install。</block>
  <block id="5fa86531d41ab8ca8bee80ba657a599d" category="list-text">操作员安装成功后、导航到单击View Operator。</block>
  <block id="72c52a676e647d2aa400f12fe446f9f1" category="list-text">然后单击操作符中Astra Control Center图块中的Create Instance。</block>
  <block id="500c99ec2ed1582312d17f1ea94ab5d0" category="list-text">填写`Create AstraControlCenter` Form字段、然后单击Create。</block>
  <block id="097026a522eed2b2c71f07efd97bcf31" category="list-text">输入Astra控制中心的帐户名称和管理员详细信息、例如名字、姓氏和电子邮件地址。</block>
  <block id="ad2acc92f46f11a5d2a5ace0c933a44c" category="list-text">在映像注册表中、输入注册表的FQDN以及在将映像推送到注册表时提供的组织名称(在此示例中为`astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra`)。</block>
  <block id="3e99f691e1f9756e43f68a0aa28e61e0" category="list-text">如果您使用的注册表需要进行身份验证、请在映像注册表部分输入机密名称。</block>
  <block id="f009662483a899fd0d4b99ff5f1912f3" category="list-text">为Astra控制中心资源限制配置扩展选项。</block>
  <block id="3752e68cccc911651920465532b3d6b4" category="paragraph">在裸机上使用Anthos与硬件无关的功能、您可以选择针对您的用例优化的计算平台。因此，您可以匹配现有基础架构并减少资本支出。</block>
  <block id="fb5205026c598f136a15ad6c49fc1826" category="paragraph">下表列出了实施解决方案 所需的最低存储硬件组件数量、尽管所使用的硬件型号可能因客户要求而异。</block>
  <block id="0e98dfa85df93b279e4fd456b30409cf" category="admonition">此多操作系统环境显示了与裸机解决方案 上受支持的操作系统版本Anthos的互操作性。我们预计，客户将在部署时对一个或一小部分操作系统进行标准化。</block>
  <block id="97e84aad4ef505e4cda6422dc1c95990" category="doc">追加信息 ：借助NetApp Astra实现开发运营</block>
  <block id="0221d1074d249c254f0679e761454a05" category="inline-link"><block ref="0221d1074d249c254f0679e761454a05" category="inline-link-rx"></block></block>
  <block id="40454fb96e27a719bd7a751c4ec47d16" category="paragraph"><block ref="40454fb96e27a719bd7a751c4ec47d16" category="inline-link-rx"></block></block>
  <block id="5eae6f5974c9d4195ebe0cf8b607647e" category="list-text">Ansible文档</block>
  <block id="015674032a5c43c779a74ee9e3dbfc94" category="inline-link"><block ref="015674032a5c43c779a74ee9e3dbfc94" category="inline-link-rx"></block></block>
  <block id="f13ae695d1de0b91201bca0cd4e87c69" category="paragraph"><block ref="f13ae695d1de0b91201bca0cd4e87c69" category="inline-link-rx"></block></block>
  <block id="f89c93af274397315016bac75d215351" category="inline-link"><block ref="f89c93af274397315016bac75d215351" category="inline-link-rx"></block></block>
  <block id="9e4287aba38224954e73e528ce96bb47" category="paragraph"><block ref="9e4287aba38224954e73e528ce96bb47" category="inline-link-rx"></block></block>
  <block id="7a42c46751036b34f81738e60f1b7e97" category="list-text">Rancher文档</block>
  <block id="6483799d4ba7ad61fe06633600d8824a" category="inline-link"><block ref="6483799d4ba7ad61fe06633600d8824a" category="inline-link-rx"></block></block>
  <block id="b8e7a2183995014079b38a90770a02ea" category="paragraph"><block ref="b8e7a2183995014079b38a90770a02ea" category="inline-link-rx"></block></block>
  <block id="d7c98030ea1f0ace5cb1fc0a5954a87c" category="list-text">Kubernetes文档</block>
  <block id="943b2a1ab5485e1a2db3098051987614" category="summary">使用FlexClone技术快速部署</block>
  <block id="065cb44483a670695f374bc25a1f01b4" category="doc">使用案例验证：采用NetApp Astra的DevOps</block>
  <block id="438d983a4a02b97c1363407ba1bb3dbd" category="paragraph">以下用例已通过NetApp Astra DevOps验证：</block>
  <block id="47d55e9f9b259c93da777f74a5e832ee" category="inline-link-macro">利用NetApp Astra Control将保护功能集成到CI/CD管道中</block>
  <block id="86ebb4e5f51da406d6b6170528e02c8c" category="list-text"><block ref="86ebb4e5f51da406d6b6170528e02c8c" category="inline-link-macro-rx"></block></block>
  <block id="a9e51e0a4f30c204f900ee62c24b54e8" category="inline-link-macro">利用Astra Control促进对应用程序进行死后分析和还原</block>
  <block id="5ea6f0d962656bf6d901dedc10e9da49" category="list-text"><block ref="5ea6f0d962656bf6d901dedc10e9da49" category="inline-link-macro-rx"></block></block>
  <block id="6c9a3a62fc54ba1feccaee9df9c39f88" category="inline-link-macro">利用NetApp FlexClones加速软件开发</block>
  <block id="001bc4e878f5da889174d53f10bc3a58" category="list-text"><block ref="001bc4e878f5da889174d53f10bc3a58" category="inline-link-macro-rx"></block></block>
  <block id="d0f564d49f74b4698141e88cbce5ad41" category="summary">NetApp拥有多个存储平台、这些平台已通过Astra Trident和Astra Control认证、可用于为容器化应用程序配置、保护和管理数据、从而有助于定义和最大程度地提高DevOps吞吐量。</block>
  <block id="b43c4021858544ebd3a492d082a7f349" category="doc">NetApp存储系统概述</block>
  <block id="e3775ded02e90946eb22f7f559238e62" category="list-text"><block ref="e3775ded02e90946eb22f7f559238e62" category="inline-link-macro-rx"></block></block>
  <block id="70806b7246c09c2ec58c7947d781ebdf" category="doc">NetApp Astra Control概述</block>
  <block id="3d4bc8fb320a39f7369e26aa8dd43ff9" category="paragraph">有关Astra控制中心的详细安装和操作指南、请按照文档进行操作 <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>。</block>
  <block id="778aa9cc77239e29447d4ec0991d37ed" category="section-title">Astra控制中心自动化</block>
  <block id="1c3dabdc1df77100ef6e17757091285e" category="paragraph">Astra控制中心具有一个功能完备的REST API、可用于编程访问。用户可以使用任何编程语言或实用程序与Astra Control REST API端点进行交互。要了解有关此API的详细信息、请参见文档 <block ref="bb2ca4e10b1254bc49d4388c68f9edb7" category="inline-link-macro-rx"></block>。</block>
  <block id="5d9f4b40183d98a25c3ab751a2c22032" category="paragraph">如果您正在寻找可与Astra Control REST API交互的现成软件开发工具包、NetApp提供了一个包含Astra Control Python SDK的工具包、您可以下载该工具包 <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>。</block>
  <block id="22082fb9e9a42ddec66d9e75b3a3e61f" category="paragraph">如果编程不适合您的情况、而您希望使用配置管理工具、则可以克隆并运行NetApp发布的Ansible攻略手册 <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>。</block>
  <block id="b75bc3343d170f8dd97d55a434b978ed" category="doc">使用Astra Control便于进行数据剖析和恢复应用程序</block>
  <block id="3bbc946d425216e518cab3d8bcac2d2e" category="inline-link-macro">首次使用案例</block>
  <block id="3693bda9c9f6c60fbcfaa68a3c84d1c0" category="paragraph">在中 <block ref="378d294ca149bdd5226353f2fb623f62" category="inline-link-macro-rx"></block>、我们演示了如何使用NetApp Astra控制中心来保护Kubernetes中的应用程序。本节介绍如何使用NetApp Astra工具包中的Python SDK通过Astra Control将应用程序备份直接集成到您的开发工作流中。这种方法可以在持续集成和持续部署(CI/CD)过程中自动执行按需备份、从而保护开发和生产环境。在CI/CD管道和生产应用程序中增加了这一额外的应用程序一致的数据保护层、因此、如果开发过程中出现问题、开发流程就会很安全、从而促进良好的业务连续性实践。</block>
  <block id="93cf0eac312e112dec7819cf9726e08d" category="paragraph">在传统工作流中、在将应用程序升级到新版本时遇到故障后、开发团队会尝试根据客户提供的错误报告实时对问题描述 进行故障排除。或者、在出现第一次故障时、团队可以尝试将应用程序重新部署到并行调试环境、以使该过程脱机。他们可以将旧代码库从先前版本重新部署到生产环境中、从而将应用程序恢复到正常运行状态。</block>
  <block id="63cbc205a471137f16d61f24cd16531d" category="image-alt">传统工作流</block>
  <block id="cd78d769508976f182829ab0d59eb537" category="paragraph">尽管此方法有效、但团队必须确保已损坏的生产应用程序的状态与出现问题时在生产中看到的版本的状态一致。他们还必须花时间从存储库中提取代码并重新部署计算机映像、以便将应用程序还原到正常运行状态、从而将已知良好的构建提升到生产环境。此外、在这种情况下、我们不考虑生产数据库本身是否因错误代码而损坏。理想情况下、数据库数据有单独的备份过程、但我们是否必须假定这些备份过程与应用程序发布时的状态一致？在这种情况下、使用Astra Control进行有状态和应用程序一致的备份、还原和克隆的优势真正体现了它们的价值。</block>
  <block id="8b8ad5ef011a096e139bfa3245f80536" category="paragraph">首先、我们可以使用Astra Control对应用程序的状态进行事后分析。为此、我们会以应用程序一致的方式将Buggy生产版本克隆到并行测试环境中。将此环境置于错误状态、可以帮助我们实时解决问题。</block>
  <block id="f94a2c6cdc2965b0f258d8215d1d28e0" category="paragraph">此外、Astra Control还支持原位还原功能、使我们可以将生产应用程序还原到最后可接受的备份(在受影响的代码版本之前)。还原的版本采用应用程序一致且有状态的方式、包括先前分配的传入IP、并采用先前的错误生产应用程序的位置。因此、访问前端的客户可能不会意识到向备份版本的过渡。</block>
  <block id="1b0d7d8dcdf6d93ab2d330cc2396dfbc" category="image-alt">事后工作流</block>
  <block id="204890df83c01d375e4f4b6a724cc278" category="section-title">使用情形验证前提条件</block>
  <block id="93323e0f22b5aab17967ba48325ffbfa" category="paragraph">部署和配置了以下工具或平台作为前提条件：</block>
  <block id="f4f24690df38094196eebb86cb8ae057" category="list-text">Red Hat OpenShift容器平台。</block>
  <block id="727324215fe79d6ac06ad699c15bc8b6" category="list-text">NetApp Astra Trident安装在OpenShift上、后端配置为NetApp ONTAP 系统。</block>
  <block id="229afb3c2926b78c5616a952d849e68c" category="list-text">已配置一个指向NetApp ONTAP 后端的默认存储器。</block>
  <block id="ba5452097a4c1be15b1efd3a6b26349f" category="list-text">NetApp Astra Control Center安装在OpenShift集群上。</block>
  <block id="81c0c009a723f32f259a76657c0df955" category="list-text">OpenShift集群作为受管集群添加到Astra控制中心。</block>
  <block id="6500a898faeb0dbf12368cd5d4c62b66" category="list-text">Jenkins安装在OpenShift集群上。</block>
  <block id="76046924ab57dbfe48ac94a0d7cd184f" category="list-text">在生产环境中安装了Magento应用程序。此用例中的生产环境是Red Hat OpenShift集群中名为"mageno-prod"的命名空间。</block>
  <block id="7e5531e0bbdbf2a1b4736169f5261238" category="list-text">由Astra控制中心管理的生产应用程序。</block>
  <block id="be3750e953403822ff53f62de7d378c9" category="list-text">使用Astra Control捕获的生产应用程序的已知良好备份。</block>
  <block id="a571d6a950aa43dc09919def5e2f001a" category="section-title">克隆和还原管道</block>
  <block id="c04ae281a30f44b5bfe0091b23da26f7" category="paragraph">考虑到该应用程序已升级到新版本、生产环境(`mageno-prod`)中的应用程序在升级后无法按预期运行。假设前端查询返回的数据与请求不匹配、或者数据库实际上已损坏。要克隆和还原管道、请完成以下步骤：</block>
  <block id="8c2af21e6b34f2b1071040d4d1cfcb1c" category="image-alt">应用程序失败</block>
  <block id="6b1006b72a3e1550c386243b3965f2dc" category="list-text">登录到Jenkins并通过依次单击"新项目"和"管道"创建管道。</block>
  <block id="42c6ce7c0a0da42cf240660b7916b661" category="list-text">从Jenkinsfile复制管道<block ref="8676dd4f33dff00c4bf2944921591642" category="inline-link-rx"></block>。</block>
  <block id="64b46adfefce359622cb0f4882c6c1bd" category="list-text">将管道粘贴到Jenkins管道部分、然后单击保存。</block>
  <block id="68d9707b516a968ed4c0757cbe9d5a9f" category="list-text">使用相应的详细信息填充Jenkins管道的参数、例如生产环境中的当前Magento应用程序版本、Astra控制中心FQDN、API令牌、生产和调试环境的实例ID和应用程序名称或命名空间以及源和目标集群名称。在本用例中、生产环境是一个名为"mageno-prod"的命名空间、而调试环境是一个名为"mageno-debug"的命名空间、该命名空间是在Red Hat OpenShift集群上配置的。</block>
  <block id="0aada8c0ec6d36d56210caa3cac9e025" category="list-text">单击Build now。管道将开始执行并逐步完成各个步骤。应用程序将首先在当前状态克隆到调试环境、然后还原到已知正常运行的备份。</block>
  <block id="4413dc875e85526bf92964b740f23064" category="image-alt">生前管道</block>
  <block id="4abbf0b75dc539f2afebf5014fbe6ea8" category="list-text">验证克隆的应用程序是否为包含错误的版本。</block>
  <block id="cbcf57aecdb6a6d216d8239a690bc2f6" category="image-alt">克隆的应用程序失败</block>
  <block id="e73e23a9c5f896c3c98ea35a77116dfe" category="list-text">验证生产环境是否已还原到工作备份、生产环境中的应用程序是否按预期工作。</block>
  <block id="b24fb6cbfbfd8a2620eab1cb8f9d1563" category="image-alt">已还原的生产应用程序</block>
  <block id="cbd612409ffde58db700aacbf7ea15ca" category="paragraph">这两项操作结合在一起、可以加快恢复正常业务运营的速度。要查看此用例的实际操作、请观看视频 <block ref="f5eb99e953852b5d0acfc08abd7c4f00" category="inline-link-macro-rx"></block>。</block>
  <block id="847338f2bbcf0d01da4eec4011f6ad14" category="summary">本技术报告概述了NetApp如何在使用容器化应用程序时、在多个方面轻松高效地使用DevOps用例。首先、我们将利用Astra产品组合详细介绍NetApp存储系统及其与Kubernetes平台的集成。最后，我们还探讨并记录了许多解决方案验证和实际使用情形。</block>
  <block id="322f410c2f08f93c29982d4bf9cabcc0" category="doc">TR-4919：《采用NetApp Astra的DevOps》</block>
  <block id="ede7528f12f050f41a167a0f19204ecb" category="paragraph">采用NetApp Astra解决方案 的开发运营旨在为客户提供卓越的价值、其使用情形如下：</block>
  <block id="2dcb73ff09329212051362094e88c1a7" category="list-text">易于部署和管理在受支持的Kubernetes分发版上部署的应用程序和开发环境。</block>
  <block id="c267f4560fe6c3f4bee2d0420cdd7977" category="list-text">讨论DevOps工作流的实际使用情形、以及NetApp可提供的工具和方法示例、以使这些方法更易于采用和使用。</block>
  <block id="52d3258544cd838f0c52461847e6943b" category="list-text">探索如何使用应用程序一致的快照、备份和克隆来增强DevOps体验。</block>
  <block id="6071498e95e7692ffc4f3f66e80e1fe2" category="list-text">堆栈中所有层的高可用性、因此工作流不会中断。</block>
  <block id="0fd2f931dbf65015445450e54266b6dd" category="list-text">为最终用户简化部署和管理过程。</block>
  <block id="683aa4d78ced60b9236f9cc2f4eaf1eb" category="list-text">API驱动的可编程基础架构、可跟上微服务和开发人员灵活性的步伐。</block>
  <block id="440bd390f196ecee0d5c1bbc242f74c1" category="list-text">能够根据工作负载需求以自动化方式独立扩展基础架构。</block>
  <block id="e1151e572983d1f8759759f2765ccd80" category="list-text">保护应用程序及其为DevOps工作流提供支持的永久性数据集、无需依赖重新部署或手动复制数据、加快了产品上市速度。</block>
  <block id="556e90029d54aba834e233882cb7bdb5" category="paragraph">本技术报告认识到这些功能和挑战、概述了使用广泛的NetApp产品组合改进和简化容器化应用程序的DevOps用例的过程。</block>
  <block id="3c4a3a2e21fd3a1caee264afd78ccaa4" category="paragraph">采用NetApp解决方案 的DevOps包含以下主要组件：</block>
  <block id="26ebb4a3d87e964eeae59f74f1cf7565" category="section-title">DevOps实践</block>
  <block id="d113ef32a81ded7eb94b33e9a12344d3" category="paragraph">DevOps实践侧重于自动化、可重复且易于管理的操作、通过允许最终用户控制其代码开发环境来增强开发工作流。本解决方案 提供了几个示例和用例、其中NetApp技术可为这些操作带来最大优势。</block>
  <block id="301a5e3f98e4b9ad41275bc224cd61ec" category="paragraph">目前使用的容器业务流程平台数量众多。虽然其中大多数平台都基于Kubernetes、但每个平台都有利弊。因此、在为DevOps工作流选择容器编排平台时、了解功能集和集成非常重要。借助NetApp Astra产品套件、我们可以为以下平台提供全面的DevOps用例支持：</block>
  <block id="6c00bd8314a0e887501377d7e80e84a0" category="list-text"><block ref="41493d18eda2456ccaff840381cd2ba9" category="inline-link-rx"></block> 4.6.8+</block>
  <block id="82033d4b30c6027097326898ed36b593" category="inline-link">Rancher</block>
  <block id="30fad75d887172c8bd19dcc5febd9364" category="list-text"><block ref="f47c99eede6f9eae831133d1e9b5034b" category="inline-link-rx"></block> 2.5以上</block>
  <block id="22bd2466d697a7c77e319d9a31c2166f" category="list-text"><block ref="fe8d70118059c4a67994e27a008bb3e0" category="inline-link-rx"></block> 1.20以上</block>
  <block id="a56837df79ae6671b6b511c330431135" category="inline-link">VMware Tanzu Kubernetes网格</block>
  <block id="b2bc0f20995d2c98d2f854eb51c195c7" category="list-text"><block ref="3f98585591c50cc93953cd157cf0939c" category="inline-link-rx"></block> 1.4及更高版本</block>
  <block id="a1c1bb4994628000cfe61563bf4ff4f5" category="inline-link">VMware Tanzu Kubernetes Grid Integrated Edition</block>
  <block id="a75ee0eed3c5f01371e94695f023b820" category="list-text"><block ref="948fe538658bc79d22a37c7852e43c83" category="inline-link-rx"></block> 1.12.2+</block>
  <block id="44a18520ed05f9b0b2e06135a4ff7518" category="summary">本技术报告概述了DevOps和潜在用例。</block>
  <block id="74b9fd8d0b2ef1c2b396580a2afd59ae" category="doc">DevOps概述</block>
  <block id="d5df4eecbaafa5d83d7698ba92c7cecd" category="paragraph">在过去几年中、构建软件的企业一直在接受DevOps的概念。DevOps实践打破了组织障碍、让开发和运营团队更加紧密地联系在一起。开发运营实践还可以帮助团队加快交付速度、提高可用性并提高服务和应用程序的稳定性、从而提高团队的工作效率。此外、采用自动化框架也是成功的关键要素—从大规模构建、测试和操作应用程序到管理完全自动化的基础架构平台或堆栈。下面我们将讨论开发运营的一些主要用例、在这些用例中、可以实施NetApp解决方案来帮助增强开发运营实践者在日常实践中遇到的体验。</block>
  <block id="e7ccc944261680ee4a52d724dd1ca1c5" category="section-title">开发运营用例</block>
  <block id="e4fd3fc8a04e3e1d2e788cd1b017e1f2" category="paragraph">虽然DevOps没有一个普遍接受的定义、但适用于DevOps实践者的解决方案通常包含类似的构造或理念、可实现轻松的大规模实施、重复和管理。以下各节介绍了NetApp解决方案支持的DevOps工作流的潜在用例。</block>
  <block id="020a9588f0f051f7f9ff59fabaffa365" category="section-title">持续集成、持续交付和持续部署(CI/CD)</block>
  <block id="b1a2676c9ceea5e6ef4c514562097e9a" category="paragraph">持续集成、持续交付和持续部署(Continuous Integration、Continuous Delivery和Continuous Deployment、CI/CD)是一种编码理念、它鼓励开发人员通过制定一种方法、使其能够以自动化方式持续更新、测试和部署代码、从而实施和转变其编码实践。在大多数DevOps工作流中实施CI/CD的最常用方法是CI/CD管道、有几个第三方软件应用程序可以帮助实现这一点。</block>
  <block id="3ff91355eb24188940a49b15da87cb74" category="image-alt">CI/CD映像</block>
  <block id="64d92cb8c4c053363095cf796a7b89ba" category="paragraph">请参见以下常见应用程序示例、这些应用程序可以帮助您处理CI/CD类型的工作流：</block>
  <block id="418f66e40d28aac0fa315742070e645f" category="inline-link">ARgoCD</block>
  <block id="2e54334c0a5ce2e3e5a5845df3ab3ada" category="inline-link">Jenkins</block>
  <block id="e1500a23f27fb897c6cdf5caab04195d" category="inline-link">特克顿</block>
  <block id="4d094d290ed5b2a855427290709addea" category="paragraph"><block ref="ff7d5093e53bbd8006cbcaaeb044f69a" category="inline-link-rx"></block>
<block ref="0d8e72f4ae085bb6c45eba7c3f144090" category="inline-link-rx"></block>
<block ref="313a601d85cff2a8e7d85ce0f552cc73" category="inline-link-rx"></block></block>
  <block id="2c14caaf080b9d4ff53b1e0d7364a348" category="paragraph">本技术报告后面介绍的一些使用情形已在Jenkins中进行了演示、但主要的CI/CD原则可应用于组织在自己的实践中实施的任何工具。</block>
  <block id="af41549605744cf23f27cbc14458bf82" category="section-title">基础架构即代码</block>
  <block id="3e9f73de1e8a89473ea5df8ed9ad7651" category="paragraph">基础架构即代码有助于通过自动化命令、API和软件开发套件(SDK)配置和管理IT资源。这一概念通过消除物理数据中心或资源限制、极大地增强了开发运营体验、因为这些限制可能会妨碍开发人员实现其目标。</block>
  <block id="9b2cf15c50955773c7604b77322b057e" category="image-alt">基础架构即代码映像</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="inline-link">Python</block>
  <block id="d51d5ee15f404c2f4f7863bebcde1fac" category="inline-link">Ansible</block>
  <block id="14590850b4107a6f92feb1af739b82eb" category="inline-link">Puppet</block>
  <block id="10feac82bf81358ba2b3681989464290" category="paragraph">最终用户通常使用编程语言、例如<block ref="11022d613ff738bd6763caad4acd7f7e" category="inline-link-rx"></block> 或自动化工具、例如<block ref="9790ec336069075a6bee003fe52e73bb" category="inline-link-rx"></block> 或<block ref="82158671408fe4876cefcfa78b9fd777" category="inline-link-rx"></block> 创建可重复的自动化基础架构扩展操作、开发人员可以根据需要调用这些操作。</block>
  <block id="25d4b1e166882d63d2b4f8c8919a7513" category="paragraph">NetApp ONTAP 和Astra Control都包含面向公有 的API和Ansible模块或软件开发工具包、这些模块或工具包可以使自动化操作非常易于采用并集成到DevOps流程中。</block>
  <block id="72a943bda30daac28d5a7097897df424" category="summary">NetApp提供了许多产品、可帮助客户在基于容器的环境中编排和管理永久性数据。</block>
  <block id="d9ac8f9dec3643254ee6240ba67244f5" category="list-text"><block ref="d9ac8f9dec3643254ee6240ba67244f5" category="inline-link-macro-rx"></block></block>
  <block id="dd2387c2fbbd7ec35d40da2a116c5349" category="list-text"><block ref="dd2387c2fbbd7ec35d40da2a116c5349" category="inline-link-macro-rx"></block></block>
  <block id="ae5d1fe148e47e375a2109cb3f29045a" category="paragraph">请参见文档 <block ref="a57add0d538360cd0adbee43a89f028d" category="inline-link-macro-rx"></block> 安装和使用Astra Trident。</block>
  <block id="dc51ad14ee45a258aa1e6606251cf967" category="doc">视频和演示：借助NetApp Astra实现DevOps</block>
  <block id="cd70acb1d118792e37e49b5dc15142ad" category="paragraph">以下视频演示了本文档中介绍的一些功能：</block>
  <block id="c6b924f851b08c850fe2e53f34ada256" category="doc">利用NetApp FlexClone技术加快软件开发速度</block>
  <block id="e071982902994eb194aeef35d4e7d131" category="paragraph">对于希望通过与合作伙伴共享环境或在开发环境中测试新版本的代码而不影响当前正在处理的版本的开发人员来说、在Kubernetes集群中克隆已部署的应用程序是一种非常有用的工具。Kubernetes应用程序的有状态和应用程序一致克隆是NetApp Astra Control中的一项主要功能、同时还包括应用程序的备份和还原。另外、如果使用同一存储后端在同一个Kubernetes集群中克隆应用程序、则Astra Control会默认使用NetApp FlexClone技术来复制永久性数据卷、从而显著加快此过程。通过加快此过程、克隆的环境会在几分钟内完成配置并可供使用、与重新部署测试或开发环境相比、开发人员只需短暂的暂停即可恢复工作。为了方便起见、NetApp Astra Control中提供的所有功能均可通过API调用、从而可以轻松集成到Ansible等自动化框架中。因此、环境的暂存速度可以更快、因为开始克隆操作步骤 只需要在攻略手册或角色中进行少量更改。</block>
  <block id="130a289acaa6c63f08a152e232264781" category="section-title">什么是NetApp FlexClone技术？</block>
  <block id="de7fc3e1378f3d66008013e37abfc654" category="paragraph">NetApp FlexClone技术是NetApp FlexVol 的可写时间点Snapshot副本。它们几乎可以即时配置、包含源卷中的所有数据、并且不会占用额外的存储空间、直到新卷中的数据开始从源中转移为止。当多个数据副本可用于暂存、而存储系统用于配置这些卷的资源有限时、它们通常用于开发或基于模板的环境。与必须多次复制数据并消耗大量存储空间和时间的传统存储系统相比、NetApp FlexClone技术可以加快执行与存储相关的任务。</block>
  <block id="66b43b8d36a821005edbb505f73e703f" category="image-alt">FlexClone映像</block>
  <block id="b9ca5ba97cf75d3dafb51f78e073770a" category="inline-link">NetApp文档</block>
  <block id="b9c059adc88329f807d19beff36c402c" category="paragraph">要了解有关NetApp FlexClone技术的详细信息、请访问上的页面<block ref="26a4454b15f9e59c91953aae4d5cca61" category="inline-link-rx"></block>。</block>
  <block id="c2bdd689dbc313e32552cbc9e519673e" category="list-text">受支持的Kubernetes Distribution、例如Red Hat OpenShift 4.6.8+、Rancher 2.5+或Kubernetes 1.19+。</block>
  <block id="17909bff47021a48534aa137533988cb" category="list-text">NetApp Astra控制中心21.12及更高版本。</block>
  <block id="f6e864ce20ae64f2d8e8d9788960ddcb" category="list-text">一种NetApp ONTAP 系统、其中包含通过NetApp Astra Trident配置的存储后端。</block>
  <block id="02de8f49568cea93a498f8b7b321a4e4" category="list-text">Ansible 2.9及更高版本。</block>
  <block id="0f466e306fc4825f1141ddc130ca599a" category="list-text">适用于您要在NetApp Astra Control中克隆为受管应用程序的环境的模板。</block>
  <block id="3e36385ca501623e48219eaf55547185" category="section-title">用例简介</block>
  <block id="c7af167d0f4082e772505e76bb547621" category="paragraph">对于此用例、我们可以直观地显示类似于以下工作流的内容：</block>
  <block id="fc1fa3a113fd483da9a2a706cef62740" category="image-alt">工作流映像</block>
  <block id="3056a7af3144c13993f45fa84e78699e" category="list-text">用户运行Ansible攻略手册来创建新的暂存环境。</block>
  <block id="c48538a3317fc98bc2fa8cf73553ca0b" category="list-text">Ansible使用URI-API模块调用Astra Control来执行克隆操作。</block>
  <block id="af27beb3ef227700c87619b941ef922d" category="list-text">Astra Control会在预配置的模板环境中执行克隆操作、从而创建新的托管应用程序。</block>
  <block id="afec891492c1e0c4d92776aa8fbb7a37" category="admonition">此环境可以是开发中的一个独立应用程序、也可以是Jenkins CI/CD管道等整个开发环境。</block>
  <block id="b120622a84d96b41ece4bf14a2afc42c" category="list-text">然后、用户将其代码的某个版本从Gitea等联机存储库提取到克隆的开发环境中。</block>
  <block id="58b9c8dff15389cfc89079bed15b0353" category="list-text">新版本的应用程序由NetApp Astra Control部署和管理。</block>
  <block id="512473ae00b91f234459da9d54a73d63" category="admonition">这两个过程都可以实现自动化。</block>
  <block id="45469e0108aa4b426d8e379bf3e01032" category="list-text">用户可以在此克隆环境中开发新代码。</block>
  <block id="290324e3d59e2f7053c0f9e9e6e0efa3" category="list-text">如果用户对开发工作感到满意、他们可以将代码推回托管存储库。</block>
  <block id="30d4a5dfd238538be60a29a62c199938" category="paragraph">此处提供的使用情形取决于您要克隆的特定环境或应用程序是否存在黄金模板。在我们的环境中、我们创建了三个此类模板、一个用于Wordpress部署、一个用于Magento部署、一个用于使用Gitea的Jenkins CI/CD环境、我们将其命名为DevTools。</block>
  <block id="c30f4e03a21fface6aa43659a4078d71" category="image-alt">模板图像</block>
  <block id="1107495525479f3871a68bae36a3f17b" category="paragraph">其中每个环境都由NetApp Astra控件管理、其中的永久性卷当前存储在NetApp ONTAP 存储系统上、并由NetApp Astra Trident提供NFS后端。</block>
  <block id="2ba3749d66f6540154024e19b4d99cc9" category="section-title">使用情形验证</block>
  <block id="7a73c2eecaec86daa9aee3eff521b699" category="list-text">克隆NetApp解决方案工程团队提供的Ansible工具包、其中包括克隆角色和应用程序更新攻略手册。</block>
  <block id="6264ab91acf969dcae78c1602bca2059" category="list-text">编辑`vars/clone_vars.yml`并填写适合您的Astra Control环境的全局值。</block>
  <block id="240e34a15ccbba0aea72efc21aaab86d" category="admonition">您需要填写的全局环境值可在NetApp Astra Control的"API Access"菜单下的用户配置文件图标下找到。</block>
  <block id="f35821a1d6caaf6d90163620f4ea7458" category="image-alt">API访问映像</block>
  <block id="25037aa69bc75f53a1077e99016fcb35" category="list-text">完成全局变量后、您可以为要克隆的特定应用程序选择值。要将devtools环境克隆到名为`alan-devtools`的个人环境、您需要执行以下操作：</block>
  <block id="3c88bcd7ff9904c39c203d75df0f43aa" category="admonition">要在克隆过程中利用NetApp FlexClone技术、`src集群`和`dest-cluster`必须相同。</block>
  <block id="7701b76fd4e9f02523bba989b59e089f" category="list-text">现在、您可以执行此攻略手册来克隆此应用程序。</block>
  <block id="b843fd904e687b09c9fea5652dd26835" category="admonition">写入的攻略手册必须由root用户或通过传递"-K"参数在sudo过程中升级的人员运行。</block>
  <block id="47261a281b6d461c0e208fcdd564b6ef" category="list-text">攻略手册运行完毕后、克隆的应用程序将在Astra控制中心控制台中显示为可用。</block>
  <block id="4ebfaaa8ab1aa4f1a8e1f0e4c080a066" category="image-alt">克隆的应用程序映像</block>
  <block id="d7d808da7950a8d4bece269105013664" category="list-text">然后、用户可以登录到部署该应用程序的Kubernetes环境、验证该应用程序是否已使用新的IP地址公开、并开始其开发工作。</block>
  <block id="ba87075b7677acd5c3798c45d5899095" category="paragraph">有关此用例的演示以及升级应用程序的示例、请参见 <block ref="c3446aeb84c085acd211fbde68c1be91" category="inline-link-macro-rx"></block>。</block>
  <block id="2f1df67ff878abb3db18e3010bcc2920" category="paragraph">DevOps工作流的一个最常见用途是持续集成和持续部署(CI/CD)管道、这些管道可在开发人员提交新代码时在应用程序上构建、集成和运行自动化测试套件。开发运营工程师和站点可靠性工程师(SRE)通常拥有专用于各种工作流的管道、用于开发新功能、回归测试、错误修复、质量工程以及开发流程中的其他功能。</block>
  <block id="1413f73ce604910297e839d41a24e9f9" category="paragraph">随着团队提高自动化水平、生产应用程序的变革步伐可能会让人感到不知所措。因此、某些团队更愿意保护生产中的应用程序或服务。除了保护代码和容器映像之外、他们还希望保护应用程序状态、配置数据(例如与应用程序关联的Kubernetes对象和资源)以及应用程序的永久性数据。</block>
  <block id="8322f060ae0335cf0232ac3b55da6556" category="paragraph">在此使用情形中、我们将深入了解一个从促销到生产的管道、该管道会部署新版本的应用程序：首先部署到暂存环境、然后部署到生产环境。此示例同样适用于主要公有 云以及内部环境。虽然我们展示了一个版本的应用程序的部署、但该渠道也可用于其他策略、例如蓝色/绿色或金丝雀部署。作为CI/CD管道的一部分、我们将通过创建完整的应用程序备份来保护应用程序。对生产中应用程序及其数据、状态和配置进行应用程序感知备份、对于众多DevOps工作流来说非常有用。</block>
  <block id="13c258a59936aa47a4215b1c02921c7d" category="image-alt">采用NetApp Astra的DevOps用例1架构</block>
  <block id="fcd7f001e9274fdefb14bff91c799306" category="inline-link">Magento</block>
  <block id="0e8625d3981b9d26e0866da357d318c8" category="inline-link">NetApp Astra Control Python SDK</block>
  <block id="e5c0235557a0821c530e70a6ac76e817" category="paragraph">用于验证此用例的应用程序为<block ref="ca8bdc27f15f815590190c112abb55a0" category="inline-link-rx"></block>一种基于Web的前端电子商务解决方案 、一种用于搜索和分析功能的Elasticsearch实例以及一个跟踪所有购物清单和交易详细信息的MariaDB数据库。此容器化应用程序安装在Red Hat OpenShift集群中。应用程序中的每个POD都使用永久性卷来存储数据。永久性卷由NetApp Astra Trident自动创建、NetApp Astra Trident是适用于Kubernetes的容器存储接口兼容存储编排程序、可在NetApp存储系统上配置存储。此外、为了利用Astra控制中心的应用程序保护功能、相关应用程序由Astra Control管理、然后使用该控制器触发应用程序备份、这些备份将存储应用程序的状态以及永久性卷中的数据。我们使用了<block ref="d0b4b6e44937c3a38c218d58868f48cf" category="inline-link-rx"></block> 自动执行触发应用程序备份的过程、然后将该过程引入到CI/CD管道中。此管道是使用一个常用的CI/CD工具创建和执行的、该工具称为 <block ref="2362760839a75356cff2ce591e8175c5" category="inline-link-rx"></block>]以自动执行流、从而构建、保护和部署应用程序。</block>
  <block id="be6d35c56a8d9c9eda054648f5aaf778" category="paragraph">让我们来了解一下前提条件和操作步骤 、以便在CI/CD管道中引入保护。</block>
  <block id="019b3399490601533f0c22df26617506" category="list-text">NetApp Astra Trident安装在OpenShift上、并配置了NetApp ONTAP 系统的后端</block>
  <block id="32714d2e851023befd52d2dafcb3df12" category="list-text">已配置一个指向NetApp ONTAP 后端的默认存储器</block>
  <block id="4feccdee8cd5d15c137a63228c1e8035" category="list-text">NetApp Astra Control Center安装在OpenShift集群上</block>
  <block id="89a7002b85e3c07334367a744cb41016" category="list-text">OpenShift集群作为受管集群添加到Astra控制中心</block>
  <block id="f485827022df06c2991a88b97eeb4e48" category="list-text">Jenkins安装在OpenShift集群上、并配置了一个代理节点、其中安装了Docker引擎</block>
  <block id="e6b72ced375884adc1f139800a859ef1" category="section-title">安装应用程序</block>
  <block id="cd03481692ef65344c4dd7bf363bc056" category="paragraph">首先、让我们从暂存和生产环境中的应用程序初始安装开始。在此使用情形中、此步骤是前提条件、因此可以手动执行。随着新版本的应用程序、CI/CD管道用于后续的构建和部署工作流。</block>
  <block id="2ee68ca17059fe4d4ab06d0230bed0c3" category="paragraph">此用例中的生产环境是一个名为`mageno-prod`的命名空间、相应的暂存环境是在Red Hat OpenShift集群上配置的一个名为`mageno-staging`的命名空间。要安装此应用程序、请完成以下步骤：</block>
  <block id="05586ccfd2c7dbe7b3226b21240add7c" category="list-text">在生产环境中使用BitNami Helm图表安装Magento应用程序。我们对Magento和MariaDB Pod使用rwx PV。</block>
  <block id="14224ce39d8587f380c4b992c668c24d" category="admonition">Magento BitNami Helm图表需要负载平衡器服务才能显示Magento GUI服务。我们使用了 <block ref="6beef47e42ff9b3760535f361acb6931" category="inline-link-macro-rx"></block> 用于在此示例中提供内部负载平衡器服务。</block>
  <block id="4750ba228d6f73ce1e9d9e27f0cd2ca5" category="list-text">几分钟后、验证所有Pod和服务是否都在运行。</block>
  <block id="3a0715e577e143188e1e748efe2fca27" category="list-text">对暂存环境重复相同的操作步骤。</block>
  <block id="e684201cc94f2e04edf2353711b58fe5" category="section-title">在Astra控制中心管理Magento应用程序</block>
  <block id="e9758d5e82771fcca93395ce3a7c1d40" category="list-text">导航到应用程序并选择发现的应用程序选项卡。</block>
  <block id="082833c45c4a99b63cbf53365495e0d2" category="list-text">在生产环境中、单击Magento应用程序旁边的省略号(`mageno-prod`)、然后单击管理。</block>
  <block id="28a12dc4e9b29cb97bfaf36914e9983a" category="list-text">现在、Magento应用程序由Astra控制中心管理。Astra Control支持的所有操作均可在此应用程序上执行。同时、请记下此应用程序的版本。</block>
  <block id="4ef629c07108e88861fc4036780e9a1f" category="image-alt">升级前检查Magento版本</block>
  <block id="c03f75891d5e0356b60d3752df0f0444" category="list-text">重复执行在暂存环境中管理Magento应用程序的步骤(`mageno-staging`)。</block>
  <block id="881e2f21543c210893e098f6383f4199" category="section-title">具有集成保护的CI/CD管道</block>
  <block id="841e01ce1d424839fd87eed89e1ce154" category="paragraph">使用新版本的应用程序时、我们会使用CI/CD管道构建容器映像、备份暂存和生产环境、将新版本的应用程序部署到暂存环境、等待批准升级到生产环境、 然后将新版本的应用程序部署到生产环境中。要使用CI/CD管道、请完成以下步骤：</block>
  <block id="88ba71f9d62d24eeb2decfe9cd30cfb1" category="list-text">登录到Jenkins并创建所需的凭据：一个用于Magento creds、一个用于MariaDB管理creds、另一个用于MariaDB根creds。</block>
  <block id="9743ff34b00bc2d03fdc0b6ee11b0781" category="list-text">导航到Manage Jenkins &gt; Manage Credentials、然后单击相应的域。</block>
  <block id="5efc31d04501ec1bfbc5b2e785ac7cc2" category="list-text">单击Add Credentials、然后将种类设置为Username、并将密码和范围设置为Global。输入凭据的用户名、密码和ID、然后单击确定。</block>
  <block id="5ff08be42358b0ed5a5235096ccfa397" category="image-alt">创建凭据</block>
  <block id="ef7b482a4875dec8ec53a6a7ecea081b" category="list-text">对其他两个凭据重复相同的操作步骤。</block>
  <block id="955b68bae8db1bc3b2abbf6ada3710be" category="list-text">返回信息板、单击"新建项目"创建管道、然后单击"管道"。</block>
  <block id="027f0bd54326a6b14e6c7daf65d07f5c" category="list-text">从Jenkinsfile复制管道<block ref="94d69998dfd97a76d20ae02a64c629ae" category="inline-link-rx"></block>。</block>
  <block id="843730ff8981a034040c0f42fdaa48ce" category="list-text">使用相应的详细信息填充Jenkins管道的参数、包括Helm图表版本、要升级到的Magento应用程序版本、Astra工具包版本、Astra控制中心FQDN、API令牌及其实例ID。指定生产和暂存环境的Docker注册表、命名空间和Magento IP、同时指定所创建凭据的凭据ID。</block>
  <block id="3f52d6cbc878f43533503f2bd5a61952" category="list-text">单击Build now。管道将开始执行并逐步完成各个步骤。首先构建应用程序映像并将其上传到容器注册表。</block>
  <block id="059d6fb9b965d0897c20fb2482659279" category="image-alt">管道进度</block>
  <block id="ed2c1f4dfcf187d5140cf31e58801b4f" category="list-text">应用程序备份通过Astra Control启动。</block>
  <block id="633d66eb7984b86ee4487b6a10ffc34a" category="image-alt">已启动备份</block>
  <block id="75b0ba1236c133f891fdd36b2e3913f3" category="list-text">成功完成备份阶段后、从Astra控制中心验证备份。</block>
  <block id="2b3a33094c5c31ac6cc6be770417a07c" category="image-alt">备份成功</block>
  <block id="fec272abe380f3502ef64cbc2cc652bf" category="list-text">然后、新版本的应用程序将部署到暂存环境中。</block>
  <block id="4576032c05f55b22a040f067151cde6f" category="image-alt">已启动暂存部署</block>
  <block id="4d4659ee9b2600243399d4aceca7c670" category="list-text">完成此步骤后、该程序将等待用户批准部署到生产环境中。在此阶段、假设QA团队执行一些手动测试并批准生产。然后、您可以单击批准将新版本的应用程序部署到生产环境中。</block>
  <block id="e30db45e8514d0d8f662187e28b8b5ec" category="image-alt">正在等待升级</block>
  <block id="3a7b15850615e9fd306b379f77e0e016" category="list-text">验证生产应用程序是否也已升级到所需版本。</block>
  <block id="f11253856e2b859c46731353f46b732e" category="image-alt">已升级生产应用程序</block>
  <block id="70817285f3f68722fd851dde7464feb2" category="paragraph">作为CI/CD管道的一部分、我们展示了通过创建完整的应用程序感知型备份来保护应用程序的能力。由于整个应用程序已作为从促销到生产的渠道的一部分进行备份、因此您对高度自动化的应用程序部署更有信心。此应用程序感知型备份包含应用程序的数据、状态和配置、可用于大量DevOps工作流。一个重要的工作流是、在出现不可预知的问题时回滚到应用程序的先前版本。</block>
  <block id="94ec4ad32f9ba408876eabf1a42f6901" category="paragraph">虽然我们使用Jenkins工具展示了CI/CD工作流、但可以轻松高效地将此概念外推到不同的工具和策略中。要查看此用例的实际操作、请观看视频 <block ref="2eda593691b1da530fed5bfcba32a663" category="inline-link-macro-rx"></block>。</block>
  <block id="0e60ae06a3d7bec5f8950d8ea76b57d4" category="paragraph">最新版Astra Trident于2022年4月发布。已测试的 Trident 版本的支持列表，可在该支持列表中找到 Kubernetes 分发版本<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>。</block>
  <block id="b453397e87e54278a4cd32ac644d5934" category="sidebar">关于我们的合作伙伴解决方案</block>
  <block id="ff94fd25dea669a1eb9fc9bad5af5e80" category="sidebar">Red Hat OpenShift网站</block>
  <block id="8cf2142329e586b4350d53a76071db82" category="sidebar">Anthos网站</block>
  <block id="a5860a0f10641c9e31f8301d3f3ae548" category="sidebar">关于我们的容器资源</block>
  <block id="e2ed9dce9d5bb40e79fc6d3008de22ff" category="sidebar">采用NetApp技术的Anthos</block>
  <block id="500ce409f120039287d7670f42ff1821" category="sidebar">与NetApp携手开发运营</block>
  <block id="59b5f97219239806c778ffff9bda8ad0" category="sidebar">使用案例验证</block>
  <block id="1a4f47ee7c7d8b59e68be952ac121268" category="sidebar">适用于Anthos的高级配置选项</block>
  <block id="b0ed101b405f642695988c7ef3313b52" category="sidebar">归档解决方案</block>
  <block id="9eb662185982de390339607d2ee459a4" category="summary">Google Cloud中的Cloud Volumes Service 提供了多种本机保护数据安全的方法。</block>
  <block id="52aa20c1efa9dfeda78d72f4c056c23f" category="doc">Google Cloud中的Cloud Volumes Service 如何保护您的数据安全</block>
  <block id="9967209a1408f78f781d93dd0cdf88c4" category="section-title">安全架构和租户模式</block>
  <block id="9ba9e0f1cce71f64d3188bfdc502a43d" category="inline-link-macro">Cloud Volumes Service 架构</block>
  <block id="33186704f78f73f32736a9ba7f8ddc85" category="inline-link">私有服务访问</block>
  <block id="5971da0242ce7b616ff2972978613cef" category="inline-link-macro">"租户模式"</block>
  <block id="01760cb04e3a4a93404ab2c878b036db" category="inline-link-macro">"共享VPC"</block>
  <block id="e70da8f06ec706ed45906f411481eda0" category="paragraph">在此架构中、租户(请参见第节 <block ref="0a088dd892133b6a77304655c2b8b829" category="inline-link-macro-rx"></block>)定义为除非用户明确连接、否则彼此完全隔离的Google Cloud项目。通过租户、可以使用Cloud Volumes Service 卷平台将数据卷、外部名称服务以及解决方案 的其他基本部分与其他租户完全隔离。由于Cloud Volumes Service 平台是通过VPC对等连接的、因此这种隔离也会对其进行适用场景。您可以使用共享VPC在多个项目之间共享Cloud Volumes Service 卷(请参见一节) <block ref="c2426c8c5bcdce9adb82a8906c5a3478" category="inline-link-macro-rx"></block>）。您可以对SMB共享和NFS导出应用访问控制、以限制可以查看或修改数据集的用户或对象。</block>
  <block id="35a0e1620a03f33da8739635aaa3b607" category="section-title">为控制平台提供强大的身份管理功能</block>
  <block id="4504de40d15959838801111af31d224e" category="inline-link">身份访问管理(IAM)</block>
  <block id="d242c9a4fc4e118d87391841845ef44b" category="paragraph">在进行Cloud Volumes Service 配置的控制平面中、身份管理通过进行管理<block ref="490163f8d94b8a8397824811fb91c5ec" category="inline-link-rx"></block>。IAM是一项标准服务、可用于控制对Google Cloud项目实例的身份验证(登录)和授权(权限)。所有配置都使用Cloud Volumes Service API通过使用TLS 1.2加密的安全HTTPS传输执行、而身份验证则使用JWT令牌执行、以提高安全性。适用于Cloud Volumes Service 的Google控制台UI可将用户输入转换为Cloud Volumes Service API调用。</block>
  <block id="688247a9da881160b1073a4b76442640" category="section-title">安全强化—限制攻击面</block>
  <block id="4901056002c8d64da3b67da6a5a2dbbb" category="paragraph">有效安全性的一部分是限制服务中可用的攻击面数。攻击面可能包括各种内容、包括空闲数据、正在传输的数据、登录信息以及数据集本身。</block>
  <block id="733e720a346376b07eb9adac497c4063" category="inline-link-macro">"服务操作"、</block>
  <block id="aa6187208cb06e0a43851ee1783a370c" category="paragraph">托管服务可从其设计中消除某些固有的攻击面。基础架构管理、如一节所述 <block ref="ddbc8ce5f4099ff7254959018f566688" category="inline-link-macro-rx"></block> 由专门的团队处理、并可自动执行、以减少人员实际接触配置的次数、从而有助于减少有意和无意的错误数量。网络隔离、以便只有必要的服务才能彼此访问。加密会插入到数据存储中、只有数据平面需要Cloud Volumes Service 管理员的安全注意。通过隐藏API接口背后的大部分管理内容、可通过限制攻击面来实现安全性。</block>
  <block id="d8d81a048343e815b76f916e1c58e636" category="section-title">零信任模式</block>
  <block id="d2c4e1022fc22d0780bd913d3f16498e" category="paragraph">过去、IT安全理念一直是信任、但要进行验证、这种理念表现为仅依靠外部机制(例如防火墙和入侵检测系统)来缓解威胁。但是、攻击和违规行为演变成通过网络钓鱼、社交工程、内部威胁以及其他验证方法绕过环境中的验证、从而进入网络并造成严重破坏。</block>
  <block id="853f80d22a64d4fff24c05d305e800a8" category="paragraph">Zero Trust已成为一种全新的安全方法、目前的口号是"不信任任何内容、但仍需验证一切"。 因此、默认情况下不允许访问任何内容。此命令可通过多种方式实施、包括标准防火墙和入侵检测系统(IDS)以及以下方法：</block>
  <block id="d07f4106373448c16aedf0c01749e560" category="list-text">强大的身份验证方法(例如AES加密的Kerberos或JWT令牌)</block>
  <block id="4bbee6cac6b31b494ade66a9fc2f16e7" category="list-text">单一强身份源(例如Windows Active Directory、轻型目录访问协议(LDAP)和Google IAM)</block>
  <block id="da31693a70531052458cd4eff104672d" category="list-text">网络分段和安全多租户(默认情况下仅允许租户访问)</block>
  <block id="a8ce5780cff146b27ae2c2b3fddc0447" category="list-text">采用最低特权访问策略的粒度访问控制</block>
  <block id="493f70c348ea51d5c7cb8a28593df5a1" category="list-text">拥有数字审核和纸质跟踪的一小部分专属管理员</block>
  <block id="fd5070ec3e2f12398e4de9b77b900cbf" category="paragraph">在Google Cloud中运行的Cloud Volumes Service 通过实施"不信任、不验证一切"的立场、遵循零信任模式。</block>
  <block id="d7f2615c71a1567cc13cf3a7f7de0aea" category="section-title">加密</block>
  <block id="83c3a5400dd4f14665a803a22add4a9d" category="inline-link-macro">"空闲数据加密"</block>
  <block id="a37154afafe65368d5170741a4669261" category="inline-link-macro">"SMB加密"</block>
  <block id="e688fd1eb8866f914263d3493c30ccbb" category="inline-link-macro">"跨区域复制"</block>
  <block id="c05431edaaaefc20b48a7cd96f110e5d" category="inline-link-macro">"传输中的数据加密"</block>
  <block id="48aa29a35d8e13e796333876f4ea9f62" category="inline-link-macro">"Google Cloud network"</block>
  <block id="31d64d3cd8b2a692701b32dd6a611c76" category="paragraph">对空闲数据进行加密(请参见一节 <block ref="ce3046d8bb0cfdf8a89295f31068c29b" category="inline-link-macro-rx"></block>) <block ref="9963d74c8d0d381d9818a5c550dd7163" category="inline-link-macro-rx"></block> 或NFS Kerberos 5p支持。您可以轻松了解跨区域复制传输是否受TLS 1.2加密保护(请参见一节 <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>）。此外、Google网络还提供加密通信(请参见一节 <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block>)、以添加抵御攻击的保护层。有关传输加密的详细信息、请参见一节 <block ref="0e3bb83173de6418179f08aaa25b48dd" category="inline-link-macro-rx"></block>。</block>
  <block id="db57ea7882be0cb73c78bf1ba25a6823" category="section-title">数据保护和备份</block>
  <block id="48b5832efbf50440742eee7bfd02733b" category="inline-link-macro">Cloud Volumes Service 备份</block>
  <block id="cdb185875636a141b69ddabde6df7040" category="paragraph">安全性不仅仅是为了防止攻击。此外、还需要了解我们如何从发生的攻击中恢复。此策略包括数据保护和备份。Cloud Volumes Service 提供了在发生中断时复制到其他区域的方法(请参见一节 <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>)或数据集受勒索软件攻击影响时。此外、它还可以使用将数据异步备份到Cloud Volumes Service 实例以外的位置 <block ref="92f2015a7a07a74ffc21a27b08fadbb0" category="inline-link-macro-rx"></block>。通过定期备份、减少安全事件所需的时间、为管理员节省资金并提高效率。</block>
  <block id="3b0aab94fdc89c539c78fcbbf0190080" category="section-title">利用行业领先的Snapshot副本快速减少勒索软件</block>
  <block id="e7d51c7f9901730a4f176b908516d9f0" category="inline-link-macro">"不可变的Snapshot副本"</block>
  <block id="613542b40dc5d23e9b7129726e6901e9" category="inline-link-macro">"服务操作"</block>
  <block id="06646d879e1be0df7191f42262dc1293" category="paragraph">除了数据保护和备份之外、Cloud Volumes Service 还支持不可变的Snapshot副本(请参见一节) <block ref="46dfee0c3fc63af00a088b428ebe2c09" category="inline-link-macro-rx"></block>)允许从勒索软件攻击中恢复的卷(请参见一节 <block ref="f545e9c9b1aa4e21f947ee53ac36de63" category="inline-link-macro-rx"></block>)在发现问题描述 后数秒内完成、中断最少。恢复时间和影响取决于Snapshot计划、但您可以创建Snapshot副本、在勒索软件攻击中只能提供一小时的增量。Snapshot副本对性能和容量使用的影响微乎其微、是一种低风险、高回报的数据集保护方法。</block>
  <block id="9b6e8c1f1a4d79991136cfd2b3fde77a" category="summary">通过Cloud Volumes Service 、可以将Cloud Volumes Service 实例连接到外部Active Directory服务器、以便为SMB和UNIX用户进行身份管理。要在Cloud Volumes Service 中使用SMB、需要创建Active Directory连接。</block>
  <block id="d099e6eafff98e1042c1029849e2db1b" category="doc">创建Active Directory连接的注意事项</block>
  <block id="b092138563f7b68473c3bf2a6a23a434" category="inline-link">私有 Google 访问</block>
  <block id="dd1f65c08f03e8278da92a88b4c609b5" category="inline-link">在Google Cloud中使用Active Directory的最佳实践</block>
  <block id="758d9a1746e1f53cf6e7882ed864c1a4" category="paragraph">此配置提供了多个选项、需要在一定程度上考虑安全性。外部Active Directory服务器可以是内部实例或云原生。如果您使用的是内部Active Directory服务器、请勿将域公开到外部网络(例如使用DMZ或外部IP地址)。而是使用安全专用通道或VPN、单向林信任或专用网络连接到内部网络<block ref="76bc9bf9d2d87bee997fb1ade7da1eaa" category="inline-link-rx"></block>。有关的详细信息、请参见Google Cloud文档<block ref="28831e2b31059cd3ce2ee26e8b5c8fcf" category="inline-link-rx"></block>。</block>
  <block id="22900d9fe4089ff2f29ada31dfd82836" category="admonition">CVS-SW要求Active Directory服务器位于同一区域。如果尝试在CVS-SW中与另一个区域建立DC连接、则尝试将失败。使用CVS-SW时、请务必创建包含Active Directory DC的Active Directory站点、然后在Cloud Volumes Service 中指定站点、以避免尝试跨区域DC连接。</block>
  <block id="9f69695f33b67147c3fd64e477aa784b" category="section-title">Active Directory凭据</block>
  <block id="2ae640f39e0e652f621ec44b74e57892" category="paragraph">启用SMB或LDAP for NFS后、Cloud Volumes Service 将与Active Directory控制器进行交互、以创建用于身份验证的计算机帐户对象。这与Windows SMB客户端加入域的方式并要求对Active Directory中的组织单位(OU)具有相同的访问权限没有区别。</block>
  <block id="d5b16e2c41dd06274f88cd52182d8034" category="paragraph">在许多情况下、安全组不允许在Cloud Volumes Service 等外部服务器上使用Windows管理员帐户。在某些情况下、作为安全最佳实践、Windows管理员用户将被完全禁用。</block>
  <block id="e33d961644188dff361a3a61603aee23" category="section-title">创建SMB计算机帐户所需的权限</block>
  <block id="7274d74c9decfd509d3c2a9c91098fca" category="inline-link">用于创建和修改计算机帐户对象的委派权限</block>
  <block id="da90c2a52e7d047f641621a25fcd43c7" category="paragraph">要将Cloud Volumes Service 计算机对象添加到Active Directory、此帐户对域具有管理权限或具有管理权限<block ref="39a1d8c5f0c0a4ae053b3e24111592ed" category="inline-link-rx"></block> 指定的OU为必填项。您可以使用Active Directory中的"控制委派向导"执行此操作、方法是创建一个自定义任务、使用户能够使用提供的以下访问权限创建/删除计算机对象：</block>
  <block id="db3317ceb65be02e43db6f277e0ad94e" category="list-text">读 / 写</block>
  <block id="9da76760248a4997f94bdd63f1c04f01" category="list-text">创建/删除所有子对象</block>
  <block id="858ac25470b9539b8e2bb4d6958fde5b" category="list-text">读/写所有属性</block>
  <block id="e798906fb7bcd7b0403d97d21044e339" category="list-text">更改/重置密码</block>
  <block id="4eb6bcf48028313e542c0964c09b46b9" category="paragraph">这样会自动将定义的用户的安全ACL添加到Active Directory中的OU中、并最大限度地减少对Active Directory环境的访问。委派用户后、可以在此窗口中将此用户名和密码作为Active Directory凭据提供。</block>
  <block id="66d939bc6b363153976bbd24624850b8" category="admonition">传递到Active Directory域的用户名和密码会在计算机帐户对象查询和创建期间利用Kerberos加密来提高安全性。</block>
  <block id="8575c9ec9ca166098f9d546c3c12e9b1" category="section-title">Active Directory连接详细信息</block>
  <block id="452740f6c26f32def386962441d5cb2c" category="inline-link">Active Directory连接详细信息</block>
  <block id="af31d4ab1f284e1f94d3522fd1fa36fe" category="paragraph">。<block ref="9255123c1378b2d08be170075ba389b5" category="inline-link-rx"></block> 为管理员提供字段、以便为计算机帐户放置提供特定的Active Directory架构信息、例如：</block>
  <block id="353000b4dd170de2ebede38bb7420e40" category="list-text">* Active Directory连接类型*用于指定某个区域中的Active Directory连接是用于Cloud Volumes Service 服务类型的卷还是CVS-Performance服务类型的卷。如果在现有连接上设置不正确、则在使用或编辑时可能无法正常工作。</block>
  <block id="d5cc4c55027c65e3b8d52c15d308935d" category="list-text">*域。* Active Directory域名。</block>
  <block id="c3fab9d188d8e1e4a9e0ba27a52306c6" category="inline-link">注意事项</block>
  <block id="925e235ec5866cd9c094261d9e20eec4" category="list-text">*站点*为了保证安全性和性能、将Active Directory服务器限制为特定站点<block ref="cae534855afa8eaefaa37d26edea88d5" category="inline-link-rx"></block>。如果多个Active Directory服务器跨越多个区域、则必须执行此操作、因为Cloud Volumes Service 目前不支持向Cloud Volumes Service 实例以外的其他区域的Active Directory服务器发出Active Directory身份验证请求。(例如、Active Directory域控制器所在的区域仅支持CVS-Performance、但您希望在CVS-SW实例中使用SMB共享。)</block>
  <block id="bc3a6531a92e21b83c95f7d7044fd498" category="list-text">* DNS服务器。*要在名称查找中使用的DNS服务器。</block>
  <block id="44ea07387884d17ba7d18393d327374b" category="inline-link-macro">Cloud Volumes Service 在Active Directory中的显示方式</block>
  <block id="32b5af659fee51ef98e34710303d53ba" category="list-text">* NetBIOS名称(可选)。*如果需要、则为服务器指定NetBIOS名称。这是使用Active Directory连接创建新计算机帐户时使用的。例如、如果NetBIOS名称设置为cvs-East、则计算机帐户名称将为cvs-East-｛1234｝。请参见一节 <block ref="0bba591d00c255586e052c023629a690" category="inline-link-macro-rx"></block> 有关详细信息 ...</block>
  <block id="00a4c212426e322a34af5aeccdc494f7" category="list-text">*组织单位(OU)。*用于创建计算机帐户的特定OU。如果要将计算机帐户的控制权委派给特定OU的用户、则此功能非常有用。</block>
  <block id="06852342816b885474a42d89311e2113" category="list-text">* AES加密。*您也可以选中或取消选中为AD身份验证启用AES加密复选框。为Active Directory身份验证启用AES加密可在用户和组查找期间为Cloud Volumes Service 到Active Directory的通信提供额外的安全性。启用此选项之前、请与域管理员联系以确认Active Directory域控制器支持AES身份验证。</block>
  <block id="7d51d6a8b37a2763f6c84b7b3a3a7e97" category="admonition">默认情况下、大多数Windows服务器不会禁用较弱的密码(例如DES或RC4-HMAC)、但如果您选择禁用较弱的密码、请确认已将Cloud Volumes Service Active Directory连接配置为启用AES。否则、身份验证将失败。启用AES加密不会禁用较弱的密码、而是会向Cloud Volumes Service SMB计算机帐户添加对AES密码的支持。</block>
  <block id="3da975567fcd6ebd164f43cca13384f2" category="section-title">Kerberos域详细信息</block>
  <block id="9a62ab6b4d79a99749d02cd8af945f25" category="paragraph">此选项不适用于SMB服务器。而是在为Cloud Volumes Service 系统配置NFS Kerberos时使用。填充这些详细信息后、将配置NFS Kerberos域(类似于Linux上的krb5.conf文件)、并在创建Cloud Volumes Service 卷时指定NFS Kerberos时使用此域、因为Active Directory连接充当NFS Kerberos分发中心(KDC)。</block>
  <block id="e53ab7e80d5d436b4a496f0c2bef7cb2" category="admonition">目前不支持将非Windows KDC与Cloud Volumes Service 结合使用。</block>
  <block id="f447ac856e7e72435904956e3b15f433" category="section-title">Region</block>
  <block id="38da42463bdc613d24159bd6e0405ba6" category="paragraph">使用区域可以指定Active Directory连接所在的位置。此区域必须与Cloud Volumes Service 卷所在的区域相同。</block>
  <block id="4dfb982db9679a6eec578ccd86af978a" category="list-text">*使用LDAP的本地NFS用户。*本节还提供了一个允许使用LDAP的本地NFS用户的选项。如果要将UNIX用户组成员资格支持扩展到NFS (扩展组)的16组限制之外、则必须取消选择此选项。但是、使用扩展组需要为UNIX身份配置LDAP服务器。如果您没有LDAP服务器、请取消选择此选项。如果您有LDAP服务器、并且还希望使用本地UNIX用户(例如root)、请选择此选项。</block>
  <block id="5059a39455b0e2649d69d289516cdf1b" category="section-title">备份用户</block>
  <block id="0e051a51493712b34966f346e858a0c3" category="inline-link">启用对该用户访问的审核</block>
  <block id="d3980aa1c5f0625161c9b0fb5a6cace0" category="paragraph">使用此选项可以指定对Cloud Volumes Service 卷具有备份权限的Windows用户。某些应用程序需要使用备份特权(SeBackupPrivilege)来正确备份和还原NAS卷中的数据。此用户对卷中的数据具有较高的访问权限、因此您应考虑这一点<block ref="b5fba80299f6d29935863b6604a98277" category="inline-link-rx"></block>。启用后、审核事件将显示在事件查看器&gt; Windows日志&gt;安全性中。</block>
  <block id="70136e0b9257bc91e1eb5216b32580de" category="paragraph"><block ref="70136e0b9257bc91e1eb5216b32580de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6833e65d65b96c0d79b7fc114c9a2968" category="section-title">安全权限用户</block>
  <block id="63a19a4d390181634079ba6ba20fe287" category="inline-link">例如SQL Server</block>
  <block id="c9a97779c6062109c66675cc5368a6b8" category="inline-link">审核用户的访问权限</block>
  <block id="296bdd6f36456d0f48d21431f3bd7853" category="paragraph">使用此选项可以指定对Cloud Volumes Service 卷具有安全修改权限的Windows用户。某些应用程序需要安全特权(SeSecurityPrivilege) <block ref="cef5278acd430b226f8e7bcad71f9075" category="inline-link-rx"></block>)以在安装期间正确设置权限。管理安全日志需要此权限。虽然此特权的功能不如SeBackupPrivilege强大、但NetApp建议这样做<block ref="2238ada9972b35c5f01addc7598ffd7a" category="inline-link-rx"></block> 如果需要、则使用此权限级别。</block>
  <block id="f044d72e46ac4189129dc6e27333c449" category="inline-link">分配给新登录的特殊权限</block>
  <block id="1384ec27890f8bac59aae8edf1ff83e9" category="paragraph">有关详细信息，请参见<block ref="791e82319c9cb432525cbf92f3a07623" category="inline-link-rx"></block>。</block>
  <block id="3fc6256a9aed6803167ff54873f78a00" category="paragraph">Cloud Volumes Service 在Active Directory中显示为普通计算机帐户对象。命名约定如下。</block>
  <block id="864917f152404280b59cd43c564f6733" category="list-text">CIFS/SMB和NFS Kerberos会创建单独的计算机帐户对象。</block>
  <block id="79adcd3b0eb62b997e160c91e737deb2" category="list-text">启用了LDAP的NFS会在Active Directory中为Kerberos LDAP绑定创建一个计算机帐户。</block>
  <block id="2ed35f8c3fa643ff6b7226a2163085c5" category="list-text">使用LDAP的双协议卷共享LDAP和SMB的CIFS/SMB计算机帐户。</block>
  <block id="3028cc04aacef3f671388051ac5a05cf" category="list-text">CIFS/SMB计算机帐户的命名约定为name-1234 (随机四位ID、并在&lt; 10个字符名称后附加连字符)。您可以通过Active Directory连接上的NetBIOS名称设置来定义名称(请参见一节<block ref="7d2ad38c1c26cdc0446a7f473a720f92" category="inline-xref-macro-rx"></block>")。</block>
  <block id="b3330aabe270fd3b52fec421dc299283" category="list-text">NFS Kerberos使用nfs-name-1234作为命名约定(最多15个字符)。如果使用的字符数超过15个、则名称为nfs-truncated-name-1234。</block>
  <block id="50b0fcc303b033d01b24dbb96023de81" category="list-text">启用了LDAP的仅NFS CVS-Performance实例创建一个SMB计算机帐户、以便使用与CIFS/SMB实例相同的命名约定绑定到LDAP服务器。</block>
  <block id="d4895b82fd7385bed173b438d89c807e" category="inline-link-macro">"默认隐藏共享"</block>
  <block id="6d7a9f810c1df414bda9e341201f414b" category="list-text">创建SMB计算机帐户时、默认隐藏的管理共享(请参见一节 <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>)也会创建(c$、admin$、ipc$)、但这些共享没有分配ACL、因此无法访问。</block>
  <block id="e1547130d9a70017a557e263270469eb" category="list-text">默认情况下、计算机帐户对象放置在CN=Computers中、但您可以在必要时指定其他OU。请参见第节"<block ref="99b866e46eaefba106810f4a564a9de4" category="inline-xref-macro-rx"></block>有关为Cloud Volumes Service 添加/删除计算机帐户对象所需的访问权限的信息。</block>
  <block id="5a1324cda45cd652ecb95755709fd8e1" category="paragraph">当Cloud Volumes Service 将SMB计算机帐户添加到Active Directory时、将填充以下字段：</block>
  <block id="650ca2f93573bbd3b4e7f2e4fc5d536e" category="list-text">cn (使用指定的SMB服务器名称)</block>
  <block id="493629591f73624fd57b9ff00cb6d94e" category="list-text">dnsHostName (使用SMBserver.domain.com)</block>
  <block id="ed877e9b9c0c0bb19ecf1f342cdda00f" category="list-text">MSDS-SupportedEncryptionTypes (如果未启用AES加密、则允许使用DES_CBC_MD5、RC4_HMAC_MD5；如果启用了AES加密、则允许使用计算机Kerberos帐户使用DES_CBC_MD5、RC4_HMAC_MD5、AES128_CTS_HMAC_SHA1_96、AES256_CTS_HMAC_SHA1_96)</block>
  <block id="987e945fa65d0a9e76f890e3892961cc" category="list-text">名称(使用SMB服务器名称)</block>
  <block id="6c4b390273352496044f436350e3e996" category="list-text">sAMAccountName (使用SMBserver$)</block>
  <block id="603c37960edbea70b7dd05f369016869" category="list-text">servicePrincipalName (具有用于Kerberos的host/smbserver.domain.com和host/smbserver SPN)</block>
  <block id="e4d5beb18aee5989e4944d5f91b181e4" category="paragraph">如果要在计算机帐户上禁用较弱的Kerberos加密类型(enctype)、则可以将计算机帐户上的MSDS-SupportedEncryptionTypes值更改为下表中的一个值、以便仅允许AES。</block>
  <block id="d7b35b0eb85a800cd27ae4d86378e957" category="cell">MSDS-SupportedEncryptionTypes值</block>
  <block id="b20e97401d06f2734903c9c8ce3bd34e" category="cell">已启用EncType</block>
  <block id="3afb17e90ee63072dfd4ad5496e22ecf" category="cell">DES_CBC_MD5</block>
  <block id="427e6bbc6e437e1008a5c41adc923d0e" category="cell">RC4 HMAC</block>
  <block id="16105c1a0d76dfdb5c1df287b56762db" category="cell">仅限AES128_CTS_HMAC_SHA1_96</block>
  <block id="bdacd7093a31449b44a8d708a5a055de" category="cell">仅限AES256_CTS_HMAC_SHA1_96</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="ea8f561ef42d9f42f97782208f239797" category="cell">AES128_CTS_HMAC_SHA1_96和AES256_CTS_HMAC_SHA1_96</block>
  <block id="34173cb38f07f89ddbebc2ac9128303f" category="cell">30 个</block>
  <block id="bbfe7622403fb2a786b158ba768ac4ca" category="cell">DES_CBC_MD5、RC4_HMAC、AES128_CTS_HMAC_SHA1_96和AES256_CTS_HMAC_SHA1_96</block>
  <block id="adfa4c5560980c9b2841dda24bda5935" category="paragraph">要为SMB计算机帐户启用AES加密、请在创建Active Directory连接时单击为AD身份验证启用AES加密。</block>
  <block id="fd0625de17999274e1465433cabc43a7" category="inline-link">请参见Cloud Volumes Service 文档</block>
  <block id="9e167fdd1e36cc753653d71cef598f95" category="paragraph">为NFS Kerberos启用AES加密、<block ref="a1ea73992eb480d81ba9d6fd0002e272" category="inline-link-rx"></block>。</block>
  <block id="5e64a4b25a4f107aefb7d4e2a56b9dfb" category="summary">在对NAS共享使用Cloud Volumes Service 时、可能需要外部依赖关系才能正常运行。这些依赖关系在特定情况下起作用。</block>
  <block id="f4b5e0cbc9d84ca994a4dc85d6f45205" category="doc">其他NAS基础架构服务依赖关系(KDC、LDAP和DNS)</block>
  <block id="c4c97073fa9e6d604787db13592331a3" category="paragraph">在对NAS共享使用Cloud Volumes Service 时、可能需要外部依赖关系才能正常运行。这些依赖关系在特定情况下起作用。下表显示了各种配置选项以及需要哪些依赖关系(如果有)。</block>
  <block id="c9b3a27f085427ada9b946daa430f1f8" category="cell">需要依赖关系</block>
  <block id="954898296a4e7ec7e15ab65964b50da0" category="cell">仅限NFSv3</block>
  <block id="e69d896f8231ad7dd96dd4937ba18d07" category="cell">仅限NFSv3 Kerberos</block>
  <block id="6040c1d5c15727690384a7cd3e8d3fa4" category="cell">Windows Active Directory：* KDC * DNS * LDAP</block>
  <block id="b88d0e1e32f67294d9d45e05a25495e7" category="cell">仅限NFSv4.1</block>
  <block id="1cc44815edb1648976dd6fa410f26802" category="cell">客户端ID映射配置(/etc/idmap.conf)</block>
  <block id="c2e2e93edfc9ea6acddd551b71be27bf" category="cell">仅限NFSv4.1 Kerberos</block>
  <block id="411c501ecf4d59f4ef8d7e9c444b838a" category="list-text">Windows Active Directory：KDC DNS LDAP</block>
  <block id="59b6dd4c5b36405b29c64750f1e82401" category="cell">仅SMB</block>
  <block id="11a431c64d07fefe0bbb5880e03069c5" category="cell">Active Directory：* KDC * DNS</block>
  <block id="420da7f0cb45485c925482687369c1ad" category="cell">多协议NAS (NFS和SMB)</block>
  <block id="b756e6f6a894749273e32e03e551180c" category="list-text">客户端ID映射配置(仅限NFSv4.1；/etc/idmap.conf)</block>
  <block id="8777a112bd8b1e9205dda0717a12965b" category="section-title">计算机帐户对象的Kerberos keytab轮换/密码重置</block>
  <block id="b8333cf0e11040ea157a74560b3a6d77" category="paragraph">对于SMB计算机帐户、Cloud Volumes Service 会为SMB计算机帐户计划定期密码重置。这些密码重置会使用Kerberos加密进行、并按每第四个星期日的计划在晚上11点到凌晨1点之间随机运行。这些密码重置会更改Kerberos密钥版本、轮换存储在Cloud Volumes Service 系统上的密钥选项卡、并帮助保持在Cloud Volumes Service 中运行的SMB服务器的更高级别安全性。计算机帐户密码是随机设置的、管理员不知道这些密码。</block>
  <block id="6df7123d2b1a64b11c7df1c2b837f752" category="paragraph">对于NFS Kerberos计算机帐户、只有在与KDC创建/交换新的keytab时、才会发生密码重置。目前、在Cloud Volumes Service 中无法执行此操作。</block>
  <block id="7631991924ea0015e269781ad88bd8d3" category="section-title">用于LDAP和Kerberos的网络端口</block>
  <block id="52d1b9583b81da6bee6ba24d74c4018b" category="inline-link">有关安全注意事项的Cloud Volumes Service 文档</block>
  <block id="2363dee608bcd9f6ce7f980bfdad5789" category="section-title">LDAP</block>
  <block id="d0a2de9b178b436803f7732ff69d0c14" category="paragraph">Cloud Volumes Service 充当LDAP客户端、并使用标准LDAP搜索查询来查找用户和组的UNIX身份。如果要使用Cloud Volumes Service 提供的标准默认用户之外的用户和组、则需要使用LDAP。如果您计划将NFS Kerberos与用户主体(如user1@domain.com)结合使用、也需要LDAP。目前、仅支持使用Microsoft Active Directory的LDAP。</block>
  <block id="2eaa173e56517db74fb0eb92806a0877" category="inline-link">RFC-2307-bis</block>
  <block id="50af1bf8bee07c6cb1c61e9c19599403" category="paragraph">要使用Active Directory作为UNIX LDAP服务器、您必须在要用于UNIX身份的用户和组上填充必要的UNIX属性。Cloud Volumes Service 使用默认LDAP模式模板、根据查询属性<block ref="54011f528a38d24d58a7f02f98da0d00" category="inline-link-rx"></block>。因此、下表显示了为用户和组填充所需的最小Active Directory属性以及每个属性的用途。</block>
  <block id="a6e75b8341b03d08fb1d6817635b1d47" category="inline-link">管理双协议访问。</block>
  <block id="c0f3d72f07b570cdf3f5d1376c72a389" category="paragraph">有关在Active Directory中设置LDAP属性的详细信息、请参见<block ref="c2741a8ac44d0c827e11ee9004dcd081" category="inline-link-rx"></block></block>
  <block id="f2bbdf9f72c085adc4d0404e370f0f4c" category="cell">属性</block>
  <block id="b12c51b935d86f01d092fb23a1fa4f9f" category="cell">功能</block>
  <block id="e266bea072e01571abba7fc5075c2c86" category="cell">UID*</block>
  <block id="0689aaddc7bfae9cad3778f6d706bd7a" category="cell">指定UNIX用户名</block>
  <block id="525f84e25602ba8efb61d7b8ca793b7c" category="cell">uidNumber*</block>
  <block id="604edb3bb733537b2d6c63b0b84fa1ec" category="cell">指定UNIX用户的数字ID</block>
  <block id="825c2f924ee564de1d57d2b63edd800d" category="cell">gidNumber*</block>
  <block id="eb91949970817d632278971bdf06baef" category="cell">指定UNIX用户的主组数字ID</block>
  <block id="18b5aa92067bde95c39c3039f02bf70e" category="cell">objectclass*</block>
  <block id="ce41297dde1628c606d60ef2bbe154cd" category="cell">指定正在使用的对象类型；Cloud Volumes Service 要求在对象类列表中包含"用户"(默认情况下、大多数Active Directory部署都包含此用户)。</block>
  <block id="db108aa570113ecd6745a2e272d68544" category="cell">有关帐户的常规信息(真实姓名、电话号码等、也称为gecos)</block>
  <block id="17a12df2f12fa6f25328eb6c9fcffedf" category="cell">unixUserPassword</block>
  <block id="4306442303f7519026403fc1912e8e2e" category="cell">无需设置此参数；不会在用于NAS身份验证的UNIX身份查找中使用。如果设置此选项、则会将配置的unixUserPassword值设置为纯文本。</block>
  <block id="d146b96a250f5bcf84b56d2a0f8a2f87" category="cell">unixHomeDirectory</block>
  <block id="1208d15552f3ca8721989c162201e0de" category="cell">定义用户从Linux客户端根据LDAP进行身份验证时UNIX主目录的路径。如果要使用LDAP for UNIX主目录功能、请设置此选项。</block>
  <block id="0693ba16c955b74875d26f79148b66f0" category="cell">loginShell</block>
  <block id="61940c4af8b62a3bb77f4ab0eb491c08" category="cell">定义用户根据LDAP进行身份验证时Linux客户端的bash/配置文件Shell的路径。</block>
  <block id="9ed4554644da662e0634bf83a7e18666" category="paragraph">*表示要在Cloud Volumes Service 中正常运行、必须具有属性。其余属性仅供客户端使用。</block>
  <block id="ac975e575ff07bee5423d326c261e07e" category="cell">CN*</block>
  <block id="b982e168cd50ef73d1f3ce851cb4ddac" category="cell">指定UNIX组名称。使用Active Directory进行LDAP时、会在首次创建对象时设置此值、但可以稍后更改。此名称不能与其他对象相同。例如、如果名为user1的UNIX用户属于Linux客户端上名为user1的组、则Windows不允许两个具有相同CN属性的对象。要解决此问题、请将Windows用户重命名为唯一名称(例如user1-unix)；Cloud Volumes Service 中的LDAP将使用UID属性作为UNIX用户名。</block>
  <block id="dc1d913bf6d70def379cf9f0d70abace" category="cell">指定UNIX组数字ID。</block>
  <block id="1afbf0b9465b3d5c13329cd43dda4e9e" category="cell">指定正在使用的对象类型；Cloud Volumes Service 要求组包含在对象类列表中(默认情况下、此属性包含在大多数Active Directory部署中)。</block>
  <block id="5e4db984d78b91a65e9096eebf726d40" category="cell">memberUID</block>
  <block id="6cd5795a9ccf8fa0d1da852e88da95cd" category="cell">指定哪些UNIX用户是UNIX组的成员。对于Cloud Volumes Service 中的Active Directory LDAP、不需要此字段。Cloud Volumes Service LDAP模式使用成员字段作为组成员资格。</block>
  <block id="cadd4e3eefdff4ed3ad7de830179c314" category="cell">成员*</block>
  <block id="defbfcaae1980c16f810c5ddaa1ecb87" category="cell">组成员资格/二级UNIX组必需。此字段通过向Windows组添加Windows用户来填充。但是、如果Windows组未填充UNIX属性、则这些属性不会包含在UNIX用户的组成员资格列表中。任何需要在NFS中可用的组都必须填充此表中列出的所需UNIX组属性。</block>
  <block id="14476f6ea303cd9ac37328cb484a1fa1" category="section-title">LDAP绑定信息</block>
  <block id="af0c1d97230a1daa0f7341dc35f53a29" category="paragraph">要在LDAP中查询用户、Cloud Volumes Service 必须绑定(登录)到LDAP服务。此登录具有只读权限、用于查询LDAP UNIX属性以查找目录。目前、LDAP绑定只能使用SMB计算机帐户。</block>
  <block id="4a9b831487cab83d7de4d5a515e0eadd" category="paragraph">您只能为`CVS-Performance`实例启用LDAP、并将其用于NFSv3、NFSv4.1或双协议卷。要成功部署已启用LDAP的卷、必须在与Cloud Volumes Service 卷相同的区域建立Active Directory连接。</block>
  <block id="c41605f9de6fa81e35ab98dd9e8b1b02" category="paragraph">启用LDAP后、在特定情况下会发生以下情况。</block>
  <block id="f9f5dcaa4945ab96d402d905be4ed78c" category="list-text">如果Cloud Volumes Service 项目仅使用NFSv3或NFSv4.1、则会在Active Directory域控制器中创建一个新的计算机帐户、并且Cloud Volumes Service 中的LDAP客户端会使用计算机帐户凭据绑定到Active Directory。不会为NFS卷和默认隐藏管理共享创建SMB共享(请参见一节 <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>)已删除共享ACL。</block>
  <block id="f3dad67ce399cefb4b495c573d3ddcb8" category="list-text">如果Cloud Volumes Service 项目使用双协议卷、则只会使用为SMB访问创建的单个计算机帐户将Cloud Volumes Service 中的LDAP客户端绑定到Active Directory。不会创建其他计算机帐户。</block>
  <block id="7168c010de7dd97d077c0e69f48cfbb5" category="list-text">如果专用SMB卷是单独创建的(在启用具有LDAP的NFS卷之前或之后)、则用于LDAP绑定的计算机帐户将与SMB计算机帐户共享。</block>
  <block id="248e702975c1b53305536e1e9c698e19" category="list-text">如果还启用了NFS Kerberos、则会创建两个计算机帐户—一个用于SMB共享和/或LDAP绑定、一个用于NFS Kerberos身份验证。</block>
  <block id="738deb1a3cec2cc7d670e7de69d3a7c6" category="section-title">LDAP查询</block>
  <block id="a204dba492103f34b09fe60e7ab98921" category="paragraph">尽管LDAP绑定已加密、但LDAP查询仍会使用通用LDAP端口389以纯文本形式通过网线进行传递。目前无法在Cloud Volumes Service 中更改此众所周知的端口。因此、有权在网络中嗅探数据包的用户可以查看用户和组名称、数字ID以及组成员资格。</block>
  <block id="d10f3c8108e06d8e622b7a6fb88adb08" category="inline-link-macro">《数据包嗅探/跟踪注意事项》。</block>
  <block id="b046f19aab64225d509f228ccd32fb2c" category="paragraph">但是、Google Cloud VM无法嗅探其他VM的单播流量。只有主动参与LDAP流量(即能够绑定)的VM才能看到LDAP服务器的流量。有关在Cloud Volumes Service 中嗅探数据包的详细信息、请参见一节 <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="d815e456141423f092087c21cd312f23" category="section-title">LDAP客户端配置默认值</block>
  <block id="1c1b57ee3fb14f95067e88e579a44eec" category="paragraph">在Cloud Volumes Service 实例中启用LDAP后、默认情况下会创建一个LDAP客户端配置、其中包含特定的配置详细信息。在某些情况下、选项不适用于Cloud Volumes Service (不受支持)或不可配置。</block>
  <block id="cc2eacdb2cc579f99a0f4359e61ed258" category="cell">LDAP客户端选项</block>
  <block id="31ce3cdcd67850870b616f75b555bbc5" category="cell">默认值</block>
  <block id="216a8093d27a97d2912ed6822d19d410" category="cell">是否可以更改？</block>
  <block id="ffe990396bf99448f8fe6e6fa1c3c3ea" category="cell">LDAP服务器列表</block>
  <block id="0b22102603051537f2c4bfccc964b74e" category="cell">设置要用于查询的LDAP服务器名称或IP地址。这不适用于Cloud Volumes Service。而是使用Active Directory域定义LDAP服务器。</block>
  <block id="9ba66a9f92056682b7d86a38b4bc18c0" category="cell">未设置</block>
  <block id="f490d3302e7cd81f3dafead6c8311b60" category="cell">Active Directory域</block>
  <block id="63dfe9dc44b2881b25560d6d5bd5dff6" category="cell">设置用于LDAP查询的Active Directory域。Cloud Volumes Service 利用DNS中LDAP的SRV记录在域中查找LDAP服务器。</block>
  <block id="6575821e7d2ff9eec297128f6e66933a" category="cell">设置为在Active Directory连接中指定的Active Directory域。</block>
  <block id="00227bc990a551282373139d6439feb4" category="cell">首选Active Directory服务器</block>
  <block id="01d685ed68515214956910d3e26f1c71" category="cell">设置用于LDAP的首选Active Directory服务器。Cloud Volumes Service 不支持。而是使用Active Directory站点控制LDAP服务器选择。</block>
  <block id="f41520c4ef898fb19bb93ee749be3fdd" category="cell">未设置。</block>
  <block id="b626ddcd91311f0f7c4622fdcb7ba05e" category="cell">使用SMB服务器凭据绑定</block>
  <block id="cb97b8ae4a5bb23e8ffa9e1547fe5078" category="cell">使用SMB计算机帐户绑定到LDAP。目前、Cloud Volumes Service 中唯一支持的LDAP绑定方法。</block>
  <block id="f827cf462f62848df37c5e1e94a4da74" category="cell">true</block>
  <block id="d95e3278cf3c7f4cd1d7e40c5a89e7a7" category="cell">模式模板</block>
  <block id="33387315b367e8397cc901a4bf37ad44" category="cell">用于LDAP查询的模式模板。</block>
  <block id="16165a1c7229a30ce1a980b0e648d65f" category="cell">MS-AD-BIS</block>
  <block id="b825dd7cf8df99909db6f3117c567721" category="cell">LDAP服务器端口</block>
  <block id="731fba188f3670e36bac64d2ca64db37" category="cell">用于LDAP查询的端口号。Cloud Volumes Service 当前仅使用标准LDAP端口389。目前不支持LDAPS/端口636。</block>
  <block id="c86a7ee3d8ef0b551ed58e354a836f2b" category="cell">389.</block>
  <block id="9a76dbbba394b04594907973bb6c192e" category="cell">是否已启用LDAPS</block>
  <block id="98c3437e89f8128c7359f6b999731fcc" category="cell">控制是否对查询和绑定使用基于安全套接字层的LDAP (SSL)。Cloud Volumes Service 目前不支持。</block>
  <block id="3452a15eecd4e9b3215025c747cfce4e" category="cell">查询超时(秒)</block>
  <block id="4fbc7a2f8fb9f56de093d04afac67fa3" category="cell">查询超时。如果查询所用时间超过指定值、则查询将失败。</block>
  <block id="4211f908e9b523117776324e2349a87c" category="cell">最低绑定身份验证级别</block>
  <block id="cf6cfd37577ec3f1cc20caa7fb10bd45" category="cell">支持的最低绑定级别。由于Cloud Volumes Service 使用计算机帐户进行LDAP绑定、并且默认情况下Active Directory不支持匿名绑定、因此出于安全考虑、此选项不起作用。</block>
  <block id="7079c72c21415131774625ba1d64f4b0" category="cell">匿名</block>
  <block id="58384d924f3205aaac5f4a09d3b33801" category="cell">绑定 DN</block>
  <block id="4d73cec492ef07eaddad38a4a553639d" category="cell">使用简单绑定时用于绑定的用户/可分辨名称(DN)。Cloud Volumes Service 使用计算机帐户进行LDAP绑定、目前不支持简单绑定身份验证。</block>
  <block id="6c22befafec962f5002017b68e639f92" category="cell">基础DN</block>
  <block id="413689794b4599826344869870d6e0a7" category="cell">用于LDAP搜索的基础DN。</block>
  <block id="796658213567ec39e68bd43e48ac6eff" category="cell">用于Active Directory连接的Windows域、采用DN格式(即DC=domain、DC=local)。</block>
  <block id="30e8b85f236e0c0e7b13a8a98bd46d6f" category="cell">基本搜索范围</block>
  <block id="26cbec2c997dd79e69cd5279817c5506" category="cell">基础DN搜索的搜索范围。值可以包括base、onelevel或subtree。Cloud Volumes Service 仅支持子树搜索。</block>
  <block id="187c471e7dfcb7890077311c532fffd0" category="cell">子树</block>
  <block id="de20d00fd9f0840e6c05dce6aca169e4" category="cell">用户DN</block>
  <block id="4ddd431d35193d0d6dc9555aeecf86e1" category="cell">定义LDAP查询的用户搜索开始位置的DN。目前Cloud Volumes Service 不支持、因此所有用户搜索均从基础DN开始。</block>
  <block id="389048eda41eb7c0e810c83269814943" category="cell">用户搜索范围</block>
  <block id="0c5e0f35296916ccacc860481c53c663" category="cell">用户DN搜索的搜索范围。值可以包括base、onelevel或subtree。Cloud Volumes Service 不支持设置用户搜索范围。</block>
  <block id="68a7f97c57468e034a3f8016831c3c54" category="cell">组DN</block>
  <block id="5874ce023df38d8485da62d095f714f5" category="cell">定义为LDAP查询开始组搜索的DN。目前Cloud Volumes Service 不支持、因此所有组搜索均从基础DN开始。</block>
  <block id="c76b264e7f1c2aadf6b61ca4a7b9dc52" category="cell">组搜索范围</block>
  <block id="2d21b088cabd39a7f25a62fc99148f20" category="cell">组DN搜索的搜索范围。值可以包括base、onelevel或subtree。Cloud Volumes Service 不支持设置组搜索范围。</block>
  <block id="9819b4f0996b3e603488836501e3318e" category="cell">网络组DN</block>
  <block id="b5e1f3448b6d3c978f83c2d3d12a2d1e" category="cell">定义为LDAP查询启动网络组搜索的DN。目前Cloud Volumes Service 不支持、因此所有网络组搜索均从基础DN开始。</block>
  <block id="de25b155c30a2cba210598b604a5b8c8" category="cell">网络组搜索范围</block>
  <block id="334dde86dbe71e59b3c942c6a2384d70" category="cell">网络组DN搜索的搜索范围。值可以包括base、onelevel或subtree。Cloud Volumes Service 不支持设置网络组搜索范围。</block>
  <block id="e2bdddbf27283c0eca38d39759107a44" category="cell">使用基于LDAP的start_tls</block>
  <block id="24788f1c660aa47d895fa832d61d2fcf" category="cell">利用Start TLS通过端口389建立基于证书的LDAP连接。Cloud Volumes Service 目前不支持。</block>
  <block id="cb64fc71803a6196ec2185116e525243" category="cell">启用netgroup-by-host查找</block>
  <block id="d92aed09a16438d9bc4cf2735e54815f" category="cell">启用按主机名查找网络组、而不是扩展网络组以列出所有成员。Cloud Volumes Service 目前不支持。</block>
  <block id="ae1e3e9f0f050830d9ad4ff1441a4080" category="cell">按主机的网络组DN</block>
  <block id="6dc9eeb7bc11f937a1c509e27237db6f" category="cell">定义在LDAP查询中按主机搜索网络组的起始DN。Cloud Volumes Service 当前不支持按主机进行网络组。</block>
  <block id="0b5200ff3b38841dd95a404d7e6ff385" category="cell">netgroup-by-host搜索范围</block>
  <block id="4ce621e884478e7fc52e17ed91eed525" category="cell">netgroup-by-host DN搜索的搜索范围。值可以包括base、onelevel或subtree。Cloud Volumes Service 当前不支持按主机进行网络组。</block>
  <block id="19a0fc26f19842a9f7bc78040d0c381c" category="cell">客户端会话安全性</block>
  <block id="16ed23b379774b2be1797f8efa0fe9a5" category="cell">LDAP转介跟踪</block>
  <block id="a408a02f7b8e36f4913d8dc2debb2b95" category="cell">使用多个LDAP服务器时、如果在第一个服务器中找不到条目、则转介跟踪功能允许客户端引用列表中的其他LDAP服务器。Cloud Volumes Service 目前不支持此功能。</block>
  <block id="5f362229a019eb903f4b21e28b15a1f5" category="cell">组成员资格筛选器</block>
  <block id="55ad576cc6cd581d8a2f558d69828312" category="cell">提供了一个自定义LDAP搜索筛选器、用于从LDAP服务器查找组成员资格。Cloud Volumes Service 当前不支持。</block>
  <block id="b735835c02ee9b8eba41846beea27bc6" category="section-title">使用LDAP进行非对称名称映射</block>
  <block id="10d248b3ae3729560e0f9f75ff23f70e" category="paragraph">默认情况下、Cloud Volumes Service 会双向映射用户名相同的Windows用户和UNIX用户、而无需特殊配置。只要Cloud Volumes Service 可以找到有效的UNIX用户(使用LDAP)、就会进行1：1名称映射。例如、如果使用了Windows用户`johnsmith`、则如果Cloud Volumes Service 在LDAP中找到名为`johnsmith`的UNIX用户、则该用户的名称映射将成功、则由`johnsmith`创建的所有文件/文件夹将显示正确的用户所有权、 而且、无论使用何种NAS协议、影响`johnsmith`的所有ACL都将得到遵守。这称为对称名称映射。</block>
  <block id="a4e6c429f8e2b5bc009025d9469cd6bd" category="paragraph">非对称名称映射是指Windows用户和UNIX用户身份不匹配的情况。例如、如果Windows用户`johnsmith`的UNIX身份为`jsmith`、则Cloud Volumes Service 需要了解此变体。由于Cloud Volumes Service 当前不支持创建静态名称映射规则、因此必须使用LDAP查找用户的身份以获取Windows和UNIX身份、以确保文件和文件夹的所有权以及所需权限正确无误。</block>
  <block id="159e0e9db457fce00641b7a639cdfef9" category="paragraph">默认情况下、Cloud Volumes Service 在名称映射数据库的实例的ns-switch中包含`ldap`、因此、要通过对非对称名称使用LDAP来提供名称映射功能、您只需修改某些用户/组属性以反映Cloud Volumes Service 的查找内容即可。</block>
  <block id="5083578eb1523417a04b030704e11a97" category="paragraph">下表显示了为实现非对称名称映射功能、必须在LDAP中填充哪些属性。在大多数情况下、Active Directory已配置为执行此操作。</block>
  <block id="2e4b53007a09bf23d9111917c46d1902" category="cell">Cloud Volumes Service 属性</block>
  <block id="009097a0950f2d6565c2cb446aa081dd" category="cell">Cloud Volumes Service 用于名称映射的值</block>
  <block id="df642bb30c436da15b0b74923cb45806" category="cell">Windows到UNIX对象类</block>
  <block id="75f68f87af42701b9e548f875f39cefe" category="cell">指定要使用的对象类型。(即用户、组、posixAccount等)</block>
  <block id="2b731e8ed189a8b7587c21b21d6620cf" category="cell">必须包括用户(如果需要、可以包含多个其他值。)</block>
  <block id="288eebd1d2cddc03953f475edbcb2d5f" category="cell">Windows到UNIX属性</block>
  <block id="1b356493e583b25fdd7b1e44d6a4df0d" category="cell">用于在创建时定义Windows用户名。Cloud Volumes Service 将此功能用于Windows到UNIX查找。</block>
  <block id="5ce0ca6d681fede8d46460fed64bf8ef" category="cell">此处无需更改；sAMAccountName与Windows登录名相同。</block>
  <block id="e7d22294bdcb7133967c3548ece982e5" category="cell">UID</block>
  <block id="d93b9102027ae26f7bbfa53ff0cd3f28" category="cell">定义UNIX用户名。</block>
  <block id="abd2101078216980cdcf2dc6f87172b9" category="cell">所需的UNIX用户名。</block>
  <block id="78e7065e65f76fc53c1953f598d424de" category="paragraph">Cloud Volumes Service 当前不会在LDAP查找中使用域前缀、因此多域LDAP环境无法在LDAP命名映射查找中正常运行。</block>
  <block id="1a19ad8ba3f26bc83d40bf699210c5b3" category="paragraph">以下示例显示了一个名为`unymmetric`、UNIX名为`unix-user`的用户、以及从SMB和NFS写入文件时的行为。</block>
  <block id="cf613896f3bf97cfe22b19367188faac" category="paragraph">下图显示了LDAP属性在Windows服务器中的外观。</block>
  <block id="bb859b3ee7438471d7bd0441aec37b09" category="paragraph"><block ref="bb859b3ee7438471d7bd0441aec37b09" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74a3bb1b92afc37821849f4d2c6a2e08" category="paragraph">在NFS客户端中、您可以查询UNIX名称、但不能查询Windows名称：</block>
  <block id="9a9b54fd5d17009b1290538bd0bea332" category="paragraph">从NFS写入文件时、如果为`unix-user`、则NFS客户端会生成以下结果：</block>
  <block id="2d78fc711a4a8afa3553c40cb81a7f5a" category="paragraph">在Windows客户端中、您可以看到文件所有者已设置为正确的Windows用户：</block>
  <block id="dd276babf175f2baaf7d31c63630e9ce" category="paragraph">相反、Windows用户`非对称`从SMB客户端创建的文件将显示正确的UNIX所有者、如以下文本所示。</block>
  <block id="840e343f2946d2e3ecafb4d3af6751c5" category="paragraph">SMB：</block>
  <block id="7369fcede1216c5a449bffa4016f597a" category="paragraph">NFS ：</block>
  <block id="1a2ced64ce54d0878867c66c1264ef73" category="section-title">LDAP通道绑定</block>
  <block id="7bc3122060898b084ade9ae81cb840d5" category="inline-link">Microsoft安全建议ADV190023</block>
  <block id="9c2bd50d1c3b17373f80735ce60e0d91" category="paragraph">由于Windows Active Directory域控制器存在一个漏洞、<block ref="9230172696f08489abbbe06ad2878984" category="inline-link-rx"></block> 更改DC允许LDAP绑定的方式。</block>
  <block id="c389bcb5002ce56cb9cf28680eb6ff4c" category="paragraph">对Cloud Volumes Service 的影响与对任何LDAP客户端的影响相同。Cloud Volumes Service 当前不支持通道绑定。由于Cloud Volumes Service 默认通过协商支持LDAP签名、因此LDAP通道绑定不应是问题描述。如果在启用了通道绑定的情况下绑定到LDAP时确实存在问题、请按照ADV190023中的修复步骤操作、以允许从Cloud Volumes Service 进行LDAP绑定。</block>
  <block id="ed5f2bdecbd4bd349d09412d1ff6a6fb" category="section-title">DNS</block>
  <block id="8cc300201cbc74e712f45393efb60e69" category="inline-link">动态DNS</block>
  <block id="80052c998ef6da49a98a2d9004c75c33" category="paragraph">Active Directory和Kerberos都依赖于DNS来进行主机名到IP/IP到主机名解析。DNS要求端口53处于打开状态。Cloud Volumes Service 不会对DNS记录进行任何修改、目前也不支持使用<block ref="2df544fb17221302fef729d1eb6bd715" category="inline-link-rx"></block> 在网络接口上。</block>
  <block id="5f36386498075ef9c05d674112b69981" category="inline-link">保护Windows DNS的安全</block>
  <block id="e3aa134886f9dad39f14489844fe7763" category="paragraph">您可以配置Active Directory DNS以限制哪些服务器可以更新DNS记录。有关详细信息，请参见<block ref="1abda701cc77717e0b1a0b391ec2fed8" category="inline-link-rx"></block>。</block>
  <block id="e8ba0470f4bd2498fbecdead3ab1b183" category="paragraph">请注意、Google项目中的资源默认使用Google Cloud DNS、而Google Cloud DNS未连接到Active Directory DNS。使用云DNS的客户端无法解析Cloud Volumes Service 返回的UNC路径。加入Active Directory域的Windows客户端已配置为使用Active Directory DNS、并且可以解析此类UNC路径。</block>
  <block id="71870bac7a9267067ab69566f75d36c3" category="inline-link">为什么我的客户端无法解析SMB NetBIOS名称？</block>
  <block id="b0ffc266c9e05cd7ae80810305b932bf" category="paragraph">要将客户端加入Active Directory、必须将其DNS配置为使用Active Directory DNS。或者、您也可以配置云DNS以将请求转发到Active Directory DNS。请参见<block ref="d568657413aac86de4b237a9edcddc2d" category="inline-link-rx"></block>有关详细信息 ...</block>
  <block id="a0c7db04deaabb45ee60d5a501e67eb8" category="admonition">Cloud Volumes Service 当前不支持DNSSEC、DNS查询以纯文本形式执行。</block>
  <block id="c3a18bc4fd14cf11bc551540f29f6375" category="section-title">文件访问审核</block>
  <block id="cc6e776769986190d1536969ad7e5307" category="paragraph">目前不支持Cloud Volumes Service。</block>
  <block id="5cffe1f133f0ed3a472da05d0b1d3f0d" category="section-title">防病毒保护</block>
  <block id="2b91875198ddd07e9b4cff7f1fe46663" category="paragraph">您必须在客户端的Cloud Volumes Service 中对NAS共享执行防病毒扫描。目前未将原生 防病毒与Cloud Volumes Service 集成。</block>
  <block id="fd7d290d66c64aa2fc13dd9bbca9c540" category="summary">通过Cloud Volumes Service 、可以向SMB和NFS客户端共享相同的数据集、同时保持适当的访问权限双协议。这是通过协调协议之间的身份映射以及使用中央后端LDAP服务器向Cloud Volumes Service 提供UNIX身份来实现的。您可以使用Windows Active Directory为Windows和UNIX用户提供方便易用的功能。</block>
  <block id="d27d01220b09abd6dc8be87dd2b7f8d4" category="doc">双协议/多协议</block>
  <block id="9a5ba82ef925964774fad34d380585ce" category="inline-link">双协议</block>
  <block id="afbf550dbb927e70d6e5e81aba4cf54e" category="paragraph">通过Cloud Volumes Service 、可以向SMB和NFS客户端共享相同的数据集、同时保持适当的访问权限 <block ref="090248040bf8d7cbf59e0f5bcb2aeb23" category="inline-link-rx"></block>）。这是通过协调协议之间的身份映射以及使用中央后端LDAP服务器向Cloud Volumes Service 提供UNIX身份来实现的。您可以使用Windows Active Directory为Windows和UNIX用户提供方便易用的功能。</block>
  <block id="65bd83537129be15c8027ec94bec5bd3" category="section-title">访问控制</block>
  <block id="b481dc764d87d694bd99e41051212b98" category="inline-link-macro">"具有本地/BUILTIN管理员/备份权限的帐户。"</block>
  <block id="4349221797619aa2539cd1d814d55cf3" category="inline-link">MMC/计算机管理</block>
  <block id="ab67de3b2d37b16da324871c9cd7f96b" category="list-text">*共享访问控制。*确定哪些客户端和/或用户和组可以访问NAS共享。对于NFS、导出策略和规则控制客户端对导出的访问。NFS导出可通过Cloud Volumes Service 实例进行管理。SMB使用CIFS/SMB共享和共享ACL、在用户和组级别提供更精细的控制。您只能使用从SMB客户端配置共享级ACL<block ref="dbc4cec831b164bbb509e51caacd0209" category="inline-link-rx"></block> 具有Cloud Volumes Service 实例管理员权限的帐户(请参见一节 <block ref="c9946e41ec7364b03516e2beacd1b339" category="inline-link-macro-rx"></block>）。</block>
  <block id="1020ac8238c0e64a401514745b8a3c6a" category="list-text">*文件访问控制。*在文件或文件夹级别控制权限、并且始终从NAS客户端进行管理。NFS客户端可以使用传统模式位(rwx)或NFSv4 ACL。SMB客户端利用NTFS权限。</block>
  <block id="dcfd17a407b936210845de342300e631" category="paragraph">为NFS和SMB提供数据的卷的访问控制取决于所使用的协议。有关双协议权限的信息、请参见"<block ref="7251f6a3aba1b22d43e125a8c39f6f0a" category="inline-xref-macro-rx"></block>。 "</block>
  <block id="20d918db09dacfd5fbfbaadfaede2f80" category="section-title">用户映射</block>
  <block id="c9677302c2548820abda217b496a541b" category="paragraph">当客户端访问卷时、Cloud Volumes Service 会尝试反向将传入用户映射到有效用户。这一点对于跨协议确定正确的访问权限以及确保请求访问的用户确实是他们所宣称的用户是必不可少的。</block>
  <block id="7e9b11fc569fee58c3b42b689df2fbec" category="paragraph">例如、如果名为`joe`的Windows用户尝试通过SMB访问具有UNIX权限的卷、则Cloud Volumes Service 将执行搜索以查找名为`joe`的相应UNIX用户。如果存在一个、则以Windows用户`joe`的身份写入SMB共享的文件在NFS客户端中显示为UNIX用户`joe`。</block>
  <block id="b9e4f77748fb373f23ad2bc9eb2d3de0" category="paragraph">或者、如果名为`Joe`的UNIX用户尝试使用Windows权限访问Cloud Volumes Service 卷、则UNIX用户必须能够映射到有效的Windows用户。否则、将拒绝对卷的访问。</block>
  <block id="98b9b81e4ad07f5198dd8381a0c5d43c" category="inline-link">创建AD连接</block>
  <block id="d6210f83492bb730b32d0e719a1d5100" category="paragraph">目前、只有Active Directory支持使用LDAP进行外部UNIX身份管理。有关配置对此服务的访问权限的详细信息、请参见<block ref="cfe0f81fca904ab10d3dcbbfceb0f3de" category="inline-link-rx"></block>。</block>
  <block id="7fc7c5bf3cd7f453807f2e17dc846957" category="section-title">权限模型</block>
  <block id="94b74cdf7c7dc9ef00fc04cf642127d9" category="paragraph">使用双协议设置时、Cloud Volumes Service 会使用卷的安全模式来确定ACL的类型。这些安全模式是根据指定的NAS协议设置的、对于双协议、则是在创建Cloud Volumes Service 卷时选择的。</block>
  <block id="b3544688f5ad40244fc991f13471c525" category="list-text">如果您仅使用NFS、则Cloud Volumes Service 卷将使用UNIX权限。</block>
  <block id="95b899e9e3d21a94ae7e8ce04eac3bb3" category="list-text">如果您仅使用SMB、则Cloud Volumes Service 卷将使用NTFS权限。</block>
  <block id="51c16477dee3c257c4930e8614eda5ba" category="paragraph">如果要创建双协议卷、则可以在创建卷时选择ACL模式。应根据所需的权限管理来做出此决策。如果您的用户从Windows/SMB客户端管理权限、请选择NTFS。如果您的用户希望使用NFS客户端和chmod/chown、请使用UNIX安全模式。</block>
  <block id="451abeb07875465ff669fc3bfc502564" category="summary">安全性、尤其是在基础架构不受存储管理员控制的云环境中、对于将数据信任到云提供商提供的服务产品至关重要。本文档概述了NetApp Cloud Volumes Service 在Google Cloud中提供的安全产品。</block>
  <block id="85f174d487aef272a0a9ea0f980e4827" category="doc">TR-4918：安全概述—Google Cloud中的NetApp Cloud Volumes Service</block>
  <block id="09f7873d6f07efaef82aef2b95f42e0a" category="paragraph">NetApp公司Justin Parisi的Oliver Krause</block>
  <block id="1e06922fd676ae97f9dc69dbbfc93992" category="section-title">文档范围</block>
  <block id="c2f1a37c5b3a149d2e79ad5a41c86139" category="inline-link">Cloud Volumes Service 在Google Cloud中提供</block>
  <block id="c2197b5184a5af948e5dc6e6dcf6e5c3" category="paragraph">安全性、尤其是在基础架构不受存储管理员控制的云环境中、对于将数据信任到云提供商提供的服务产品至关重要。本文档概述了NetApp提供的安全产品<block ref="b29f7971c7793aea2bb4311fa5c38ee0" category="inline-link-rx"></block>。</block>
  <block id="f2b84afd0523a6df7547c404aa3647d8" category="section-title">目标受众</block>
  <block id="75ff467aeacdad8bd3ed9fe31431d022" category="paragraph">本文档的目标受众包括但不限于以下角色：</block>
  <block id="3487d2ed085064f5b68318d25038bcd6" category="list-text">云提供商</block>
  <block id="203ea32883f92321782cc1a312345903" category="list-text">存储管理员</block>
  <block id="7e89bd35a6b8558a95e9e4ec446df00d" category="list-text">存储架构师</block>
  <block id="528efe83de18ec1cf2eb982cc641bb89" category="list-text">现场资源</block>
  <block id="a6205b388d7b872550efc1a57461e045" category="list-text">业务决策者</block>
  <block id="d9a404dc3c51a0dfc2360a6f7f97c00c" category="inline-link-macro">"联系我们。"</block>
  <block id="ec45e675f8dd5d470d6edacfc9ac6a2d" category="paragraph">如果您对本技术报告的内容有任何疑问、请参见一节 <block ref="bbd2d7f57ba5e479a6b271845e2b7ec0" category="inline-link-macro-rx"></block></block>
  <block id="b54d58d7e43c404563f91e38d3efbcac" category="cell">缩写</block>
  <block id="0b890b1926b90387673882e6ccae7fdc" category="cell">定义</block>
  <block id="e898e7a5df4dec909ad011657b510e2d" category="cell">CVS-SW</block>
  <block id="3b558136fa0b6447d030d5fd2d28765b" category="cell">Cloud Volumes Service 、服务类型CVS</block>
  <block id="439d7969e09b4b31626fcf209b8fdcb7" category="cell">CVS 性能</block>
  <block id="3da305112390b1f2d5e6ad8818e00065" category="cell">Cloud Volume Service、服务类型CVS-Performance</block>
  <block id="041159b903daf7d5923837346de98407" category="cell">PSA</block>
  <block id="60298c0c8282022dec640948e48114c1" category="summary">Cloud Volumes Service 团队负责管理Google Cloud中的后端服务、并使用多种策略来保护平台安全并防止不必要的访问。</block>
  <block id="d5558f87207ef258cc599e6b4f31fa1f" category="doc">服务操作</block>
  <block id="01f3694459a5570182960c35de3adea0" category="paragraph">每个客户都获得自己的唯一子网、默认情况下、该子网的访问会与其他客户隔离、而Cloud Volumes Service 中的每个租户都获得自己的命名空间和VLAN以实现整体数据隔离。用户通过身份验证后、服务交付引擎(SDE)只能读取特定于该租户的配置数据。</block>
  <block id="3efd389b601ec82d2d3d7d1fe8c7a952" category="section-title">物理安全性</block>
  <block id="e6cbbd1872a42cfa36ceca16da55e6af" category="paragraph">经过适当的预先批准后、只有现场工程师和具有NetApp徽标的现场支持工程师(Field Support Engineer、FSE)才能访问固定框架和机架进行物理工作。不允许进行存储和网络管理。只有这些现场资源才能执行硬件维护任务。</block>
  <block id="f4cc7ff420af18ead26b06b01e65be30" category="paragraph">对于现场工程师、将为工作说明书(SOW)提交一个服务单、其中包括机架ID和设备位置(RU)、所有其他详细信息均包含在服务单中。对于NetApp现场服务工程师、必须向Colo提交现场访问服务单、此服务单应包含访客的详细信息、日期和时间、以供审核。FSE的SOW会在内部传达给NetApp。</block>
  <block id="e6da80db21921cfa31a2ec8ae71c8a44" category="section-title">运营团队</block>
  <block id="575c886f27b4fd6adbc422b9466a7d77" category="paragraph">Cloud Volumes Service 运营团队由生产工程和云卷服务站点可靠性工程师(SRE)以及NetApp现场支持工程师和硬件合作伙伴组成。所有运营团队成员都获得了在Google Cloud中工作的认证、并为提交的每个服务单维护详细的工作记录。此外、我们还制定了严格的变更控制和批准流程、以确保对每项决策进行适当审查。</block>
  <block id="62b92b1afcd6e99ad8ef6fc6e66fe1c6" category="paragraph">SRE团队负责管理控制平台以及如何将数据从UI请求路由到Cloud Volumes Service 中的后端硬件和软件。SRE团队还负责管理系统资源、例如卷和索引节点最大值。不允许SRES与客户数据进行交互或访问客户数据。此外、SRES还可以与退回材料授权(Return Material Authorizations、RMA)进行协调、例如为后端硬件请求新磁盘或内存更换请求。</block>
  <block id="20ac318b6aafb241498518b27a204f2d" category="section-title">客户责任</block>
  <block id="5b18708f6a9b76d94aad073287e9c4aa" category="paragraph">Cloud Volumes Service 的客户负责管理其组织的Active Directory和用户角色管理以及卷和数据操作。客户可以具有管理角色、并可以使用NetApp和Google Cloud提供的两个预定义角色(管理员和查看器)将权限委派给同一Google Cloud项目中的其他最终用户。</block>
  <block id="70612d623f8ac2ccbad1aa9289e54eb2" category="paragraph">管理员可以将客户项目中的任何VPC与客户确定合适的Cloud Volumes Service 建立对等关系。客户有责任管理对其Google Cloud Marketplace订阅的访问权限、并管理有权访问数据平面的VPC。</block>
  <block id="1e9614b8d81927a9e9bad94fe64884d6" category="section-title">恶意SRE保护</block>
  <block id="1ced9b3b1b2408070d8594c7310def52" category="paragraph">可能会出现的一个问题是、Cloud Volumes Service 如何防止出现恶意SRE或SRE凭据受到损坏的情况？</block>
  <block id="0cf58dc2d9a00ecaeb191e61685b36e5" category="paragraph">只能由有限数量的SRE人员访问生产环境。管理权限进一步限制为少数经验丰富的管理员。我们的安全信息和事件管理(Cloud Volumes Service)威胁情报平台会记录任何人在生产环境中执行的所有操作、并检测到基线异常或可疑活动。因此、在对Cloud Volumes Service 后端造成过多损坏之前、可以跟踪和缓解恶意操作。</block>
  <block id="9893b21aa64e031fdfd6920fef8147a3" category="section-title">卷生命周期</block>
  <block id="1135939baa7babe550972f3d2430315f" category="paragraph">Cloud Volumes Service 仅管理服务中的对象、而不管理卷中的数据。只有访问卷的客户端才能管理数据、ACL、文件所有者等。这些卷中的数据会在空闲时进行加密、并且只能由Cloud Volumes Service 实例的租户访问。</block>
  <block id="dd04bd242a373a0c9b066d0704ba4d66" category="paragraph">Cloud Volumes Service 的卷生命周期为create-update-delete。卷会保留卷的Snapshot副本、直到删除卷为止、只有经过验证的Cloud Volumes Service 管理员才能删除Cloud Volumes Service 中的卷。当管理员请求删除卷时、还需要输入卷名称来验证删除操作。删除卷后、该卷将消失、无法恢复。</block>
  <block id="1744c1e09f5b1b7990b7f2b80a7a9500" category="paragraph">如果Cloud Volumes Service 合同终止、NetApp会在特定时间段后标记要删除的卷。在该时间段到期之前、您可以根据客户的请求恢复卷。</block>
  <block id="13e637fe96062929286b911c16b3c2df" category="section-title">认证</block>
  <block id="af06a002abcc2b02896192d8fd1052cd" category="inline-link">合规性：数据安全和数据隐私</block>
  <block id="258a58248bd2280e3d97717c4150b3cf" category="paragraph">适用于Google Cloud的Cloud Volumes Services目前已通过ISO/IEC 27001：2013和ISO/IEC 27018：2019标准的认证。该服务最近还收到了其SOC2 I类证明报告。有关NetApp对数据安全和隐私的承诺的信息、请参见<block ref="751448d9ace7c1569cfa25749b75ea26" category="inline-link-rx"></block>。</block>
  <block id="4e94c8ad46c8aef1ca637841dfbe2159" category="section-title">GDPR</block>
  <block id="ee69241049506ca93a3a1cd627e44851" category="inline-link">客户合同</block>
  <block id="15655a5f67808f893102ffa3cbde3b01" category="inline-link">客户数据处理附录</block>
  <block id="cd0ae90a69c7d21d42b18252b9e1707d" category="inline-link">标准合同条款</block>
  <block id="de315e46a9bdf4936de71254f87d2fe0" category="paragraph">我们的许多公司都承诺遵守GDPR并遵守隐私规定 <block ref="c2118342007d8714fcb1b4f6106c575c" category="inline-link-rx"></block>、例如我们的<block ref="7f657124cd056ea8e74c57dcafd4df75" category="inline-link-rx"></block>、其中包括 <block ref="85bd1a4ed188bfd53fcaef2fb6e1962a" category="inline-link-rx"></block> 由欧盟委员会提供。我们还会在隐私政策中做出这些承诺、并以我们公司行为准则中规定的核心价值为后盾。</block>
  <block id="81e9930d895d3e301d9d41dffc998bf4" category="summary">信任云解决方案 的一部分是了解架构及其安全保护方式。本节将介绍Google中Cloud Volumes Service 架构的不同方面、以帮助缓解对数据安全保护的潜在担忧、并指出可能需要执行其他配置步骤才能实现最安全的部署。</block>
  <block id="e5a9d7217b1490853e4230120cdedb32" category="paragraph">Cloud Volumes Service 的通用架构可细分为两个主要组件：控制平面和数据平面。</block>
  <block id="650717c72d7a99e6505592f83821e4ed" category="section-title">控制面板</block>
  <block id="b2b6e947ec64376b51417e89ab29e213" category="paragraph">Cloud Volumes Service 中的控制平台是由Cloud Volumes Service 管理员和NetApp原生 自动化软件管理的后端基础架构。此平台对最终用户完全透明、并包括网络、存储硬件、软件更新等、可帮助为Cloud Volumes Service 等驻留在云中的解决方案 提供价值。</block>
  <block id="52a0e67f81bfbe486860a8219dfb3707" category="section-title">数据平面</block>
  <block id="9d4d4fccf74cab21d8073077985a0cf6" category="paragraph">Cloud Volumes Service 中的数据平面包括实际数据卷和整体Cloud Volumes Service 配置(例如访问控制、Kerberos身份验证等)。数据平面完全由Cloud Volumes Service 平台的最终用户和使用者控制。</block>
  <block id="099a80e29da5319c76116b6b2b41b2bf" category="paragraph">每个平面的安全保护和管理方式各不相同。以下各节将从Cloud Volumes Service 架构概述开始介绍这些差异。</block>
  <block id="9114bfd7ba3e781df4e595c0a3199bfb" category="summary">了解如何保护数据安全的第一步是识别风险和潜在的攻击面。</block>
  <block id="d446619c29484b970941bed7884dfd57" category="doc">安全注意事项和攻击面</block>
  <block id="1f48f12466296c53740ed0375b4d0111" category="list-text">管理和登录</block>
  <block id="78b73d10586b526c3f0d3f97bd32dfba" category="list-text">空闲数据</block>
  <block id="42517361027a563c9ab61d813badc939" category="list-text">数据正在传输</block>
  <block id="58be36e591707c2a60f9bed405a8ef25" category="list-text">网络和防火墙</block>
  <block id="3a7d83d110f5fe7d4f435b9594806caf" category="list-text">勒索软件、恶意软件和病毒</block>
  <block id="417a78919920edf51d22038b236740f1" category="paragraph">了解攻击面可以帮助您更好地保护环境。Google Cloud中的Cloud Volumes Service 已经考虑了其中许多主题、并在默认情况下实施了安全功能、而无需任何管理交互。</block>
  <block id="70e43ccaf26985ea09dd44568ea9f36b" category="section-title">确保安全登录</block>
  <block id="67fe2a3de92df4f2c45227cff1adea77" category="paragraph">在保护关键基础架构组件安全时、必须确保只有经过批准的用户才能登录和管理您的环境。如果不良行为者违反您的管理凭据、则他们将拥有存储区的密钥、并可以执行所需的任何操作—更改配置、删除卷和备份、创建后台或禁用Snapshot计划。</block>
  <block id="3a2f2973e275ef04d08d1dda935f1ee0" category="paragraph">Cloud Volumes Service for Google Cloud可通过将存储即服务(StaaS)混淆来防止未经授权的管理登录。Cloud Volumes Service 由云提供商完全维护、无法从外部登录。所有设置和配置操作都是完全自动化的、因此、除了极少数情况之外、人工管理员不必与系统进行交互。</block>
  <block id="22b01eb5fb8c08ffb16c6ef9ef8b71b6" category="inline-link-macro">Cloud Volumes Service 架构。</block>
  <block id="b019d60ff2b9589700c94d2d71d13c8f" category="paragraph">如果需要登录、Google Cloud中的Cloud Volumes Service 会保留一个非常短的可访问登录到系统的可信管理员列表、从而确保登录安全。这种关守有助于减少具有访问权限的潜在不良行为者的数量。此外、Google Cloud网络还会将系统隐藏在网络层安全的基础之上、并仅向外部环境公开所需的内容。有关Google Cloud、Cloud Volumes Service 架构的信息、请参见一节 <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="582157e9744c945cab3000f99e5c51f4" category="section-title">集群管理和升级</block>
  <block id="ac816ab3f2fb9ede37e87c223bf39690" category="paragraph">存在潜在安全风险的两个方面包括集群管理(如果不良者拥有管理员访问权限会发生什么情况)和升级(如果软件映像受到影响会发生什么情况)。</block>
  <block id="e3f83199a3d154c9a938a90ed76188d4" category="section-title">存储管理保护</block>
  <block id="e9406b6097629a60364e6b24a83dd40b" category="inline-link-macro">"服务操作"。</block>
  <block id="a16c40cfa1517a64fe23c8a84e7fca32" category="paragraph">以服务形式提供的存储可通过删除云数据中心以外的最终用户的访问权限、消除管理员面临的额外风险。而是只为客户的数据访问平面进行配置。每个租户都管理自己的卷、任何租户都无法访问其他Cloud Volumes Service 实例。此服务通过自动化进行管理、只需一小部分受信任管理员即可通过本节所述的流程访问系统 <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="bc94b58452719d0cfedd1ceb30c4fd53" category="paragraph">CVS-Performance服务类型提供跨区域复制选项、以便在发生区域故障时为其他区域提供数据保护。在这种情况下、可以将Cloud Volumes Service 故障转移到不受影响的区域以保持数据访问。</block>
  <block id="b8bb5b62315a69e1364d070de73bbfa5" category="section-title">服务升级</block>
  <block id="a5e1144c0e37d7facbd53bdffaa58f52" category="paragraph">更新有助于保护容易受到攻击的系统。每个更新都提供了安全增强功能和错误修复、可最大限度地减少攻击面。软件更新会从中央存储库下载并进行验证、然后才允许更新、以验证是否使用了官方映像、以及升级是否不会受到不良行为者的影响。</block>
  <block id="79f1689ccfaec67bc50dd620185adbac" category="paragraph">借助Cloud Volumes Service 、更新由云提供商团队处理、通过提供精通配置和升级的专家来消除管理员团队面临的风险、这些专家已经对流程进行了自动化和全面测试。升级不会造成中断、Cloud Volumes Service 会维护最新的更新、以获得最佳的整体效果。</block>
  <block id="6a274e2791c8f2a1f59a7a6f87261122" category="paragraph">有关执行这些服务升级的管理员团队的信息、请参见一节 <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="eeae9bcc33a487e1224ffb4815f79821" category="section-title">保护空闲数据的安全</block>
  <block id="11062b94d57add7cf5c44a9ec7e9274c" category="paragraph">空闲数据加密对于在磁盘被盗、退回或重新利用时保护敏感数据非常重要。Cloud Volumes Service 中的数据通过基于软件的加密在空闲时受到保护。</block>
  <block id="ad04a8dc3b058793f75e8c97c787ceea" category="list-text">Google生成的密钥用于CVS-SW。</block>
  <block id="b114edcfa107ab9d459e2e75aea2cfdb" category="inline-link">FIPS 140-2证书#4144</block>
  <block id="855bcb8730de4b24527a09801b103d97" category="list-text">对于CVS-Performance、每个卷的密钥存储在Cloud Volumes Service 内置的密钥管理器中、该管理器使用NetApp ONTAP CryptoMod生成AES-256加密密钥。CryptoMod列在CMVP FIPS 140-2验证模块列表中。请参见<block ref="c8bf3ef21e8efdca1f27a1e57e809607" category="inline-link-rx"></block>。</block>
  <block id="a934c8bfa11942a4baa792ed229b8bb8" category="paragraph">自2021年11月起、CVS-Performance提供了客户管理的预览加密(CMEK)功能。通过此功能、您可以使用Google密钥管理服务(KMS)中托管的每个项目、每个区域的主密钥对每个卷的密钥进行加密。您可以通过Kms连接外部密钥管理器。</block>
  <block id="08a22fe6e00e4ceb40cd56453b4a5864" category="paragraph">有关架构的详细信息、请参见一节 <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="fb787119808b111e9df5553be31361c8" category="section-title">保护传输中的数据安全</block>
  <block id="8255b8a6d9844c87b5ecd1d2287b2f60" category="paragraph">除了保护空闲数据之外、当数据在Cloud Volumes Service 实例与客户端或复制目标之间传输时、您还必须能够保护数据的安全。Cloud Volumes Service 通过使用加密方法(例如使用Kerberos进行SMB加密、对数据包进行签名/密封以及对数据传输进行端到端加密的NFS Kerberos 5p)为通过NAS协议传输的数据提供加密。</block>
  <block id="c42b0018cf60c30c0490998e63dfdac1" category="paragraph">Cloud Volumes Service 卷的复制使用TLS 1.2、它会利用AES-GCM加密方法。</block>
  <block id="17882f1649689ee4f6fcf4aeba6d150b" category="paragraph">默认情况下、大多数不安全的传输中协议(例如telnet、NDMP等)都处于禁用状态。但是、Cloud Volumes Service 不会对DNS进行加密(不支持DNS安全)、应尽可能使用外部网络加密进行加密。请参见一节 <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block> 有关保护传输中数据的详细信息、请参见。</block>
  <block id="4bb00cc1adfaf9a4b73ae2593bc7d4e8" category="inline-link-macro">"NAS协议"。</block>
  <block id="d47f2c6bf1e6a3776038244ab35f5415" category="paragraph">有关NAS协议加密的信息、请参见一节 <block ref="386abb448925212e530f9be720946265" category="inline-link-macro-rx"></block></block>
  <block id="46dc4f8fa1d2951250a02fa29fccc4cb" category="section-title">NAS权限的用户和组</block>
  <block id="4a6786c54b7ea4a860834c0ffda11c7f" category="paragraph">在云中保护数据的一部分工作涉及到正确的用户和组身份验证、其中、访问数据的用户会作为环境中的实际用户进行验证、而组包含有效用户。这些用户和组可为存储系统中的文件和文件夹提供初始共享和导出访问权限以及权限验证。</block>
  <block id="52c7382ae7438c8a3366ad6f38d5d2a4" category="paragraph">Cloud Volumes Service 对SMB共享和Windows模式权限使用基于Active Directory的标准Windows用户和组身份验证。该服务还可以利用UNIX身份提供程序、例如用于UNIX用户的LDAP以及用于NFS导出的组、NFSv4 ID验证、Kerberos身份验证和NFSv4 ACL。</block>
  <block id="59935480b9f5ac6361a1a360ad8a9ec2" category="admonition">目前、Cloud Volumes Service 仅支持Active Directory LDAP功能。</block>
  <block id="7c47e0b7c3aa389a1b437364885d5562" category="section-title">检测、防止和缓解勒索软件、恶意软件和病毒</block>
  <block id="b647cba0e4b0ad0f479019e47713c5a2" category="paragraph">勒索软件、恶意软件和病毒是管理员面临的持久威胁、企业组织始终将检测、预防和缓解这些威胁作为头等大事。关键数据集上的一个勒索软件事件可能会导致数百万美元的损失、因此您可以尽最大可能降低风险。</block>
  <block id="ba1e21a6e8310b88e0349770718e717c" category="inline-link">自动检测勒索软件</block>
  <block id="b80fb0d337605da9f0fdaf2687c3de1e" category="paragraph">尽管Cloud Volumes Service 目前不包括防病毒保护或等原生 检测或预防措施<block ref="2ed126fbf9f5caf3d13a90f230e3475a" category="inline-link-rx"></block>、通过启用定期Snapshot计划、可以快速从勒索软件事件中恢复。Snapshot副本是指向文件系统中已更改块的不可变和只读指针、它们接近瞬时、对性能的影响最小、并且仅在更改或删除数据时才会占用空间。您可以为Snapshot副本设置计划、使其与所需的可接受恢复点目标(RPO)/恢复时间目标(RTO)相匹配、并且每个卷最多可保留1、024个Snapshot副本。</block>
  <block id="e9c1c7d4ca860adb553d87c2c1d9ef35" category="inline-link">适用于勒索软件的NetApp解决方案</block>
  <block id="85ebd62090617323187e9e7827c343e7" category="paragraph">Snapshot支持包括在Cloud Volumes Service 中、无需额外费用(对于Snapshot副本所保留的更改块/数据收取的数据存储费用除外)、如果发生勒索软件攻击、可以在攻击发生之前使用它回滚到Snapshot副本。快照还原只需几秒钟即可完成、然后您可以恢复正常提供数据。有关详细信息，请参见<block ref="e347ba4858ee244fead32d2fe59a64dd" category="inline-link-rx"></block>。</block>
  <block id="7994d1312e8f4fe2cdf2f7e13347d8bf" category="paragraph">要防止勒索软件影响您的业务、需要采用多层方法、其中包括以下一项或多项：</block>
  <block id="7aa2bd35ac13684bd5c9434296dd6b03" category="list-text">端点保护</block>
  <block id="9cdff1d919782c79338864086178c7b0" category="list-text">通过网络防火墙防止外部威胁</block>
  <block id="eb4079f2ecc7735fcfaa169c5562cbfd" category="list-text">检测数据异常</block>
  <block id="aac3c67c846910bdfd381a7101344e96" category="list-text">对关键数据集进行多个备份(现场和异地)</block>
  <block id="3845e8b5ec9d78bcebac29ec50d8077f" category="list-text">定期对备份进行还原测试</block>
  <block id="a550fe6fd1b40af5260e9636cdea66fd" category="list-text">不可变的只读NetApp Snapshot副本</block>
  <block id="533a4f72ffc639d4cc87d034dfe92f2c" category="list-text">关键基础架构的多因素身份验证</block>
  <block id="b1d3b419f981a509b3c5203c7546b96b" category="list-text">系统登录的安全审核</block>
  <block id="4e329c801824e6bdc0209c98146064c3" category="paragraph">此列表远非详尽无遗、但在应对潜在的勒索软件攻击时、是一个理想的蓝图。Google Cloud中的Cloud Volumes Service 提供了多种方法来防止勒索软件事件并减少其影响。</block>
  <block id="2fdb508dbc71674add1fe7fc21ccbf8e" category="section-title">不可变的Snapshot副本</block>
  <block id="1682a7464d9210c8161ec78abc8010e2" category="paragraph">Cloud Volumes Service 本机提供不可变的只读Snapshot副本、这些副本会按照可自定义的计划创建、以便在数据删除或整个卷受到勒索软件攻击时快速进行时间点恢复。根据Snapshot计划和RTO /RO的保留期限、将Snapshot还原到先前的正常Snapshot副本速度非常快、并可最大程度地减少数据丢失。Snapshot技术对性能的影响可以忽略不计。</block>
  <block id="c0bd33c36fff1f6dbb2bf9253a7f40dd" category="paragraph">由于Cloud Volumes Service 中的Snapshot副本为只读副本、因此、除非勒索软件在未经注意的情况下激增到数据集中、并且已为受勒索软件感染的数据创建Snapshot副本、否则它们不会受到勒索软件的感染。因此、您还必须考虑根据数据异常检测勒索软件。Cloud Volumes Service 目前不提供本机检测功能、但您可以使用外部监控软件。</block>
  <block id="9b641219ac63451505f5a25a887038d4" category="section-title">备份和还原</block>
  <block id="5e2f84170723d4cfed011f9ebc6c557e" category="paragraph">Cloud Volumes Service 提供标准NAS客户端备份功能(例如通过NFS或SMB进行备份)。</block>
  <block id="0d69441d7fc21e56d3cf2eb944fbf6c1" category="inline-link">卷复制</block>
  <block id="161b127f579db2727ace94e4fb6f9e5b" category="inline-link">云备份</block>
  <block id="56a32ac982c7663e59f24c58cfb673d6" category="paragraph">卷复制可提供源卷的精确副本、以便在发生灾难(包括勒索软件事件)时快速进行故障转移。</block>
  <block id="ae2679a66d07f8c7efd50d972a34a112" category="section-title">跨区域复制</block>
  <block id="1a094951f7e9c42a89c4ef4b0b328eee" category="paragraph">通过CVS-Performance、您可以在NetApp控制的后端服务网络上使用用于在Google网络上运行复制的特定接口使用TLS1.2 AES 256 GCM加密功能、在Google Cloud区域之间安全地复制卷、以实现数据保护和归档使用情形。主(源)卷包含活动生产数据、并复制到二级(目标)卷、以提供主数据集的精确副本。</block>
  <block id="f8e2c7b5b15f4332525ac9687a100a28" category="paragraph">初始复制会传输所有块、但更新仅传输主卷中发生更改的块。例如、如果将主卷上的1 TB数据库复制到二级卷、则在初始复制时会传输1 TB的空间。如果该数据库中有几百行(假设有几MB)在初始化和下次更新之间发生变化、则只有包含更改行的块才会复制到二级(几MB)。这有助于确保传输时间保持较短、并降低复制成本。</block>
  <block id="fd25283b48ea77209e43fe9173df1354" category="paragraph">文件和文件夹上的所有权限都会复制到二级卷、但共享访问权限(例如导出策略和规则或SMB共享和共享ACL)必须单独处理。在发生站点故障转移时、目标站点应利用相同的名称服务和Active Directory域连接、以便一致地处理用户和组身份和权限。如果发生灾难、您可以使用二级卷作为故障转移目标、方法是中断复制关系、从而将二级卷转换为读写卷。</block>
  <block id="940c6fa9c7eb366ae4e471e545edb27b" category="paragraph">卷副本为只读副本、可为异地数据提供不可变的副本、以便在病毒已感染数据或勒索软件已对主数据集进行加密的情况下快速恢复数据。只读数据不会加密、但如果主卷受到影响并发生复制、则受感染的块也会进行复制。您可以使用不受影响的旧Snapshot副本进行恢复、但SLA可能会超出承诺的RTO /RRPO范围、具体取决于检测到攻击的速度。</block>
  <block id="fe62647cc35dde214e0df1ae1fe9d0ab" category="inline-link">安全注意事项</block>
  <block id="8ee215caafa31f1ecdd53056d288eb19" category="paragraph">虽然Cloud Volumes Service 可提供较高的数据持久性、但外部事件可能会导致发生原因 数据丢失。在发生病毒或勒索软件等安全事件时、备份和恢复对于及时恢复数据访问至关重要。管理员可能会意外删除Cloud Volumes Service 卷。或者、用户只希望将数据的备份版本保留数月、而在卷中保留额外的Snapshot副本空间将成为一项成本难题。虽然Snapshot副本应该是在过去几周内保留备份版本以恢复其丢失的数据的首选方式、但它们位于卷中、如果卷消失、它们将丢失。</block>
  <block id="a5cef37749b0ea6b89d13e2bfc190bcc" category="paragraph">Cloud Volumes Service 备份会在Google云存储(GCS)上生成卷的副本。它只会备份存储在卷中的实际数据、而不会备份可用空间。它始终以增量形式运行、也就是说、它会一次性传输卷内容、并在上继续备份更改的数据。与具有多个完整备份的传统备份概念相比、它可以节省大量备份存储、从而降低成本。由于与卷相比、备份空间的每月价格更低、因此、它是延长备份版本的理想之选。</block>
  <block id="d41618915810c18642064f885af2a835" category="paragraph">用户可以使用Cloud Volumes Service 备份将任何备份版本还原到同一区域内的相同或不同卷。如果删除了源卷、则备份数据会保留下来、需要单独管理(例如删除)。</block>
  <block id="3289695e643b478f0efa19edc74cf567" category="inline-link">Cloud Volumes Service 备份文档</block>
  <block id="be7923d42a302a1a86fdaa9f096fde63" category="inline-link">支持的最大备份版本数</block>
  <block id="59aab28b54594c59dab8d19afd9478e4" category="inline-link">定价</block>
  <block id="9a647ae53ed9b2a783aef42530e1fe97" category="paragraph">项目的所有备份数据都存储在GCS存储分段中、此存储分段由服务管理、用户无法看到。每个项目使用不同的存储分段。目前、存储分段与Cloud Volumes Service 卷位于同一区域、但正在讨论更多选项。有关最新状态、请参见文档。</block>
  <block id="4e1c6d2a637d959db4ce4a09b3e5c580" category="paragraph">从Cloud Volumes Service 存储分段到GCS的数据传输使用具有HTTPS和TLS1.2的服务内部Google网络。数据会使用Google管理的密钥在空闲时进行加密。</block>
  <block id="5e467dce18f46b1803b06097fae60b82" category="inline-link">角色/netappcloudvolumes.admin</block>
  <block id="6ab0778deb23383f6063990e47d38567" category="summary">Cloud Volumes Service 中的所有卷都使用AES-256加密进行空闲加密、这意味着写入介质的所有用户数据都将进行加密、并且只能使用每个卷的密钥进行解密。</block>
  <block id="05a42723f4aebc1b8fea32f0da56f531" category="doc">空闲数据加密</block>
  <block id="4a41d68019f2643468ef37e122fc87a9" category="list-text">对于CVS-SW、使用Google生成的密钥。</block>
  <block id="68056df8fa340722ff859d534da347e4" category="list-text">对于CVS-Performance、每个卷的密钥存储在Cloud Volumes Service 中内置的密钥管理器中。</block>
  <block id="e23c4fadd8e7d70663bc3393bca7d576" category="inline-link">Google密钥管理服务(KMS)。</block>
  <block id="387ccb6d293c8d2f51b2730c375c3f3a" category="paragraph">自2021年11月起、提供了预览客户管理的加密密钥(CMEK)功能。这样、您就可以使用中托管的每个项目的每个区域主密钥对每个卷的密钥进行加密<block ref="145d140dc09dde7f8aacc53f1269c2de" category="inline-link-rx"></block> 您可以通过Kms连接外部密钥管理器。</block>
  <block id="1988a6b2308f38718c8100c2e344eb5c" category="inline-link">设置客户管理的加密密钥</block>
  <block id="13a2c7416db43025d8318ec9db325859" category="summary">传输中的数据可以在NAS协议层进行加密、Google Cloud网络本身也会进行加密、如以下各节所述。</block>
  <block id="f7ccd4455f141bba37dd989458bfd1f3" category="doc">传输中的数据加密</block>
  <block id="8de1715de3864b137091fa8f6d71053f" category="section-title">Google Cloud网络</block>
  <block id="a94ac9daf8e09a31f9e81f7de9ee7ab6" category="inline-link">传输中加密</block>
  <block id="57d5b464e5bc1a25ae2337c72e492c88" category="paragraph">Google Cloud按中所述在网络级别对流量进行加密<block ref="df3d10947a311abbd08a64a5cc9629d3" category="inline-link-rx"></block> 在Google文档中。如"云卷服务架构"一节所述、Cloud Volumes Service 是通过NetApp控制的PSA生产商项目交付的。</block>
  <block id="4322a5ae7fc781564c1349bf92846311" category="paragraph">对于CVS-SW、生产者租户运行Google VM来提供服务。Google会自动对用户VM和Cloud Volumes Service VM之间的流量进行加密。</block>
  <block id="d3072f2789ba193441ddf485cc806a82" category="inline-link">IEEE 802.1AE加密(MAC秒)</block>
  <block id="6141361c43c6e429fa93fd0f6f8b2dac" category="inline-link">封装</block>
  <block id="2a5cd9c0503b957ff28d59f12a8bb05a" category="paragraph">虽然在网络层上、CVS-Performance的数据路径未完全加密、但NetApp和Google会结合使用<block ref="83e770b09a2e800e59cae429b60dde07" category="inline-link-rx"></block>，<block ref="c5a2137e5d30663db35a2f990a0275f0" category="inline-link-rx"></block> (数据加密)和受物理限制的网络、用于保护Cloud Volumes Service CVS-Performance服务类型与Google Cloud之间传输的数据。</block>
  <block id="95151e0beeb1cf14e98ed9e0e0ebc86f" category="section-title">NAS协议</block>
  <block id="7661437a0dea607fd6013193db5363be" category="paragraph">NFS和SMB NAS协议可在协议层提供可选的传输加密。</block>
  <block id="198a269fc15076e5cc8ab572d6711771" category="section-title">SMB加密</block>
  <block id="69c2cd6d510299a43f241a4afbeef373" category="paragraph"><block ref="ebb0763fea63f976f4d3ea586b6fe491" category="inline-link-rx"></block> 为SMB数据提供端到端加密、并防止数据在不可信的网络上被窃听。您可以同时为客户端/服务器数据连接(仅适用于具有SMB3.x功能的客户端)和服务器/域控制器身份验证启用加密。</block>
  <block id="a8c42b910beec902a232a69b59a37847" category="paragraph">启用SMB加密后、不支持加密的客户端将无法访问共享。</block>
  <block id="72635a952bf12498ca4ca124b1a14d51" category="paragraph">Cloud Volumes Service 支持使用RC4 HMAC、AES-128-CTS-HMAC-SHA1和AES-256-CTS-HMAC-SHA1安全密码进行SMB加密。SMB协商到服务器支持的最高加密类型。</block>
  <block id="980b28eb45b1ea66cdd07d05e78099a3" category="section-title">NFSv4.1 Kerberos</block>
  <block id="b97e4c9117cfcc0dd5d7a10e1a7a2631" category="inline-link">RFC7530</block>
  <block id="69a4f8e652e19cfdfb26e27d4447ae98" category="paragraph">对于NFSv4.1、CVS-Performance可提供Kerberos身份验证、如中所述<block ref="526af9c532c496dd16998f764e15dc87" category="inline-link-rx"></block>。您可以按卷启用Kerberos。</block>
  <block id="b2833929a77bd8c490997197ed3f00be" category="paragraph">当前最强的Kerberos加密类型为AES-256-CTS-HMAC-SHA1。NetApp Cloud Volumes Service 支持适用于NFS的AES-256-CTS-HMAC-SHA1、AES-128-CTS-HMAC-SHA1、DES3和DES。它还支持对CIFS/SMB流量使用ARCFOUR-HMAC (RC4)、但不支持对NFS使用。</block>
  <block id="59417c70dd426d4c6a1a81a09043bb7b" category="paragraph">Kerberos为NFS挂载提供了三种不同的安全级别、这些安全级别可以选择Kerberos安全性的强程度。</block>
  <block id="710c8a535ea62cee124026e31e71a5bd" category="inline-link">通用挂载选项</block>
  <block id="224b49d2f24ee42bbb73b2ca635c6d9a" category="paragraph">根据RedHat的要求<block ref="1849b335749f623c227052141b2e8b11" category="inline-link-rx"></block> 文档：</block>
  <block id="babd6b3b4aea27ca41d56a231f2625af" category="paragraph">一般来说、Kerberos安全级别必须执行的操作越多、性能就越差、因为客户端和服务器会花费时间对发送的每个数据包的NFS操作进行加密和解密。许多客户端和NFS服务器都支持将AES-NI负载分流到CPU、以获得更好的整体体验、但Kerberos 5p (完全端到端加密)的性能影响远远大于Kerberos 5 (用户身份验证)的影响。</block>
  <block id="986c123032dbfdac18bc180d1a2c3562" category="paragraph">下表显示了每个级别在安全性和性能方面的差异。</block>
  <block id="f12149bd43eabe8557e021017cfb9b1f" category="cell">安全级别</block>
  <block id="af75613ef5351b4f2563e49218c01d5b" category="cell">NFSv3—系统</block>
  <block id="d65540b3d2f3c15e237b23f6d4d823e5" category="list-text">安全性最低；纯文本、包含数字用户ID/组ID</block>
  <block id="2310efb28386099d85b1dbcaf5f9c51f" category="list-text">能够查看UID、GID、客户端IP地址、导出路径、文件名、 数据包捕获中的权限</block>
  <block id="07b50706d3894aa894686195ddeed426" category="list-text">最适合大多数情况</block>
  <block id="54fcc149f825f18bfaaa374d6876e25a" category="cell">NFSv4.x—系统</block>
  <block id="3777f761befcdc3f42a4d77cde2962fe" category="list-text">比NFSv3 (客户端ID、名称字符串/域字符串匹配)更安全、但仍为纯文本</block>
  <block id="25199bb4f6f6a3eadd28c84579d0fcf7" category="list-text">能够查看UID、GID、客户端IP地址、名称字符串、域ID、 数据包捕获中的导出路径、文件名和权限</block>
  <block id="5145a8956e4807aeba5a7a4a1677c598" category="list-text">适用于顺序工作负载(如VM、数据库、大型文件)</block>
  <block id="bc96a40b0174b0ec2f9133e1e704d7cb" category="list-text">错误、文件数量较多/元数据较高(较差30-50%)</block>
  <block id="f25baf1a23f237c73f28b4834def4161" category="cell">NFS—krb5</block>
  <block id="0661ead41dc806181d0a0bff696e49df" category="list-text">对每个NFS数据包中的凭据进行Kerberos加密—在GSS包装程序中的RPC调用中封装用户/组的UID/GID</block>
  <block id="b012a8b71e44e4c118c2a97f94c11c1f" category="list-text">请求访问挂载的用户需要有效的Kerberos票证(通过用户名/密码或手动密钥选项卡交换)；票证将在指定时间段后过期、用户必须重新进行身份验证才能进行访问</block>
  <block id="ab2293d06a9e3594a17eb02b827c471a" category="list-text">对于NFS操作或挂载/端口映射程序/NLM等辅助协议、不进行加密(可以查看导出路径、IP地址、文件句柄、权限、文件名、 数据包捕获中的atime/mtime)</block>
  <block id="6d140d250a49ec533ff2211674c16138" category="list-text">大多数情况下最适合使用Kerberos；比AUTH_SYS更差</block>
  <block id="bc578f6162e4255fe0d1d4445ec8d975" category="cell">NFS—krb5i</block>
  <block id="7886fbf427a34b659783d690ee4ad3dd" category="list-text">请求访问挂载的用户需要有效的Kerberos票证(通过用户名/密码或手动密钥选项卡交换)；票证将在指定时间段后过期、用户必须重新进行身份验证才能访问</block>
  <block id="49d02d7e5db8eb8139c3777891f63e2e" category="list-text">每个数据包都会添加Kerberos GSS校验和、以确保不会截获任何数据包。如果校验和匹配、则允许对话。</block>
  <block id="0ea3431437c971e8ac8f271b60694b38" category="list-text">优于krb5p、因为NFS有效负载未加密；与krb5相比、唯一增加的开销是完整性校验和。krb5i的性能不会比krb5差得多、但会有所下降。</block>
  <block id="facbd78bc28fa0b36f521d74ff5f0cec" category="cell">NFS—krb5p</block>
  <block id="d11093694c8bd1d8897446e4cf645e48" category="list-text">请求访问挂载的用户需要有效的Kerberos票证(通过用户名/密码或手动密钥表交换)；票证将在指定时间段后过期、用户必须重新进行身份验证才能进行访问</block>
  <block id="29af1c9e08784f1ef0e42433aef21eee" category="list-text">所有NFS数据包有效负载都使用GSS包装程序进行加密(在数据包捕获中看不到文件句柄、权限、文件名、atime/mtime)。</block>
  <block id="70aa40903816c1fda65618ae32c56d8b" category="list-text">包括完整性检查。</block>
  <block id="3e7dfd7567a414307d5fe93ea83ce4f6" category="list-text">NFS操作类型是可见的(fsINFO、access、getattr等)。</block>
  <block id="6b375be1f905197ba21c586647e973f4" category="list-text">辅助协议(挂载、端口映射、NLM等)未加密-(可以查看导出路径、IP地址)</block>
  <block id="6de6f14759a24d6fcb16973384e01c00" category="list-text">安全级别的性能最差；krb5p必须对更多内容进行加密/解密。</block>
  <block id="abac32415b4bfbaf4765dec9d36149cd" category="paragraph">在Cloud Volumes Service 中、配置的Active Directory服务器用作Kerberos服务器和LDAP服务器(从RFC2307兼容模式查找用户身份)。不支持其他Kerberos或LDAP服务器。NetApp强烈建议您在Cloud Volumes Service 中使用LDAP进行身份管理。有关NFS Kerberos在数据包捕获中的显示方式的信息、请参见一节 <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="4780631a0451a6605045de3ace692cc6" category="list-text">适用于Cloud Volumes Service 的Google Cloud文档</block>
  <block id="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link"><block ref="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link-rx"></block></block>
  <block id="8e65fc49f8ebbf3d9cc9651ce7940654" category="paragraph"><block ref="8e65fc49f8ebbf3d9cc9651ce7940654" category="inline-link-rx"></block></block>
  <block id="0e8aec42089c0c73812fa42d1888b3c8" category="list-text">Google私有服务访问</block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">NetApp 产品文档</block>
  <block id="f670e58416e680d41a98914939ff8b4d" category="list-text">加密验证模块计划—NetApp CryptoMod</block>
  <block id="904728949094c548bcec2129979a28a6" category="inline-link"><block ref="904728949094c548bcec2129979a28a6" category="inline-link-rx"></block></block>
  <block id="50dc6dd0a76419597a78231ee45ad7f5" category="paragraph"><block ref="50dc6dd0a76419597a78231ee45ad7f5" category="inline-link-rx"></block></block>
  <block id="fb35bc32af8e0bce21ef22bad9052b39" category="inline-link"><block ref="0ea855bd074e3e4be70d90c120079c12" category="inline-link-rx"></block></block>
  <block id="56f0874ab11ee024b4419753f2a3f06f" category="paragraph"><block ref="801eea2aa1601f12cc3d53d718ad33a7" category="inline-link-rx"></block></block>
  <block id="61eb0e8494826dc8f30af9122fd97664" category="list-text">TR-4616 ： ONTAP 中的 NFS Kerberos</block>
  <block id="ed78f5221deba5e60a950d28a62de702" category="inline-link"><block ref="ed78f5221deba5e60a950d28a62de702" category="inline-link-rx"></block></block>
  <block id="d677acd46c811ecd9bac37aa26d8668c" category="paragraph"><block ref="d677acd46c811ecd9bac37aa26d8668c" category="inline-link-rx"></block></block>
  <block id="1bebe65011b1928d45d041533c04d2b1" category="paragraph">请告诉我们如何改进本技术报告。</block>
  <block id="8b1418ea0c579605e873907335ca62c7" category="paragraph">联系我们、电子邮件地址为：mailto：doccomments@netapp.com^ doccomments@netapp.com。在主题行中包含技术报告4918。</block>
  <block id="402d245fd6f48d88ea661814c622456e" category="summary">NAS协议是一个网络上的多个客户端访问存储系统上相同数据的方法、例如GCP上的Cloud Volumes Service。NFS和SMB是定义的NAS协议、在客户端/服务器基础上运行、Cloud Volumes Service 充当服务器。</block>
  <block id="900608117b1be22303e2a172c6d9b280" category="doc">NAS协议基础知识</block>
  <block id="b03874a8574793b2c634d05da5dae732" category="paragraph">NAS协议是一个网络上的多个客户端访问存储系统上相同数据的方法、例如GCP上的Cloud Volumes Service。NFS和SMB是定义的NAS协议、在客户端/服务器基础上运行、Cloud Volumes Service 充当服务器。客户端向服务器发送访问、读取和写入请求、服务器负责协调文件锁定机制、存储权限以及处理身份和身份验证请求。</block>
  <block id="86a29faa66a25c7e3fd290cf1e53761c" category="paragraph">例如、如果NAS客户端要在文件夹中创建新文件、则遵循以下常规过程。</block>
  <block id="817aaff54aa6b5cd0e96c54c0b20ea1d" category="list-text">客户端要求服务器提供有关目录的信息(权限、所有者、组、文件ID、可用空间、 等)；如果发出请求的客户端和用户对父文件夹具有必要的权限、则服务器将使用此信息进行响应。</block>
  <block id="9ec40c2869366ebe8cf1a8c690bb6471" category="list-text">如果目录上的权限允许访问、则客户端会询问服务器所创建的文件名是否已存在于文件系统中。如果文件名已在使用中、则创建将失败。如果文件名不存在、服务器会让客户端知道它可以继续。</block>
  <block id="83a9d09522edde42d016b5f2649ad9b6" category="list-text">客户端调用服务器以使用目录句柄和文件名创建文件、并设置访问和修改时间。服务器会向文件发出唯一的文件ID、以确保不会使用相同的文件ID创建其他文件。</block>
  <block id="4884742626257d3e2fee8f3fa6d74f9c" category="list-text">在执行写入操作之前、客户端会发送一个调用来检查文件属性。如果权限允许、客户端将写入新文件。如果协议/应用程序使用锁定、则客户端会要求服务器提供锁定、以防止其他客户端在锁定期间访问文件、以防止数据损坏。</block>
  <block id="432be93985cd954e5f755048381e528d" category="summary">NFS是一种分布式文件系统协议、它是在Request for Comments (RFC)中定义的开放式IETF标准、允许任何人实施该协议。</block>
  <block id="b53dfc952aa9d99343d94971cf6c3fee" category="paragraph">通过导出客户端或一组客户端可访问的路径、可以将Cloud Volumes Service 中的卷共享到NFS客户端。挂载这些导出的权限由导出策略和规则定义、这些策略和规则可由Cloud Volumes Service 管理员配置。</block>
  <block id="0e3cb63bde3f98dbd812d470d8b100cf" category="paragraph">NetApp NFS实施被视为该协议的黄金标准、用于无数企业级NAS环境。以下各节介绍了Cloud Volumes Service 中提供的NFS和特定安全功能及其实施方式。</block>
  <block id="8b575afc20d2914501471190a68364ed" category="section-title">默认本地UNIX用户和组</block>
  <block id="c9f0864944a97085b2897c473c91dccc" category="paragraph">Cloud Volumes Service 包含多个用于各种基本功能的默认UNIX用户和组。当前无法修改或删除这些用户和组。当前无法将新的本地用户和组添加到Cloud Volumes Service 中。默认用户和组以外的UNIX用户和组需要由外部LDAP名称服务提供。</block>
  <block id="8002bcf6ec4e483483e32633f99bee00" category="paragraph">下表显示了默认用户和组及其对应的数字ID。NetApp建议不要在LDAP中或在重新使用这些数字ID的本地客户端上创建新用户或组。</block>
  <block id="0346306b31bbb7a0ae5245da13ec03c4" category="cell">默认用户：数字ID</block>
  <block id="c782adef8851cb8855543f329d548bb2" category="cell">默认组：数值ID</block>
  <block id="a38b2868ff594195dcec8e7fe562b0be" category="list-text">根：0</block>
  <block id="44b4512252320c293616b69743e2a445" category="list-text">pcuser：65534</block>
  <block id="95312f9502cf30aaff5cbbd3a4585a68" category="list-text">nobody：65535</block>
  <block id="39fff4671c3793536f3df78e41aed899" category="list-text">守护进程：1.</block>
  <block id="ffe991bd5946c28affb0a08326a88c3f" category="admonition">使用NFSv4.1时、root用户在NFS客户端上运行目录列出命令时可能会显示为nobody。这是因为客户端的ID域映射配置。请参见名为的部分 <block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block> 有关此问题描述 以及如何解决此问题的详细信息、请参见。</block>
  <block id="97d69dfca64d2bd85ec6cc9736cd662b" category="section-title">root用户</block>
  <block id="767a04b899f673915ec8d6d78f549f3b" category="paragraph">在Linux中、root帐户可以访问基于Linux的文件系统中的所有命令、文件和文件夹。由于此帐户的强大功能、安全最佳实践通常要求以某种方式禁用或限制root用户。在NFS导出中、可以通过导出策略和规则以及称为根强制转换的概念在Cloud Volumes Service 中控制root用户对文件和文件夹的能力。</block>
  <block id="7cd60419657f1f0735c557afd44724f0" category="inline-link">setuid/setgid命令(粘滞位)</block>
  <block id="b95ee7e499b2b5ee7f9c911c9c86f8a2" category="paragraph">根强制转换可确保访问NFS挂载的root用户被强制转换为匿名数字用户65534 (请参见第节<block ref="07a7b24bc0f7cda943dc05060d1188d8" category="inline-xref-macro-rx"></block>")、并且当前仅在使用CVS-Performance时可用、方法是在创建导出策略规则期间选择off作为root访问权限。如果root用户被强制转换为匿名用户、则它将无法再运行chown或<block ref="451ac5d05b7e3e41db0c92126d9290ad" category="inline-link-rx"></block> 对于NFS挂载中的文件或文件夹、以及root用户创建的文件或文件夹、将anon UID显示为所有者/组。此外、root用户无法修改NFSv4 ACL。但是、root用户仍可访问其没有显式权限的chmod和已删除的文件。如果要限制对root用户的文件和文件夹权限的访问、请考虑使用具有NTFS ACL的卷、创建名为`root`的Windows用户并将所需权限应用于文件或文件夹。</block>
  <block id="0b2cc4ee83c7e73e4426e294c95be2c7" category="section-title">匿名用户</block>
  <block id="f489703ccadc6e9616bab479ace6cf03" category="paragraph">匿名(anon)用户ID指定映射到未使用有效NFS凭据的客户端请求的UNIX用户ID或用户名。使用root用户强制转换时、这可能包括root用户。Cloud Volumes Service 中的anon用户为65534。</block>
  <block id="48da046d67add0ab58d9cbc2c2da421c" category="paragraph">在Linux环境中、此UID通常与用户名`nobody`或`nfsnobody`关联。Cloud Volumes Service 还使用65534作为本地UNIX用户` pcuser`(请参见第节<block ref="21f1cd16f2baec63c7c604945762d1f2" category="inline-xref-macro-rx"></block>")、当在LDAP中找不到有效匹配的UNIX用户时、它也是Windows到UNIX名称映射的默认回退用户。</block>
  <block id="1a64786b80a72f5b468ee5a6c27c19bb" category="paragraph">由于Linux和Cloud Volumes Service 中UID 65534的用户名不同、因此使用NFSv4.1时映射到65534的用户的名称字符串可能不匹配。因此、在某些文件和文件夹上、您可能会看到`nobody`作为用户。请参见第节"<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>有关此问题描述 以及如何解决此问题的信息、请参见。</block>
  <block id="093b885796f6b6edbf133d153a574ee0" category="section-title">访问控制/导出</block>
  <block id="c40a72feaf9e622dcbd1a55edff6fdbf" category="paragraph">NFS挂载的初始导出/共享访问通过导出策略中包含的基于主机的导出策略规则进行控制。定义了主机IP、主机名、子网、网络组或域、以允许访问挂载NFS共享以及主机允许的访问级别。导出策略规则配置选项取决于Cloud Volumes Service 级别。</block>
  <block id="519377bf4a5b0a2078c3d66b249040aa" category="paragraph">对于CVS-SW、导出策略配置可使用以下选项：</block>
  <block id="fdbbd602d808015eb2f536ce2add5b6e" category="list-text">*客户端匹配。* IP地址列表以逗号分隔、主机名、子网、网络组和域名列表以逗号分隔。</block>
  <block id="4984ee657e0bd2919476369a84dfe159" category="list-text">* RO或RW访问规则。*选择读/写或只读以控制导出的访问级别。</block>
  <block id="3a3236a433ddc1bb46fe40e058aad584" category="list-text">*根访问(开/关)。*配置根强制转换(请参见一节<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>"了解详细信息)。</block>
  <block id="0c1b0b2a02124e4f1e2111f36d28432e" category="list-text">*协议类型。*此操作会将对NFS挂载的访问限制为特定协议版本。为卷同时指定NFSv3和NFSv4.1时、请将这两个字段留空或同时选中这两个框。</block>
  <block id="553de93bd85985676f0ef4762f4de2ab" category="list-text">* Kerberos安全级别(选择启用Kerberos时)。*提供了krb5、krb5i和/或krb5p选项、用于只读或读写访问。</block>
  <block id="a98abf6af551f8564e89efb200e37032" category="section-title">更改所有权(chown)和更改组(chgrp)</block>
  <block id="545978eda72a981e986a37d84621575d" category="paragraph">Cloud Volumes Service 上的NFS仅允许root用户对文件和文件夹运行chown/chgrp。其他用户会看到`Operation not permitted`错误、即使是在其拥有的文件上也是如此。如果使用root squash (如第节中所述)<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>")、根卷将被强制转换为非root用户、并且不允许访问chown和chgrp。目前、Cloud Volumes Service 中没有允许非root用户使用chown和chgrp的解决方法。如果需要更改所有权、请考虑使用双协议卷并将安全模式设置为NTFS、以便从Windows端控制权限。</block>
  <block id="b40637b973f7941123dacf09ceef0fba" category="section-title">权限管理</block>
  <block id="b48f3521890100492cddc30349f6e7b2" category="paragraph">Cloud Volumes Service 同时支持模式位(例如rwx的6444、777等)和NFSv4.1 ACL、以控制使用UNIX安全模式的卷在NFS客户端上的权限。标准权限管理用于这些对象(例如chmod、chown或nfs4_setfacl)、并可用于支持这些对象的任何Linux客户端。</block>
  <block id="a4f4a04396f203764eb677e59aeea059" category="paragraph">此外、使用设置为NTFS的双协议卷时、NFS客户端可以利用Cloud Volumes Service 名称映射到Windows用户、然后使用该映射来解析NTFS权限。这需要通过LDAP连接到Cloud Volumes Service 来提供数字ID到用户名的转换、因为Cloud Volumes Service 需要有效的UNIX用户名才能正确映射到Windows用户名。</block>
  <block id="40c93306b7b5fa43d5bdeaaf6446b5c8" category="section-title">为NFSv3提供粒度ACL</block>
  <block id="38244b1450366af1bc12c6d85adcf6d2" category="paragraph">模式位权限仅涵盖语义中的所有者、组和其他所有人、这意味着基本NFSv3没有粒度用户访问控制。Cloud Volumes Service 既不支持POSIX ACL、也不支持扩展属性(例如chattr)、因此、只有在使用NFSv3的以下情况下、才可以使用粒度ACL：</block>
  <block id="15ad8d0b9866344d62ea9ffa4ae25982" category="list-text">具有有效UNIX到Windows用户映射的NTFS安全模式卷(需要CIFS服务器)。</block>
  <block id="c14f9a108935fe84b2ee2c80664062d4" category="list-text">使用挂载NFSv4.1的管理客户端应用NFSv4.1 ACL以应用ACL。</block>
  <block id="b90aebde70afe18a23fa55cafb7bd6e7" category="inline-link-macro">"LDAP"</block>
  <block id="fc96ac54908c774cd60159cf8c65272e" category="paragraph">这两种方法都需要使用LDAP连接进行UNIX身份管理、并填充有效的UNIX用户和组信息(请参见一节 <block ref="941c88f858b9781fbfe78651e071df70" category="inline-link-macro-rx"></block>)、并且仅适用于CVS-Performance实例。要对NFS使用NTFS安全模式卷、必须使用双协议(SMB和NFSv3)或双协议(SMB和NFSv4.1)、即使未建立SMB连接也是如此。要对NFSv3挂载使用NFSv4.1 ACL、必须选择`both (NFSv3/NFSv4.1)`作为协议类型。</block>
  <block id="b9fd9ad6fc3c3b72bb1d8b9db35c4ff8" category="inline-link">NFS4_ACL—NFSv4访问控制列表</block>
  <block id="8454ec39d80a4c7dced33aed7bc5cc3c" category="paragraph">常规UNIX模式位提供的权限粒度级别与NTFS或NFSv4.x ACL提供的权限级别不同。下表对NFSv3模式位和NFSv4.1 ACL之间的权限粒度进行了比较。有关NFSv4.1 ACL的信息、请参见<block ref="6f8990d4da30b2d9c1096f2d7fdec422" category="inline-link-rx"></block>。</block>
  <block id="04bf6ba29148b02f9bc0aece8b1ab976" category="cell">NFSv3 模式位</block>
  <block id="ec969632045eaebe3e92b63bc00edf03" category="cell">NFSv4.1 ACL</block>
  <block id="b7073329ceba059aa3ad7875190c661f" category="list-text">执行时设置用户ID</block>
  <block id="573fa671705c50ff1c121cd141dfeb90" category="list-text">执行时设置组ID</block>
  <block id="0ab8eb5c98bf5a8e01cc9dc03065fd63" category="list-text">保存交换的文本(未在POSIX中定义)</block>
  <block id="78e3e57905e586d5d03519b5883d9b49" category="list-text">所有者的读取权限</block>
  <block id="07ea3a6ddfd17ab896abc34a5fb98c32" category="list-text">所有者的写入权限</block>
  <block id="ef1c725ac00a8daafb96e6f926b38e84" category="list-text">对文件执行所有者权限；或者在目录中查找(搜索)所有者权限</block>
  <block id="d51cc2a74a686e9f6b08108c215a677e" category="list-text">组的读取权限</block>
  <block id="6750a7dbc586cfe9c3c1e6fc348bc47f" category="list-text">组的写入权限</block>
  <block id="66471165b6102256624c1aaa1bf05ef9" category="list-text">对文件中的组执行权限；或者在目录中查找(搜索)组权限</block>
  <block id="860c8444d0dfe3bf1e1818fdbe8c3733" category="list-text">其他人的读取权限</block>
  <block id="95663f359ae8aaa2910488b36c7168fb" category="list-text">其他人的写入权限</block>
  <block id="54384d9f12231abb228dd692b2c7a689" category="list-text">对其他人对文件执行权限；或者在目录中查找(搜索)其他人的权限</block>
  <block id="4d6deb7613496d18f12d0d0d0fe84ecb" category="paragraph">访问控制条目(ACE)类型(允许/拒绝/审核)*继承标志*目录继承*文件继承*无传播-继承*仅继承</block>
  <block id="13640bb94453faf76256f49439337e2e" category="paragraph">权限*读取数据(文件)/列表目录(目录)*写入数据(文件)/创建文件(目录)*附加数据(文件)/创建子目录(目录)*执行(文件)/更改目录(目录)*删除*删除子目录*读取属性*写入属性*读取命名属性*写入ACL *写入所有者*写入ACL *写入操作</block>
  <block id="0bfe97b6a2010bf8a46c30c256d9bc67" category="paragraph">最后、根据RPC数据包限制、对于AUTH_SYS、NFS组成员资格(在NFSv3和NFSv4.x中)限制为默认最大16个。NFS Kerberos最多可提供32个组、NFSv4 ACL可通过粒度用户和组ACL (每个ACE最多1024个条目)来消除此限制。</block>
  <block id="27aabeb671232f388e6288cf9395fda9" category="inline-link">创建和管理NFS卷</block>
  <block id="75812520c9040a205064d0d2cb2263e9" category="section-title">NFSv3用户和组ID</block>
  <block id="b1695eaaf5db3491be45228e42d7894f" category="paragraph">NFSv3用户和组ID以数字ID而非名称的形式通过网线传输。Cloud Volumes Service 使用NFSv3无法解析这些数字ID的用户名、而UNIX安全模式卷仅使用模式位。如果存在NFSv4.1 ACL、则需要进行数字ID查找和/或名称字符串查找才能正确解析此ACL、即使使用NFSv3也是如此。对于NTFS安全模式卷、Cloud Volumes Service 必须将数字ID解析为有效的UNIX用户、然后映射到有效的Windows用户以协商访问权限。</block>
  <block id="c88acee1e86a1d4e088392362c04bb3b" category="section-title">NFSv3用户和组ID的安全限制</block>
  <block id="51d0cb09f5edabf17b3490e1b53d7b22" category="paragraph">使用NFSv3时、客户端和服务器无需确认尝试使用数字ID进行读写的用户是否为有效用户；这只是隐式信任。这样、只需欺骗任何数字ID即可使文件系统不受潜在漏洞的影响。为了防止出现此类安全漏洞、Cloud Volumes Service 提供了一些选项。</block>
  <block id="467b69ba310f54b371bbdbffe09e6497" category="list-text">实施适用于NFS的Kerberos会强制用户使用用户名和密码或keytab文件进行身份验证、以获取Kerberos票证以允许访问挂载。Kerberos可用于CVS-Performance实例、仅适用于NFSv4.1。</block>
  <block id="9120b024c7fefc321f0ebc6fee670c59" category="list-text">限制导出策略规则中的主机列表会限制哪些NFSv3客户端可以访问Cloud Volumes Service 卷。</block>
  <block id="1b652183dcffb7bab733d50929de6844" category="list-text">使用双协议卷并对卷应用NTFS ACL会强制NFSv3客户端将数字ID解析为有效的UNIX用户名、以便正确进行身份验证以访问挂载。这需要启用LDAP并配置UNIX用户和组身份。</block>
  <block id="8d5c591e079f79f63fd9e9807dc0f747" category="list-text">将root用户强制转换会限制root用户对NFS挂载可能造成的损害、但不会完全消除风险。有关详细信息、请参见"<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>。 "</block>
  <block id="2013c75e17676506ba3c06142530277a" category="paragraph">最终、NFS安全性仅限于您所使用的协议版本。虽然NFSv3的总体性能优于NFSv4.1、但提供的安全性级别不同。</block>
  <block id="1d9f0263509a5bc0f447962105bb1a92" category="paragraph">与NFSv3相比、NFSv4.1的安全性和可靠性更高、原因如下：</block>
  <block id="11d0cb4a0817a571de35b1a57bcd7b86" category="list-text">通过基于租赁的机制实现集成锁定</block>
  <block id="2a7079f12b8b7175a78aa4192442cceb" category="list-text">有状态会话</block>
  <block id="78d4290f55bf351449981f773525bc0b" category="list-text">通过单个端口提供所有NFS功能(2049)</block>
  <block id="53ec1aa3e51de041ca30580dcd5695db" category="list-text">仅限TCP</block>
  <block id="762c048886aaa3279e7ff7d4bbe56f5c" category="list-text">ID域映射</block>
  <block id="7e6be8eb2ba9a556864cfd20857c1565" category="list-text">Kerberos集成(NFSv3可以使用Kerberos、但只能用于NFS、而不能用于辅助协议、例如NLM)</block>
  <block id="1f2bcbb2c0049fcc033a40cb665f19fc" category="section-title">NFSv4.1依赖关系</block>
  <block id="f83a89d33e724f74ff5a673c34fe9ac6" category="paragraph">由于NFSv4.1中的额外安全功能、因此、使用NFSv3时不需要涉及一些外部依赖关系(类似于SMB需要依赖关系的方式、例如Active Directory)。</block>
  <block id="0e8ff8f10d56a8534800018ecdbcbfb7" category="paragraph">Cloud Volumes Service 支持NFSv4.x ACL、与正常的POSIX模式权限相比、这些ACL具有明显的优势、例如：</block>
  <block id="e7c21967cc185dee47ba9548ba30b26e" category="list-text">精细控制用户对文件和目录的访问</block>
  <block id="a5e0d0cbd4020f568d08cdaed3dedd6b" category="list-text">提高 NFS 安全性</block>
  <block id="fd272c227f4884473fc1b4409d1fa6f0" category="list-text">改进了与CIFS/SMB的互操作性</block>
  <block id="1c0d9e3bfe82d85776be6deeefb1b8d1" category="list-text">取消了使用AUTH_SYS安全性时每个用户16个组的NFS限制</block>
  <block id="37c82add6470c2f73fad45f1e887f214" category="list-text">ACL不需要进行组ID (GID)解析、从而有效地消除了GID限制NFSv4.1 ACL由NFS客户端控制、而不是通过Cloud Volumes Service 控制。要使用NFSv4.1 ACL、请确保您的客户端软件版本支持这些ACL、并安装了正确的NFS实用程序。</block>
  <block id="f497540fbfe4bb6c8784249b7ca44322" category="section-title">NFSv4.1 ACL与SMB客户端之间的兼容性</block>
  <block id="b18893becc5c5979b433330d581d0502" category="paragraph">NFSv4 ACL与Windows文件级ACL (NTFS ACL)不同、但具有类似的功能。但是、在多协议NAS环境中、如果存在NFSv4.1 ACL、而您使用的是双协议访问(同一数据集中的NFS和SMB)、则使用SMB2.0及更高版本的客户端将无法通过Windows安全选项卡查看或管理ACL。</block>
  <block id="e24382a2de980eb4d0fad087c2279291" category="section-title">NFSv4.1 ACL的工作原理</block>
  <block id="65da9b80e25e8e6b76e6f95a27e33773" category="paragraph">定义了以下术语以供参考：</block>
  <block id="3f33ebc7aedc435f5da6f0cdb363e903" category="list-text">*访问控制列表(ACL)。*权限条目的列表。</block>
  <block id="e8b619b2feea9964d68e458010421937" category="list-text">*访问控制条目(ACE)。*列表中的一个权限条目。</block>
  <block id="e22c8ddaa933012f7b9658b15556e1d9" category="paragraph">当客户端在SETATTR操作期间为文件设置NFSv4.1 ACL时、Cloud Volumes Service 会在对象上设置此ACL、以替换任何现有ACL。如果文件没有ACL、则文件的模式权限将通过所有者@、组@和所有人@计算得出。如果文件上存在任何现有的SUID/SGID/粘滞位、它们不会受到影响。</block>
  <block id="bbfc3dd393a8c0fb0275a317ea92cdb6" category="paragraph">如果客户端在getattr操作期间获取文件的NFSv4.1 ACL、则Cloud Volumes Service 将读取与该对象关联的NFSv4.1 ACL、构建ACE列表并将该列表返回给客户端。如果文件具有NT ACL或模式位、则会使用模式位构建ACL并将其返回给客户端。</block>
  <block id="e91b7b9c71eaf21c16d5232d74f4c5c3" category="paragraph">如果ACL中存在拒绝ACE、则拒绝访问；如果存在允许ACE、则授予访问权限。但是、如果ACL中不存在任何ACE、则访问也会被拒绝。</block>
  <block id="85e34118580ac115f838cd805832291e" category="paragraph">安全描述符由一个安全ACL (SACL)和一个随机ACL (DACL)组成。如果NFSv4.1与CIFS/SMB互操作、则DACL将与NFSv4和CIFS进行一对一映射。DACL由ALLOW ACE和DENY ACE组成。</block>
  <block id="f26fe9c5bd9a38964b075295ff6b600f" category="paragraph">如果在设置了NFSv4.1 ACL的文件或文件夹上运行基本的`chmod`、则会保留现有用户和组ACL、但会修改默认所有者@、组@、每个人@ ACL。</block>
  <block id="51cdc67f907418899df11513b246dd1c" category="inline-link">继承标志</block>
  <block id="bfb9f4f4e0b3ee74bbf0624c3acb6f05" category="paragraph">使用NFSv4.1 ACL的客户端可以为系统上的文件和目录设置和查看ACL。在具有ACL的目录中创建新文件或子目录时、该对象将继承ACL中已标记为相应的所有ACE<block ref="efe32d9e162a0a9bfdfda1b55921a64c" category="inline-link-rx"></block>。</block>
  <block id="4ede33bb65432e74e322d690608c2334" category="paragraph">如果文件或目录具有NFSv4.1 ACL、则无论使用哪个协议访问文件或目录、都可以使用该ACL来控制访问。</block>
  <block id="0d733f1633c2aa51a107a6e21dfd5644" category="paragraph">只要父目录上的NFSv4 ACL为ACE添加了正确的继承标志、文件和目录就会继承这些ACE (可能需要进行适当修改)。</block>
  <block id="a61aaa9a4f599d5b80e71c232d23147a" category="paragraph">在根据NFSv4请求创建文件或目录时、生成的文件或目录上的ACL取决于文件创建请求是包含ACL还是仅包含标准UNIX文件访问权限。ACL还取决于父目录是否具有ACL。</block>
  <block id="5ac8b682abcf5cc600bff1df60b6eeb0" category="list-text">如果请求包含 ACL ，则会使用该 ACL 。</block>
  <block id="68d4655ff3b6740e5735fd80c7910023" category="list-text">如果此请求仅包含标准 UNIX 文件访问权限，并且父目录没有 ACL ，则会使用客户端文件模式设置标准 UNIX 文件访问权限。</block>
  <block id="2cf6ef9c801da66f5a80033edc51acf8" category="list-text">如果此请求仅包含标准UNIX文件访问权限、并且父目录具有不可继承的ACL、则会根据传递给此请求的模式位为新对象设置默认ACL。</block>
  <block id="c1eac2f9759f1dd2f7680287789d03f9" category="list-text">如果此请求仅包含标准 UNIX 文件访问权限，但父目录具有 ACL ，则只要父目录的 ACL 中的 ACE 已使用适当的继承标志进行标记，新文件或目录就会继承这些 ACE 。</block>
  <block id="1aeffd8cf8d8faca5f1d6379d7ad7b42" category="section-title">ACE权限</block>
  <block id="be30a66f742a1c4b197f654c5456f525" category="inline-link">如何：使用NFSv4 ACL</block>
  <block id="1e0ba766d5b81a0076401367c75ba49d" category="paragraph">NFSv4.1 ACL权限使用一系列大小写字母值(例如`rxtncy`)来控制访问。有关这些字母值的详细信息、请参见<block ref="19e15d2b871d5802ed53b8bb943cfa1d" category="inline-link-rx"></block>。</block>
  <block id="e5db87d9c7835194478e833b1c2341a3" category="section-title">具有umask和ACL继承的NFSv4.1 ACL行为</block>
  <block id="2d01b8b9abf1cd5dd5dc3a87babfa478" category="inline-link">NFSv4 ACL可提供ACL继承功能</block>
  <block id="90f70b82033cb9c398aab9c2ab8e4b97" category="inline-link">ACL继承标志</block>
  <block id="b40177dea06ae321d6ba903c296a8bf4" category="paragraph"><block ref="a4a4eca6555a8c7e71d54636b6d02bd2" category="inline-link-rx"></block>。ACL继承是指在设置了NFSv4.1 ACL的对象下创建的文件或文件夹可以根据的配置继承ACL<block ref="0dfdf6ea7cd5f3c14c3e752e09504ece" category="inline-link-rx"></block>。</block>
  <block id="e3847e2a1d0d27fe2e50f7b68080126e" category="inline-link">umask</block>
  <block id="391e42635de569b9fd15585f0b03777a" category="inline-link">RFC 5661</block>
  <block id="a5147a6538ae36d50a705033dee8e1ea" category="paragraph"><block ref="63bfc707387dfd47bf50e485c5b4d27f" category="inline-link-rx"></block> 用于控制在目录中创建文件和文件夹而无需管理员干预的权限级别。默认情况下、Cloud Volumes Service 允许umask覆盖继承的ACL、这是预期的行为<block ref="c202d210fe4151f93fd56939449ae558" category="inline-link-rx"></block>。</block>
  <block id="c283f512453dfbe4a4d54a5de963c63a" category="section-title">ACL格式化</block>
  <block id="af26ba96448cb4f36fa75d37c0c24884" category="paragraph">NFSv4.1 ACL采用特定格式。以下示例是对文件设置的ACE：</block>
  <block id="90bdfef72a7e9f73c8492c28764bfecc" category="paragraph">上述示例遵循以下ACL格式准则：</block>
  <block id="7d665626903fe1069f3c052eb3b93597" category="inline-link"><block ref="7d665626903fe1069f3c052eb3b93597" category="inline-link-rx"></block></block>
  <block id="192707027419e02a79fe3b9af5a845c4" category="paragraph">类型`a`表示"允许"。 在这种情况下、不会设置继承标志、因为主体不是组、并且不包括继承。此外、由于ACE不是审核条目、因此无需设置审核标志。有关NFSv4.1 ACL的详细信息、请参见<block ref="588b628ed19e81b60db990218fbd0aa2" category="inline-link-rx"></block>。</block>
  <block id="767a03c18193757348519856b05f7d1c" category="paragraph">如果NFSv4.1 ACL设置不正确(或者客户端和服务器无法解析名称字符串)、则ACL可能无法按预期运行、或者ACL更改可能无法应用并引发错误。</block>
  <block id="e0ad83b43ccb7e44bcdb46bcdc1189d9" category="paragraph">示例错误包括：</block>
  <block id="bf837e35002530c307569ba2ec195e9a" category="section-title">显式拒绝</block>
  <block id="68a14c985893a66fdf24403b891ddc6c" category="paragraph">NFSv4.1权限可以包括所有者、组和所有人的显式拒绝属性。这是因为NFSv4.1 ACL为default-deny、这意味着如果ACE未明确授予ACL、则会拒绝该ACL。显式拒绝属性会覆盖任何访问ACE、无论显式还是非显式。</block>
  <block id="22759a58413e45c1ab8a0a53300ea43c" category="paragraph">deny ACE使用属性标记`D`设置。</block>
  <block id="3bce872a832106c5038ea04d532162ba" category="paragraph">在以下示例中、组@允许所有读取和执行权限、但拒绝所有写入访问。</block>
  <block id="8b4ed201924d12a3d0ec41f5538460b2" category="paragraph">应尽可能避免拒绝ACE、因为它们可能会造成混乱和复杂；不明确定义的允许ACL会被隐式拒绝。如果设置了拒绝ACE、则在用户希望获得访问权限时、可能会拒绝其访问。</block>
  <block id="fb976fa579c74ac9e0b64ac922a938d7" category="paragraph">上述一组ACE相当于模式位中的755、这意味着：</block>
  <block id="de9d71e2841fbf06bf2e96e40b0655d0" category="list-text">所有者拥有完全权限。</block>
  <block id="391533122a44e47fc6d7eed8f3d46152" category="list-text">组具有只读。</block>
  <block id="233c314243fd8ff0f129355150358c9b" category="list-text">其他用户只读。</block>
  <block id="004367158d382df49675a222d852e2c2" category="paragraph">但是、即使权限调整为775等效权限、访问也可能会因为对Everyone设置了显式拒绝而被拒绝。</block>
  <block id="c9533a3d4ca28b597d9e4f0b7c2d7d28" category="section-title">NFSv4.1 ID域映射依赖关系</block>
  <block id="b8c7283821c3d4795f01644c47598298" category="paragraph">NFSv4.1利用ID域映射逻辑作为安全层、帮助验证尝试访问NFSv4.1挂载的用户是否确实是他们所宣称的身份。在这些情况下、NFSv4.1客户端的用户名和组名称会附加一个名称字符串并将其发送到Cloud Volumes Service 实例。如果此用户名/组名称和ID字符串组合不匹配、则此用户和/或组将被强制转换为客户端上的`/etc/idmapd.conf`文件中指定的默认nobody用户。</block>
  <block id="5aec5d2b81e4e7bc2bb96b8eee7f6a1f" category="paragraph">要确保正确遵守权限、需要使用此ID字符串、尤其是在使用NFSv4.1 ACL和/或Kerberos时。因此、要确保客户端和Cloud Volumes Service 之间的一致性、以正确解析用户和组名称身份、必须具有LDAP服务器等名称服务服务器依赖关系。</block>
  <block id="ea6c924c6846969cae29ab27aa4c3d9e" category="paragraph">Cloud Volumes Service 使用静态默认ID域名值`defaultv4iddomain.com`。NFS客户端的ID域名设置默认为DNS域名、但您可以在`/etc/idmapd.conf`中手动调整ID域名。</block>
  <block id="a524142e9e2e4c80b2545aea06b82fb6" category="paragraph">如果在Cloud Volumes Service 中启用了LDAP、则Cloud Volumes Service 会自动将NFS ID域更改为DNS中为搜索域配置的内容、并且客户端不需要修改、除非它们使用不同的DNS域搜索名称。</block>
  <block id="13c371145cb8e423bcc06c41dafa7d27" category="paragraph">如果Cloud Volumes Service 可以解析本地文件或LDAP中的用户名或组名称、则会使用域字符串、而不匹配的域ID将强制转换为nobody。如果Cloud Volumes Service 在本地文件或LDAP中找不到用户名或组名称、则会使用数字ID值、NFS客户端会正确解析此名称(这类似于NFSv3行为)。</block>
  <block id="2920d1231c77a15a148be7e24a4224a8" category="paragraph">如果不更改客户端的NFSv4.1 ID域以匹配Cloud Volumes Service 卷正在使用的内容、您将看到以下行为：</block>
  <block id="cf7f7139ed9bd9c2ce206642dd7fa858" category="list-text">在Cloud Volumes Service 中具有本地条目的UNIX用户和组(如在本地UNIX用户和组中定义的root)将被强制转换为nobody值。</block>
  <block id="b4aa27a84e1a2079915902824805faed" category="list-text">如果NFS客户端和Cloud Volumes Service 之间的DNS域不同、则具有LDAP条目的UNIX用户和组(如果Cloud Volumes Service 配置为使用LDAP)将强制转换为nobody。</block>
  <block id="ef7ad0d3015777d2990a6af6b71f374b" category="list-text">没有本地条目或LDAP条目的UNIX用户和组使用数字ID值并解析为NFS客户端上指定的名称。如果客户端上不存在任何名称、则仅显示数字ID。</block>
  <block id="62dcf28b3972264f1b30c2bd51a03def" category="paragraph">下面显示了上述情形的结果：</block>
  <block id="696c02f546b2ffcdac74d99c917daa24" category="paragraph">如果客户端ID域和服务器ID域匹配、则相同文件列表的显示方式如下：</block>
  <block id="406ef9702da9a43b3a7b54a25411d799" category="paragraph">有关此问题描述 以及如何解决此问题的详细信息、请参见"<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>。 "</block>
  <block id="feb3aa3308fe030fd35a38b78a2300bd" category="section-title">Kerberos依赖关系</block>
  <block id="40bbfae3ce12130d42058c7017ceb5ed" category="paragraph">如果您计划对NFS使用Kerberos、则Cloud Volumes Service 必须具有以下配置：</block>
  <block id="97a82eff6d3d292af521c01da598a578" category="list-text">Kerberos分发中心服务(KDC)的Active Directory域</block>
  <block id="7539d3051db830d97dee8f6d5d504289" category="list-text">Active Directory域、其中用户和组属性填充了有关LDAP功能的UNIX信息(Cloud Volumes Service 中的NFS Kerberos需要用户SPN到UNIX用户映射才能正常运行。)</block>
  <block id="39780a85d8e7edcc28fd4bc1f6b379f9" category="list-text">已在Cloud Volumes Service 实例上启用LDAP</block>
  <block id="9b306ebe81f909f9a456adcadd197090" category="list-text">DNS服务的Active Directory域</block>
  <block id="3f1e5b600401b83c49c16e0c80170842" category="section-title">NFSv4.1和nobody用户/组</block>
  <block id="5c79e57a072b5ea9e69b08395268c3fe" category="paragraph">NFSv4.1配置中最常见的问题之一是、如果列表中使用`ls`显示的文件或文件夹属于`user：group` combination of `nobody：nobody`。</block>
  <block id="2436a7de6f774d774219a86839e40d54" category="paragraph">数字ID为`99`。</block>
  <block id="89429eb5e6061e2e0b04707c39588b82" category="paragraph">在某些情况下、文件可能会显示正确的所有者、但会显示组`nobody`。</block>
  <block id="8155be8c03c24d2ae2a39ba5b9659708" category="paragraph">谁不是谁？</block>
  <block id="01e2f333d529d07a7774464ebe7c0d52" category="paragraph">NFSv4.1中的`nobody`用户与`nfsnobody`用户不同。您可以运行`id`命令来查看NFS客户端如何识别每个用户：</block>
  <block id="bb1a16c53f7bf27e8010e55518128316" category="paragraph">使用NFSv4.1时、`nobody`用户是由`idmapd.conf`文件定义的默认用户、可定义为要使用的任何用户。</block>
  <block id="25df38609547f38c12a30d2f7fa376e3" category="paragraph">为什么会发生这种情况？</block>
  <block id="0c52fa2fe9ffee5f1757712d7b9151d3" category="paragraph">由于通过名称字符串映射实现安全性是NFSv4.1操作的关键要素、因此、如果名称字符串不匹配、则默认行为是将该用户强制转换为通常无法访问用户和组所拥有的文件和文件夹的用户。</block>
  <block id="ee345fce71ab8dd58d64ab30df90665d" category="paragraph">如果您在文件列表中看到用户和/或组的`nobody`、则这通常意味着NFSv4.1中的某些内容配置不当。区分大小写可以在此处发挥作用。</block>
  <block id="6f0eaeb67bf8645d4cb5b6d6634d62e9" category="paragraph">例如、如果user1@CVSDEMO.LOCAL (uid 1234、gid 1234)正在访问导出、则Cloud Volumes Service 必须能够找到user1@CVSDEMO.LOCAL (uid 1234、gid 1234)。如果Cloud Volumes Service 中的用户为USER1@CVSDEMO.LOCAL、则不匹配(大写用户1与小写用户1)。在许多情况下、您可以在客户端上的消息文件中看到以下内容：</block>
  <block id="501dfba2ca7e696ebe3828fe0a72358d" category="paragraph">客户端和服务器都必须同意用户确实是他们所声称的用户、因此您必须检查以下内容、以确保客户端看到的用户与Cloud Volumes Service 看到的用户具有相同的信息。</block>
  <block id="c45f88d46edf246ef524b5ae57bfd939" category="list-text">* NFSv4.x ID域。*客户端：`idmapd.conf` file；Cloud Volumes Service 使用`defaultv4iddomain.com`、无法手动更改。如果将LDAP与NFSv4.1结合使用、则Cloud Volumes Service 会将ID域更改为DNS搜索域所使用的域、该域与AD域相同。</block>
  <block id="4ad682a8c77e394fdf80dd7dc8013933" category="list-text">*用户名和数字ID。*这决定了客户端查找用户名的位置、并利用名称服务开关配置—client：`nsswitch.conf`和/或本地passwd和group文件；Cloud Volumes Service 不允许修改此设置、但在启用LDAP后会自动将其添加到配置中。</block>
  <block id="278ba27763f1a046a43e86bd394f831b" category="list-text">*组名称和数字ID。*这决定了客户端查找组名称的位置、并利用名称服务开关配置—client：`nsswitch.conf`和/或本地passwd和group文件；Cloud Volumes Service 不允许修改此设置、但会在启用LDAP后自动将其添加到配置中。</block>
  <block id="6b9ce9cbf95dd872dc03e91534746dc9" category="paragraph">在几乎所有情况下、如果您在客户端的用户和组列表中看到`nobody`、则问题描述 将在Cloud Volumes Service 和NFS客户端之间进行用户或组名称域ID转换。要避免这种情况、请使用LDAP在客户端和Cloud Volumes Service 之间解析用户和组信息。</block>
  <block id="55c4b4ea1ecc6c7d5d39c90a0b42830f" category="section-title">查看客户端上NFSv4.1的名称ID字符串</block>
  <block id="c194a1cc7281e9894e494f5ccc1267d9" category="paragraph">如果您使用的是NFSv4.1、则会在NFS操作期间进行名称-字符串映射、如上所述。</block>
  <block id="600a8e1223f644dfc8fc6d9eaf7c6585" category="inline-link">nfsidmap -l</block>
  <block id="315b0c6cb599d172afa3879fb5aff687" category="paragraph">除了使用`/var/log/messages`查找具有NFSv4 ID的问题描述 之外、您还可以使用<block ref="b0f2e0837ffda1ff0550aeef038779e7" category="inline-link-rx"></block> 命令以查看哪些用户名已正确映射到NFSv4域。</block>
  <block id="c72321f4072e32fa1625318fcee53b38" category="paragraph">例如、这是客户端发现的用户以及Cloud Volumes Service 访问NFSv4.x挂载后命令的输出：</block>
  <block id="7fdd86c292924f1df8a7d9127ece25dc" category="paragraph">如果某个用户未正确映射到NFSv4.1 ID域(在本例中为`netapp-user`)、则会尝试访问同一挂载并触摸某个文件、系统会按预期为其分配`nobody：nobody`。</block>
  <block id="bf667093961d1f59e9282ef8a28d89f7" category="paragraph">`nfsidmap -l`输出会在屏幕上显示用户`pcuser`、但不会显示`netapp-user`；这是我们导出策略规则中的匿名用户(`65534`)。</block>
  <block id="f054dd8cc88786d8030b18d90271f377" category="summary">Cloud Volumes Service 公开多个TCP端口来提供NFS和SMB共享。</block>
  <block id="c5381dc540506dbb210e2d300554e4cd" category="doc">防火墙：</block>
  <block id="1e45092c94634e40f68ce647e16109a4" category="paragraph">Cloud Volumes Service 公开多个TCP端口以提供NFS和SMB共享：</block>
  <block id="8ace993e6a8c37342617dbf22185890a" category="inline-link">NFS访问所需的端口</block>
  <block id="259c7a7ef42d8165caa2c0238cb6f9fe" category="inline-link">SMB访问所需的端口</block>
  <block id="48e54afcf03ca45bfe38f6b7ff58764a" category="inline-link">已配置</block>
  <block id="2957bc03d53f1be7c11d427906ed1479" category="inline-link">基于DNS的DC发现</block>
  <block id="02d7b2e18b6bb033bf88be07d39aab4c" category="inline-link">加入Cloud Volumes Service</block>
  <block id="934adb56d62c2e8a1334785cbb6d4987" category="inline-link">将端口公开到此处所述的Cloud Volumes Service CIDR中</block>
  <block id="4a3327b1b286d1e67b6b26ccadab7e11" category="paragraph">联系我们、电子邮件地址为：mailto：doccomments@netapp.com^ doccomments@netapp.com。在主题行中包含技术报告4918。</block>
  <block id="8a7d64073f6ea3e3562e48ad7babe165" category="summary">NAS协议包括NFS (v3和v4.1)和SMB/CIFS (2.x和3.x)。这些协议是CVS允许在多个NAS客户端之间共享访问数据的方式。此外、Cloud Volumes Service 还可以同时提供对NFS和SMB/CIFS客户端的访问(双协议)、同时遵守NAS共享中文件和文件夹的所有身份和权限设置。</block>
  <block id="90654829f21fcf187b576a4c4bad0d65" category="doc">NAS协议概述</block>
  <block id="2ea1602d2ad8b38f601e3e9a049c625d" category="paragraph">NAS协议包括NFS (v3和v4.1)和SMB/CIFS (2.x和3.x)。这些协议是CVS允许在多个NAS客户端之间共享访问数据的方式。此外、Cloud Volumes Service 还可以同时提供对NFS和SMB/CIFS客户端的访问(双协议)、同时遵守NAS共享中文件和文件夹的所有身份和权限设置。为了保持尽可能高的数据传输安全性、Cloud Volumes Service 支持使用SMB加密和NFS Kerberos 5p进行协议加密。</block>
  <block id="4fbbc372dd84225f54ba28f08d3ff4c7" category="admonition">双协议仅适用于CVS-Performance。</block>
  <block id="be0bbf78cc02e3b8c5c134bc7dd71544" category="summary">对Cloud Volumes Service 执行的所有管理操作均通过API完成。集成到GCP云控制台的Cloud Volumes Service 管理也使用Cloud Volumes Service API。</block>
  <block id="dd03419f7f2124dca2e83694ae1b7211" category="doc">控制平面架构</block>
  <block id="791716f366839a73d41b8ac1ae95bad0" category="section-title">身份和访问管理</block>
  <block id="41dff7155cc7aeb11c06434f6a450bb3" category="inline-link">IAM</block>
  <block id="d0455114933a93b857dff40ad9829c80" category="paragraph">身份和访问管理 <block ref="3e7f3b73b3f103986fbe162302b5e57e" category="inline-link-rx"></block>)是一项标准服务、可用于控制对Google Cloud项目实例的身份验证(登录)和授权(权限)。Google IAM可提供权限授权和删除的完整审核跟踪。目前、Cloud Volumes Service 不提供控制平面审核。</block>
  <block id="697308a09680ed006fe009f5a90fd74c" category="section-title">授权/权限概述</block>
  <block id="cb5b383a5c27210bdf8f2fd443c68ebb" category="inline-link">在此填写粒度权限列表</block>
  <block id="f6c6a3fb346fa0197c1eeba05a4736c6" category="paragraph">IAM还提供了两个预定义角色、称为`netappcloudvolumes.admin`和`netappcloudvolumes.viewer`。可以将这些角色分配给特定用户或服务帐户。</block>
  <block id="6d90e176a60105dd03d5580c615cc5fe" category="paragraph">分配适当的角色和权限以允许IAM用户管理Cloud Volumes Service。</block>
  <block id="010558e705f1d93db66b5a129431b39d" category="paragraph">使用粒度权限的示例包括：</block>
  <block id="cf95655b33a1e3a77d897074d8353e7e" category="list-text">仅使用获取/列表/创建/更新权限构建自定义角色、以使用户无法删除卷。</block>
  <block id="fdc24340d58c0f0e7d38a4a3f6a7218c" category="list-text">使用仅具有`snapshot.*`权限的自定义角色创建用于构建应用程序一致的Snapshot集成的服务帐户。</block>
  <block id="b1ef9a9445de9905dc5e0ab77e08e183" category="list-text">构建自定义角色、将`volumereplication *`委派给特定用户。</block>
  <block id="c33f7c2cbeaca5f1462c1b3e1c276145" category="section-title">服务帐户</block>
  <block id="303e96f80576360d0c7b07ae7528fa4b" category="inline-link">Terraform</block>
  <block id="b6d8efd38d2a5551a2c43104314740bd" category="paragraph">通过脚本或进行Cloud Volumes Service API调用<block ref="d99d6c9612fe6a2189c372e0abf640d5" category="inline-link-rx"></block>、您必须创建一个具有`角色/netappcloudvolumes.admin`角色的服务帐户。您可以使用此服务帐户通过两种不同的方式生成对Cloud Volumes Service API请求进行身份验证所需的JWT令牌：</block>
  <block id="87cacfdb2dd389d5d00fef712c2f874b" category="list-text">生成JSON密钥并使用Google API从该密钥派生JWT令牌。这是最简单的方法、但涉及手动密钥(JSON密钥)管理。</block>
  <block id="d77fb2baf15918343921ee724cfacb2f" category="inline-link">服务帐户模拟</block>
  <block id="9d8270b5a4616fc246d5f96cccc9f61e" category="inline-link">应用程序默认凭据</block>
  <block id="c1f48ac217f6b993bda4f82835777177" category="list-text">使用 ...<block ref="09540132e155f93461287a2e21a4e25d" category="inline-link-rx"></block> 使用`Roles/iam.serviceAccountTokenCreator`。代码(脚本、Terraform等)运行<block ref="ffba44c35d88772fc8c63157b8dc0cf7" category="inline-link-rx"></block> 并模拟服务帐户以获取其权限。此方法反映了Google的安全最佳实践。</block>
  <block id="01aa2fa55c64df5a4122b637c9ababc7" category="inline-link">正在创建服务帐户和私钥</block>
  <block id="a325b85a1545e8c507701fb5aa32e6b8" category="section-title">Cloud Volumes Service API</block>
  <block id="d06e940dcf329e87ca49cb2a665f5fd8" category="inline-link">Google云文档中的Cloud Volumes API</block>
  <block id="de13c3e3b25af602f2652dd51a503a8a" category="paragraph">API端点由NetApp使用标准HTTPS (TLSv1.2)功能进行操作和保护。</block>
  <block id="8eac7c9151aa7742216ac387e27479a7" category="section-title">JWT令牌</block>
  <block id="56ebd33e81a27d6c3c78f2f67f2d3c1a" category="inline-link">RFC-7519</block>
  <block id="f2c16a4802323f9b9c1ac55acf92645f" category="paragraph">使用JWT承载令牌对API进行身份验证 <block ref="89a64c0d993ae56a4af8e7ccde6ee59e" category="inline-link-rx"></block>）。必须使用Google Cloud IAM身份验证获取有效的JWT令牌。必须通过提供服务帐户JSON密钥从IAM提取令牌来完成此操作。</block>
  <block id="f45362733fe1dd1af3c58ae64471d466" category="section-title">审核日志记录</block>
  <block id="1ccbd48d467dc56358432c49ba82e95a" category="paragraph">目前、没有用户可访问的控制平面审核日志。</block>
  <block id="9dfacef1e7d01943a3363c481a0ab54f" category="summary">适用于Google Cloud的Cloud Volumes Service 利用Google Cloud私有服务访问框架。在此框架中、用户可以连接到Cloud Volumes Service。此框架像使用其他Google Cloud服务一样使用服务网络和VPC对等结构、确保租户之间完全隔离。</block>
  <block id="65d49b550fb0a0afd0ad601dc275ea12" category="doc">数据平台架构</block>
  <block id="57e0a1cde7582cc59173756aff450054" category="paragraph">适用于Google Cloud的Cloud Volumes Service 利用了Google Cloud<block ref="466f20229cc0e1fa2efa2b4b45528417" category="inline-link-rx"></block> 框架。在此框架中、用户可以连接到Cloud Volumes Service。此框架像使用其他Google Cloud服务一样使用服务网络和VPC对等结构、确保租户之间完全隔离。</block>
  <block id="fabc0e878e19ad7e95bb8e906ab9e8a1" category="inline-link">适用于Cloud Volumes Service 的架构</block>
  <block id="81001e33ae42635e6a292ced69cda439" category="paragraph">有关适用于Google Cloud的Cloud Volumes Service 架构概述、请参见<block ref="7e96ff285aa6f06b814f61dc37a8da61" category="inline-link-rx"></block>。</block>
  <block id="dcfa6d27a1891efb4ad8492d3a127b28" category="paragraph">用户vPC (独立或共享)与托管卷的Cloud Volumes Service 托管租户项目中的vPC建立对等关系。</block>
  <block id="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="paragraph"><block ref="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e3d4716c5a2ddac5bbd6a03d58d03af" category="paragraph">上图显示了一个项目(中间为CVS使用者项目)、其中三个VPC网络连接到Cloud Volumes Service 、多个计算引擎VM (GCE1-7)共享卷：</block>
  <block id="fbf1e8aceed7750d8ed8c4e7168cdb02" category="list-text">VC1允许GCE1访问卷A和B</block>
  <block id="dc5d4ca9052ec8ea299a69ef985a32b0" category="list-text">VPC2允许GCE2和GCE4访问卷C</block>
  <block id="3274f78cc9286288af4912642932b72e" category="list-text">第三个VPC网络是一个共享VPC、与两个服务项目共享。它允许GCE3、GCE4、GCE5和GCE6访问卷D和E只有CVS-Performance服务类型的卷才支持共享VPC网络。</block>
  <block id="be3759e5f4a6574585df9e1159c20c30" category="admonition">GCE7无法访问任何卷。</block>
  <block id="597134b02aeec788dec5f24fa0adba89" category="paragraph">可以在Cloud Volumes Service 中对传输中(使用Kerberos和/或SMB加密)和空闲数据进行加密。</block>
  <block id="3e7c5a939584e1a53201dd8eddfe85d1" category="summary">Cloud Volumes Service 采用与其他Google Cloud原生 服务类似的方式、例如CloudSQL、Google Cloud VMware Engine (GCVE)和Filestore、使用Google PSA提供此服务。</block>
  <block id="16929468b925d0d420441bcbba519e7d" category="doc">Cloud Volumes Service 架构</block>
  <block id="98cdf6a29cf39ecd5239e5071cb0dc88" category="inline-link">Google PSA</block>
  <block id="d4d6aaf620a68430d28b38f847f2a6af" category="inline-link">VPC网络对等</block>
  <block id="353164decd5aa0c4f58b4e56559e1b13" category="inline-link">架构部分</block>
  <block id="8055d5a25a1838f115c8636545abb21a" category="paragraph"><block ref="8055d5a25a1838f115c8636545abb21a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6f34964d3060f5dd66e2cc7c8711679" category="paragraph">虚线上方的部分显示服务的控制平面、控制卷生命周期。虚线下方的部分显示数据平面。左侧蓝色框表示用户VPC (服务使用者)、右侧蓝色框表示NetApp提供的服务生产者。两者均通过VPC对等连接。</block>
  <block id="0d127864a05110e3053c2690dea7d914" category="section-title">租户模式</block>
  <block id="dc947df9f7b14883cbc411bc0a7de469" category="paragraph">在Cloud Volumes Service 中、各个项目被视为唯一租户。这意味着、卷、Snapshot副本等操作是按项目执行的。换言之、所有卷均归在中创建它们的项目所有、默认情况下、只有该项目才能管理和访问其中的数据。这被视为服务的控制面板视图。</block>
  <block id="b9ea9f76a11191d80f8fe1abc9437eb6" category="section-title">共享 vPC</block>
  <block id="cc11b3be8b129e07961938139b138eb5" category="paragraph">在数据平面视图中、Cloud Volumes Service 可以连接到共享VPC。您可以在托管项目中或连接到共享VPC的某个服务项目中创建卷。连接到此共享VPC的所有项目(主机或服务)均可访问网络层(TCP/IP)上的卷。由于共享VPC上具有网络连接的所有客户端都可能通过NAS协议访问数据、因此必须使用单个卷上的访问控制(例如、NFS导出的用户/组访问控制列表(ACL)和主机名/IP地址)来控制谁可以访问数据。</block>
  <block id="0b97558649d416ff7a157c6ebb3415d9" category="paragraph">每个客户项目最多可以将Cloud Volumes Service 连接到五个vPC。在控制平面上、您可以通过该项目管理所有已创建的卷、无论这些卷连接到哪个VPC。在数据平面上、VPC彼此隔离、每个卷只能连接到一个VPC。</block>
  <block id="be52fe1bd184b72048acd2ba911bb069" category="paragraph">对各个卷的访问由特定协议(NFS/SMB)访问控制机制控制。</block>
  <block id="a3328901555fee8fe9134fc5bd6e641b" category="paragraph">换言之、在网络层、连接到共享VPC的所有项目都能够看到卷、而在管理端、控制平面仅允许所有者项目查看卷。</block>
  <block id="90f3668b3811dddcb8de24b77c6a6d64" category="section-title">VPC服务控制</block>
  <block id="d5fc4459a5e756d9c4ad2c88c260092b" category="paragraph">VPC服务控制功能可围绕连接到互联网且可在全球访问的Google Cloud服务建立访问控制边界。这些服务可通过用户身份提供访问控制、但不能限制发出哪些网络位置请求。VPC服务控制通过引入限制对定义的网络的访问的功能来缩小这一差距。</block>
  <block id="601553f09795c6051748c4f4f63ce893" category="paragraph">Cloud Volumes Service 数据平面不会连接到外部Internet、而是连接到具有明确定义的网络边界(边界)的私有VPC。在该网络中、每个卷都使用特定于协议的访问控制。任何外部网络连接均由Google Cloud项目管理员明确创建。但是、控制平面不提供与数据平面相同的保护、任何人都可以使用有效凭据(<block ref="f0e6a8c8639b1f1713f124143221142a" category="inline-link-rx"></block>）。</block>
  <block id="7755a392158406ad802334080cd41f73" category="paragraph">简而言之、Cloud Volumes Service 数据平面可提供网络访问控制功能、无需支持VPC服务控制、也不明确使用VPC服务控制。</block>
  <block id="892d60d0a1c71243b5ddff2c66ed584c" category="section-title">数据包嗅探/跟踪注意事项</block>
  <block id="93b0389d05d1b6926967749b8692f2f6" category="paragraph">数据包捕获对于解决网络问题或其他问题(例如NAS权限、LDAP连接等)非常有用、但也可以恶意使用数据包捕获来获取有关网络IP地址、MAC地址、用户和组名称以及端点上使用的安全级别的信息。由于配置Google Cloud网络、VPC和防火墙规则的方式、如果没有用户登录凭据或、则很难获取对网络数据包的不必要访问 <block ref="2a18c6d0cd80103144f47d02366a785f" category="inline-link-macro-rx"></block> 迁移到云实例。只有端点(如虚拟机(VM))才可以捕获数据包、只有VPC内部的端点才可以捕获数据包、除非使用共享VPC和/或外部网络通道/IP转发明确允许外部流量传输到端点。无法嗅探客户端外部的流量。</block>
  <block id="ce58b63a24bebe6bac29cfe248428477" category="paragraph"><block ref="ce58b63a24bebe6bac29cfe248428477" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c72e76f5c978aa82e296df17081b6836" category="admonition">unixUserPassword由LDAP查询、不会以纯文本形式发送、而是以盐哈希形式发送。默认情况下、Windows LDAP不会填充unixUserPassword字段。只有在需要利用Windows LDAP通过LDAP交互式登录到客户端时、才需要此字段。Cloud Volumes Service 不支持对实例进行交互式LDAP登录。</block>
  <block id="01b21a51d124432b5b7fe641eae6a004" category="paragraph">下图显示了通过AUTH_SYS捕获NFS旁边的NFS Kerberos对话中的数据包捕获。请注意、跟踪中提供的信息在这两者之间有何不同、以及启用动态加密如何为NAS流量提供更高的整体安全性。</block>
  <block id="0d66010f122b3df766abd8a0cb2ff598" category="paragraph"><block ref="0d66010f122b3df766abd8a0cb2ff598" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ba81028f56cfd4f5e21c7102a8eff68" category="paragraph"><block ref="5ba81028f56cfd4f5e21c7102a8eff68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04aa3ce627dbf5b220c8aa6d4955fb34" category="section-title">VM网络接口</block>
  <block id="8ec45d68b7d371d25a3b82a76db3142b" category="inline-link">混杂模式</block>
  <block id="e59b81e20588b0d3a3c495a545d75322" category="paragraph">攻击者可能会尝试的一个技巧是、在中向虚拟机添加新的网络接口卡(Network Interface Card、NIC)<block ref="39c80826df1f145e2784d4b04af9d477" category="inline-link-rx"></block> (端口镜像)或在现有NIC上启用混杂模式以嗅探所有流量。在Google Cloud中、添加新的NIC需要完全关闭虚拟机、这样会创建警报、因此攻击者无法在无人察觉的情况下执行此操作。</block>
  <block id="b726bce4fa04e9b7a6d788f212f00c17" category="paragraph">此外、NIC根本无法设置为混杂模式、并会在Google Cloud中触发警报。</block>
  <block id="599e7197321e9ab772426d7187714f67" category="summary">SMB是Microsoft开发的一种网络文件共享协议、可通过以太网为多个SMB客户端提供集中式用户/组身份验证、权限、锁定和文件共享。</block>
  <block id="b4fdd997b1f33e0d4c6964444c2bf399" category="doc">SMB</block>
  <block id="e0a515b0910f55d3d1d5adda978e8e4f" category="paragraph"><block ref="395dbbdb78e4ae6be8daf8ab2b7828a7" category="inline-link-rx"></block> 是Microsoft开发的一种网络文件共享协议、可通过以太网为多个SMB客户端提供集中式用户/组身份验证、权限、锁定和文件共享。文件和文件夹通过共享呈现给客户端、共享可以配置各种共享属性、并通过共享级别权限提供访问控制。SMB可以提供给提供协议支持的任何客户端、包括Windows、Apple和Linux客户端。</block>
  <block id="63f2e3eee09c9d71b23530e2205eb36a" category="paragraph">Cloud Volumes Service 支持SMB 2.1和3.x版本的协议。</block>
  <block id="cc4a835dfb2ac9e7ba402c068a4ef9a0" category="section-title">访问控制/SMB共享</block>
  <block id="f122c057113b41c182d10fddf2a82817" category="list-text">当Windows用户名请求访问Cloud Volumes Service 卷时、Cloud Volumes Service 会使用Cloud Volumes Service 管理员配置的方法查找UNIX用户名。</block>
  <block id="ac960a1b86a1625e4ff98dbb3feef120" category="list-text">如果配置了外部UNIX身份提供程序(LDAP)、并且Windows/UNIX用户名相同、则Windows用户名将1：1映射到UNIX用户名、而无需任何其他配置。启用LDAP后、Active Directory用于托管用户和组对象的这些UNIX属性。</block>
  <block id="3c60aff1fcf4407fc40492eebac8e37b" category="inline-link-macro">"使用LDAP进行非对称名称映射"</block>
  <block id="e4adb9d6d8d5650dfb0663dde5495dff" category="list-text">如果Windows名称和UNIX名称不匹配、则必须将LDAP配置为允许Cloud Volumes Service 使用LDAP名称映射配置(请参见一节) <block ref="1cca6755f54a82023ec645e8be5d4c82" category="inline-link-macro-rx"></block>）。</block>
  <block id="5205bf34161159f00d7f28cb5e6e2a89" category="list-text">如果未使用LDAP、则Windows SMB用户会映射到Cloud Volumes Service 中名为`pcuser`的默认本地UNIX用户。这意味着在多协议NAS环境中、映射到`pcuser`的用户在Windows中写入的文件将UNIX所有权显示为`pcuser`。`pcuser`此处是Linux环境中的`nobody`用户(UID 65534)。</block>
  <block id="0ff58f508b02c651e0b4ee271b1792d9" category="paragraph">在仅使用SMB的部署中、仍会进行`pcuser`映射、但这无关紧要、因为Windows用户和组所有权会正确显示、并且不允许对仅使用SMB的卷进行NFS访问。此外、仅SMB卷在创建后不支持转换为NFS或双协议卷。</block>
  <block id="9327392a148953617bfae88e7e46a666" category="paragraph">Windows利用Kerberos与Active Directory域控制器进行用户名身份验证、这需要与AD DC进行用户名/密码交换、AD DC位于Cloud Volumes Service 实例外部。如果SMB客户端使用`\\servername` UNC路径且满足以下条件、则会使用Kerberos身份验证：</block>
  <block id="61caea7c1c859702c330a0781763fd23" category="list-text">服务器名称存在DNS A/AAAA条目</block>
  <block id="de4327d512f4e62f9b3ae80f8bb719cc" category="list-text">服务器名称存在有效的SMB/CIFS访问SPN</block>
  <block id="f5c19a901f7d9431872c0e8893aaa498" category="inline-link-macro">《Cloud Volumes Service 在Active Directory中的显示方式》。</block>
  <block id="93c756ce24f344cc333703bcd2e7a06e" category="paragraph">创建Cloud Volumes Service SMB卷时、系统会按照一节中的定义创建计算机帐户名称 <block ref="087d516981f271a0b6f0df624ae1e840" category="inline-link-macro-rx"></block> 该计算机帐户名称也会成为SMB共享访问路径、因为Cloud Volumes Service 利用动态DNS (DDNS)在DNS中创建必要的A/AAAA和PTR条目、并在计算机帐户主体上创建必要的SPN条目。</block>
  <block id="aafa8c8c59e359a65d0c657f05772244" category="admonition">要创建PTR条目、DNS服务器上必须存在Cloud Volumes Service 实例IP地址的反向查找区域。</block>
  <block id="ecd31d9efcb752f09a0690c2f62bf88f" category="paragraph">例如、此Cloud Volumes Service 卷使用以下UNC共享路径：`\\cvs-east- 433d.cvsdema.local`。</block>
  <block id="c6ee58936680de9d2229f523a4c54ffb" category="paragraph">在Active Directory中、这些是Cloud Volumes Service生成的SPN条目：</block>
  <block id="5c3c803198a53be899a500a43fcf1d24" category="paragraph"><block ref="5c3c803198a53be899a500a43fcf1d24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97422e33b69a5567af9908d5b2d397fc" category="paragraph">这是DNS正向/反向查找结果：</block>
  <block id="1d3d964bf7fdd6249507cb3738908e54" category="paragraph">或者、可以通过在Cloud Volumes Service 中为SMB共享启用/要求SMB加密来应用更多访问控制。如果其中一个端点不支持SMB加密、则不允许访问。</block>
  <block id="e5e9be92303e18ef3f22dfa57dcbd0d3" category="section-title">使用SMB名称别名</block>
  <block id="500c4de8d7a022d507313e514b85d485" category="paragraph">在某些情况下、如果最终用户知道Cloud Volumes Service 使用的计算机帐户名称、则可能会出于安全考虑。在其他情况下、您可能只想为最终用户提供一个更简单的访问路径。在这种情况下、您可以创建SMB别名。</block>
  <block id="6c7c194988807a9112adc7f6bc9b1dd5" category="paragraph">如果要为SMB共享路径创建别名、可以利用DNS中的CNAME记录。例如、如果您要使用名称`\\cifs`来访问共享、而不是`\\cvs-east- 433d.cvsdema.local`、但您仍要使用Kerberos身份验证、则DNS中指向现有A/AAAA记录的CNAME以及添加到现有计算机帐户的其他SPN可提供Kerberos访问。</block>
  <block id="620b0e4f14250d32e58b3411c5fd3044" category="paragraph"><block ref="620b0e4f14250d32e58b3411c5fd3044" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a030a66483dc3115cd014273bad041d" category="paragraph">这是添加CNAME后生成的DNS正向查找结果：</block>
  <block id="97ec437207d5ac6fb22613655e7e395e" category="paragraph">这是添加新SPN后生成的SPN查询：</block>
  <block id="5730e2788651b014b918d2ee1bfdfe67" category="paragraph"><block ref="5730e2788651b014b918d2ee1bfdfe67" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df91b2b002b78b2f9f87c79b56293060" category="paragraph">在数据包捕获中、我们可以使用与CNAME绑定的SPN查看会话设置请求。</block>
  <block id="8b36b24049a6cda34019fd47ea0273fc" category="paragraph"><block ref="8b36b24049a6cda34019fd47ea0273fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65cc39e4fb8a95d5fcc2098d620ff3b6" category="section-title">SMB身份验证方言</block>
  <block id="fe9fdc3d8157e10bf5b31e8d28fe7827" category="inline-link">方言</block>
  <block id="c50c24feef6ada40d8e2f7be85359c0f" category="paragraph">Cloud Volumes Service 支持以下功能<block ref="88f3097f4ad7d144185bbacf0330fbeb" category="inline-link-rx"></block> 对于SMB身份验证：</block>
  <block id="dfd5b430bc4db2c2836d0227ad9ac0c4" category="list-text">LM</block>
  <block id="d11322c1a7a2383491c23f13113c59ea" category="list-text">NTLM</block>
  <block id="d0952ee882764dd5c3105f5b23a3e505" category="list-text">NTLMv2</block>
  <block id="87b3695bfd6f672e2c7c4da7ca2b46a8" category="list-text">Kerberos</block>
  <block id="11012bc0af4eda341c391c39cf6aa27c" category="paragraph">用于SMB共享访问的Kerberos身份验证是您可以使用的最安全的身份验证级别。启用AES和SMB加密后、安全级别将进一步提高。</block>
  <block id="e5c584f1ac6fa07c9594321f8fc845e2" category="paragraph">Cloud Volumes Service 还支持LM和NTLM身份验证的向后兼容性。如果Kerberos配置不当(例如创建SMB别名)、则共享访问会回退到身份验证方法较弱的位置(例如NTLMv2)。由于这些机制的安全性较低、因此在某些Active Directory环境中会禁用它们。如果禁用了较弱的身份验证方法、并且未正确配置Kerberos、则共享访问将失败、因为没有可回退的有效身份验证方法。</block>
  <block id="d87250f3f8075c2dfbcfe941d0c7bde9" category="inline-link">网络安全：LAN Manager身份验证级别</block>
  <block id="f4457a3dba045094cb39418e2233c8c1" category="paragraph">有关在Active Directory中配置/查看受支持的身份验证级别的信息、请参见<block ref="d671b936eec72b8caa6e3a555955a849" category="inline-link-rx"></block>。</block>
  <block id="6ccfb9a0791b337d38ef8ff2cdf26cf8" category="section-title">权限模式</block>
  <block id="b1728e361f14c53940f081871f87e6ee" category="section-title">NTFS/文件权限</block>
  <block id="3e5348fb86c26b3cabf2912e6e597902" category="paragraph">NTFS权限是指应用于符合NTFS逻辑的文件系统中的文件和文件夹的权限。您可以在`基本`或`高级`中应用NTFS权限、并可设置为`允许`或`D允许`来进行访问控制。</block>
  <block id="80b0c49680a2b15ae6a40273fadefaa8" category="paragraph">基本权限包括：</block>
  <block id="704a2a0ea2e007dae9f25d038a988076" category="list-text">完全控制</block>
  <block id="7f090bbab1cc7f9c08bf4e54d932d3c0" category="list-text">修改</block>
  <block id="3ed713666b4f5112539dd5ffb9376ff4" category="list-text">读取和执行</block>
  <block id="7a1a5f3e79fdc91edf2f5ead9d66abb4" category="list-text">读取</block>
  <block id="1129c0e4d43f2d121652a7302712cff6" category="list-text">写入</block>
  <block id="75484cb1059b92206b918bde1204007a" category="paragraph">为用户或组(称为ACE)设置权限时、该用户或组驻留在ACL中。NTFS权限使用与UNIX模式位相同的读/写/执行基础知识、但也可以扩展到更精细的扩展访问控制(也称为"特殊权限")、例如"获取所有权"、"创建文件夹/附加数据"、"写入属性"等。</block>
  <block id="77636166006179e57dc5edc6df25b80c" category="paragraph">标准UNIX模式位提供的粒度级别与NTFS权限不同(例如、能够为ACL中的各个用户和组对象设置权限或设置扩展属性)。但是、NFSv4.1 ACL提供的功能与NTFS ACL相同。</block>
  <block id="9434d016806e0f50ac7f14efbfa3a3df" category="paragraph">NTFS权限比共享权限更具体、可与共享权限结合使用。对于NTFS权限结构、限制性最强。因此、在定义访问权限时、显式拒绝用户或组甚至会覆盖"完全控制"。</block>
  <block id="c0ad12f90a714e04744ab070d26a9c80" category="paragraph">NTFS权限由Windows SMB客户端控制。</block>
  <block id="ef950b5546945ec414f9da7909c4fe8a" category="section-title">共享权限</block>
  <block id="3df5ef25e4045d2e51c43effb69aa5de" category="paragraph">共享权限比NTFS权限更常规(仅限读取/更改/完全控制)、并可控制SMB共享的初始条目、类似于NFS导出策略规则的工作方式。</block>
  <block id="41123e00ec2463c8d7c60a10f3d3ede4" category="paragraph">虽然NFS导出策略规则通过IP地址或主机名等基于主机的信息来控制访问、但SMB共享权限可以通过使用共享ACL中的用户和组ACE来控制访问。您可以从Windows客户端或Cloud Volumes Service 管理UI设置共享ACL。</block>
  <block id="7f455f054b3ad11fb335d2f9ec69e3ff" category="paragraph">默认情况下、共享ACL和初始卷ACL包括具有完全控制的Everyone。应更改文件ACL、但共享权限会被共享中对象的文件权限所取代。</block>
  <block id="8d37bee954f03966b12b65871768a438" category="paragraph">例如、如果仅允许用户读取Cloud Volumes Service 卷文件ACL、则即使共享ACL设置为"具有完全控制的所有人"、也会拒绝用户访问创建文件和文件夹、如下图所示。</block>
  <block id="47ff9e7720c14a2a27bfa4ce12bbd268" category="paragraph"><block ref="47ff9e7720c14a2a27bfa4ce12bbd268" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef46360b81c847c0d6f5015920fd5f3e" category="paragraph"><block ref="ef46360b81c847c0d6f5015920fd5f3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="316a22056a64a8465269d31ac436fc22" category="paragraph">要获得最佳安全性结果、请执行以下操作：</block>
  <block id="09fced4bea14e9b030bd1179b95f3b89" category="list-text">从共享和文件ACL中删除Everyone、而是为用户或组设置共享访问权限。</block>
  <block id="8941d253e49282460162b7dac68ad2ba" category="list-text">使用组进行访问控制、而不是使用单个用户、以便于管理、并加快删除/添加用户的速度、以便通过组管理共享ACL。</block>
  <block id="f63df4fd4f9e10c567332b34b05d35ae" category="list-text">允许对共享权限上的ACE进行限制性更低的常规共享访问、并锁定对具有文件权限的用户和组的访问、以实现更精细的访问控制。</block>
  <block id="afe52910905ef63730591f8a01bcb75e" category="list-text">避免常规使用显式拒绝ACL、因为它们会覆盖允许ACL。限制需要限制的用户或组快速访问文件系统时使用显式拒绝ACL。</block>
  <block id="9a2191ac8d9f65679cdf29455149f6cb" category="inline-link">ACL继承</block>
  <block id="780d68252d03e9f7617f6bf5fe95c1ce" category="list-text">请务必注意<block ref="19af65d9616f33b3ccaee367e8d4dc82" category="inline-link-rx"></block> 修改权限时的设置；在文件数量较多的目录或卷的顶层设置继承标志意味着该目录或卷下的每个文件都添加了继承权限、 这可能会在调整每个文件时产生不必要的行为、例如意外访问/拒绝以及长时间更改权限。</block>
  <block id="0c2104afa1bd6c96b5ccc9c7a7ee8a6a" category="section-title">SMB共享安全功能</block>
  <block id="05ec24f8004d55ad7596b79266cd4691" category="paragraph">首次在Cloud Volumes Service 中创建具有SMB访问权限的卷时、系统会为您提供一系列用于保护该卷的选项。</block>
  <block id="53eaeead30ddbd2dcb1526241312aedf" category="paragraph">其中一些选项取决于Cloud Volumes Service 级别(性能或软件)、选项包括：</block>
  <block id="d65a6ba5ce40987a368f3f757b5721ae" category="list-text">*使Snapshot目录可见(可用于CVS-Performance和CVS-SW)。*此选项控制SMB客户端是否可以访问SMB共享中的Snapshot目录(`\\server\share\~snapshot`和/或先前版本选项卡)。默认设置不会选中、这意味着卷默认隐藏和禁止访问`~snapshot`目录、并且卷的"先前版本"选项卡中不会显示任何Snapshot副本。</block>
  <block id="9ebf5e1b6bf20c2942f0add8e979dd7a" category="paragraph"><block ref="9ebf5e1b6bf20c2942f0add8e979dd7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="baf0124343f1806f3ff44f011e92c73f" category="paragraph">出于安全原因、性能原因(从AV扫描中隐藏这些文件夹)或偏好、可能需要向最终用户隐藏Snapshot副本。Cloud Volumes Service 快照是只读的、因此、即使这些快照可见、最终用户也无法删除或修改Snapshot目录中的文件。创建Snapshot副本时对文件或文件夹的文件权限将适用。如果文件或文件夹在Snapshot副本之间的权限发生变化、则所做的更改也会应用于Snapshot目录中的文件或文件夹。用户和组可以根据权限访问这些文件或文件夹。虽然无法删除或修改Snapshot目录中的文件、但可以从Snapshot目录中复制文件或文件夹。</block>
  <block id="2716bd858fb85bb9b111c5d51138cb40" category="list-text">*启用SMB加密(可用于CVS-Performance和CVS-SW)。*默认情况下、SMB共享上禁用SMB加密(未选中)。选中此复选框可启用SMB加密、这意味着SMB客户端和服务器之间的流量将使用协商的最高支持加密级别进行动态加密。Cloud Volumes Service 最多支持对SMB进行AES-256加密。启用SMB加密确实会对SMB客户端造成性能降低、这种降低可能会也可能不会对SMB客户端造成明显影响、大致处于10-20%的范围内。NetApp强烈建议通过测试来确定性能降低是否可接受。</block>
  <block id="ab7715a00a3e7691d84318bb2f1a3bc1" category="list-text">*隐藏SMB共享(可用于CVS-Performance和CVS-SW)。*设置此选项可在正常浏览时隐藏SMB共享路径。这意味着、不知道共享路径的客户端在访问默认UNC路径(例如`\\CVS-SMB`)时无法看到共享。选中此复选框后、只有明确知道SMB共享路径或具有组策略对象定义的共享路径的客户端才能访问此路径(通过混淆实现安全性)。</block>
  <block id="67699a5a5f5ec8d69977d9f44b521201" category="inline-link">基于访问的枚举(ABE)如何工作？</block>
  <block id="eb36f3383eadcd01f954bc9848b7de21" category="list-text">*启用基于访问的枚举(ABE)(仅限CVS-SW)。*这与隐藏SMB共享类似、只是共享或文件仅对无权访问对象的用户或组隐藏。例如、如果至少不允许Windows用户`Joe`通过权限进行读取访问、则Windows用户`Joe`根本看不到SMB共享或文件。默认情况下、此选项处于禁用状态、您可以通过选中此复选框来启用它。有关ABE的详细信息、请参见NetApp知识库文章<block ref="6d2d0139fec74415d85dc1015aa48640" category="inline-link-rx"></block></block>
  <block id="5ff6480cf15803c821d9cc9bb3dcbe5c" category="inline-link">持续可用的SMB共享</block>
  <block id="17faa8cfb0bc70572c6d4f120cb6de10" category="list-text">*启用持续可用(CA)共享支持(仅限CVS-Performance)。*<block ref="97476034cc2961d2c1c061d5bdcc519a" category="inline-link-rx"></block> 通过在Cloud Volumes Service 后端系统中的节点之间复制锁定状态、提供一种在故障转移事件期间最大限度地减少应用程序中断的方法。这不是一项安全功能、但可以提供更好的整体故障恢复能力。目前、此功能仅支持SQL Server和FSLogix应用程序。</block>
  <block id="f816f594817af59eac10c8385f34d319" category="section-title">默认隐藏共享</block>
  <block id="7ce84bf53b21b783ae6c62b61f60f9e3" category="inline-link">隐藏的管理共享</block>
  <block id="31a7b0c828b1a1039c3fe9e855430acd" category="paragraph">在Cloud Volumes Service 中创建SMB服务器时、会显示<block ref="e698db250309574e2563e69229bd950f" category="inline-link-rx"></block> (使用$命名约定)。其中包括C$(命名空间访问)和IPC$(共享命名管道以在程序之间进行通信、例如用于Microsoft管理控制台(MMC)访问的远程操作步骤 调用(RPC))。</block>
  <block id="64667cec654fa57a129c5c1fe752d7ae" category="inline-link">默认情况下、Windows不允许匿名访问这些共享</block>
  <block id="7962a42fa319b5ea9ccf0429193d4f3c" category="paragraph">ipc$共享不包含共享ACL、无法修改—它严格用于RPC调用和<block ref="582b1e06ccfbbf9885ff446ec79f8b0f" category="inline-link-rx"></block>。</block>
  <block id="c2c8a4f76f99f203d14ee3c1adae3c40" category="paragraph">默认情况下、C$共享允许BUILTIN/Administrators访问、但Cloud Volumes Service 自动化会删除共享ACL、并且不允许任何人访问、因为访问C$共享可以查看Cloud Volumes Service 文件系统中所有已挂载的卷。因此、尝试导航到`\\Server\C$`失败。</block>
  <block id="444613ce56f4180cf88b531783a9e3bc" category="section-title">具有本地/BUILTIN管理员/备份权限的帐户</block>
  <block id="5659f387517ed75a127b9a6bda6f1329" category="paragraph">Cloud Volumes Service SMB服务器与常规Windows SMB服务器具有类似的功能、因为有本地组(例如BUILTIN\Administrators)会将访问权限应用于选定域用户和组。</block>
  <block id="709eb202e09b717ba82624b788948428" category="inline-link">SeBackupPrivilege和SeRestorePrivilege</block>
  <block id="03455d8db7797aab1e6e9efe9bf4d2a5" category="paragraph">指定要添加到备份用户的用户时、该用户将添加到使用该Active Directory连接的Cloud Volumes Service 实例中的BUILTIN\Backup Operators组中、然后该组将获取<block ref="3d66e5b4422b04db3b01ddbcafb3649a" category="inline-link-rx"></block>。</block>
  <block id="b5b39a908a856900d75e0b129fb9e349" category="inline-link">SMB共享上的SQL Server</block>
  <block id="52f5e8856edf4d634cf608cb64bec885" category="paragraph">将用户添加到安全权限用户时、系统会为该用户授予SeSecurityPrivilege、这在某些应用程序使用情形下非常有用、例如<block ref="b685ff2242ac25f5022af8207109cc39" category="inline-link-rx"></block>。</block>
  <block id="99c9211b9f5166d96d9e6613c4be9f77" category="paragraph"><block ref="99c9211b9f5166d96d9e6613c4be9f77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59976878f4cfcf8cd4a9bccf37270fec" category="paragraph">您可以使用适当的权限通过MMC查看Cloud Volumes Service 本地组成员资格。下图显示了已使用Cloud Volumes Service 控制台添加的用户。</block>
  <block id="9b02abec53251430b553f5124b676b1f" category="paragraph"><block ref="9b02abec53251430b553f5124b676b1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09e7cb53843328fd35bff1d1075e8e04" category="paragraph">下表显示了默认BUILTIN组的列表以及默认添加的用户/组。</block>
  <block id="52087222d7968b7bd85e5698912f6cee" category="cell">本地/BUILTIN组</block>
  <block id="c899fa178e9ccd9c46154a79773b9e8e" category="cell">默认成员</block>
  <block id="f6c0ddae69a704e001f6cba9fba3f951" category="cell">BUILTIN\Administrators *</block>
  <block id="6930162f33d7d3cc792907afc2d709d6" category="cell">域\域管理员</block>
  <block id="291b9d53abc37bd4eeab64a68607df4f" category="cell">BUILTIN\Backup Operators*</block>
  <block id="f87e4b3cc74234e59b0d07ad558b2c05" category="cell">BUILTIN\guests</block>
  <block id="bea5dc29e529ecf572942e7f6cbbf19b" category="cell">域\域子系统</block>
  <block id="bafee069f6320499a0f630485028a961" category="cell">BUILTIN\Power Users</block>
  <block id="d3ffae89384cc2219d9dc26887d6422c" category="cell">BUILTIN\Domain用户</block>
  <block id="a26444fe66f07a77f6e392ad714158ff" category="cell">域\域用户</block>
  <block id="ee6df957412594fad1ce714d75089e5f" category="paragraph">*组成员资格在Cloud Volumes Service Active Directory连接配置中控制。</block>
  <block id="c648fec724703de3d038fda21e884ef7" category="paragraph">您可以在MMC窗口中查看本地用户和组(以及组成员)、但不能在此控制台中添加或删除对象或更改组成员资格。默认情况下、只有域管理员组和管理员才会添加到Cloud Volumes Service 中的BUILTIN\Administrators组。目前、您无法修改此设置。</block>
  <block id="39aedbfda9a943aea0e4c841bc68dc0a" category="paragraph"><block ref="39aedbfda9a943aea0e4c841bc68dc0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ae7d2b2ec0c231b6934886bf6690c9e" category="paragraph"><block ref="0ae7d2b2ec0c231b6934886bf6690c9e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="255c5bd3cdece4dd4a7891941d9c964e" category="section-title">MMC/计算机管理访问</block>
  <block id="7f956759e187dbb2b65022241e8053cd" category="paragraph">通过Cloud Volumes Service 中的SMB访问、您可以连接到计算机管理MMC、从而可以查看共享、管理共享ACL、以及查看/管理SMB会话和打开的文件。</block>
  <block id="e3d561744b3b4f6ab5953c2f96daaad7" category="paragraph">要使用MMC在Cloud Volumes Service 中查看SMB共享和会话、登录的用户当前必须是域管理员。其他用户可以通过MMC查看或管理SMB服务器、并在尝试查看Cloud Volumes Service SMB实例上的共享或会话时收到"您没有权限"对话框。</block>
  <block id="aaf8b324d80834b9d235cb6b6d84be89" category="paragraph">要连接到SMB服务器、请打开计算机管理、右键单击计算机管理、然后选择连接到另一台计算机。此时将打开选择计算机对话框、在此可以输入SMB服务器名称(可在Cloud Volumes Service 卷信息中找到)。</block>
  <block id="c34ce8bbe19f26cf58867de938f87920" category="paragraph">查看具有适当权限的SMB共享时、您会看到Cloud Volumes Service 实例中共享Active Directory连接的所有可用共享。要控制此行为、请在Cloud Volumes Service 卷实例上设置隐藏SMB共享选项。</block>
  <block id="b939aeb87de29dc576ad4adc5fa19bce" category="paragraph"><block ref="b939aeb87de29dc576ad4adc5fa19bce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c57a1134332b8bafcaa5f411a65b4a49" category="paragraph"><block ref="c57a1134332b8bafcaa5f411a65b4a49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1325fb66f29e707e7e3402f0d45d59dc" category="paragraph">下表列出了MMC支持/不支持的功能。</block>
  <block id="241bac47978fca670a6b9c52e3432067" category="cell">支持的功能</block>
  <block id="fe2de21fdfcaf4ed19a251aab83bf0ff" category="cell">不支持的功能</block>
  <block id="ad338fe21209358afd2f29eee14817c6" category="list-text">查看共享</block>
  <block id="a5dc19ca94f052a57587a2f4f1433678" category="list-text">查看活动的SMB会话</block>
  <block id="ff50826288707e494282b4cf6bec983b" category="list-text">查看打开的文件</block>
  <block id="8c006cf58f2706f56d65e1431b1e128e" category="list-text">查看本地用户和组</block>
  <block id="bad02cc8e307a9ac8bf6899188811a54" category="list-text">查看本地组成员资格</block>
  <block id="5ab1c0d0251d23bc086198a8fc219a69" category="list-text">枚举系统中的会话、文件和树连接列表</block>
  <block id="bd7ff4b31e7eade785d74789a052242c" category="list-text">关闭系统中已打开的文件</block>
  <block id="3a6cd2ea18cf077c57b65c28c40f9851" category="list-text">关闭打开的会话</block>
  <block id="e5ded1413b3fd0a1690184029acf1845" category="list-text">创建 / 管理共享</block>
  <block id="b4d1348a7ae3aa39ac1fbd299a07ebb9" category="list-text">创建新的本地用户 / 组</block>
  <block id="5c3d34e6fdaee1edee0722fcef147f8a" category="list-text">管理/查看现有本地用户/组</block>
  <block id="1c79052ffd16d848acb6278dd54f0d33" category="list-text">查看事件或性能日志</block>
  <block id="eedf037c0977372c4f0adaa359d5f6e0" category="list-text">管理存储</block>
  <block id="d5d1ca904ae55c0d5399eb923b8d6d21" category="list-text">管理服务和应用程序</block>
  <block id="dddaf61539328810b230a60430960038" category="section-title">SMB服务器安全信息</block>
  <block id="7c7ff5a0c882bba2c6d86dc13caa6e49" category="paragraph">Cloud Volumes Service 中的SMB服务器使用一系列选项来定义SMB连接的安全策略、包括Kerberos时钟偏差、票证期限、加密等。</block>
  <block id="bdf80cb84c583e3d6af81c4778921102" category="paragraph">下表列出了这些选项、它们的功能、默认配置以及是否可以使用Cloud Volumes Service 进行修改。某些选项不适用于Cloud Volumes Service。</block>
  <block id="708cc30ece03d9ba30511bea4ea09792" category="cell">安全选项</block>
  <block id="ad67361f283520dada90173b5fbfaad7" category="cell">最大Kerberos时钟间隔(分钟)</block>
  <block id="ebd83f9f3f1a10793a7aaf199f57a32b" category="cell">Cloud Volumes Service 与域控制器之间的最大时间偏差。如果时间偏差超过5分钟、则Kerberos身份验证将失败。此值设置为Active Directory默认值。</block>
  <block id="e4da3b7fbbce2345d7772b0674a318d5" category="cell">5.</block>
  <block id="ccf9068a42f159a1b1cd3e07b84c5ecd" category="cell">Kerberos票证生命周期(小时)</block>
  <block id="34c1c29ec6cffe3b75b5f4db3cd4e12f" category="cell">在要求续订之前、Kerberos票证保持有效的最长时间。如果在10小时之前未发生续订、您必须获取新的服务单。Cloud Volumes Service 会自动执行这些续订。Active Directory默认值为10小时。</block>
  <block id="b63288488b52af4af602d79dce8aa252" category="cell">Kerberos票证续订上限(天)</block>
  <block id="082ea39c709884c3439c0b1e937ee15a" category="cell">在需要新的授权请求之前可以续订Kerberos票证的最长天数。Cloud Volumes Service 会自动续订SMB连接的服务单。Active Directory默认值为七天。</block>
  <block id="8f14e45fceea167a5a36dedd4bea2543" category="cell">7.</block>
  <block id="2127af947646b417ab67c66e82922af5" category="cell">Kerberos KDC连接超时(秒)</block>
  <block id="4a4dfa50ac48d9523d22b929a8df2e01" category="cell">KDC连接超时前的秒数。</block>
  <block id="09b779421f875a0831c9165f7730b710" category="cell">传入SMB流量需要签名</block>
  <block id="8f4c5ae7b0c978c58bbe10790f9eb578" category="cell">设置为SMB流量需要签名。如果设置为true、则不支持签名的客户端连接将失败。</block>
  <block id="c77326ff7e3ae38e2b7ed07e3bff97e8" category="cell">本地用户帐户需要密码复杂度</block>
  <block id="fab3a355aeb5f939ba8dcdc4ae0ea4b8" category="cell">用于本地SMB用户的密码。Cloud Volumes Service 不支持创建本地用户、因此此选项不适用于Cloud Volumes Service。</block>
  <block id="a3ab2beb782b5f0d7b6d1eb3cacdff1f" category="cell">对Active Directory LDAP连接使用start_tls</block>
  <block id="0e46800ed1870ec055aaa1a1193ff94e" category="cell">用于为Active Directory LDAP启用启动TLS连接。Cloud Volumes Service 当前不支持启用此功能。</block>
  <block id="b3734582301f762d04b757dd4bc38917" category="cell">已启用适用于Kerberos的AES-128和AES-256加密</block>
  <block id="4f36af6c9bdde3ebcee7b34176ffe895" category="cell">此选项用于控制是否对Active Directory连接使用AES加密、并在创建/修改Active Directory连接时使用为Active Directory身份验证启用AES加密选项进行控制。</block>
  <block id="60a39bccb81f56ddfcbb75f0ffcd1fb6" category="cell">LM兼容性级别</block>
  <block id="a4ada97522d5a887e144bf5d59b41a79" category="cell">Active Directory连接支持的身份验证方言级别。请参见第节"<block ref="17dc1460fa48a825f7967ddb6804d663" category="inline-xref-macro-rx"></block>"了解更多信息。</block>
  <block id="cba8970659f15f342022079c22a97ee9" category="cell">NTLMv2-KRB</block>
  <block id="5e22abe32604d6b7925fa4768934bb5d" category="cell">传入CIFS流量需要SMB加密</block>
  <block id="ae7c4fcb353d520e8996acadf9c9c42f" category="cell">所有共享都需要SMB加密。Cloud Volumes Service 不会使用此功能；而是按卷设置加密(请参见一节<block ref="6931acdfb95dc44f28af40d26d20d65c" category="inline-xref-macro-rx"></block>")。</block>
  <block id="e00514b301b6206c1024de564d0d71fe" category="cell">客户端会话安全性</block>
  <block id="b9e69cb6a219e02ada3e29b808558c45" category="inline-link-macro">"LDAP通道绑定。"</block>
  <block id="d16466e25f07f41d5c768e32becc9751" category="cell">为LDAP通信设置签名和/或密封。目前未在Cloud Volumes Service 中设置此选项、但在未来版本中可能需要执行此操作。本节将介绍由于Windows修补程序而导致的LDAP身份验证问题的修复方法 <block ref="4bb24ef2f48443c7e6d43902d0f8498e" category="inline-link-macro-rx"></block>。</block>
  <block id="b4c17f5cf25d927d8fb7dbab5e1d84c5" category="cell">SMB2为DC连接启用</block>
  <block id="31a7643648d0d4454c1fd8a860f1a12d" category="cell">使用SMB2进行DC连接。默认情况下处于启用状态。</block>
  <block id="2cd88a3568a04efbfd46abb6cce9a411" category="cell">系统默认值</block>
  <block id="6158881a00903bd45b66955e6487a27c" category="cell">LDAP转介跟踪</block>
  <block id="4ddc9ad0bd193ba15a48f662666ccd96" category="cell">使用LDAPS实现安全Active Directory连接</block>
  <block id="4182d7f699521f08b56835082e7caf27" category="cell">启用基于SSL的LDAP。Cloud Volumes Service 目前不支持。</block>
  <block id="b31e0a21b1fa97ab2faf1479ea00c9db" category="cell">DC连接需要加密</block>
  <block id="23cc5b51f575d3c458ac112689f7a2f1" category="cell">要成功建立DC连接、需要加密。默认情况下、在Cloud Volumes Service 中处于禁用状态。</block>
  <block id="ebd8431a0b14e9588377860f5d21d80b" category="sidebar">架构概述</block>
  <block id="a20fe2a1eb3b2546487a96f1e639d4f3" category="sidebar">其他NAS基础架构服务依赖关系(KDC、LDAP、DNS)</block>
  <block id="92e704fe041898cac086cd4a192a1815" category="cell">2022年5月20日</block>
  <block id="efae07e57b0f279c460d1361b379cf52" category="cell">全新的SuperPOD BeeGFS设计和部署指南</block>
  <block id="197d6fccbd337f46908b50e1ac3ece5d" category="sidebar">SuperPOD：NetApp和NVIDIA解决方案</block>
  <block id="ed05ff1aa7ef3023c5dc2359de4e2d15" category="sidebar">基于NetApp的BeeGFS (设计指南)</block>
  <block id="b877ddfe299c52df6f7a340fdcaa52eb" category="sidebar">基于NetApp的BeeGFS (部署指南)</block>
  <block id="e6bec38fe69985a0817e3c0b2b3a0c20" category="cell">*内容登录页面*</block>
  <block id="b1dc18184f115680e9fe3b64295c4678" category="cell">一组基于 AI 的解决方案。AI登录页面提供了内容专用的"图块"中的热门内容。</block>
  <block id="e68818392f0eda6e918ccb9e7537e282" category="inline-link-macro">AI内容</block>
  <block id="748eaad82fcc3f281aebd8c5467a4d91" category="cell"><block ref="748eaad82fcc3f281aebd8c5467a4d91" category="inline-link-macro-rx"></block></block>
  <block id="53840db4921094507c6397fb6ee31d58" category="cell">现代数据分析解决方案的集合(例如 Splunk SmartStore、Apache Spark等)。现代数据分析登录页面提供了在特定内容的"板块"中呈现的热门内容。</block>
  <block id="1b1956b226e3085af9e004e60ce183b4" category="inline-link-macro">现代数据分析内容</block>
  <block id="16321f09e6ea361ef5515d5939fa73f1" category="cell"><block ref="16321f09e6ea361ef5515d5939fa73f1" category="inline-link-macro-rx"></block></block>
  <block id="87867e178542e6ed3cf6ea885807d4f1" category="cell">一组虚拟化核心解决方案、包括桌面虚拟化。虚拟化登录页面提供了在特定内容的"图块"中显示的常见内容。</block>
  <block id="5654a75155b39867a9f4372fcc292bab" category="inline-link-macro">虚拟化内容</block>
  <block id="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="cell"><block ref="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="inline-link-macro-rx"></block></block>
  <block id="24a8e607718680e8d1dd293b9d736add" category="cell">基于容器的解决方案集合。虚拟化登录页面提供了在特定内容的"图块"中显示的常见内容。</block>
  <block id="afb6dbef1b44c7f79b8883cae5cc3b30" category="inline-link-macro">容器内容</block>
  <block id="d76e9a2c09fc047c91b6cb4c2f340644" category="cell"><block ref="d76e9a2c09fc047c91b6cb4c2f340644" category="inline-link-macro-rx"></block></block>
  <block id="0cf49f958731e4b4c23d4b04f0802ba0" category="cell">业务应用程序和数据库</block>
  <block id="73c685140b2461529432f6e9628ef281" category="cell">业务应用程序和数据库解决方案的集合。SAP和SAP HANA登录页面可提供特定于内容的"图块"中的热门内容。本节还介绍Oracle和SQL Server数据库解决方案。</block>
  <block id="ef0bea1a6ce6e68dd3ebae18ea2de71f" category="inline-link-macro">SAP和SAP HANA内容</block>
  <block id="589c17157183d6295af608cccff7c8da" category="cell"><block ref="589c17157183d6295af608cccff7c8da" category="inline-link-macro-rx"></block></block>
  <block id="d7339a230985e723af5d49a6470f4fc8" category="cell">数据迁移、数据保护和数据安全解决方案的集合。</block>
  <block id="d3d4dd76fc599d6c513fa0434537bc08" category="summary">一系列博客、讨论所有NetApp解决方案内容中的解决方案 功能</block>
  <block id="4d46b81ad5db47d845e86c95088ff47a" category="doc">NetApp解决方案：博客</block>
  <block id="a93daa19938c1852de52ce10350307a4" category="paragraph">重点介绍许多NetApp解决方案的特定功能的博客概述。</block>
  <block id="bf20a476dd72893f0f21a3d56a601784" category="open-title">人工智能</block>
  <block id="e6c9e9316fee7048645938d93d674056" category="list-text"><block ref="e6c9e9316fee7048645938d93d674056" category="inline-link-macro-rx"></block></block>
  <block id="3e78754f8bb90f06073e18a2399d0b7f" category="list-text"><block ref="3e78754f8bb90f06073e18a2399d0b7f" category="inline-link-macro-rx"></block></block>
  <block id="821c35321bcc709868cdd0b7f31165ee" category="cell">2022年4月1日</block>
  <block id="b4ea7c36c784b6da08e2b44d82018c65" category="open-title">AWS/VMC</block>
  <block id="b9b37266c1f6c6a5244f3fef48f644e1" category="list-text">部署和配置适用于AWS的VMware Cloud</block>
  <block id="57669ed11798d25a8216675c3f0f6ecf" category="inline-link-macro">VMC的配置步骤</block>
  <block id="9e88bf7f3ee359d8f536975aa39ab6a5" category="open-title">Azure / AVS</block>
  <block id="293193a848a4345d095f41ff490fd1a4" category="inline-link-macro">AVS的配置步骤</block>
  <block id="7e7790ea083a371632d0764a881695f6" category="open-title">GCP / GCVE</block>
  <block id="e44b11e9adb07a14c72f48599f700cd4" category="inline-link-macro">GCVE的配置步骤</block>
  <block id="52be4c6acc8cca3a598e3a651421de3d" category="inline-link-macro">VMC的子系统连接存储选项</block>
  <block id="a8e9a5787febc7740af29cd0bebf2e95" category="inline-link-macro">AVS的子系统连接存储选项</block>
  <block id="2da991b20a7647acbdd67154515723cf" category="inline-link-macro">GCVE的子系统连接存储选项</block>
  <block id="685435b4b2388bd8f370b8fbb6ef6cc7" category="cell">*已连接子系统*</block>
  <block id="8299249ba5f910704b6288ee7e271747" category="cell">* AWS *</block>
  <block id="eb35b03ceb49f5f06a4570454e08c34c" category="cell">CVO FSX ONTAP<block ref="999b20d9470091fda2e66b2dde5b0af7" category="inline-link-macro-rx"></block></block>
  <block id="1bdeba09294eb5abc383607bb93ff443" category="cell">* Azure *</block>
  <block id="06a1c60be3b7274c063385eaa240863f" category="cell">CVO ANF<block ref="f44f46a20eba78aa72ad4f68a0486a31" category="inline-link-macro-rx"></block></block>
  <block id="25bdffbd4ab087e994a0e54fe22ff6bd" category="cell">* GCP*</block>
  <block id="96e48152153beabed038aa4e41f2abf8" category="cell">CVO CVS<block ref="a54d2eac225d57696bf863778373ea0b" category="inline-link-macro-rx"></block></block>
  <block id="a46eb72d67c0cbcbbdfcde010fbc0b03" category="paragraph">详细了解NetApp为Azure提供的解决方案。</block>
  <block id="d8732ebfbd98db5a8cd9db59aa5b0637" category="paragraph">VMware将云工作负载定义为以下三个类别之一：</block>
  <block id="2cb256015e8585083bd2350f010676fb" category="list-text">保护(包括灾难恢复和备份/还原)</block>
  <block id="3bc026b815790a05493fa56fc4b8d8bd" category="list-text">扩展</block>
  <block id="2c0a3f21d3cbc96381e4c2fe29329ec1" category="paragraph">在以下各节中浏览可用的解决方案。</block>
  <block id="97740c0c87b83b324e18993ba93f0617" category="open-title">保护</block>
  <block id="e74fe990166c1a4bb77dde7f12823b5d" category="paragraph">即将推出！！</block>
  <block id="3d98cfc43616995ea335b20aa9b10ef2" category="paragraph">Azure支持使用 原生 Azure NetApp Files (ANF)服务或Cloud Volumes ONTAP (CVO)的子系统连接NetApp存储。</block>
  <block id="8f53b5241aa3284f9058318dcbc2504d" category="section-title">Azure NetApp 文件 (ANF)</block>
  <block id="2295dc11d84df2756a1eaac36330b417" category="paragraph">Azure NetApp Files 为Azure提供了企业级数据管理和存储、让您可以轻松管理工作负载和应用程序。将工作负载迁移到云并在不影响性能的情况下运行这些工作负载。</block>
  <block id="806f1ffa4d2e1d7ee40a30337658a5ef" category="paragraph">Azure NetApp Files 消除了各种障碍、因此您可以将所有基于文件的应用程序迁移到云。这是您第一次不必重新构建应用程序、而是为应用程序提供了不复杂的持久存储。</block>
  <block id="12eb3a27c6c1134f55e12f1349b87a91" category="paragraph">由于此服务是通过Microsoft Azure门户提供的、因此用户将在其Microsoft企业协议中体验到完全托管的服务。由Microsoft管理的一流支持让您高枕无忧。通过这一个解决方案 、您可以快速轻松地添加多协议工作负载。您可以构建和部署基于Windows和Linux文件的应用程序、即使对于传统环境也是如此。</block>
  <block id="7afda8c8e445dfa1015ae8245fa8026e" category="section-title">Cloud Volumes ONTAP (CVO)</block>
  <block id="8560d03d6d9a5398acd72a06a8fddd12" category="paragraph">Cloud Volumes ONTAP 是行业领先的云数据管理解决方案 、基于NetApp的ONTAP 存储软件构建、可在Amazon Web Services (AWS)、Microsoft Azure和Google Cloud Platform (GCP)上本机获得。</block>
  <block id="12f2a9cf238d1339eddfc43be9f107e1" category="paragraph">它是ONTAP 的软件定义版本、使用云原生存储、可以在云端和内部环境中使用相同的存储软件、从而减少了对IT员工进行全新数据管理方法培训的需求。</block>
  <block id="62c9becbf4c5643c0df4cbe868b09f0c" category="paragraph">借助CVO、客户可以无缝地将数据从边缘、数据中心、云和云端来回移动、从而将混合云整合在一起—所有这些都通过一个单一窗格管理控制台NetApp Cloud Manager进行管理。</block>
  <block id="aafae379e910c7a153b831ce5122f5e8" category="paragraph">按照设计、CVO可提供极致性能和高级数据管理功能、甚至可以满足云中要求最苛刻的应用程序的需求</block>
  <block id="6db49f93b02d752e6b80616d15759056" category="inline-link-macro">NetApp/VMware云解决方案</block>
  <block id="a088d0b353502e225826d0feb3041d57" category="list-text"><block ref="a088d0b353502e225826d0feb3041d57" category="inline-link-macro-rx"></block></block>
  <block id="9e348c60eb79913385ed14a65efffff6" category="paragraph">查看详细信息 <block ref="be78464beb9b2a2b1696a7fe38c0e484" category="inline-link-macro-rx"></block>。</block>
  <block id="cb9ab2dcef988aa0eaa2da1d789cfdb4" category="section-title">解决方案用例</block>
  <block id="c9c270552e6f44a0219e4d2459cb4b90" category="paragraph">借助 NetApp 和 VMware 云解决方案，许多用例都可以轻松部署在 Azure AVS 中。为VMware定义的每个云区域定义了SE案例：</block>
  <block id="3fac70d2bc4023bd8c5bb8f7c93b16e8" category="list-text">保护(包括灾难恢复和备份/还原)</block>
  <block id="79e4e4c7346c156a268641272a85c01e" category="inline-link-macro">浏览适用于 Azure AVS 的 NetApp 解决方案</block>
  <block id="6626f21cba60531fb6ab33c5b686fd03" category="paragraph"><block ref="6626f21cba60531fb6ab33c5b686fd03" category="inline-link-macro-rx"></block></block>
  <block id="ef3abc0e33a9bba2f6844fc8bc6416c6" category="section-title">适用于VMware环境的NetApp解决方案</block>
  <block id="7c56979dc4b16fa4dd69a289608a432d" category="paragraph">无论您是采用混合云模式还是采用"云优先"模式、NetApp都可以提供多种解决方案来解决在云或混合云模式下管理工作负载的最常见使用情形。</block>
  <block id="14b428df74ec47d859b4b41c2a528f79" category="paragraph">有关为每个超大规模提供商提供的解决方案的更多详细信息、请访问：</block>
  <block id="d7d90ddf3d849c680942374007293390" category="inline-link-macro">适用于AWS/VMC的解决方案</block>
  <block id="902d95c8e7b033260ed791d46b121684" category="inline-link-macro">适用于Azure/AVS的解决方案</block>
  <block id="739e02805dc104b2c68811e1ea86f2e5" category="inline-link-macro">适用于GCP / GCVE的解决方案</block>
  <block id="4c27cd4763075e77fef142db7e967384" category="paragraph">详细了解NetApp为AWS提供的解决方案。</block>
  <block id="6619dc0097706121ef2efa1294da110b" category="example-title">注册AWS帐户</block>
  <block id="3f01bd52a695afbced7f2a43525ec966" category="example-title">注册"我的VMware帐户"</block>
  <block id="f52c436d16c8976963f940ce7dfbd3b0" category="paragraph">AWS支持使用原生 FSX服务(FSX ONTAP)或Cloud Volumes ONTAP (CVO)的子系统连接NetApp存储。</block>
  <block id="480bc55cb0b0c11472f598d17424afa2" category="section-title">FSX ONTAP</block>
  <block id="6df37dbe4c736ce113cfd677b79431d8" category="paragraph">Amazon FSX for NetApp ONTAP 是一项完全托管的服务、可提供基于NetApp常用ONTAP 文件系统构建的高度可靠、可扩展、高性能和功能丰富的文件存储。FSX for ONTAP 将NetApp文件系统的常见特性、性能、功能和API操作与完全托管的AWS服务的灵活性、可扩展性和精简性相结合。</block>
  <block id="f1afd8f76dc3ed417abd5daffa1d5a5f" category="paragraph">FSX for ONTAP 提供功能丰富、快速且灵活的共享文件存储、可从AWS或内部运行的Linux、Windows和macOS计算实例广泛访问。适用于ONTAP 的FSX可提供具有亚毫秒级延迟的高性能固态驱动器(SSD)存储。借助适用于ONTAP 的FSX、您可以为工作负载实现SSD级别的性能、而只需为一小部分数据购买SSD存储即可。</block>
  <block id="dd29cd696f931f8230a783a5d65ab8c4" category="paragraph">只需单击一个按钮、即可使用适用于ONTAP 的FSX轻松管理数据、因为您可以创建文件快照、克隆和复制文件。此外、适用于ONTAP 的FSX会自动将数据分层到成本较低的弹性存储中、从而减少配置或管理容量的需求。</block>
  <block id="697c147172074c2927997e2d7c472fc0" category="paragraph">此外、适用于ONTAP 的FSX还可通过完全托管的备份提供高可用性和持久性存储、并支持跨区域灾难恢复。为了更轻松地保护和保护数据、适用于ONTAP 的FSx支持常见的数据安全和防病毒应用程序。</block>
  <block id="461ab3a83d6c51e1cc25f42118f407bd" category="paragraph">查看详细信息 <block ref="f56028ac73883785be6a54941a0e4e64" category="inline-link-macro-rx"></block>。</block>
  <block id="3721bfebe60fa9888e0ea17bd294772d" category="paragraph">借助 NetApp 和 VMware 云解决方案，许多用例都可以轻松部署在 AWS VMC 中。为VMware定义的每个云区域定义了使用情形：</block>
  <block id="7c9a6204c3d04cd593127efe773bc82e" category="inline-link-macro">浏览适用于 AWS VMC 的 NetApp 解决方案</block>
  <block id="e9923439d335946afaff146da3d107ff" category="paragraph"><block ref="e9923439d335946afaff146da3d107ff" category="inline-link-macro-rx"></block></block>
  <block id="7c0dae765c7854235808e7e373346d06" category="paragraph">详细了解NetApp为GCP提供的解决方案。</block>
  <block id="370e7d693bc429e40244684cac20b0cf" category="list-text"><block ref="370e7d693bc429e40244684cac20b0cf" category="inline-link-macro-rx"></block></block>
  <block id="80d79003a84a32474624e54935709e67" category="paragraph">查看详细信息 <block ref="996ade122099ed78c4d5fea15d95f62c" category="inline-link-macro-rx"></block>。</block>
  <block id="80b43a415019d937ea5c38446043549a" category="paragraph">查看详细信息 <block ref="8e20eef09273fc2519292ca4ed666573" category="inline-link-macro-rx"></block>。</block>
  <block id="e67def868f3133574b28ffe738ad44c1" category="inline-link-macro">浏览适用于 Google Cloud GCVE 的 NetApp 解决方案</block>
  <block id="5e7670e99ae7db80618f16965d677af6" category="paragraph"><block ref="5e7670e99ae7db80618f16965d677af6" category="inline-link-macro-rx"></block></block>
  <block id="f0f52a47448cc3bc6237a09f83ad3e74" category="example-title">部署和配置 GCVE</block>
  <block id="7973cdedf3e9a37ff146bc9fd29ff017" category="paragraph">GCP支持使用Cloud Volumes ONTAP (CVO)或Cloud Volumes Service (CVS)的子系统连接的NetApp存储。</block>
  <block id="622f93ad4ff43627a425523c5e2538ad" category="section-title">Cloud Volumes Service (CVS)</block>
  <block id="b5a9beef520c0dd1f8e978800f35268e" category="paragraph">Cloud Volumes Services (CVS)是一套完整的数据服务产品组合、可提供高级云解决方案。Cloud Volumes Services支持为主要云提供商提供多种文件访问协议(NFS和SMB支持)。</block>
  <block id="82c8cb0896f20daa9ddbb9d49332f9b6" category="paragraph">其他优势和功能包括：使用Snapshot进行数据保护和还原；在内部或云端复制、同步和迁移数据目标的特殊功能；以及在专用闪存存储系统级别实现一致的高性能。</block>
  <block id="443f43c84a8efb54c46feb5a61b1a9cc" category="paragraph">在本文档中、我们将使用VMware用例详细介绍云工作负载参考。这些用例包括：</block>
  <block id="0198315ccfb9d5c56e9c865f01bee365" category="paragraph">借助NetApp和VMware云解决方案、许多用例都可以轻松部署到您选择的超大规模云提供商中。VMware将主要云工作负载用例定义为：</block>
  <block id="e0525641cbca59e199eed50739c0c3b8" category="inline-link-macro">浏览适用于AWS/VMC的NetApp解决方案</block>
  <block id="3a602723648efc3d9a864906b6ec2d9c" category="paragraph"><block ref="3a602723648efc3d9a864906b6ec2d9c" category="inline-link-macro-rx"></block></block>
  <block id="d18a9fea9b4ca38bf7f042e32420e14e" category="inline-link-macro">浏览适用于Azure/AVS的NetApp解决方案</block>
  <block id="bd6708bcf0c060976324512475c1a212" category="paragraph"><block ref="bd6708bcf0c060976324512475c1a212" category="inline-link-macro-rx"></block></block>
  <block id="cac969404c87e9e141b320e34ee1ba4b" category="inline-link-macro">浏览适用于Google Cloud Platform (GCP)/GCVE的NetApp解决方案</block>
  <block id="7f86100566a3de37a45dc2bd4ea422a0" category="paragraph"><block ref="7f86100566a3de37a45dc2bd4ea422a0" category="inline-link-macro-rx"></block></block>
  <block id="95adefbc130d345041c4487820a9ab16" category="summary">NetApp企业数据库解决方案是一组战略和技术功能、用于展示NetApp存储在主要企业数据库中的功能。</block>
  <block id="e890f04973d00c3664a44f4cc586bb5d" category="doc">NetApp企业数据库解决方案</block>
  <block id="809247403bb2b3e7178b69b038356678" category="inline-link-macro">vSphere数据存储库和协议功能：NFS</block>
  <block id="ff7854cc2ae62511b4a52320f31aa005" category="paragraph"><block ref="ff7854cc2ae62511b4a52320f31aa005" category="inline-link-macro-rx"></block></block>
  <block id="ccf0b7773e492df3e851d36b689b69b1" category="paragraph">请参见以下视频和演示、其中重点介绍了混合云、虚拟化和容器解决方案的特定功能。</block>
  <block id="ab5efb952cd51767fdde3f548f7d3f18" category="paragraph">有关适用于 VMware vSphere 的 NetApp SnapCenter 插件的详细信息，请参见 <block ref="39b49e6fd504a137658d6db31d129abd" category="inline-link-macro-rx"></block>。</block>
  <block id="0b59976821e81163a037c4ed7f21b209" category="paragraph"><block ref="0b59976821e81163a037c4ed7f21b209" category="inline-link-macro-rx"></block></block>
  <block id="4bff68299377013f00a500a01c7a2f19" category="list-text"><block ref="4bff68299377013f00a500a01c7a2f19" category="inline-link-macro-rx"></block></block>
  <block id="e5f4fe92e1832b16532011df56ee39a5" category="list-text"><block ref="c30f78a476776106411b5cd1ee097f4f" category="inline-link-macro-rx"></block></block>
  <block id="380fbb2dc2a4b42876553664c398fb3f" category="paragraph">在提供解决方案以应对当今的业务挑战时、NetApp提供的解决方案具有以下目标：</block>
  <block id="008347e050bccf7e2812ae39dd816f41" category="list-text">提供经验证的部署和配置步骤、</block>
  <block id="4ef594072d2fdf53ad9ca6af7fe16569" category="list-text">提供易于使用的解决方案、</block>
  <block id="3f68e576fe6e3e328b5feeea03707572" category="list-text">提供具有可预测结果、易于重复且可在客户整个企业内扩展的解决方案 部署。</block>
  <block id="928a4532882b0eb0208abcae9b7fd6f0" category="paragraph">为了实现这些目标、通过我们的解决方案提供的基础架构和/或应用程序的部署和配置必须通过自动化来简化。NetApp致力于通过自动化简化解决方案 使用。</block>
  <block id="d6d7e89b087a9e69ae7622847dc932e5" category="paragraph">利用Red Hat Ansible、HashiCorp Terraform或Microsoft PowerShell等开源自动化工具、NetApp解决方案可以自动执行应用程序部署、云配置、配置管理和许多其他常见IT任务。NetApp的解决方案可利用公开发布的自动化项目、并提供NetApp编写的自动化功能、以简化解决方案 的整体部署。</block>
  <block id="e532e5979d2ecc30b8177530683810e2" category="paragraph">如果提供了自动化功能、解决方案 资料将指导用户通过特定自动化工具完成解决方案 或解决方案 步骤的自动化过程。</block>
  <block id="aaac1ea7463ef799eaafc693b16b1f81" category="doc">NetApp解决方案 自动化入门</block>
  <block id="66bd3dbe1f46a5715420e201e457ff65" category="paragraph">NetApp解决方案 自动化为NetApp解决方案所使用的许多常见任务提供了简便性和可重复性。</block>
  <block id="bf7d92f5ef43a7e0ab10c8d11d28ef6e" category="paragraph">在运行任何解决方案 自动化之前、必须为环境配置自动化执行方式。您可以通过命令行或AWX或塔等工具运行自动化。</block>
  <block id="dcdcb9b7436ca5ceca042e84e9c3ccf5" category="paragraph">以下各节将概述为每个指定环境配置环境所需的步骤。</block>
  <block id="245ab73d4b9beb43ff76c082e9bc77db" category="open-title">AI/数据分析</block>
  <block id="901b32f6abd15fbb3d43fbd044218a64" category="open-title">企业级应用程序和数据库</block>
  <block id="71fbb346a6b64c94052f0e171d5d3eed" category="open-title">数据保护和数据迁移</block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">一系列视频和演示、讨论NetApp的许多解决方案的功能</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">NetApp解决方案：视频和演示</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">视频和演示概述、重点介绍NetApp的许多解决方案的具体功能。</block>
  <block id="ab440644113265a70e7e0bb7c44b2f63" category="paragraph">*案例研究*</block>
  <block id="25aa061b5bc79f1f85182fd8ca1f3165" category="inline-link-macro">VMware视频集</block>
  <block id="847fff0b97afdc8ceabb5c717634d413" category="list-text"><block ref="847fff0b97afdc8ceabb5c717634d413" category="inline-link-macro-rx"></block></block>
  <block id="55418abe87135e6107123ca2c087964c" category="sidebar">适用于超大规模云中的VMware的NetApp解决方案</block>
  <block id="195b49c0610d30d327f5440759b7b642" category="sidebar">支持的解决方案</block>
  <block id="3ffbc70cc0bdd47bd7c4ed3cfa35be8a" category="sidebar">FSX ONTAP 作为子系统连接存储</block>
  <block id="06e1970c26d133efed67d51224ceff1c" category="sidebar">安全概述—Google Cloud中的NetApp Cloud Volumes Service (CVS)</block>
  <block id="30162ed78b6c10f731411f2fc440c24f" category="sidebar">Oracle</block>
  <block id="51b19c4a2c13c8f8a69b0608959bdfca" category="sidebar">FlexPod 数据中心上的Oracle 19c RAC数据库</block>
  <block id="a71f76c3256e4c206a4841d8eb0fed35" category="sidebar">SQL 服务器</block>
  <block id="81d59bad51a910734812cab3d20641b0" category="sidebar">混合云数据库解决方案</block>
  <block id="934553b3e6b7dd417ef37d2b3213dd00" category="sidebar">SAP SAP HANA</block>
  <block id="1f036821b23def9a55e4116bdbd60c1b" category="sidebar">更改历史记录</block>
  <block id="bb5dc731b06d417365e41cb2d0230213" category="sidebar">视频演示</block>
  <block id="f9cffb4fda587c713c06e50699299f0f" category="sidebar">解决方案 登录页面</block>
  <block id="bf8e2974cd692b57a29e42874b662b52" category="sidebar">企业数据库</block>
  <block id="d4a3e435684aa9918c9dd0bada78d4fb" category="sidebar">为AWS配置VMC</block>
  <block id="883512106f2cef4187ee5f6b5a94c6f8" category="sidebar">配置适用于Azure的AVS</block>
  <block id="a271625e92b27bca4202ba79dab27301" category="sidebar">为GCP配置GCVE</block>
  <block id="76862b378878c90a8052499ae898932f" category="sidebar">用于VMC的子系统连接存储</block>
  <block id="5703f41cd5551fad387ed46631532278" category="sidebar">用于AVS的子系统连接存储</block>
  <block id="1f9511a418cf9a352bacd19d937a5237" category="sidebar">GCVE的子系统连接存储</block>
  <block id="a0e8297bc18713002f47301829625ea1" category="sidebar">适用于AWS/VMC的NetApp</block>
  <block id="d530fb3a1e80511b2d7787728700d3fa" category="sidebar">适用于Azure / AVS的NetApp</block>
  <block id="8d9d90a84ad6b34129f140e0b3e23326" category="sidebar">适用于GCP / GCVE的NetApp</block>
  <block id="a3e92580de1a77cd25163bb63cd24a7d" category="inline-image-macro">链路=<block ref="9b22e52230cfacf7992c01194e7a95d2" category="inline-link-rx"></block></block>
  <block id="f9da9dedda46425dea9fe2b0092e4b1a" category="paragraph"><block ref="f9da9dedda46425dea9fe2b0092e4b1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">本节概述了此解决方案 中验证的三种情形。</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">测试和验证计划</block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">在此解决方案 设计中、我们对以下三种情形进行了验证：</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">在JupyterLab工作空间中使用适用于Kubernetes的NetApp DataOps工具包进行编排的推理任务、包括使用和不使用Protopia混淆。</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">在Kubernetes上使用使用NetApp DataOps Toolkit for Kubernetes编排的数据卷进行批量推理作业、包括使用和不使用Protopia混淆。</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">使用NVIDIA Triton推理服务器实例的推理任务、该实例使用适用于Kubernetes的NetApp DataOps工具包进行编排。在调用Triton推理API之前、我们会对映像应用程序混淆、以模拟通过网络传输的任何数据必须被混淆的常见要求。此工作流适用于在受信任区域内收集数据、但必须传递到该受信任区域之外以进行推理的情形。如果没有Protopia混淆、则在敏感数据不离开受信任区域的情况下、无法实施此类工作流。</block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">在此验证中、我们使用一组原始映像为图像检测用例执行推理。然后、我们对同一组图像执行了相同的推理任务、并在推理之前添加了质子模糊。我们对Protopia混淆组件使用不同的alpha值重复执行此任务。</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">推理准确性比较</block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">在此验证中、我们使用一组原始映像为图像检测用例执行推理。然后、我们对同一组图像执行了相同的推理任务、并在推理之前添加了质子模糊。我们对Protopia混淆组件使用不同的alpha值重复执行此任务。在Protopia混淆的上下文中、alpha值表示应用的混淆量、较高的alpha值表示较高的混淆级别。然后、我们对这些不同的运行中的推理准确性进行了比较。</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">以下两个表提供了有关我们使用情形的详细信息并概述了结果。</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia直接与客户合作、为特定使用情形确定适当的alpha值。</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">面板(PyTorch)-</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">FDDB数据集</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">前倾混淆</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">字母</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">准确性</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0.9337148153739079</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0.05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0.9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0.1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0.9024301009661478</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0.9081836283186224</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0.9073066107482036</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0.8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0.8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0.8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0.9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0.8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0.95</block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">本节概述了解决方案 设计验证环境。</block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">下表概括了解决方案 设计验证环境。</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="b0f69588db488e358ab3c85429ab6b3a" category="cell">NetApp Astra Trident CSI驱动程序</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">适用于Kubernetes的NetApp DataOps工具包</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="cell">NVIDIA Triton 推理服务器</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3.</block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">NetApp ONTAP 数据管理软件—ONTAP 信息库</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="2cd8f6bd0ec1bbc37315b8bc134e16c5" category="list-text">适用于容器的NetApp持久存储—NetApp Astra Trident</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia AI—机密推理</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">NVIDIA Triton推理服务器文档</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">PyTorch中的FaceBoxes</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">NetApp首席产品经理Mark Cates</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">NetApp技术营销工程师Sufian Ahmad</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">首席技术官兼Protopia AI教授Hadi Essmaeilzadeh</block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">数据处于三种状态：空闲、传输和计算。任何AI推理服务的一个重要部分都应该是在整个过程中保护数据免受威胁。在推理期间保护数据至关重要、因为该过程可以公开有关外部客户和提供推理服务的企业的私有信息。</block>
  <block id="4282c9ab06938351529fcc9258e39d5a" category="paragraph">数据有三种状态：空闲、传输和计算。任何AI推理服务的一个重要部分都应该是在整个过程中保护数据免受威胁。在推理期间保护数据至关重要、因为该过程可以公开有关外部客户和提供推理服务的企业的私有信息。Protopia AI是一种在当今市场中用于机密人工智能推理的纯软件解决方案。借助Protopia、AI只会从数据记录中传输经过转换的信息、而这些信息对于执行手头的AI/ML任务至关重要、而且不会再提供更多信息。这种随机转型不是一种屏蔽形式、而是基于使用精心设计的噪声以数学方式更改数据表示形式。</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">具有ONTAP 功能的NetApp存储系统可提供与本地SSD存储相同或更好的性能、并且与NetApp DataOps工具包相结合、可为数据科学家、数据工程师、AI/ML开发人员以及业务或企业IT决策者带来以下优势：</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">针对灾难恢复、业务连续性和法规要求的企业级数据保护和数据监管。</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">简化了数据管理操作的调用；从Jupyter笔记本电脑中的NetApp DataOps工具包快速获取数据科学家工作空间的Snapshot副本、以实现备份和可追溯性。</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">NetApp和Protopia解决方案 提供了一个灵活的横向扩展架构、非常适合企业级AI推理部署。它支持数据保护、并为敏感信息提供隐私保护、可通过内部部署和混合云部署中的负责AI实践满足机密AI推理要求。</block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">本节介绍完成验证所需的任务。</block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">要执行本节所述的任务、您必须能够访问安装并配置了以下工具的Linux或macOS主机：</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl (配置为访问现有Kubernetes集群)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">可参见安装和配置说明<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block>。</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">可以找到安装说明<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block>。</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">场景1—JupyterLab中的按需推理</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">为AI/ML推理工作负载创建Kubernetes命名空间。</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">使用NetApp DataOps工具包配置永久性卷、以存储要执行推理的数据。</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">使用NetApp DataOps工具包创建新的JupyterLab工作空间。使用`-mount- PVC`选项挂载上一步中创建的永久性卷。根据需要使用`- nvidia-GPU`选项将NVIDIA GPU分配给工作空间。</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">在以下示例中、永久性卷`推理-data`会挂载到JupyterLab工作空间容器中、该容器位于` home/jovyon/data`。使用Project Jupyter官方容器映像时、`/home/jovyan`将作为JupyterLab Web界面中的顶级目录提供。</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">使用`create jupyterlab`命令输出中指定的URL访问JupyterLab工作空间。数据目录表示已挂载到工作空间的永久性卷。</block>
  <block id="1f069f45990199d6afbe5926fb26f127" category="paragraph"><block ref="1f069f45990199d6afbe5926fb26f127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">打开`data`目录并上传要执行推理的文件。将文件上传到数据目录时、这些文件会自动存储在挂载到工作空间的永久性卷上。要上传文件、请单击上传文件图标、如下图所示。</block>
  <block id="f6d07c27f458648455903cf09530655f" category="paragraph"><block ref="f6d07c27f458648455903cf09530655f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">返回顶级目录并创建新的笔记本。</block>
  <block id="59e51e40d73317a796f7d0b25d8fa003" category="paragraph"><block ref="59e51e40d73317a796f7d0b25d8fa003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">向笔记本电脑添加推理代码。以下示例显示了图像检测用例的推理代码。</block>
  <block id="901ae9d6148669912b400c6d2647bfbf" category="paragraph"><block ref="901ae9d6148669912b400c6d2647bfbf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f10850488ed018cdad31f8ac9e8bab" category="paragraph"><block ref="45f10850488ed018cdad31f8ac9e8bab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">将Protopia混淆添加到推理代码中。Protopia直接与客户合作、提供特定于使用情形的文档、不在本技术报告的范围内。以下示例显示了添加了Protopia混淆的图像检测用例的推理代码。</block>
  <block id="5a10342224477df560528e700989b536" category="paragraph"><block ref="5a10342224477df560528e700989b536" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20f77c05fa583bdc62074b26870e07e7" category="paragraph"><block ref="20f77c05fa583bdc62074b26870e07e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">场景2—Kubernetes上的批处理推理</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">使用要执行推理的数据填充新的永久性卷。</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">NetApp DataOps工具包S3 Data Mover功能</block>
  <block id="2933df0ebac7b47c349bd6bd7099fb90" category="paragraph">可以通过多种方法将数据加载到PVC上。如果您的数据当前存储在与S3兼容的对象存储平台中、例如NetApp StorageGRID 或Amazon S3、则可以使用<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block>。另一种简单的方法是创建JupyterLab工作空间、然后通过JupyterLab Web界面上传文件、如""一节中的步骤3到5所述<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>。 "</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">为批处理推理任务创建Kubernetes作业。以下示例显示了一个图像检测用例的批处理推理作业。此作业会对一组映像中的每个映像执行推理、并将推理准确性指标写入到stdout。</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">确认推理作业已成功完成。</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">将Protopia混淆添加到推理作业。您可以从Protopia中找到直接添加Protopia混淆的使用案例专用说明、该说明不在本技术报告的讨论范围内。以下示例显示了一个人脸检测用例的批处理推理作业、该用例使用0.8的字母值添加了质子模糊。此作业会在对一组图像中的每个图像执行推理之前应用程序对象模糊、然后将推理准确性指标写入stdout。</block>
  <block id="7a1adb5cebbf78f3eddc08a64751149e" category="inline-link-macro">"推理准确性比较。"</block>
  <block id="da2c9dc305dff324654e67571156b295" category="paragraph">对于alpha值0.05%、0.1、0.2、0.4、0.6、 0.8、0.9和0.95。您可以在中查看结果 <block ref="af158494e4986d64d04037857fed2d1c" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">场景3—NVIDIA Triton推理服务器</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">使用NetApp DataOps工具包配置永久性卷、以用作NVIDIA Triton推理服务器的型号存储库。</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">格式。</block>
  <block id="6c21d87641bab7a6c49bc29065185e4f" category="paragraph">可以通过多种方法将数据加载到PVC上。一种简单的方法是创建JupyterLab工作空间、然后通过JupyterLab Web界面上传文件、如中的步骤3到5所述<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>。"</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">使用NetApp DataOps工具包部署新的NVIDIA Triton推理服务器实例。</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">使用Triton客户端SDK执行推理任务。以下Python代码摘录使用Triton Python客户端SDK为人脸检测用例执行推理任务。此示例调用Triton API并传递图像以进行推理。然后、Triton推理服务器接收请求、调用模型、并在API结果中返回推理输出。</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">将Protopia混淆添加到推理代码中。您可以从Protopia中找到直接添加Protopia混淆的使用案例专用说明；但是、此过程不在本技术报告的讨论范围内。以下示例显示了与上一步5中显示的相同的Python代码、但添加了Protopia obfuscation。</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">请注意、在将图像传递到Triton API之前、系统会对该映像应用程序模糊。因此、非混淆映像永远不会离开本地计算机。仅通过网络传递模糊映像。此工作流适用于以下情形：在受信任区域内收集数据、但随后需要传递到该受信任区域以外以进行推理。如果没有Protopia混淆、则在敏感数据不离开受信任区域的情况下、无法实施此类工作流。</block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">数字图像处理具有许多优势、可以使许多组织充分利用与可视化表示相关的数据。NetApp和Protopia解决方案 提供了一种独特的AI推理设计、用于在整个ML/DL生命周期内保护AI/ML数据并将其私营化。它可以帮助客户保留敏感数据的所有权、通过减轻与隐私相关的顾虑来使用公有 或混合云部署模式以实现规模和效率、并在边缘部署AI推理。</block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">环境智能</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">行业可以通过多种方式在环境危害领域利用地理空间分析。政府和公有 Works部门可以获得有关公有 运行状况和天气状况的切实可行的见解、以便在发生大流行病或野火等自然灾害时更好地为公有 提供建议。例如、您可以在机场或医院等公有 空间识别出COVID-阳性患者、而不会影响受影响患者的隐私、并提醒相关主管部门和附近的公有 采取必要的安全措施。</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">边缘设备可穿戴设备</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">在军队和战场上、您可以使用边缘的人工智能推理作为可穿戴设备来跟踪军人的健康状况、监控司机行为、并就接近军车的安全和相关风险向当局发出警报、同时保护和保护军人的隐私。随着战场物联网(Internet of Battlefield Things、IoBT)和军事物联网(Internet of militar Things、IoMT)的发展、军队的未来将采用高科技设备、通过快速边缘计算帮助军人识别敌人并提高作战性能。保护和保留从无人机和可穿戴设备等边缘设备收集的视觉数据对于防止黑客和敌人入侵至关重要。</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">非作战人员疏散操作</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">非作战人员后送行动(Noncombatant evelevation operations、NEO)由国防部执行、旨在帮助将生命面临危险的美国公民和公民、国防部文职人员以及指定人员(东道国(HN)和第三国公民(TCN))疏散到适当的安全天堂。所实施的管理控制主要采用手动疏散人员筛查流程。但是、使用高度自动化的AI/ML工具以及AI/ML视频模糊技术、可能会提高疏散人员识别、疏散人员跟踪和威胁筛选的准确性、安全性和速度。</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">人工智能/机器学习分析的云迁移</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">数据保护</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link">TR-4886人工智能在边缘进行推理</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">智能与隐私</block>
  <block id="215649425fa669fb4825e25a6ace492e" category="paragraph">有关其他行业的边缘计算和AI推理的其他用例、请参见<block ref="922342ea98ca297422c6dc441f974a04" category="inline-link-rx"></block> 以及NetApp AI博客、<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block>。</block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">本节概述了完成此解决方案 所需的各种技术组件。</block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">Protopia</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AI提供了一种不引人注目的纯软件解决方案 、用于在当今市场中进行保密推理。通过最大限度地减少敏感信息的暴露、Protopia解决方案 可为推理服务提供无与伦比的保护。AI只会馈送数据记录中对执行手头任务真正至关重要的信息、而不会再提供更多信息。大多数推理任务不会使用每个数据记录中的所有信息。无论您的AI是使用图像、语音、视频还是结构化表格数据、Protopia都能提供推理服务所需的功能。获得专利的核心技术利用数学精心设计的噪声来随机转换数据、并收集给定ML服务不需要的信息。此解决方案 不会屏蔽数据、而是会使用随机筛选的噪声来更改数据表示形式。</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">Protopia解决方案 将更改表示形式的问题表述为基于梯度的最大干扰方法、该方法仍会在输入功能空间中保留与模型功能相关的信息。此发现过程将在训练ML模型结束时作为微调过程运行。在传递自动生成一组概率分布之后、低开销数据转换会将这些分布中的噪声样本应用于数据、并在将其传递到模型进行推理之前使其发生混淆。</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">NetApp ONTAP AI参考架构由DGX A100系统和NetApp云互联存储系统提供支持、由NetApp和NVIDIA开发并验证。它为 IT 组织提供了一个架构，可提供以下优势：</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AI将DGX A100系统和NetApp AFF A800存储系统与一流的网络紧密集成在一起。ONTAP AI可消除设计复杂性和猜测性工作、从而简化AI部署。客户可以从小规模入手、实现无中断增长、同时智能管理从边缘到核心再到云再到云的数据。</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">下图显示了采用DGX A100系统的ONTAP AI解决方案系列中的多种变体。最多可使用八个DGX A100系统验证AFF A800系统性能。通过向ONTAP 集群添加存储控制器对、该架构可以扩展到多个机架、以支持多个DGX A100系统和数PB的存储容量、并实现线性性能。这种方法可以灵活地根据所使用的DL型号的大小以及所需的性能指标独立更改计算与存储的比率。</block>
  <block id="316a5094893ef1b058844a75c53aaf04" category="paragraph"><block ref="316a5094893ef1b058844a75c53aaf04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153：采用NVIDIA DGX A100系统和Mellanox频谱以太网交换机的NetApp ONTAP AI。</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">有关追加信息 关于ONTAP AI的信息、请参见<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ONTAP 9.11是NetApp推出的最新一代存储管理软件、可帮助企业打造现代化的基础架构并过渡到云就绪数据中心。借助行业领先的数据管理功能，无论数据位于何处， ONTAP 都可以通过一组工具来管理和保护数据。您还可以将数据自由移动到需要的任何位置：边缘，核心或云。ONTAP 9.11包含许多功能、可简化数据管理、加快和保护关键数据、并在混合云架构中实现下一代基础架构功能。</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOps工具包是一个Python库、可使开发人员、数据科学家、开发运营工程师和数据工程师轻松执行各种数据管理任务、例如近乎即时地配置新的数据卷或JupyterLab工作空间、近乎即时地克隆数据卷或JupyterLab工作空间、 并近乎即时地为数据卷或JupyterLab工作空间创建快照、以实现可追溯性或基线化。此Python库可以用作命令行实用程序或函数库、您可以将其导入到任何Python程序或Jupyter笔记本电脑中。</block>
  <block id="dea84e2e635ce73ddc479a38d5616c98" category="paragraph">NVIDIA Triton推理服务器是一款开源推理服务软件、可帮助实现模型部署和执行标准化、从而在生产环境中提供快速且可扩展的AI。Triton推理服务器支持团队从任何基于GPU或CPU的基础架构上的任何框架部署、运行和扩展经过培训的AI模型、从而简化了AI推理过程。Triton推理服务器支持所有主要框架、例如TensorFlow、NVIDIA TensorRT、PyTorch、MXNet、 OpenVINO等。Triton与Kubernetes集成、用于协调和扩展、您可以在所有主要公有 云AI和Kubernetes平台中使用。它还与许多MLOps软件解决方案集成在一起。</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="section-title">PyTorch</block>
  <block id="04f7f16178ab3e9bddfd0837b64d21a2" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block> 是开源ML框架。它是一个经过优化的用于深度学习的tensor库、使用GPU和CPU。PyTorch软件包包含多维感应器的数据结构、可提供许多实用程序来高效地序列化其他有用实用程序中的感应器。它还具有一个CUDA对应项、可用于在具有计算功能的NVIDIA GPU上运行Tensor计算。在此验证中、我们使用OpenCV-Python (CV2)库来验证我们的型号、同时利用Python最直观的计算机视觉概念。</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">数据管理对于企业IT运营和数据科学家至关重要、这样才能将适当的资源用于AI应用程序和训练AI/ML数据集。以下有关NetApp技术的追加信息 不在此验证范围内、但可能与您的部署相关。</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">ONTAP 数据管理软件包括以下功能、可简化操作并降低总运营成本：</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">实时数据缩减和扩展的重复数据删除。数据缩减可减少存储块中浪费的空间、重复数据删除可显著提高有效容量。此适用场景数据存储在本地，并分层到云。</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">最低、最高和自适应服务质量(AQoS)。精细的服务质量(QoS)控制有助于在高度共享的环境中保持关键应用程序的性能水平。</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598：FabricPool 最佳实践</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetApp FabricPool。可将冷数据自动分层到公有 和私有云存储选项、包括Amazon Web Services (AWS)、Azure和NetApp StorageGRID Storage解决方案。有关 FabricPool 的详细信息，请参见<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block>。</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP 可提供卓越的性能和数据保护、并通过以下方式扩展这些功能：</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">性能和更低的延迟。ONTAP 可提供尽可能高的吞吐量和尽可能低的延迟。</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">数据保护ONTAP 可提供内置数据保护功能、并在所有平台之间进行通用管理。</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">NetApp卷加密(NVE)。ONTAP 提供原生 卷级加密、并支持板载和外部密钥管理。</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">多租户和多因素身份验证。ONTAP 支持以最高的安全性级别共享基础架构资源。</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP 可通过以下功能满足不断变化的苛刻业务需求：</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">无缝扩展和无中断运行。ONTAP 支持无中断地向现有控制器和横向扩展集群添加容量。客户可以升级到 NVMe 和 32 Gb FC 等最新技术，而无需进行成本高昂的数据迁移或中断。</block>
  <block id="74c384c0caae9c39b0e414cecc8c66ea" category="list-text">云连接。ONTAP 是云互联程度最高的存储管理软件、可在所有公有 云中选择软件定义的存储(ONTAP Select)和云原生实例(NetApp Cloud Volumes Service)。</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">与新兴应用程序集成。ONTAP 通过使用支持现有企业应用程序的相同基础架构、为下一代平台和应用程序(例如自动驾驶汽车、智能城市和行业4.0)提供企业级数据服务。</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">NetApp Astra Control</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Astra 控制服务</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">NetApp Astra 产品系列为内部和公有 云中的 Kubernetes 应用程序提供存储和应用程序感知型数据管理服务，并采用 NetApp 存储和数据管理技术。通过它、您可以轻松备份Kubernetes应用程序、将数据迁移到其他集群以及即时创建有效的应用程序克隆。如果您需要管理在公有 云中运行的Kubernetes应用程序、请参见的文档<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block>。Astra Control Service 是一项由 NetApp 管理的服务，可在 Google Kubernetes Engine （ GKEE ）和 Azure Kubernetes Service （ AKS ）中为 Kubernetes 集群提供应用程序感知型数据管理。</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> NetApp 是适用于 Docker 和 Kubernetes 的开源动态存储编排程序，可简化永久性存储的创建，管理和使用。Trident是Kubernetes本机应用程序、直接在Kubernetes集群中运行。借助 Trident ，客户可以将 DL 容器映像无缝部署到 NetApp 存储上，并为 AI 容器部署提供企业级体验。Kubernetes用户(ML开发人员、数据科学家等)可以创建、管理和自动化流程编排和克隆、从而利用NetApp技术提供的高级数据管理功能。</block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">在此验证中、我们对1920 x 1080像素图像应用了五次Protopia混淆、并测量了每次完成混淆步骤所需的时间。</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">模糊速度</block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">本文档介绍了在三种不同场景下经过验证的设计解决方案 、这些场景会涉及到与保护隐私和部署负责的AI解决方案 相关的图像混淆和不混淆。</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan、Michael Oglesby、NetApp ByG Hoon Ahn、Jennifer Cwagenberg、Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">随着图像捕获和图像处理的出现、视觉解释已成为通信不可或缺的一部分。数字图像处理中的人工智能(AI)带来了新的业务机会、例如癌症和其他疾病的医学领域、用于研究环境危害的地理空间视觉分析、模式识别、用于打击犯罪的视频处理等。但是、这一机会也伴随着非凡的责任。</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">企业将越来越多的决策交由AI处理、他们就越能接受与数据隐私和安全以及法律、道德和法规问题相关的风险。通过负责任的AI、企业和政府组织可以建立信任和监管、这对于大型企业的大规模AI至关重要。本文档介绍了在三种不同情形下由NetApp验证的AI推理解决方案 、它使用NetApp数据管理技术与Protopia数据混淆软件将敏感数据私营化并降低风险和道德问题。</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">消费者和业务实体每天都使用各种数字设备生成数百万张图像。因此、数据和计算工作负载的大规模激增使企业转向云计算平台以实现规模和效率。同时、在传输到公有 云时、会出现有关图像数据中所含敏感信息的隐私问题。缺乏安全和隐私保证已成为部署图像处理AI系统的主要障碍。</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">擦除权</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">隐私法案</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">此外、还有<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> 根据《一般数据保护条例》、个人有权要求组织擦除其所有个人数据。此外、还提供了<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block>、建立公平信息实践准则。根据《一般数据保护条例》、照片等数字图像可以构成个人数据、该条例规定了数据的收集、处理和擦除方式。如果不遵守《一般数据保护条例》、可能会因违反合规性而被处以巨额罚款、从而对组织造成严重损害。隐私原则是实施负责任AI的基石、它可以确保机器学习(ML)和深度学习(DL)模型预测的公平性、并降低与违反隐私或法规相关的风险。</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">本文档介绍了在三种不同场景下经过验证的设计解决方案 、其中包括与保护隐私和部署负责的AI解决方案 相关的图像混淆和不混淆：</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*场景1.*在Jupyter笔记本电脑中按需推理。</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*场景2.* Kubernetes上的批处理推理。</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*场景3.* NVIDIA Triton推理服务器。</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">对于此解决方案 、我们将使用面部检测数据集和基准测试(FDDB)、这是一个人脸区域数据集、用于研究无约束面部检测问题、并结合使用PyTorch机器学习框架来实施FaceBoxes。此数据集包含一组具有各种分辨率的2845图像中5171个面的标注。此外、本技术报告还介绍了解决方案 的一些领域以及在适用此解决方案 的情况下从NetApp客户和现场工程师收集的相关用例。</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">本技术报告面向以下受众：</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">业务主管和企业架构师、他们希望设计和部署负责的AI、并解决与公有 空间中面部图像处理相关的数据保护和隐私问题。</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">数据科学家、数据工程师、AI/机器学习(ML)研究人员以及旨在保护和维护隐私的AI/ML系统开发人员。</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">为符合GDPR、CCPA或国防部(DoD)隐私法案等法规标准的AI/ML模型和应用程序设计数据混淆解决方案的企业架构师。</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">数据科学家和AI工程师正在寻找高效的方法来部署深度学习(DL)和AI/ML/DL推理模型、以保护敏感信息。</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">此解决方案 可通过利用GPU的处理能力以及传统CPU来处理大型数据集中的实时和批量推理AI工作负载。此验证证明了ML的隐私保护推理以及寻求负责AI部署的组织所需的最佳数据管理。此解决方案 提供的架构适合单节点或多节点Kubernetes平台、用于与核心内部部署的NetApp ONTAP AI、NetApp DataOps工具包以及使用Jupyter实验室和CLI界面的Protopia混淆软件互连的边缘和云计算。下图显示了由NetApp提供支持的Data Fabric与DataOps Toolkit和Protopia的逻辑架构概述。</block>
  <block id="950724ad73ee22fd3b76ae9570281f64" category="paragraph"><block ref="950724ad73ee22fd3b76ae9570281f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Protopia混淆软件可在NetApp DataOps工具包上无缝运行、并在离开存储服务器之前转换数据。</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">负责的AI和机密推理—NetApp AI与Protopia Image Transformation</block>
  <block id="2ffe7358ce461fb4d630742ed966cf0b" category="example-title">适用于 VMware vSphere 的 NetApp ONTAP 工具</block>
  <block id="e78afc9f7bd61b3284539108287c91ca" category="example-title">采用AWS FSX for NetApp ONTAP 的AWS上的VMware云</block>
  <block id="f83bc0ebbeff6798c7394f8638db2695" category="example-title">适用于VMware的ONTAP 工具—概述</block>
  <block id="f1d501df2ff1e67b18b06eedd1bad6e8" category="example-title">使用ONTAP 配置VMware iSCSI数据存储库</block>
  <block id="a5e8a94cc8a28008eb4e2e719f658780" category="example-title">使用ONTAP 配置VMware NFS数据存储库</block>
  <block id="d69c8ea377286ab60d47066fa2946919" category="example-title">使用iSCSI使用FSX ONTAP 的Windows子系统连接存储</block>
  <block id="113249c2329945af0bbbc9830088e9ea" category="example-title">使用NFS使用FSX ONTAP 的Linux子系统连接存储</block>
  <block id="05799bad32c5bd80547efe4144fb57af" category="example-title">适用于 VMware vSphere 的 SnapCenter 插件—解决方案 前提条件</block>
  <block id="47d7646bd1c6577d907ac316431ae609" category="example-title">适用于 VMware vSphere 的 SnapCenter 插件—部署</block>
  <block id="11d13047d237d5bccdd941bafda45d9d" category="example-title">适用于 VMware vSphere 的 SnapCenter 插件—备份工作流</block>
  <block id="16bbc152851c33a02fcac2fbf943ffee" category="example-title">适用于 VMware vSphere 的 SnapCenter 插件—还原工作流</block>
  <block id="305f1daa74a8ec01eaf0ce2c9a8ce355" category="example-title">SnapCenter — SQL 还原工作流</block>
  <block id="891220762a1a15ebfba11cf98afb3729" category="cell">2022年6月7日</block>
  <block id="e19e98a669ae21f94ffd1659998fd072" category="cell">数据分析</block>
  <block id="c32698794f1279b1f46bacea38a72264" category="cell">添加了使用Splunk Enterprise解决方案 的NetApp EF600的链接</block>
  <block id="32e9989956756ffe28b84c0dab24eb03" category="cell">2022年2月6日</block>
  <block id="9ceed07936bb73f756027dc20e7869e5" category="open-title">美洲</block>
  <block id="a58c228b4723aee54800749a595ee3d1" category="cell">* AWS地区*</block>
  <block id="0ea8853bd99df0275ce197d81b4acdf3" category="cell">* VMC可用性*</block>
  <block id="da5de74c1914c54c36141e9bbc0bfb2c" category="cell">* FSX ONTAP 可用性*</block>
  <block id="db1904255fd919e193388d9dfc4066ae" category="cell">* NFS数据存储库可用性*</block>
  <block id="34f9a39dcbb737fbdd35cfb9214308b5" category="cell">美国东部(北弗吉尼亚)</block>
  <block id="227b0fc1350a24236051cdda52db89ae" category="cell">美国东部（俄亥俄州）</block>
  <block id="578ab1f7b2f00d70184a6fd055855a32" category="cell">美国西部(北加利福尼亚)</block>
  <block id="2826ad747baf050dc2cfb69d5171f78f" category="cell">US West （俄勒冈州）</block>
  <block id="1978cc170637ba3fa169853b7c5b2791" category="cell">GovCloud (美国西部)</block>
  <block id="86378e5a26945a10df6434e3cebc709b" category="cell">加拿大（中部）</block>
  <block id="1289483fccf49359b30e09d42f550943" category="cell">南美(圣保罗)</block>
  <block id="dbb56fbaa43a12cf5dc69fde5096e785" category="paragraph">最后更新日期：2022年6月2日。</block>
  <block id="0f1c6d45b761226679e0927cc47d24d3" category="open-title">欧洲、中东和非洲</block>
  <block id="8c0594d8d8e156a108f31e22903e4349" category="cell">欧洲(爱尔兰)</block>
  <block id="05f6cd9d18df6f52665dab10eda2ebe1" category="cell">欧洲(伦敦)</block>
  <block id="5efd079b952b87c886a8a02de8dd5d83" category="cell">欧洲(法兰克福)</block>
  <block id="5be61c2e880e77ca057a65a4ff532d45" category="cell">欧洲(巴黎)</block>
  <block id="ecb3d21f3ca319a515169d4aafe9ed99" category="cell">欧洲(米兰)</block>
  <block id="529f3fee69162e06098d8924e8084ca6" category="cell">欧洲（斯德哥尔摩）</block>
  <block id="2ebc1f6a39f03ec89f2b4bfdaf802f4c" category="open-title">亚太地区</block>
  <block id="4c2aaaa08c4d6f6e7e5af0e5fecf29df" category="cell">Asia Pacific (Sydney)</block>
  <block id="60b549aa334760e9f2bd47c8296afb7b" category="cell">亚太地区(东京)</block>
  <block id="dfbd3a51c0e9a689817234013c0d51ee" category="cell">亚太地区(日本、日本)</block>
  <block id="c8d7db357b2344e3ebeab70a1e63c6c9" category="cell">亚太地区(新加坡)</block>
  <block id="5294ca76dd36c8368fcafd7e951115ef" category="cell">亚太地区(首尔)</block>
  <block id="78c8c0f60d4851b109cbd33284f812ca" category="cell">亚太地区(孟买)</block>
  <block id="82f98bf67698e189fc9d846325345bbd" category="cell">亚太地区(雅加达)</block>
  <block id="1b15cf1d695d130132edd42a701b41a1" category="cell">亚太地区(香港)</block>
  <block id="3b041c1182ede15a52a683344c9512e0" category="section-title">AWS区域可用性</block>
  <block id="c5fde59b3560ee1ea5aeeebaf94bdf39" category="section-title">Azure区域可用性</block>
  <block id="844f1178f4ff7b95030ee50d8917da61" category="sidebar">NFS数据存储库的区域支持</block>
  <block id="15b1cf33f2d910f9ab5e6fdaeb331bcc" category="sidebar">为AWS中的NFS数据存储库提供区域支持</block>
  <block id="81a6037600add9bb79d72eb49534ff94" category="sidebar">为Azure中的NFS数据存储库提供区域支持</block>
  <block id="1da3fb2408fde551ca108534afed1987" category="sidebar">采用Splunk Enterprise的NetApp EF600</block>
  <block id="419f5ca56c881443509bda0a14523c9c" category="cell">更新了AVS区域支持、以匹配公有 预览公告/支持</block>
  <block id="40640c0c34d4427f5d18b9ca476e3158" category="summary">本页介绍了 NetApp ONTAP 存储上 Oracle19c 的自动数据保护。</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">医疗保健和生物医学研究</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">图像处理用于通过计算机体层成像(CT)或磁场共振成像(MRI)获得的3D图像诊断用于手术计划的病理学。HIPAA隐私规则规定了组织必须如何收集、处理和擦除所有个人信息和照片等数字图像的数据。要使数据符合HIPAA《安全港》规定的可共享性、必须删除全面照片图像和任何类似图像。用于从结构化的CT/MR图像中模糊个人面部特征的除名或头骨‐剥离算法等自动化技术已成为生物医学研究机构数据共享过程的重要组成部分。</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">传统上、企业客户已经在内部培训和部署了AI/ML模式。出于规模经济和效率方面的考虑、这些客户正在进行扩展、将AI/ML功能迁移到公有 、混合云或多云云部署中。但是、它们受数据可以公开到其他基础架构的约束。NetApp解决方案可解决所需的各种网络安全威胁<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> 和安全性评估、结合使用Protopia数据转换、最大程度地降低将图像处理AI/ML工作负载迁移到云的相关风险。</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928：《责任AI和机密推理—NetApp AI与Protopia映像和数据转型》</block>
  <block id="5b8a88d59edea26637f628caefd05974" category="list-text">您已有一个有效的 Kubernetes 集群，并且正在运行 Trident 支持的 Kubernetes 版本。有关支持的版本列表，请参见<block ref="77881c904b113f84b0f08c355b95174f" category="inline-link-rx"></block>。</block>
  <block id="b81146e6af95bf6e22cf57459890216f" category="inline-link">后端</block>
  <block id="f652904c3bfb48fb25a0a75f485f0ff6" category="inline-link">StorageClasses</block>
  <block id="05543563edfd7ed0348edd3b47280705" category="list-text">如果您未使用 NVIDIA DeepOps 部署 Kubernetes 集群，或者您只是希望手动部署 Trident ，则可以按照部署 Trident<block ref="e119dd171387190517d77417752a581c" category="inline-link-rx"></block> 在 Trident 文档中。有关如何配置的详细信息、请务必至少创建一个Trident后端和一个Kubernetes StorageClass<block ref="9e44c6ae604c64be7a70b0384fa1cccd" category="inline-link-rx"></block> 和<block ref="336146b6899186b663ba5a7b38e8c39b" category="inline-link-rx"></block> 请参见NetApp文档中链接的小节。</block>
  <block id="36522cc6d4eb67d30ef19d321901fa6e" category="cell">2022年6月16日</block>
  <block id="e1ea84e227dd99913363ade155774bcf" category="cell">添加了采用NetApp设计指南的NVIDIA DGX SuperPOD</block>
  <block id="1edbb6849585c57ecbf402c0706ecf2d" category="sidebar">采用NetApp技术的NVIDIA DGX SuperPOD (设计指南)</block>
  <block id="e340bc103d02ce2b8e016eb60705029c" category="sidebar">SAP 和 SAP HANA</block>
  <block id="703fd9e283392bf196948a4c2ed72680" category="list-text">登录到NetApp支持站点并下载最新版本的NetApp Astra控制中心。为此，您需要在 NetApp 帐户中附加许可证。下载完 tarball 后，将其传输到工作站。</block>
  <block id="42042ccfc3ffee97e94beca237148ed4" category="list-text">创建或获取对要安装Astra控制中心的OpenShift集群具有管理员访问权限的kubeconfig文件。</block>
  <block id="aff7b433e7f33e585c67f69803192117" category="list-text">编辑`vars/vars.yml`文件、并使用所需信息填充变量。</block>
  <block id="b4ca5df207a7b1e22a2f19cac43dd6ad" category="paragraph">如果用户配置了基于密码的sudo访问权限、请运行以下命令以运行攻略手册、然后输入sudo密码。</block>
  <block id="f04c9d184475a1c831571242df5998ca" category="paragraph">除了已付费版本的Astra控制中心之外、还提供90天评估许可证。评估版可通过电子邮件和社区Slack渠道获得支持。客户可以访问这些资源、其他知识库文章以及产品支持信息板上提供的文档。</block>
  <block id="9c38b2d834f16a22a033cc493828d911" category="paragraph">NetApp Cloud Volumes ONTAP 是NetApp ONTAP 的云部署版本、可部署在多个公有 云中、包括Amazon AWS、Microsoft Azure和Google Cloud。</block>
  <block id="c48c25afacd7dddac49ab104ad056df0" category="paragraph">Astra Trident是一款完全受支持的开源存储编排程序、适用于｛K8s_distribution_name｝等容器和Kubernetes分发版。Trident 可与包括 NetApp ONTAP 和 Element 存储系统在内的整个 NetApp 存储产品组合配合使用，并且还支持 NFS 和 iSCSI 连接。Trident 允许最终用户从其 NetApp 存储系统配置和管理存储，而无需存储管理员干预，从而加快了 DevOps 工作流的速度。</block>
  <block id="7654a00ca744e9bf01021439190e3119" category="doc">VMware Tanzu Kubernetes Grid Integrated Edition (TKGI)概述</block>
  <block id="644bd75ee9c13f7d8778e4638d9eb2b2" category="paragraph">VMware Tanzu Kubernetes Grid Integrated (TKGI) Edition (以前称为VMware Enterprise PKS)是一个基于Kubernetes的独立容器编排平台、具有生命周期管理、集群运行状况监控、高级网络连接、容器注册表等功能。TKGI使用由Bossh和Ops Manager组成的TKGI控制平面来配置和管理Kubernetes集群。</block>
  <block id="a84b33dfae5a2fdc1618084442bc3df0" category="paragraph">TKGI可以在内部vSphere或OpenStack环境中安装和操作、也可以在其各自IaaS产品上的任何主要公有 云中安装和操作。此外、通过将TKGI与NSX-T和港口相集成、企业工作负载的使用情形也会更加广泛。要了解有关TKGI及其功能的更多信息、请访问相关文档 <block ref="0b1e387b87be5caa8371b58b8e02b1f8" category="inline-link-macro-rx"></block>。</block>
  <block id="26f1f37ed65557967fe3a789aa75c364" category="paragraph">根据不同的用例和设计、TKGI安装在多种平台上。按照指南进行操作 <block ref="54093918574a441541c9219fc9d087f1" category="inline-link-macro-rx"></block> 安装和配置TKGI及其前提条件。TKGI使用Bossh VM作为Tanzu Kubernetes集群的节点、这些集群运行不可变的配置映像、并且在Bossh VM上进行的任何手动更改在重新启动后都不会保持持久性。</block>
  <block id="58959a34911d9e88e191f3453ddc81f0" category="paragraph">重要注意事项：</block>
  <block id="d7fc6fcd5f3c3c3fca9edded9bf380e1" category="list-text">NetApp Trident需要有权限的容器访问。因此、在安装TKGI期间、请确保选中步骤中的启用特权容器复选框以配置Tanzu Kubernetes集群节点计划。</block>
  <block id="651650f759262b05cb38b56003e55784" category="image-alt">TKGI中的特权容器</block>
  <block id="956d281862a0ec3c4bb386cd28bf959c" category="list-text">NetApp建议将所有生产环境部署在多个主部署中、以实现容错、并选择工作节点的配置、以满足预期工作负载的要求。因此、对于高度密集型工作负载、建议的TKGI集群计划应至少由三名主节点和三名员工组成、其中至少包含四个vCPU和12 GB RAM。</block>
  <block id="71417a3dd01aa388d35bf54aa4c401fa" category="summary">此页面包含一些视频链接、这些视频演示了本文档中介绍的一些功能。</block>
  <block id="952be0b8dee874c73cd76a4d6a526b27" category="doc">视频和演示：采用NetApp的VMware Tanzu</block>
  <block id="de15ad9e760a3587b2effb60a58133b1" category="summary">Astra Trident是一款开源且完全受支持的存储编排程序、适用于容器和Kubernetes分发版、包括VMware Tanzu。</block>
  <block id="143c9ea21ac76ba425aa94411fbba07b" category="doc">Astra Trident概述</block>
  <block id="ebe5598ec22d01fe25c02071b488309b" category="section-title">使用Helm部署Trident操作员</block>
  <block id="a082551b03c5e35829be23792317ac16" category="list-text">添加NetApp Astra Trident Helm存储库。</block>
  <block id="836237f5ff429cb9283688cdfaa56c76" category="list-text">更新Helm存储库。</block>
  <block id="875c7439b686e253522033c63d909efe" category="list-text">为Trident的安装创建新的命名空间。</block>
  <block id="82b1cf842f022e618212caef5d3c942d" category="list-text">使用DockerHub凭据创建一个密钥以下载Astra Trident映像。</block>
  <block id="e5073fdda88ef7d6b18ac4f938abbece" category="list-text">对于由TKGS (采用Tanzu的vSphere)或采用管理集群部署的TKG管理的用户或工作负载集群、请完成以下操作步骤 以安装Astra Trident：</block>
  <block id="d409e9c69dd2082fd0ed8a86d87258e8" category="list-text">确保已登录用户有权在Trident命名空间中创建服务帐户、并且Trident命名空间中的服务帐户有权创建Pod。</block>
  <block id="397ae57f2a6cbd8444c419c896f19886" category="list-text">运行以下helm命令、在创建的命名空间中安装Trident操作员。</block>
  <block id="eef6352658410e2218bd7027ae8ff351" category="list-text">对于由TKGI部署管理的用户或工作负载集群、请运行以下helm命令在创建的命名空间中安装Trident操作员。</block>
  <block id="12d34565a0d56eff4f8d3f99b138e11a" category="list-text">验证Trident Pod是否已启动且正在运行。</block>
  <block id="f48fa73c7f509e20ce14901e4639f13d" category="paragraph">完成 Astra Trident 操作员安装后，您必须为所使用的特定 NetApp 存储平台配置后端。按照以下链接继续设置和配置Astra Trident。</block>
  <block id="c060cacb4d77409e1402a5dcab49bf8b" category="list-text"><block ref="c060cacb4d77409e1402a5dcab49bf8b" category="inline-link-macro-rx"></block></block>
  <block id="2280e7f4e3cc9a8caee65d058e1db860" category="list-text"><block ref="2280e7f4e3cc9a8caee65d058e1db860" category="inline-link-macro-rx"></block></block>
  <block id="fa6f7af807ffa3ac6e2efb5c31463a4f" category="paragraph">要通过NFS与NetApp ONTAP 存储系统实现Trident集成、您必须创建一个后端、以便与存储系统进行通信。我们在此解决方案 中配置了一个基本后端、但如果您要查找更多自定义选项、请访问相关文档 <block ref="f72d871ae286e7b7cf7d9ea12426661a" category="inline-link-macro-rx"></block>。</block>
  <block id="aaa6c6e969e6e978f9a8bce54e31b5f7" category="section-title">在ONTAP 中创建SVM</block>
  <block id="b1c04b7e96694453a1307ecc81208ae5" category="list-text">登录到ONTAP 系统管理器、导航到存储&gt; Storage VM、然后单击添加。</block>
  <block id="f53bd08113ff367a9bcd470b70a036d8" category="list-text">输入SVM的名称、启用NFS协议、选中允许NFS客户端访问复选框、然后在导出策略规则中添加工作节点所在的子网、以便允许将卷作为PV挂载到工作负载集群中。</block>
  <block id="0cdb2a8f015b7a7d81ab5c3d73de88a5" category="image-alt">使用NFS创建SVM</block>
  <block id="e570ad3092406b5118fcd78a9374e048" category="admonition">如果您要在NSX-T中使用NAT部署用户集群或工作负载集群、则需要将出口子网(对于TKGS0)或浮动IP子网(对于TKGI)添加到导出策略规则中。</block>
  <block id="8f254daa71e82320e11e55258b095b00" category="list-text">提供数据LIF的详细信息以及SVM管理帐户的详细信息、然后单击保存。</block>
  <block id="02ffb816541fbf18a204c877564fb92e" category="image-alt">SVM数据LIF和SVM管理</block>
  <block id="491df82049a4ac2d8b8b2fe6b773d65d" category="list-text">将聚合分配给SVM。导航到存储&gt;存储VM、单击新创建的SVM旁边的省略号、然后单击编辑。选中将卷创建限制为首选本地层复选框、并将所需聚合附加到其中。</block>
  <block id="85c5adc69f6da0ebb2ebf365c4211508" category="image-alt">SVM聚合分配</block>
  <block id="95fdf7e31ffa1073f8c42359589c334e" category="list-text">如果要安装Trident的用户或工作负载集群采用NAT方式进行部署、则由于SNAT、存储挂载请求可能来自非标准端口。默认情况下、ONTAP 仅允许从根端口发出卷挂载请求。因此、请登录到ONTAP 命令行界面并修改设置、以允许来自非标准端口的挂载请求。</block>
  <block id="03c8ff4111bb9cfc032f786c9bd7c6e8" category="section-title">创建后端和StorageClasses</block>
  <block id="e15177ebae9bfb9adab94a9ccf5f2e96" category="list-text">对于提供NFS服务的NetApp ONTAP 系统、请使用backendName、managementLIF、dataLIF、SVM、username在jumphost上创建一个后端配置文件。 密码和其他详细信息。</block>
  <block id="c75cfbdcbbe9d48dc121fc816d4a2ccf" category="list-text">运行以下命令创建Trident后端。</block>
  <block id="ad2008cda12d454189828df19b2f9742" category="list-text">创建后端后，您接下来必须创建一个存储类。以下存储类定义示例突出显示了必填字段和基本字段。参数`backendType`应反映新创建的Trident后端的存储驱动程序。</block>
  <block id="0286d73690ed0ef54af06bd9175945cd" category="list-text">运行kubectl命令创建存储类。</block>
  <block id="8d8b689e86dbd34b31294b3f829db499" category="list-text">创建存储类后，您必须创建第一个永久性卷请求（ PVC ）。下面提供了一个PVC定义示例。确保`storageClassName`字段与刚刚创建的存储类的名称匹配。根据要配置的工作负载、可以根据需要进一步自定义PVC定义。</block>
  <block id="c764ff1d25a2f9241afec7161127f74d" category="list-text">发出kubectl命令创建PVC。根据所创建的后备卷的大小，创建可能需要一些时间，因此您可以在该过程完成后进行观察。</block>
  <block id="5f87e8fbf603b28eb84592d8e64980c6" category="doc">追加信息 ：采用NetApp技术的VMware Tanzu</block>
  <block id="a6f4f5f0d313fa8894e4ad13a09339c0" category="list-text">VMware Tanzu文档</block>
  <block id="57a35ee57ca4eb666386f668ebc74599" category="inline-link"><block ref="57a35ee57ca4eb666386f668ebc74599" category="inline-link-rx"></block></block>
  <block id="35d5768f9d0ee829a3e2cae0cba15216" category="paragraph"><block ref="35d5768f9d0ee829a3e2cae0cba15216" category="inline-link-rx"></block></block>
  <block id="2839dd9e9e31ca41ba6399c0a64d3333" category="list-text">VMware Tanzu Kubernetes网格文档</block>
  <block id="94ecd750f91f6d1908b92ec42eb37398" category="inline-link"><block ref="94ecd750f91f6d1908b92ec42eb37398" category="inline-link-rx"></block></block>
  <block id="f0a59887fc9e8ee88512ff6312c13efa" category="paragraph"><block ref="f0a59887fc9e8ee88512ff6312c13efa" category="inline-link-rx"></block></block>
  <block id="9cf21c31f745a435ac892addf1fd1a3f" category="list-text">VMware Tanzu Kubernetes网格服务文档</block>
  <block id="98978b88e05533d45b79613d9ee6f26d" category="inline-link"><block ref="98978b88e05533d45b79613d9ee6f26d" category="inline-link-rx"></block></block>
  <block id="56c4cea9b33fd23cf082d00ca92d5a46" category="paragraph"><block ref="56c4cea9b33fd23cf082d00ca92d5a46" category="inline-link-rx"></block></block>
  <block id="c23715ed7437fed1084a24cebb89e63c" category="list-text">VMware Tanzu Kubernetes Grid Integrated Edition文档</block>
  <block id="fd2560680b89b39b1b988587bf383fb4" category="inline-link"><block ref="fd2560680b89b39b1b988587bf383fb4" category="inline-link-rx"></block></block>
  <block id="f4b2873e621660e86074a62e5a6c5eac" category="paragraph"><block ref="f4b2873e621660e86074a62e5a6c5eac" category="inline-link-rx"></block></block>
  <block id="3ff1ba174bc4d7824738ba1a0c0b4035" category="summary">NetApp Astra控制中心为有状态Kubernetes工作负载提供了一组丰富的存储和应用程序感知型数据管理服务、这些服务部署在内部环境中、并采用NetApp值得信赖的数据保护技术。</block>
  <block id="678f429fd30f5d3718b72e260e17f5f0" category="paragraph">如果您正在寻找可与Astra Control REST API交互的现成软件开发工具包、NetApp提供了一个包含Astra Control Python SDK的工具包、您可以下载该工具包 <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>。</block>
  <block id="6b24baf9bd0e230b887612f836d0fbd5" category="paragraph">如果编程不适合您的情况、并且您希望使用配置管理工具、则可以克隆并运行NetApp发布的Ansible攻略手册 <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>。</block>
  <block id="c90524de7ee251d8a5128ac3f59847c6" category="paragraph">安装Astra控制中心需要满足以下前提条件：</block>
  <block id="9f2559e9a5f31fdb3d5489aa3367ae35" category="list-text">一个或多个由管理集群、TKGS或TKGI管理的Tanzu Kubernetes集群。支持TKG工作负载集群1.4+和TKGI用户集群1.12.2+。</block>
  <block id="c94e1287a80d82c490967572d336083d" category="list-text">必须已在每个Tanzu Kubernetes集群上安装和配置Astra Trident。</block>
  <block id="ba1c516a3e7a998469a5ac73695127ce" category="admonition">最佳做法是、每个安装在站点上的Tanzu Kubernetes都要有一个专用的SVM来实现永久性存储。多站点部署需要额外的存储系统。</block>
  <block id="c756010e6a027d7d6ae199c033f4b1db" category="list-text">必须在每个Tanzu Kubernetes集群上配置一个Trident存储后端、其中包含一个由ONTAP 集群提供支持的SVM。</block>
  <block id="dd7ed1e31baf27a40282a08242cf6efc" category="list-text">在每个Tanzu Kubernetes集群上配置的一个默认StorageClass、其中使用Astra Trident作为存储配置程序。</block>
  <block id="e8ed7f9c94a716f73364706e6db9c1c6" category="list-text">如果您使用的是ingType `AccesTraefik`、则必须在每个Tanzu Kubernetes集群上安装并配置负载平衡器、以实现负载平衡并公开Astra控制中心。</block>
  <block id="6b769b6cd8bf0a312e04e05973e13018" category="list-text">如果您使用的是ingressType `Generic`、则必须在每个Tanzu Kubernetes集群上安装并配置一个入口控制器、以公开Astra控制中心。</block>
  <block id="0e6886020b4adf5871ebc7346b63c3a0" category="list-text">您必须对安装了Astra控制中心的Tanzu Kubernetes集群具有集群管理员访问权限。</block>
  <block id="8bd3433e327d75f3a3c33d9998840fce" category="list-text">RHEL或Ubuntu管理工作站。</block>
  <block id="ed060d0439d2eda03baa2005199d9bc1" category="paragraph">本解决方案 介绍了使用Ansible攻略手册安装Astra控制中心的自动化操作步骤。如果您正在寻找手动操作步骤 来安装Astra控制中心、请按照详细的安装和操作指南进行操作 <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>。</block>
  <block id="df57d245f4173d8ac23df756917bb6ae" category="list-text">创建或获取对要安装Astra控制中心的用户或工作负载Tanzu Kubernetes集群具有管理员访问权限的kubeconfig文件。</block>
  <block id="b2d9440273952d4b05aed1b36c66494d" category="list-text">将目录更改为`na_astera_control_suite`。</block>
  <block id="7489123185b81a6e11b42218fabb4c3b" category="list-text">编辑`vars/vars.yml`文件并使用所需信息填充变量。</block>
  <block id="2b6b49be82749b9e141c2f0a23c8d11f" category="paragraph">如果运行攻略手册的用户为root或配置了无密码sudo、请运行以下命令运行攻略手册。</block>
  <block id="111dd0947a16442f317af649a2aac536" category="list-text">如果ingressType为AccTraefik、请获取trafik服务负载平衡器IP。</block>
  <block id="25ce05402248633e67c7cbc234573b60" category="list-text">要使Astra控制中心的所有功能正常运行、需要获得许可证。要添加许可证，请导航到 " 帐户 "&gt;" 许可证 " ，单击 " 添加许可证 " ，然后上传许可证文件。</block>
  <block id="bf3293f2603ff733102e45d1152bc0a1" category="admonition">如果您在安装或配置 NetApp Astra 控制中心时遇到问题，可以参考已知问题的知识库<block ref="695f48b1d8b7348c0e2828947d24161e" category="inline-link-rx"></block>。</block>
  <block id="318a4bce7f9fca07a60ed82408fbcd29" category="doc">VMware Tanzu Kubernetes Grid (TKG)概述</block>
  <block id="11e5f8209ef45e9884518caf7b5bc68d" category="paragraph">VMware Tanzu Kubernetes Grid也称为TKG、可用于在混合云或公有 云环境中部署Tanzu Kubernetes集群。TKG作为管理集群进行安装、该集群本身就是Kubernetes集群、用于部署和操作Tanzu Kubernetes集群。这些Tanzu Kubernetes集群是部署了实际工作负载的工作负载Kubernetes集群。</block>
  <block id="9a67a32e17609515d2fc11383d1a7b59" category="paragraph">Tanzu Kubernetes Grid基于一些前景广阔的上游社区项目构建、并提供由VMware开发、营销和支持的Kubernetes平台。除了Kubernetes分发版之外、Tanzu Kubernetes Grid还提供了其他附加组件、这些附加组件是重要的生产级服务、例如注册表、负载平衡、身份验证等。具有管理集群的VMware TKG在vSphere 6.7环境中广泛使用、尽管它受支持、但不建议在vSphere 7环境中部署、因为TKGS具有与vSphere 7的原生 集成功能。</block>
  <block id="4e6c29e9760f3e53993a64a5f6c63aaa" category="image-alt">具有管理集群的VMware Tanzu Kubernetes Grid</block>
  <block id="ec30336a82729146050b0931adab64f2" category="paragraph">有关Tanzu Kubernetes Grid的详细信息、请参见文档 <block ref="f4dbc56b610d9f5cd603e1a13bb6dedf" category="inline-link-macro-rx"></block>。</block>
  <block id="86fcbed2a7f5b8edced11b10bd1e4266" category="paragraph">根据Tanzu Kubernetes网格是安装在vSphere集群内部还是云环境中、请按照安装指南准备并部署Tanzu Kubernetes网格 <block ref="492c3fae38681e036fd18bedc1bf8ae5" category="inline-link-macro-rx"></block>。</block>
  <block id="c1f07986544fbf96897f8099577b0e72" category="paragraph">安装完Tanzu Kubernetes Grid的管理集群后、请根据需要按照文档部署用户集群或工作负载集群 <block ref="7d3f6d9f879d392af501006eacd0d221" category="inline-link-macro-rx"></block>。VMware TKG管理集群要求为Tanzu Kubernetes集群的安装和操作提供SSH密钥。此密钥可用于使用`capv`用户登录到集群节点。</block>
  <block id="07f15dfb0f84a062c67184adcee67a8b" category="summary">本参考文档对不同类型的VMware Tanzu Kubernetes解决方案进行了部署验证、这些解决方案已通过NetApp验证部署为Tanzu Kubernetes Grid (TKG)、Tanzu Kubernetes Grid Service (TKGS)或Tanzu Kubernetes Grid Integrated (TKGI)。</block>
  <block id="bec8bc9f783c7d01005b7e64d1ad1785" category="doc">NVA-1166：采用NetApp技术的VMware Tanzu</block>
  <block id="c837e955d75d674feb57af7e68b3d74c" category="paragraph">本参考文档对不同类型的VMware Tanzu Kubernetes解决方案进行了部署验证、这些解决方案已通过NetApp验证部署为Tanzu Kubernetes Grid (TKG)、Tanzu Kubernetes Grid Service (TKGS)或Tanzu Kubernetes Grid Integrated (TKGI)。同时、还介绍了与NetApp存储系统以及用于管理永久性存储的Astra Trident存储编排程序的存储集成、以及用于使用此永久性存储备份和克隆有状态应用程序的Astra控制中心。最后、本文档还提供了有关解决方案 集成和验证的视频演示。</block>
  <block id="c0a14f456cfcfac669f2cf374f60561b" category="paragraph">采用NetApp解决方案 的VMware Tanzu经过精心设计、可在以下使用情形下为客户提供卓越的价值：</block>
  <block id="8cc1d80dbdd5d6d142f0173d8c8f2261" category="list-text">易于部署和管理部署在VMware vSphere上并与NetApp存储系统集成的VMware Tanzu Kubernetes Grid产品。</block>
  <block id="8796988ff3c4f065733c3b887d886609" category="list-text">企业级容器和虚拟化工作负载与VMware Tanzu Kubernetes Grid产品相结合的强大功能。</block>
  <block id="d7071bc518e2fa9a30b1debdd8e721f1" category="list-text">与NetApp存储和NetApp Astra产品套件结合使用时、真实的配置和使用情形重点介绍了VMware Tanzu的功能。</block>
  <block id="3d4565b89cb9591acc32839ce0d48627" category="list-text">使用Astra控制中心对部署在VMware Tanzu Kubernetes Grid集群上的容器化工作负载进行应用程序一致的保护或迁移、这些集群的数据驻留在NetApp存储系统上。</block>
  <block id="29375f7cc2c5eece7fdd9c99f40eb3f8" category="list-text">能够在混合云模式下部署、容器既在内部数据中心运行、也在云中运行。</block>
  <block id="ddea0381617b5a4b43a0a98a440c6658" category="paragraph">VMware Tanzu和NetApp公司对这些挑战表示认可、并提供了一个解决方案 、通过在客户选择的混合云环境中部署VMware Tanzu Kubernetes产品来帮助解决每个问题。</block>
  <block id="c57f369df48137f738543c0e5012006c" category="paragraph">采用NetApp解决方案 的VMware Tanzu由以下主要组件组成：</block>
  <block id="67d7b0b61202e57bcae8cda82f02e2b3" category="section-title">VMware Tanzu Kubernetes平台</block>
  <block id="55ad4cb8f0feecb71e184ef92cff1f70" category="paragraph">VMware Tanzu具有各种不同的风格、NetApp的解决方案工程团队已经在我们的实验室中进行了验证。每个Tanzu版本都成功地与NetApp存储产品组合集成、并且每个版本都可以帮助满足特定的基础架构需求。以下项目符号重点介绍了本文档中所述的每个Tanzu版本的功能和功能。</block>
  <block id="5849f8d5cb1d66cb095da163e533dea7" category="paragraph">VMware Tanzu Kubernetes网格(TKG)</block>
  <block id="45915535ce313f81567f3b3c41571fe9" category="list-text">在VMware vSphere环境中部署的标准上游Kubernetes环境。</block>
  <block id="32fcd5c42dc47b5cc021d74a489dee4f" category="list-text">以前称为基本PKS (从2019年2月的收购获得)。</block>
  <block id="16196833d09cc8d52a1ef3790b4e15d3" category="list-text">TKG部署有一个单独的管理集群实例、以便在vSphere 6.7U3及更高版本上提供支持。</block>
  <block id="08f2ff1c0826ffc53a185010cce7dac7" category="list-text">TKG部署既可以部署在云中、也可以部署在AWS或Azure中。</block>
  <block id="15aa7eec2d32a1ba74b5cea8af5241ec" category="list-text">允许使用Windows或Linux工作节点(Ubuntu或Photon)。</block>
  <block id="89a8813ef0f3f2c1a9b0f20dab87e2a2" category="list-text">NSX-T、HA代理、Avi网络或负载平衡器可用于控制平面。</block>
  <block id="2ad16c86af27df82ae725dfd15176212" category="list-text">TKG支持应用程序/数据平面的MetalLB。</block>
  <block id="7bf259c507ef53db8da3607757164b2e" category="list-text">可以使用vSphere CSI以及NetApp Astra Trident等第三方CSI。</block>
  <block id="c840af216b38aff44cc5ba246da60e17" category="paragraph">VMware Tanzu Kubernetes网格服务(TKGS)</block>
  <block id="27077307fac1683851c72a97ba11c62e" category="list-text">仅在vSphere 7.0U1及更高版本上部署了与监控集群和工作负载集群一起部署的TKGS。</block>
  <block id="3ee27cde76894c76ad60736ecbca78da" category="list-text">TKGS支持对应用程序/数据平面使用MetalLB。</block>
  <block id="443c9bd7eeb4bc3d39f67cc555b4aab2" category="list-text">为采用Tanzu的vSphere Pod提供支持、允许Pod直接在环境中已启用的ESXi主机上运行。</block>
  <block id="f4ef19f9ee886fa602632ef3f35019ad" category="list-text">以前称为企业级PKS (从收购eptio获得、2019年2月)。</block>
  <block id="28789df26df63aa440b3aded601e67a6" category="list-text">可以使用NSX-T、HA代理或Avi。您还可以提供自己的负载平衡器。</block>
  <block id="2b681f710a75cd56332534e50fe625ff" category="list-text">受vSphere 6.7U3及更高版本以及AWS、Azure和GCP支持。</block>
  <block id="f09eefe449cf027cce033ceb064c2fae" category="list-text">通过向导进行设置、以便于部署。</block>
  <block id="78c9a89b579a1005676bf4b1a4b3aad7" category="list-text">在由Bossh管理的受控不可变VM中运行Tanzu。</block>
  <block id="46c96f35ab6c6f57dd96776e1f115737" category="list-text">可以使用vSphere CSI以及NetApp Astra Trident等第三方CSI (某些条件适用)。</block>
  <block id="b63d5ee355078976e86c94b5c978788e" category="paragraph">NetApp Astra控制中心为有状态的Kubernetes工作负载提供一套丰富的存储和应用程序感知型数据管理服务、这些服务部署在内部环境中、并采用值得信赖的NetApp数据保护技术。</block>
  <block id="e764fe6b8f8825a307a87cedbef45678" category="cell">22.04</block>
  <block id="63355c54bd7e8ff73915da41610ec6f7" category="cell">22.04.0</block>
  <block id="22053fd2d26d3a313aea03b09e9a776c" category="cell">VMware Tanzu Kubernetes网格服务</block>
  <block id="c99c6e88d4de8db879b1b5ec64d1f7ed" category="cell">0.0.15个vSphere命名空间</block>
  <block id="8eb1302ead60c09b6d757b2b7ab84040" category="cell">1.22.6 [监控集群Kubernetes ]</block>
  <block id="caf617dd6edf29fd289caff7469ea66b" category="cell">VMware Tanzu Kubernetes Grid Integrated</block>
  <block id="1d5bc9367c9565bbe31cc00aa1f870a4" category="cell">1.13.3.</block>
  <block id="5d9dd4ee62c5446f01e895cd118d98dd" category="cell">VMware NSX-T数据中心</block>
  <block id="7bc09c21b8fa1161768459982f0ec89e" category="cell">网络和安全性</block>
  <block id="b1179856b0372cb8777975cb658548ac" category="cell">3.1.3</block>
  <block id="cc540661734771d2e0272e8b4ef5c228" category="cell">VMware NSX高级负载平衡器</block>
  <block id="50382c1137e78c7c038faabadb85d9fd" category="cell">负载平衡器</block>
  <block id="d08680d7e9b745c4d4b81a2d6df7a012" category="cell">20.1.3</block>
  <block id="30a7219728f2665214ac7ae0458c27a8" category="list-text"><block ref="30a7219728f2665214ac7ae0458c27a8" category="inline-link-macro-rx"></block></block>
  <block id="15693c045ae1b118bd5c3f8e9cee5c08" category="summary">要使Astra控制中心能够管理工作负载、您必须先注册Tanzu Kubernetes集群。</block>
  <block id="3a16c17a7d5ce69951add72b2e46c340" category="doc">将VMware Tanzu Kubernetes集群注册到Astra控制中心</block>
  <block id="a723b0aede16ae3d3bdd6761d359595b" category="section-title">注册VMware Tanzu Kubernetes集群</block>
  <block id="779e6578abb36499d7c5399b33269c9c" category="list-text">第一步是将Tanzu Kubernetes集群添加到Astra控制中心并对其进行管理。转至Clusters并单击Add a Cluster、上传Tanzu Kubernetes集群的kubeconfig文件、然后单击Select Storage。</block>
  <block id="d9687c204aa759a004b29f4f41e01908" category="list-text">添加集群后、集群将变为"正在发现"状态、而Astra控制中心将对其进行检查并安装必要的代理。成功注册后、集群状态将更改为`Healthy`。</block>
  <block id="1e7084bafe0fe7d10e28e10eea2641aa" category="admonition">在受管集群上安装的代理从该注册表中提取映像时、由Astra控制中心管理的所有Tanzu Kubernetes集群都应有权访问用于安装的映像注册表。</block>
  <block id="f3eca6ba1067d4a61b1229f18ab1a463" category="list-text">将 ONTAP 集群作为存储资源导入，以便由 Astra 控制中心作为后端进行管理。在将Tanzu Kubernetes集群添加到Astra并配置了storageclass后、它会自动发现并检查支持该storageclass的ONTAP 集群、但不会将其导入到要管理的Astra控制中心中。</block>
  <block id="3c786ecd99f0ebd5edd64d81ad32375c" category="list-text">要导入ONTAP 集群、请导航到后端、单击下拉列表、然后选择要管理的ONTAP 集群旁边的管理。输入 ONTAP 集群凭据，单击查看信息，然后单击导入存储后端。</block>
  <block id="af64f63e0642401224fc8f9c2ec7d1c5" category="list-text">添加后端后，状态将更改为 Available 。现在、这些后端可提供有关Tanzu Kubernetes集群中的永久性卷以及ONTAP 系统上的相应卷的信息。</block>
  <block id="688cdc8b62507f4c74f7452e7889821d" category="list-text">要使用Astra控制中心在Tanzu Kubernetes集群之间进行备份和还原、您必须配置支持S3协议的对象存储分段。当前支持的选项包括ONTAP S3、StorageGRID 、AWS S3和Microsoft Azure Blob Storage。为此，我们将配置一个 AWS S3 存储分段。转到 " 分段 " ，单击 " 添加分段 " ，然后选择 " 通用 S3" 。输入有关S3存储分段和凭据的详细信息以访问它、单击复选框将此存储分段设置为云的默认存储分段、然后单击添加。</block>
  <block id="9c5a4b54facfb25c9699e51ca3728574" category="summary">注册VMware Tanzu Kubernetes集群后、您可以通过Astra控制中心发现已部署的应用程序并对其进行管理。</block>
  <block id="ada6daf9261af1429947be91dd72757b" category="paragraph">注册完Tanzu Kubernetes集群后、您可以通过Astra控制中心发现已部署的应用程序并对其进行管理。</block>
  <block id="48652ad0d003928f33825c84d5c8d950" category="list-text">在将Tanzu Kubernetes集群和ONTAP 后端注册到Astra控制中心后、控制中心将自动开始发现所有命名空间中使用配置了指定ONTAP 后端的storageclass的应用程序。</block>
  <block id="96b5419ab713b49685af4d923930ce22" category="summary">要通过iSCSI将NetApp ONTAP 存储系统与用于永久性卷的VMware Tanzu Kubernetes集群集成、第一步是通过登录每个节点并配置iSCSI实用程序或软件包来准备节点以挂载iSCSI卷。</block>
  <block id="da883967924519350a1c423bd85906dd" category="paragraph">要通过iSCSI将NetApp ONTAP 存储系统与适用于永久性卷的VMware Tanzu Kubernetes集群集成、第一步是通过登录到每个节点并配置iSCSI实用程序或软件包以挂载iSCSI卷来准备节点。为此、请按照本节中所述的操作步骤 进行操作 <block ref="fb2092145032d18c9376d95ca453f9a7" category="inline-link-macro-rx"></block>。</block>
  <block id="50c35de69200a8b9e4be302372e74851" category="admonition">NetApp不建议在采用NAT方式部署VMware Tanzu Kubernetes集群时使用此操作步骤。</block>
  <block id="bfc5022105ee1678e96b6f9991116647" category="admonition">TKGI使用Bossh VM作为运行不可变配置映像的Tanzu Kubernetes集群的节点、而在重新启动后、对Bossh VM上的iSCSI软件包进行的任何手动更改都不会保持持久性。因此、NetApp建议对由TKGI部署和操作的Tanzu Kubernetes集群使用NFS卷作为永久性存储。</block>
  <block id="16e4431f428a4ec8abdfbee6ec2c2889" category="paragraph">为iSCSI卷准备好集群节点后、您必须创建一个后端、以便与存储系统进行通信。我们在此解决方案 中配置了一个基本后端、但是、如果您要查找更多自定义选项、请访问文档 <block ref="f151238ff3a8d488c82b6303d676eaa3" category="inline-link-macro-rx"></block>。</block>
  <block id="31cd969d7cf1970993d449ccccaeddfe" category="paragraph">要在ONTAP 中创建SVM、请完成以下步骤：</block>
  <block id="70d94c82da2765251783d499556773b7" category="list-text">输入SVM的名称、启用iSCSI协议、然后提供数据LIF的详细信息。</block>
  <block id="9305b9f7555d613129963713b0c214e6" category="image-alt">iSCSI SVM数据LIF</block>
  <block id="f9edece6d4cf48c209a5fe7da61f0ecb" category="list-text">输入SVM管理帐户的详细信息、然后单击保存。</block>
  <block id="2b44a7a64e9a3efc0b4e423d6339aaa7" category="image-alt">iSCSI SVM管理</block>
  <block id="f61c0f70e825557a7be7fe0ac432bdf7" category="list-text">要将聚合分配给SVM、请导航到存储&gt;存储VM、单击新创建的SVM旁边的省略号、然后单击编辑。选中将卷创建限制为首选本地层复选框、并将所需聚合附加到其中。</block>
  <block id="74ede5d2e56e369e9eda54f4095292f5" category="list-text">创建后端之后、您必须接下来创建一个存储类。以下存储类定义示例突出显示了必填字段和基本字段。参数`backendType`应反映新创建的Trident后端的存储驱动程序。另请注意 name-field 值，稍后必须引用该值。</block>
  <block id="cf2c5963ca8332d4f43e6c3a955da4da" category="admonition">此文件中定义了一个名为 `FSType` 的可选字段。在iSCSI后端、可以将此值设置为特定的Linux文件系统类型(XFS、ext4等)、也可以删除此值、以便Tanzu Kubernetes集群决定要使用的文件系统。</block>
  <block id="af4fcf3aff174981414dc5c9fce2f4ec" category="section-title">创建应用程序快照</block>
  <block id="29335406e75e8b137ee91c9f44068bc6" category="paragraph">应用程序的快照会创建ONTAP Snapshot副本和应用程序元数据的副本、这些副本可用于根据该Snapshot副本将应用程序还原或克隆到特定时间点。</block>
  <block id="9bb92323cd91f66cadcdc492341cddd5" category="section-title">创建应用程序备份</block>
  <block id="c4c29bc3f7db6d04fde98415386e1e7f" category="list-text">要还原应用程序、请导航到应用程序&gt;受管选项卡、然后单击相关应用程序。单击应用程序名称旁边的下拉菜单、然后单击还原。</block>
  <block id="2c0d64177d5c89bc452e9f1eb0fd4f65" category="list-text">输入新命名空间的详细信息、选择要将其克隆到的集群、然后选择是要从现有快照、从备份还是从应用程序的当前状态克隆该命名空间。查看详细信息后、单击下一步、然后单击审阅窗格上的克隆。</block>
  <block id="ef0b684dddd1cea4885513d892f39cfa" category="paragraph"><block ref="ef0b684dddd1cea4885513d892f39cfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3901d4e16e17c29d42ccb430b94cc402" category="paragraph"><block ref="3901d4e16e17c29d42ccb430b94cc402" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62772f599e4130a9b43b483c82338681" category="summary">VMware Tanzu是一款产品组合、可帮助企业实现应用程序及其运行基础架构的现代化。VMware Tanzu的全套功能将开发和IT运营团队整合在一个平台上、在内部和混合云环境中统一地在其应用程序和基础架构中实现现代化、从而持续为生产提供更好的软件。</block>
  <block id="969f4a20d38cf3096e1659b96da1b729" category="doc">VMware Tanzu概述</block>
  <block id="c395793804bd9dfa82ff727781faf3c5" category="image-alt">VMware Tanzu产品组合</block>
  <block id="3614585a8ed284306a5eadc9e31585b8" category="paragraph">要详细了解Tanzu产品组合中的不同产品和功能、请访问相关文档 <block ref="e9fed892b98a6bbccfc15bfe67c5aa96" category="inline-link-macro-rx"></block>。</block>
  <block id="3ff60e0bc78c13ace612734741c1e1da" category="paragraph">关于Tanzu的Kubernetes Operations目录、VMware针对Tanzu Kubernetes Grid实施了多种方案、所有这些方案都可以在各种平台上配置和管理Tanzu Kubernetes集群的生命周期。Tanzu Kubernetes集群是由VMware构建并支持的成熟的Kubernetes分发版。</block>
  <block id="caaf1eb22b79381e3d4a2b2b9a7d1698" category="paragraph">NetApp已在其实验室中测试并验证了以下VMware Tanzu产品组合产品的部署和互操作性：</block>
  <block id="0fe3792ebba34a6c12f05656d54ecb49" category="list-text"><block ref="0fe3792ebba34a6c12f05656d54ecb49" category="inline-link-macro-rx"></block></block>
  <block id="eac001284f9380ccf17ee4490dbe13e1" category="list-text"><block ref="eac001284f9380ccf17ee4490dbe13e1" category="inline-link-macro-rx"></block></block>
  <block id="d6a1da4b26eb2ae838f5db5e80c44aee" category="inline-link-macro">VMware Tanzu Kubernetes Grid Integrated (TKGI)</block>
  <block id="57729a0bf5ad457403cd6505bdfeb143" category="list-text"><block ref="57729a0bf5ad457403cd6505bdfeb143" category="inline-link-macro-rx"></block></block>
  <block id="aa7b3dace1453f21689852e3b066f673" category="summary">VMware Tanzu Kubernetes Grid Service (也称为vSphere with Tanzu)可让您在vSphere中本机创建和操作Tanzu Kubernetes集群、还可以直接在ESXi主机上运行一些较小的工作负载。</block>
  <block id="b71ad38bc3fd2c1a10efc2b09270e430" category="doc">VMware Tanzu Kubernetes Grid Service (TKGS)概述</block>
  <block id="9f0bacdd758242392df6d215d34d9b8e" category="paragraph">VMware Tanzu Kubernetes Grid Service (也称为vSphere with Tanzu)可让您在vSphere中本机创建和操作Tanzu Kubernetes集群、还可以直接在ESXi主机上运行一些较小的工作负载。通过它、您可以将vSphere转换为一个平台、以便在虚拟机管理程序层本机运行容器化工作负载。Tanzu Kubernetes Grid Service启用后、会在vSphere上部署一个监控集群、用于部署和运行工作负载所需的集群。它与vSphere 7本机集成、并利用vCenter SSO、内容库、vSphere网络、vSphere存储、vSphere HA和DRS以及vSphere安全性等多种可靠的vSphere功能、提供更加无缝的Kubernetes体验。</block>
  <block id="6b25ac3e69375bd4a52dbffeb5c9cb14" category="paragraph">采用Tanzu的vSphere为混合应用程序环境提供了一个平台、您可以在容器或VM中运行应用程序组件、从而为开发人员、开发运营工程师和vSphere管理员提供了更好的可见性和易操作性。VMware TKGS仅支持vSphere 7环境、是Tanzu Kubernetes操作产品组合中唯一允许您直接在ESXi主机上运行Pod的产品。</block>
  <block id="0e1d3327747a52bdd78d80247d5b6500" category="image-alt">VMware Tanzu Kubernetes Service</block>
  <block id="6e1adc41159b779c5ef1a0c9c934a673" category="paragraph">有关Tanzu Kubernetes Grid Service的详细信息、请按照文档进行操作 <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>。</block>
  <block id="767b04965a47baa63782400d36a0c62e" category="paragraph">在功能集、网络等方面、需要考虑许多架构注意事项。根据所选的架构、Tanzu Kubernetes Grid Service的前提条件和部署过程会有所不同。要在您的环境中部署和配置Tanzu Kubernetes Grid Service、请按照指南进行操作 <block ref="5e5ad4985bdb8ab17883db4008c7c4a2" category="inline-link-macro-rx"></block>。此外、要登录到通过TKGS部署的Tanzu Kubernetes集群节点、请遵循此指南中所述的操作步骤<block ref="7db41b551ba1165c4dfa4cf2d8a36e55" category="inline-link-rx"></block>。</block>
  <block id="46d890e88b951c5a84a444aad08079ae" category="paragraph">NetApp建议将所有生产环境部署在多个主部署中、以实现容错、并选择工作节点的配置、以满足预期工作负载的要求。因此、对于高度密集型工作负载、建议的VM类至少具有四个vCPU和12 GB RAM。</block>
  <block id="e8a4d3a2e07c429150e133b7fedebd64" category="paragraph">在命名空间中创建Tanzu Kubernetes集群时、具有`owner`或`edit`权限的用户可以使用用户帐户直接在任何命名空间中创建Pod。这是因为具有`owner`或`edit`权限的用户将分配集群管理员角色。但是、在任何命名空间中创建部署、守护进程集、有状态集或其他时、您必须为相应的服务帐户分配具有所需权限的角色。这是必需的、因为部署或守护进程集会利用服务帐户来部署Pod。</block>
  <block id="dc4ab077311e2aad5b5af968844fc5fe" category="paragraph">要将集群管理员角色分配给集群中的所有服务帐户、请参见以下ClusterRoleBinding.示例：</block>
  <block id="5851271128193658704cec246f4fd21c" category="doc">NetApp存储集成概述</block>
  <block id="c21c42ee74a060038cdb9ea059b7702a" category="list-text"><block ref="c21c42ee74a060038cdb9ea059b7702a" category="inline-link-macro-rx"></block></block>
  <block id="bbf3919625853b65280d28c2d26004fd" category="list-text"><block ref="bbf3919625853b65280d28c2d26004fd" category="inline-link-macro-rx"></block></block>
  <block id="22a3cd730895fa6285f7ee2b7838bc34" category="list-text">创建或获取对要安装Astra控制中心的｛k8s_usercluster_name｝集群具有管理员访问权限的kubeconfig文件。</block>
  <block id="c67346d734cf1873532bdc9f9a1421da" category="list-text">能够同时运行虚拟化和容器化工作负载</block>
  <block id="71d00a17a6d603b0b4ebb168354950db" category="list-text">能够根据工作负载需求独立扩展基础架构</block>
  <block id="1722f248c3b6574ad844b53f30ac236c" category="sidebar">采用NetApp技术的VMware Tanzu</block>
  <block id="c9fc26b21b932419e6f167a5ef97a61a" category="sidebar">VMware Tanzu网站</block>
  <block id="8a22a6c667b205ca4e784c0364ccc5ea" category="sidebar">VMware TKG (Tanzu Kubernetes Grid)概述</block>
  <block id="e5103defcbafcf380570238b4848f4a1" category="sidebar">VMware TKGS (Tanzu Kubernetes Grid Service)概述</block>
  <block id="a2ec151aed88d77a34df663b329daf31" category="sidebar">VMware TKGI (Tanzu Kubernetes Grid Integrated Edition)概述</block>
  <block id="e47703dd1fad3279269dda3b343b2272" category="sidebar">注册您的Tanzu Kubernetes集群</block>
  <block id="84f09994e75c5ede8e07c6ab4070faae" category="summary">本节详细介绍了Swingbench模拟OLTP工作负载的性能验证和基准测试结果。</block>
  <block id="d9a4da5bae7f5f09fa9c3850a052c626" category="doc">性能验证和基准测试结果</block>
  <block id="4e71b9ce7d16c817e38c3c0b45825062" category="paragraph">此性能验证的目标不是设置任何标记。相反、如果您按照本文档中所述的部署过程和最佳实践进行操作、则在公有 云中部署Oracle数据库时、性能指标可能会类似。</block>
  <block id="0215fc4537f81bbc2d6ff19ba75efeb5" category="paragraph">我们使用Swingbench销售订单条目(Sales Order Entry、SOE)模块模拟OLTP类型的工作负载、并对部署到NFS协议上具有FSX存储卷的M5 EC2实例的Oracle数据库应用此工作负载。默认Swingbench SOE I/O配置文件接近80/20读/写拆分、接近实际OLTP Oracle工作负载配置文件。</block>
  <block id="611831b4b814ffa8e208ff6b01e797d9" category="paragraph">增加客户端上执行销售订单输入、浏览、清单查询等操作的并发用户数、从而增加工作负载。测试的数字分别为8、16、32、64和128个并发用户。Swingbench使用的算法在服务器端很重、用于推送合理的事务卷并测试Oracle服务器限制。我们观察到、在128个并发用户时、EC2实例CPU利用率大约达到了80-90%的容量。</block>
  <block id="a5cbb12f8f9f28c970230ab16d36e184" category="paragraph">以下各节详细介绍了设置和测试结果。</block>
  <block id="e018eaf806fedc0fa46d2acde6f60425" category="section-title">测试环境设置</block>
  <block id="ff4adf700c0c4ba7e493af033a81ac29" category="paragraph">我们部署了一个EC2 M5实例、该实例具有8个vCPU、32 G RAM和10 Gps网络带宽。</block>
  <block id="2940f21a2cd7581a414576699c946a28" category="paragraph"><block ref="2940f21a2cd7581a414576699c946a28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5e18ca4731d9d72ae0bd4438c7e84b5" category="section-title">FSX存储</block>
  <block id="dc29ebaf5cc1f622aabb0ae70efeced6" category="paragraph">我们创建了三个数据库卷、并在EC2实例上使用NFS挂载了这些卷、如下所示：</block>
  <block id="829e4dfdaee315e0cfdba47e5047adf7" category="list-text">/u01—Oracle二进制文件</block>
  <block id="5853f5304485ce536b44cd0dfb18bdbc" category="list-text">/u02—Oracle数据文件、控制文件</block>
  <block id="ee6ac3c6792e507ea8c5717f79c8ab46" category="list-text">/u03—Oracle日志文件、控制文件</block>
  <block id="363dd83f018d937efa507464961997c5" category="paragraph">我们为一个关键控制文件保留了两个副本、以实现冗余。</block>
  <block id="009187ce6b03d07047e46c6ed738f305" category="paragraph"><block ref="009187ce6b03d07047e46c6ed738f305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9c8184a7a7a9ecb63af93d93759b393" category="paragraph">FSX文件系统配置了80、000 IOPS容量和2 GiBps I/O吞吐量。</block>
  <block id="3570146db42993029d30dbd022107030" category="section-title">Oracle配置</block>
  <block id="9daecb8faf1751109e100894205a6aef" category="paragraph">我们安装了Oracle版本19c以及RU修补程序19.8。已在服务器上启用DNFS。</block>
  <block id="9041eebdfc5395440a43baff789c663b" category="paragraph">该数据库部署为一个包含三个PDB的容器化数据库。我们使用一个PDB实例进行性能测试。下图显示了NFS挂载点上的Oracle存储大小调整。</block>
  <block id="9ae30014c647d5fd5e38a292d1061810" category="paragraph"><block ref="9ae30014c647d5fd5e38a292d1061810" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8da929e8cdb57e8ea66260e3f7090d35" category="section-title">Swingbench配置</block>
  <block id="6af00d716d36ee74995307e004b66d3f" category="paragraph">我们在具有8个vCPU和32 G RAM的Windows主机上部署了Swingbench 2.6 (最新版本)。我们使用SOE PLSQL测试模块版本2作为基准。默认负载配置文件提供80/20读/写比率、用于模拟实际OLTP事务工作负载。</block>
  <block id="5850fdbd1ed0c58b02c8d3797381e7c6" category="paragraph">我们使用的架构扩展因子为50、提供了160 G的初始数据负载大小和30 G的临时空间分配。在这种规模因素下、SOE模式为模拟在线订单处理提供了1000个仓库和5000万客户。</block>
  <block id="9bc139569eaa30f1804b313d21ab69fa" category="paragraph">以下屏幕截图显示了Swingbench Windows UI中的工作负载配置文件和典型事务运行指标。</block>
  <block id="4da81979345d8adfb02c96de8993662a" category="paragraph"><block ref="4da81979345d8adfb02c96de8993662a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5531d1590836e811c3ace97db7e230eb" category="paragraph">如此图所示、在整个测试运行期间、事务级别始终保持在同一级别。</block>
  <block id="6c805c8ead51e13766957cbda36fd2c0" category="section-title">测试结果分析</block>
  <block id="54f9f904b574caddc93a83f3057be251" category="paragraph">我们捕获了每次测试运行的Swingbench结果、并获得了相应的Oracle AWR报告以进行性能分析。</block>
  <block id="9126019861ad7339333760b7b3bd5174" category="paragraph">从最终用户角度来看、我们查看了关键指标、例如事务量和用户响应时间。这两个指标都显示了在登录到销售订单输入系统的并发用户数量以及用户在输入订单后完成事务并收到响应的速度下、用户可以从销售订单输入系统执行多少事务。</block>
  <block id="809217313025f03af0a774770ed7688d" category="paragraph">从Oracle服务器端、我们解析了Oracle AWR报告、以确定可能会减慢用户事务处理速度的前几个等待事件。排名前10位的Oracle等待事件表明、在Swingbench模拟事务测试运行期间、Oracle服务器的I/O大多受限于`db文件顺序读取`上的数据库时间高达50%-60%。`log file sync`也是一个影响因素、因为事务会使发生原因 通过Oracle日志记录过程将日志I/O从缓冲区缓存转储到磁盘上的日志文件、尽管这在数据库时间百分比级别上是一个较小的因素。</block>
  <block id="4da3501ef8d9ebc196009ef0bf4e4360" category="paragraph">我们根据事务运行期间的并发用户数量绘制了用户事务卷、用户响应时间和Oracle前几个等待事件的图表。结果如下所示：</block>
  <block id="911fadede55cdf4e5db896695fd4f9c3" category="paragraph"><block ref="911fadede55cdf4e5db896695fd4f9c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b225219fb0a32b17f3f7f3964edfa599" category="paragraph">这些结果表明、我们可以通过增加并发用户数量来稳定地增加用户事务卷、同时保持稳定的低I/O延迟和用户响应时间、这对于Oracle应用程序来说是合适的性能。</block>
  <block id="ccc7b98ab0c81e5b7e4033e88910e92e" category="paragraph">当我们达到128个并发用户时、I/O延迟和用户响应时间开始有所增加。这是预期的、因为EC2实例接近全满服务器容量、如下图所示：</block>
  <block id="0cc8a57e10ae7e4e152d74423527f2f0" category="paragraph"><block ref="0cc8a57e10ae7e4e152d74423527f2f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faf8392c1e8a1c488f303b45f48fd31d" category="paragraph">同样、下图显示了当时执行用户事务卷时相应的FSX IOPS和吞吐量。</block>
  <block id="a18559304ff06a743412352fbfb82b00" category="paragraph"><block ref="37451e9b66358e4a66c6a1b882f378a1" category="inline-image-macro-rx" type="image"></block>
<block ref="b0d8c670dcd70932cfb6876c97b62036" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d8430502705720b257f565ec9140e72" category="inline-link-macro">部署Oracle数据库时需要考虑的因素。</block>
  <block id="b25a4c32c9b6cc39890fa799e15301dc" category="paragraph">当Oracle服务器EC2实例成为限制因素时、以IOPS或吞吐量表示、我们未达到配置的FSX存储容量。因此、您必须根据用户应用程序级别的事务卷正确估算计算和存储的大小、如一节所示 <block ref="fa519ff010063f0b425f11c556e4445d" category="inline-link-macro-rx"></block></block>
  <block id="ca449b8ca808c6d325abf6b1a047318c" category="paragraph">以下架构图展示了在具有FSX存储服务的AWS EC2实例上部署高可用性Oracle数据库的情况。可以设置一个类似的部署方案、但在另一个区域中使用备用模式进行灾难恢复。</block>
  <block id="228488653f80c4dfe7bd79d5f9634ea4" category="paragraph">而FSX卷上的Oracle数据库存储则通过AWS FSX控制台或CLI进行部署。随后、Oracle二进制卷、数据卷或日志卷将显示并挂载到EC2实例Linux主机上。根据使用的底层存储协议、每个数据或日志卷可以分配多个LUN。</block>
  <block id="be571c48040d6c3bf764ba40188888d2" category="paragraph">SnapCenter 提供了用于Oracle数据库时间点恢复或在主分区或备用分区(如果需要)克隆数据库的工作流。通过SnapCenter UI、您可以根据RTO或RPO目标将Oracle数据库备份和复制配置为备用FSX存储、以实现高可用性或灾难恢复。</block>
  <block id="be22c0b35f58a932be14c9e55b163ac4" category="paragraph">解决方案 提供了一个替代过程、可提供与Oracle RAC和Data Guard部署中提供的功能类似的功能。</block>
  <block id="f3b25b37995dab3a1b6c753dd74ca21e" category="summary">本节详细介绍了如何通过SnapCenter UI管理适用于Oracle数据库的AWS RDS自定义、作为AWS RDS控制台UI的补充。</block>
  <block id="cf8b301cbf8aa698c578ff1f8e64ccc2" category="paragraph">除了AWS EC2和FSX管理控制台之外、此Oracle环境还部署了Ansible控制节点和SnapCenter UI工具来进行数据库管理。</block>
  <block id="ab1b9a020f08729c00ecee14e5a3be69" category="paragraph">Ansible控制节点可用于管理Oracle环境配置、并可通过并行更新来保持主实例和备用实例同步、以便进行内核或修补程序更新。故障转移、重新同步和故障恢复可通过NetApp自动化工具包自动进行、以便通过Ansible实现快速应用程序恢复和可用性归档。可以使用攻略手册执行一些可重复的数据库管理任务、以减少人为错误。</block>
  <block id="53bd53a68bce8fe697a7455feae3861b" category="inline-link-macro">适用于Oracle数据库的SnapCenter 插件概述</block>
  <block id="8dad283458f149f04a674f7c674818ed" category="paragraph">SnapCenter UI工具可以使用适用于Oracle数据库的SnapCenter 插件执行数据库快照备份、时间点恢复、数据库克隆等操作。有关Oracle插件功能的详细信息、请参见 <block ref="053f091ffb001fc31a47d30bc3d11350" category="inline-link-macro-rx"></block>。</block>
  <block id="c165a519b858dc997da23262308d6463" category="paragraph">以下各节详细介绍了如何使用SnapCenter UI实现Oracle数据库管理的关键功能：</block>
  <block id="95154aa7c50b812d3683b6995bed8771" category="list-text">数据库快照备份</block>
  <block id="b055b8a9cd44d5f8e1fa330c20aa1dc3" category="list-text">数据库时间点还原</block>
  <block id="20f913ca57379280e5f37dce9cd0de61" category="list-text">创建数据库克隆</block>
  <block id="e724243c3ef9e2c58168b76f3f537412" category="paragraph">数据库克隆会在单独的EC2主机上创建主数据库的副本、以便在发生逻辑数据错误或损坏时进行数据恢复、克隆也可用于应用程序测试、调试、修补程序验证等。</block>
  <block id="418768c00fe9ab38a23d8417250d676b" category="section-title">正在创建快照</block>
  <block id="c018c634b9245f8522eaf32d3fffaa7a" category="paragraph">EC2/FSX Oracle数据库会按用户配置的间隔定期备份。用户也可以随时执行一次性快照备份。此适用场景 既可执行完整数据库快照备份、也可执行仅归档日志的快照备份。</block>
  <block id="0a1758b0d7a64bf446ccd6c9ea2a559d" category="section-title">创建完整的数据库快照</block>
  <block id="6aa82df330acc0ad1c1859bf7d19d8c6" category="paragraph">完整的数据库快照包括所有Oracle文件、包括数据文件、控制文件和归档日志文件。</block>
  <block id="71a81fc61b4bde806ab23dbb0dff87ab" category="list-text">登录到SnapCenter UI、然后单击左侧菜单中的"Resources"。从视图下拉列表中、更改为资源组视图。</block>
  <block id="097f9e0f1d7d03a8b8db3110da618df1" category="paragraph"><block ref="097f9e0f1d7d03a8b8db3110da618df1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a16fe4e102f4f80c9a0ebe875e00921" category="list-text">单击完整备份资源名称、然后单击立即备份图标以启动附加临时备份。</block>
  <block id="b157c6d0dbf1f6fc8e66e048cdf587dc" category="paragraph"><block ref="b157c6d0dbf1f6fc8e66e048cdf587dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c41836f211ec5f0aee4024039682c6d3" category="list-text">单击备份、然后确认备份以启动完整数据库备份。</block>
  <block id="de38ecf82e29f57be2cb258095500ffc" category="paragraph"><block ref="de38ecf82e29f57be2cb258095500ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5114009902f821226811cd39b519e8ae" category="paragraph">从数据库的资源视图中、打开数据库托管备份副本页面、验证一次性备份是否已成功完成。完整数据库备份会创建两个快照：一个用于数据卷、一个用于日志卷。</block>
  <block id="23c2c3d9fc4ea06c4f1744caa77dd75f" category="paragraph"><block ref="23c2c3d9fc4ea06c4f1744caa77dd75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc2bc8e691b80fc2b94cd487cd59a41e" category="section-title">创建归档日志快照</block>
  <block id="c2a2cc866aaa30cb6344e65c853429a7" category="paragraph">只会为Oracle归档日志卷创建归档日志快照。</block>
  <block id="973f07a93ca1636baa391407a84cb38b" category="list-text">登录到SnapCenter UI、然后单击左侧菜单栏中的"Resources"选项卡。从视图下拉列表中、更改为资源组视图。</block>
  <block id="47f0395291ce13022063147f4981f69f" category="list-text">单击日志备份资源名称、然后单击立即备份图标为归档日志启动附加临时备份。</block>
  <block id="1417f1fbdcb104994815efb345497300" category="paragraph"><block ref="1417f1fbdcb104994815efb345497300" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8ee5a2ad5f43fcd955b6b30854d2f98" category="list-text">单击备份、然后确认备份以启动归档日志备份。</block>
  <block id="03cb3b3b0da0531d726d5e6b4af1920c" category="paragraph"><block ref="03cb3b3b0da0531d726d5e6b4af1920c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40cffcacb55d81916f38114aac845d4b" category="paragraph">从数据库的资源视图中、打开数据库托管备份副本页面、验证一次性归档日志备份是否已成功完成。归档日志备份会为日志卷创建一个快照。</block>
  <block id="01422619a982004bea1ad1e237269525" category="paragraph"><block ref="01422619a982004bea1ad1e237269525" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e16045e122b02913b74ef1e8bd29d75c" category="section-title">还原到某个时间点</block>
  <block id="7d2260465121189e3f5aef56d1734e86" category="paragraph">在同一个EC2实例主机上执行基于SnapCenter的时间点还原。完成以下步骤以执行还原：</block>
  <block id="52443d446e6aa795d8e3a08e581684cb" category="list-text">在SnapCenter 资源选项卡&gt;数据库视图中、单击数据库名称以打开数据库备份。</block>
  <block id="51d148134901f85184886bb72062b2a0" category="paragraph"><block ref="51d148134901f85184886bb72062b2a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bc3aa5bd0c870df97abdd69ef227826" category="list-text">选择数据库备份副本以及要还原的所需时间点。同时、记下时间点对应的SCN编号。可以使用时间或SCN执行时间点还原。</block>
  <block id="f4a16324772958025bfa77d2ed8af61e" category="paragraph"><block ref="f4a16324772958025bfa77d2ed8af61e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acee7bbe553399023f78a7ac814d7a94" category="list-text">突出显示日志卷快照、然后单击挂载按钮挂载此卷。</block>
  <block id="b068acd736c964d27b5833d30c220f7c" category="paragraph"><block ref="b068acd736c964d27b5833d30c220f7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d06beb2a91e58c7e57367e901abc09fd" category="list-text">选择要挂载日志卷的主EC2实例。</block>
  <block id="94bf51064baf8263a5c7e0d6dba0f38a" category="paragraph"><block ref="94bf51064baf8263a5c7e0d6dba0f38a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f83a9f884d94d22d3c52d510a051ac90" category="list-text">验证挂载作业是否已成功完成。另外、请检查EC2实例主机以查看该日志卷已挂载以及挂载点路径。</block>
  <block id="53044f6472847053eea58f6f40258b7c" category="paragraph"><block ref="01717ad5eefdb68ab0f128386310e509" category="inline-image-macro-rx" type="image"></block>
<block ref="684c418b818adf3876d8fd9877edd90f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12a7a64116d859fb64b3f841a43e6fac" category="list-text">将归档日志从挂载的日志卷复制到当前归档日志目录。</block>
  <block id="f57c6961965ccab84762e9b4bbdd72f0" category="list-text">返回到SnapCenter 资源选项卡&gt;数据库备份页面、突出显示数据快照副本、然后单击还原按钮以启动数据库还原工作流。</block>
  <block id="eb283dcbcce9c21f038d1985c87645da" category="paragraph"><block ref="eb283dcbcce9c21f038d1985c87645da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a08ce545f0f81946ee65326ff4608df" category="list-text">选中"所有数据文件"和"根据还原和恢复需要更改数据库状态"、然后单击下一步。</block>
  <block id="c53b030895e9cee782d7dfcea4a679ad" category="paragraph"><block ref="c53b030895e9cee782d7dfcea4a679ad" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e589c1295b0849053e2d8cc2bbf96a1e" category="list-text">使用SCN或时间选择所需的恢复范围。挂载的归档日志路径可以在"指定外部归档日志文件位置"中列出以供恢复、而不是像第6步所示将挂载的归档日志复制到当前日志目录。</block>
  <block id="12bfd26a9c7f1551fe3664e25975f022" category="paragraph"><block ref="12bfd26a9c7f1551fe3664e25975f022" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f3b533a6c9cd757a311b56318115bbe" category="list-text">如有必要、指定要运行的可选预处理程序。</block>
  <block id="0c61f73092ad29b6a823f67f23872ffb" category="paragraph"><block ref="0c61f73092ad29b6a823f67f23872ffb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16a70e704c6e5104eff1adca9f951c36" category="list-text">指定一个可选的后处理脚本、以便在必要时运行。恢复后检查打开的数据库。</block>
  <block id="5e5add6f904fa1973ca9f5564c87bdab" category="paragraph"><block ref="5e5add6f904fa1973ca9f5564c87bdab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="975952869f93fd5cb45acf8a19b97834" category="list-text">如果需要作业通知、请提供SMTP服务器和电子邮件地址。</block>
  <block id="125beea11cb628a2850a9c3b01628d3b" category="paragraph"><block ref="125beea11cb628a2850a9c3b01628d3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f92d4c842e7343ab2f69eac4e3561bc" category="list-text">还原作业摘要。单击完成以启动还原作业。</block>
  <block id="0dac703b5b68b8ce38eae7f7224a3de3" category="paragraph"><block ref="0dac703b5b68b8ce38eae7f7224a3de3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e783d4afe611873ddc32a5a59ff2078" category="list-text">验证是否已从SnapCenter 还原。</block>
  <block id="7cc0ed8d8b03fe709b0d004e75183201" category="paragraph"><block ref="7cc0ed8d8b03fe709b0d004e75183201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6e8e06b3f3e03bdb3391888df78e46" category="list-text">验证从EC2实例主机还原的情况。</block>
  <block id="06adcc9a574fcfaa717309c54d0fc7e9" category="paragraph"><block ref="06adcc9a574fcfaa717309c54d0fc7e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="983d6ea8d6962c3e0f9abef0c4c948f4" category="list-text">要卸载还原日志卷、请反转步骤4中的步骤。</block>
  <block id="ca0c306ba98701576c42d241b48d4038" category="section-title">创建数据库克隆</block>
  <block id="a8bd304fe0995bcddba8dd93a8d447a6" category="paragraph">下一节将演示如何使用SnapCenter 克隆工作流创建从主数据库到备用EC2实例的数据库克隆。</block>
  <block id="91956afde8e3bc7ac47e37b9821ca6f9" category="list-text">使用完整备份资源组从SnapCenter 为主数据库创建完整快照备份。</block>
  <block id="023d426483e83bc3abf204154e323eba" category="paragraph"><block ref="023d426483e83bc3abf204154e323eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b08a0a4966d6a40934f84e0367df5124" category="list-text">从SnapCenter 资源选项卡&gt;数据库视图中、打开要从中创建副本的主数据库的数据库备份管理页面。</block>
  <block id="f14aaf01a42159b842a496f880063869" category="paragraph"><block ref="f14aaf01a42159b842a496f880063869" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b265d526ea8d86f13a3ee5b3df11ce5" category="list-text">将步骤4中创建的日志卷快照挂载到备用EC2实例主机。</block>
  <block id="160b6f6b07db1490de7e1252e8f6ec84" category="paragraph"><block ref="074cfbf53cae79233eac44ac8a4aa5f8" category="inline-image-macro-rx" type="image"></block>
<block ref="a75c3f795382693108f8d772396f248b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15c2865196d70f81dd791b3329d2604e" category="list-text">突出显示要为副本克隆的Snapshot副本、然后单击克隆按钮启动克隆操作步骤。</block>
  <block id="568f30b58394b2e0d4e795beb731c0eb" category="paragraph"><block ref="568f30b58394b2e0d4e795beb731c0eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ebc0e83f8e5d02518da0756a18aaab4" category="list-text">更改副本副本名称、使其与主数据库名称不同。单击下一步。</block>
  <block id="b77619cc2b53d1b603e6051036b122b6" category="paragraph"><block ref="b77619cc2b53d1b603e6051036b122b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ba0975a31e144349d50f09393a5ca21" category="list-text">将克隆主机更改为备用EC2主机、接受默认命名、然后单击下一步。</block>
  <block id="d39fd3bd4059fb775d174eef3e53919b" category="paragraph"><block ref="d39fd3bd4059fb775d174eef3e53919b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eeda8df21c3391dcc7a327cfec8f8704" category="list-text">更改Oracle主设置以与为目标Oracle服务器主机配置的设置相匹配、然后单击下一步。</block>
  <block id="8cb5c7c55cf01620e1eaae0dd817ad2c" category="paragraph"><block ref="8cb5c7c55cf01620e1eaae0dd817ad2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f10b26890bad0f92387ad2c8efb9b532" category="list-text">使用时间或SCN和挂载的归档日志路径指定恢复点。</block>
  <block id="9d2a5645a731a8a3af7ee677133ba312" category="paragraph"><block ref="9d2a5645a731a8a3af7ee677133ba312" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684abeacd08eb59922d70d928ce47f45" category="list-text">根据需要发送SMTP电子邮件设置。</block>
  <block id="84bb684b488190f680f548303196f5b9" category="paragraph"><block ref="84bb684b488190f680f548303196f5b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2cc0c6ba26bdf7b30e39313a0ad4098" category="list-text">克隆作业摘要、然后单击完成以启动克隆作业。</block>
  <block id="3461ca6663823ff26ef7d3121d8592c7" category="paragraph"><block ref="3461ca6663823ff26ef7d3121d8592c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5cd909b2ce2e22f0bb8734426ea9e9a" category="list-text">通过查看克隆作业日志来验证副本克隆。</block>
  <block id="c6c9a361716f3695e5f582cbbaf857f6" category="paragraph"><block ref="c6c9a361716f3695e5f582cbbaf857f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66a858d0c53f7ecef6ff665372a428c5" category="paragraph">克隆的数据库会立即在SnapCenter 中注册。</block>
  <block id="8fc5846614431a858445f7c55fe6f8bf" category="paragraph"><block ref="8fc5846614431a858445f7c55fe6f8bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9b70fde27d9d03d393dc2fd619546988" category="list-text">关闭Oracle归档日志模式。以Oracle用户身份登录到EC2实例并执行以下命令：</block>
  <block id="ca1a9785bb111fcadc4527aae18f822d" category="admonition">与主Oracle备份副本不同、也可以使用相同的过程从目标FSX集群上复制的二级备份副本创建克隆。</block>
  <block id="2a75f5115dab8b39875560a4d7252d2f" category="section-title">HA故障转移到备用并重新同步</block>
  <block id="f5bc6d05191457096f9da00e0fa56d40" category="paragraph">备用Oracle HA集群可在主站点发生故障时提供高可用性、无论是在计算层还是存储层。解决方案 的一个重要优势是、用户可以随时或以任何频率测试和验证基础架构。故障转移可以由用户模拟、也可以由实际故障触发。故障转移过程完全相同、可以自动执行、以便快速恢复应用程序。</block>
  <block id="6775249aa36196ee3d9c71774992f2c4" category="paragraph">请参见以下故障转移过程列表：</block>
  <block id="eb171dc2d1f739dfee2e358326abd0e9" category="list-text">对于模拟故障转移、请运行日志快照备份、将最新事务刷新到备用站点、如一节所示 <block ref="58f2fe5f16b910e6ad4f8b3f8679e256" category="inline-xref-macro-rx"></block>。对于因实际故障而触发的故障转移、最后一个可恢复的数据将通过上次成功计划的日志卷备份复制到备用站点。</block>
  <block id="abdc57f5efdfeac30fe822d9eda2fc9f" category="list-text">中断主FSX集群和备用FSX集群之间的SnapMirror。</block>
  <block id="bd54ae4d51454c6a89990f066be03d35" category="list-text">在备用EC2实例主机上挂载复制的备用数据库卷。</block>
  <block id="588698147b1d63f4f9f6d78dd8d83595" category="list-text">如果复制的Oracle二进制文件用于Oracle恢复、请重新链接Oracle二进制文件。</block>
  <block id="0f1ac3f743fcb2d14875c7a731c3d251" category="list-text">将备用Oracle数据库恢复到最后一个可用的归档日志。</block>
  <block id="ab933bdc7c043f4a3c977049791f0640" category="list-text">打开备用Oracle数据库以供应用程序和用户访问。</block>
  <block id="6928cb13e9136438c86e16b724b3b64f" category="list-text">对于实际主站点故障、备用Oracle数据库现在充当新的主站点、数据库卷可用于使用反向SnapMirror方法将故障主站点重建为新的备用站点。</block>
  <block id="13e25eed8fa423975f854101e3be1e89" category="list-text">对于用于测试或验证的模拟主站点故障、请在完成测试练习后关闭备用Oracle数据库。然后、从备用EC2实例主机卸载备用数据库卷、并将复制从主站点重新同步到备用站点。</block>
  <block id="c3fd0f78855e219b0fd44077ce74e7b5" category="paragraph">可以使用NetApp自动化工具包执行这些过程、该工具包可从公有 NetApp GitHub站点下载。</block>
  <block id="ba4d6e5d6eeea04cdc5a4f243b1e5dd8" category="paragraph">在尝试进行设置和故障转移测试之前、请仔细阅读自述文件说明。</block>
  <block id="7d34df46082e5771e092eb8736597ee0" category="summary">本节介绍使用FSX存储部署Oracle RDS自定义数据库的部署过程。</block>
  <block id="f70ec60e40ece5900605229a28081b13" category="section-title">通过EC2控制台部署适用于Oracle的EC2 Linux实例</block>
  <block id="03d6d2463e27b63c2d7f7ad0e62697af" category="paragraph">如果您是AWS的新用户、则首先需要设置AWS环境。AWS网站登录页面上的文档选项卡提供了有关如何部署Linux EC2实例的EC2说明链接、该实例可用于通过AWS EC2控制台托管Oracle数据库。以下部分总结了这些步骤。有关详细信息、请参见链接的AWS EC2专用文档。</block>
  <block id="e1fc23220db46fe659667702f62b75e4" category="section-title">设置AWS EC2环境</block>
  <block id="6d0669826a2bd6e9eb35ea7e89cbe3f4" category="paragraph">您必须创建一个AWS帐户来配置必要的资源、以便在EC2和FSX服务上运行Oracle环境。以下AWS文档提供了必要的详细信息：</block>
  <block id="2966cbe914210fb4f4a3e5fe6adf4762" category="inline-link-macro">设置为使用Amazon EC2</block>
  <block id="1e4a01fe43fb3542c08649e20440f5f1" category="list-text"><block ref="1e4a01fe43fb3542c08649e20440f5f1" category="inline-link-macro-rx"></block></block>
  <block id="df6ca3590d3bec198846463f0ef1c6a8" category="paragraph">主要主题：</block>
  <block id="74122bb32fc969b565a8b132d4178581" category="list-text">注册AWS。</block>
  <block id="fe536eddec5cc1d661347011844ba132" category="list-text">创建密钥对。</block>
  <block id="6582688edf89986f408a52095794f65b" category="list-text">创建安全组。</block>
  <block id="c78747962ae12e635749aa6b08a4da09" category="section-title">在AWS帐户属性中启用多个可用性区域</block>
  <block id="2d5ade6857f59cf6d198344d5049da40" category="paragraph">对于架构图中所示的Oracle高可用性配置、您必须在一个区域中至少启用四个可用性区域。多个可用性区域也可以位于不同区域、以满足灾难恢复所需的距离。</block>
  <block id="b6067af8a0645a7009ccfb45c5271f1e" category="paragraph"><block ref="b6067af8a0645a7009ccfb45c5271f1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8faa9e48d0380a023114890a62861d0f" category="section-title">创建并连接到EC2实例以托管Oracle数据库</block>
  <block id="82499151e189f9313aa1450e912f4ffd" category="inline-link-macro">开始使用Amazon EC2 Linux实例</block>
  <block id="822fd31d54c32c4886e9010d12a8dce7" category="paragraph">请参见教程 <block ref="6d0a9d65d170226042c573685041d5e9" category="inline-link-macro-rx"></block> 分步部署过程和最佳实践。</block>
  <block id="a15c0d1773407cc677a49f4cc169a63c" category="list-text">概述。</block>
  <block id="4d99c712f714ff14ae3b251667dda4b2" category="list-text">前提条件。</block>
  <block id="67b035efef4b92412bb7a8a903121da6" category="list-text">第1步：启动实例。</block>
  <block id="6640566c783363c8a66fe226c2a7227b" category="list-text">第2步：连接到实例。</block>
  <block id="c271b00c470f8a1fb17c05dc6092d9af" category="list-text">第3步：清理实例。</block>
  <block id="9e0cd4f11314aeaa31fce7e3f5960c4c" category="paragraph">以下屏幕截图展示了如何使用EC2控制台部署M5类型的Linux实例以运行Oracle。</block>
  <block id="993b6250c7c69b01670a8165c0cf949d" category="list-text">在EC2信息板中、单击黄色的Launch Instance按钮以启动EC2实例部署工作流。</block>
  <block id="37266a1d594801e15c8f2a455a3ea854" category="paragraph"><block ref="37266a1d594801e15c8f2a455a3ea854" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71a4046454ceb8a1793ee0cfa14dc581" category="list-text">在第1步中、选择"Red Hat Enterprise Linux 8 (HVM)、SSD卷类型- AMI-0b0af3577fe5e3532 (64位x86)/AMI-01fc429821bf1f4b4 (64位ARM)"。</block>
  <block id="755d0918a7bfcbc1b7541acd1235598e" category="paragraph"><block ref="755d0918a7bfcbc1b7541acd1235598e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5956dcc5f6331fe980094b6ddba4650c" category="list-text">在步骤2中、根据Oracle数据库工作负载选择一个M5实例类型、并分配适当的CPU和内存。单击"下一步：配置实例详细信息"。</block>
  <block id="55898408b090c35ed97aede8b9893299" category="paragraph"><block ref="55898408b090c35ed97aede8b9893299" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302a3b9b8b1d7dfc842dbfcaa5468b1a" category="list-text">在步骤3中、选择应放置实例的VPC和子网、并启用公有 IP分配。单击"下一步：添加存储"。</block>
  <block id="86ec5cd603e5f7341f3f213d5b660cbb" category="paragraph"><block ref="86ec5cd603e5f7341f3f213d5b660cbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e421be5ecc966b1d156d7f0a6f81716a" category="list-text">在步骤4中、为根磁盘分配足够的空间。您可能需要空间来添加交换。默认情况下、EC2实例分配的交换空间为零、这不是运行Oracle的最佳选择。</block>
  <block id="5246bec51cd11bdee5a098fd3d3d5909" category="paragraph"><block ref="5246bec51cd11bdee5a098fd3d3d5909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="843f8ce7ab50f800b312d3d109724de6" category="list-text">在步骤5中、根据需要添加用于实例标识的标记。</block>
  <block id="30a97756451355fd7db0bfd07cc6f667" category="paragraph"><block ref="30a97756451355fd7db0bfd07cc6f667" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3ab3dbfdf3bf87e86423bcf042be111" category="list-text">在第6步中、选择现有安全组或使用所需的实例入站和出站策略创建一个新安全组。</block>
  <block id="bdeb5b41f7c9bee78d1e7264990c0a27" category="paragraph"><block ref="bdeb5b41f7c9bee78d1e7264990c0a27" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6232d41ab5791353e400740b1c677c4b" category="list-text">在第7步中、查看实例配置摘要、然后单击启动以启动实例部署。系统将提示您创建密钥对或选择密钥对以访问实例。</block>
  <block id="fdd8bffe3363802212b12c3b1a7626da" category="paragraph"><block ref="8dc5efc0ebc99dc3e7017ef07cffd6c3" category="inline-image-macro-rx" type="image"></block>
<block ref="ea979786416bbc8ec09d933e3d57cfc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="640d800543e4acd4be5582f719fe45e6" category="list-text">使用SSH密钥对登录到EC2实例。根据需要更改密钥名称和实例IP地址。</block>
  <block id="69321a8301f0cb7557529f92163852a6" category="paragraph">您需要在其指定可用性区域中创建两个EC2实例作为主Oracle服务器和备用Oracle服务器、如架构图所示。</block>
  <block id="de55d86dd430c134cc875c8122ebfd71" category="section-title">为ONTAP 文件系统配置FSX以存储Oracle数据库</block>
  <block id="2a0b48da85066bd283380f9313f9cd2f" category="paragraph">EC2实例部署会为操作系统分配EBS根卷。适用于ONTAP 文件系统的FSX可提供Oracle数据库存储卷、包括Oracle二进制卷、数据卷和日志卷。FSX存储NFS卷可以从AWS FSX控制台或Oracle安装进行配置、也可以通过配置自动化在自动化参数文件中按照用户配置的方式分配卷。</block>
  <block id="3560913f6885261f7b64e7cfeea69eab" category="section-title">为ONTAP 文件系统创建FSX</block>
  <block id="db188150cd7e1fbc9cfd2bc034c7b4bb" category="inline-link">管理适用于ONTAP 文件系统的FSX</block>
  <block id="3b46f3b2334f11bf806517b04969429a" category="paragraph">已参考此文档<block ref="eea1efb396f41a443a43d43b53db120b" category="inline-link-rx"></block> 用于为ONTAP 文件系统创建FSX。</block>
  <block id="f992b6bed702bc01496187fcaec0b8c6" category="paragraph">主要注意事项：</block>
  <block id="c6d0abeaa6d014ec6632e6b8493487d2" category="list-text">SSD存储容量。最小1024 GiB、最大192 TiB。</block>
  <block id="2b410cef067f8cb6a53d05ad2271439b" category="list-text">已配置SSD IOPS。根据工作负载要求、每个文件系统最多可达到80、000 SSD IOPS。</block>
  <block id="3ab61d0f90da3f61b5741ceb5eb191cc" category="list-text">吞吐量容量。</block>
  <block id="94412c99e275ca9b650dc655a6e69119" category="list-text">设置管理员fsxadmin/vsadmin密码。FSX配置自动化所需。</block>
  <block id="c9de3d23d86cd04ff4ebf9b1458d70c4" category="list-text">备份和维护。禁用自动每日备份；数据库存储备份通过SnapCenter 计划执行。</block>
  <block id="b2ad37d85471ba4bcaf2c2141b1a576d" category="list-text">从SVM详细信息页面检索SVM管理IP地址以及特定于协议的访问地址。FSX配置自动化所需。</block>
  <block id="da6dd59d1114c8c42782cf7be16609b7" category="paragraph"><block ref="da6dd59d1114c8c42782cf7be16609b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15d09dd6ced339d4022eb28264e99543" category="paragraph">有关设置主HA FSX集群或备用HA FSX集群的步骤、请参见以下分步过程。</block>
  <block id="b2232ae7fcc8b0c89d7c5f62a079a0f9" category="list-text">在FSX控制台中、单击Create File System以启动FSX配置工作流。</block>
  <block id="97a3753a6b826d3f7027a60fbc138cac" category="paragraph"><block ref="97a3753a6b826d3f7027a60fbc138cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8863368642c82b76b987f6f94659021d" category="list-text">选择适用于NetApp ONTAP 的Amazon FSX。然后单击下一步。</block>
  <block id="064467bccc8ccdcdddef0abbcb9694e0" category="paragraph"><block ref="064467bccc8ccdcdddef0abbcb9694e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4912f49d35e15fbe2d9881db397feb" category="list-text">选择标准创建、然后在文件系统详细信息中将文件系统命名为Multi-AZ HA。根据您的数据库工作负载、选择自动或用户配置的IOPS、最高可达80、000 SSD IOPS。FSX存储在后端提供高达2 TiB的NVMe缓存、可提供更高的测量IOPS。</block>
  <block id="989e0e2825ffa339331f1712bf630fb4" category="paragraph"><block ref="989e0e2825ffa339331f1712bf630fb4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="463daf4dcf56c33aa1c738fb16d15a27" category="list-text">在网络和安全部分中、选择VPC、安全组和子网。应在部署FSX之前创建这些卷。根据FSX集群的角色(主或备用)、将FSX存储节点置于相应的分区中。</block>
  <block id="3e99b854fb0db94f93ca0ee83bec339a" category="paragraph"><block ref="3e99b854fb0db94f93ca0ee83bec339a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="461a86bccdfc4b32cbc62af43ea97bb3" category="list-text">在安全性和加密部分中、接受默认值、然后输入fsxadmin密码。</block>
  <block id="82d80f8b6e156fcc9a64215b60433630" category="paragraph"><block ref="82d80f8b6e156fcc9a64215b60433630" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e500f789aeb2255be7988000eaff0e8" category="list-text">输入SVM名称和vsadmin密码。</block>
  <block id="84f414cec0c77118741eb2dde6127c3b" category="paragraph"><block ref="84f414cec0c77118741eb2dde6127c3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979fcc33806fd9594ae032fb4fe33c03" category="list-text">将卷配置留空；此时不需要创建卷。</block>
  <block id="9cc80fc34e28347ad7a346e723ff34ac" category="paragraph"><block ref="9cc80fc34e28347ad7a346e723ff34ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18c8eecfeb7f2ef5acbe5fe3fc1eb398" category="list-text">查看摘要页面、然后单击创建文件系统以完成FSX文件系统配置。</block>
  <block id="992da039cb86b69379ac2a507ea018b2" category="paragraph"><block ref="992da039cb86b69379ac2a507ea018b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edbcb61873336784ce88a841052fa45e" category="section-title">为Oracle数据库配置数据库卷</block>
  <block id="2dd5d229a6d07b62ae8943394f3a9a05" category="inline-link-macro">管理ONTAP 卷的FSX—创建卷</block>
  <block id="846568a6ddb0b9c5539e3bffbecefada" category="paragraph">请参见 <block ref="031a801f4fdac5974fa88d05f1809883" category="inline-link-macro-rx"></block> 了解详细信息。</block>
  <block id="ca3a40f13fd000ce8baf0adbf73ee561" category="list-text">适当调整数据库卷的大小。</block>
  <block id="383e4b0acf358da05802b9571408fa27" category="list-text">为性能配置禁用容量池分层策略。</block>
  <block id="086994099a77453bffc426910b6c783b" category="list-text">为NFS存储卷启用Oracle DNFS。</block>
  <block id="814d7476ebeabfd3208ed0432cb5ea38" category="list-text">为iSCSI存储卷设置多路径。</block>
  <block id="398cf8d5f0d4c7da2b945809849b5105" category="section-title">从FSX控制台创建数据库卷</block>
  <block id="6afbf36a53c717018bd3d99a6d735c98" category="paragraph">在AWS FSX控制台中、您可以为Oracle数据库文件存储创建三个卷：一个用于Oracle二进制文件、一个用于Oracle数据、一个用于Oracle日志。请确保卷命名与Oracle主机名(在自动化工具包中的hosts文件中定义)匹配、以便正确识别。在此示例中、我们使用db1作为EC2 Oracle主机名、而不是使用典型的基于IP地址的主机名作为EC2实例。</block>
  <block id="a732ebfc126f02de82d9e2cb4cba3b30" category="paragraph"><block ref="680b0ab2cf542daf748f396bdb970bee" category="inline-image-macro-rx" type="image"></block>
<block ref="7cf576b202936b23771e87094082b21e" category="inline-image-macro-rx" type="image"></block>
<block ref="9a3c4da48152c48ddee14308524b2023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05980643a3cf9b987fd426669d474257" category="admonition">FSX控制台当前不支持创建iSCSI LUN。对于适用于Oracle的iSCSI LUN部署、可以通过NetApp自动化工具包中的自动化for ONTAP 来创建卷和LUN。</block>
  <block id="09ee5fa03999e48e0789df07dd602d40" category="section-title">在具有FSX数据库卷的EC2实例上安装和配置Oracle</block>
  <block id="9f92271be71e4bc6eb96033a9ca6d798" category="paragraph">NetApp自动化团队提供了一个自动化套件、用于根据最佳实践在EC2实例上运行Oracle安装和配置。当前版本的自动化套件支持采用默认RU修补程序19.8的基于NFS的Oracle 19c。如果需要、可以轻松地对该自动化套件进行调整、以支持其他RU修补程序。</block>
  <block id="61790d4e19b846282d97e8ceb58e84e0" category="section-title">准备Ansible控制器以运行自动化</block>
  <block id="20f3b4bca246eb128d1c7a63ca954276" category="paragraph">请按照"<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>"以配置一个小型EC2 Linux实例以运行Ansible控制器。与使用RedHat相比、使用2vCPU和8G RAM的Amazon Linux T2.large应该足以满足要求。</block>
  <block id="6d42906c67a4432124b27f032f56e4dc" category="section-title">检索NetApp Oracle部署自动化工具包</block>
  <block id="7beb3cf1c62df8d836bddc0d2b6a3e57" category="paragraph">以EC2-user身份登录到步骤1中配置的EC2 Ansible控制器实例、然后从EC2-user主目录执行`git clone`命令克隆自动化代码的副本。</block>
  <block id="49130c144c12238cfeca4888e29fbef6" category="section-title">使用自动化工具包执行自动化Oracle 19c部署</block>
  <block id="ad5d9ee07a5238092f01b66ae1b4ecca" category="paragraph">请参见以下详细说明 <block ref="1d838bac5e7032e3241598fe6496fbd6" category="inline-link-macro-rx"></block> 使用CLI自动化部署Oracle 19c。执行攻略手册时的命令语法略有变化、因为您使用的是SSH密钥对、而不是主机访问身份验证的密码。以下列表概括介绍了相关内容：</block>
  <block id="dc8e3956f25fc431225feacc016616b5" category="list-text">默认情况下、EC2实例使用SSH密钥对进行访问身份验证。从Ansible控制器自动化根目录`/home/EC2-user/na_oracle19c_deploy`和`/home/EC2-user/na_RDS_FSx_oranfs_config`中、为在步骤中部署的Oracle主机创建SSH密钥`accesstkey.pem`的副本"<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>。 "</block>
  <block id="9391c5feaa671121befe114951f00442" category="list-text">以EC2-user身份登录到EC2实例数据库主机、然后安装python3库。</block>
  <block id="03c10a897f1e18c6adaea250b9f30f19" category="inline-link-macro">如何使用交换文件分配内存以用作Amazon EC2实例中的交换空间？</block>
  <block id="85e9698f3736149506cd49ab88086364" category="list-text">从根磁盘驱动器创建16G交换空间。默认情况下、EC2实例创建的交换空间为零。请按照以下AWS文档操作： <block ref="53c9867a131506eab4afe1a1678bb974" category="inline-link-macro-rx"></block>。</block>
  <block id="be82130abf6bfa8956a5648b39ad4aa8" category="list-text">返回到Ansible控制器(`cd /home/EC2-user/na_RDS_FSx_oranfs_config`)、并根据相应要求和`linux_config`标记执行克隆前攻略手册。</block>
  <block id="83e233b8fca25fb162266daf344246e4" category="list-text">切换到`/home/EC2-user/na_oracle19c_deploy-master`目录、阅读README文件、并使用相关全局参数填充全局`vars.yml`文件。</block>
  <block id="aed4b8eabfef5056093412d8609b5b9a" category="list-text">使用`host_vars`目录中的相关参数填充`host_name.yml`文件。</block>
  <block id="4b8d8efa08e1060a3db2c7693c4de645" category="list-text">执行适用于Linux的攻略手册、并在系统提示输入vsadmin密码时按Enter键。</block>
  <block id="4d552f393608513441eb151998098b4a" category="list-text">执行适用于Oracle的攻略手册、并在系统提示您输入vsadmin密码时按Enter键。</block>
  <block id="af392a54b9a2464fdd334372589f1a39" category="paragraph">如果需要、将SSH密钥文件上的权限位更改为400。将Oracle主机(`host_vars`文件中的`Ansible主机`) IP地址更改为EC2实例公有 地址。</block>
  <block id="ac52b3f8d77eb6814ddf5c761b019c22" category="section-title">在主FSX HA集群和备用FSX HA集群之间设置SnapMirror</block>
  <block id="3798adb983c6ffabbcf459359d5ddd4c" category="paragraph">为了实现高可用性和灾难恢复、您可以在主FSX存储集群和备用FSX存储集群之间设置SnapMirror复制。与其他云存储服务不同、FSX支持用户按所需频率和复制吞吐量控制和管理存储复制。此外、它还允许用户在不影响可用性的情况下测试HA/DR。</block>
  <block id="5414f0571ab88c4269ee945ce4291f65" category="paragraph">以下步骤显示了如何在主FSX存储集群和备用FSX存储集群之间设置复制。</block>
  <block id="006c42f009ead3331b1f69ac1979609d" category="list-text">设置主集群对等和备用集群对等。以fsxadmin用户身份登录到主集群、然后执行以下命令。此对等创建过程会在主集群和备用集群上执行create命令。将`standby-cluster_name`替换为适用于您的环境的名称。</block>
  <block id="c725d46c724a573eb994f08a1f309eec" category="list-text">在主集群和备用集群之间设置SVM对等关系。以vsadmin用户身份登录到主集群、然后执行以下命令。将`primary_vserver_name`、`standby-vserver_name`、`standby-cluster_name`替换为适用于您环境的名称。</block>
  <block id="91ba2ff3a22b9830c626441ad69c84ce" category="list-text">验证集群和SVM对等项是否设置正确。</block>
  <block id="7b39dc0f7648c038ec8ac59504316d0e" category="paragraph"><block ref="7b39dc0f7648c038ec8ac59504316d0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4cb6743e20f6b87b419d9386d784acc" category="list-text">在备用FSX集群上为主FSX集群上的每个源卷创建目标NFS卷。根据您的环境需要替换卷名称。</block>
  <block id="8f65518a43c3a1ba084510438fa2d7d3" category="list-text">如果使用iSCSI协议进行数据访问、则还可以为Oracle二进制文件、Oracle数据和Oracle日志创建iSCSI卷和LUN。在卷中为快照留出大约10%的可用空间。</block>
  <block id="43aea99cd4b66a7a2f8efdc090e3a5ad" category="paragraph">vol create -volume dr_db1_log -aggregate aggr1 -size 250G -state online -policy default -unix-permissions -rwxr-x -type rw</block>
  <block id="18274474e00c13f064a0b4df0b516185" category="list-text">对于iSCSI LUN、使用二进制LUN作为示例、为每个LUN的Oracle主机启动程序创建映射。将igroup替换为适合您环境的名称、并增加每个附加LUN的lun-id。</block>
  <block id="0c2c0f6ddcbbbf39434893162abce545" category="list-text">在主数据库卷和备用数据库卷之间创建SnapMirror关系。替换您的环境的相应SVM名称</block>
  <block id="a25539ee33148e6d4880b87e1378cafe" category="paragraph">可以使用适用于NFS数据库卷的NetApp自动化工具包自动设置此SnapMirror。该工具包可从NetApp公有 GitHub站点下载。</block>
  <block id="f9f129d1122f9209f8f27fa07a5ee4b2" category="paragraph">在尝试进行设置和故障转移测试之前、请仔细阅读自述文件中的说明。</block>
  <block id="03b2167f2383aa796f361c5c1c689a49" category="admonition">将Oracle二进制文件从主集群复制到备用集群可能会涉及Oracle许可证。有关说明、请联系您的Oracle许可证代表。另一种方法是在恢复和故障转移时安装和配置Oracle。</block>
  <block id="fa697481d9c5655bd57d6ee69f0e9f07" category="section-title">SnapCenter 部署</block>
  <block id="3f4b23cd1391b97e8a33f3973471103b" category="section-title">SnapCenter 安装</block>
  <block id="4c88778182d61374292e3c4ad43ae50e" category="inline-link-macro">安装SnapCenter 服务器</block>
  <block id="282e73196d7c89bb5ec3820592ecee7c" category="paragraph">请遵循 <block ref="9cac1dd5d049b670d2cd847d9e42d30c" category="inline-link-macro-rx"></block> 安装SnapCenter 服务器。本文档介绍如何安装独立的SnapCenter 服务器。SaaS版本的SnapCenter 正在进行测试审核、不久将推出。如果需要、请咨询NetApp代表以了解可用性。</block>
  <block id="a4c2182f79a7834db47fccf9c264332d" category="section-title">为EC2 Oracle主机配置SnapCenter 插件</block>
  <block id="8d0edf4e55e8bc1a96862466762dcdd6" category="list-text">自动安装SnapCenter 后、以安装SnapCenter 服务器的Window主机的管理用户身份登录到SnapCenter。</block>
  <block id="27ee26e15e1da051ff520bf3f87f2a03" category="paragraph"><block ref="27ee26e15e1da051ff520bf3f87f2a03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4af2386526da94f1d101d825c0a623e0" category="list-text">从左侧菜单中、单击设置、然后单击凭据和新建、为SnapCenter 插件安装添加EC2-user凭据。</block>
  <block id="252932f5140410e8d8795c4236e41b47" category="paragraph"><block ref="252932f5140410e8d8795c4236e41b47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37fc637fcb7f9b2e4336350dd7d4775e" category="list-text">通过编辑EC2实例主机上的`/etc/ssh/sshd_config`文件、重置EC2-user密码并启用密码SSH身份验证。</block>
  <block id="c1e0ecc2d0f187a040af9ef1e783314d" category="list-text">验证是否已选中"Use sudo privileges"复选框。您只需在上一步中重置EC2-user密码即可。</block>
  <block id="cc57c2c5394de6466406382d198ba244" category="paragraph"><block ref="cc57c2c5394de6466406382d198ba244" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3326cea52418b74168243fb56340785" category="list-text">将SnapCenter 服务器名称和IP地址添加到EC2实例主机文件以进行名称解析。</block>
  <block id="59c8e627359bc3d4ce92126cbb1356cc" category="list-text">在SnapCenter 服务器Windows主机上、将EC2实例主机IP地址添加到Windows主机文件`C：\Windows\System32\drivers\etc\hosts`。</block>
  <block id="4f91fe76ef9595ef98ee3b0c06a43160" category="list-text">在左侧菜单中、选择主机&gt;受管主机、然后单击添加将EC2实例主机添加到SnapCenter。</block>
  <block id="a5714b50c71edc910f423bfdc433d799" category="paragraph"><block ref="a5714b50c71edc910f423bfdc433d799" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb20727c22e9cab381fd0cd7e817ab85" category="paragraph">检查Oracle数据库、然后在提交之前、单击更多选项。</block>
  <block id="7fab569defa89099ea4c5d28723e2031" category="paragraph"><block ref="7fab569defa89099ea4c5d28723e2031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e249b54031e8a30915659857356cab" category="paragraph">选中跳过预安装检查。确认跳过预安装检查、然后在保存后单击提交。</block>
  <block id="3d82631a68b3ec0960761342005b2eca" category="paragraph"><block ref="3d82631a68b3ec0960761342005b2eca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d66b31e61ce12ed5022484588882f5f" category="paragraph">系统将提示您确认指纹、然后单击确认并提交。</block>
  <block id="795d864d6ec7d5ca3d8c36c9a83bba6e" category="paragraph"><block ref="795d864d6ec7d5ca3d8c36c9a83bba6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99177ab734274d9f5f703761e4b2deef" category="paragraph">成功配置插件后、受管主机的整体状态将显示为正在运行。</block>
  <block id="1fa50503e60bc51f7dea31d9e91c9c20" category="paragraph"><block ref="1fa50503e60bc51f7dea31d9e91c9c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="112fdeb0eaa93f627cf0effc06f49c76" category="section-title">配置Oracle数据库的备份策略</block>
  <block id="30baaa9bedea395f88f6183eda043198" category="paragraph">请参见本节 <block ref="5b001af64dcc5050a16c7369f5f2fae2" category="inline-link-macro-rx"></block> 有关配置Oracle数据库备份策略的详细信息。</block>
  <block id="6bfb2a8edb5f9cfb06059a588dda9cc0" category="paragraph">通常、您需要为完整快照Oracle数据库备份创建一个策略、并为Oracle归档日志唯一快照备份创建一个策略。</block>
  <block id="708ae75a87a6997af6838bc2e5149a28" category="admonition">您可以在备份策略中启用Oracle归档日志修剪、以控制日志归档空间。如果需要复制到HA或DR的备用位置、请选中"选择二级复制选项"中的"创建本地Snapshot副本后更新SnapMirror"。</block>
  <block id="acea2698961ae21a708203b9a9b86b94" category="section-title">配置Oracle数据库备份和计划</block>
  <block id="56f3e355b3a4359c9a0808d978ca484c" category="paragraph">SnapCenter 中的数据库备份可由用户配置、可以单独设置、也可以作为资源组中的组进行设置。备份间隔取决于RTO和RPO目标。NetApp建议您每隔几小时运行一次完整的数据库备份、并以10到15分钟等较高的频率对日志备份进行归档、以实现快速恢复。</block>
  <block id="cd6290f31cba79c826366f0927d0dc94" category="paragraph">请参阅的Oracle部分 <block ref="6d8b99fb2ff81ed91f5551e33542f4f8" category="inline-link-macro-rx"></block> 有关实施一节中创建的备份策略的详细分步过程 <block ref="f2afcb5a9b8ad2d8fe33e91cb4edb80f" category="inline-xref-macro-rx"></block> 和用于备份作业计划。</block>
  <block id="b47b1d2e2c373fd6c07f22a130e90a41" category="paragraph">下图举例说明了为备份Oracle数据库而设置的资源组。</block>
  <block id="9736ab13cec4c0e5ba0c09476a101fb2" category="paragraph"><block ref="9736ab13cec4c0e5ba0c09476a101fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8a1d7e9120e3db2795bd53b504018b4e" category="summary">本白皮书概述并验证了适用于AWS的解决方案 自定义Oracle RDS数据库HA和DR、并在多可用性区域部署中利用AWS FSx存储服务。</block>
  <block id="b4c8c277e19db14e178b1060214b896e" category="paragraph">NetApp公司的Allen Cao、Niyaz Mohamed、Jeffrey Steiner</block>
  <block id="6848412b0f30d614f7e0bcd903cac052" category="paragraph">许多任务关键型企业级Oracle数据库仍托管在内部、许多企业都希望将这些Oracle数据库迁移到公有 云。这些Oracle数据库通常以应用程序为中心、因此需要用户专用配置、而许多数据库即服务公共云产品都缺少这一功能。因此、当前的数据库环境要求基于公共云的Oracle数据库解决方案 、该数据库是基于高性能、可扩展的计算和存储服务构建的、可满足独特的需求。AWS EC2计算实例和AWS FSX存储服务可能是这个难题的缺失部分、您可以利用这些信息构建任务关键型Oracle数据库工作负载并将其迁移到公有 云。</block>
  <block id="37b7c86d51875922e0a9f122a670aa62" category="paragraph">Amazon Elastic Compute Cloud (Amazon EC2)是一种Web服务、可在云中提供安全、可调整大小的计算容量。它旨在使企业更轻松地进行网络级云计算。通过简单的Amazon EC2 Web服务界面、您可以轻松获得和配置容量、而不会产生任何摩擦。它可以让您完全控制计算资源、并在经过Amazon验证的计算环境中运行。</block>
  <block id="c9550c9d9c1b379ad427d739b5c69f00" category="paragraph">Amazon FSX for ONTAP 是一种AWS存储服务、它使用行业领先的NetApp ONTAP 块和文件存储、可公开NFS、SMB和iSCSI。借助如此强大的存储引擎、将任务关键型Oracle数据库应用程序重新定位到AWS从未如此简单、其响应时间为亚毫秒级、吞吐量高达多Gbps、每个数据库实例的IOPS超过100、000次。更好的是、FSX存储服务还附带了原生 复制功能、您可以轻松地将内部Oracle数据库迁移到AWS、或者将任务关键型Oracle数据库复制到二级AWS可用性区域以实现HA或DR。</block>
  <block id="b3f95d0186b2e4989ad81f07a21d72c5" category="paragraph">本文档的目标是、提供有关如何使用FSX存储和EC2实例部署和配置Oracle数据库的分步流程、过程和最佳实践指导、该实例可提供与内部系统类似的性能。NetApp还提供了一个自动化工具包、用于自动执行在AWS公有 云中部署、配置和管理Oracle数据库工作负载所需的大部分任务。</block>
  <block id="32800a2387c1d841d80eab97ff7205c2" category="summary">本节详细介绍了在AWS EC2实例和FSX存储上部署Oracle数据库时需要考虑的因素。</block>
  <block id="c53749244d982efb6aa5653328227c2a" category="doc">部署Oracle数据库时需要考虑的因素</block>
  <block id="96f819dcc02d1203a3923ddad366ff4b" category="paragraph">公有 云为计算和存储提供了多种选择、使用正确类型的计算实例和存储引擎是开始部署数据库的好地方。您还应选择针对Oracle数据库进行优化的计算和存储配置。</block>
  <block id="e958329ac331abb8419551328745ce28" category="paragraph">以下各节介绍了在使用FSX存储的EC2实例上的AWS公有 云中部署Oracle数据库时的主要注意事项。</block>
  <block id="af9adf45d47438d70bedeea4353827c3" category="paragraph">选择合适的 VM 大小对于公有云中关系数据库的最佳性能非常重要。为了提高性能、NetApp建议在Oracle部署中使用EC2 M5系列实例、该实例针对数据库工作负载进行了优化。AWS还会使用相同的实例类型为Oracle的RDS实例提供支持。</block>
  <block id="1dbc89cff7796dd99cbe9338453d04d7" category="list-text">根据工作负载特征选择正确的vCPU和RAM组合。</block>
  <block id="ff1a938ecebc5237c31b8f5d9a9b87ce" category="list-text">向VM添加交换空间。默认的EC2实例部署不会创建交换空间、而交换空间对于数据库来说并不是最佳选择。</block>
  <block id="d4d5d0e2fb33dadfad4435489bd718a4" category="section-title">存储布局和设置</block>
  <block id="0fe994abd6c200feb672e77242fe9fcb" category="paragraph">NetApp建议采用以下存储布局：</block>
  <block id="c1b542506bceb69c76148851e217c49f" category="list-text">对于NFS存储、建议的卷布局为三个卷：一个用于Oracle二进制文件；一个用于Oracle数据和一个重复的控制文件；一个用于Oracle活动日志、归档日志和控制文件。</block>
  <block id="02833700de6eac537733ce81ef6352a3" category="paragraph"><block ref="02833700de6eac537733ce81ef6352a3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc828f321000aae204feb1f0f945893" category="list-text">对于iSCSI存储、建议的卷布局为三个卷：一个用于Oracle二进制文件；一个用于Oracle数据和一个重复的控制文件；一个用于Oracle活动日志、归档日志和控制文件。但是、理想情况下、每个数据卷和日志卷都应包含四个LUN。在HA集群节点上、LUN的平衡性最佳。</block>
  <block id="cddd034875839504dacaa29e5dca803f" category="paragraph"><block ref="cddd034875839504dacaa29e5dca803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7810ed5b0bbb3acf153d353ac803a51" category="list-text">对于存储IOPS和吞吐量、您可以为FSX存储集群的已配置IOPS和吞吐量选择阈值、并且可以随时在工作负载发生变化时动态调整这些参数。</block>
  <block id="c5493cd0fe001da987655ad852808dc7" category="list-text">自动IOPS设置是、在已分配存储容量或用户定义的存储中、每个GiB三个IOPS、最多80、000个。</block>
  <block id="6524d7ff1096fc6a10590b6d1f7163b6" category="list-text">吞吐量级别将按以下方式递增：128、256、512、1024、2045 Mbps。</block>
  <block id="bc4bb24d5e702fb79be623b84e7cf47e" category="inline-link-macro">适用于NetApp ONTAP 性能的Amazon FSX</block>
  <block id="b59267e60b3253fa9c2edeed17c1340f" category="paragraph">查看 <block ref="a572b0e55a3a15b7b3460602e8714ba1" category="inline-link-macro-rx"></block> 估算吞吐量和IOPS规模时的文档。</block>
  <block id="10edbbba4e4c39fc161aeac9fbb88aef" category="section-title">NFS 配置</block>
  <block id="2b7570eaa12a3e472e9d0cbac6631d57" category="paragraph">需要考虑的其他因素：</block>
  <block id="6841f6ce9d9a2af93222223df564ca34" category="list-text">TCP插槽表是主机总线适配器(host-bus-adapter、HBA)队列深度的NFS等效项。这些表可控制任何时候都可以处理的NFS操作的数量。默认值通常为16、该值太低、无法实现最佳性能。在较新的Linux内核上会出现相反的问题、这会自动将TCP插槽表限制增加到使NFS服务器充满请求的级别。</block>
  <block id="5a749fcdd97cee211c5fea00babe8691" category="paragraph">为了获得最佳性能并防止出现性能问题、请将控制TCP插槽表的内核参数调整为128。</block>
  <block id="dcd7ebfa96f217f8d20c58a185a48531" category="list-text">下表提供了适用于Linux NFSv3 -单个实例的建议NFS挂载选项。</block>
  <block id="4780ee7b64d0ec83e06977206e8a35b5" category="paragraph"><block ref="4780ee7b64d0ec83e06977206e8a35b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2fe1fc26875d6d38f4b15a3a03d498fb" category="paragraph">如解决方案 架构所示、HA基于存储级别复制构建。因此、Oracle的启动和可用性取决于计算和存储的启动和恢复速度。请参见以下主要因素：</block>
  <block id="137bc4c57a9561d086601728a3db1a90" category="list-text">准备好备用计算实例、并通过向两个主机进行Ansible并行更新与主实例同步。</block>
  <block id="d653e9032c9904901af96f496db98a3e" category="list-text">从主系统复制二进制卷以供备用、这样您就不需要在最后一分钟安装Oracle并确定需要安装和修补的内容。</block>
  <block id="77991416cd2e0bfc66a77d32e3fbb45a" category="list-text">复制频率决定了恢复Oracle数据库以提供服务的速度。复制频率与存储消耗之间存在一定的权衡。</block>
  <block id="0797ee9bca14d1064492a93ac7cc7fa1" category="list-text">利用自动化功能快速恢复并切换到备用模式、不会出现人为错误。为此、NetApp提供了一个自动化工具包。</block>
  <block id="90a0d380974aa73acb8330f1ff9a7930" category="summary">本节详细介绍了将Oracle数据库从内部迁移到AWS EC2实例和FSX存储时需要考虑的因素。</block>
  <block id="895a8d39dd9ae7fe795349bdbc3f05dc" category="doc">将数据库从内部迁移到公有 云</block>
  <block id="373ae4e24c2daa280a4a5aca82dd3818" category="paragraph">数据库迁移无论如何都是一项极具挑战性的工作。将Oracle数据库从内部迁移到云也不例外。</block>
  <block id="d1e968e04e34c971d41e644820094cef" category="paragraph">以下各节提供了在使用AWS EC2计算和FSX存储平台将Oracle数据库迁移到AWS公有 云时需要考虑的关键因素。</block>
  <block id="84639b5fb3b348e6a053dde95414e039" category="section-title">ONTAP 存储可在内部使用</block>
  <block id="df2111c23e70fa013a85041e1415639e" category="list-text">构建与内部实例匹配的目标计算EC2实例。</block>
  <block id="1931f75e563d3dc9ee112e9b4ebd66b7" category="list-text">从FSX控制台配置大小相等的匹配数据库卷。</block>
  <block id="98201e355445ae8a2eff3b7c33132cc6" category="list-text">将FSX数据库卷挂载到EC2实例。</block>
  <block id="53fad15133e494dc37bbd0494b8f3a6c" category="list-text">在内部数据库卷与目标FSX数据库卷之间设置SnapMirror复制。初始同步可能需要一段时间才能移动主源数据、但后续的任何增量更新都要快得多。</block>
  <block id="8da4f0ed2ee5c7e68c3fe9ec3dde280e" category="list-text">拆分镜像卷、在目标上运行Oracle恢复、并启动数据库以进行服务。</block>
  <block id="6efd103fd0a488a3d023523ab6377e4e" category="list-text">将应用程序指向云中的Oracle数据库。</block>
  <block id="86afa353cad293784396216eab80ee52" category="section-title">ONTAP 存储在内部不可用</block>
  <block id="c11080183211191097c120f87656c802" category="paragraph">如果内部Oracle数据库托管在ONTAP 以外的第三方存储上、则数据库迁移基于还原Oracle数据库备份副本。切换前、必须播放归档日志以使其保持最新。</block>
  <block id="722283478873a13974c4b1b6ea967a40" category="paragraph">AWS S3可用作数据库移动和迁移的暂存存储区域。有关此方法、请参见以下高级步骤：</block>
  <block id="9312555163563ac6b35994e42f15d009" category="list-text">配置一个与内部实例相当的新的匹配EC2实例。</block>
  <block id="8705a6dedde3ea188c113bda4fe97c14" category="list-text">从FSX存储配置等效的数据库卷、并将这些卷挂载到EC2实例。</block>
  <block id="6aeff6e3d9f2f107fa5584191966f816" category="list-text">创建磁盘级Oracle备份副本。</block>
  <block id="0f90c0c06dae8f50c3f93d33a7547df2" category="list-text">将备份副本移动到AWS S3存储。</block>
  <block id="d8fd670e7724b3db99919ea02cd762cc" category="list-text">重新创建Oracle控制文件、并通过从S3存储中提取数据和归档日志来还原和恢复数据库。</block>
  <block id="c4a99d505e8ebe4d5f04ae86d2a724b7" category="list-text">将目标Oracle数据库与内部源数据库同步。</block>
  <block id="3bac7326688b384ce82c7c9807cae4b7" category="list-text">切换时、关闭应用程序和源Oracle数据库。复制最后几个归档日志并将其应用于目标Oracle数据库以使其保持最新。</block>
  <block id="98cf6a7f87338026b5b95afee91d5676" category="list-text">启动目标数据库以供用户访问。</block>
  <block id="021e473c3a779caff7d794ce36c8ef68" category="list-text">将应用程序重定向到目标数据库以完成切换。</block>
  <block id="a8fba1abc3fbaa027d18daed3f6e170d" category="doc">安装MetalLB负载平衡器</block>
  <block id="48501496ee9b06b63701de94b6ffc3a5" category="paragraph">此页面列出了MetalLB受管负载平衡器的安装和配置说明。</block>
  <block id="ccd779a5e754b22c1589256334866c0a" category="paragraph">MetalLB负载平衡器与VMware上的Anthos集群完全集成在一起、并从1.11版开始在管理和用户集群设置中执行自动部署。在相应的`cluster.YAML`配置文件中存在文本块、您必须修改这些块才能提供负载平衡器信息。它可以在您的Anthos集群上自行托管、而无需像其他受支持的负载平衡器解决方案那样部署外部资源。此外、您还可以创建一个IP池、通过在未在云提供商上运行的集群中创建类型为负载平衡器的Kubernetes服务来自动分配地址。</block>
  <block id="b938ac6243408826bd53c58d2a6a6f1f" category="paragraph">为Anthos admin启用MetalLB负载平衡器时、您必须修改`admin-cluster.YAML`文件中`loadbalancer：`部分中的几行。您只能修改`controlPlaneVIP：` address、然后将`kind：`设置为MetalLB。有关示例、请参见以下代码片段：</block>
  <block id="79fdf71abab382ca3fbab93d863f835c" category="paragraph">为Anthos用户集群启用MetalLB负载平衡器时、每个`user-cluster.YAML`文件中有两个区域必须更新。首先、您必须以类似于`admin-cluster.yaml`文件的方式在`loadbalancer：`部分中修改`controlPlaneVIP：`、`ingressVIP：`和`kind：`值。有关示例、请参见以下代码片段：</block>
  <block id="c173f58ae6718fb7dc80d6ddb9b392e5" category="admonition">此ingresVIP IP地址必须位于稍后在配置中分配给MetalLB负载平衡器的IP地址池中。</block>
  <block id="77960f17a334c28c4bacd9515ac55817" category="paragraph">然后、您需要导航到`metalLB：`子部分、并通过在`- name：`变量中命名池来修改`addressPools：`部分。此外、还必须创建一个IP地址池、MetalLB可以通过为`addresses：`变量提供一个范围来将该IP地址池分配给loadbalancer类型的服务。</block>
  <block id="8dfd015968f24ba6c3e2d8386cd40cbe" category="admonition">可以像示例一样提供地址池范围、将其限制为特定子网中的多个地址、也可以在整个子网可用时提供CIDR表示法。</block>
  <block id="ea4a20324a094d5f515252d5669a60ca" category="list-text">创建类型为loadbalancer的Kubernetes服务时、MetalLB会自动为这些服务分配外部IP、并通过响应ARP请求来公布IP地址。</block>
  <block id="c09bdf0c852b6f771b10fb71482778db" category="paragraph">应用程序的备份可捕获应用程序的活动状态及其资源配置、将其转换为文件、并将其存储在远程对象存储分段中。</block>
  <block id="3805fe09ab2fab11e5a88285db1ba4f1" category="paragraph">要创建应用程序备份、请完成以下步骤：</block>
  <block id="17937980068cd45516e074151c756bab" category="list-text">要在Astra控制中心创建受管应用程序的备份、请导航到应用程序&gt;受管、然后单击要备份的应用程序。单击应用程序名称旁边的下拉菜单，然后单击备份。</block>
  <block id="d587342349a123dddff71bef9eb7b6e6" category="paragraph">要还原应用程序、请完成以下步骤：</block>
  <block id="804e8c9205cc0caea9e5cb6645febba7" category="list-text">导航到应用程序&gt;受管选项卡、然后单击有问题的应用程序。单击应用程序名称旁边的下拉菜单、然后单击还原。</block>
  <block id="b0ff29eefb84e5d7a2cdae616ae42213" category="list-text">输入新命名空间的详细信息、选择要将其克隆到的集群、然后选择是要从现有快照、备份还是应用程序的当前状态克隆该命名空间。查看详细信息后、单击下一步、然后单击"审阅"窗格上的克隆。</block>
  <block id="4c0e19abe22935505e774d4d3b2e8449" category="list-text">当Astra控制中心在选定集群上创建应用程序时、新应用程序将进入发现状态。在Astra安装并检测到应用程序的所有资源后、该应用程序将进入可用状态。</block>
  <block id="abb33c60fb7710d77680621bb6bb0433" category="doc">安装F5 BIG-IP负载平衡器</block>
  <block id="4f3422718812b2a40b70340da35b565c" category="paragraph">F5 BIG-IP是一款应用程序交付控制器(Application Delivery Controller、AD)、可提供一系列高级的生产级流量管理和安全服务、例如L4-L7负载平衡、SSL/TLS卸载、DNS、防火墙等。这些服务可显著提高应用程序的可用性、安全性和性能。</block>
  <block id="81d91349803cba0e1b0d0f84948ff37c" category="paragraph">F5 BIG-IP可以通过多种方式进行部署和使用、包括在专用硬件上、在云中或作为内部虚拟设备。请参见此处的文档、了解并部署F5 BIG-IP。</block>
  <block id="cb9f661ea2c5b0b25cb936398de81286" category="admonition">F5 BIG-IP可以在独立模式或集群模式下部署。为了进行此验证、F5 BIG-IP部署在独立模式下。但是、出于生产目的、NetApp建议创建一个由大IP实例组成的集群、以避免单点故障。</block>
  <block id="9c62eb7c12e4e6a75fc74fffecb2db09" category="paragraph">NetApp的解决方案工程团队已在我们的实验室中验证下表中的版本、以使用Anthos On-Prem的部署：</block>
  <block id="930835cee46ee894bb92b5627c286380" category="paragraph"><block ref="930835cee46ee894bb92b5627c286380" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5869793ca55f5fc50960cbd965138c70" category="inline-image-macro">部署 Big IP 设备，第 2 部分</block>
  <block id="b395903460348cc88bfae6fcad255f21" category="paragraph"><block ref="b395903460348cc88bfae6fcad255f21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca9eda681850d46169f2940362b1548f" category="inline-image-macro">部署 Big IP 设备，第 3 部分</block>
  <block id="9c7b1162de6217dfe316b9d57d67b16f" category="paragraph"><block ref="9c7b1162de6217dfe316b9d57d67b16f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="372bcca75330a5dc5675a722489ff49b" category="paragraph"><block ref="372bcca75330a5dc5675a722489ff49b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e7de45031877e6ff00d3069664fbcaf" category="inline-image-macro">BIG-IP 配置，第 2 部分</block>
  <block id="cee8fbb1e19d03d10bbd1e01e76cf77b" category="paragraph"><block ref="cee8fbb1e19d03d10bbd1e01e76cf77b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b648434aacde9879c494bb807f510d0a" category="inline-image-macro">BIG-IP 配置，第 3 部分</block>
  <block id="abc7fe3f8ac78f7eef2f5ca730be051c" category="paragraph"><block ref="abc7fe3f8ac78f7eef2f5ca730be051c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48f2578529c2f8c811567604f610cb5f" category="inline-image-macro">BIG-IP 配置，第 4 部分</block>
  <block id="7032ef2cca6e17b4d3590ecbbce7ff16" category="paragraph"><block ref="7032ef2cca6e17b4d3590ecbbce7ff16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9fd499e062b35d18ef68efd381c6c09" category="inline-image-macro">BIG-IP 配置，第 6 部分</block>
  <block id="78df99aca47bd680a19574eebccf4249" category="paragraph"><block ref="78df99aca47bd680a19574eebccf4249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4e4f5e5f31a0b8312fb2338d9015dd0" category="inline-image-macro">BIG-IP 配置，第 7 部分</block>
  <block id="72cb9d54a4958e24c358ee0871b24454" category="paragraph"><block ref="72cb9d54a4958e24c358ee0871b24454" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c574654bbbf1cf9927e54a1cf4152c71" category="list-text">向导的第一页配置冗余；保留默认值，然后单击下一步。在下一页中，您可以在负载平衡器上配置内部接口。接口1.1映射到OVF部署向导中标记为Internal的vmnic。</block>
  <block id="19ee7bbff17fca60aeffed9079a87c6b" category="inline-image-macro">BIG-IP 配置，第 8 部分</block>
  <block id="93e0638cb95146eb8773223a90aa6d86" category="list-text">在下一页中，您可以配置一个外部网络，用于将服务映射到 Kubernetes 中部署的 Pod 。从 VM_Network 范围中选择一个静态 IP ，相应的子网掩码以及同一范围中的浮动 IP 。接口1.2映射到OVF部署向导中标记为外部的vmnic。</block>
  <block id="803c8b846cb5b5c6c8d5a2b0b07f4dba" category="inline-image-macro">BIG-IP 配置，第 9 部分</block>
  <block id="9cd42351da162e75b1a0178bdd0ded20" category="inline-image-macro">BIG-IP 配置，第 10 部分</block>
  <block id="ad99125325ea694a08a4db92eabb18a1" category="inline-image-macro">BIG-IP 配置，第 11 部分</block>
  <block id="d71ac8787685cb0f3b8f800520d684b1" category="paragraph"><block ref="d71ac8787685cb0f3b8f800520d684b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0344c261b0475e6caf01bb585530f" category="list-text">显示的屏幕仅显示当前通用分区。单击右侧的Create创建以创建第一个附加分区、并将其命名为`GKE-Admin`。然后单击重复、将分区命名为`User-Cluster-1`。再次单击重复按钮可将下一个分区命名为`User-Cluster-2`。最后，单击 " 完成 " 以完成向导。此时将返回分区列表屏幕，其中列出了所有分区。</block>
  <block id="938c47fe40c045ae4bc242bf2339ab01" category="inline-image-macro">BIG-IP 配置，第 12 部分</block>
  <block id="598f9d349e1cb4c318e78a0d182dd743" category="paragraph"><block ref="598f9d349e1cb4c318e78a0d182dd743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc19630e1d9c7f2a85a541796c5ec51" category="paragraph">每个配置文件中分别有一个部分用于管理集群和您选择部署的每个用户集群、用于配置负载平衡器、以便由Prem上的Anthos管理。</block>
  <block id="38779167fbee63015f17c4c1b453dd32" category="paragraph">以下脚本是GKE-Admin集群分区配置的示例。需要取消注释和修改的值以粗体文本显示在下方：</block>
  <block id="288c554e356764c1144e77f0d78f97bf" category="doc">了解负载平衡器选项</block>
  <block id="807a04fd6be3315608f66b00ab708987" category="paragraph">部署在Anthos中的应用程序通过由部署在Anthos内部环境中的负载平衡器提供的服务向世界公开。</block>
  <block id="a5fcf88905522eca0a7500198fc13ea9" category="paragraph">示例包括：</block>
  <block id="231a9d200c75839cf9b4ffeecde45821" category="list-text">*自带Linux操作系统。*通过选择要将裸机环境部署到的Linux操作系统、您可以确保Anthos环境与现有基础架构和管理方案完美结合。</block>
  <block id="8f3c025cf8c4fb1a7841163ea4213611" category="list-text">*提高性能并降低成本。*如果不需要虚拟机管理程序、则裸机集群中的Anthos-on-bare要求直接访问服务器硬件资源、包括GPU等性能优化的硬件设备。</block>
  <block id="5c96e444541cebd597916a4a84177f6b" category="list-text">*提高了网络性能并降低了延迟。*由于裸机Anthos-on-bare服务器节点直接连接到您的网络、而无需虚拟化抽象层、因此可以对其进行优化、以实现低延迟和低性能。</block>
  <block id="08c2b93847522285403aa57a50c67356" category="paragraph">在裸机上使用Anthos-on-bare节点时、可以根据客户的选择配置多个不同的Linux分发版、以匹配其当前的数据中心基础架构。</block>
  <block id="cb9cc8981898224a2fe45ac6ff7d4244" category="cell">1.11</block>
  <block id="969f1705e87aebac2415f45faaf8ef89" category="cell">A250、A220</block>
  <block id="9401797270b98418222b9be6674161bc" category="admonition">此多操作系统环境显示了与受支持的操作系统版本的裸机解决方案 互操作性。我们预计、客户将在部署时对一个或一小部分操作系统进行标准化。</block>
  <block id="3a6810b280d17ed872c226f7c95dac46" category="list-text">至少一个DNS服务器、可提供可从管理网络访问的完整主机名解析。</block>
  <block id="14de5275438fed7bf294f7d1ef6ebfce" category="list-text">至少一个可从管理网络访问的NTP服务器。</block>
  <block id="ab851d2f29c7c89b9bc55851dd1002d2" category="list-text">(可选)两个带内管理网络的出站Internet连接。</block>
  <block id="82d4df3a9be244e5548f2913b75e403c" category="admonition">本文档的"视频和演示"一节提供了有关裸机部署的Anthos的演示视频。</block>
  <block id="e66e12138810859d8abf5fa2081fb491" category="summary">如何使用Google Cloud Console将应用程序部署到内部的Anthos GKEE集群。</block>
  <block id="0fedf382c8cab1bb4bd4137b2edd4ddf" category="doc">从Google Cloud Console Marketplace部署应用程序</block>
  <block id="db974f321885ec32e283b3ba19624bf5" category="list-text">一个部署在内部并注册到Google Cloud Console的Anthos集群</block>
  <block id="86baa7935f2da05d24c2736b997d56af" category="list-text">在Anthos集群中配置的MetalLB负载平衡器</block>
  <block id="0e4a5cc43eded7fb6f9688b4db42749c" category="list-text">有权将应用程序部署到集群的帐户</block>
  <block id="0abcad93e8aa42fe77227a82e7bfac88" category="list-text">如果您选择具有相关成本的应用程序、则为Google Cloud的计费帐户(可选)</block>
  <block id="241b7771ea8f8a56aa7c79c94ea05b45" category="section-title">部署应用程序</block>
  <block id="7519665b833135b7a83098238355d197" category="paragraph">在此使用情形中、我们使用Google Cloud Console将一个简单的WordPress应用程序部署到一个Anthos集群中。此部署使用NetApp ONTAP 在预定义的存储库中提供的永久性存储。然后、我们将演示两种不同的方法来修改应用程序默认服务、以便MetalLB负载平衡器为其提供IP地址并将其公开给世界。</block>
  <block id="0f46ecb3b1113d47388dd5a45b007f77" category="paragraph">要以这种方式部署应用程序、请完成以下步骤：</block>
  <block id="284e9ebcc65faa3412015e1aef0b212f" category="list-text">确认要部署到的集群可在Google Cloud Console中访问。</block>
  <block id="c5ae9e1da0751273beff7dba35e9f3a0" category="inline-image-macro">已注册集群</block>
  <block id="113157b1187558580348ca8d41e0e09d" category="paragraph"><block ref="113157b1187558580348ca8d41e0e09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ffca2e9c9a134c6025fcd79da7b2c759" category="list-text">从左侧菜单中选择应用程序、选择顶部的三点选项菜单、然后选择从Marketplace部署、此时将显示一个新窗口、您可以从Google Cloud Marketplace中选择应用程序。</block>
  <block id="0684d335d9a7c1f72f6bfcd5a3f89e00" category="inline-image-macro">应用程序市场</block>
  <block id="c2c2bcc598caddf4725c028c7db228b2" category="paragraph"><block ref="c2c2bcc598caddf4725c028c7db228b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1116a3fdba8715414e3ef4e4f99912" category="list-text">搜索要安装的应用程序、此处为WordPress。</block>
  <block id="822f5bce2ee65cbb4bdffaba2710ba34" category="inline-image-macro">搜索WordPress</block>
  <block id="660eb3f5a04738d18f35a59427836264" category="paragraph"><block ref="660eb3f5a04738d18f35a59427836264" category="inline-image-macro-rx" type="image"></block></block>
  <block id="510d39751378d8f38e07c02ea0fc6be6" category="list-text">选择WordPress应用程序后、将显示一个概述屏幕。单击配置按钮。</block>
  <block id="10caa5e50634911a226bf4aadc5a0c7a" category="inline-image-macro">WordPress概述屏幕</block>
  <block id="096a5432cb51a4b959599922c18c06c1" category="paragraph"><block ref="096a5432cb51a4b959599922c18c06c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6ef5c869d6fe64bd1b351a45360b963" category="list-text">在下一页的案例演示集群中、您必须选择要部署到的集群。选择或创建新的命名空间和应用程序实例名称、然后选择WordPress应用程序及其后备MariaDB数据库所需的存储类和永久性卷大小。在这两种情况下、我们都选择了ontap-nas-csi存储类。</block>
  <block id="355246a53a979cfb1041a2b1940f6879" category="inline-image-macro">WordPress配置</block>
  <block id="d888949dd50bbca6d60ecc23eaef49f9" category="paragraph"><block ref="d888949dd50bbca6d60ecc23eaef49f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d655c70f06a3434e67cbfc80248a9a" category="admonition">请勿选择启用公有 IP访问。这样会创建一个类型为NodePort的服务、此服务无法从内部部署的Anthos部署访问。</block>
  <block id="afab588b2fdc93623ccf8cb877caf4da" category="list-text">单击Deploy按钮后、您将看到一个页面、其中提供了应用程序详细信息。您可以刷新此页面或使用命令行界面登录到集群以检查部署状态。</block>
  <block id="31e41095bfaa14799239e8d9ba7ad438" category="inline-image-macro">应用程序详细信息</block>
  <block id="d0354e2068a16698befdae7925d598c8" category="paragraph"><block ref="d0354e2068a16698befdae7925d598c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="182bdd798d19f66a7142e53dc7ba7d03" category="list-text">在部署应用程序时、可以使用命令行界面在应用程序命名空间中运行命令以提取Pod信息：`kubectl get pods -n anthos-wp`来检查应用程序的状态。</block>
  <block id="4fdb8b8bf983b608be34dc4a03f63bae" category="inline-image-macro">Kubectl GET POD</block>
  <block id="5d15d1dcdf1862334a130d3d7fe69ccc" category="paragraph"><block ref="5d15d1dcdf1862334a130d3d7fe69ccc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e9914dac3fe74f2b341b37fde931ccc8" category="admonition">请注意、此屏幕截图显示一个部署程序POD处于错误状态。这是正常的。此Pod是Google Cloud Console使用的一个帮助程序Pod、用于部署在其他Pod开始初始化过程后自终止的应用程序。</block>
  <block id="9d8881c161170e208f09b8b2a142a66f" category="list-text">请稍后确认您的应用程序正在运行。</block>
  <block id="ce0590d3b5f26b188a077af82f7344a2" category="inline-image-macro">应用程序正在运行</block>
  <block id="011a851bc4637452cc423fc951144521" category="paragraph"><block ref="011a851bc4637452cc423fc951144521" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3acabe74bca98e10c24bed74bda730" category="section-title">公开应用程序</block>
  <block id="76ce15c259c30934261379d5c782fb7a" category="paragraph">部署应用程序后、您可以通过两种方法为其分配可访问全球的IP。</block>
  <block id="636274e5bcac1260da12a33d8dae0b1e" category="section-title">使用Google Cloud Console</block>
  <block id="affe13ca759d7abbd8dd52510dcccb9d" category="paragraph">您可以通过使用Google Cloud Console并在浏览器中编辑服务的YAML输出来设置可公开访问的IP来公开应用程序。要执行此操作、请执行以下步骤：</block>
  <block id="e14de37e4860e0a27178cce381f79223" category="list-text">在Google Cloud Console中、单击左侧菜单中的服务和入口。</block>
  <block id="7888520f99ee2ce14da11b431d5ae318" category="inline-image-macro">服务和传入</block>
  <block id="a30c95bc1250f0f260b3859484a79e52" category="paragraph"><block ref="a30c95bc1250f0f260b3859484a79e52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6187f833f4cb9c4f7b8ee4db49498f1b" category="list-text">单击`WordPress-WordPress-Svc`服务。此时将打开服务详细信息屏幕。单击顶部的编辑按钮。</block>
  <block id="d203ca99d4a0afdab1bcfe540a547944" category="inline-image-macro">编辑服务详细信息</block>
  <block id="572acf06c07873db504c906b27cd9089" category="paragraph"><block ref="572acf06c07873db504c906b27cd9089" category="inline-image-macro-rx" type="image"></block></block>
  <block id="668b0ecfd7e72dc665e312c2993930b3" category="list-text">此时将打开编辑服务详细信息页面、其中包含此服务的YAML信息。向下滚动、直到看到`sPec：`部分和`type：`值、该值设置为`ClusterIP`。将此值更改为`loadbalancer`、然后单击保存按钮。</block>
  <block id="d6b6ff61b6af359d37d3635e95073c9d" category="inline-image-macro">键入ClusterIP值</block>
  <block id="198f2e2e4e51b005096e30bd1dc74de8" category="paragraph"><block ref="198f2e2e4e51b005096e30bd1dc74de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5f9f0194a478fbc7f5f93f46c2953de" category="inline-image-macro">键入loadbalancer值</block>
  <block id="51301646eb8394e4ac0765ad84f0d777" category="paragraph"><block ref="51301646eb8394e4ac0765ad84f0d777" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7331da14461f4638eebbff81857db51" category="list-text">返回到服务详细信息页面后、`Type：` NOW会列出`loadbalancer`、而`External Endpoints：`字段会列出从MetalLB池分配的IP地址以及可访问应用程序的端口。</block>
  <block id="3ec7f6e26f5dfb369960a71540f97a1f" category="inline-image-macro">服务详细信息最终确定</block>
  <block id="e5b2b641e4db64d79ddda6476267c442" category="paragraph"><block ref="e5b2b641e4db64d79ddda6476267c442" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74e17d078471c59b2bf53ed27db0fb1f" category="section-title">使用Kubectl修补服务</block>
  <block id="f022ee3e39dabcf83208cc99a6eb4a8b" category="paragraph">您可以使用CLI和`kubectl patch`命令来修改部署并设置可公开访问的IP来公开应用程序。为此，请完成以下步骤：</block>
  <block id="7d217d270c695202071f85ac46866514" category="list-text">使用`kubectl get services -n anthos-wp`命令列出与命名空间中Pod关联的服务。</block>
  <block id="fe7c7c8f844859020a7db7a331ade810" category="inline-image-macro">列出服务</block>
  <block id="45c0563dbcc7191f2f4360b2e8740e4a" category="paragraph"><block ref="45c0563dbcc7191f2f4360b2e8740e4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6969be1fd50af4592e0d142a1d8d70cd" category="list-text">使用以下命令将服务类型从`ClusterIP`修改为类型`LoadBaler`：</block>
  <block id="ee64374fc07de409e3af533d716265a7" category="paragraph">系统会自动从MetalLB池为这种新服务类型分配一个可用的IP地址。</block>
  <block id="c2a179dcfc744c6d0e1f8e669f780a31" category="inline-image-macro">修补服务到类型负载平衡器</block>
  <block id="ee6e2870bddeced39fa0bbc481e1cd21" category="paragraph"><block ref="ee6e2870bddeced39fa0bbc481e1cd21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="515ddbc3d2b92a28024949cdc11effe0" category="section-title">访问公开的外部IP上的应用程序</block>
  <block id="9f32f710fb943684fe7ac71944e06000" category="paragraph">现在、您已使用可公开访问的IP地址公开应用程序、您可以使用浏览器访问WordPress实例。</block>
  <block id="3922853243ef47d8d33c4ed74259c64a" category="inline-image-macro">浏览器中的WordPress</block>
  <block id="d989de00c947c6c543a0711c796da0b3" category="paragraph"><block ref="d989de00c947c6c543a0711c796da0b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21e8ffc6f822b183559b39b43061c1d2" category="summary">NetApp提供了许多产品、可帮助客户在Anthos等基于容器的环境中编排和管理持久数据。</block>
  <block id="7a8b9d74335d44fbaaf7f5d5aebf0cfd" category="paragraph">Google Cloud会定期通过其Anthos Ready存储合作伙伴计划请求对合作伙伴存储与新版本Anthos的集成进行更新验证。您可以找到当前已验证的存储解决方案、CSI驱动程序、可用功能以及支持的Anthos版本的列表<block ref="0ccc93736ba595a77f031ff105798de0" category="inline-link-rx"></block>。</block>
  <block id="d9c9cc94777c7797db966b663b32ce4d" category="paragraph">下表列出了NetApp和NetApp合作伙伴工程师在Anthos Ready存储合作伙伴计划中验证NetApp Astra Trident CSI驱动程序和功能集所测试的Anthos版本：</block>
  <block id="84aafd4e962655f32c5bdea750278fba" category="paragraph">NetApp提供了许多产品、可帮助您在基于容器的环境(如Anthos)中编排和管理永久性数据。</block>
  <block id="55713395841bbe573d35c776279d08cc" category="paragraph">NetApp Astra Trident是一款开源的完全受支持存储编排程序、适用于容器和Kubernetes分发软件、包括Anthos。有关详细信息，请访问 Astra Trident 网站<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>。</block>
  <block id="305e92355c5c05eac28d2fbad20eaa5c" category="list-text">* Anthos管理工作站。*一种部署主机、可从中运行`gkectl`和`kubectl`命令来部署Anthos部署并与之进行交互。</block>
  <block id="3cd74a54f5924b896bf9cb97397e8b35" category="list-text">*管理集群。*在VMware上设置Anthos集群时部署的初始集群。此集群可管理所有从属用户集群操作、包括部署、扩展和升级。</block>
  <block id="11b774f9c0d1531100a341b6da7d98fa" category="list-text">*用户集群。*每个用户集群都部署有自己的负载平衡器实例或分区、使其可以充当单个用户或组的独立Kubernetes集群、从而帮助实现完全多租户。</block>
  <block id="b4dfd3f706cb0162d524cf7c36093e7c" category="paragraph">下图显示了VMware上部署Anthos-clusters的问题描述。</block>
  <block id="f34111b15d3f3387462dd512dde1392f" category="list-text">*节省成本。*最终用户可以将多个用户集群部署到同一物理环境中、并将自己的物理资源用于应用程序部署、而不是在Google Cloud环境或大型裸机集群中配置资源、从而显著节省成本。</block>
  <block id="f89d1a459fed3d81a3b4a7360d0e85fc" category="list-text">通过* VMware vSphere vMotion* VMware vCenter、您可以根据请求在集群中的节点之间热迁移虚拟机、而不会造成中断。</block>
  <block id="e7a811d106a4076d6c6992a7b97734a0" category="paragraph">下表列出了NetApp和我们的合作伙伴用于验证解决方案 的vSphere版本。</block>
  <block id="0dc619d5fd0af9a7a1c5ddea5b3e05a4" category="paragraph">虽然可以在少于三个节点的vSphere集群中安装Anthos以进行演示或评估、但不建议用于生产工作负载。虽然两个节点支持基本HA和容错功能、但必须修改Anthos集群配置以禁用默认主机关联性、Google Cloud不支持此部署方法。</block>
  <block id="67243afe565a819d977d538c55049340" category="admonition">Anthos在每个`cluster.yaml`文件中都有一个配置选项、用于自动创建节点关联性规则、该规则可根据环境中的ESXi主机数量启用或禁用。</block>
  <block id="2f0792348007b672e999da06f311bd6f" category="summary">Astra Trident是一款完全受支持的开源存储编排程序、适用于容器和Kubernetes分发版、包括Anthos。</block>
  <block id="e16f8b7c3b79f3d80b3d5b5862b4481a" category="paragraph">管理员可以根据项目需求和存储系统型号配置多个存储后端、以实现高级存储功能、包括压缩、特定磁盘类型和QoS级别、从而保证一定水平的性能。定义后，开发人员可以在其项目中使用这些后端创建永久性卷声明（ PVC ），并按需将永久性存储附加到容器。</block>
  <block id="1efa4d2f8950cdd5154a6c130953c9f2" category="paragraph">在22.04版本中、我们提供了一个Helm图表、用于简化Trident操作员的安装。</block>
  <block id="1b8283857d1e7c1a4e80a12b3ba66ad9" category="paragraph"><block ref="1b8283857d1e7c1a4e80a12b3ba66ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2540200d51d81caebf749b3eb92aa66f" category="paragraph"><block ref="2540200d51d81caebf749b3eb92aa66f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="695cc7df9129054b4e4bd425d0094832" category="paragraph"><block ref="695cc7df9129054b4e4bd425d0094832" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79cdad7595deba66ecab4005ebe50206" category="paragraph"><block ref="79cdad7595deba66ecab4005ebe50206" category="inline-image-macro-rx" type="image"></block></block>
  <block id="235db056b84e051c45e51c19dc088d7a" category="paragraph"><block ref="235db056b84e051c45e51c19dc088d7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54132be89475e52a0550d90f4b162e74" category="paragraph"><block ref="54132be89475e52a0550d90f4b162e74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7f329dfec2100f6b17e76aecd655cac" category="paragraph"><block ref="a7f329dfec2100f6b17e76aecd655cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ad0944f93fe082ef02313cd33db47" category="paragraph"><block ref="ec1ad0944f93fe082ef02313cd33db47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28eb5fe5f641c3ffa32f2488fa166a36" category="paragraph">本参考文档将对部署在多个数据中心环境中的Anthos与NetApp解决方案 进行部署验证。此外、还详细介绍了如何使用Astra Trident存储编排程序管理永久性存储、从而与NetApp存储系统实现存储集成。最后、我们将探讨并记录许多解决方案 验证和实际使用情形。</block>
  <block id="0d3aabd1c9ad032e07b543d0aff99cb1" category="list-text">使用在裸机上提供的`bmctl`工具或在VMware vSphere上使用`gkectl`工具部署的Anthos环境、易于部署和管理。</block>
  <block id="ee1ef628edbfb6bb102163064fbd3d8e" category="paragraph">采用NetApp解决方案 的Anthos认识到这些挑战、并提供了一个解决方案 、通过在客户选择的数据中心环境中在内部实施完全自动化的Anthos部署、帮助解决每个问题。</block>
  <block id="ffedc012b4decbb02d6a5ca1791f3d60" category="admonition">如果使用`kubeadmin` user登录到专用注册表、请使用令牌而不是密码。</block>
  <block id="b0215348c4b61c9ef3af7e95c45db79b" category="doc">安装seesaw负载平衡器</block>
  <block id="2498fd03c323b46a1d209aa07977fa55" category="paragraph">seesaw是VMware环境中安装在Anthos Clusters 1.6到1.10版的默认受管网络负载平衡器。</block>
  <block id="1de0bfc08643a28f36a8fcd5662e17f0" category="section-title">安装seesaw负载平衡器</block>
  <block id="7e83a37698e612c5150b6c3a383cf59b" category="paragraph">seesaw负载平衡器与VMware上的Anthos集群完全集成、并在管理和用户集群设置中自动执行部署。`cluster.YAML`配置文件中存在文本块、必须进行修改才能提供负载平衡器信息、然后在部署集群之前、还需要执行一个额外步骤、使用内置的`gkectl`工具部署负载平衡器。</block>
  <block id="3d4d180e7186ad7195269636446a1c4c" category="admonition">可以在HA或非HA模式下部署seesaw负载平衡器。为了进行此验证、seesaw负载平衡器部署在非HA模式下、这是默认设置。出于生产目的、NetApp建议在HA配置中部署seesaw、以实现容错和可靠性。</block>
  <block id="613f73d2545e2e4434e09e47400d96a6" category="paragraph">每个配置文件中分别为管理集群和您选择部署的每个用户集群提供了一个部分、用于配置负载平衡器、以便由Anthos on-Prem管理。</block>
  <block id="71f92aabf82706f3d2a00af1b3a34f95" category="paragraph">seesaw负载平衡器还具有一个单独的静态`seesaw-block.yaml`文件、您必须为每个集群部署提供该文件。此文件必须位于与`cluster.yaml`部署文件相关的同一目录中、或者必须在上述部分中指定完整路径。</block>
  <block id="cda0b5b1eab2f931076d0edc39a6920a" category="paragraph">`admin-seesaw-block.yaml`文件的示例类似于以下脚本：</block>
  <block id="967a8ba34c500bbb53dbf69cee7587d9" category="doc">将Red Hat OpenShift集群注册到Astra控制中心</block>
  <block id="d2b3fd1f3d8ac38be89cec192a9d1558" category="list-text">第一步是将 OpenShift 集群添加到 Astra 控制中心并对其进行管理。转至集群、单击添加集群、上传OpenShift集群的`kubeconfig`文件、然后单击选择存储。</block>
  <block id="0fafca9f5d93d0accfd1e6ed440a772b" category="list-text">要使用 Astra 控制中心在 OpenShift 集群之间进行备份和还原，您必须配置支持 S3 协议的对象存储分段。目前支持的选项包括 ONTAP S3 ， StorageGRID 和 AWS S3 。为此，我们将配置一个 AWS S3 存储分段。转到 " 分段 " ，单击 " 添加分段 " ，然后选择 " 通用 S3" 。输入有关S3存储分段及其访问凭据的详细信息、单击复选框将此存储分段设置为云的默认存储分段、然后单击添加。</block>
  <block id="fc31dc82d7754f65126c60eab5625947" category="inline-link-macro">使用Google Cloud Console安装应用程序</block>
  <block id="627662d598c35dc9438ec1747d7766dc" category="paragraph"><block ref="627662d598c35dc9438ec1747d7766dc" category="inline-link-macro-rx"></block></block>
  <block id="ee1514b17e642c9cd1384a20cec220e3" category="summary">从此页面链接到的视频演示了本文档中介绍的一些功能。</block>
  <block id="18d4f7e36efb77494db296ea83bc4753" category="paragraph">有关NetApp部署的裸机集群上的Anthos的详细信息、请访问 <block ref="eb911f2bc48f3132c014132a2870169f" category="inline-link-macro-rx"></block>。</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="sidebar">部署过程</block>
  <block id="71ab9d8f34c9ab92ef83627b823e9825" category="sidebar">数据库管理</block>
  <block id="c3b88d5ff29715f5f8dd3c907b3f1bc3" category="sidebar">数据库迁移</block>
  <block id="1781760e35ea460b2019eb0440baf384" category="paragraph"><block ref="1781760e35ea460b2019eb0440baf384" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6909280d84c97f4c2d6301b2d570e37a" category="paragraph"><block ref="6909280d84c97f4c2d6301b2d570e37a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf19992eca1061913e185b60f91a8344" category="list-text"><block ref="bf19992eca1061913e185b60f91a8344" category="inline-link-macro-rx"></block></block>
  <block id="297afb95cdd3600afb3f67c77b24215f" category="list-text"><block ref="297afb95cdd3600afb3f67c77b24215f" category="inline-link-macro-rx"></block></block>
  <block id="0395f03c04f82443f0fc31b418d2ded6" category="list-text"><block ref="0395f03c04f82443f0fc31b418d2ded6" category="inline-link-macro-rx"></block></block>
  <block id="ea3f2894c4df21a157c45dcbcf989bda" category="paragraph">以下页面介绍了有关已在采用NetApp解决方案 的Anthos中针对应用程序和永久性存储管理进行验证的NetApp产品的追加信息。</block>
  <block id="f6762efea56447c717fea204b2676851" category="list-text">单击下一步继续执行每个步骤，并接受显示的每个屏幕的默认值，直到显示存储选择屏幕为止。选择要将虚拟机部署到的VM_Datastore、然后单击下一步。</block>
  <block id="da0289d58f35e36d18325d6e8038b226" category="admonition">此文件中定义了一个名为 `FSType` 的可选字段。在iSCSI后端、可以将此值设置为特定的Linux文件系统类型(XFS、ext4等)、也可以将其删除、以允许工作节点操作系统确定要使用的文件系统。</block>
  <block id="ca2835359be5e4e2e79ed5b6fd777515" category="paragraph"><block ref="ca2835359be5e4e2e79ed5b6fd777515" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f154001e329eb4cb13b7745ba16dac" category="doc">支持采用VMware的NetApp混合多云配置</block>
  <block id="9daaf09aeccc99c61fe453295253eae0" category="doc">总结和结论：为什么要将NetApp混合多云与VMware结合使用</block>
  <block id="0c17a5e22f572303947d9e14cd98db39" category="paragraph">NetApp Cloud Volumes 以及适用于主要超大规模企业的 VMware 解决方案为希望利用混合云的企业提供了巨大的潜力。本节其余部分将介绍有关集成NetApp Cloud Volumes以实现真正的混合多云功能的使用情形。</block>
  <block id="17c56e542773e2aafc2645d0e9f0d8ec" category="summary">采用VMware的NetApp混合多云解决方案是一组战略和技术功能、用于展示NetApp存储在主要公有 云超大规模企业中的功能。</block>
  <block id="27dafc6e4e2e3563b0434812fa3fee7c" category="section-title">GCP地区可用性</block>
  <block id="68c6fcf9f9393805f0529c36994a9266" category="paragraph">当GCP进入公有 可用性状态时、将发布GCP区域可用性。</block>
  <block id="b632c27ff82cfe142baffd346253a21b" category="doc">采用VMware的NetApp混合多云的用例</block>
  <block id="0257f1ddf73d49021a7feba150b7ea8b" category="paragraph">在这种情况下，最简单的问题解答是每个超大规模提供商中的 VMware 产品。与 NetApp ® Cloud Volumes 一样， VMware 提供了一种将内部 VMware 环境迁移或扩展到任何云的方法，使您可以在云中本机运行工作负载的同时保留现有内部资产，技能和工具。这样可以降低风险，因为不会发生服务中断或需要更改 IP ，并使 IT 团队能够使用现有技能和工具在内部执行操作。这样可以加快云迁移速度、并更平稳地过渡到混合多云架构。</block>
  <block id="33a1a24f2edf4ad9358baef7fb3c9cdf" category="doc">使用ANF和Jetstream进行灾难恢复</block>
  <block id="14f4fb472fe43e084476c5d8329b15f8" category="paragraph">将灾难恢复到云是一种弹性且经济高效的方式、可保护工作负载免受站点中断和数据损坏事件(例如勒索软件)的影响。使用VMware VAIO框架、可以将内部VMware工作负载复制到Azure Blob存储并进行恢复、从而最大限度地减少或接近无数据丢失、并实现近乎零的RTO。</block>
  <block id="b614fc13a076bceeca03cda9c4b1fdce" category="paragraph">可以使用Jetstream DR无缝恢复从内部复制到AVS、特别是复制到Azure NetApp Files 的工作负载。它通过在灾难恢复站点使用最少的资源和经济高效的云存储来实现经济高效的灾难恢复。Jetstream DR可通过Azure Blob Storage自动恢复到ANF数据存储库。Jetstream灾难恢复可根据网络映射将独立的VM或相关VM组恢复到恢复站点基础架构中、并提供时间点恢复以实现勒索软件保护。</block>
  <block id="29d141d1797b070195b4a3a5af842d35" category="paragraph">本文档介绍了Jetstream灾难恢复的操作原理及其主要组件。</block>
  <block id="0b3b3c3ee7cf95d87f597441efd5f743" category="example-title">解决方案 部署概述</block>
  <block id="1dff5e9fa7f5c212df3e98d343d6a771" category="list-text">在内部数据中心安装Jetstream DR软件。</block>
  <block id="7b87ce74b3d0f7e81fef7a7994f9c8ed" category="list-text">从Azure Marketplace (ZIP)下载Jetstream DR软件包、并在指定集群中部署Jetstream DR MSA (OVA)。</block>
  <block id="56c27e9a114a51f4863d0fef4cab3eba" category="list-text">使用I/O筛选器软件包配置集群(安装Jetstream VIB)。</block>
  <block id="43de8924da88a34109307d6aac84811a" category="list-text">在与DR AVS集群相同的区域中配置Azure Blob (Azure存储帐户)。</block>
  <block id="2cee29b70a6ea4765a6365e4d71775c7" category="list-text">部署DRVA设备并分配复制日志卷(来自现有数据存储库或共享iSCSI存储的VMDK)。</block>
  <block id="9c6ca12d0f999d69d715e02482665e5d" category="list-text">创建受保护域(相关VM的组)并分配DRBA和Azure Blob Storage/ANF。</block>
  <block id="04fd46fc4d0422c8562609b47b636797" category="list-text">启动保护。</block>
  <block id="8391f9ad7383911e1b8e67d8dfd23ffb" category="list-text">在Azure VMware解决方案 私有云中安装Jetstream DR软件。</block>
  <block id="81aaea44e289ce199fea205f7d0b8cd9" category="list-text">使用Run命令安装和配置Jetstream DR。</block>
  <block id="ef261b549f401ed8d66b72f8310d7376" category="list-text">添加相同的Azure Blob容器并使用扫描域选项发现域。</block>
  <block id="3c22f96e96fb514aec06cc03a6d35958" category="list-text">部署所需的DRVA设备。</block>
  <block id="a8930e0df42395d789466e0695d11ce7" category="list-text">使用可用的vSAN或ANF数据存储库创建复制日志卷。</block>
  <block id="087316b53a71d576c6dfeda2385ef108" category="list-text">导入受保护域并配置RocVA (恢复VA)、以便使用ANF数据存储库放置VM。</block>
  <block id="f47df812f6139d9d12dc179df9e7da57" category="list-text">选择相应的故障转移选项、并为接近零的RTO域或VM启动持续重新融合。</block>
  <block id="eb50fc931b0aff72e9034088a04a260b" category="list-text">在发生灾难事件期间、触发故障转移到指定AVS灾难恢复站点中的Azure NetApp Files 数据存储库。</block>
  <block id="21e74b3c28d006317f38a2bc8eb1da3b" category="inline-link">Azure Marketplace</block>
  <block id="f314a6aa5faf9dfffba2cdac4d4dd420" category="list-text">在受保护站点恢复后调用故障恢复到受保护站点。在启动之前、请确保满足此中所述的前提条件<block ref="600591f3feccd7454d660dd4d2972306" category="inline-link-rx"></block> 此外、还可以运行Jetstream Software提供的带宽测试工具(BWT)来评估Azure Blob存储在与Jetstream DR软件结合使用时的潜在性能及其复制带宽。在具备包括连接在内的前提条件后、从设置并订阅Jetstream DR for AVS<block ref="e842a0f9c9000f3898fd5cb9408b8b3e" category="inline-link-rx"></block>。下载软件包后、继续执行上述安装过程。</block>
  <block id="01543f177a0cc07917f4dc3510b8649e" category="paragraph">在为大量VM (例如100多个)规划和启动保护时、请使用Jetstream DR Automation Toolkit中的容量规划工具(CPT)。提供要保护的VM列表及其RTO和恢复组首选项、然后运行CPT。</block>
  <block id="ddfb9ed8decef8b3db76f88d682c7f1e" category="paragraph">CPT可执行以下功能：</block>
  <block id="ab5991781a05bc72668a8bf941d7a4a5" category="list-text">根据虚拟机的RTO将其组合到保护域中。</block>
  <block id="b3229123cf8dd56b28f1a8e13f79ddde" category="list-text">定义最佳的DRBA数及其资源。</block>
  <block id="2c3b2c6c87689b15c4cd3ea75cb40ef8" category="list-text">估计所需的复制带宽。</block>
  <block id="88d06f884976bb7a1ce66e51624c0196" category="list-text">确定复制日志卷的特征(容量、带宽等)。</block>
  <block id="60a85cb526817dd0f1172dcdacc94700" category="list-text">估计所需的对象存储容量等。</block>
  <block id="ea56b8a01683ebc544ddabe2f0fcf571" category="admonition">规定的域数量和内容取决于各种VM特征、例如平均IOPS、总容量、优先级(用于定义故障转移顺序)、RTO等。</block>
  <block id="fc321ed0fcff278e628765c7a327d1c0" category="section-title">在内部数据中心中安装Jetstream DR</block>
  <block id="87674fd676f223da1c84cd30ba47e2d2" category="paragraph">Jetstream灾难恢复软件由三个主要组件组成：Jetstream灾难恢复管理服务器虚拟设备(Virtual Appliance、MSA)、灾难恢复虚拟设备(DR Virtual Appliance、DRVA)和主机组件(I/O筛选器软件包)。MSA用于在计算集群上安装和配置主机组件、然后管理Jetstream DR软件。以下列表提供了安装过程的高级问题描述 ：</block>
  <block id="44a5c8a42b561b0a83b98c7dffe66dc4" category="list-text">检查前提条件。</block>
  <block id="6035c664a9aaf8fa1c40e58c8beaab92" category="list-text">运行容量规划工具以获取资源和配置建议(可选、但建议用于概念验证试用)。</block>
  <block id="ccc2ab66d8941e0dddf26ed50f55ba4c" category="list-text">将Jetstream DR MSA部署到指定集群中的vSphere主机。</block>
  <block id="efdd725636035b733a89826db0da74f4" category="list-text">在浏览器中使用其DNS名称启动MSA。</block>
  <block id="39602c8241f165da483e3678f5d62871" category="list-text">向MSA注册vCenter Server。要执行安装、请完成以下详细步骤：</block>
  <block id="f6a1019b86d486190fed5e4a0c122f59" category="list-text">部署Jetstream DR MSA并注册vCenter Server后、请使用vSphere Web Client访问Jetstream DR插件。可通过导航到"数据中心"&gt;"配置"&gt;"Jetstream DR"来完成此操作。</block>
  <block id="623c8f2c05001c7eeecb0781c049f16b" category="paragraph"><block ref="623c8f2c05001c7eeecb0781c049f16b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5b9a2e255ce372cd80d886148efdd00" category="list-text">从Jetstream灾难恢复界面中、选择相应的集群。</block>
  <block id="699c846ab66a56017e37da99f6ea7320" category="paragraph"><block ref="699c846ab66a56017e37da99f6ea7320" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d18d2901e95370132a2545c2f511db3" category="list-text">使用I/O筛选器软件包配置集群。</block>
  <block id="34896ae2be725a2f3d42bd7b4b7888fd" category="paragraph"><block ref="34896ae2be725a2f3d42bd7b4b7888fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0598abb730b378c25cbbc28507342260" category="list-text">添加位于恢复站点的Azure Blob Storage。</block>
  <block id="76ef667a7a95f046d391e54cea1b9142" category="list-text">从设备选项卡部署灾难恢复虚拟设备(DR Virtual Appliance、DRVA)。</block>
  <block id="ba445d98067e8161fa165b8f25ad294d" category="admonition">DvA可以由CPT自动创建、但对于POC试用、我们建议手动配置和运行灾难恢复周期(启动保护&gt;故障转移&gt;故障恢复)。</block>
  <block id="60de8eac7ca6ad5f7321abf5b462b65d" category="paragraph">Jetstream DRVA是一个虚拟设备、可促进数据复制过程中的关键功能。受保护集群必须至少包含一个DRVA、通常每个主机配置一个DRVA。每个DRVA都可以管理多个受保护域。</block>
  <block id="f55f11c27893cdacff776d302a9b9d07" category="paragraph"><block ref="f55f11c27893cdacff776d302a9b9d07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ece649567fdf82717852e0f8662d070" category="paragraph">在此示例中、为80个虚拟机创建了四个DRVA。</block>
  <block id="cf5c65945851f67013f23b2d83d4a346" category="list-text">使用VMDK从可用的数据存储库或独立的共享iSCSI存储池为每个DRVA创建复制日志卷。</block>
  <block id="9ad06750519e0664bc1ec852cc5e07b6" category="list-text">在受保护域选项卡中、使用Azure Blob Storage站点、DRVA实例和复制日志的相关信息创建所需数量的受保护域。受保护域定义集群中一个或一组一起受保护的特定虚拟机、并为故障转移/故障恢复操作分配优先级顺序。</block>
  <block id="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="paragraph"><block ref="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e68391e0d2ed07243f438a1d725a243a" category="list-text">选择要保护的VM并启动受保护域的VM保护。此时将开始向指定的Blob Store复制数据。</block>
  <block id="24e5f5b0186cca0606b176380e3ee45c" category="admonition">验证受保护域中的所有VM是否使用相同的保护模式。</block>
  <block id="9870cb575efa482fab7fa9aa1fdf16ac" category="admonition">回写(VMDK)模式可以提供更高的性能。</block>
  <block id="895d59858a04439859a33d3288706702" category="paragraph"><block ref="895d59858a04439859a33d3288706702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6ea2b1c670425ac09f1aadbc26e266" category="paragraph">验证复制日志卷是否放置在高性能存储上。</block>
  <block id="3237de27ecac8fd3a072d337514991eb" category="admonition">可以对故障转移运行手册进行配置、以便对VM (称为恢复组)进行分组、设置启动顺序以及修改CPU/内存设置和IP配置。</block>
  <block id="840c65296e1af99a67123dd9459e5548" category="section-title">使用Run命令在Azure VMware解决方案 私有云中安装Jetstream DR for AVS</block>
  <block id="d2441f955b3d04e99be7845bb7af68a6" category="paragraph">恢复站点(AVS)的一个最佳实践是、提前创建一个三节点的试用集群。这样可以对恢复站点基础架构进行预配置、其中包括以下各项：</block>
  <block id="dab895f226673c73578b4c45dead73c0" category="list-text">目标网络分段、防火墙、DHCP和DNS等服务等。</block>
  <block id="188d8743a82411348e186c7118e92c9a" category="list-text">安装适用于AVS的Jetstream DR</block>
  <block id="fd3bf57ff38b27ccbf66886b71a34f76" category="list-text">将ANF卷配置为数据存储库、并且moreJetStream DR支持任务关键型域的RTO模式接近零。对于这些域、应预安装目标存储。在这种情况下、建议使用ANF存储类型。</block>
  <block id="89aa12cc0cd4846ef86fbe8dfd78d8bc" category="admonition">应在AVS集群上配置网络配置、包括创建网段、以满足内部部署要求。</block>
  <block id="d50efdb8ff06cd2518521c1d4f68a67a" category="paragraph">根据SLA和RTO要求、可以使用持续故障转移或常规(标准)故障转移模式。对于接近零的RTO、应在恢复站点启动持续再融合。</block>
  <block id="7c1dc76f383d9b6253a273d35f636909" category="paragraph">要在Azure VMware解决方案 私有云上安装Jetstream DR for AVS、请完成以下步骤：</block>
  <block id="7f0bec83fc0010707471d9d3b84fd45b" category="list-text">从Azure门户中、转到Azure VMware解决方案 、选择私有云、然后选择运行命令&gt;软件包&gt; JSDR.Configuration。</block>
  <block id="6e37d4d4f3c60de2fb2e2e218753f9ea" category="admonition">Azure VMware解决方案 中的默认CloudAdmin用户没有足够的权限来安装适用于AVS的Jetstream DR。Azure VMware解决方案 通过调用适用于Jetstream DR的Azure VMware解决方案 Run命令、可以简化并自动安装Jetstream DR。</block>
  <block id="832830e8d1c5e28f4e206c65a067fbfc" category="paragraph">以下屏幕截图显示了使用基于DHCP的IP地址进行安装的情况。</block>
  <block id="1ca67a15b29b11c686a17480c2ecde9c" category="paragraph"><block ref="1ca67a15b29b11c686a17480c2ecde9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23fac09aaa7dcea6eb534251f50feae2" category="list-text">完成适用于AVS的Jetstream DR安装后、刷新浏览器。要访问Jetstream DR UI、请转到SDDC Datacenter &gt;配置&gt; Jetstream DR。</block>
  <block id="58517d8d2fa977f39ca2b76c09c43dc4" category="paragraph"><block ref="58517d8d2fa977f39ca2b76c09c43dc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bf7f298e2ed24c67b98b8d5c4e6dbe" category="list-text">从Jetstream DR界面中、添加用于将内部集群作为存储站点进行保护的Azure Blob Storage帐户、然后运行扫描域选项。</block>
  <block id="1e976589dd0f1f098c13f4564f91813c" category="paragraph"><block ref="1e976589dd0f1f098c13f4564f91813c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4e7f9056aa9f52fd1bff1e2837a4e84" category="list-text">导入受保护域后、部署DRVA设备。在此示例中、可以使用Jetstream DR UI从恢复站点手动启动持续再水化。</block>
  <block id="7aa502331a6314a8d66df611c4538f75" category="admonition">也可以使用CPT创建的计划自动执行这些步骤。</block>
  <block id="bf4fdf975fae154bdca78e36bd7edbe3" category="list-text">导入受保护域并配置恢复VA以使用ANF数据存储库放置VM。</block>
  <block id="0a4fc536683686b518331dd2531934b5" category="paragraph"><block ref="0a4fc536683686b518331dd2531934b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="827098a514e7d7fc1579120ec370bfd9" category="admonition">确保选定网段上已启用DHCP、并且有足够的可用IP。在恢复域时、系统会临时使用动态IP。每个正在恢复的VM (包括持续重新融合)都需要一个单独的动态IP。恢复完成后、此IP将被释放并可重复使用。</block>
  <block id="10e011fef535dced7a4095544de7266d" category="list-text">选择相应的故障转移选项(持续故障转移或故障转移)。在此示例中、选择了持续再融合(持续故障转移)。</block>
  <block id="adac1a1b7a65bae37b6bd9cbd66b248a" category="paragraph"><block ref="adac1a1b7a65bae37b6bd9cbd66b248a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6a68077ca82bffe5f08d96bdcd36e18" category="section-title">正在执行故障转移/故障恢复</block>
  <block id="61a6473493a7f05f03d606cdfeb234d6" category="list-text">在内部环境的受保护集群发生灾难(部分或完全故障)后、触发故障转移。</block>
  <block id="3a09da9a187f9208fcd685b78b772764" category="admonition">CPT可用于执行故障转移计划、以便将虚拟机从Azure Blob Storage恢复到AVS集群恢复站点。</block>
  <block id="f66e570f82bdb271d0adb30435ad5b2b" category="admonition">在AVS中启动受保护的VM后进行故障转移(针对持续或标准再融合)、保护将自动恢复、Jetstream DR将继续将其数据复制到Azure Blob Storage中的相应/原始容器中。</block>
  <block id="d27309d11731255db072c47f9675d22f" category="paragraph"><block ref="d27309d11731255db072c47f9675d22f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4a8f8fdcb45687697d39da1e99dc36" category="paragraph"><block ref="ef4a8f8fdcb45687697d39da1e99dc36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf84d29276236d6a8b8e75f1a2c8f115" category="paragraph">任务栏显示故障转移活动的进度。</block>
  <block id="8430656d9f62a51ed63ade1e47ad34f7" category="list-text">任务完成后、访问已恢复的VM、业务将继续正常进行。</block>
  <block id="f89c6dfb9ae23126d1e04570e23dcda9" category="paragraph"><block ref="f89c6dfb9ae23126d1e04570e23dcda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c8214eaedd2bb37ba1d1b018bf4aa63" category="paragraph">主站点启动并重新运行后、可以执行故障恢复。VM保护将恢复、应检查数据一致性。</block>
  <block id="2743b11e431e1c7f8504d917d4ffc4d6" category="list-text">还原内部环境。根据灾难意外事件的类型、可能需要还原和/或验证受保护集群的配置。如有必要、可能需要重新安装Jetstream DR软件。</block>
  <block id="232732afcd0f951efbcfaea123f0a632" category="admonition">注意：可使用Automation Toolkit中提供的`recovery_utility_prepare_failback`脚本帮助清理原始受保护站点中任何废弃的VM、域信息等。</block>
  <block id="6d52b59b59572c39053e3858b37fcc57" category="list-text">访问已还原的内部环境、转到Jetstream DR UI、然后选择相应的受保护域。受保护站点准备好进行故障恢复后、在UI中选择故障恢复选项。</block>
  <block id="7350f3b9fc85111b45034212957d9d98" category="paragraph"><block ref="7350f3b9fc85111b45034212957d9d98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82bc01d2feed0849423b6b5676888f97" category="admonition">CPT生成的故障恢复计划还可用于启动VM及其数据从对象存储返回到原始VMware环境的操作。</block>
  <block id="36e8c86c253ad3dad15eaab2f5de961c" category="admonition">指定在恢复站点暂停VM并在受保护站点重新启动后的最大延迟。这包括在停止故障转移VM后完成复制、清理恢复站点的时间以及在受保护站点中重新创建VM的时间。NetApp建议值为10分钟。</block>
  <block id="c53daff4bd6065c0627bf739410f7e88" category="paragraph">完成故障恢复过程、然后确认虚拟机保护和数据一致性的恢复。</block>
  <block id="ddd33ab61759ca3d4dcfcd934ab83b04" category="section-title">Ransomware恢复</block>
  <block id="459d2a2d25c4ad6db53b9e0b367f3d4c" category="paragraph">从勒索软件中恢复可能是一项艰巨的任务。具体而言、IT组织很难确定安全的返回点、一旦确定、如何确保恢复的工作负载免受再次发生的攻击(来自休眠的恶意软件或通过容易受到攻击的应用程序)。</block>
  <block id="414dfaa4bcffbd76b7f5ed891cdf1535" category="paragraph">Jetstream DR for AVS与Azure NetApp Files 数据存储库可通过允许组织从可用时间点恢复来解决这些问题、以便在需要时将工作负载恢复到正常运行的隔离网络。通过恢复、应用程序可以相互运行并进行通信、同时不会使它们暴露在北-南流量中、从而为安全团队提供一个安全的地方来执行取证和其他必要的修复。</block>
  <block id="a20215628470de7f6faa691cc18c4971" category="paragraph"><block ref="a20215628470de7f6faa691cc18c4971" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f95900d5509fa4de2d1c7e9489f4dc6" category="summary">将灾难恢复到云是一种具有弹性且经济高效的方式、可保护工作负载免受站点中断和勒索软件等数据损坏事件的影响。借助NetApp SnapMirror、可以将使用来宾连接存储的内部VMware工作负载复制到在Azure中运行的NetApp Cloud Volumes ONTAP。</block>
  <block id="48b47eaa686f297ed741f5cb81de709d" category="paragraph">作者：NetApp公司Ravi BCB和Niyaz Mohamed</block>
  <block id="be93173f941fd10be0e9fddb606bd940" category="paragraph">将灾难恢复到云是一种具有弹性且经济高效的方式、可保护工作负载免受站点中断和勒索软件等数据损坏事件的影响。借助NetApp SnapMirror、可以将使用来宾连接存储的内部VMware工作负载复制到在Azure中运行的NetApp Cloud Volumes ONTAP。其中包括应用程序数据；但是、实际VM本身又如何。灾难恢复应涵盖所有相关组件、包括虚拟机、VMDK、应用程序数据等。为此、可以使用SnapMirror以及Jetstream无缝恢复从内部复制到Cloud Volumes ONTAP 的工作负载、同时对VM VMDK使用vSAN存储。</block>
  <block id="b25b60af8de6f7256f832e93e5651972" category="paragraph">本文档提供了使用NetApp SnapMirror、Jetstream和Azure VMware解决方案 (AVS)设置和执行灾难恢复的分步方法。</block>
  <block id="8f0e380cfb4a39395f72ab50e67ea50e" category="paragraph"><block ref="8f0e380cfb4a39395f72ab50e67ea50e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72916c3a8dffc193957f3809a8b4acbf" category="paragraph">本文档重点介绍应用程序数据的子系统内存储(也称为子系统连接)、我们假定内部环境正在使用SnapCenter 进行应用程序一致的备份。</block>
  <block id="d2e057fdab62f3ae766c18c66acc57fd" category="admonition">本文档将对任何第三方备份或恢复解决方案 进行适用场景。根据环境中使用的解决方案 、按照最佳实践创建符合组织SLA的备份策略。</block>
  <block id="380a8e9be36984cc009caa1b7aaadc5d" category="paragraph">要在内部环境与Azure虚拟网络之间建立连接、请使用Express route全局访问或具有VPN网关的虚拟WAN。应根据内部VLAN设计创建分段。</block>
  <block id="057412b2bc7b34ca7066f70b80b69510" category="admonition">将内部数据中心连接到Azure有多种选项、这使我们无法在本文档中概述特定的工作流。有关适当的内部到Azure连接方法、请参见Azure文档。</block>
  <block id="ecc1cadbbbb0ef1d84ddc861f4497661" category="section-title">部署DR解决方案</block>
  <block id="5497ec7c1fdee07126ed64bf9fed5d87" category="section-title">解决方案 部署概述</block>
  <block id="8eaa61639db3e085f8c7eb12151b3736" category="list-text">确保使用具有必要RPO要求的SnapCenter 备份应用程序数据。</block>
  <block id="a04938b02e6c8ce6c9dbb34eac7d6a0a" category="list-text">在相应的订阅和虚拟网络中使用Cloud Manager使用正确的实例大小配置Cloud Volumes ONTAP。</block>
  <block id="15a6eec061b4c7d026aa504c05f01405" category="list-text">为相关应用程序卷配置SnapMirror。</block>
  <block id="3d1e7fac653a4e240c35721f0e3902da" category="list-text">更新SnapCenter 中的备份策略、以便在计划作业完成后触发SnapMirror更新。</block>
  <block id="2a690d204d02bcc25768246a5c2082bb" category="list-text">在内部数据中心安装Jetstream灾难恢复软件、并启动虚拟机保护。</block>
  <block id="060b718b1c12d4bed763206429b5c467" category="list-text">在灾难事件期间、使用Cloud Manager中断SnapMirror关系、并触发虚拟机故障转移到指定AVS灾难恢复站点中的Azure NetApp Files 或vSAN数据存储库。</block>
  <block id="16193a2e612115bbf00cb18e7a9ec1aa" category="list-text">重新连接应用程序VM的iSCSI LUN和NFS挂载。</block>
  <block id="d274e9c5c862dd28666a25176c344293" category="list-text">在主站点恢复之后、通过反向重新同步SnapMirror来调用对受保护站点的故障恢复。</block>
  <block id="c99b24a6817b7fd3c4d8687fc4bb35df" category="section-title">部署详细信息</block>
  <block id="eb5301ce7e383557ea1c2ecc5d8df8a4" category="example-title">在Azure上配置CVO并将卷复制到CVO</block>
  <block id="97e7c9a7d06eac006a28bf05467fcc8b" category="inline-link">链接。</block>
  <block id="30200baf346b021de0310f8f8307fd8e" category="paragraph"><block ref="30200baf346b021de0310f8f8307fd8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b453212f1c9ff723da2989dbb439d57e" category="example-title">配置AVS主机和CVO数据访问</block>
  <block id="46fdc14ede3dd0a84faa31cf1cde9624" category="paragraph">部署SDDC时需要考虑的两个重要因素是Azure VMware解决方案 中SDDC集群的大小以及SDDC的持续运行时间。对于灾难恢复解决方案 、这两个主要注意事项有助于降低整体运营成本。SDDC可以小至三台主机、在整个规模的部署中一直到多主机集群。</block>
  <block id="938f299f0522c6e7bea183a8ea437225" category="paragraph">部署AVS集群的决定主要取决于RPO/RTO要求。借助Azure VMware解决方案 、可以及时配置SDDC、以便为测试或实际灾难事件做好准备。及时部署的SDDC可在您不应对灾难时节省ESXi主机成本。但是、在配置SDDC时、这种部署形式会影响RTO几小时。</block>
  <block id="595875340c961d4ff4461ee8fe8a3ce3" category="paragraph">最常见的部署选项是、SDDC以无中断的引导模式运行。此选项占用的空间很小、可容纳三台始终可用的主机、还可以通过为模拟活动和合规性检查提供运行基线来加快恢复操作的速度、从而避免生产站点和灾难恢复站点之间发生操作偏差的风险。当需要处理实际灾难恢复事件时、可以快速将引导灯集群扩展到所需的级别。</block>
  <block id="f63f01c08cfc3f386ad47993e097e207" category="paragraph">正确配置Cloud Volumes ONTAP 和AVS后、请使用VAIO机制并利用SnapMirror将应用程序卷副本复制到Cloud Volumes ONTAP 、开始配置Jetstream、以便自动将内部工作负载恢复到AVS (具有应用程序VMDK的VM和具有来宾存储的VM)。</block>
  <block id="9f9a4d5afd3892f2b17ecc3ed2ad2630" category="example-title">在内部数据中心中安装Jetstream DR</block>
  <block id="68027d729e644485691d1aa185f22dad" category="paragraph">Jetstream灾难恢复软件由三个主要组件组成：Jetstream灾难恢复管理服务器虚拟设备(Virtual Appliance、MSA)、灾难恢复虚拟设备(DR Virtual Appliance、DRVA)和主机组件(I/O筛选器软件包)。MSA用于在计算集群上安装和配置主机组件、然后管理Jetstream DR软件。安装过程如下：</block>
  <block id="2e5f490166b4cbb95848c72a3f3296cd" category="list-text">检查前提条件。</block>
  <block id="01eb617ea64b2e2237c95fa866dc6c99" category="list-text">运行容量规划工具以获取资源和配置建议。</block>
  <block id="91d290eafae733f57fe1874a21a706be" category="list-text">将Jetstream DR MSA部署到指定集群中的每个vSphere主机。</block>
  <block id="130231ab3f0401b0c0e0f66fadd45d5d" category="list-text">向MSA注册vCenter Server。</block>
  <block id="6f621d6c94ab64b27eea06de601902d1" category="list-text">部署Jetstream DR MSA并注册vCenter Server后、导航到vSphere Web Client中的Jetstream DR插件。可通过导航到"数据中心"&gt;"配置"&gt;"Jetstream DR"来完成此操作。</block>
  <block id="874efc870db36a204a974a32ac47c11e" category="paragraph"><block ref="874efc870db36a204a974a32ac47c11e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9aad471e9824a9ef2c43fae648b07613" category="list-text">在Jetstream DR界面中、完成以下任务：</block>
  <block id="7ab4f3b382b4ad9e82615cacd27d739c" category="paragraph"><block ref="7ab4f3b382b4ad9e82615cacd27d739c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc59cbc4a86e6676ff3d70ba71ba6c0c" category="list-text">添加位于恢复站点的Azure Blob存储。</block>
  <block id="c86146f54b5d798bebf8802ac8b9fcde" category="paragraph"><block ref="c86146f54b5d798bebf8802ac8b9fcde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47d0f0f8f33fcbb5e022f9d64bbbed63" category="list-text">从设备选项卡部署所需数量的灾难恢复虚拟设备(DR Virtual Appliances、DRVA)。</block>
  <block id="f609ba6f20a39912fd585d05df8bc4de" category="admonition">使用容量规划工具估计所需的DRBA数量。</block>
  <block id="4c16a641767d4c33c410687e7b6613ef" category="paragraph"><block ref="4c16a641767d4c33c410687e7b6613ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6b84958a757d2c38048bdf788c590f" category="paragraph"><block ref="1a6b84958a757d2c38048bdf788c590f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7fbe3ea0d16e8cdd943c71406ee9095" category="list-text">使用可用数据存储库或独立的共享iSCSI存储池中的VMDK为每个DRVA创建复制日志卷。</block>
  <block id="376f9301b1fb23692806f601a501bc1d" category="paragraph"><block ref="376f9301b1fb23692806f601a501bc1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3603870d5d8cd5f384cf0b1258a4276a" category="list-text">在受保护域选项卡中、使用Azure Blob Storage站点、DRVA实例和复制日志的相关信息创建所需数量的受保护域。受保护域定义集群中一个或一组同时受保护的应用程序VM、并为故障转移/故障恢复操作分配优先级顺序。</block>
  <block id="fc72030b6d0a9889fccd2facfedc6b0e" category="paragraph"><block ref="fc72030b6d0a9889fccd2facfedc6b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09795e4b943747b98cfc63dfc54275c3" category="paragraph"><block ref="09795e4b943747b98cfc63dfc54275c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb05314ca50bac72a0b13f171a2b6912" category="list-text">选择要保护的VM、并根据依赖关系将这些VM分组到应用程序组中。通过应用程序定义、您可以将VM集分组到逻辑组中、这些逻辑组包含其启动顺序、启动延迟以及可在恢复时执行的可选应用程序验证。</block>
  <block id="818cadd78e726fcca2ca69a99c22df63" category="admonition">确保对受保护域中的所有VM使用相同的保护模式。</block>
  <block id="8cc32e4f2682b9a5731a285459a5d9c5" category="admonition">回写(VMDK)模式可提供更高的性能。</block>
  <block id="639f5dd27b8ff76608b346f78c673b4c" category="paragraph"><block ref="639f5dd27b8ff76608b346f78c673b4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c916465a580d8d569bd369e8e7f6d609" category="list-text">确保将复制日志卷放置在高性能存储上。</block>
  <block id="1fc3826d710244fdb6c4a09d89f98d5f" category="paragraph"><block ref="1fc3826d710244fdb6c4a09d89f98d5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5038dd04f28442b45e40cc394920ed6" category="list-text">完成后、单击受保护域的开始保护。此时将开始将选定虚拟机的数据复制到指定的Blob存储。</block>
  <block id="5ed7580bd1e6ae0cef691df5ee3b54a2" category="paragraph"><block ref="5ed7580bd1e6ae0cef691df5ee3b54a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e860406ba63567c5eccf30055287b47" category="list-text">复制完成后、虚拟机保护状态将标记为可恢复。</block>
  <block id="c873c8c59414399f210af5ec22a764d8" category="paragraph"><block ref="c873c8c59414399f210af5ec22a764d8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a918d27a636eddf2d16b9e8544402c44" category="admonition">可以对故障转移运行手册进行配置、以便对VM (称为恢复组)进行分组、设置启动顺序以及修改CPU/内存设置以及IP配置。</block>
  <block id="90ee2ee79e46dfb341705824bdba5b5a" category="list-text">单击设置、然后单击运行手册配置链接以配置运行手册组。</block>
  <block id="92471f4927394b88148206ffbdc25dbd" category="paragraph"><block ref="92471f4927394b88148206ffbdc25dbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c352449075dfd7c55f51cc486cc2541" category="list-text">单击创建组按钮开始创建新的运行手册组。</block>
  <block id="e2fbd552cab46f747bc672bf2e1b0fe9" category="admonition">如果需要、请在屏幕下部应用自定义预脚本和后脚本、以便在运行手册组执行操作之前和之后自动运行。确保Runbook脚本驻留在管理服务器上。</block>
  <block id="27601285770e6db675411c9282459b87" category="paragraph"><block ref="27601285770e6db675411c9282459b87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f26b7048f93345b3726eb88bd506893a" category="list-text">根据需要编辑VM设置。指定用于恢复VM的参数、包括启动顺序、启动延迟(以秒为单位指定)、CPU数量以及要分配的内存量。单击向上或向下箭头更改VM的启动顺序。此外、还提供了用于保留MAC的选项。</block>
  <block id="ff0274a4eb386ebd23581a082f3b5b5b" category="paragraph"><block ref="ff0274a4eb386ebd23581a082f3b5b5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c2cb19a0ef20564c20014e97d134168" category="list-text">可以为组中的各个VM手动配置静态IP地址。单击虚拟机的NIC视图链接以手动配置其IP地址设置。</block>
  <block id="f26795dd104c3568722b09bce335c904" category="paragraph"><block ref="f26795dd104c3568722b09bce335c904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85bcb54a31960de00ecac27985d3f3a" category="list-text">单击配置按钮以保存相应虚拟机的NIC设置。</block>
  <block id="d6431b9ceb7168220978cc8a6f804dc2" category="paragraph"><block ref="d6431b9ceb7168220978cc8a6f804dc2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c295c7835a978c48c9f8253edc92e6ab" category="paragraph"><block ref="c295c7835a978c48c9f8253edc92e6ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423aff401e73269c665789c2a91cd2ba" category="paragraph">现在、故障转移和故障恢复运行手册的状态均列为已配置。故障转移和故障恢复操作手册组会使用相同的初始VM和设置成对创建。如有必要、可以通过单击相应的详细信息链接并进行更改来单独自定义任何运行手册组的设置。</block>
  <block id="8868e7fa41b895d0441f3c000558500e" category="example-title">在私有云中安装Jetstream DR for AVS</block>
  <block id="ca2d476f98a102308a1ca46e0314f094" category="paragraph">恢复站点(AVS)的一个最佳实践是、提前创建一个三节点的试用集群。这样可以对恢复站点基础架构进行预配置、其中包括以下内容：</block>
  <block id="03bd3d186e1fc83d47907ac1797d8eaf" category="list-text">目标网络分段、防火墙、DHCP和DNS等服务等</block>
  <block id="543c0ee14bc42e7f38251e99ace0ea62" category="list-text">将ANF卷配置为数据存储库等</block>
  <block id="1e09668d117c7996e6a76a4aa2e44013" category="paragraph">Jetstream DR支持任务关键型域采用接近零的RTO模式。对于这些域、应预安装目标存储。在这种情况下、建议使用ANF存储类型。</block>
  <block id="d9a7d19a656972791042b00bc2a308fa" category="admonition">根据SLA和RTO要求、您可以使用持续故障转移或常规(标准)故障转移模式。对于接近零的RTO、您应在恢复站点开始持续重新水化。</block>
  <block id="4b2287bada3112a86338f8d33bb7f745" category="list-text">要在Azure VMware解决方案 私有云上安装Jetstream DR for AVS、请使用Run命令。从Azure门户中、转到Azure VMware解决方案 、选择私有云、然后选择运行命令&gt;软件包&gt; JSDR.Configuration。</block>
  <block id="f36d2f16d7b758d071070007e41f1dc3" category="admonition">Azure VMware解决方案 的默认CloudAdmin用户没有足够的权限来安装适用于AVS的Jetstream DR。Azure VMware解决方案 通过调用适用于Jetstream DR的Azure VMware解决方案 Run命令、可以简化并自动安装Jetstream DR。</block>
  <block id="d5c094ac3602dc70c812b6f203db3080" category="paragraph"><block ref="d5c094ac3602dc70c812b6f203db3080" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1059f69ded45aab3e16676f7655ce33e" category="paragraph"><block ref="1059f69ded45aab3e16676f7655ce33e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f56ba70e80cd5a9d7e833ae9c2a8d00b" category="list-text">添加用于将内部集群作为存储站点进行保护的Azure Blob Storage帐户、然后运行扫描域选项。</block>
  <block id="d46ac425273c7af91c98f03afab4d05d" category="list-text">在显示的弹出对话框窗口中、选择要导入的受保护域、然后单击其导入链接。</block>
  <block id="8f6ce8893e72ca9a99ea54a38aa9123c" category="paragraph"><block ref="8f6ce8893e72ca9a99ea54a38aa9123c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="258e652acbaceeb040a052eb56f710ff" category="list-text">已导入此域以进行恢复。转到"受保护域"选项卡并验证是否已选择目标域、或者从"选择受保护域"菜单中选择所需域。此时将显示受保护域中可恢复的VM列表。</block>
  <block id="44f0914b6b6c354b3ed0d0f5c88f5f40" category="paragraph"><block ref="44f0914b6b6c354b3ed0d0f5c88f5f40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab8894857a9c27d55e00ceb59f0a0a9d" category="list-text">导入受保护域后、部署DRVA设备。</block>
  <block id="a594598fd21c66eb364972e1018fc5b1" category="admonition">也可以使用CPT创建的计划自动执行这些步骤。</block>
  <block id="5dbd13899d13d449aaa288efb68bc4e7" category="list-text">导入受保护域并配置恢复VA以使用ANF数据存储库放置VM。</block>
  <block id="30c90d4c81b9e156fa124f63997bd267" category="paragraph"><block ref="30c90d4c81b9e156fa124f63997bd267" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27ece16fa591c8a94d158b6371824318" category="admonition">确保选定网段上已启用DHCP、并且有足够的可用IP。在恢复域时、系统会临时使用动态IP。每个正在恢复的VM (包括持续重新融合)都需要一个单独的动态IP。恢复完成后、此IP将被释放并可重复使用。</block>
  <block id="221af48bbe7986080d7f1ef43b7cc9af" category="admonition">尽管执行配置时的持续故障转移和故障转移模式有所不同、但这两种故障转移模式都使用相同的步骤进行配置。在发生灾难事件时、可以同时配置和执行故障转移步骤。可以随时配置持续故障转移、然后允许在正常系统运行期间在后台运行。发生灾难事件后、将完成持续故障转移、以便立即将受保护VM的所有权转移到恢复站点(接近零的RTO)。</block>
  <block id="12d3f891efb3e0286e3d610d87fa763c" category="paragraph"><block ref="12d3f891efb3e0286e3d610d87fa763c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fad47d76ebfb2068cc150f23d3abc231" category="paragraph">持续故障转移过程开始、可从UI监控其进度。单击当前步骤部分中的蓝色图标将显示一个弹出窗口、其中显示了故障转移过程当前步骤的详细信息。</block>
  <block id="07216bb55061288a2fa29cda954742e3" category="example-title">故障转移和故障恢复</block>
  <block id="3dd9279db501526060882c484e7fa2eb" category="list-text">在内部环境的受保护集群发生灾难(部分或完整故障)后、您可以在中断相应应用程序卷的SnapMirror关系后使用Jetstream为VM触发故障转移。</block>
  <block id="4e26d6c9cc7404940d6c72a71775d261" category="paragraph"><block ref="4e26d6c9cc7404940d6c72a71775d261" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7c749826108cc466667dcaeb67965a7" category="paragraph"><block ref="f7c749826108cc466667dcaeb67965a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="253d2b2bed504833d82e064634bbf83e" category="admonition">此步骤可以轻松地自动执行、以便于恢复过程。</block>
  <block id="9824ceea6f74aa9d72ed2bd7473b9362" category="list-text">在AVS SDDC (目标端)上访问Jetstream UI并触发故障转移选项以完成故障转移。任务栏将显示故障转移活动的进度。</block>
  <block id="b39966f9c6438e5d60c1de37dfa3ed05" category="paragraph">在完成故障转移时显示的对话框窗口中、可以按计划或假定强制指定故障转移任务。</block>
  <block id="684bb098f20646b3f18e10bc17e2d3c4" category="paragraph"><block ref="684bb098f20646b3f18e10bc17e2d3c4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="562cb54fd49a347cfb889e6021e0be34" category="paragraph"><block ref="562cb54fd49a347cfb889e6021e0be34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979b519fc9d5e27e5d114696ce4b1366" category="paragraph">强制故障转移假定主站点不再可访问、并且恢复站点应直接接管受保护域的所有权。</block>
  <block id="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="paragraph"><block ref="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9be51d726dd7c6ae76c2545a91f36d11" category="paragraph"><block ref="9be51d726dd7c6ae76c2545a91f36d11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fce15eac6afaa8615d7a00cc4972808" category="list-text">持续故障转移完成后、将显示一条消息、确认任务完成。任务完成后、访问已恢复的VM以配置iSCSI或NFS会话。</block>
  <block id="53839296d302ef4a3faf8220562c1ce4" category="admonition">故障转移模式将更改为在故障转移中运行、并且VM状态可恢复。受保护域中的所有VM现在都在恢复站点上以故障转移操作手册设置指定的状态运行。</block>
  <block id="50ff3dc4ca6f3eb140f2099f2b480b83" category="admonition">要验证故障转移配置和基础架构、可以在测试模式(测试故障转移选项)下运行Jetstream DR、以观察虚拟机及其数据从对象存储恢复到测试恢复环境的过程。在测试模式下执行故障转移操作步骤 时、其操作类似于实际的故障转移过程。</block>
  <block id="a6687fcac4b89ac042d0bf01e0eed2c7" category="paragraph"><block ref="a6687fcac4b89ac042d0bf01e0eed2c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf3e40ce09f6fe770361fe49d398cad9" category="list-text">恢复虚拟机后、请对子系统中的存储使用存储灾难恢复。要演示此过程、请在此示例中使用SQL Server。</block>
  <block id="e5007f72fe428769908e4b66a64b1ace" category="list-text">登录到AVS SDDC上已恢复的SnapCenter VM并启用灾难恢复模式。</block>
  <block id="8bc57e8e0debd3b1f0e1c01431ceb73b" category="list-text">使用browserN访问SnapCenter UI。</block>
  <block id="b29ffa42af1df2e35cdf88be1740bdf8" category="paragraph"><block ref="b29ffa42af1df2e35cdf88be1740bdf8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="392d143fa78a9868b2d56197de458a8d" category="list-text">在设置页面中、导航到设置&gt;全局设置&gt;灾难恢复。</block>
  <block id="f4060a5dfc75e427eab8fc559b5c3873" category="list-text">选择启用灾难恢复。</block>
  <block id="79bee17b4293b619c241ae80aef8ef62" category="list-text">单击应用。</block>
  <block id="24049296b222c98c12a36098c1928b9f" category="paragraph"><block ref="24049296b222c98c12a36098c1928b9f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f31c54b6a166b6ab176f034d0f52e291" category="list-text">单击"监控"&gt;"作业"以验证是否已启用灾难恢复作业。</block>
  <block id="a194386b24136c162d5de560f2c4b3c9" category="admonition">应使用NetApp SnapCenter 4.6或更高版本进行存储灾难恢复。对于先前版本、应使用应用程序一致的快照(使用SnapMirror复制)、如果必须在灾难恢复站点中恢复先前的备份、则应执行手动恢复。</block>
  <block id="a1e59d581c6cda40186a3488aa35c0b5" category="list-text">确保SnapMirror关系已断开。</block>
  <block id="ab99ab9f50b0f74bd7b676fbb522f5e8" category="paragraph"><block ref="ab99ab9f50b0f74bd7b676fbb522f5e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5fabb74faf982c31918e4a241092e386" category="list-text">使用相同的驱动器号将LUN从Cloud Volumes ONTAP 连接到已恢复的SQL子虚拟机。</block>
  <block id="faedf38240e42a0e3f085f6acdc22aec" category="paragraph"><block ref="faedf38240e42a0e3f085f6acdc22aec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="458585a8fad71bd63549d32afd2c2f69" category="list-text">打开iSCSI启动程序、清除先前已断开连接的会话、然后为复制的Cloud Volumes ONTAP 卷添加新目标以及多路径。</block>
  <block id="5d06816a9331ccf1bde11d80e2438672" category="paragraph"><block ref="5d06816a9331ccf1bde11d80e2438672" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2483b40da799327d80d5aa5c4683efee" category="list-text">确保使用DR之前使用的相同驱动器盘符连接所有磁盘。</block>
  <block id="75c3e1de048df1f08f612bb44462afd4" category="paragraph"><block ref="75c3e1de048df1f08f612bb44462afd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6048d3c947f6b9163f72586701cec853" category="list-text">重新启动MSSQL服务器服务。</block>
  <block id="9f8472ea6d004535fc1659d1e6863867" category="paragraph"><block ref="9f8472ea6d004535fc1659d1e6863867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="632dc72bd4eb731f74582d644a0f4b3c" category="list-text">确保SQL资源重新联机。</block>
  <block id="9d19926e46fa4cd818065a2726bcf42d" category="paragraph"><block ref="9d19926e46fa4cd818065a2726bcf42d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01fb98a09bb6b1d922a6275724f31823" category="admonition">对于NFS、请使用mount命令连接卷并更新`/etc/fstab`条目。</block>
  <block id="8145668f843709bddb7b6c8b3f3abbfb" category="paragraph">此时、可以正常运行运营并继续正常运营。</block>
  <block id="8020518363652d35b23a9585c780e480" category="admonition">在NSX-T端、可以创建一个单独的专用第1层网关来模拟故障转移场景。这样可以确保所有工作负载可以相互通信、但任何流量都不能路由到环境或从环境中路由出来、这样、执行任何鉴别、控制或强化任务都不会面临交叉感染的风险。此操作不在本文档的讨论范围内、但在模拟隔离时可以轻松完成。</block>
  <block id="7d7b7ba342280685358aeb9937ce1118" category="paragraph">主站点启动并重新运行后、您可以执行故障恢复。Jetstream将恢复VM保护、并且必须反转SnapMirror关系。</block>
  <block id="5a24d57462c6d674800fbb2a7e0c59ce" category="list-text">还原内部环境。根据灾难意外事件的类型、可能需要还原和/或验证受保护集群的配置。如有必要、可能需要重新安装Jetstream DR软件。</block>
  <block id="5cf6cc1cdb0715aca121fb45bdc4f42e" category="admonition">CPT生成的故障恢复计划还可用于启动VM及其数据从对象存储返回到原始VMware环境的操作。</block>
  <block id="130f86be5d695ec045cce675d14637b8" category="paragraph"><block ref="130f86be5d695ec045cce675d14637b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="504e0be50ebedab76e2a7714a22354d3" category="admonition">指定暂停恢复站点中的VM并在受保护站点中重新启动VM后的最大延迟。完成此过程所需的时间包括：停止故障转移VM后完成复制、清理恢复站点所需的时间以及在受保护站点中重新创建VM所需的时间。NetApp建议10分钟。</block>
  <block id="41f8873d7ef0fd0767f8ed6d7798fe87" category="paragraph"><block ref="41f8873d7ef0fd0767f8ed6d7798fe87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5752ed9acb85541568eca0327a24e09f" category="list-text">完成故障恢复过程、然后确认虚拟机保护恢复和数据一致性。</block>
  <block id="f872505992d08e75adcaa8a9adbc0d18" category="paragraph"><block ref="f872505992d08e75adcaa8a9adbc0d18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684bcaaa7dda535165cb0b8f8e76a5ea" category="list-text">恢复VM后、断开二级存储与主机的连接并连接到主存储。</block>
  <block id="79f47ff1cd40017f1ef0eb31e7397d75" category="paragraph"><block ref="79f47ff1cd40017f1ef0eb31e7397d75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18f7dd50970b99e8a3cdeab8c42567b0" category="paragraph"><block ref="18f7dd50970b99e8a3cdeab8c42567b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f0269cfb1a6f24731b2bb3a15b436b2" category="list-text">验证SQL资源是否已恢复联机。</block>
  <block id="bb9592df1a1b3d7ea469affe88be679f" category="paragraph"><block ref="bb9592df1a1b3d7ea469affe88be679f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41823ca0d78e787fda8ba7b1c398a29" category="admonition">要故障恢复到主存储、请执行反向重新同步操作、以确保关系方向与故障转移前的关系方向保持一致。</block>
  <block id="6decfeed5d1c375e40e96552e631df25" category="admonition">要在执行反向重新同步操作后保留主存储和二级存储的角色、请再次执行反向重新同步操作。</block>
  <block id="2087f49e4433786c996468974c61ae4a" category="paragraph">此过程适用于Oracle等其他应用程序、类似的数据库模式以及使用来宾连接存储的任何其他应用程序。</block>
  <block id="33b4e9a3c1a928dbdf5273b34d899e61" category="paragraph">在将关键工作负载迁移到生产环境之前、请始终测试恢复这些工作负载所涉及的步骤。</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="section-title">此解决方案 的优势</block>
  <block id="3a02a011f551429a5ec8b46a00017abd" category="list-text">使用高效且具有故障恢复能力的SnapMirror复制。</block>
  <block id="74915666b8d10f77a73b526e91724cc8" category="list-text">使用ONTAP 快照保留功能恢复到任何可用时间点。</block>
  <block id="a3704e4802422c6765dd406472307ba1" category="list-text">从存储、计算、网络和应用程序验证步骤中恢复成百上千个VM所需的所有步骤均可实现完全自动化。</block>
  <block id="c0e8bb909ee76b5f9683012fd9418729" category="list-text">SnapCenter 使用的克隆机制不会更改复制的卷。</block>
  <block id="d92ea079cd9d83d3d60c1269804b766c" category="list-text">这样可以避免卷和快照的数据损坏风险。</block>
  <block id="843b8877e30b7587ad87b95cd115df4a" category="list-text">在灾难恢复测试工作流期间避免复制中断。</block>
  <block id="a29a4a29d457d4322f1f22ed58f9b06a" category="list-text">将灾难恢复数据用于灾难恢复以外的工作流、例如开发/测试、安全测试、修补和升级测试以及修复测试。</block>
  <block id="e04e963feedf7f0157e360dc2be6d7b3" category="list-text">CPU和RAM优化可通过恢复到较小的计算集群来帮助降低云成本。</block>
  <block id="bd3260deba05f8c5831890f164f83733" category="doc">ANF数据存储库解决方案概述</block>
  <block id="626c4c46c0b0900648e0b954a96c4399" category="paragraph">每个成功的组织都在转型和现代化的道路上。在此过程中、企业通常会利用现有的VMware投资、同时利用云优势、并探索如何尽可能无缝地迁移、突发、扩展和灾难恢复过程。迁移到云的客户必须评估弹性和突发、数据中心退出、数据中心整合、寿命终结情形、合并、收购等问题。每个组织采用的方法可能因其各自的业务优先级而异。在选择基于云的操作时、选择一个具有适当性能且最大程度减少障碍的低成本模式是一个关键目标。除了选择合适的平台之外、存储和工作流编排对于充分发挥云部署和弹性的潜能尤其重要。</block>
  <block id="bcc2a83e573fb5cbbcd097908c609fa6" category="paragraph">虽然Azure VMware解决方案 为客户提供了独特的混合功能、但有限的原生 存储选项限制了它对存储负载繁重的组织的有用性。由于存储与主机直接相关、因此扩展存储的唯一方法是添加更多主机、这样对于存储密集型工作负载、成本可能会增加35-40%或更多。这些工作负载需要额外的存储、而不是额外的功率、但这意味着需要为额外的主机付费。</block>
  <block id="abc79d01b4318a1c67504eb7714e360f" category="paragraph">我们来考虑以下情形：客户需要六台主机来提供功率(vCPU/vMem)、但他们也需要大量存储。根据他们的评估、他们需要12台主机来满足存储要求。这样可以提高总体TCO、因为他们必须购买所有这些额外的动力、而他们真正需要的只是更多的存储。这适用于任何使用情形、包括迁移、灾难恢复、突发、开发/测试、 等等。</block>
  <block id="f6faa113f88d1f8c4795fe189493d34f" category="paragraph">Azure VMware解决方案 的另一个常见使用情形是灾难恢复(DR)。大多数企业都没有防虚灾难恢复策略、或者可能难以为灾难恢复运行虚影数据中心。管理员可以使用轻型试点集群或按需集群探索零占用空间灾难恢复选项。然后、他们可以在不添加额外主机的情况下扩展存储、这可能是一个极具吸引力的选择。</block>
  <block id="feb87b8a766262f1649eb73f664b5237" category="paragraph">因此、概括地说、使用情形可以分为两种分类方式：</block>
  <block id="113270f68f35ffcbf2a57597bd22e665" category="list-text">使用ANF数据存储库扩展存储容量</block>
  <block id="a46f3b69652b37f2becc5ad8def389fe" category="list-text">在软件定义的数据中心(SDDC)之间、将ANF数据存储库用作从内部或Azure区域进行成本优化的恢复工作流的灾难恢复目标。本指南深入介绍如何使用Azure NetApp Files 为数据存储库提供优化的存储(当前处于公有 预览模式) 除了Azure VMware解决方案 中同类最佳的数据保护和灾难恢复功能之外、您还可以通过此功能从vSAN存储中卸载存储容量。</block>
  <block id="9d5486edf9a5ddec98d7f7509d50101c" category="section-title">Azure中的VMware Cloud选项</block>
  <block id="809dd7fcec8077467eab0222ea68e259" category="paragraph">Azure VMware解决方案 (AVS)是一种混合云服务、可在Microsoft Azure公有 云中提供功能完备的VMware SDDC。AVS是由Microsoft全面管理和支持并经过VMware验证的第一方解决方案 、它使用Azure基础架构。因此、客户可以获得用于计算虚拟化的VMware ESXi、用于超融合存储的vSAN以及用于网络连接和安全的NSX、同时充分利用Microsoft Azure的全球影响力、一流的数据中心设施以及与丰富的原生 Azure服务和解决方案生态系统的邻近性。Azure VMware解决方案 SDDC与Azure NetApp Files 相结合、可提供最佳性能、同时将网络延迟降至最低。</block>
  <block id="8718654ef588a85b2a2e46a7727fa16d" category="paragraph">无论使用何种云、在部署VMware SDDC时、初始集群都包括以下组件：</block>
  <block id="b6955e4f04d87bd186e8f355b710c814" category="list-text">用于计算虚拟化的VMware ESXi主机、以及用于管理的vCenter Server设备。</block>
  <block id="c865d5c3f7aef0fea827cecdf6da386c" category="list-text">VMware vSAN超融合存储、整合了每个ESXi主机的物理存储资产。</block>
  <block id="4d53c4a03b478ccb8f5a4a2cde37db71" category="list-text">VMware NSX用于虚拟网络连接和安全性、并使用NSX Manager集群进行管理。</block>
  <block id="94d43b2c8702afe74d26d3a9052e59b4" category="paragraph">无论您是以全云还是混合云为目标、Azure NetApp Files 都可以提供出色的选项来部署和管理应用程序工作负载以及文件服务、同时通过将数据需求无缝地迁移到应用程序层来降低TCO。无论使用何种情形、都可以选择Azure VMware解决方案 和Azure NetApp Files 、以快速实现云优势、跨内部和多个云实现一致的基础架构和运营、并实现工作负载双向可移植性以及企业级容量和性能。这是用于连接存储的熟悉过程。请记住、随新名称一起更改的只是数据的位置；工具和流程都保持不变、Azure NetApp Files 有助于优化整体部署。</block>
  <block id="7017a5961c414dfbe07b539da73560fb" category="list-text">现在、您可以在AVS SDDC上使用Azure NetApp Files 作为数据存储库。</block>
  <block id="1997ea39c8d744bf66dd1b36df20eca0" category="list-text">加快应用程序响应速度并提高可用性、以便在需要时随时随地访问工作负载数据。</block>
  <block id="d229778544c20c94bc3a4e634983743a" category="list-text">通过简单的即时调整大小功能简化vSAN存储的整体复杂性。</block>
  <block id="220eb8ba4e87069e79226f808999d319" category="list-text">利用动态重塑功能为任务关键型工作负载提供有保障的性能。</block>
  <block id="de55b3d8d98ed7c720c8410fbbce524e" category="list-text">如果Azure VMware解决方案 Cloud是目标、则Azure NetApp Files 是最适合优化部署的存储解决方案。</block>
  <block id="a13de136306e099dce523fd8db3f037c" category="list-text">Azure VMware解决方案 文档</block>
  <block id="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link"><block ref="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link-rx"></block></block>
  <block id="5e65b51c08430d6fa3dc13275b00da9d" category="paragraph"><block ref="5e65b51c08430d6fa3dc13275b00da9d" category="inline-link-rx"></block></block>
  <block id="6c32a3d0f1a665987b98dde5a0f96d7d" category="list-text">Azure NetApp Files 文档</block>
  <block id="ac236475735595f1237223b0184c5cca" category="inline-link"><block ref="ac236475735595f1237223b0184c5cca" category="inline-link-rx"></block></block>
  <block id="742cb4a55dadc1d5ca8efd2956575138" category="paragraph"><block ref="742cb4a55dadc1d5ca8efd2956575138" category="inline-link-rx"></block></block>
  <block id="8d60f49fa5ec93fd2bea5e083359bdc1" category="paragraph">在内部部署中、ESXi版本3引入了NFS数据存储库支持功能、极大地扩展了vSphere的存储功能。</block>
  <block id="1aaea72f240547a6a057b9a88a27144b" category="paragraph">在NFS上运行vSphere是内部虚拟化部署的一个广泛采用的选项、因为它可以提供强大的性能和稳定性。如果您在内部数据中心中拥有大量网络连接存储(NAS)、则应考虑在Azure中部署一个采用Azure NetApp文件数据存储库的Azure VMware解决方案 SDDC、以克服容量和性能挑战。</block>
  <block id="19fb9916968211db983d13bffe0cc6af" category="inline-link">99.99%</block>
  <block id="ad25c186e2eeaa2ec5fa0b9d3fa4b8c7" category="paragraph">Azure NetApp Files 基于行业领先且高度可用的NetApp ONTAP 数据管理软件构建。Microsoft Azure服务分为三类：基础服务、主流服务和专业服务。Azure NetApp Files 属于专业类别、由许多地区已部署的硬件提供支持。借助内置的高可用性(HA)、Azure NetApp Files 可以保护您的数据免受大多数中断的影响、并为您提供行业领先的SLA<block ref="404362048587970f5f15a4d9376a71ea" category="inline-link-rx"></block> 正常运行时间。</block>
  <block id="1b69b6091c2756a0aac2b81e4a880f93" category="paragraph">在推出Azure NetApp Files 数据存储库功能之前、对于计划托管性能和存储密集型工作负载的客户来说、横向扩展操作需要同时扩展计算和存储。</block>
  <block id="09d432ffd44a3af2e2524362730628cf" category="paragraph">请记住以下问题：</block>
  <block id="79786892120b18078ded972068ce7cab" category="list-text">不建议在SDDC集群中使用不平衡的集群配置。因此、扩展存储意味着添加更多主机、这意味着TCO增加。</block>
  <block id="4d7a269595fa13e9d4bb48449c996a41" category="list-text">只能使用一个 vSAN 环境。因此、所有存储流量都直接与生产工作负载竞争。</block>
  <block id="99407e1fc016dc5a4f17896a330e66b0" category="list-text">无法提供多个性能层来满足应用程序要求、性能和成本要求。</block>
  <block id="f5188d9f655a6ac9c3d0dccb20d81997" category="list-text">轻松达到基于集群主机的vSAN的存储容量限制。通过将Azure—原生 平台即服务(Platform-as-a-Service、PaaS)产品(例如Azure NetApp Files)集成为数据存储库、 客户可以选择单独扩展其存储、并仅根据需要向SDDC集群添加计算节点。此功能可克服上述挑战。</block>
  <block id="cf1c082028930ec1827badc0e64627c6" category="admonition">请联系Azure和NetApp解决方案 架构师、以规划和调整存储规模、并确定所需的主机数量。NetApp建议在最终确定用于测试、POC和生产部署的数据存储库布局之前确定存储性能要求。</block>
  <block id="1622404dda50f5803c9577efc058ec11" category="paragraph"><block ref="1622404dda50f5803c9577efc058ec11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3488e5e13ca2586de3bcc01700bd61b" category="paragraph">迁移或灾难恢复中最重要的方面是确定目标环境的正确大小。了解需要多少个节点才能从内部迁移到Azure VMware解决方案 、这一点非常重要。</block>
  <block id="b39d58eedf7db669f2a65fd75198d49e" category="paragraph">对于规模估算、请使用RVTools (首选)或Live Optics或Azure Migrate等其他工具从内部环境中获取的历史数据。RVTools是捕获vCPU、vMem、vDisk以及所有所需信息(包括已打开或关闭的VM)以确定目标环境特征的理想工具。</block>
  <block id="9b45f8f524f59dcb44852dc933d31d60" category="paragraph">要运行RVtools、请完成以下步骤：</block>
  <block id="b9b14f9a77af6302e167ec8031bac435" category="list-text">下载并安装RVTools。</block>
  <block id="a379941a0582174b350ce316b1e64b36" category="list-text">运行RVTools、输入连接到内部vCenter Server所需的信息、然后按Login。</block>
  <block id="7d0ff8053a5012b379d5e45f7d80bd81" category="list-text">将清单导出到Excel电子表格。</block>
  <block id="ad7235861abcfd585f9793a320142cb9" category="list-text">编辑电子表格、并从vInfo选项卡中删除任何不是理想候选对象的虚拟机。此方法可提供有关存储要求的清晰输出、可用于根据所需主机数量调整Azure VMware SDDC集群的大小。</block>
  <block id="66a03e4bdc70563bcc83f39fd18f2993" category="admonition">与子系统内存储一起使用的子系统VM必须单独计算；但是、Azure NetApp Files 可以轻松地覆盖额外的存储容量、从而保持较低的总TCO。</block>
  <block id="ee7f083efd1984641bff3ff302c447a9" category="section-title">部署和配置Azure VMware解决方案</block>
  <block id="95220678e12ace3a65339c08bb6019e5" category="paragraph">与内部部署一样、规划Azure VMware解决方案 对于创建虚拟机和迁移的生产就绪环境成功至关重要。</block>
  <block id="1b3379256eb1cb0d26126368cc62ab52" category="paragraph">本节介绍如何设置和管理AVS、以便与Azure NetApp Files 结合使用、并将其用作具有子系统内存储的数据存储库。</block>
  <block id="449e01682ffd6d9e79c75acf22fa249b" category="list-text">注册资源提供商并创建私有云。</block>
  <block id="17d7be5e1d44a11ff74be89af34822c9" category="list-text">连接到新的或现有的ExpressRoute虚拟网络网关。</block>
  <block id="28325f137394bcd829a01024c035cb5e" category="list-text">验证网络连接并访问私有云。请参见此部分 <block ref="c494c3efc2923b26ad63800ea1f5c612" category="inline-link-macro-rx"></block> 逐步完成Azure VMware解决方案 SDDC配置过程。</block>
  <block id="b2666a13d31389019b43a9085ffd2fe8" category="section-title">使用Azure VMware解决方案 配置Azure NetApp Files</block>
  <block id="dbfbac0b1aee2557c747f90a52c200ed" category="paragraph">通过Azure NetApp Files 之间的新集成、您可以通过Azure VMware解决方案 资源提供程序API/CLI为Azure NetApp Files 卷创建NFS数据存储库、并将这些数据存储库挂载到私有云中您选择的集群上。除了托管VM和应用程序VMDK之外、还可以从Azure VMware解决方案 SDDC环境中创建的VM挂载Azure NetApp文件卷。这些卷可以挂载到Linux客户端上并映射到Windows客户端上、因为Azure NetApp Files 支持服务器消息块(SMB)和网络文件系统(NFS)协议。</block>
  <block id="3fcf61e60f3486b366489a2db86e92c0" category="admonition">为了获得最佳性能、请将Azure NetApp Files 部署在与私有云相同的可用性区域中。与Express路由快速路径的主机代管可提供最佳性能、并将网络延迟降至最低。</block>
  <block id="7042805ebe69bccc6ab09f9518f94556" category="paragraph">要将Azure NetApp文件卷作为Azure VMware解决方案 私有云的VMware数据存储库附加、请确保满足以下前提条件。</block>
  <block id="49588f95c73f4a9df95958ba5e856d0c" category="list-text">使用AZ登录并验证订阅是否已注册到Microsoft .AVS命名空间中的CloudSanExpertion功能。</block>
  <block id="c0e46e4183896be214bad3fd077b5834" category="list-text">如果未注册、请注册它。</block>
  <block id="8fb14eb63139db9a1c626865766368e4" category="admonition">完成注册可能需要大约15分钟。</block>
  <block id="91bc7290f2d4745c25033c52b73c0662" category="list-text">要检查注册状态、请运行以下命令。</block>
  <block id="bd00d81bc80103cfbf6f24470f9de4fa" category="list-text">如果注册停留在中间状态超过15分钟、请取消注册、然后重新注册此标志。</block>
  <block id="30d4986a1e28c78ed243b8fe94ebe5be" category="list-text">验证订阅是否已注册到Microsoft .AVS命名空间中的AnfDatastore体验 功能。</block>
  <block id="10b9b69a3124f921ee9a3a8271028b78" category="list-text">验证是否已安装VMware扩展。</block>
  <block id="329e9fb0e53008fcf269d03c5476847d" category="list-text">如果已安装扩展、请验证版本是否为3.0.0。如果安装的是旧版本、请更新此扩展。</block>
  <block id="f5e4a463688cab0acae8d53e64bd5e36" category="list-text">如果尚未安装扩展、请安装它。</block>
  <block id="11d2eb5b9d070e139a779747ce885490" category="list-text">登录到Azure门户并访问Azure NetApp Files。使用`az provider register``-namespace Microsoft.NetApp–wait`命令验证对Azure NetApp Files 服务的访问并注册Azure NetApp Files 资源提供程序。注册后、创建一个NetApp帐户。请参见此部分<block ref="2c2f4008511e047aaaf92ad514e98ec9" category="inline-link-rx"></block> 了解详细步骤。</block>
  <block id="09e7af76fc12c4b14e8fbca51314b508" category="paragraph"><block ref="09e7af76fc12c4b14e8fbca51314b508" category="inline-image-macro-rx" type="image"></block></block>
  <block id="187927c7525fb36ec9428b4d84fe0aff" category="list-text">创建NetApp帐户后、使用所需的服务级别和大小设置容量池。有关详细信息、请参见此<block ref="0a52e91c67ac030fc237a7b13d0404c6" category="inline-link-rx"></block>。</block>
  <block id="c7d6fd5f235d0c8a960facf04a79e4a7" category="paragraph"><block ref="c7d6fd5f235d0c8a960facf04a79e4a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c573a9eace62b9790820458dd59448b0" category="list-text">Azure NetApp Files 上的数据存储库支持NFSv3。</block>
  <block id="0d55d5c3a7459f59fd437a2311322791" category="list-text">为Azure NetApp Files 配置委派子网、并在创建卷时指定此子网。有关创建委派子网的详细步骤、请参见此文档<block ref="e84891bed408b1977d062f4ccc1816aa" category="inline-link-rx"></block>。</block>
  <block id="36fc58c2c3fa32ac586d5628570e9499" category="list-text">使用容量池刀片下的卷刀片为数据存储库添加NFS卷。</block>
  <block id="2832d137c1714a9759f87412fb05253e" category="paragraph"><block ref="2832d137c1714a9759f87412fb05253e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="372d7a6604390fe9757888aff0a92970" category="example-title">将Azure NetApp Files 数据存储库添加到私有云</block>
  <block id="0f9e7cabe2f81455810e96baca91c6a7" category="paragraph">要将Azure NetApp Files 数据存储库添加到私有云、请完成以下步骤：</block>
  <block id="b1248573ef968f7d6fc7eaa453fa4d45" category="list-text">注册所需功能后、运行相应的命令将NFS数据存储库连接到Azure VMware解决方案 私有云集群。</block>
  <block id="567531ac8390e0378f43db080cbeec2b" category="list-text">使用Azure VMware解决方案 私有云集群中的现有ANF卷创建数据存储库。</block>
  <block id="ed491060b6ac47e89ad70eecda183065" category="paragraph">C：\Users\Niyaz&gt;AZ VMware数据存储库列表-resource-group anfavsval2 -cluster cluster-1 -private-cloud ANFDataClus [｛"diskPoolVolume"：null、"id"："/subscriptions/0efa2dfb-917c-4497-b56a-b3fetastors"s"/"DS4fab/s"s"/"s"vetas" Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecods/volumes/ANFRecoDS001"、"s"s"s"s"s"s"1/s"s"/"s"s"s"s"s"s"s"s"s"s"s"s&amp;"s"s"s"s&amp;"s"s"s"s&amp;"s"s"s"s&amp;"s"s"s"s"s&amp;"s"s"s"s"s&amp;"s"s"s"s"s"s&amp;"s"s"s"s"s&amp;"s"s"s"s&amp;"s"s"s"s&amp;"s"s"s&amp;"s"s&amp;"s"s"s ｛"diskPoolVolume"：null、"id"：Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecodsu/volumes/anfrecodsU002""/subscriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/resourcegroups/anfavsval2/providers/microsoft.AVS/privateClouds/ANFDataClus/clusters/Cluster-1/Clusters-1/DS4a"DSA/SA/S4372/"DSA/S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S&amp;S-</block>
  <block id="d1903b7932291ae49bf265e5af7a75f4" category="list-text">建立必要的连接后、这些卷将作为数据存储库挂载。</block>
  <block id="b9eb0553d93e0e4bbee4142fec9403f9" category="paragraph"><block ref="b9eb0553d93e0e4bbee4142fec9403f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="078f601da77f62e8c7e097d5744f9b1b" category="section-title">规模估算和性能优化</block>
  <block id="2954ff66e26b577154cf218d077ff1a9" category="paragraph">Azure NetApp Files 支持三种服务级别：标准（每 TB 16 MBps ），高级（每 TB 64 MBps ）和超级（每 TB 128 MBps ）。配置适当的卷大小对于优化数据库工作负载性能非常重要。使用Azure NetApp Files 时、卷性能和吞吐量限制取决于以下因素：</block>
  <block id="a5d62ae512b963e1f05e839467577f19" category="paragraph"><block ref="a5d62ae512b963e1f05e839467577f19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1261ba8eeb83d9d138ff9e9a37214a7e" category="section-title">性能注意事项</block>
  <block id="f4479400cc63a0bc54ea3a609d8d89aa" category="paragraph">请务必了解、在NFS版本3中、ESXi主机和单个存储目标之间只有一个活动管道用于连接。这意味着、尽管可能有备用连接可用于故障转移、但单个数据存储库和底层存储的带宽仅限于单个连接可以提供的带宽。</block>
  <block id="f4c57c87dfa0d5843279b51c6e10d0a6" category="paragraph">要利用Azure NetApp Files 卷的更多可用带宽、ESXi主机必须与存储目标建立多个连接。要解决此问题描述 问题、您可以配置多个数据存储库、每个数据存储库在ESXi主机和存储之间使用单独的连接。</block>
  <block id="bde357669435115ce8fac67e3a3a5786" category="paragraph">为了提高带宽、最佳做法是使用多个ANF卷创建多个数据存储库、创建VMDK并在VMDK之间对逻辑卷进行条带化。</block>
  <block id="c01a936a44f773bc3d0a636cb655c28c" category="list-text">默认情况下、Azure VMware解决方案 允许八个NFS数据存储库。可以通过支持请求来增加此数量。</block>
  <block id="cd58e3b202d882202a16834028640630" category="list-text">利用ER快速通道和超SKU提高带宽并降低延迟。更多信息</block>
  <block id="6ef5173b6cc36d0f4efabbafeeee7443" category="list-text">借助Azure NetApp Files 中的"基本"网络功能、Azure VMware解决方案 的连接受ExpressRoute电路和ExpressRoute网关的带宽限制。</block>
  <block id="fad725216d945a6443f15949ae73b316" category="cell">需要记住的要点</block>
  <block id="0d3f5dc8a647758ee9ad71d0af34e75e" category="section-title">增加数据存储库的大小</block>
  <block id="9ae97248366686f76c6f9f6ac9b8d073" category="paragraph">卷重新调整和动态服务级别更改对SDDC是完全透明的。在Azure NetApp Files 中、这些功能可实现持续的性能、容量和成本优化。通过从Azure Portal调整卷大小或使用命令行界面来增加NFS数据存储库的大小。完成后、访问vCenter、转到数据存储库选项卡、右键单击相应的数据存储库、然后选择刷新容量信息。此方法可用于增加数据存储库容量、并以动态方式提高数据存储库的性能、而不会造成停机。此过程对于应用程序也是完全透明的。</block>
  <block id="264b475cf0374b319edf3b094fe25874" category="list-text">通过卷重新调整和动态服务级别功能、您可以针对稳定状态的工作负载进行规模估算、从而优化成本、从而避免过度配置。</block>
  <block id="35084d885dea7b061e6894c1cf3036d9" category="section-title">工作负载</block>
  <block id="f7458ac9343d5418ff038f156d9b29fc" category="paragraph">迁移是最常见的使用情形之一。使用VMware HCX或vMotion移动内部VM。或者、您也可以使用Riverbadow.将VM迁移到Azure NetApp Files 数据存储库。</block>
  <block id="36e402ac6b1a4b9a31bd376a7f89c68e" category="paragraph">备份VM并快速恢复VM是ANF数据存储库的主要优势之一。使用Snapshot副本在不影响性能的情况下快速创建虚拟机或数据存储库的副本、然后将其发送到Azure存储以实现长期数据保护、或者使用跨区域复制将其发送到二级区域以实现灾难恢复。这种方法只存储更改后的信息，从而最大限度地减少存储空间和网络带宽。</block>
  <block id="2bd24edc1157f2ea366bbf67e980b57e" category="paragraph">使用Azure NetApp Files Snapshot副本进行一般保护、并使用应用程序工具保护事务数据、例如驻留在子VM上的SQL Server或Oracle。这些 Snapshot 副本与 VMware （一致性）快照不同，适用于长期保护。</block>
  <block id="c69157396b1ac0cb910d839c99a0a9e3" category="admonition">对于ANF数据存储库、可以使用还原到新卷选项克隆整个数据存储库卷、还原的卷可以作为另一个数据存储库挂载到AVS SDDC中的主机。挂载数据存储库后、可以注册、重新配置和自定义数据存储库中的VM、就像它们是单独克隆的VM一样。</block>
  <block id="ad15ef62ee17e83e2a2c4de5cfc0a7e0" category="paragraph">可以通过完成以下步骤来安装设置和保护策略：</block>
  <block id="3a1d9263efa0039dd46c2e2d0dfc2dec" category="list-text">添加云订阅凭据(客户端和机密值)、然后添加包含您要保护的资源的云订阅帐户(NetApp帐户和关联资源组)。</block>
  <block id="60d5826756f013d28eadac75aec57698" category="list-text">创建一个或多个备份策略、用于管理资源组备份的保留、频率和其他设置。</block>
  <block id="6ad3833cba216d2fe6639be4726ad69e" category="list-text">创建一个容器以添加一个或多个需要使用备份策略进行保护的资源。</block>
  <block id="f0c88a652a15d9fedafa82483a1959b4" category="list-text">如果发生故障、请将整个虚拟机或特定的各个VMDK还原到同一位置。</block>
  <block id="52c902402ab9b60471632cf95f1940b6" category="admonition">借助Azure NetApp Files Snapshot技术、备份和恢复速度非常快。</block>
  <block id="08042ba10c942968c10ed6576a20c1e6" category="paragraph"><block ref="08042ba10c942968c10ed6576a20c1e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3a1d923fd4fc5d2bc1c7e9ac58f59ef" category="example-title">使用Azure NetApp Files 、Jetstream DR和Azure VMware解决方案 进行灾难恢复</block>
  <block id="93460124cbffe590c9cee7667d85d1da" category="paragraph">将灾难恢复到云是一种弹性且经济高效的方式、可保护工作负载免受站点中断和数据损坏事件(例如勒索软件)的影响。使用VMware VAIO框架、可以将内部VMware工作负载复制到Azure Blob存储并进行恢复、从而最大限度地减少或接近无数据丢失、并实现近乎零的RTO。可以使用Jetstream DR无缝恢复从内部复制到AVS、特别是复制到Azure NetApp Files 的工作负载。它通过在灾难恢复站点使用最少的资源和经济高效的云存储来实现经济高效的灾难恢复。Jetstream DR可通过Azure Blob Storage自动恢复到ANF数据存储库。Jetstream灾难恢复可根据网络映射将独立的VM或相关VM组恢复到恢复站点基础架构中、并提供时间点恢复以实现勒索软件保护。</block>
  <block id="8b8adea1567023f8a36745e1e256b41e" category="inline-link-macro">DR解决方案 与ANF、Jetstream和AVS</block>
  <block id="adeb8aee914844a07a855dd7b8fe7ffc" category="paragraph"><block ref="d016a1e57ae2464bcf00474caa126151" category="inline-link-macro-rx"></block>。</block>
  <block id="fcee9cbc5f0c4f0ed62751d0d5f181ef" category="doc">采用VMware解决方案的NetApp混合多云</block>
  <block id="980ba21a8b1f775a9fae0552d8594171" category="doc">NetApp混合多云与VMware概述</block>
  <block id="6e74d566879067f078b210f01e393989" category="paragraph">从高层面来看、此架构(如下图所示)介绍了如何使用NetApp Cloud Volumes ONTAP 、Cloud Volumes Service for Google Cloud和Azure NetApp Files 作为额外的子系统内存储选项、在多个云提供商之间实现混合多云连接和应用程序可移植性。</block>
  <block id="3fe4ff67f6902f4d03e2aff729e6ca40" category="cell">2022年7月21日</block>
  <block id="c1cb2a6b83f79bd02d9023a9dc25d399" category="cell">为AVS添加了具有CVO和Jetstream功能的DR解决方案 (子系统连接存储)</block>
  <block id="ac0f5de8cc00db2cb13da85ebd7e8780" category="cell">2022年6月10日</block>
  <block id="e92ea8797c2bfc161566c53da6321114" category="cell">增加了AVS与ANF原生 数据存储库概述以及使用Jetstream进行灾难恢复</block>
  <block id="b481ba8b3ad7fbb6a9786c9907a7c1ba" category="cell">添加了适用于采用VMware的NetApp混合多云的NFS数据存储库的区域可用性列表</block>
  <block id="27f04e57a2bba90c65656f5f47785def" category="open-title">采用VMware的混合多云</block>
  <block id="24fef7dbaeab186ae1ddf8a1fa31ef68" category="cell">在混合多云模式下定义NetApp—包括公有 云中的VMware和每个超大规模云中的NetApp存储选项。混合多云登录页面提供了内容专用的"板块"中的热门内容。</block>
  <block id="91ef1e01c1592f4e80d47d11c68ddf5c" category="inline-link-macro">采用VMware内容的混合多云</block>
  <block id="356bcf8558d9911b876554df23345496" category="cell"><block ref="356bcf8558d9911b876554df23345496" category="inline-link-macro-rx"></block></block>
  <block id="9c155d9143dcac03a6b69afd6ec499b0" category="open-title">混合多云</block>
  <block id="749354a37dc4552d3c41bbf24ba08598" category="sidebar">适用于VMC的NetApp混合多云与VMware</block>
  <block id="045ec2e9b9dff589c32c257549300273" category="sidebar">CVO作为来宾连接存储</block>
  <block id="ff106355f094608231dc8d7116a273e1" category="sidebar">适用于VMC的混合多云解决方案</block>
  <block id="0ab50f8c17f87a8eecee4603b22f16c8" category="sidebar">适用于AVS的NetApp混合多云与VMware</block>
  <block id="5ab938ef85bdfd3c94e8c4c5f1cfa448" category="sidebar">ANF作为来宾连接存储</block>
  <block id="5ab22899d20e83b71d3c1cbbedea208e" category="sidebar">适用于AVS的混合多云解决方案</block>
  <block id="9fe80f9f1edda788e503795e34b7eb80" category="sidebar">适用于GCVE的NetApp混合多云与VMware</block>
  <block id="f0476be9310e3a4606daded5c91d346f" category="sidebar">CVS作为来宾连接存储</block>
  <block id="e809dfa83f36389270c46ad868461471" category="sidebar">适用于GCVE的混合多云解决方案</block>
  <block id="d4cc78732ab0fdcd767ab42a015d34e0" category="sidebar">安全概述—Google Cloud中的NetApp CVS</block>
  <block id="538d26f438b9f54f2e02fe3eff3093f8" category="sidebar">采用VMware的NetApp混合多云</block>
  <block id="a3e69dd4d9f892aab0dcbf0a5dd246e2" category="cell">1.4及更高版本</block>
  <block id="f78d920d9d248820ddf7a3acdd9a34c0" category="doc">采用Tanzu的VMware vSphere概述</block>
  <block id="bac31e763c1b2955be0a10de0a4d8012" category="image-alt">采用Kubernetes的VMware vSphere</block>
  <block id="c2e55cf1007600b25e0708bfe26a41f3" category="paragraph">与原生 TKGS集群一样、在工作负载管理下启用了具有Tanzu环境的VMware vSphere。</block>
  <block id="9ff6aa8ffa487db2f0aebe3967972d77" category="image-alt">监控集群</block>
  <block id="b3ba0fe968ce39dcfc6fe8cc0f1b02da" category="image-alt">命名空间</block>
  <block id="516a32af5ad38dd3b9ca9c156da39add" category="inline-link-macro">采用Tanzu的VMware vSphere (vSphere Pod)</block>
  <block id="a6726486b20bc2510c7d0b189955e69c" category="list-text"><block ref="a6726486b20bc2510c7d0b189955e69c" category="inline-link-macro-rx"></block></block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">随着客户认识到Splunk数据分析的强大功能和易用性、他们自然希望为不断增长的数据量编制索引。随着数据量的增长、为数据提供服务所需的计算和存储基础架构也在增长。</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">智能分层并节省成本</block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">随着客户认识到Splunk数据分析的强大功能和易用性、他们自然希望为不断增长的数据量编制索引。随着数据量的增长、为数据提供服务所需的计算和存储基础架构也在增长。由于引用旧数据的频率较低、因此、投入相同数量的计算资源并消耗昂贵的主存储的效率越来越低。为了实现大规模运营、客户可以将热数据迁移到更经济高效的层、从而腾出计算和主存储来存储热数据。</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">采用StorageGRID 的Splunk SmartStore为组织提供了一个可扩展、性能出色且经济高效的解决方案。由于SmartStore具有数据感知功能、因此它会自动评估数据访问模式、以确定哪些数据需要访问以进行实时分析(热数据)、哪些数据应驻留在成本较低的长期存储(热数据)中。智能商店动态、智能地使用行业标准AWS S3 API、将数据放置在StorageGRID 提供的S3存储中。StorageGRID 灵活的横向扩展架构可使热数据层根据需要经济高效地增长。StorageGRID 基于节点的架构可确保以最佳方式满足性能和成本要求。</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">下图显示了Splunk和StorageGRID 分层。</block>
  <block id="821f09f0a5870b1dd3ee40e65f17b546" category="paragraph"><block ref="821f09f0a5870b1dd3ee40e65f17b546" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">行业领先的Splunk SmartStore与NetApp StorageGRID 相结合、可通过全堆栈解决方案 实现分离架构的优势。</block>
  <block id="f362fde28c17f629ded4d965d576f423" category="summary">Splunk Enterprise是市场领先的解决方案 、推动安全、IT和开发运营团队取得成果。Splunk的使用在我们客户的组织中显著增加。因此、需要添加更多数据源、同时将数据保留更长时间、从而给Splunk基础架构带来压力。</block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">Splunk SmartStore和NetApp StorageGRID 相结合、旨在为企业提供一个可扩展的架构、从而通过SmartStore和StorageGRID 对象存储提高载入性能、并提高Splunk环境在多个地理区域的可扩展性。</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="list-text">NetApp StorageGRID 文档资源</block>
  <block id="68d4d5362a15088f2ac3fa494c971af5" category="inline-link"><block ref="68d4d5362a15088f2ac3fa494c971af5" category="inline-link-rx"></block></block>
  <block id="580c43c30953ec671dd4a70120e1b513" category="paragraph"><block ref="580c43c30953ec671dd4a70120e1b513" category="inline-link-rx"></block></block>
  <block id="2e85fc867cab94d246e0bf6043b361cd" category="paragraph"><block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="list-text">Splunk Enterprise文档</block>
  <block id="f710d46c12a05abcfde056d779cb608c" category="inline-link"><block ref="f710d46c12a05abcfde056d779cb608c" category="inline-link-rx"></block></block>
  <block id="2ab8bf37a62983163c96b3c2f9a275d4" category="paragraph"><block ref="2ab8bf37a62983163c96b3c2f9a275d4" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="list-text">Splunk Enterprise关于SmartStore</block>
  <block id="98bda64923adc1da4a0e009dd52832a4" category="inline-link"><block ref="98bda64923adc1da4a0e009dd52832a4" category="inline-link-rx"></block></block>
  <block id="86d261d18a8cb6ce8f95f58af41452e5" category="paragraph"><block ref="86d261d18a8cb6ce8f95f58af41452e5" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="list-text">Splunk Enterprise分布式部署手册</block>
  <block id="048c67f334d3e1bbcb765e563d076b7d" category="inline-link"><block ref="048c67f334d3e1bbcb765e563d076b7d" category="inline-link-rx"></block></block>
  <block id="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="paragraph"><block ref="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="list-text">Splunk Enterprise管理索引器和索引器集群</block>
  <block id="87fbe590fc8f855078f14ba53325eb46" category="inline-link"><block ref="87fbe590fc8f855078f14ba53325eb46" category="inline-link-rx"></block></block>
  <block id="d0438efbc1a0dbee965023150ccf9334" category="paragraph"><block ref="d0438efbc1a0dbee965023150ccf9334" category="inline-link-rx"></block></block>
  <block id="881214767967db331c99550277ceb793" category="summary">此页面介绍了Splunk架构、包括关键定义、Splunk分布式部署、Splunk SmartStore、数据流、 硬件和软件要求、单站点和多站点要求等。</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Splunk架构</block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">关键定义</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">下面两个表列出了分布式Splunk部署中使用的Splunk和NetApp组件。</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">此表列出了分布式Splunk Enterprise配置的Splunk硬件组件。</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Splunk组件</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">索引器</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Splunk Enterprise数据存储库</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">通用转发器</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">负责载入数据并将数据转发给索引器</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">搜索头</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">用于在索引器中搜索数据的用户前端</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">集群主节点</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">管理索引器和搜索头的Splunk安装</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">监控控制台</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">在整个部署中使用集中式监控工具</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">许可证主节点</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">许可证主节点负责处理Splunk Enterprise许可</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">部署服务器</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">更新配置并将应用程序分发到处理组件</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">存储组件</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">用于管理热层数据的全闪存存储。也称为本地存储。</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">用于管理热层数据的S3对象存储。由SmartStore用于在热层和热层之间移动数据。也称为远程存储。</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">此表列出了Splunk存储架构中的组件。</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">负责的组件</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">智能存储</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">使索引器能够将数据从本地存储分层到对象存储。</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">热</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">通用转发器放置新写入数据的登录点。存储是可写的、数据是可搜索的。此数据层通常由SSD或快速HDD组成。</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">缓存管理器</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">管理索引数据的本地缓存、在执行搜索时从远程存储提取热数据、并从缓存中提取最不常用的数据。</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">暖</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">数据会从逻辑上滚动到存储分段、并首先从热分层重命名为热分层。此层中的数据受保护、与热层一样、可由容量更大的SSD或HDD组成。使用通用数据保护解决方案支持增量备份和完整备份。</block>
  <block id="392d70ca39f31f10bd637936769788df" category="cell">StorageGRID</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Splunk分布式部署</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">要支持数据源自多台计算机的大型环境、您需要处理大量数据。如果许多用户需要搜索数据、您可以通过在多台计算机之间分布Splunk Enterprise实例来扩展部署。这称为分布式部署。</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">在典型的分布式部署中、每个Splunk Enterprise实例都会执行一项专用任务、并驻留在与主要处理功能对应的三个处理层中的一个上。</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">下表列出了Splunk Enterprise处理层。</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">层</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">数据输入</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">转发器</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">转发器使用数据、然后将数据转发到一组索引器。</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">索引编制</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">索引器为通常从一组转发器接收的传入数据编制索引。索引器将数据转换为事件并将事件存储在索引中。索引器还会根据搜索头发出的搜索请求搜索索引数据。</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">搜索管理</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">搜索头可用作搜索的中央资源。集群中的搜索头可以互换、并且可以从搜索头集群的任何成员访问相同的搜索、信息板、知识对象等。</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">下表列出了分布式Splunk Enterprise环境中使用的重要组件。</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">责任</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">索引集群主节点</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">协调索引器集群的活动和更新</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">索引管理</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">索引集群</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">一组Splunk Enterprise索引器、这些索引器配置为相互复制数据</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">搜索头部署程序</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">处理集群主节点的部署和更新</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">搜索头管理</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">搜索头集群</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">作为搜索中央资源的一组搜索头</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">负载平衡器</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">由集群组件使用、以满足搜索头、索引器和S3目标在集群组件之间分布负载的日益增长的需求。</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">集群组件的负载管理</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">了解Splunk Enterprise分布式部署的以下优势：</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">访问多种或分散的数据源</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">提供各种功能来满足任何规模和复杂性的企业的数据需求</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">通过数据复制和多站点部署实现高可用性并确保灾难恢复</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Splunk SmartStore</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore是一种索引器功能、可使Amazon S3等远程对象存储存储存储存储索引数据。随着部署的数据量的增加、对存储的需求通常会超过对计算资源的需求。通过SmartStore、您可以单独扩展索引器存储和计算资源、从而经济高效地管理这些资源。</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore引入了一个远程存储层和一个缓存管理器。这些功能允许数据驻留在索引器本地或远程存储层上。缓存管理器可管理索引器与远程存储层之间的数据移动、而远程存储层是在索引器上配置的。</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">借助SmartStore、您可以将索引器的存储占用空间降至最低、并选择I/O优化的计算资源。大多数数据驻留在远程存储上。索引器会维护一个本地缓存、其中包含的数据量极少：热分段、参与活动或近期搜索的热分段副本以及分段元数据。</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Splunk SmartStore数据流</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">当从各种源传入的数据到达索引器时、将为数据编制索引并将其保存在本地的热分段中。索引器还会将热分段数据复制到目标索引器。到目前为止、数据流与非SmartStore索引的数据流相同。</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">当热分段转至热状态时、数据流将会分散。源索引器会将热分段复制到远程对象存储(远程存储层)、而将现有副本保留在其缓存中、因为搜索往往会在最近编制索引的数据中运行。但是、目标索引器会删除其副本、因为远程存储可提供高可用性、而无需维护多个本地副本。存储分段的主副本现在位于远程存储中。</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">下图显示了Splunk SmartStore数据流。</block>
  <block id="9fb3b10aa394792f93ac799606bd8ed5" category="paragraph"><block ref="9fb3b10aa394792f93ac799606bd8ed5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">索引器上的缓存管理器是SmartStore数据流的核心。它会根据需要从远程存储提取分段副本以处理搜索请求。它还会从缓存中检索旧的或搜索较少的存储分段副本、因为它们参与搜索的可能性会随着时间的推移而降低。</block>
  <block id="715f39bb7952ceb84a6bd1bb44c1ac4d" category="paragraph">缓存管理器的任务是优化可用缓存的使用、同时确保搜索能够立即访问所需的存储分段。</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">下表列出了实施解决方案 所需的软件组件。在任何解决方案实施中使用的软件组件可能会因客户要求而异。</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">产品系列</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">产品名称</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">产品版本</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">StorageGRID 对象存储</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11.6.</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Enterprise</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">采用SmartStore的Splunk Enterprise</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">单站点和多站点要求</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">在企业Splunk环境(大中型部署)中、数据来源于多台计算机、许多用户需要搜索数据、您可以通过在单个和多个站点之间分布Splunk Enterprise实例来扩展部署。</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">下表列出了分布式Splunk Enterprise环境中使用的组件。</block>
  <block id="1fbd0b2f11fe7779db6380b6d09478df" category="cell">一组Splunk Enterprise索引器、这些索引器已配置为相互复制数据</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">负载平衡器</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">集群组件的负载管理</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">此图显示了一个单站点分布式部署示例。</block>
  <block id="733ecc3327823660187d1d7d76df7079" category="paragraph"><block ref="733ecc3327823660187d1d7d76df7079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">此图显示了一个多站点分布式部署示例。</block>
  <block id="d10d5e57a05119c14c599013d15d6553" category="paragraph"><block ref="d10d5e57a05119c14c599013d15d6553" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">下表列出了实施解决方案 所需的最低硬件组件数量。解决方案的特定实施中使用的硬件组件可能会因客户要求而异。</block>
  <block id="40b955882ffd3093985177c3721cfed2" category="admonition">无论您是在单个站点还是在多个站点中部署了Splunk SmartStore和StorageGRID 、所有系统都通过StorageGRID 网格管理器在一个管理平台中进行管理。有关详细信息、请参见"使用网格管理器进行简单管理"一节。</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">此表列出了单个站点使用的硬件。</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">Disk</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">可用容量</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">注意</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">管理节点和负载平衡器</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">X48、8 TB (NL-SAS HDD)</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1 PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">远程存储</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">此表列出了多站点配置(每个站点)所使用的硬件。</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">管理节点和负载平衡器</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">NetApp StorageGRID 负载平衡器：SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">对象存储需要使用负载平衡器来呈现云存储命名空间。StorageGRID 支持F5和Citrix等领先供应商的第三方负载平衡器、但许多客户选择企业级StorageGRID 平衡器来实现精简性、故障恢复能力和高性能。StorageGRID 负载平衡器可用作VM、容器或专用设备。</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">StorageGRID SG1000有助于在S3数据路径连接中使用高可用性(High Availability、HA)组和智能负载平衡。任何其他内部对象存储系统都无法提供自定义的负载平衡器。</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">SG1000设备可提供以下功能：</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">负载平衡器以及可选的管理节点可用于StorageGRID 系统</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">StorageGRID 设备安装程序、用于简化节点部署和配置</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">简化了S3端点和SSL的配置</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">专用带宽(而不是与其他应用程序共享第三方负载平衡器)</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">最多4个100 Gbps聚合以太网带宽</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">下图显示了SG1000网关服务设备。</block>
  <block id="3e44556364ce6907a44a9fb5c09eab69" category="paragraph"><block ref="3e44556364ce6907a44a9fb5c09eab69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="section-title">SG6060</block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">StorageGRID SG6060设备包括一个计算控制器(SG6060)和一个存储控制器架(E系列E2860)、其中包含两个存储控制器和60个驱动器。此设备可提供以下功能：</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">在一个命名空间中最多可扩展到400 PB。</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">高达4倍的25 Gbps聚合以太网带宽。</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">包括StorageGRID 设备安装程序、用于简化节点部署和配置。</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">每个SG6060设备可以有一个或两个额外的扩展架、总共可容纳180个驱动器。</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">两个E系列E2800控制器(双工配置)、用于提供存储控制器故障转移支持。</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">五抽盒驱动器架、可容纳60个3.5英寸驱动器(两个固态驱动器和58个NL-SAS驱动器)。</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">下图显示了SG6060设备。</block>
  <block id="8d3bb0a39a1d477f7f0b8789769c96c5" category="paragraph"><block ref="8d3bb0a39a1d477f7f0b8789769c96c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Splunk设计</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">下表列出了单个站点的Splunk配置。</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">核心</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16个核心</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32 GB RAM</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">管理用户数据</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">用户前端在索引器中搜索数据</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">处理搜索头集群的更新</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">管理Splunk安装和索引器</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">监控控制台和许可证主节点</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">对整个Splunk部署执行集中监控、并管理Splunk许可证</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">下表介绍了多站点配置的Splunk配置。</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">此表列出了多站点配置(站点A)的Splunk配置。</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">负责载入数据并将数据转发给索引器。</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">对整个Splunk部署执行集中监控、并管理Splunk许可证。</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">此表列出了多站点配置(站点B)的Splunk配置。</block>
  <block id="722462e25c63551f73985fc89f6a2139" category="summary">解决方案 允许添加计算、热存储或S3资源、以满足单站点和多站点部署中不断增长的用户数量或载入率需求。</block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*性能。* Splunk SmartStore和NetApp StorageGRID 相结合、可以使用对象存储在热分段和热分段之间快速迁移数据。StorageGRID 通过为大型对象工作负载提供快速性能、大幅提升了迁移过程的性能。</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*多站点就绪。* StorageGRID 分布式架构允许Splunk SmartStore通过一个全局命名空间扩展单个站点和多个站点的部署、在该命名空间中、无论数据位于何处、均可从任何站点访问数据。</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*提高了可扩展性。*独立于计算资源扩展存储资源、以满足Splunk环境中不断变化的需求和需求、从而提高TCO。</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*容量。*通过将单个命名空间扩展到560 PB以上、利用StorageGRID 满足Splunk部署中快速增长的卷。</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*数据可用性。*优化数据可用性、性能、地理分布、保留、保护、 元数据驱动型策略可随着数据业务价值的发展动态调整、从而降低存储成本。</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Splunk提供的准则</block>
  <block id="29c3e2f956fc4b206ef3c7bbbb3730b0" category="paragraph">利用SmartStore缓存提高性能、SmartStore缓存是索引器的一个组件、用于在本地(热)存储和远程(热)存储之间传输存储分段副本。此解决方案 的Splunk规模估算基于<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block>。解决方案 允许添加计算、热存储或S3资源、以满足单站点和多站点部署中不断增长的用户数量或载入率需求。</block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">本技术报告概述了NetApp为Splunk SmartStore解决方案 提供的优势、同时演示了在您的环境中设计和调整Splunk SmartStore大小的框架。因此、解决方案 简单、可扩展且具有故障恢复能力、可提供极具吸引力的TCO。</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869：NetApp StorageGRID 与Splunk SmartStore</block>
  <block id="2dafc6e921d43527cceb2ba642abf973" category="paragraph">Karthikeyan Nagalingam、Bobby Oommen、Joseph Kdatilparambil</block>
  <block id="648e525fafbee4c7b749ab8740beb0d3" category="paragraph">Splunk Enterprise是市场领先的安全信息和事件管理(Security Information and Event Management、解决方案)、可推动安全、IT和开发运营团队取得成果。数据量继续呈指数级增长、为能够利用这一庞大资源的企业创造了巨大的机会。Splunk Enterprise继续在更广泛的使用情形中得到采用。随着使用情形的增加、Splunk Enterprise所载入和处理的数据量也会增加。Splunk Enterprise的传统架构采用分布式横向扩展设计、可提供出色的数据访问和可用性。但是、使用此架构的企业面临着与扩展以满足快速增长的数据量相关的成本不断增长的问题。</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">采用NetApp StorageGRID 的Splunk SmartStore提供了一种分离计算和存储的新部署模式、从而解决了这一挑战。此解决方案 还可以为Splunk企业环境提供无与伦比的扩展能力和弹性、支持客户跨单个和多个站点进行扩展、同时通过允许计算和存储独立扩展并为基于云的S3对象存储添加智能分层来降低成本。</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">解决方案 可优化本地存储中的数据量、同时保持搜索性能、从而可以根据需要扩展计算和存储。SmartStore会自动评估数据访问模式、以确定哪些数据需要访问以进行实时分析、哪些数据应驻留在成本较低的S3对象存储中。</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">本技术报告概述了NetApp为Splunk SmartStore解决方案 提供的优势、同时演示了在您的环境中设计和调整Splunk SmartStore大小的框架。因此、解决方案 简单、可扩展且具有故障恢复能力、可提供极具吸引力的TCO。StorageGRID 可提供基于S3协议/API的可扩展且经济高效的对象存储(也称为远程存储)、使企业能够以更低的成本扩展Splunk解决方案 、同时提高弹性。</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore将对象存储称为远程存储或远程存储层。</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">关于NetApp StorageGRID</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID 是一款软件定义的对象存储解决方案 、适用于大型归档、媒体存储库和Web数据存储。借助StorageGRID 、NetApp利用20年的丰富经验提供行业领先的创新和数据管理解决方案、同时帮助企业管理内部以及公有 、私有云或混合云部署中的信息并最大限度地发挥其价值。</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID 可为大规模非结构化数据提供安全，持久的存储。元数据驱动的集成生命周期管理策略可优化数据在整个生命周期中的位置。将内容放置在合适的位置，合适的时间和合适的存储层上，以降低成本。无论StorageGRID 存储的地理位置如何、单个命名空间都允许通过单个调用访问数据。客户可以在数据中心之间以及云基础架构中部署和管理多个StorageGRID 实例。</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">StorageGRID 系统由全球分布的冗余异构节点组成、这些节点可与现有客户端应用程序和下一代客户端应用程序集成。</block>
  <block id="5680b078511221b1538af544a52a477e" category="paragraph"><block ref="5680b078511221b1538af544a52a477e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape最近在最新报告《IDC MarketScape：2019年全球基于对象的存储供应商评估》中将NetApp评为领导者。StorageGRID 在要求最严苛的行业中部署了近20年的生产环境、是公认的非结构化数据领导者。</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">借助StorageGRID 、您可以实现以下目标：</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">部署多个StorageGRID 实例、以便通过一个可轻松扩展到数百PB的命名空间从数据中心和云之间的任何位置访问数据。</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">灵活地跨基础架构进行部署和集中管理。</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">利用分层擦除编码(EC)提供无与伦比的持久性和十五个九的持久性。</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">通过与Amazon S3 Glacier和Azure Blob的经验证集成、实现更多混合多云功能。</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">无需专有API或受制于供应商、即可通过防篡改数据保留来履行法规义务并促进合规。</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">NetApp StorageGRID 主页</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">有关StorageGRID 如何帮助您解决最复杂的非结构化数据管理问题的详细信息、请参见<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block>。</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">关于Splunk Enterprise</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise是一个将数据转化为业务的平台。日志文件、网站、设备、传感器和应用程序等各种源生成的数据会发送到Splunk索引器并由其进行解析、从而使您能够从这些数据中获得丰富的洞察力。它可能会发现数据泄露、指出客户和产品趋势、发现优化基础架构的机会、或者针对各种使用情形提供可操作的洞察力。</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">关于Splunk SmartStore</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore扩展了Splunk架构的优势、同时简化了其经济高效地扩展的能力。计算资源和存储资源的分离会导致索引器节点针对I/O进行优化、并显著降低存储需求、因为它们只会将一部分数据存储为缓存。如果只需要其中一种资源、则无需添加额外的计算或存储、这样可以显著节省成本。您可以使用经济高效且易于扩展的基于S3的对象存储、从而进一步简化环境、降低成本、并维护更大规模的数据集。</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore为企业带来了巨大的价值、其中包括：</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">通过将热数据迁移到经过成本优化的S3对象存储来降低存储成本</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">通过分离存储和计算实现无缝扩展</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">利用弹性云原生存储简化业务连续性</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">为了进一步增强端点配置， StorageGRID 提供了内置于管理节点中的流量分类策略，可用于监控工作负载流量，并对工作负载应用各种服务质量（ QoS ）限制。流量分类策略会应用于网关节点和管理节点的 StorageGRID 负载平衡器服务上的端点。这些策略可帮助您调整和监控流量。</block>
  <block id="7d68f597b217695f6702ae71ae4eb455" category="summary">StorageGRID 具有多种功能、用户可以根据不断变化的环境利用和自定义这些功能。从部署到扩展Splunk SmartStore、您的环境需要快速采用变更、并且不会对Splunk造成中断。您可以通过StorageGRID 灵活数据管理策略(ILM)和流量分类器(QoS)来规划和适应您的环境。</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">适用于Splunk SmartStore的灵活StorageGRID 功能</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">网格管理器是一个基于浏览器的图形界面、可用于在一个管理平台中跨全球分布的位置配置、管理和监控StorageGRID 系统、如下图所示。</block>
  <block id="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="paragraph"><block ref="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">使用网格管理器界面执行以下任务：</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">适用于Splunk的NetApp StorageGRID 应用程序</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">适用于Splunk的NetApp StorageGRID 应用程序是专为Splunk Enterprise设计的应用程序。此应用程序可与适用于Splunk的NetApp StorageGRID 附加软件结合使用。通过它可以查看StorageGRID 运行状况、帐户使用情况信息、安全审核详细信息、资源使用情况和监控等信息。</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">下图显示了适用于Splunk的StorageGRID 应用。</block>
  <block id="7c39625522ddbadc65ea87056e2d32c9" category="paragraph"><block ref="7c39625522ddbadc65ea87056e2d32c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">ILM策略</block>
  <block id="fce13f2ee25ffdd1859d6a17a94b0e73" category="paragraph">StorageGRID 具有灵活的数据管理策略、其中包括保留多个对象副本、并根据特定性能和数据保护要求使用2+1和4+2 (以及许多其他)等EC (纠删编码)方案来存储对象。随着工作负载和要求随时间的变化， ILM 策略也往往会随时间的变化而变化。修改 ILM 策略是一项核心功能，可使 StorageGRID 客户快速轻松地适应不断变化的环境。</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID 可通过添加更多节点来扩展性能，这些节点可以是 VM ，裸机或专用设备，例如 SG5712 ， SG5760 ， SG6060 或 SGF6024 。在我们的测试中、我们使用SG6060设备使用最小大小的三节点网格、从而超出了SmartStore的关键性能要求。随着客户利用更多索引器扩展Splunk基础架构、他们可以添加更多存储节点以提高性能和容量。</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">负载平衡器和端点配置</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">StorageGRID 中的管理节点提供了网格管理器 UI （用户界面）和 REST API 端点，用于查看，配置和管理 StorageGRID 系统，并可通过审核日志来跟踪系统活动。为了为Splunk SmartStore远程存储提供高可用性的S3端点、我们实施了StorageGRID 负载平衡器、该平衡器作为服务在管理节点和网关节点上运行。此外，负载平衡器还管理本地流量并与 GSLB （全局服务器负载平衡）进行通信，以帮助进行灾难恢复。</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">为了进一步增强端点配置、StorageGRID 提供了内置于管理节点中的流量分类策略、可用于监控工作负载流量、并对工作负载应用各种服务质量(QoS)限制。流量分类策略会应用于网关节点和管理节点的 StorageGRID 负载平衡器服务上的端点。这些策略有助于限制和监控流量。</block>
  <block id="b27064a5ca31ea524411e6ce281c8f0c" category="paragraph">NetApp为Splunk SmartStore提供了一个简单且可扩展的解决方案 、可最大限度地提高性能和故障恢复能力、同时提供极具吸引力的TCO。</block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">此页面介绍了用于完成此解决方案 的组件、包括NetApp StorageGRID 、Splunk Enterprise和Splunk SmartStore。</block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID 是一款高性能且经济高效的对象存储平台。它采用基于节点的分布式网格架构，提供智能的策略驱动型全局数据管理。它通过其无处不在的全局对象命名空间以及复杂的数据管理功能，简化了对数 PB 的非结构化数据和数十亿个对象的管理。单次调用对象访问可扩展到各个站点，并简化高可用性架构，同时确保无论站点或基础架构发生中断，都能持续访问对象。</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">多租户支持在同一网格中安全地处理多个云和企业非结构化数据应用程序、从而提高StorageGRID 的ROI并增加其用例。可以使用元数据驱动型对象生命周期策略创建多个服务级别，从而优化多个地理位置的持久性，保护，性能和位置。用户可以根据需求的变化无中断地调整策略和重新调整数据环境。</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore利用StorageGRID 作为远程存储层、并允许客户部署多个分布在不同地理位置的站点、以实现强大的可用性和持久性、并将其作为一个对象命名空间呈现。这样、Splunk SmartStore就可以利用StorageGRID 的高性能、高密度容量、并能够使用一个URL跨多个物理站点扩展到数百个节点以与对象交互。通过这一 URL ，即使在一个站点之外，存储扩展，升级和修复也不会造成中断。StorageGRID 独特的数据管理策略引擎可提供经过优化的性能和持久性级别、并可满足数据位置要求。</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunk是机器生成数据收集和分析领域的领导者、通过其运营分析功能帮助简化IT并实现现代化。它还扩展到业务分析、安全性和物联网用例。存储是成功部署Splunk软件的关键推动因素。</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">计算机生成的数据是增长最快的大数据类型。格式不可预测、并且来自许多不同的来源、通常采用高速率且数量巨大的格式。这些工作负载特征通常称为数字排气。Splunk SmartStore有助于理解这些数据、并提供智能数据分层、以便在最经济高效的存储层上优化热数据和热数据的放置。</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore是一种索引器功能、它使用StorageGRID 等对象存储(也称为远程存储或远程存储层)来使用S3协议存储热数据。</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">随着部署数据量的增加、对存储的需求通常会超过对计算机资源的需求。通过SmartStore、您可以通过单独扩展计算和存储来经济高效地管理索引器存储和计算资源。</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore引入了一个使用S3协议的远程存储层和一个缓存管理器。这些功能允许数据驻留在本地索引器或远程存储上。位于索引器上的缓存管理器可管理索引器与远程存储层之间的数据移动。数据与存储分段元数据一起存储在存储分段(热和热)中。</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">借助SmartStore、您可以将索引器的存储占用空间降至最低、并选择I/O优化的计算资源、因为大多数数据都驻留在远程存储层上。索引器会维护一个本地缓存、表示返回请求和预测的结果所需的最少数据量。本地缓存包含热分段、参与活动或近期搜索的热分段副本以及分段元数据。</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">借助采用StorageGRID 的Splunk SmartStore、客户可以利用高性能和经济高效的远程存储逐步扩展环境、同时为整个解决方案 提供高度的弹性。这样、无论客户是否需要更多索引器、更改数据保留、还是在不中断的情况下提高载入速率、客户都可以在任意给定时间添加任意给定数量的任何组件(热存储和/或热S3存储)。</block>
  <block id="5273463fa2459ed38da1af200de6f150" category="summary">此页面介绍了NetApp StorageGRID 控制器上的Splunk SmartStore性能。Splunk SmartStore可将热数据移动到远程存储、而远程存储是性能验证中的StorageGRID 对象存储。</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">单站点SmartStore性能</block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">本节介绍NetApp StorageGRID 控制器上的Splunk SmartStore性能。Splunk SmartStore可将热数据移动到远程存储、在这种情况下、是性能验证中的StorageGRID 对象存储。</block>
  <block id="1d01dcffdd1257afb01e4194d766d2f9" category="paragraph"><block ref="1d01dcffdd1257afb01e4194d766d2f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">我们将EF600用于热/缓存存储、而StorageGRID 6060用于远程存储。我们使用以下架构进行性能验证。我们使用了两个搜索头、四个重磅转发器将数据转发到索引器、使用七个Splunk事件生成器(Eventgens)生成实时数据、使用18个索引器存储数据。</block>
  <block id="a2fd19ff7e04cf04d5d99320b979cd00" category="paragraph"><block ref="a2fd19ff7e04cf04d5d99320b979cd00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">下表列出了用于SmartStorage性能验证的硬件。</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">重型转发器</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16个核心</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">SLED 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">用户前端在索引器中搜索数据</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">SmartStore远程存储性能验证</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">在此性能验证中、我们在所有索引器上的本地存储中配置了SmartStore缓存、用于存储10天的数据。我们在Splunk集群管理器中启用了`maxDataSize=auto`(750 MB存储分段大小)、并将更改推送到所有索引器。为了衡量上传性能、我们在10天内每天载入10 TB、并同时将所有热分段置于热状态、并从SmartStore监控控制台信息板中捕获每个实例和整个部署的峰值和平均吞吐量。</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">此图显示了一天内载入的数据。</block>
  <block id="c1b0c9568cd6b9bf236fb9566021d8a4" category="paragraph"><block ref="c1b0c9568cd6b9bf236fb9566021d8a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">我们从集群主节点运行以下命令(索引名称为`eventgen-test`)。然后、我们会通过SmartStore监控控制台信息板捕获每个实例和整个部署范围的峰值和平均上传吞吐量。</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">集群主节点可对所有索引器进行无密码身份验证(RTP-idx0001…RTP-idx0018)。</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">为了衡量下载性能、我们使用以下命令运行两次逐出命令行界面、从而将所有数据逐出缓存。</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">我们从集群主节点运行以下命令、并在StorageGRID 远程存储的10天数据之上从搜索头运行搜索。然后、我们会通过SmartStore监控控制台信息板捕获每个实例和整个部署范围的峰值和平均上传吞吐量。</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">索引器配置已从SmartStore集群主节点推送。集群主节点对索引器具有以下配置。</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">我们在搜索头上运行以下搜索查询以收集性能列表。</block>
  <block id="39b8fe84a2982bcbeb6d733343e0678d" category="paragraph"><block ref="39b8fe84a2982bcbeb6d733343e0678d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">我们从集群主节点收集性能信息。峰值性能为61.34 GBps。</block>
  <block id="0feb590fe449a8a847517a38f1e0415f" category="paragraph"><block ref="0feb590fe449a8a847517a38f1e0415f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">平均性能约为29 GBps。</block>
  <block id="2a1437158884c9696a6d4cac546972b1" category="paragraph"><block ref="2a1437158884c9696a6d4cac546972b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">StorageGRID 性能</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">Eventgen</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">SmartStore性能基于从大量数据中搜索特定模式和字符串。在此验证中、事件是使用生成的<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> 通过搜索头访问特定Splunk索引(eventgen-test)、对于大多数查询、此请求将转至StorageGRID。下图显示了查询数据的命中和未命中情况。命中数据来自本地磁盘、未命中数据来自StorageGRID 控制器。</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">绿色显示命中数据、橙色显示未命中数据。</block>
  <block id="0bf13ffd9c4e3655384eea9760fdd547" category="paragraph"><block ref="0bf13ffd9c4e3655384eea9760fdd547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">在StorageGRID 上运行查询以搜索时、下图显示了从StorageGRID 检索S3速率的时间。</block>
  <block id="5e789be14498e5bac09395d944ced093" category="paragraph"><block ref="5e789be14498e5bac09395d944ced093" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">StorageGRID 硬件使用情况</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">StorageGRID 实例具有一个负载平衡器和三个StorageGRID 控制器。所有这三个控制器的CPU利用率从75%到100%不等。</block>
  <block id="5c78f5ad926b76e88a749362fb6e3412" category="paragraph"><block ref="5c78f5ad926b76e88a749362fb6e3412" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">采用NetApp存储控制器的SmartStore—为客户带来优势</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*分离计算和存储。* Splunk SmartStore分离计算和存储、有助于您独立扩展。</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*按需提供数据。* SmartStore可使数据接近按需计算、并提供计算和存储弹性以及成本效益、从而实现更长的大规模数据保留时间。</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*符合AWS S3 API。* SmartStore使用AWS S3 API与还原存储进行通信、还原存储是一种符合AWS S3和S3 API的对象存储、例如StorageGRID。</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*降低了存储需求和成本。* SmartStore降低了旧数据(热/冷)的存储需求。它只需要一个数据副本、因为NetApp存储可提供数据保护、并可处理故障和高可用性。</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*硬件故障。* SmartStore部署中的节点故障不会使数据无法访问、并且可以更快地从硬件故障或数据不平衡中恢复索引器。</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">应用程序和数据感知缓存。</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">按需添加-删除索引器和设置-卸载集群。</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">存储层不再与硬件绑定。</block>
  <block id="f377bdd54f0f567b139a5913567466f1" category="paragraph">* VMware Tanzu Kubernetes Grid (TKG)*</block>
  <block id="7a3368d887604b1812f8f796b668f0e7" category="paragraph">* VMware Tanzu Kubernetes Grid Service (TKGS)*</block>
  <block id="8da30835717bc9e00a9ea2b89d75d943" category="paragraph">* VMware Tanzu Kubernetes Grid Integrated (TKGI)*</block>
  <block id="22bd1c4adfe1c3f7d3dc00763a7a8d40" category="paragraph">*采用Tanzu的vSphere (vSphere Pod)*</block>
  <block id="4f50bac068dbe84c04d257f75bb42142" category="list-text">vSphere本机Pod在基于光子的精简层中运行、并使用规定的虚拟硬件实现完全隔离。</block>
  <block id="c8cefb07aba3cc260670993281c9bef5" category="list-text">需要NSX-T、但这样可以支持其他功能、例如、一个存储映像注册表。</block>
  <block id="b603aa094817eb0510887a841cc71df8" category="list-text">使用TKGS等虚拟Supervisor集群在vSphere 7.0U1中部署和管理。直接在ESXi节点上运行Pod。</block>
  <block id="cf3b96589f75768a855cebe2679e5b8b" category="list-text">完全集成vSphere、可通过vSphere管理获得最高可见性和控制力。</block>
  <block id="3b050b735b1eb713cc1b3816851e3060" category="list-text">基于CRX的隔离POD可实现最高的安全性。</block>
  <block id="e7004adb0d2f74954305a1023249e642" category="list-text">对于永久性存储、仅支持vSphere CSI。不支持第三方存储编排程序。</block>
  <block id="90534ff553f8895d609b7e0cec5e7977" category="paragraph">Astra Trident是一款完全受支持的开源存储编排程序、适用于容器和Kubernetes分发版、包括VMware Tanzu。</block>
  <block id="25e19f6e213533d24e711ce5e6738fa9" category="paragraph">采用Tanzu的VMware vSphere (也称为vSphere Pod)允许您在裸机Kubernetes环境中使用VMware vSphere环境中的ESXi虚拟机管理程序节点作为工作节点。</block>
  <block id="c2556907e1f90b93c9c43e198113de8b" category="paragraph">创建虚拟化监控集群可为Kubernetes提供高可用性控制平台、并为每个应用程序创建个人命名空间、以确保为用户隔离资源。</block>
  <block id="9e2885b693a2045e931fda4aeb8bf28f" category="paragraph">启用带有Tanzu的VMware vSphere后、每个ESXi主机都安装并配置了Spherelet应用程序。这样、每个节点就可以在Kubernetes部署中充当辅助角色、并管理每个节点上部署的Pod。</block>
  <block id="c44d7c5351501c027261c0480a658d6d" category="paragraph">目前、采用Tanzu和vSphere Pod的VMware vSphere仅支持本地vSphere CSI驱动程序。这样、管理员就可以在vSphere客户端中创建存储策略、并从当前可用作vSphere数据存储库的存储目标中进行选择。这些策略用于为容器化应用程序创建永久性卷。</block>
  <block id="fe41e8fdcbc9d8447c9077fbd167fe8d" category="admonition">尽管目前不支持可直接连接到外部ONTAP 和Element存储阵列的NetApp Astra Trident CSI驱动程序、但这些NetApp存储系统通常用于支持vSphere环境的主存储、 NetApp高级数据管理和存储效率工具也可通过这种方式使用。</block>
  <block id="70aaffec040bcf9e5cf77c0ccabb8f11" category="paragraph">如果您想了解有关采用Tanzu的VMware vSphere的更多信息、请参见相关文档 <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>。</block>
  <block id="f0fa38f675f888f14af946299f91a36a" category="summary">VMware vSphere可在数据中心以及所有主要云提供商之间提供虚拟化基础架构。对于虚拟化计算保持一致的灾难恢复情形、无论位于何处、此生态系统都是理想之选。此解决方案 可在数据中心位置和AWS上的VMware云中使用VMware虚拟化计算资源。</block>
  <block id="c0b7ac0f313be4f2bef55fc6cf3a1947" category="paragraph">此解决方案 使用运行VMware vSphere v7.0U3的HPE DL360第10代服务器。我们部署了六个计算实例、以便为SQL服务器和Oracle服务器提供充足的资源。</block>
  <block id="ff1600196b624f9503bddaca0ce10f5d" category="paragraph">我们部署了10个运行SQL Server 2019的Windows Server 2019 VM、这些VM使用不同的数据库大小、另外还部署了10个运行Oracle 19c的Oracle Linux 8.5 VM和不同的数据库大小。</block>
  <block id="20f748e1f003c63ad3c63122e1629424" category="paragraph">我们在AWS上的VMware Cloud中部署了一个SDDC、其中包含两台主机、用于提供足够的资源来运行从主站点还原的虚拟机。</block>
  <block id="a84e981cfea0f9fca307649d4e7bd364" category="paragraph"><block ref="a84e981cfea0f9fca307649d4e7bd364" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f10db05e58b527be630ad143ec566a5" category="summary">本文档中介绍的使用情形侧重于经过验证的灾难恢复技术、这些技术突出了NetApp与VMware之间的集成。NetApp ONTAP 存储系统提供经验证的数据镜像技术、使企业能够设计涵盖领先云提供商所采用的内部和ONTAP 技术的灾难恢复解决方案。</block>
  <block id="86082b0bfc7279f0a1feebe1de23f618" category="paragraph">AWS上的ONTAP FSX就是这样一种解决方案 、它可以与SnapCenter 和SyncMirror 无缝集成、以便将应用程序数据复制到云。Veeam备份和复制是另一项众所周知的技术、可与NetApp ONTAP 存储系统完美集成、并可提供到vSphere原生 存储的故障转移。</block>
  <block id="81127e42ddbedbb1cad03bf70d694aa9" category="paragraph">此解决方案 使用托管SQL Server和Oracle应用程序数据的ONTAP 系统中的子系统连接存储提供了一个灾难恢复解决方案。采用SnapMirror的SnapCenter 提供了一个易于管理的解决方案 、用于保护ONTAP 系统上的应用程序卷、并将其复制到驻留在云中的FSX或CVO。SnapCenter 是一种支持灾难恢复的解决方案 、用于将所有应用程序数据故障转移到AWS上的VMware Cloud。</block>
  <block id="66e5d5ad5173b295e6b59ee5152216d0" category="list-text">指向解决方案 文档的链接</block>
  <block id="4f6300de9742001d9f7a797da5d53a27" category="paragraph"><block ref="4f6300de9742001d9f7a797da5d53a27" category="inline-link-rx"></block></block>
  <block id="6590e8ec3c5ce0748f55250c70ec048c" category="paragraph"><block ref="6590e8ec3c5ce0748f55250c70ec048c" category="inline-link-rx"></block></block>
  <block id="314695da56c7e601cdf6cfc3227858d9" category="paragraph">成功完成此解决方案 中所述的故障转移过程后、SnapCenter 和Veeam将恢复在AWS中运行的备份功能、而适用于ONTAP 的FSX现在已指定为主存储、并且与原始内部数据中心没有SnapMirror关系。在内部恢复正常功能后、您可以使用与本文档所述过程相同的过程将数据镜像回内部ONTAP 存储系统。</block>
  <block id="44ee07074aaf6f8c932889c7158c9906" category="paragraph">如本文档中所述、您还可以配置SnapCenter 、以便将应用程序数据卷从适用于ONTAP 的FSx镜像到驻留在内部的ONTAP 存储系统。同样、您也可以将Veeam配置为使用横向扩展备份存储库将备份副本复制到Amazon S3、以便驻留在内部数据中心的Veeam备份服务器可以访问这些备份。</block>
  <block id="fd41e9ec1db4527e12ae403974c6c63c" category="paragraph">故障恢复不在本文档的讨论范围内、但故障恢复与此处所述的详细过程差别不大。</block>
  <block id="cd39f47230bb959e72acb3eb9e5be469" category="paragraph">此解决方案 包含NetApp、VMware、Amazon Web Services (AWS)和Veeam的创新技术。</block>
  <block id="ded9cd19cde727f824d72e3ad8ef7662" category="section-title">VMware Cloud Foundation</block>
  <block id="66c9de10f8f96cbfebae805c8a5d0c23" category="paragraph">VMware Cloud Foundation平台集成了多种产品、可使管理员在异构环境中配置逻辑基础架构。这些基础架构(称为域)可在私有云和公有 云之间提供一致的操作。Cloud Foundation软件附带的材料清单可确定经过预先验证和认证的组件、以降低客户风险并简化部署。</block>
  <block id="6fa493c0540d656a06e5bc7de182aa5d" category="paragraph">Cloud Foundation BOM的组件包括以下内容：</block>
  <block id="ea712de8051099e742f7b2832804bbe4" category="list-text">Cloud Builder</block>
  <block id="719175eb8771501a012c6d964c29be69" category="list-text">SDDC管理器</block>
  <block id="beb9456af324db48fa76084e755d8d0b" category="list-text">VMware vCenter Server 设备</block>
  <block id="f7eea647714641318ee86fedbbed4691" category="list-text">VMware ESXi</block>
  <block id="4ef3d5ade4e00a1767e0cb9da8f6a895" category="list-text">VMware NSX</block>
  <block id="8b1198108d735d15d15ede582012a434" category="list-text">vRealize Automation</block>
  <block id="ea7e7011cc6c20fceefe3f63a6f66b73" category="list-text">vRealize Suite Lifecycle Manager</block>
  <block id="7b0dffec85c977f50577ae9e44323ccc" category="list-text">vRealize Log Insight</block>
  <block id="9170490ac213e0fff83de34c7e91bcae" category="inline-link">VMware Cloud Foundation文档</block>
  <block id="d48b3b75cdd9d69e243c551b712f75e8" category="paragraph">有关VMware Cloud Foundation的详细信息、请参见<block ref="c470e518572535c6a48639b6f7d6e5a7" category="inline-link-rx"></block>。</block>
  <block id="776e392281968fc227c904b7efb2c82d" category="paragraph">VMware vSphere是一个虚拟化平台、可将物理资源转换为计算、网络和存储池、以满足客户的工作负载和应用程序要求。VMware vSphere的主要组件包括：</block>
  <block id="ef424b79c70de97da1b97dc4f12fadee" category="list-text">* ESXi。*此VMware虚拟机管理程序支持对计算处理器、内存、网络和其他资源进行抽象化、并使其可供虚拟机和容器工作负载使用。</block>
  <block id="b061e8a5ed8a3a3c319736ff70d51a55" category="list-text">* vCenter。* VMware vCenter可为在虚拟基础架构中与计算资源、网络和存储进行交互提供集中管理体验。</block>
  <block id="d42d5a3f8818d925febb1ccce5b5ea10" category="paragraph">通过将NetApp ONTAP 与深度产品集成、强大的支持以及强大的功能和存储效率结合使用、客户可以充分发挥其vSphere环境的全部潜能、从而打造出强大的混合多云环境。</block>
  <block id="841d75538dc45858ed53ac16358cc7ad" category="paragraph">有关VMware vSphere的详细信息、请参见<block ref="e516b39e5a9a3597e0dc419e086e5395" category="inline-link-rx"></block>。</block>
  <block id="95d57daea7acbc2a7bbae6ded68ee952" category="paragraph">有关采用VMware的NetApp解决方案的详细信息、请参见<block ref="3137e9e57f0cd434b880b626db7b2f62" category="inline-link-rx"></block>。</block>
  <block id="3c7164d9420b263a215271d6db617f2b" category="paragraph">VMware NSX通常称为网络虚拟机管理程序、它采用软件定义的模型来连接虚拟化工作负载。VMware NSX在内部和AWS上的VMware Cloud中无处不在、它为客户应用程序和工作负载的网络虚拟化和安全性提供支持。</block>
  <block id="0b044c7db1e40b4d475fb5b8e225f65e" category="paragraph">有关VMware NSX的详细信息、请参见<block ref="24474a71eda89537e8233714a7d94cc5" category="inline-link-rx"></block>。</block>
  <block id="1299e00bdf464c0bee14fc2f6aab0f37" category="paragraph">近 20 年来， NetApp ONTAP 软件一直是 VMware vSphere 环境中的领先存储解决方案，并不断增加创新功能来简化管理，同时降低成本。将 ONTAP 与 vSphere 结合使用是一个很好的组合，可帮助您降低主机硬件和 VMware 软件支出。您还可以利用原生 存储效率、以更低的成本、稳定一致的高性能保护数据。</block>
  <block id="00f8f930135e2662dd01e1e4fc65ec48" category="paragraph">有关NetApp ONTAP 的详细信息、请参见<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>。</block>
  <block id="cc1cc96c6bd7a597d867c658bca3b7d2" category="section-title">适用于VMware的NetApp ONTAP 工具</block>
  <block id="f19b4defe5bd521861bd47f062cab40e" category="paragraph">适用于VMware的ONTAP 工具可将多个插件组合到一个虚拟设备中、从而为使用NetApp存储系统的VMware环境中的虚拟机提供端到端生命周期管理。适用于VMware的ONTAP 工具包括以下内容：</block>
  <block id="dd167aeb5a59f14930ce90d7b32a1310" category="list-text">*虚拟存储控制台(VSC)。*使用NetApp存储对VM和数据存储库执行全面的管理任务。</block>
  <block id="caba40f1f4e68f7405c7405bbdf4067a" category="list-text">*适用于ONTAP 的VASA Provider。*支持使用VMware虚拟卷(VVOL)和NetApp存储进行基于存储策略的管理(SPBM)。</block>
  <block id="52d97a7fde4d2984a3335c87380d5ab4" category="list-text">*存储复制适配器(SRA)*。与VMware Site Recovery Manager (SRM)结合使用时、在发生故障时恢复vCenter数据存储库和虚拟机。</block>
  <block id="829e52698f21d046badfc12c5846a723" category="paragraph">通过适用于VMware的ONTAP 工具、用户不仅可以管理外部存储、还可以与VVOL以及VMware Site Recovery Manager集成。这样可以更轻松地在vCenter环境中部署和操作NetApp存储。</block>
  <block id="88d6ca70545898ecc8709b701555225b" category="paragraph">有关适用于VMware的NetApp ONTAP 工具的详细信息、请参见<block ref="c1c4ef8e79ad3b0cab24049eb01885be" category="inline-link-rx"></block>。</block>
  <block id="805c9517e95d3e9efc4b46738ab825fc" category="section-title">NetApp SnapCenter</block>
  <block id="de29da4940709c9f9b03e3d597dcb7cd" category="paragraph">NetApp SnapCenter 软件是一款易于使用的企业平台，可安全地协调和管理应用程序，数据库和文件系统之间的数据保护。SnapCenter 可将这些任务卸载到应用程序所有者、而不会影响对存储系统上活动的监控和监管、从而简化备份、还原和克隆生命周期管理。通过利用基于存储的数据管理、SnapCenter 不仅可以提高性能和可用性、还可以缩短测试和开发时间。</block>
  <block id="a1f54fde77874bbd5be133ca3970d7e8" category="paragraph">适用于VMware vSphere的SnapCenter 插件支持对虚拟机(VM)、数据存储库和虚拟机磁盘(VMDK)执行崩溃状态一致和VM一致的备份和还原操作。它还支持SnapCenter 应用程序专用插件、以保护虚拟化数据库和文件系统的应用程序一致的备份和还原操作。</block>
  <block id="f655858b5e82a216de5b6aea071de457" category="paragraph">有关NetApp SnapCenter 的详细信息、请参见<block ref="aa600981aea381f09908ce10e8269417" category="inline-link-rx"></block>。</block>
  <block id="98c2040e71eaa6795dfe7287a8c6ad93" category="section-title">第三方数据保护</block>
  <block id="a03670ab805efda6af1029d0cc6ed56e" category="paragraph">Veeam备份和复制是一种适用于云、虚拟和物理工作负载的备份、恢复和数据管理解决方案。Veeam Backup &amp; Replication与NetApp Snapshot技术具有专门的集成、可进一步保护vSphere环境。</block>
  <block id="a174e33a347bdf86d254ef6b64ebb844" category="paragraph">有关Veeam Backup &amp; Replication的详细信息、请参见<block ref="ff5498b1e93a9fbc10c4f9b6c05db801" category="inline-link-rx"></block>。</block>
  <block id="e1d618f208de1e0652f995ea9ef70c8a" category="section-title">AWS身份和访问管理</block>
  <block id="72e3b385ab9dce0490acd4320d69b190" category="paragraph">AWS环境包含多种产品、包括计算、存储、数据库、网络、分析、 以及更多有助于解决业务挑战的功能。企业必须能够定义有权访问这些产品、服务和资源的人员。同样重要的是、确定允许用户在哪些条件下操作、更改或添加配置。</block>
  <block id="e0371101cd60437f116ae662823d656b" category="paragraph">AWS身份和访问管理(AWS Identity and Access Management、Aaim)提供了一个安全控制平台、用于管理对AWS服务和产品的访问。正确配置的用户、访问密钥和权限允许在AWS和Amazon FSX上部署VMware Cloud。</block>
  <block id="f97bd254f4560b300dffc1c8320c079a" category="paragraph">有关AIM"的详细信息、请参见<block ref="51dd129a9a709f0af102f91347214719" category="inline-link-rx"></block>。</block>
  <block id="f93a7ad035f2ab23b92d7f904c204a67" category="paragraph">基于 AWS 的 VMware 云通过优化对原生 AWS 服务的访问，将 VMware 企业级 SDDC 软件引入 AWS 云。VMware Cloud on AWS由VMware Cloud Foundation提供支持、它将VMware的计算、存储和网络虚拟化产品(VMware vSphere、VMware vSAN和VMware NSX)与VMware vCenter Server管理功能相集成、并经过优化、可在专用的弹性裸机AWS基础架构上运行。</block>
  <block id="21b9508ecf23f768b8172f58ec935a32" category="paragraph">有关AWS上的VMware Cloud的详细信息、请参见<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>。</block>
  <block id="4d82a1ec1af02725042c8c785564ee7a" category="section-title">适用于 NetApp ONTAP 的 Amazon FSX</block>
  <block id="5588d719a2e52cc2437eac404a5afac6" category="paragraph">适用于NetApp ONTAP 的Amazon FSx是一款功能全面且受全面管理的ONTAP 系统、可作为原生 AWS服务使用。它基于NetApp ONTAP 构建、可提供熟悉的功能、同时还可提供完全托管的云服务的简便性。</block>
  <block id="4f706209d760c6b9c796b171e747ba84" category="paragraph">适用于ONTAP 的Amazon FSX可为各种计算类型提供多协议支持、包括公有 云或内部环境中的VMware。适用于ONTAP 的Amazon FSX可用于当今的子系统连接用例以及技术预览版中的NFS数据存储库、支持企业从内部环境和云中利用熟悉的功能。</block>
  <block id="97461b19a572ee6589bfdc8bb87cf344" category="paragraph">有关适用于NetApp ONTAP 的Amazon FSX的详细信息、请参见<block ref="8010f27a5d53263c1742228bc262a2e3" category="inline-link-rx"></block>。</block>
  <block id="b7dd764025f54c4b3bccf4f05424bf77" category="doc">还原SQL Server应用程序数据</block>
  <block id="95f316bb0a092035f960a46cc12705d3" category="paragraph">以下过程提供了有关在发生灾难导致内部站点无法运行时如何在AWS的VMware云服务中恢复SQL Server的说明。</block>
  <block id="eb7b93b4aadbfaf4b78c0c4bfe125171" category="paragraph">假定已完成以下前提条件、才能继续执行恢复步骤：</block>
  <block id="aca50891060f7ebe7be1192b4a8b78ad" category="list-text">已使用Veeam Full Restore将Windows Server VM还原到VMware Cloud SDDC。</block>
  <block id="9731e8839876f65368eab4ef1eecdc20" category="inline-link-macro">SnapCenter 备份和还原过程摘要。</block>
  <block id="565a76f57020cb4db728d0a24384a0d9" category="section-title">VM：SQL Server VM的还原后配置</block>
  <block id="eface2367b3de31eee3102f62de9295d" category="paragraph">虚拟机还原完成后、您必须配置网络连接和其他项目、以便在SnapCenter 中重新发现主机虚拟机。</block>
  <block id="0a64ec0b8b14816ed47650a0096fd3b3" category="list-text">为管理和iSCSI或NFS分配新的IP地址。</block>
  <block id="8ceacb8e6c12d270f190550e317ed5be" category="list-text">将主机加入Windows域。</block>
  <block id="612dbb7fb61a87afcf471d797448e487" category="list-text">将主机名添加到DNS或SnapCenter 服务器上的hosts文件中。</block>
  <block id="21b91bc158a5a6579966133ece84f927" category="admonition">如果部署SnapCenter 插件时使用的域凭据与当前域不同、则必须在SQL Server VM上更改适用于Windows服务的插件的登录帐户。更改登录帐户后、重新启动SnapCenter SMCore、适用于Windows的插件和适用于SQL Server的插件服务。</block>
  <block id="0634c3a099feec2a74ff9c0751719ed6" category="admonition">要在SnapCenter 中自动重新发现还原的VM、FQDN必须与最初添加到内部SnapCenter 中的VM相同。</block>
  <block id="0d4bede73841f93a92c80d25b0194d1e" category="section-title">为SQL Server还原配置FSX存储</block>
  <block id="1a87030fb5d5a31f7bcfdfa68ade9691" category="paragraph">要完成SQL Server VM的灾难恢复还原过程、您必须断开与FSX集群的现有SnapMirror关系并授予对卷的访问权限。为此，请完成以下步骤：</block>
  <block id="4c9e09e4807ffb0a4456b29e6f9a4281" category="list-text">要中断SQL Server数据库和日志卷的现有SnapMirror关系、请从FSX命令行界面运行以下命令：</block>
  <block id="3d20282913974593577c784c3192e510" category="list-text">通过创建包含SQL Server Windows VM的iSCSI IQN的启动程序组来授予对LUN的访问权限：</block>
  <block id="d287a88d877191e5695e6e46cde801a3" category="list-text">最后、将LUN映射到刚刚创建的启动程序组：</block>
  <block id="e47557c42d0af2df20a15a19f84795ee" category="list-text">要查找路径名称、请运行`lun show`命令。</block>
  <block id="c38f08ac05515c2b594fc836b22181e0" category="section-title">设置Windows VM以进行iSCSI访问并发现文件系统</block>
  <block id="39eb9c3b6c8eb2106dcb06edfdbb6f65" category="list-text">在SQL Server VM中、设置iSCSI网络适配器、以便在VMware端口组上进行通信、该端口组已建立、并可连接到FSX实例上的iSCSI目标接口。</block>
  <block id="cf8c6b6b8c54ec784d05b5f092751a4d" category="list-text">打开iSCSI启动程序属性实用程序、并清除发现、收藏的目标和目标选项卡上的旧连接设置。</block>
  <block id="1a2e1a79fa495e5f511838af9609be4f" category="list-text">找到用于访问FSX实例/集群上的iSCSI逻辑接口的IP地址。您可以在AWS控制台中的Amazon FSx &gt; ONTAP &gt; Storage Virtual Machine下找到此选项。</block>
  <block id="d9401c99c6ddc6dbcd6070c357088cf5" category="paragraph"><block ref="d9401c99c6ddc6dbcd6070c357088cf5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba5037ceee608981a7684c3277ceca73" category="list-text">在发现选项卡中、单击发现门户、然后输入FSX iSCSI目标的IP地址。</block>
  <block id="49ba75dd04ab3da15488d6e271466575" category="paragraph"><block ref="49ba75dd04ab3da15488d6e271466575" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd6bd08689af39f12a04ce95acbaa7df" category="paragraph"><block ref="cd6bd08689af39f12a04ce95acbaa7df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="193f314b02dfe15e71a9ec5d16f5ce73" category="list-text">在目标选项卡上、单击连接、根据您的配置选择启用多路径、然后单击确定连接到目标。</block>
  <block id="8625607d58104640aa3cc3a687356560" category="paragraph"><block ref="8625607d58104640aa3cc3a687356560" category="inline-image-macro-rx" type="image"></block></block>
  <block id="907488914aeab882127886e6028b0ea0" category="list-text">打开计算机管理实用程序并使磁盘联机。确认它们保留的驱动器号与先前相同。</block>
  <block id="885afbf2d17d52ec64abfd147535488e" category="paragraph"><block ref="885afbf2d17d52ec64abfd147535488e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc8ec032118740c31355c3345d62bf4" category="section-title">连接SQL Server数据库</block>
  <block id="7f423619ca14c77f6b9db6f7bda8de76" category="list-text">从SQL Server VM中、打开Microsoft SQL Server Management Studio并选择Attach以开始连接到数据库的过程。</block>
  <block id="fd43b9851dc24c4889086cdc9afd2a3a" category="paragraph"><block ref="fd43b9851dc24c4889086cdc9afd2a3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8bff2998bccc1ca5a6d707233af02c9" category="list-text">单击添加并导航到包含SQL Server主数据库文件的文件夹、将其选中、然后单击确定。</block>
  <block id="f700bbcedcee0092e600d8527c84b19f" category="paragraph"><block ref="f700bbcedcee0092e600d8527c84b19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a827dff2feb3c6226fcac7b4b80a3cc8" category="list-text">如果事务日志位于单独的驱动器上、请选择包含事务日志的文件夹。</block>
  <block id="f42947d249de7e97db085085f542e3c4" category="list-text">完成后、单击确定以连接数据库。</block>
  <block id="74242a349c592d71e13c317715f21c6f" category="paragraph"><block ref="74242a349c592d71e13c317715f21c6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f8fd7fd0d8b19f4ee350fa3bfaca1ca" category="section-title">确认SnapCenter 与SQL Server插件的通信</block>
  <block id="b6c6326ece2d2042cc822762ac90932a" category="paragraph">将SnapCenter 数据库还原到其先前状态后、它会自动重新发现SQL Server主机。要使此操作正常运行、请记住以下前提条件：</block>
  <block id="db44d05563a2083dddeaf5a8c08c36b8" category="list-text">必须将SnapCenter 置于灾难恢复模式。可以通过Swagger API或Disaster Recovery下的Global Settings实现此目的。</block>
  <block id="f77564f6296c2b86366fa8c55cde3b3d" category="list-text">SQL Server的FQDN必须与内部数据中心中运行的实例相同。</block>
  <block id="7effb9a6b0bfb89f35e1496a0b8ee21c" category="list-text">必须断开原始SnapMirror关系。</block>
  <block id="25c898cf2666acc247fd6eda6262658f" category="list-text">必须将包含数据库的LUN挂载到SQL Server实例、并连接数据库。</block>
  <block id="9c7568e40b946736fc8b8e0b79f35603" category="paragraph">要确认SnapCenter 处于灾难恢复模式、请在SnapCenter Web客户端中导航到设置。转到全局设置选项卡、然后单击灾难恢复。确保启用"启用灾难恢复"复选框。</block>
  <block id="fa26a16fa4868aed3c0c634a2d7a27a5" category="paragraph"><block ref="fa26a16fa4868aed3c0c634a2d7a27a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba3ddc84b2f59fd2a102309365db81a" category="doc">使用Veeam完全还原还原应用程序VM</block>
  <block id="36dc3b29e336105b87846d5917f36466" category="section-title">创建备份存储库并从S3导入备份</block>
  <block id="bfa510d8cc1cb8902740f538c9871cd5" category="paragraph">从二级Veeam服务器导入S3存储的备份、并将SQL Server和Oracle VM还原到VMware Cloud集群。</block>
  <block id="e2f3927605d5be5f9e2924c7578d06ab" category="paragraph">要从内部横向扩展备份存储库中的S3对象导入备份、请完成以下步骤：</block>
  <block id="04e06ef7f33197a158ddc19d53c0d1a5" category="list-text">转到备份存储库、然后单击顶部菜单中的添加存储库以启动添加备份存储库向导。在向导的第一页上、选择对象存储作为备份存储库类型。</block>
  <block id="6206d8a7c31f00a44ec41ebae87e8b6b" category="paragraph"><block ref="6206d8a7c31f00a44ec41ebae87e8b6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4fcfafe3d4baedadc9910b99baf527a" category="list-text">选择Amazon S3作为对象存储类型。</block>
  <block id="293aed632d96ade5bfef832bcdc2cd1e" category="paragraph"><block ref="293aed632d96ade5bfef832bcdc2cd1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="698ebee929c01fad4c318876313789ab" category="list-text">从Amazon Cloud Storage Services列表中、选择Amazon S3。</block>
  <block id="12cfad41ab613d7744d12d07d4a556d4" category="paragraph"><block ref="12cfad41ab613d7744d12d07d4a556d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2639f2cf7409eb24ed59c46794f26c33" category="list-text">从下拉列表中选择预先输入的凭据、或者添加用于访问云存储资源的新凭据。单击下一步继续。</block>
  <block id="ca271cf67d4c973e828e31689285727f" category="paragraph"><block ref="ca271cf67d4c973e828e31689285727f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d158a2a4f2b2c9b52c009bfbd87668a" category="list-text">在存储分段页面上、输入数据中心、存储分段、文件夹以及任何所需选项。单击应用。</block>
  <block id="cf2158b0a3f58d891bcbc6031fde92d4" category="paragraph"><block ref="cf2158b0a3f58d891bcbc6031fde92d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5adae514074dc7c746819968e035e2a0" category="list-text">最后、选择完成以完成此过程并添加存储库。</block>
  <block id="076951b7756435f95654310ef960f866" category="section-title">从S3对象存储导入备份</block>
  <block id="397f99a04387aed7bca366a20084083f" category="paragraph">要从上一节中添加的S3存储库导入备份、请完成以下步骤。</block>
  <block id="6add4097706ff1ee04793b80b99c3980" category="list-text">在S3备份存储库中、选择导入备份以启动导入备份向导。</block>
  <block id="d2e0dedfd0a67b45116f5c02f41dfad6" category="paragraph"><block ref="d2e0dedfd0a67b45116f5c02f41dfad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f08dd57757030d81cfcdd38f9c443e05" category="list-text">为导入创建数据库记录后、在摘要屏幕上选择下一步、然后选择完成以启动导入过程。</block>
  <block id="dee3665bb9cd000955be1a118818554f" category="paragraph"><block ref="dee3665bb9cd000955be1a118818554f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4afd5477c1ce1473a255dee8ce524184" category="list-text">导入完成后、您可以将虚拟机还原到VMware Cloud集群中。</block>
  <block id="8f2cd7b75623b2421c1eaadd379ca431" category="paragraph"><block ref="8f2cd7b75623b2421c1eaadd379ca431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73fee194f5e4e8ac33d750244fe7ebd5" category="section-title">通过Veeam完全还原到VMware Cloud来还原应用程序VM</block>
  <block id="ec223385ec31537dfd3adc4f3f97735d" category="paragraph">要将SQL和Oracle虚拟机还原到AWS工作负载域/集群上的VMware Cloud、请完成以下步骤。</block>
  <block id="9085bbecf522e8f0cf0f7d5480dd7cd9" category="list-text">从Veeam主页页面中、选择包含导入备份的对象存储、选择要还原的VM、然后右键单击并选择还原整个VM。</block>
  <block id="5320e29249c22b00240fc3df301d60a6" category="paragraph"><block ref="5320e29249c22b00240fc3df301d60a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d53e507da99665f0cd76090f0c8b932" category="list-text">在完整虚拟机还原向导的第一页上、根据需要修改要备份的虚拟机、然后选择下一步。</block>
  <block id="118ea730c6c794b12c6da0062216053b" category="paragraph"><block ref="118ea730c6c794b12c6da0062216053b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93e4b62efeb3d091b37047e066e45da4" category="list-text">在还原模式页面上、选择还原到新位置或使用不同设置。</block>
  <block id="53ddd9505ead460715da91ab5ae479ae" category="paragraph"><block ref="53ddd9505ead460715da91ab5ae479ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faca70e3cfbddf72933acf5dcbedf4ff" category="list-text">在主机页面上、选择要将虚拟机还原到的目标ESXi主机或集群。</block>
  <block id="5c468616bb48a8d3a72e2b3f20932126" category="paragraph"><block ref="5c468616bb48a8d3a72e2b3f20932126" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ee5d8dddaf8720bc49f23dc8e19f11b" category="list-text">在Datastores页面上、为配置文件和硬盘选择目标数据存储库位置。</block>
  <block id="ae5ebb3a87f25b2bf09c963a4029e53a" category="paragraph"><block ref="ae5ebb3a87f25b2bf09c963a4029e53a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48d9c25678124f335015d969c2c7645f" category="list-text">在网络页面上、将虚拟机上的原始网络映射到新目标位置中的网络。</block>
  <block id="b33233fb74ffe76bde21729b21fde02d" category="paragraph"><block ref="b33233fb74ffe76bde21729b21fde02d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3d7fc3c9f85e5663d3361a9e999487c" category="paragraph"><block ref="b3d7fc3c9f85e5663d3361a9e999487c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511bf18240f9f57b5658a22974a640f0" category="list-text">选择是否扫描已还原的虚拟机中的恶意软件、查看摘要页面、然后单击完成以开始还原。</block>
  <block id="0e966aefc6e57da3e61d08eb83f8f9b7" category="summary">SnapCenter 可以更新主存储系统(主存储系统&gt;镜像)和二级存储系统(主存储系统&gt;存储)中的SnapMirror关系、以便进行长期归档和保留。为此、您必须使用SnapMirror在目标卷和源卷之间建立并初始化数据复制关系。</block>
  <block id="860d1fc24372044f6c88f15cea6b9155" category="doc">配置SnapMirror关系和保留计划</block>
  <block id="1888797bfba812a31bad2548f183ffe6" category="paragraph">源和目标ONTAP 系统必须位于使用Amazon VPC对等、传输网关、AWS Direct Connect或AWS VPN建立对等关系的网络中。</block>
  <block id="aa318628cbf2869d724b704d547dc8f4" category="paragraph">要在内部ONTAP 系统和FSX ONTAP 之间设置SnapMirror关系、需要执行以下步骤：</block>
  <block id="fbfcc1aa520560c558b69fb448e3e601" category="inline-link">适用于ONTAP 的FSx—ONTAP 用户指南</block>
  <block id="7ffc7a254a972aeb4df657be8d41c5a2" category="paragraph">请参见<block ref="67cdb2cad717abb12c965d934ae13809" category="inline-link-rx"></block> 有关使用FSX创建SnapMirror关系的详细信息、请参见。</block>
  <block id="cc9e567b33c3e82ac1b18f4780ca5f42" category="section-title">记录源和目标集群间逻辑接口</block>
  <block id="44c719fef7654c0f1aecbd77f14b9ab7" category="paragraph">对于驻留在内部的源ONTAP 系统、您可以从System Manager或命令行界面检索集群间LIF信息。</block>
  <block id="d3983f090ac28583ca4499e720c4cc25" category="list-text">在ONTAP 系统管理器中、导航到"网络概述"页面、然后检索类型为"集群间"的IP地址、这些IP地址配置为与安装了FSX的AWS VPC进行通信。</block>
  <block id="de45ac288e78c12d34318717ae7cacd8" category="paragraph"><block ref="de45ac288e78c12d34318717ae7cacd8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94cf5d813faccf347c0faaab27941922" category="list-text">要检索FSX的集群间IP地址、请登录到命令行界面并运行以下命令：</block>
  <block id="244c638485f1bcb26a0e966bd289e4a9" category="paragraph"><block ref="244c638485f1bcb26a0e966bd289e4a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce2dabb10080d128fabb2edc80a417a" category="section-title">在ONTAP 和FSX之间建立集群对等关系</block>
  <block id="84c8209b0c6f3e5e18c66f9f45cf5358" category="paragraph">要在ONTAP 集群之间建立集群对等关系、必须在另一对等集群中确认在发起ONTAP 集群上输入的唯一密码短语。</block>
  <block id="085f57325580b1a203343baf39c910d1" category="list-text">使用`cluster peer create`命令在目标FSX集群上设置对等关系。出现提示时、输入一个唯一的密码短语、稍后在源集群上使用该密码短语以完成创建过程。</block>
  <block id="475947ec353590c018e5b0d813538a84" category="list-text">在源集群上、您可以使用ONTAP 系统管理器或命令行界面建立集群对等关系。在ONTAP 系统管理器中、导航到"保护"&gt;"概述"、然后选择"对等集群"。</block>
  <block id="692ee36299ec8b049d7462a75dd1463a" category="paragraph"><block ref="692ee36299ec8b049d7462a75dd1463a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa5f33eeccc2dab1c1b6aba564ec238" category="list-text">在对等集群对话框中、填写所需信息：</block>
  <block id="28b3f47a49c9a2fb506879e23a7b1723" category="list-text">输入用于在目标FSX集群上建立对等集群关系的密码短语。</block>
  <block id="157bacc8ed48f5dc430560300ef9f5a5" category="list-text">选择`是`以建立加密关系。</block>
  <block id="70c324b6369e6cb6f4a8df99ac8b4b7e" category="list-text">输入目标FSX集群的集群间LIF IP地址。</block>
  <block id="c9af913b694e4e4dcce39b7e3a2eabd2" category="list-text">单击启动集群对等以完成此过程。</block>
  <block id="409a2deb1ca3f5fe6ad3f90977529965" category="paragraph"><block ref="409a2deb1ca3f5fe6ad3f90977529965" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b39da3667dd0f4cab32a9027eeadf60" category="list-text">使用以下命令从FSX集群验证集群对等关系的状态：</block>
  <block id="25ca322582650fd7d3732bea77176905" category="paragraph"><block ref="25ca322582650fd7d3732bea77176905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdf4cefe90737a4248cd083c1a1d2e36" category="section-title">建立SVM对等关系</block>
  <block id="4f194687804b9dff8219b58d47dc2a69" category="paragraph">下一步是在目标和源Storage Virtual Machine之间设置SVM关系、这些虚拟机包含将处于SnapMirror关系中的卷。</block>
  <block id="9bd0b716a7c6f7821d01f58d3576978d" category="list-text">在源FSX集群中、从CLI使用以下命令创建SVM对等关系：</block>
  <block id="1a82405201cf3be5b0f3f96ffb551406" category="list-text">在源ONTAP 集群中、接受与ONTAP 系统管理器或命令行界面的对等关系。</block>
  <block id="dd0f7f7da0626cbd138836fd072f65de" category="list-text">在ONTAP 系统管理器中、转到"保护"&gt;"概述"、然后在"Storage VM对等方"下选择"对等Storage VM"。</block>
  <block id="486b508476b1f8dff9a5314ac26e36e9" category="paragraph"><block ref="486b508476b1f8dff9a5314ac26e36e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8b0c3d15e3f1c8ecebfa725f753f98e7" category="list-text">在对等Storage VM的对话框中、填写必填字段：</block>
  <block id="b980118a5ade1402e409e2354f286c60" category="list-text">源Storage VM</block>
  <block id="2cb119a467d09216231bdf2ff83bfb5f" category="list-text">目标集群</block>
  <block id="1d1fa3ffdce0bd1d4a0faf3d15fb94f6" category="list-text">目标Storage VM</block>
  <block id="22a926c9631a59bce535d179c6f1f5ae" category="paragraph"><block ref="22a926c9631a59bce535d179c6f1f5ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52fee5b72c266bcf84963c260c8cf2ed" category="list-text">单击对等Storage VM以完成SVM对等过程。</block>
  <block id="332a29af91768111608bcb6bf43107e7" category="section-title">创建快照保留策略</block>
  <block id="b2659ce2591907c1c9269d82e68d8109" category="paragraph">SnapCenter 管理主存储系统上作为Snapshot副本存在的备份的保留计划。这是在SnapCenter 中创建策略时建立的。SnapCenter 不会管理二级存储系统上保留的备份的保留策略。这些策略通过在二级FSX集群上创建的SnapMirror策略单独管理、并与与与源卷具有SnapMirror关系的目标卷相关联。</block>
  <block id="1d64d8f27569c9f8182a6c536add0069" category="paragraph">创建SnapCenter 策略时、您可以选择指定一个二级策略标签、该标签将添加到创建SnapCenter 备份时生成的每个快照的SnapMirror标签中。</block>
  <block id="b3ca63efc1d304947f75061071da604c" category="admonition">在二级存储上、这些标签与与与目标卷关联的策略规则匹配、以便强制保留快照。</block>
  <block id="422f63101989fe9b50c840c82bb5fe9f" category="paragraph">以下示例显示了一个SnapMirror标签、该标签位于作为SQL Server数据库和日志卷每日备份策略一部分生成的所有快照上。</block>
  <block id="5f70d8aa597c91ed28f7be347e2fac0a" category="paragraph"><block ref="5f70d8aa597c91ed28f7be347e2fac0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5c9b73d439aa92ef011ebf02237c888" category="inline-link">SnapCenter 文档</block>
  <block id="2d0828fbc32c49aad5149bd71dd05ddf" category="paragraph">有关为SQL Server数据库创建SnapCenter 策略的详细信息、请参见<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>。</block>
  <block id="f508c027fda31d58c4677043e1a3eaa8" category="paragraph">您必须先创建一个SnapMirror策略、其中包含指定要保留的Snapshot副本数量的规则。</block>
  <block id="bb66348f31a358d5d6f969b7ab6ee82c" category="list-text">在FSX集群上创建SnapMirror策略。</block>
  <block id="e8d5c5ace79f3b8be2db75ba7135e0a8" category="list-text">向策略添加SnapMirror标签与SnapCenter 策略中指定的二级策略标签匹配的规则。</block>
  <block id="5a3507b9cf4dd4a569d2ffe314e6b7eb" category="paragraph">以下脚本提供了可添加到策略中的规则示例：</block>
  <block id="762402f82600698541f18b3a2f4ac8f4" category="admonition">为每个SnapMirror标签以及要保留的快照数量(保留期限)创建其他规则。</block>
  <block id="2f061612da9689d76bf56673168e2297" category="section-title">创建目标卷</block>
  <block id="3c09a07bfb806c844317f3b57d93a884" category="paragraph">要在FSX上创建一个目标卷、使其成为源卷中Snapshot副本的收件人、请在FSX ONTAP 上运行以下命令：</block>
  <block id="9a9f4d5cf2f4ccad396091e224e45c7e" category="section-title">在源卷和目标卷之间创建SnapMirror关系</block>
  <block id="dfceac14afc666c56290006c22ba8a0a" category="paragraph">要在源卷和目标卷之间创建SnapMirror关系、请在FSX ONTAP 上运行以下命令：</block>
  <block id="e3a7ebd416df655cee455d58e86e8477" category="section-title">初始化SnapMirror关系</block>
  <block id="a457a30bf4ecea53998aa344bee4329a" category="paragraph">初始化SnapMirror关系。此过程将启动从源卷生成的新快照、并将其复制到目标卷。</block>
  <block id="dcbabf28828ef9b03cf9856a74eedf64" category="summary">在此解决方案 中、SnapCenter 为SQL Server和Oracle应用程序数据提供应用程序一致的快照。此配置与SnapMirror技术相结合、可在内部AFF 和FSX ONTAP 集群之间提供高速数据复制。此外、Veeam Backup &amp; Replication还为我们的虚拟机提供备份和还原功能。</block>
  <block id="a7b22ebf343cad0f97e90df47a7d7f0c" category="paragraph">在本节中、我们将介绍用于备份和还原的SnapCenter 、SnapMirror和Veeam的配置。</block>
  <block id="66b3c7123c5d46e3d176f20cb0ede484" category="paragraph">以下各节介绍了在二级站点完成故障转移所需的配置和步骤：</block>
  <block id="b33c39866fb3627a46e2d343e5fcdb1a" category="list-text">在内部部署和配置Windows SnapCenter 服务器。</block>
  <block id="498fdd311192093265ba745435fc1476" category="doc">部署和配置Veeam Backup Server</block>
  <block id="48e37aaf43e2a1010e9e267340ce923e" category="inline-link">Veeam帮助中心技术文档</block>
  <block id="9e67d6bed8c55a98c2cfe02531c07393" category="paragraph">解决方案 中使用Veeam Backup &amp; Replication软件来备份我们的应用程序虚拟机、并使用Veeam横向扩展备份存储库(SVBR)将备份副本归档到Amazon S3存储分段。Veeam部署在此解决方案 的Windows服务器上。有关部署Veeam的具体指导、请参见<block ref="43bd82bcfa6fc650951eb1c3021cf923" category="inline-link-rx"></block>。</block>
  <block id="a2af8a9311b9c3a74f6418a81bb700d2" category="section-title">配置Veeam横向扩展备份存储库</block>
  <block id="b61099b9ef1858547775741cc632226a" category="paragraph">部署并许可软件后、您可以创建横向扩展备份存储库(SVBR)作为备份作业的目标存储。此外、还应包括一个S3存储分段作为异地VM数据的备份、以便进行灾难恢复。</block>
  <block id="b2fe763ad14c7947f74a8693fa06bf2b" category="paragraph">开始使用前、请参见以下前提条件。</block>
  <block id="e787194bd6ef5154135951b4ab7f0317" category="list-text">在内部ONTAP 系统上创建SMB文件共享、作为备份的目标存储。</block>
  <block id="1c2ed63d64d034cdd6fe30f769495f52" category="list-text">创建要包含在SOBR中的Amazon S3存储分段。这是用于异地备份的存储库。</block>
  <block id="e349d3884df12b302e0d564f4cf3dec4" category="section-title">将ONTAP 存储添加到Veeam</block>
  <block id="3f71ccdf6fe8797ee5930ef4b5a0eaf1" category="paragraph">首先、在Veeam中将ONTAP 存储集群和关联的SMB/NFS文件系统添加为存储基础架构。</block>
  <block id="dc14600d8d3627181cbe1757142b1c03" category="list-text">打开Veeam控制台并登录。导航到存储基础架构、然后选择添加存储。</block>
  <block id="a55b866e82b1226d8874e7d53e6e50a9" category="paragraph"><block ref="a55b866e82b1226d8874e7d53e6e50a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5bb1dc14738b469545970cd32668931f" category="list-text">在添加存储向导中、选择NetApp作为存储供应商、然后选择Data ONTAP。</block>
  <block id="391d2bf94e1387196a435da4f4f0af41" category="list-text">输入管理IP地址并选中NAS文件器复选框。单击下一步。</block>
  <block id="a8485af4e188b4009412f68ce18de31a" category="paragraph"><block ref="a8485af4e188b4009412f68ce18de31a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fab62b3f01af99a63f513f81f07f4c93" category="list-text">添加凭据以访问ONTAP 集群。</block>
  <block id="5e9ee6438a10072376c31e6014cef8c3" category="paragraph"><block ref="5e9ee6438a10072376c31e6014cef8c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f55d6a23cbf126acc9c5ca42a97be0fc" category="list-text">在NAS文件管理器页面上、选择要扫描的协议、然后选择下一步。</block>
  <block id="596ee09f3551be34368ba19aa36584cd" category="paragraph"><block ref="596ee09f3551be34368ba19aa36584cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="674fb2409a1f0a9e628bebcb470960cf" category="list-text">完成向导的"Apply"和"Summary"页面、然后单击"Finish"开始存储发现过程。扫描完成后、ONTAP 集群将与NAS存储器一起添加为可用资源。</block>
  <block id="dc2bb995c316bc90c4d3a169bbb877d5" category="paragraph"><block ref="dc2bb995c316bc90c4d3a169bbb877d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f9b12801eaee10c32275f4ee61916aa" category="list-text">使用新发现的NAS共享创建备份存储库。从备份基础架构中、选择备份存储库、然后单击添加存储库菜单项。</block>
  <block id="621999df528dc938edd5a395cf0df8f3" category="paragraph"><block ref="621999df528dc938edd5a395cf0df8f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="afc15a9e4c0cbbfa567d40414a9725a1" category="inline-link">Veeam文档</block>
  <block id="218b99cee35d61ca3e9cb2d068673d9a" category="list-text">按照"新建备份存储库向导"中的所有步骤创建存储库。有关创建Veeam备份存储库的详细信息、请参见<block ref="3932357efba07e37ed76091ad3c0260c" category="inline-link-rx"></block>。</block>
  <block id="b56272bcb8aa2b6cb2998d01ed46d1f8" category="paragraph"><block ref="b56272bcb8aa2b6cb2998d01ed46d1f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fdf6cc44242ceed0927b180d30e5e75" category="section-title">将Amazon S3存储分段添加为备份存储库</block>
  <block id="8c5c80325137d0f76fbe191272748ba6" category="paragraph">下一步是将Amazon S3存储添加为备份存储库。</block>
  <block id="6a1ed885510bb28a64f66f0870fbaa39" category="list-text">导航到备份基础架构&gt;备份存储库。单击添加存储库。</block>
  <block id="bf510a56b5d84298de7541e645b836b7" category="paragraph"><block ref="bf510a56b5d84298de7541e645b836b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021391ea3955cab71330e7a32f03333f" category="list-text">在添加备份存储库向导中、选择对象存储、然后选择Amazon S3。此时将启动"新建对象存储库"向导。</block>
  <block id="c1f1ad1062498b5eeb9d31293b71343c" category="paragraph"><block ref="c1f1ad1062498b5eeb9d31293b71343c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3a3eb593a619e4becab9e45b8f46652" category="list-text">提供对象存储库的名称、然后单击下一步。</block>
  <block id="97f3c4606f2c2ebb0ffadd0616b76446" category="list-text">在下一节中、提供您的凭据。您需要AWS访问密钥和机密密钥。</block>
  <block id="e561e4c61aaefae45d0344b4ce87f23b" category="paragraph"><block ref="e561e4c61aaefae45d0344b4ce87f23b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157669cd4d5a68c9ab9f3537a9e0ea33" category="list-text">加载Amazon配置后、选择您的数据中心、存储分段和文件夹、然后单击应用。最后、单击完成以关闭向导。</block>
  <block id="2e9f45d4556ef13d4724b6f93eea5fd3" category="section-title">创建横向扩展备份存储库</block>
  <block id="7d8f14e05d872984577255cdeb1f14ec" category="paragraph">现在、我们已将存储库添加到Veeam中、我们可以创建SOBR、以便自动将备份副本分层到异地Amazon S3对象存储以进行灾难恢复。</block>
  <block id="328e03460d532c3507b2a6ba6ce53438" category="list-text">在备份基础架构中、选择横向扩展存储库、然后单击添加横向扩展存储库菜单项。</block>
  <block id="3ffac3b915968cb75860eac6dcb2255b" category="paragraph"><block ref="3ffac3b915968cb75860eac6dcb2255b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="582671a9090106ace80b09bb160558c6" category="list-text">在New Scale-Out Backup Repository中、为SOBR提供一个名称、然后单击Next。</block>
  <block id="8f7df3cc6ed6758328582e4972dcb532" category="list-text">对于性能层、选择包含驻留在本地ONTAP 集群上的SMB共享的备份存储库。</block>
  <block id="2c4b66b86991d603fc9db639a47179f8" category="paragraph"><block ref="2c4b66b86991d603fc9db639a47179f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7362749638566881b7b5f8fe545c64e8" category="list-text">对于放置策略、根据您的要求选择数据位置或性能。选择"下一步"。</block>
  <block id="2d1b39bdffbca5df6978176960bb0148" category="list-text">对于容量层、我们使用Amazon S3对象存储扩展了SOBR。为了实现灾难恢复、请在创建备份后立即选择将其复制到对象存储、以确保及时交付我们的二级备份。</block>
  <block id="3a54badf400b7e061484dbadf3a19b19" category="paragraph"><block ref="3a54badf400b7e061484dbadf3a19b19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="248e4221544eda567f1dd23b587cec68" category="list-text">最后、选择应用并完成以完成创建SOBR。</block>
  <block id="97f8173a9f8ac774dbbb04ad209a46ee" category="section-title">创建横向扩展备份存储库作业</block>
  <block id="d7b3c8996a5cc044c6c1221d000a9d9b" category="inline-link">Veeam帮助中心技术文档</block>
  <block id="2b6483678eaaf63094c195aa8a37e401" category="paragraph">配置Veeam的最后一步是使用新创建的SOBR作为备份目标来创建备份作业。创建备份作业是任何存储管理员任务的正常组成部分、我们不会介绍此处的详细步骤。有关在Veeam中创建备份作业的详细信息、请参见<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>。</block>
  <block id="3bd61e230841633b4a28f6d2f882d50e" category="summary">对于确保在发生重大中断时快速恢复业务关键型应用程序的企业来说、成熟可靠的灾难恢复(Disaster Recovery、DR)环境和计划至关重要。本解决方案 重点展示灾难恢复使用情形、重点介绍内部部署和AWS上的VMware云中的VMware和NetApp技术。</block>
  <block id="1ae55e7a3caf44baf5721cdf304e676d" category="doc">TR-4931：《在Amazon Web Services和Guest Connect上使用VMware Cloud进行灾难恢复》</block>
  <block id="5f3d0127b9424be374b1c1474deb2684" category="paragraph">NetApp与VMware集成的历史很长、成千上万的客户选择NetApp作为其虚拟化环境的存储合作伙伴就证明了这一点。这种集成将继续与云中的子系统连接选项进行、并在近期与NFS数据存储库进行集成。本解决方案 重点介绍通常称为子系统连接存储的使用情形。</block>
  <block id="1134d985d8893464bee3d37e02a36402" category="paragraph">在子系统连接的存储中、子系统VMDK部署在VMware配置的数据存储库上、应用程序数据存储在iSCSI或NFS上并直接映射到虚拟机。Oracle和MS SQL应用程序用于演示灾难恢复场景、如下图所示。</block>
  <block id="50dd1256f4cf87b2fa70e300ade578e4" category="paragraph"><block ref="50dd1256f4cf87b2fa70e300ade578e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9a05fe4fa63215c3d368883b85e9312" category="summary">此解决方案 使用NetApp SnapCenter 为SQL Server和Oracle数据库创建应用程序一致的备份。与用于备份虚拟机VMDK的Veeam备份和复制相结合、可为内部和基于云的数据中心提供全面的灾难恢复解决方案。</block>
  <block id="d312952f462ee1dc88347d6060c708da" category="section-title">在内部部署Windows SnapCenter 服务器</block>
  <block id="989d04f01dc04fe21c2b542b83a45a6b" category="inline-link">NetApp文档中心</block>
  <block id="5d15da138c85d083e6e6409b418b8411" category="paragraph">SnapCenter 软件可从NetApp支持站点获得、并可安装在位于域或工作组中的Microsoft Windows系统上。有关详细的规划指南和安装说明、请参见<block ref="c18608d8aa7f8cbafcf1d09b2fb01df0" category="inline-link-rx"></block>。</block>
  <block id="e6220e7462e6d815945c93dcd734235f" category="paragraph">SnapCenter 软件可从获取<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>。</block>
  <block id="d2476cc18d417aa498cc7c32f99e980b" category="paragraph">安装后、您可以使用｛\https://Virtual_Cluster_IP_or_FQDN:8146_｝从Web浏览器访问SnapCenter 控制台。</block>
  <block id="63b96bb46045042b50fd68d9b5a0f0ba" category="section-title">将存储控制器添加到SnapCenter</block>
  <block id="8956d4de491225a4e6515ba0ad92fb30" category="paragraph">要将存储控制器添加到SnapCenter 、请完成以下步骤：</block>
  <block id="2ba7db7e99ccd03f69c81ce1f25330e6" category="list-text">从左侧菜单中、选择存储系统、然后单击新建开始将存储控制器添加到SnapCenter 的过程。</block>
  <block id="f1d609f44050cd3b443f66e474c3b93c" category="paragraph"><block ref="f1d609f44050cd3b443f66e474c3b93c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48806d1941dc50dadf8bcd5d590511ab" category="list-text">在添加存储系统对话框中、添加本地内部ONTAP 集群的管理IP地址以及用户名和密码。然后单击提交开始发现存储系统。</block>
  <block id="7b7a93dac3e0141a111190c64a54a220" category="paragraph"><block ref="7b7a93dac3e0141a111190c64a54a220" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc7b9fe54780f87aa8bdf884b95187c5" category="list-text">重复此过程将FSX ONTAP 系统添加到SnapCenter。在这种情况下、请选择添加存储系统窗口底部的更多选项、然后单击二级复选框、将FSX系统指定为使用SnapMirror副本或主备份快照更新的二级存储系统。</block>
  <block id="4a8fedebba8d5bd8e357863942b66b79" category="paragraph"><block ref="4a8fedebba8d5bd8e357863942b66b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62104d735113c9c7e8a23cd031ca2004" category="paragraph">有关向SnapCenter 添加存储系统的详细信息、请参见中的文档<block ref="05f72e618af68eda439c6d688692dcd6" category="inline-link-rx"></block>。</block>
  <block id="c81dcfed07648c407976127bb0bdbed2" category="section-title">将主机添加到SnapCenter</block>
  <block id="e796a589329333070ad568f533b21931" category="paragraph">下一步是将主机应用程序服务器添加到SnapCenter。SQL Server和Oracle的过程都类似。</block>
  <block id="6718a4b38f7a3df604d1fd6079decaae" category="list-text">从左侧菜单中、选择主机、然后单击添加开始向SnapCenter 添加存储控制器的过程。</block>
  <block id="4106a2178f1f526d51c57cb723e0f3ef" category="list-text">在添加主机窗口中、添加主机类型、主机名和主机系统凭据。选择插件类型。对于SQL Server、选择Microsoft Windows和Microsoft SQL Server插件。</block>
  <block id="3eae7017924ae8e187a046e62f5c334e" category="paragraph"><block ref="3eae7017924ae8e187a046e62f5c334e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdb2b840f37deff5210ef9f13e554fd5" category="list-text">对于Oracle、请在添加主机对话框中填写必填字段、然后选中Oracle数据库插件对应的复选框。然后、单击提交开始发现过程、并将主机添加到SnapCenter。</block>
  <block id="6430fb639e6454a8e47d23925ec8f583" category="paragraph"><block ref="6430fb639e6454a8e47d23925ec8f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7da39703d1c501afafc02c06d1c31788" category="section-title">创建SnapCenter 策略</block>
  <block id="fa5cc6d015db1929ddc02765f2003a33" category="paragraph">策略用于建立备份作业要遵循的特定规则。它们包括但不限于备份计划、复制类型以及SnapCenter 如何处理备份和截断事务日志。</block>
  <block id="817a33901829b57a630a499c24b4daf2" category="paragraph">您可以在SnapCenter Web客户端的"设置"部分访问策略。</block>
  <block id="6ddda0770a816978059cd0702e0223d0" category="paragraph"><block ref="6ddda0770a816978059cd0702e0223d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9d91360f1fd4ad1abf6c445ec8ff103" category="paragraph">有关为SQL Server备份创建策略的完整信息、请参见<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>。</block>
  <block id="f079afadb233d404e335685a7b58c70e" category="paragraph">有关为Oracle备份创建策略的完整信息、请参见<block ref="be1c60aeb8bf91be9c4096428152eedc" category="inline-link-rx"></block>。</block>
  <block id="5847f474084786fc8a16763856c1b0da" category="list-text">在执行策略创建向导期间、请特别注意"复制"部分。在本节中、您将指定要在备份过程中创建的二级SnapMirror副本的类型。</block>
  <block id="fc3c693a9b60faa4913d47e755b4cf34" category="list-text">"创建本地Snapshot副本后更新SnapMirror"设置是指在同一集群中的两个Storage Virtual Machine之间存在SnapMirror关系时更新此关系。</block>
  <block id="77bf66c8cee4cd2482095210be78e13a" category="list-text">"创建本地快照副本后更新Snapmirror "设置用于更新两个独立集群之间以及内部ONTAP 系统与Cloud Volumes ONTAP 或FSxN之间的SnapVault 关系。</block>
  <block id="824aec6074385910e619ac91969c68a3" category="paragraph">下图显示了上述选项及其在备份策略向导中的显示方式。</block>
  <block id="89bace67b9ee8f5a253e88d282ceb63d" category="paragraph"><block ref="89bace67b9ee8f5a253e88d282ceb63d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6bd8190e5c79ad5d86289d596dd8c16" category="section-title">创建SnapCenter 资源组</block>
  <block id="2f15c296209e980cccf829b7e5c1bbca" category="paragraph">通过资源组、您可以选择要包含在备份中的数据库资源以及这些资源所遵循的策略。</block>
  <block id="e96fdebed13bd03c9e88f6cff2b7ed67" category="list-text">转到左侧菜单中的"Resources"部分。</block>
  <block id="8b5265ba89102ff3a5fd8b504ba85140" category="list-text">在窗口顶部、选择要使用的资源类型(此处为Microsoft SQL Server)、然后单击新建资源组。</block>
  <block id="695c07b026f6602eff292288473cdc42" category="paragraph"><block ref="695c07b026f6602eff292288473cdc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bad635c8aa26c147bd68eb7b700cabbe" category="paragraph">SnapCenter 文档介绍了为SQL Server和Oracle数据库创建资源组的分步详细信息。</block>
  <block id="6f9886092f343d1ecc5b676f4ca381c7" category="paragraph">要备份SQL资源、请按照<block ref="d0500a8d119256a2ca6775a9357c88fa" category="inline-link-rx"></block>。</block>
  <block id="ffbeca6b667809b446c63465c7ff671f" category="paragraph">要备份Oracle资源、请按照<block ref="c6b13e1956473c7b22893d8b12c1b8be" category="inline-link-rx"></block>。</block>
  <block id="601c3055944b06a3d06d7da4128af752" category="summary">要将我们的应用程序VM和数据库卷故障转移到AWS中运行的VMware云卷服务、必须安装和配置正在运行的SnapCenter 服务器和Veeam备份和复制服务器实例。故障转移完成后、还必须将这些工具配置为恢复正常备份操作、直到计划并执行到内部数据中心的故障恢复为止。</block>
  <block id="4f31ced8146865d2c2823db3f623bf36" category="section-title">部署备份工具</block>
  <block id="4dad49c9583060929c06d355e24a683a" category="paragraph">SnapCenter 服务器和Veeam备份和复制服务器可以安装在VMware云SDDC中、也可以安装在VPC中的EC2实例上、并通过网络连接到VMware云环境。</block>
  <block id="f709ed2f05802131924f53cb483d0216" category="section-title">SnapCenter 服务器</block>
  <block id="257b2c5a413bf4e187ebd89c8a363827" category="inline-link-macro">NetApp文档中心</block>
  <block id="2bd8e8f9848a7635d56bcd86b9ad4c8f" category="paragraph">SnapCenter 软件可从NetApp支持站点获得、并可安装在位于域或工作组中的Microsoft Windows系统上。有关详细的规划指南和安装说明、请参见 <block ref="a00f6e57d5c269a935cd1b0491cebb83" category="inline-link-macro-rx"></block>。</block>
  <block id="d099bc9c6d34500d99c2caac0e6df36c" category="paragraph">SnapCenter 软件位于<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>。</block>
  <block id="5a8e524620f781b94c018014370aad68" category="paragraph">您可以在AWS上的VMware Cloud中的Windows服务器或EC2实例上安装Veeam Backup &amp; Replication服务器。有关详细的实施指导、请参见<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>。</block>
  <block id="af7bd34681425c09ae0ef24381972fb5" category="section-title">备份工具和配置</block>
  <block id="82634d63ab3a3344fb59974c50487bac" category="paragraph">安装后、必须对SnapCenter 和Veeam Backup &amp; Replication进行配置、以执行必要的任务、将数据还原到AWS上的VMware Cloud。</block>
  <block id="4b152f4bba0a5ca6345daa47736e4622" category="section-title">SnapCenter 配置</block>
  <block id="411fce4d2b732a8bfda73c4f04da246c" category="paragraph">要还原已镜像到FSX ONTAP 的应用程序数据、必须先对内部SnapCenter 数据库执行完全还原。此过程完成后、将重新建立与VM的通信、现在可以使用FSX ONTAP 作为主存储来恢复应用程序备份。</block>
  <block id="d307f68836099290d00bdc9341ec2be7" category="inline-link-macro">部署二级Windows SnapCenter 服务器</block>
  <block id="50d8cb6b9ada9f3e6328cb534ed5773f" category="paragraph">要还原已备份到Amazon S3存储的虚拟机、Veeam服务器必须安装在Windows服务器上、并配置为与VMware Cloud、FSX ONTAP 和包含原始备份存储库的S3存储分段进行通信。此外、还必须在FSX ONTAP 上配置一个新的备份存储库、以便在虚拟机还原后对其执行新备份。</block>
  <block id="845690e8aecca4f756b60cbd6c80c7f9" category="inline-link-macro">部署二级Veeam Backup &amp; amp；复制服务器</block>
  <block id="db4ff15d9c0c503103508af3dd860139" category="summary">NetApp AFF A系列系统可提供高性能存储基础架构、并提供灵活的数据管理选项、这些选项支持云技术、可满足各种企业场景的需求。在此解决方案 中、我们使用ONTAP AFF A300作为主要内部存储系统。</block>
  <block id="6e5148fc476ca76eb8c330524bc1064d" category="paragraph">解决方案 中使用了NetApp ONTAP 以及适用于VMware和SnapCenter 的ONTAP 工具来提供与VMware vSphere紧密集成的全面管理和应用程序备份功能。</block>
  <block id="e64f2bbe0643eeea77fa30ad5e4bdbe4" category="paragraph">我们将ONTAP 存储用于托管虚拟机及其VMDK文件的VMware数据存储库。VMware支持对已连接的数据存储库使用多种存储协议、在此解决方案 中、我们对ESXi主机上的数据存储库使用NFS卷。但是、ONTAP 存储系统支持VMware支持的所有协议。</block>
  <block id="ba1139b1becb929a6ba79e930297c5b7" category="paragraph">下图显示了VMware存储选项。</block>
  <block id="6869f0a16b26f7047d40a5a9c5a0ccd4" category="paragraph"><block ref="6869f0a16b26f7047d40a5a9c5a0ccd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aed995b63d54f1d314ad87fc5d16b69d" category="paragraph">ONTAP 卷用于应用程序VM的iSCSI和NFS子系统连接存储。我们对应用程序数据使用了以下存储协议：</block>
  <block id="c787b4233027288b06ace5dad3c0e461" category="list-text">用于子系统连接的Oracle数据库文件的NFS卷。</block>
  <block id="6a13696c6a6b506058d391582e402c83" category="list-text">用于子系统连接的Microsoft SQL Server数据库和事务日志的iSCSI LUN。</block>
  <block id="6504ffb2b49026508f8d68a73a0893a1" category="cell">数据库类型</block>
  <block id="9b8bdf7379e889d83ab24e782c87d2ac" category="cell">存储协议</block>
  <block id="0fc2cb6a177a3a14f31bd4810e09fa97" category="cell">卷问题描述</block>
  <block id="31f8757839909e87266f2b53482c86ef" category="cell">Windows Server 2019</block>
  <block id="e40ceeaead715c564e85bdc9b183e491" category="cell">SQL Server 2019</block>
  <block id="458648f675593beefe031e7b7ba9fcdd" category="cell">数据库文件</block>
  <block id="81fae4ea40cc442afa43dab4cc001004" category="cell">日志文件</block>
  <block id="ed47cdd7d93d911c4e94fc2801456784" category="cell">Oracle Linux 8.5</block>
  <block id="e13e1c4f4700229b02ee474e7dda4ea2" category="cell">Oracle 19c</block>
  <block id="4659ac5526bf8dff13f1ec371e79b766" category="cell">Oracle二进制文件</block>
  <block id="f0a16b1024d40f006a15728ebd0e0f12" category="cell">Oracle数据</block>
  <block id="1d9c31e9be3c01076e13f0f4fa1c15ae" category="cell">Oracle恢复文件</block>
  <block id="26f11a15ba5f458b3d86d9ecc01b56f3" category="paragraph">我们还将ONTAP 存储用于主要Veeam备份存储库、并将其用于SnapCenter 数据库备份的备份目标。</block>
  <block id="e8d719041d7958d85248e29684218330" category="list-text">Veeam备份存储库的SMB共享。</block>
  <block id="6005cf3be81f9c1a1908df0afb543b7d" category="list-text">SMB共享作为SnapCenter 数据库备份的目标。</block>
  <block id="6872c2b6282a1ff41523f7b84a51d4da" category="section-title">云存储</block>
  <block id="72cd2806db1eac2f04ef89c81542dd54" category="paragraph">此解决方案 包括AWS上的VMware Cloud、用于托管在故障转移过程中还原的虚拟机。截至本文撰写时、VMware支持为托管VM和VMDK的数据存储库使用vSAN存储。</block>
  <block id="501c11094fdd604514f321bced51fe82" category="paragraph">FSX for ONTAP 用作使用SnapCenter 和SyncMirror 镜像的应用程序数据的二级存储。在故障转移过程中、适用于ONTAP 集群的FSX将转换为主存储、数据库应用程序可以恢复在FSX存储集群上运行的正常功能。</block>
  <block id="2872e9fbf25a6695761c355a5170f21f" category="section-title">适用于NetApp ONTAP 的Amazon FSX设置</block>
  <block id="81d8366c2ec35340f9822e490b614b41" category="paragraph">要使用Cloud Manager部署适用于NetApp ONTAP 的AWS FSX、请按照中的说明进行操作<block ref="f938a02d8e5f1cc6cb4c026bb367a9b5" category="inline-link-rx"></block>。</block>
  <block id="e48c9f83aba7e50a34062296356c11da" category="paragraph">部署FSX ONTAP 后、将内部ONTAP 实例拖放到FSX ONTAP 中以启动卷的复制设置。</block>
  <block id="bfeecfa1e5aafaba3386ba09221608e3" category="paragraph">下图展示了我们的FSX ONTAP 环境。</block>
  <block id="f0eabf6ad2404299416504a68c18c70b" category="paragraph"><block ref="f0eabf6ad2404299416504a68c18c70b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46fabc81c23066d3f0ef74556fc23d0d" category="section-title">已创建网络接口</block>
  <block id="cf36149275607710e0655ce5a52d4745" category="paragraph">适用于NetApp ONTAP 的FSX已预先配置网络接口、可用于iSCSI、NFS、SMB和集群间网络。</block>
  <block id="a23141775a4b1f964c8a4c1335d366c7" category="section-title">VM数据存储库存储</block>
  <block id="60d2a0c028f1fc1db964ff9d52cfe139" category="paragraph">VMware Cloud SDDC随附两个VSAN数据存储库、分别名为`vsandatastore`和`workloaddatastore`。我们使用`vsandatastore`托管管理VM、其访问权限仅限于cloudadmin凭据。对于工作负载、我们使用了`workloaddatastore`。</block>
  <block id="d4fab32948320ef14f4b14bb30559cd4" category="summary">要执行NetApp SyncMirror 操作、此解决方案 需要从内部ONTAP 集群成功与AWS FSX for NetApp ONTAP 互连集群网络地址进行通信。此外、Veeam备份服务器必须能够访问AWS S3存储分段。现有VPN或Direct Connect链路可用作连接S3存储分段的专用链路、而不是使用Internet传输。</block>
  <block id="c850af3ffbdd92ab67281dbdfeaf4e52" category="paragraph">ONTAP 支持用于虚拟化的所有主要存储协议、包括适用于SAN环境的iSCSI、光纤通道(FC)、以太网光纤通道(FCoE)或非易失性光纤通道快速内存(NVMe/FC)。ONTAP 还支持NFS (v3和v4.1)以及SMB或S3进行子系统连接。您可以自由选择最适合您的环境的协议、并且可以根据需要在一个系统上组合协议。例如、您可以通过一些iSCSI LUN或子系统共享来扩大NFS数据存储库的一般使用范围。</block>
  <block id="dc8286bc14e4eca04d5c8c3d3745e742" category="paragraph">此解决方案 可将NFS数据存储库用于子系统VMDK的内部数据存储库、并将iSCSI和NFS用于子系统应用程序数据。</block>
  <block id="89cf31d317f3100637041ccf296c3421" category="section-title">客户端网络</block>
  <block id="d6c8c82593995a45499a762d317c04ec" category="paragraph">通过VMkernel网络端口和软件定义的网络连接、ESXi主机可以与VMware环境以外的元素进行通信。连接性取决于所使用的VMkernel接口类型。</block>
  <block id="774cca28a02c25118dc9668598f65663" category="paragraph">对于此解决方案 、已配置以下VMkernel接口：</block>
  <block id="fe4dbcab9b910577e5035e97ac068dae" category="list-text">管理</block>
  <block id="31ce31cccd4aecd29ff8b40dd37b8305" category="section-title">已配置存储网络</block>
  <block id="a09cf1d6ddb872a8c1ee517538a9373d" category="paragraph">LIF （逻辑接口）表示集群中某个节点的网络访问点。这样可以与存储客户端访问的数据的Storage Virtual Machine进行通信。您可以在集群通过网络发送和接收通信的端口上配置 LIF 。</block>
  <block id="b976c5d6eaa4fa1f606cff663f77835f" category="paragraph">对于此解决方案 、将为以下存储协议配置LIF：</block>
  <block id="cfba851bf46ae36ca092575bba6c7289" category="section-title">云连接选项</block>
  <block id="466c519a74055fba20814454ab577c83" category="paragraph">在将内部环境连接到云资源时、客户有许多选择、包括部署VPN或Direct Connect拓扑。</block>
  <block id="ce24b5f233dc29fc3614b2c7d961948b" category="section-title">虚拟专用网络(VPN)</block>
  <block id="55e6887f1e4e535089db85cbcae36acd" category="paragraph">VPN (虚拟专用网络)通常用于使用基于Internet或专用MPLS网络创建安全的IPsec通道。VPN易于设置、但缺乏可靠性(如果基于Internet)和速度。端点可以在AWS VPC或VMware Cloud SDDC上终止。对于此灾难恢复解决方案 、我们创建了从内部网络到AWS FSx for NetApp ONTAP 的连接。因此、它可以在连接了FSX for NetApp ONTAP 的AWS VPC (虚拟专用网关或传输网关)上终止。</block>
  <block id="365e9311cae767fae52a5cdba7003f9a" category="paragraph">VPN设置可以基于路由、也可以基于策略。使用基于路由的设置时、端点会自动交换路由、而设置会学习路由到新创建的子网。在基于策略的设置中、您必须定义本地和远程子网、并且在添加新子网并允许在IPsec通道中进行通信时、您必须更新路由。</block>
  <block id="fb932a9cb1f7aff6a88af2645c80731e" category="admonition">如果未在默认网关上创建IPsec VPN通道、则必须通过本地VPN通道端点在路由表中定义远程网络路由。</block>
  <block id="2dc9d6f2c2810edb190acfe717c84a68" category="paragraph">下图显示了典型的VPN连接选项。</block>
  <block id="d90d767da5b6da33c2785b3d3120c23f" category="paragraph"><block ref="d90d767da5b6da33c2785b3d3120c23f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1fc9354c56b77f7143d2b6a7d185ad" category="section-title">直接连接</block>
  <block id="4aa5340761d0794e8da7cfa5ead94eb3" category="paragraph">Direct Connect提供指向AWS网络的专用链接。专用连接会使用1 Gbps、10 Gbps或100 Gbps以太网端口创建指向AWS的链路。AWS Direct Connect合作伙伴可使用自己与AWS之间预先建立的网络链路提供托管连接、并且可用速率介于50 Mbps到10 Gbps之间。默认情况下、流量未加密。但是、可以使用一些选项来保护MAC或IPsec的流量安全。MACsec提供第2层加密、而IPsec提供第3层加密。MAC可通过隐藏正在通信的设备来提供更好的安全性。</block>
  <block id="f41e1aa529328c6c391ee2bbb3e7b35f" category="paragraph">客户必须将其路由器设备放置在AWS Direct Connect位置。要进行设置、您可以使用AWS合作伙伴网络(APN)。该路由器与AWS路由器之间建立了物理连接。要在VPC上访问适用于NetApp ONTAP 的FSX、您必须具有专用虚拟接口或从Direct Connect到VPC的传输虚拟接口。使用专用虚拟接口时、直接连接到VPC连接的可扩展性会受到限制。</block>
  <block id="aac639f893699a86dc44236deb8c2ff8" category="paragraph">下图显示了Direct Connect接口选项。</block>
  <block id="65d0f01c0d2abb5df490f85de1a3c7f5" category="paragraph"><block ref="65d0f01c0d2abb5df490f85de1a3c7f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a547cd01b7307bbc41da8aed4983dc1" category="section-title">传输网关</block>
  <block id="5789b6855d128c642555ffa55396a65c" category="inline-link">AWS Direct Connect文档</block>
  <block id="3ae6c7e3aea4c72d9bf07244d7b959e6" category="paragraph">传输网关是一种区域级别的构造、可提高区域内直接连接到VPC连接的可扩展性。如果需要跨区域连接、则必须为传输网关建立对等关系。有关详细信息、请查看<block ref="9f2a100b6fab526146ca277977e4ef3a" category="inline-link-rx"></block>。</block>
  <block id="ac8979d211e20b50e94073d31f2e8d44" category="section-title">云网络注意事项</block>
  <block id="02c5109954e68b54548d5ef777afaf76" category="paragraph">在云中、底层网络基础架构由云服务提供商管理、而客户必须在AWS中管理VPC网络、子网、路由表等。他们还必须管理计算边缘的NSX网段。SDDC对外部VPC和Transit Connect的路由进行分组。</block>
  <block id="ee94a9a0de351e37a54ce1fec2961c62" category="paragraph">在连接到VMware Cloud的VPC上部署具有多AZ可用性的FSX for NetApp ONTAP 时、iSCSI流量会收到必要的路由表更新以启用通信。默认情况下、从VMware Cloud到所连接的VPC for Multi-AZ部署上的FSX ONTAP NFS/SMB子网的路由不可用。为了定义该路由、我们使用VMware Cloud SDDC组、该组是一个由VMware管理的传输网关、用于在同一区域的VMware Cloud SDDC之间以及外部VPC和其他传输网关之间进行通信。</block>
  <block id="7ee08649d3bd024352f28df7dabbb32f" category="admonition">使用传输网关会产生数据传输成本。有关特定于某个区域的成本详细信息、请参见<block ref="b6f8eb4f405293cd9bb0c07a2ec1b299" category="inline-link-rx"></block>。</block>
  <block id="68010b6bb26779cadbf96e9d04dad537" category="paragraph">VMware Cloud SDDC可以部署在一个可用性区域中、就像拥有一个数据中心一样。此外、还提供了延伸型集群选项、这与NetApp MetroCluster 解决方案 类似、可在可用性区域发生故障时提供更高的可用性并减少停机时间。</block>
  <block id="0d5aa9b9832dc4c044a656ccdd139dcf" category="paragraph">为了最大限度地降低数据传输成本、请将VMware Cloud SDDC和AWS实例或服务保留在同一可用性区域中。最好使用可用性区域ID而不是名称进行匹配、因为AWS会提供特定于帐户的AZ订单列表、以便在可用性区域之间分摊负载。例如、一个帐户(US-East-1a)可能指向AZ ID 1、而另一个帐户(US-East-1c)可能指向AZ ID 1。可以通过多种方式检索可用性区域ID。在以下示例中、我们从VPC子网检索到AZ ID。</block>
  <block id="64c06e81643d1c8b6eba37a5343885ec" category="paragraph"><block ref="64c06e81643d1c8b6eba37a5343885ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70cd8bfb8fd7a4082087201414ab2fe4" category="inline-link">VMware 文档</block>
  <block id="8920393d6c2c8771eef99f947100b883" category="paragraph">在VMware Cloud SDDC中、网络连接通过NSX进行管理、处理北-南流量上行链路端口的边缘网关(第0层路由器)连接到AWS VPC。计算网关和管理网关(第1层路由器)用于处理东西向流量。如果边缘的上行链路端口使用率较高、则可以创建流量组以与特定主机IP或子网关联。创建流量组会创建额外的边缘节点来分隔流量。检查<block ref="616556354bfd279ba90d5c2485799af5" category="inline-link-rx"></block> 使用多边缘设置所需的最小vSphere主机数。</block>
  <block id="e064913c9382e82051f900b9564779d5" category="paragraph">在配置VMware Cloud SDDC时、VMKernel端口已配置完毕并可供使用。VMware负责管理这些端口、无需进行任何更新。</block>
  <block id="edbc8b71394d65a981746a0ed9072b51" category="paragraph">下图显示了主机VMKernel信息示例。</block>
  <block id="24d3a9af73ac14dc11a2d9a4745a77b0" category="paragraph"><block ref="24d3a9af73ac14dc11a2d9a4745a77b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1315738b589a4d2de3fd82a05b2d4e19" category="section-title">配置的存储网络(iSCSI、NFS)</block>
  <block id="1a6b4ca0fa5ca04588d2e2eac3bf0444" category="paragraph">对于VM子系统存储网络、我们通常会创建端口组。通过NSX、我们可以创建在vCenter上用作端口组的分段。由于存储网络位于可路由的子网中、因此即使不创建单独的网段、您也可以使用默认NIC访问LUN或挂载NFS导出。要分隔存储流量、您可以创建其他分段、定义规则并控制这些分段上的MTU大小。为了提供容错功能、最好至少为存储网络配置两个专用区块。如前所述、如果上行链路带宽变为问题描述 、您可以创建流量组并分配IP前缀和网关以执行基于源的路由。</block>
  <block id="87e62e5f6f235efbfc557b0177d0e112" category="paragraph">我们建议将灾难恢复SDDC中的网段与源环境进行匹配、以防止在故障转移期间猜测是否映射网络网段。</block>
  <block id="9175bb34d0aede26315b313b9432bcbb" category="section-title">安全组</block>
  <block id="7c9ffa8d590736372f008da84037edaa" category="paragraph">许多安全选项均可在AWS VPC和VMware Cloud SDDC网络上提供安全通信。在VMware Cloud SDDC网络中、您可以使用NSX跟踪流来标识路径、包括使用的规则。然后、您可以使用VPC网络上的网络分析器确定此流期间使用的路径、包括路由表、安全组和网络访问控制列表。</block>
  <block id="bd6d688efed13ace07c5656a3de04479" category="doc">概述—AWS子系统连接存储灾难恢复</block>
  <block id="67b5a180b1adfc09bd2752e51613fea5" category="paragraph">本节提供的说明可帮助用户验证、配置和验证其内部环境和云环境、以便与NetApp和VMware结合使用。具体而言、此解决方案 侧重于VMware子系统连接的使用情形、其中包括适用于云的ONTAP AFF 内部部署和VMware Cloud以及AWS FSX ONTAP。此解决方案 通过两个应用程序进行了演示：在灾难恢复场景中使用Oracle和MS SQL。</block>
  <block id="d48ec23d0c00af2c45aa4b1c24b412d8" category="summary">对于主内部数据中心发生的灾难、我们的方案包括使用VMware Cloud on AWS故障转移到位于Amazon Web Services基础架构上的二级站点。我们假定虚拟机和内部ONTAP 集群不再可访问。此外、SnapCenter 和Veeam虚拟机将无法再访问、必须在我们的二级站点上进行重建。</block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="doc">故障转移</block>
  <block id="03c450647cafbb7294b1d6fef9f2476f" category="section-title">主站点发生灾难</block>
  <block id="ff36edd2e7e49fd0a40827688d2f4d8c" category="paragraph">本节将介绍基础架构故障转移到云的问题、我们将介绍以下主题：</block>
  <block id="9555d80191893a5b671187e1a859f379" category="list-text">SnapCenter 数据库还原。建立新的SnapCenter 服务器后、请还原MySQL数据库和配置文件、并将数据库切换到灾难恢复模式、以使二级FSX存储成为主存储设备。</block>
  <block id="2f2ee1d320a4d17fae8f4228f0a0c17a" category="list-text">使用Veeam Backup &amp; Replication还原应用程序虚拟机。连接包含VM备份的S3存储、导入备份并将其还原到AWS上的VMware Cloud。</block>
  <block id="8509dc3cb04f91e9c6eb62971df36219" category="list-text">使用SnapCenter 还原SQL Server应用程序数据。</block>
  <block id="81e920a3cfad3020139d281a7be1093a" category="list-text">使用SnapCenter 还原Oracle应用程序数据。</block>
  <block id="7c3080588178d0f5908a96d9e20be883" category="section-title">SnapCenter 数据库还原过程</block>
  <block id="86c580a0ed766eb38c0ef43f08d425e5" category="paragraph">SnapCenter 允许备份和还原其MySQL数据库和配置文件、从而支持灾难恢复场景。这样、管理员便可以在内部数据中心对SnapCenter 数据库进行定期备份、然后将该数据库还原到二级SnapCenter 数据库。</block>
  <block id="ee1f8cb839e16951e7004e4047603101" category="paragraph">要访问远程SnapCenter 服务器上的SnapCenter 备份文件、请完成以下步骤：</block>
  <block id="0b5c65b05530328f42d8b65f68657302" category="list-text">从FSX集群中断SnapMirror关系、从而使卷变为读/写卷。</block>
  <block id="dbfff075901e62d26ef1f316380d01f7" category="list-text">创建CIFS服务器(如有必要)并创建指向克隆卷的接合路径的CIFS共享。</block>
  <block id="26b0d9d510f38125c4de3a7b68569b29" category="list-text">使用xcopy将备份文件复制到二级SnapCenter 系统上的本地目录。</block>
  <block id="fa0138f778767381d2b0af9bdabad76e" category="list-text">安装SnapCenter v4.6。</block>
  <block id="736c8557bca1ad901b82efb5e946a527" category="list-text">确保SnapCenter 服务器与原始服务器具有相同的FQDN。要成功还原数据库、必须执行此操作。</block>
  <block id="6f77488ce3ed6db6422cddaa1e4cbf8f" category="paragraph">要启动还原过程、请完成以下步骤：</block>
  <block id="7220866a3d1d3ba6c1aef39d02d64b1f" category="list-text">导航到二级SnapCenter 服务器的Swagger API网页、然后按照前面的说明获取授权令牌。</block>
  <block id="a5214e49691510795c98aad40874caa1" category="list-text">导航到Swagger页面的Disaster Recovery部分、选择`/4.6/disasterrecovery/server/restore`、然后单击Try it out。</block>
  <block id="3c235173c5db1037212eff5e3a152a26" category="paragraph"><block ref="3c235173c5db1037212eff5e3a152a26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d76d7bbb789675126fd1e9a0bf929635" category="list-text">粘贴您的授权令牌、然后在"SmDRResterRequest"部分中、将备份名称和二级SnapCenter 服务器上的本地目录粘贴。</block>
  <block id="34938ae261d31ae76af2e4369a2c8b0a" category="paragraph"><block ref="34938ae261d31ae76af2e4369a2c8b0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4579e653c0e46ed15c466f496b60b0f3" category="list-text">选择执行按钮以启动还原过程。</block>
  <block id="fcbb767c97ce18f6b82f09bf8ea9c993" category="list-text">在SnapCenter 中、导航到Monitor部分以查看还原作业的进度。</block>
  <block id="8fa0520efd67da15041467d3126133a7" category="paragraph"><block ref="8fa0520efd67da15041467d3126133a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d67615193bee26cd99be6b7ea889f065" category="paragraph"><block ref="d67615193bee26cd99be6b7ea889f065" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49b4fb23e31b4cd2d12434ce03b24134" category="list-text">要从二级存储启用SQL Server还原、必须将SnapCenter 数据库切换为灾难恢复模式。此操作将作为单独的操作执行、并在Swagger API网页上启动。</block>
  <block id="35afa1a915c7752e139ef7b0362596a6" category="list-text">导航到Disaster Recovery部分、然后单击`/4.6/disasterrecovery/storage`。</block>
  <block id="7633ff4043449878afbd5ca925faa5b1" category="list-text">粘贴用户授权令牌。</block>
  <block id="5fb3d7404a8cc43eb5e120b4e22fe16d" category="list-text">在SmSetDisasterRecoverySettingsRequest部分中、将`EnableDisasterRecover`更改为`true`。</block>
  <block id="e7470af265e05d2efa8863c259541c2b" category="list-text">单击执行为SQL Server启用灾难恢复模式。</block>
  <block id="8579e283f02173e29df7090294128589" category="paragraph"><block ref="8579e283f02173e29df7090294128589" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4a08ff9e7fd1ec468bc55c7ba9df45" category="admonition">请参见有关其他过程的注释。</block>
  <block id="5b13229945c45439c072dc9c270e8177" category="inline-link-macro">在AWS上使用VMC进行灾难恢复(已连接子系统)</block>
  <block id="866b55fdae1463f1934c300853ecefe2" category="list-text"><block ref="866b55fdae1463f1934c300853ecefe2" category="inline-link-macro-rx"></block></block>
  <block id="38631d978812c49b6f395a78becd9750" category="summary">以下过程提供了有关在发生灾难导致内部站点无法运行时如何在AWS的VMware云服务中恢复Oracle应用程序数据的说明。</block>
  <block id="c8ae03dc8bb68d2ad3e63a9126f795e6" category="doc">还原Oracle应用程序数据</block>
  <block id="18ed07dc9f8533a3a2cf047292765486" category="paragraph">完成以下前提条件以继续执行恢复步骤：</block>
  <block id="d55274d1968c306eb025dc5e6eca42b4" category="list-text">Oracle Linux服务器VM已使用Veeam Full Restore还原到VMware Cloud SDDC。</block>
  <block id="b723df724fefe9f2021e7bb7bd8a57d0" category="section-title">为Oracle还原配置FSX—中断SnapMirror关系</block>
  <block id="ab26994a6aef07f6a796a6109f921a28" category="paragraph">要使FSxN实例上托管的二级存储卷可供Oracle服务器访问、必须先中断现有的SnapMirror关系。</block>
  <block id="d80c0676712ecc3e8d717347b9a0113a" category="list-text">登录到FSX命令行界面后、运行以下命令以查看使用正确名称筛选的卷。</block>
  <block id="c534b90634ff37c01e77b058859f2a29" category="paragraph"><block ref="c534b90634ff37c01e77b058859f2a29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="771b4d8e9d4a9f112068c45d013c2940" category="list-text">运行以下命令以中断现有SnapMirror关系。</block>
  <block id="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="paragraph"><block ref="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a4480a103abe04e17eca64a771420a8" category="list-text">更新Amazon FSX Web客户端中的接合路径：</block>
  <block id="a3848e78db2c915e6ec7913bc0779a86" category="paragraph"><block ref="a3848e78db2c915e6ec7913bc0779a86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="467332d89a649add4b0efb09dd2386c5" category="list-text">添加接合路径名称、然后单击更新。从Oracle服务器挂载NFS卷时、请指定此接合路径。</block>
  <block id="7a522c1cba5b4c9df88cb71a944d5efd" category="paragraph"><block ref="7a522c1cba5b4c9df88cb71a944d5efd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="974ee05a635ebfcae6d6f6aa6f5da0b9" category="section-title">在Oracle Server上挂载NFS卷</block>
  <block id="f3677efe1cf868a895b6634743ae53cd" category="paragraph">在Cloud Manager中、您可以使用正确的NFS LIF IP地址获取mount命令、以便挂载包含Oracle数据库文件和日志的NFS卷。</block>
  <block id="5ecb7cb864e3f6e77b9ae7264115942e" category="list-text">在Cloud Manager中、访问FSX集群的卷列表。</block>
  <block id="dc33973d3bef150b7e3be67c8acbde9a" category="paragraph"><block ref="dc33973d3bef150b7e3be67c8acbde9a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf957a98bd60352ec8312937f87b49dc" category="list-text">从操作菜单中、选择挂载命令以查看并复制要在Oracle Linux服务器上使用的挂载命令。</block>
  <block id="42ae5bd08cec138b52386d868d92bcfe" category="paragraph"><block ref="42ae5bd08cec138b52386d868d92bcfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8026151c7c8dc5002a8652cdd0ac0610" category="paragraph"><block ref="8026151c7c8dc5002a8652cdd0ac0610" category="inline-image-macro-rx" type="image"></block></block>
  <block id="91d32453a4c3b285d62be2bc5eb3d24c" category="list-text">将NFS文件系统挂载到Oracle Linux Server。Oracle Linux主机上已存在用于挂载NFS共享的目录。</block>
  <block id="3f7f1270061c2e231f722bfd466cec0d" category="list-text">在Oracle Linux服务器上、使用mount命令挂载NFS卷。</block>
  <block id="5cafad6c0970ad9fd32dd43eb98a7d6f" category="paragraph">对与Oracle数据库关联的每个卷重复此步骤。</block>
  <block id="264225a103d86a5e552aebab3ee7dd3f" category="admonition">要在重新启动时使NFS挂载持久、请编辑`/etc/fstab`文件以包含mount命令。</block>
  <block id="2095b7305d1da91dff871c600b482eb9" category="list-text">重新启动Oracle服务器。Oracle数据库应正常启动并可供使用。</block>
  <block id="997d17d93cccb6709985c79ccc870db0" category="doc">用于灾难恢复的SnapCenter 数据库备份</block>
  <block id="9cb03f5cfb57a7f655c8a28ca64ae0d1" category="paragraph">SnapCenter 允许备份和恢复其底层MySQL数据库和配置数据、以便在发生灾难时恢复SnapCenter 服务器。对于解决方案 、我们在VPC中的AWS EC2实例上恢复了SnapCenter 数据库和配置。有关此步骤的详细信息、请参见<block ref="85e9a4a54f289ebdfa6c4169fb097d15" category="inline-link-rx"></block>。</block>
  <block id="46137d274838eaef40c110eac160dabc" category="section-title">SnapCenter 备份前提条件</block>
  <block id="2fe071c4476effcd542a95a182832104" category="paragraph">SnapCenter 备份需要满足以下前提条件：</block>
  <block id="be2b68df1cb3db2a8f1393a8c89a5c30" category="list-text">在内部ONTAP 系统上创建的卷和SMB共享、用于查找备份的数据库和配置文件。</block>
  <block id="1a9ee88991730f920252a1445a467c77" category="list-text">内部ONTAP 系统与AWS帐户中的FSX或CVO之间的SnapMirror关系。此关系用于传输包含备份的SnapCenter 数据库和配置文件的快照。</block>
  <block id="3c0e70fa217603c0388de21f978923f3" category="list-text">Windows Server安装在云帐户中、可以安装在EC2实例上、也可以安装在VMware Cloud SDDC中的VM上。</block>
  <block id="328228524f87469e005c8944ad925402" category="list-text">SnapCenter 安装在VMware Cloud中的Windows EC2实例或VM上。</block>
  <block id="0038f6b75b40b9c37893544119ad7ca4" category="section-title">SnapCenter 备份和还原过程摘要</block>
  <block id="f4644dc8d01e527218cd1fc0daa6af40" category="list-text">在内部ONTAP 系统上创建一个卷、用于托管备份数据库和配置文件。</block>
  <block id="c4232930a0fc8d0f9a5e1a16db36a816" category="list-text">在内部部署和FSX/CVO之间设置SnapMirror关系。</block>
  <block id="3e1461fe483fb58c7a6642074cb71d8d" category="list-text">挂载SMB共享。</block>
  <block id="dd5b017c2cafc1394e2d7ab7081652e3" category="list-text">检索用于执行API任务的Swagger授权令牌。</block>
  <block id="51263d7f64b29b2b3bd6730068e64a27" category="list-text">启动数据库还原过程。</block>
  <block id="23011a36184705e18919c3e5560fd514" category="list-text">使用xcopy实用程序将数据库和配置文件本地目录复制到SMB共享。</block>
  <block id="b84dd176bda6a6d30c5cb8901a8bf5b1" category="list-text">在FSX上、创建ONTAP 卷的克隆(通过SnapMirror从内部复制)。</block>
  <block id="1a3f92b9c5623f19d294ef2907d98cc8" category="list-text">将SMB共享从FSX挂载到EC2/VMware Cloud。</block>
  <block id="87d37b3dfd2b98df04243247ebff4325" category="list-text">将还原目录从SMB共享复制到本地目录。</block>
  <block id="fd516b8b37d528453c538c9022d6d9db" category="list-text">从Swagger运行SQL Server还原过程。</block>
  <block id="63c6890e4065bde44f84394d274e05db" category="section-title">备份SnapCenter 数据库和配置</block>
  <block id="493aa18049179f21c66cc95e36c19670" category="paragraph">SnapCenter 提供了一个Web客户端界面、用于执行REST API命令。有关通过Swagger访问REST API的信息、请参见SnapCenter 文档、网址为<block ref="2a9068db8cebf7672f374b2eb0a0c5ec" category="inline-link-rx"></block>。</block>
  <block id="911dd02ad9a62d89e83d996753811c7b" category="section-title">登录到Swagger并获取授权令牌</block>
  <block id="820336a66e164f408946dd8235833c07" category="paragraph">导航到Swagger页面后、您必须检索授权令牌以启动数据库还原过程。</block>
  <block id="99899958b071bcb677dc5a5b24f1b2a3" category="list-text">访问SnapCenter Swagger API网页、网址为：//https://&lt;SnapCenter Server IP&gt;：8146/swagger /_。</block>
  <block id="20f069ff72fb03614b867af722c7c40b" category="paragraph"><block ref="20f069ff72fb03614b867af722c7c40b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ad3b9c1075f899242a74f969cbb12fa" category="list-text">展开"Auth"部分、然后单击Try it out。</block>
  <block id="5ffa75198edfa553c162f3b9945a23a0" category="paragraph"><block ref="5ffa75198edfa553c162f3b9945a23a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="41402cfc6490d3bf582b8a14ff8bfcbe" category="list-text">在用户操作文本区域中、填写SnapCenter 凭据和角色、然后单击执行。</block>
  <block id="2e1aa1ca38ffa5e45db5da3276238eac" category="paragraph"><block ref="2e1aa1ca38ffa5e45db5da3276238eac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18e649ac855810eb5b8a774b3fab5f5c" category="list-text">在下面的响应正文中、您可以看到令牌。执行备份过程时、复制令牌文本以进行身份验证。</block>
  <block id="32d5d8e51cafb2b4d387df356fe41955" category="paragraph"><block ref="32d5d8e51cafb2b4d387df356fe41955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a1a34831e3e917e934e09eb9402b4d6" category="section-title">执行SnapCenter 数据库备份</block>
  <block id="3d8b8b9e239f00e8fbddb0437a5c5659" category="paragraph">接下来、转到Swagger页面上的灾难恢复区域、开始SnapCenter 备份过程。</block>
  <block id="5fd8196e8aa6d444acf7a65f639a6085" category="list-text">单击"Disaster Recovery"区域、将其展开。</block>
  <block id="7ec34046162f53040f7ca7c8a78c4b17" category="paragraph"><block ref="7ec34046162f53040f7ca7c8a78c4b17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14245d6803dae3fc2cab0fe1fd18565e" category="list-text">展开`/4.6/disasterrecovery/server/backup`部分、然后单击Try it out。</block>
  <block id="b5f8e4e588ebd761591d02cb02f2a5dd" category="paragraph"><block ref="b5f8e4e588ebd761591d02cb02f2a5dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aad454707845382aef2a040acc30177a" category="list-text">在SmDRBackupRequest部分中、添加正确的本地目标路径并选择执行以启动SnapCenter 数据库和配置的备份。</block>
  <block id="949b4a3f3887b0d48d721acc506fb82e" category="admonition">备份过程不允许直接备份到NFS或CIFS文件共享。</block>
  <block id="ef97a1ec7f6c4c7d84f053938ce48398" category="paragraph"><block ref="ef97a1ec7f6c4c7d84f053938ce48398" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f638b2ae24161dbfa69705afbf177bd" category="section-title">从SnapCenter 监控备份作业</block>
  <block id="03322e4ba2c5a628edfa27eb5a52741b" category="paragraph">在启动数据库还原过程时、登录到SnapCenter 以查看日志文件。在"Monitor"部分下、您可以查看SnapCenter 服务器灾难恢复备份的详细信息。</block>
  <block id="82c39eed34769992987a93ed6b12a97f" category="paragraph"><block ref="82c39eed34769992987a93ed6b12a97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac753614a3d47f00caddc06fd2dc281f" category="section-title">使用XCOPY实用程序将数据库备份文件复制到SMB共享</block>
  <block id="d2a0be1c4b7f47c09b612fb78a28adee" category="paragraph">接下来、您必须将备份从SnapCenter 服务器上的本地驱动器移动到用于SnapMirror将数据复制到AWS中FSX实例上的二级位置的CIFS共享。使用带有保留文件权限的特定选项的xcopy。</block>
  <block id="fa13c8e8caa807a78a4301f1cfa0ec2f" category="paragraph">以管理员身份打开命令提示符。在命令提示符处、输入以下命令：</block>
  <block id="0b55c8177ba39a322f35975c0c3bd3ba" category="section-title">技能和知识</block>
  <block id="b1adf7ef88c9564fb1f6c97bf42dca5c" category="paragraph">要访问Cloud Volumes Service for AWS、需要以下技能和信息：</block>
  <block id="7b83d82f99126fdb6efaa234f31683f5" category="list-text">访问VMware和ONTAP 内部环境并了解相关知识。</block>
  <block id="39a8abb00c1f9d982e3a29b4baec67f2" category="list-text">访问VMware Cloud和AWS并了解相关信息。</block>
  <block id="eaad72d3a50e4be3e11d36792eb96d62" category="list-text">访问AWS和Amazon FSX ONTAP 并了解这些信息。</block>
  <block id="25e65b652ca97821fa49aa9571b2b54a" category="list-text">了解SDDC和AWS资源。</block>
  <block id="18334368a9f4fce73ca297bdd4be123a" category="list-text">了解内部资源与云资源之间的网络连接。</block>
  <block id="f917b7afd251e67bbdf50fa466a9918e" category="list-text">具备灾难恢复场景的工作知识。</block>
  <block id="77d0638c77df28bd77c058b3da580702" category="list-text">了解在VMware上部署的应用程序的工作知识。</block>
  <block id="9ef15415f400d1d1a7b2c4d3e8879124" category="section-title">管理</block>
  <block id="99be46c7a7d783d36552f0f11df8cd5e" category="paragraph">无论是在内部还是在云中与资源进行交互、用户和管理员都必须能够并有权根据自己的权限在需要时根据自己的权限在需要的位置配置这些资源。要成功部署混合云、您在内部系统(包括ONTAP 和VMware)以及云资源(包括VMware Cloud和AWS)中的角色和权限之间的交互至关重要。</block>
  <block id="e5d4baff0167d033367d67396f5608f6" category="paragraph">要使用VMware和ONTAP 内部部署以及基于AWS和FSX ONTAP 的VMware Cloud构建灾难恢复解决方案 、必须执行以下管理任务。</block>
  <block id="e6833d473d476a99c7ec8095a5bfe8df" category="list-text">启用以下配置的角色和帐户：</block>
  <block id="297c8005623a7f22aad3d141e82fabb5" category="list-text">ONTAP 存储资源</block>
  <block id="864d5ea26def3831e53731dc58671672" category="list-text">VMware VM、数据存储库等</block>
  <block id="61b883742c54e0000affbbf61cecb00a" category="list-text">AWS VPC和安全组</block>
  <block id="cae667335742a0f5e8a41bb0caa73e4c" category="list-text">配置内部VMware环境和ONTAP</block>
  <block id="7098bf260c6533f1ebf70f5b9bb041b0" category="list-text">VMware Cloud环境</block>
  <block id="eca5f84e846df7323fccde83f4ff44d5" category="list-text">适用于ONTAP 文件系统的Amazon FSX</block>
  <block id="29b34be64d30233d5ed6d4f314db7483" category="list-text">内部环境与AWS之间的连接</block>
  <block id="c89c49a63ff46b95a3a1930093133477" category="list-text">连接AWS VPC</block>
  <block id="9301a9f205ba883a750d8c90b33c2bbc" category="paragraph">VMware虚拟环境包括ESXi主机、VMware vCenter Server、NSX网络和其他组件的许可、如下图所示。所有这些组件的许可方式都不同、了解底层组件如何使用可用的许可容量非常重要。</block>
  <block id="42094e9e4a0f05012b8d6753300a1657" category="section-title">ESXi主机</block>
  <block id="1d50ac197ef032b2bc2e46d8e2e64598" category="paragraph">VMware环境中的计算主机是使用ESXi部署的。在不同容量层获得vSphere的许可后、虚拟机可以利用每个主机上的物理CPU以及适用的授权功能。</block>
  <block id="43e02e05b2879c1406a010bf6a28f8f7" category="section-title">VMware vCenter</block>
  <block id="05f79f8867c02153173be8abc21ae61a" category="paragraph">管理ESXi主机和存储是VMware管理员可通过vCenter Server使用的众多功能之一。从VMware vCenter 7.0开始、根据许可证的不同、有三个版本的VMware vCenter可用：</block>
  <block id="f958b6a3f3407168711a82d395fb4ac7" category="list-text">vCenter Server基础知识</block>
  <block id="a0301fdeb61b558341af142a9f2dd3aa" category="list-text">vCenter Server基础版</block>
  <block id="62a846eee92143dee42cae576208c443" category="list-text">vCenter Server标准版</block>
  <block id="e44df2b6e256fb033bf0234d942a29f3" category="paragraph">VMware NSX为管理员提供了启用高级功能所需的灵活性。根据获得许可的NSX-T版本启用功能：</block>
  <block id="9e8b160226c9fe22a910c782ce5076e2" category="list-text">专业人员</block>
  <block id="9b6545e4cea9b4ad4979d41bb9170e2b" category="list-text">高级</block>
  <block id="1330271d87fae19afa4e7be5cd94b9f8" category="list-text">远程办公室/分支机构</block>
  <block id="88793829da8796f676eaebd57e42009d" category="paragraph">NetApp ONTAP 许可是指管理员如何访问NetApp存储中的各种功能。许可证是一个或多个软件授权的记录。通过安装许可证密钥(也称为许可证代码)、您可以在存储系统上使用某些功能或服务。例如、ONTAP 支持所有主要的行业标准客户端协议(NFS、SMB、FC、FCoE、iSCSI、 和NVMe/FC)。</block>
  <block id="90a29bf269cfe6c256d42b29776d14dd" category="paragraph">Data ONTAP 功能许可证以软件包的形式发布、每个软件包都包含多个功能或一个功能。某个软件包需要许可证密钥、安装该密钥后、您可以访问该软件包中的所有功能。</block>
  <block id="e4b843c32b9db50414c1dfbad0c4d1c0" category="paragraph">许可证类型如下：</block>
  <block id="0f00a6a817b378adf16de8d25fbf24fa" category="list-text">*节点锁定许可证。*安装节点锁定许可证可使节点获得许可功能。要使集群能够使用许可的功能，必须至少为一个节点授予使用此功能的许可。</block>
  <block id="52db1a3edfedfc7015c35209e22f04c2" category="list-text">*主许可证/站点许可证。*主许可证或站点许可证不与特定系统序列号绑定。安装站点许可证时、集群中的所有节点均有权使用许可的功能。</block>
  <block id="b2aa6f86c442a3ce1bedb4a83498fcc6" category="list-text">*演示/临时许可证。*演示或临时许可证将在一段时间后过期。通过此许可证，您可以在不购买授权的情况下尝试某些软件功能。</block>
  <block id="c6009ee65fbe56a5eed91a0a06f3a1b5" category="list-text">*容量许可证(仅限ONTAP Select 和FabricPool)。* ONTAP Select 实例根据用户要管理的数据量获得许可。从ONTAP 9.4开始、FabricPool 要求在第三方存储层(例如AWS)上使用容量许可证。</block>
  <block id="13b92bafad23a87622890420ed0b860b" category="paragraph">SnapCenter 需要多个许可证才能启用数据保护操作。您安装的 SnapCenter 许可证类型取决于您的存储环境和要使用的功能。SnapCenter 标准版许可证可保护应用程序、数据库、文件系统和虚拟机。在将存储系统添加到 SnapCenter 之前，您必须安装一个或多个 SnapCenter 许可证。</block>
  <block id="c2aa46e5e57aae7e4f4c969c417f1238" category="paragraph">要保护应用程序、数据库、文件系统和虚拟机、您必须在FAS 或AFF 存储系统上安装基于控制器的标准许可证、或者在ONTAP Select 和Cloud Volumes ONTAP 平台上安装基于容量的标准许可证。</block>
  <block id="14c2700881a435ad41069af9e8ee6f85" category="paragraph">请参见此解决方案 的以下SnapCenter 备份前提条件：</block>
  <block id="96b3493b2e1844322d28e845c314e10b" category="list-text">在内部ONTAP 系统上创建的卷和SMB共享、用于查找备份的数据库和配置文件。</block>
  <block id="f39931d0fa94c8e0cb577222f77fb09d" category="list-text">内部ONTAP 系统与AWS帐户中的FSX或CVO之间的SnapMirror关系。用于传输包含备份的SnapCenter 数据库和配置文件的快照。</block>
  <block id="d2727816fa1087ddac7dff69e35c5536" category="section-title">MS SQL</block>
  <block id="f9e005542c2e103eede9db2dfe82bdc7" category="paragraph">在此解决方案 验证中、我们使用MS SQL演示灾难恢复。</block>
  <block id="ed94f710e6ae715e2f17c5670d6bf092" category="paragraph">有关MS SQL和NetApp ONTAP 最佳实践的详细信息、请参见<block ref="1ed6e40008e985821d1338a60f7ccab3" category="inline-link-rx"></block>。</block>
  <block id="05241239c2e205951eabc51d0b39de96" category="section-title">Veeam</block>
  <block id="cf575d98d37c3423857f91c318d883e7" category="paragraph">在此解决方案 验证过程中、我们使用Veeam演示灾难恢复。有关Veeam和NetApp ONTAP 最佳实践的详细信息、请参见<block ref="69659c9961c1e42b0f8742562f24fdfa" category="inline-link-rx"></block>。</block>
  <block id="59288c543af9b26fa84b24054d3be8dc" category="paragraph">您必须能够执行以下任务：</block>
  <block id="f35a1ddfb2f9b2cac114bd32ce5bbbab" category="list-text">部署和配置域服务。</block>
  <block id="71877c1e84cfa72072c46494d86a8ee7" category="list-text">在给定VPC中根据应用程序要求部署FSX ONTAP。</block>
  <block id="9135a2c6ac5c27bd10c50337c5a89f26" category="list-text">在AWS计算网关上配置VMware Cloud、以允许来自FSX ONTAP 的流量。</block>
  <block id="8a401f5d4b33a44bd1812ff7ead2248d" category="list-text">配置AWS安全组、以允许AWS子网上的VMware Cloud与部署了FSX ONTAP 服务的AWS VPC子网之间进行通信。</block>
  <block id="2e31cdf7daad1ca06d6642765fa13252" category="section-title">VMware Cloud</block>
  <block id="f7f38aee276941a8501ab3a4788fb838" category="list-text">在AWS SDDC上配置VMware Cloud。</block>
  <block id="08aa379cc2bcb108397d323bd5732f6c" category="section-title">Cloud Manager帐户验证</block>
  <block id="17d24c2f3d504e509ec34ba87bfea6a5" category="paragraph">您必须能够使用NetApp Cloud Manager部署资源。要验证是否可以、请完成以下任务：</block>
  <block id="2ee5d6132c6433861745857e6af68778" category="inline-link">注册Cloud Central</block>
  <block id="604e59aa26a0b211909e4b9590685eb1" category="list-text"><block ref="35c2f2ba3f068c3df62b94b779d38cce" category="inline-link-rx"></block> 如果您尚未执行此操作。</block>
  <block id="e7ef0ccc08f963a97d6ab9c3aabc5081" category="inline-link">登录到Cloud Manager</block>
  <block id="5ec677c5c014e60203e82de8cbed20e4" category="list-text"><block ref="77549d8461eff5ea7726f72f7e171b7c" category="inline-link-rx"></block>。</block>
  <block id="78e80a35b7d01f404398eea432dd9654" category="inline-link">设置工作空间和用户</block>
  <block id="6693afd5aef7c87168fb40b34d61e795" category="list-text"><block ref="491866e862424f2a10f9441373484bc0" category="inline-link-rx"></block>。</block>
  <block id="e7a9cd1dc4bf0c230d0684e18369d70d" category="inline-link">创建连接器</block>
  <block id="821d88deb5e031a9587e5a8e00abe556" category="list-text"><block ref="b3797d3b448c35004d47db91b5cf65cf" category="inline-link-rx"></block>。</block>
  <block id="4c0f2b07e3034da6a2b901197cec7210" category="paragraph">拥有AWS帐户后、您必须能够执行以下任务：</block>
  <block id="7d8207e3bfa061fd6c5b1389d79e23e4" category="list-text">创建一个能够为NetApp ONTAP 文件系统配置Amazon FSX的IAM管理用户。</block>
  <block id="7984cdcb84b94f3ec5af3c2aa0bc9f9c" category="section-title">配置前提条件</block>
  <block id="799b279302dc2106f49a0c61994a42a1" category="paragraph">鉴于客户拥有不同的拓扑结构、本节重点介绍实现从内部资源到云资源的通信所需的端口。</block>
  <block id="dee55c33a91e43d371aa8eab0ee8968e" category="section-title">所需端口和防火墙注意事项</block>
  <block id="34e0f9db6d0a94f20e464420fb481570" category="paragraph">下表介绍了必须在整个基础架构中启用的端口。</block>
  <block id="28c5fdd36289c2258f08118f41c54729" category="paragraph">有关Veeam Backup &amp; Replication软件所需端口的更全面列表、请按照<block ref="2a9b4a1873abbc6819ad7073e9ebc1a5" category="inline-link-rx"></block>。</block>
  <block id="2a975bb27423e33e6c65cb2e2b14db28" category="paragraph">有关SnapCenter 的端口要求的更全面列表、请按<block ref="4939c26301b3a22bfb3c0a6725311b88" category="inline-link-rx"></block>。</block>
  <block id="8a042a39d5b3b0e7e0554c5af7abd76b" category="paragraph">下表列出了Microsoft Windows Server的Veeam端口要求。</block>
  <block id="5da618e8e4b89c66fe86e32cdafde142" category="cell">from</block>
  <block id="e12167aa0a7698e6ebc92b4ce3909b53" category="cell">收件人：</block>
  <block id="60aaf44d4b562252c04db7f98497e9aa" category="cell">Port</block>
  <block id="f4c6f851b00d5518bf888815de279aba" category="cell">注释：</block>
  <block id="52045ab804b1b913874ef04c2c3a2f69" category="cell">备份服务器</block>
  <block id="de6900dd0f213be9d369252ce490a1df" category="cell">Microsoft Windows服务器</block>
  <block id="b136ef5f6a01d816991fe3cf7a6ac763" category="cell">TCP</block>
  <block id="67f7fb873eaf29526a11a9b7ac33bfac" category="cell">445</block>
  <block id="3f8c4ba1591441de01c30814d6be96cb" category="cell">部署Veeam Backup &amp; Replication组件所需的端口。</block>
  <block id="a34fcb59deecb10582ae58c505df58ba" category="cell">备份代理</block>
  <block id="fa3060edb66e6ff4507886f9912e1ab9" category="cell">6160</block>
  <block id="a615435ab6eb1aac4a4b4c4ebe2a89e9" category="cell">Veeam安装程序服务使用的默认端口。</block>
  <block id="480ddf908a09bb49e2eb46b2293d83e0" category="cell">备份存储库</block>
  <block id="84c456c47f1859be98a88fa53ffca994" category="cell">2500到3500</block>
  <block id="1622c3ddec12802a4bc6cbb96c7b1b49" category="cell">用作数据传输通道和收集日志文件的默认端口范围。</block>
  <block id="a31f402016255891ea5a6010567d0c28" category="cell">挂载服务器</block>
  <block id="6aaba9a124857622930ca4e50f5afed2" category="cell">6162</block>
  <block id="f36e2d75f4071e4e994fdbc77c14ddb0" category="cell">Veeam Data Mover使用的默认端口。</block>
  <block id="510f315f3436af1e5ec4cb22dd263070" category="admonition">对于作业使用的每个TCP连接、都会为此范围分配一个端口。</block>
  <block id="655a5fe10451fb66645cbcdec5034698" category="paragraph">下表列出了Linux Server的Veeam端口要求。</block>
  <block id="b5d9f1a9fbf0fb75f6765f140eb5774f" category="cell">Linux服务器</block>
  <block id="28c991d1c426febedd1596fd29a3f864" category="cell">用作从控制台到目标Linux主机的控制通道的端口。</block>
  <block id="a4fda10bbaa8015596c2c1c1dd6f1a36" category="paragraph">下表列出了Veeam Backup Server的端口要求。</block>
  <block id="4197adf45342f775880cf0b40b2bebe4" category="cell">HTTPS、TCP</block>
  <block id="ff48f6174c8c54c3faa04ebcf25b720d" category="cell">用于连接到vCenter Server的默认端口。用作从控制台到目标Linux主机的控制通道的端口。</block>
  <block id="dad95acf5318650271f0853ca3c36a1a" category="cell">托管Veeam Backup &amp; Replication配置数据库的Microsoft SQL Server</block>
  <block id="8fb5f8be2aa9d6c64a04e3ab9f63feee" category="cell">1443</block>
  <block id="dc0848552680aa2839c317b54853b6c8" category="cell">用于与部署Veeam Backup &amp; Replication配置数据库的Microsoft SQL Server进行通信的端口(如果使用Microsoft SQL Server默认实例)。</block>
  <block id="1cdaa0286d1e5b2da16bb4a4d56030e5" category="cell">所有备份服务器的名称解析DNS服务器</block>
  <block id="8643c8e2107ba86c47371e037059c4b7" category="cell">3389</block>
  <block id="2914ea759530f85f84d8d97088f4c0fb" category="cell">用于与DNS服务器通信的端口</block>
  <block id="462cb0982d9c6d8b64cd1a92197cad0e" category="admonition">如果使用vCloud Director、请确保打开底层vCenter Server上的端口443。</block>
  <block id="5fd55c0224ae845943b259eaa37fa9de" category="paragraph">下表列出了Veeam Backup Proxy端口要求。</block>
  <block id="e564618b1a0f9a0e5b043f63d43fc065" category="cell">6210</block>
  <block id="06c6eec6c18e0d75ea5c6853a2397d90" category="cell">Veeam Backup VSS集成服务用于在SMB文件共享备份期间创建VSS快照的默认端口。</block>
  <block id="dd46e35ec3bd7632e2b6924b4ace5592" category="cell">可在vCenter设置中自定义的默认VMware Web服务端口。</block>
  <block id="67f0bc6c760260e8ecb1e44fc5337bd6" category="paragraph">下表列出了SnapCenter 端口要求。</block>
  <block id="bd9f125b279a19f0d5b7f09c7d793d35" category="cell">端口类型</block>
  <block id="d7ca8612b857419959ee2c089e5be08c" category="cell">SnapCenter 管理端口</block>
  <block id="0e8433f9a404f1f3ba601c14b026d321" category="cell">HTTPS</block>
  <block id="202ed3792e2cfa7318b12ead83763c37" category="cell">8146</block>
  <block id="a1a3a7ab0e2e0b654e17bb8a2e57e9e5" category="cell">此端口用于SnapCenter 客户端(SnapCenter 用户)与SnapCenter 服务器之间的通信。也用于从插件主机到 SnapCenter 服务器的通信。</block>
  <block id="18622e175ff22b2375f9cbc2314b3285" category="cell">SnapCenter SMCore 通信端口</block>
  <block id="bb68b5529560433e58ff13eb45622724" category="cell">此端口用于在SnapCenter 服务器与安装SnapCenter 插件的主机之间进行通信。</block>
  <block id="f79093a340ccf8139d6e585381acc44c" category="cell">Windows插件主机、安装</block>
  <block id="a1639b6147c7f85402852464ce33b9ae" category="cell">135、445</block>
  <block id="4b790f3dbcd2d867091d8fbf3b63026f" category="cell">这些端口用于在SnapCenter 服务器与要安装此插件的主机之间进行通信。这些端口可以在安装后关闭。此外、Windows Instrumentation Services还会搜索端口49152到65535、这些端口必须处于打开状态。</block>
  <block id="da8fa0760683502b8b15e2d8f992b780" category="cell">Linux插件主机、安装</block>
  <block id="765553e6c7ac8592c389acb9878a050a" category="cell">SSH</block>
  <block id="e541d805fe886aded7cfb18984fba335" category="cell">这些端口用于在SnapCenter 服务器与要安装此插件的主机之间进行通信。SnapCenter 使用这些端口将插件软件包二进制文件复制到Linux插件主机。</block>
  <block id="8ffa3ad47599004a1c67f905da7456c0" category="cell">适用于Windows/Linux的SnapCenter 插件软件包</block>
  <block id="0c0cfd9478c6551fbfe74a7acb6fc037" category="cell">8145</block>
  <block id="9b52abdc2eaa620c3f1c7588679b8764" category="cell">此端口用于在SMCore与安装了SnapCenter 插件的主机之间进行通信。</block>
  <block id="7c1239972879fe0b69b4bb6d5c9a743e" category="cell">VMware vSphere vCenter Server 端口</block>
  <block id="4047860556fa008e56adfadd36f5b7af" category="cell">此端口用于在适用于VMware vSphere的SnapCenter 插件与vCenter服务器之间进行通信。</block>
  <block id="87db2cdf992c6481194f67a3c24f2d31" category="cell">适用于VMware vSphere的SnapCenter 插件端口</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="397d2ce87a0d127486b8fa20c5f3cdb9" category="cell">此端口用于从vCenter vSphere Web Client和SnapCenter 服务器进行通信。</block>
  <block id="f201deaeba7cc565253f52d974008543" category="summary">要将应用程序VM和数据库卷故障转移到AWS中运行的VMware云卷服务、您必须安装并配置SnapCenter 服务器和Veeam备份和复制服务器的正在运行的实例。故障转移完成后、您还必须配置这些工具以恢复正常备份操作、直到计划并执行到内部数据中心的故障恢复为止。</block>
  <block id="a514f4da2fec40b52d89613d7b3854fa" category="section-title">部署二级Windows SnapCenter 服务器</block>
  <block id="dba3e8475ef38dcd147447c5730c2f7c" category="paragraph">SnapCenter 服务器部署在VMware云SDDC中或安装在VPC中的EC2实例上、并通过网络连接到VMware云环境。</block>
  <block id="1a297f32b70010f208d00a4f58855fec" category="paragraph">SnapCenter 软件可从NetApp支持站点获得、并可安装在位于域或工作组中的Microsoft Windows系统上。有关详细的规划指南和安装说明、请参见<block ref="92e6fa322f689d7da93690560d0b41bd" category="inline-link-rx"></block>。</block>
  <block id="4adffd967d9bbc0f71287e67a568e0ae" category="paragraph">您可以在以下位置找到SnapCenter 软件：<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>。</block>
  <block id="224efa116a105cfd586d82f09e7cd1fe" category="section-title">配置二级Windows SnapCenter 服务器</block>
  <block id="9ec64430f94c7b2f3824857182b8ff9d" category="paragraph">要还原镜像到FSX ONTAP 的应用程序数据、您必须先完全还原内部SnapCenter 数据库。此过程完成后、将重新建立与VM的通信、现在可以使用FSX ONTAP 作为主存储来恢复应用程序备份。</block>
  <block id="b502974234450ceabf2344f2a3e45f7a" category="paragraph">为此、您必须在SnapCenter 服务器上完成以下各项：</block>
  <block id="13d56fa22f861d817f01e34bd0dff18d" category="list-text">将计算机名称配置为与原始内部SnapCenter 服务器相同。</block>
  <block id="87da734902f9a20ba518a732df6228fc" category="list-text">配置网络以与VMware Cloud和FSX ONTAP 实例进行通信。</block>
  <block id="7f2fdcaa4d368c36731db2bdf5eb79a9" category="list-text">完成操作步骤 以还原SnapCenter 数据库。</block>
  <block id="b9f6e6c037c51c372d51f5f4254d76cc" category="list-text">确认SnapCenter 处于灾难恢复模式、以确保FSX现在成为备份的主存储。</block>
  <block id="b8864a7697abc4d58d337a7803f7ca8e" category="list-text">确认已与还原的虚拟机重新建立通信。</block>
  <block id="6b9d280aee667ad2407fdb311dc034cb" category="inline-link-macro">SnapCenter 数据库还原过程</block>
  <block id="4757e8da6d3b5465a3ae91d8390db6d9" category="paragraph">有关完成这些步骤的详细信息、请参见第节的 <block ref="fe5a34b461345b6f910f9d5fd86fde40" category="inline-link-macro-rx"></block>。</block>
  <block id="b827704a3bb22b3992173e0581a1c28b" category="paragraph">您可以在AWS上的VMware Cloud中的Windows服务器或EC2实例上安装Veeam Backup &amp; Replication服务器。有关详细的实施指导、请参见<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>。</block>
  <block id="e271ecc9b2a2050b58d0914d62a2325b" category="paragraph">要还原已备份到Amazon S3存储的虚拟机、您必须在Windows服务器上安装Veeam服务器、并将其配置为与VMware Cloud、FSX ONTAP 和包含原始备份存储库的S3存储分段进行通信。此外、还必须在FSX ONTAP 上配置一个新的备份存储库、以便在虚拟机还原后对其执行新备份。</block>
  <block id="d569da58bc917eb906ada72f76bf1030" category="paragraph">要执行此过程、必须完成以下各项：</block>
  <block id="6443544e723bdb5a8e0b2e300ce4e821" category="list-text">配置网络以与VMware Cloud、FSX ONTAP 和包含原始备份存储库的S3存储分段进行通信。</block>
  <block id="d19ea991ccb7ded9582c07fa062fb3b4" category="list-text">将FSX ONTAP 上的SMB共享配置为新的备份存储库。</block>
  <block id="adf79b820407599132e907adb994746d" category="list-text">在内部挂载用作横向扩展备份存储库一部分的原始S3存储分段。</block>
  <block id="a706ef66660617fcf4a5aeb2e6f6d76b" category="list-text">还原VM后、建立新的备份作业以保护SQL和Oracle VM。</block>
  <block id="28850f35c95cf12d5e28a35c2fdd8e5d" category="inline-link-macro">使用Veeam Full Restore还原应用程序VM</block>
  <block id="5e86473217a757f4702d326176983651" category="cell">2022年7月28日</block>
  <block id="e325d40f0256e06aa0a0f1c795ea68ee" category="cell">为AWS/VMC添加了具有SnapCenter 和Veeam功能的DR解决方案 (子系统连接存储)</block>
  <block id="af2a34190d0729a3b5a2ed9d50d9e399" category="cell">采用VMware解决方案的混合多云的有序内容：每个超大规模云提供商的登录页面以及提供的解决方案 (用例)内容</block>
  <block id="9c00744e128712d7626e5c00edcfeaa1" category="cell">创建了登录页面、以便更好地组织与VMware的虚拟化和混合多云相关的内容</block>
  <block id="5424d7e641fa7962888e16022445e1ae" category="cell">为虚拟化环境和子系统连接存储选项创建包含VMware内容的混合多云</block>
  <block id="e307db07b3975fef922a80d07455ee5e" category="cell">数据库</block>
  <block id="6c6fb0f7e5fe3a7242028f22d2792fca" category="cell">在 NetApp 解决方案区块中添加了有关企业级应用程序和数据库的博客部分。在数据库博客中添加了两个博客。</block>
  <block id="c99ec32d06b1f19699d82b1b34a80ca0" category="paragraph"><block ref="c99ec32d06b1f19699d82b1b34a80ca0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58098d451cf2728b0542acd542f9000b" category="cell">*补充NFS数据存储库*</block>
  <block id="51b0e38e5ec7edbe37b6672987ce5f2e" category="paragraph">详细了解NetApp为三(3)个主要超大规模提供商提供的功能—从NetApp作为子系统连接存储设备或补充NFS数据存储库、到迁移工作流、扩展/突发云、备份/还原和灾难恢复。</block>
  <block id="d22e98327d29984cdf19ebfeeb53bd99" category="paragraph">详细了解NetApp为AWS VMware Cloud (VMC)提供的功能—从作为子系统连接存储设备或补充NFS数据存储库的NetApp到迁移工作流、扩展/突发到云、备份/还原和灾难恢复。</block>
  <block id="e3dea11e8144be98f637687e2a2cf316" category="paragraph">NetApp存储可以通过多种方式在AWS VMC中用作guess connected或作为补充NFS数据存储库。</block>
  <block id="206616b83a19162051802c3823da0f7c" category="paragraph">此外、NetApp还为配置为来宾(来宾连接)存储或每个超大规模存储器中的补充NFS数据存储库的存储提供了解决方案。所有解决方案均与VMware对云工作负载的分类一致。这些分类包括：</block>
  <block id="04e248dee456b1f3910d53450d745125" category="list-text">利用云补充技术实现应用程序现代化。</block>
  <block id="77d50dd2ce4e2531e14f13434a560e7d" category="section-title">了解补充NFS存储选项的重要性</block>
  <block id="de8529127f85189767876e4d9a97427c" category="paragraph">尽管VMware在任何云中都能为每个客户提供独特的混合功能、但有限的补充NFS存储选项限制了它对存储负载繁重的组织的有用性。由于存储与主机直接相关，因此扩展存储的唯一方法是添加更多主机，这样对于存储密集型工作负载，成本可能会增加 35% – 40% 或更多。这些工作负载只需要额外的存储，而不是额外的功率。但这意味着需要为额外的主机付费。</block>
  <block id="af68f7a1e7ca322318bf949baba2129e" category="inline-link-macro">使用ANF和Jetstream (补充NFS数据存储库)进行灾难恢复</block>
  <block id="73c807da78ef06fdb99e2307b5d8cb57" category="list-text"><block ref="73c807da78ef06fdb99e2307b5d8cb57" category="inline-link-macro-rx"></block></block>
  <block id="f93c390413608eaad8cc43b29f8073d0" category="inline-link-macro">使用ANF和CVO (子系统连接存储)进行灾难恢复</block>
  <block id="233b8f979ad627e56656fbdd647fdc2b" category="list-text"><block ref="233b8f979ad627e56656fbdd647fdc2b" category="inline-link-macro-rx"></block></block>
  <block id="5f2df3110b7088a1c8d1659ffb728f46" category="doc">使用CVO和AVS进行灾难恢复(来宾连接存储)</block>
  <block id="9a130cd816dc8be85c4f198310f16e4c" category="paragraph">详细了解NetApp为Azure VMware解决方案 (AVS)提供的功能—从作为子系统连接存储设备或补充NFS数据存储库的NetApp到迁移工作流、扩展/突发到云、备份/还原和灾难恢复。</block>
  <block id="465fe02ad52f12cc5844200de029e385" category="paragraph">NetApp存储可以通过多种方式在Azure AVS中用作guess connected或作为补充NFS数据存储库。</block>
  <block id="827f15aa97cbfccd71eb2ba3ac7d4eac" category="doc">Azure中的补充NFS数据存储库选项</block>
  <block id="d6e093aa5c1e7500fe79b8732c410c91" category="paragraph">此外、您还可以通过Azure NetApp Files 部署多个数据存储库、通过将虚拟机放置在适当的数据存储库中并分配所需的服务级别来满足工作负载性能要求、这有助于模拟内部部署模式。凭借多协议支持的独特功能、子系统存储是SQL和Oracle等数据库工作负载的一个附加选项、同时还可以使用补充NFS数据存储库功能来容纳其余VMDK。除此之外、您还可以通过原生 快照功能执行快速备份和粒度恢复。</block>
  <block id="402936a0724fed1eeed39a4791eae422" category="paragraph">从高层面来看、此架构介绍了如何跨内部环境和Azure实现混合云连接和应用程序可移植性。此外、还介绍了如何使用Azure NetApp Files 作为补充NFS数据存储库以及Azure VMware解决方案 上托管的子虚拟机的子系统内存储选项。</block>
  <block id="66433e0e715221ebed495642af8005b7" category="doc">适用于GCP的NetApp补充NFS数据存储库选项</block>
  <block id="275ed895f3f409270670131f7369b1ac" category="paragraph">NetApp存储可以通过多种方式在GCP GCVE中用作guess connected或作为补充NFS数据存储库。</block>
  <block id="55b61b011b735ba396a8dbd7e3f95f20" category="cell">2022年5月8日</block>
  <block id="015a03470e91621621a76f7a4e3dc56e" category="sidebar">ANF as a Supplemental NFS Datastore：概述</block>
  <block id="95fd29d87d2c7d3100a5198bc7067e95" category="sidebar">AVS的补充NFS数据存储库</block>
  <block id="e7e97f343a76aab098fd05b8953ee1a5" category="list-text">将Azure NetApp Files 数据存储库连接到Azure VMware解决方案 主机(预览)</block>
  <block id="1838681ebe885a1a1e886cdf7e263065" category="inline-link"><block ref="1838681ebe885a1a1e886cdf7e263065" category="inline-link-rx"></block></block>
  <block id="2361f6fabb02c6060c638b5f1780cda2" category="paragraph"><block ref="2361f6fabb02c6060c638b5f1780cda2" category="inline-link-rx"></block></block>
  <block id="bcd4c93e63ff96ec357bc67c62874e0c" category="cell">2022年8月23日</block>
  <block id="10daf0bb04814721080056526de2b200" category="cell">已更新所有补充NFS数据存储库选项的最新区域可用性</block>
  <block id="9e779086e93810f8495caf5b07f578cd" category="paragraph">Azure / AVS上的补充NFS数据存储库的可用性由Microsoft定义。首先、您需要确定AVS和ANF是否在特定区域可用。接下来、您需要确定该区域是否支持ANF补充NFS数据存储库。</block>
  <block id="8ff7e1fad21e60bbdef17593aae83ff6" category="list-text">检查AVS和ANF的可用性 <block ref="757f75bead0b939967621d226ba54faa" category="inline-link-macro-rx"></block>。</block>
  <block id="2f53a51554f6e0b66622228f3db68361" category="list-text">检查ANF补充NFS数据存储库的可用性 <block ref="02ba6bc5fe71be0f7426aedd427de443" category="inline-link-macro-rx"></block>。</block>
  <block id="46c2094fdbb2fbdc301a330fb7419074" category="paragraph">AWS/VMC上的补充NFS数据存储库的可用性由Amazon定义。首先、您需要确定VMC和FSxN是否在指定区域中可用。接下来、您需要确定该区域是否支持FSxN补充NFS数据存储库。</block>
  <block id="c10e413ea65850b7369ee5ae6f60b460" category="list-text">VMC的FSxN补充NFS数据存储库即将推出。</block>
  <block id="a1838a4ac0f386c517d82fae26f2372e" category="paragraph">虽然信息仍在发布中、但下图将当前对VMC、FSxN和FSxN的支持标识为一个补充NFS数据存储库。</block>
  <block id="97be15a34c6b82b6177132129dd0b293" category="doc">区域可用性—VMC的补充NFS数据存储库</block>
  <block id="0b6b52ed7135814c4a167640dee306f2" category="doc">区域可用性—Google Cloud Platform (GCP)的补充NFS数据存储库</block>
  <block id="e78040a1599894c3db7423e479a1f7d1" category="summary">将灾难恢复到云是一种具有弹性且经济高效的方式、可保护工作负载免受站点中断和勒索软件等数据损坏事件的影响。借助NetApp SnapMirror、可以将使用来宾连接存储的内部VMware工作负载复制到在Google Cloud中运行的NetApp Cloud Volumes ONTAP。</block>
  <block id="58997b61f0fc8812c9977a9dd3d181c5" category="doc">使用SnapCenter 、Cloud Volumes ONTAP 和Veeam复制实现应用程序灾难恢复</block>
  <block id="0fa916b50826c2fab3e504331d6b8ad1" category="paragraph">作者：NetApp公司Suresh ThopPay</block>
  <block id="366fe59477118cc36e7ef7936cc04771" category="paragraph">将灾难恢复到云是一种具有弹性且经济高效的方式、可保护工作负载免受站点中断和勒索软件等数据损坏事件的影响。借助NetApp SnapMirror、可以将使用来宾连接存储的内部VMware工作负载复制到在Google Cloud中运行的NetApp Cloud Volumes ONTAP。其中包括应用程序数据；但是、实际VM本身又如何。灾难恢复应涵盖所有相关组件、包括虚拟机、VMDK、应用程序数据等。为此、可以使用SnapMirror和Veeam无缝恢复从内部复制到Cloud Volumes ONTAP 的工作负载、同时对VM VMDK使用vSAN存储。</block>
  <block id="93fb0db9f34ab708d4c3e5d233e4d97f" category="paragraph">本文档提供了使用NetApp SnapMirror、Veeam和Google Cloud VMware Engine (GCVE)设置和执行灾难恢复的分步方法。</block>
  <block id="669129cbcdc854bf23fe7e672be9c44c" category="paragraph"><block ref="669129cbcdc854bf23fe7e672be9c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c611c3f34a5f506ad20f441b78810981" category="paragraph">要在内部环境与Google Cloud网络之间建立连接、请使用专用互连或Cloud VPN等连接选项。应根据内部VLAN设计创建分段。</block>
  <block id="b62c675a3e45635be4cc5a65dde4c55c" category="admonition">将内部数据中心连接到Google Cloud有多种方式、这使我们无法在本文档中概述特定工作流。有关适当的内部到Google连接方法、请参见Google Cloud文档。</block>
  <block id="5e345ef39956138694764fce9921e498" category="list-text">安装Veeam软件并开始将虚拟机复制到Google Cloud VMware Engine实例。</block>
  <block id="7c6d17fe855de9f3821d0cead78f4d26" category="list-text">发生灾难事件时、使用Cloud Manager中断SnapMirror关系、并触发Veeam虚拟机故障转移。</block>
  <block id="e36e9213012a15c95ec5048a09f751b0" category="list-text">使应用程序联机。</block>
  <block id="820f3ffde5403dbc2ca3d17b511f569e" category="example-title">在Google Cloud上配置CVO并将卷复制到CVO</block>
  <block id="6765d7341fa9566a047031c62d2040b8" category="inline-link">CVO</block>
  <block id="1b6eb09708583df3feb79dd7e7b9ed2a" category="paragraph"><block ref="1b6eb09708583df3feb79dd7e7b9ed2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b67ee8de7f0f6f1b68e41ce4be6b4a0b" category="inline-link">使用SnapCenter 设置复制</block>
  <block id="5a101eac27a34cdc3b06c105760d0cee" category="example-title">配置GCVE主机和CVO数据访问</block>
  <block id="1fe9f40218e52161bc5e31e2cd383a0b" category="paragraph">部署SDDC时需要考虑的两个重要因素是GCVE解决方案 中SDDC集群的大小以及SDDC的持续运行时间。对于灾难恢复解决方案 、这两个主要注意事项有助于降低整体运营成本。SDDC可以小至三台主机、在整个规模的部署中一直到多主机集群。</block>
  <block id="4f7b492a9eedf950f4dbd01357b22979" category="paragraph">可以将Cloud Volumes ONTAP 部署到任何VPC、并且CVE应与该VPC建立专用连接、以便VM连接到iSCSI LUN。</block>
  <block id="fb75a211e033fa96e7f692258221c1da" category="paragraph">正确配置Cloud Volumes ONTAP 和GCVE后、请使用Veeam复制功能并利用SnapMirror将应用程序卷副本复制到Cloud Volumes ONTAP 、开始配置Veeam、以便自动将内部工作负载恢复到GCVE (具有应用程序VMDK的VM和具有来宾存储的VM)。</block>
  <block id="87e3cc18e14b0d78c8c46e3ed343fca7" category="example-title">安装Veeam组件</block>
  <block id="60fec867397af265e1e757d06135859e" category="example-title">使用Veeam设置VM复制</block>
  <block id="d81c3dfdfda7fb8581660b5d218c6a3a" category="inline-link">设置vSphere VM复制作业</block>
  <block id="6a67b79523a52a3a2b4e485485456565" category="paragraph">内部vCenter和GCVE vCenter都需要向Veeam注册。<block ref="9af60ccd7c779b77ba6ce43ae96a95f6" category="inline-link-rx"></block> 在向导的子系统处理步骤中、选择禁用应用程序处理、因为我们将利用SnapCenter 进行应用程序感知型备份和恢复。</block>
  <block id="34510608302d692ff6f3936359703d26" category="example-title">Microsoft SQL Server VM故障转移</block>
  <block id="ce137de4140fd114a7fb3fcb057328fa" category="list-text">Veeam复制允许更改灾难恢复站点上的VM IP地址。</block>
  <block id="dee7570423fb41bfa5f00fd539ed91da" category="doc">区域可用性—适用于ANF的补充NFS数据存储库</block>
  <block id="9e289e2a1ce460725108e7241e19b575" category="doc">AWS、Azure和GCP上的补充NFS数据存储库的区域可用性</block>
  <block id="3ce209dcd58ed0c7d8cf39f37f2b1557" category="paragraph">详细了解全球地区对AWS、Azure和Google Cloud Platform (GCP)上的补充NFS数据存储库的支持。</block>
  <block id="f22705ef66107a528d4982aa8fdd463d" category="list-text"><block ref="f22705ef66107a528d4982aa8fdd463d" category="inline-link-macro-rx"></block></block>
  <block id="d15aa19396a83c3c15a1fb8ba83efda1" category="cell">2022年8月25日</block>
  <block id="f37741764b2517136f3747b14ec803a0" category="cell">全新解决方案 ：采用NetApp和VMware的NVIDIA AI Enterprise</block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterprise是一款端到端云原生AI和数据分析软件套件、经过优化、可帮助每个企业利用AI取得成功。</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">采用NetApp和VMware的NVIDIA AI Enterprise</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">对于IT架构师和管理员来说、AI工具可能非常复杂、而且不熟悉。此外、许多AI平台还没有为企业做好准备。由NetApp和VMware提供支持的NVIDIA AI Enterprise旨在提供简化的企业级AI架构。</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterprise是一款端到端云原生AI和数据分析软件套件、经过NVIDIA优化、认证和支持、可在采用NVIDIA认证系统的VMware vSphere上运行。此软件有助于在现代混合云环境中轻松快速地部署、管理和扩展AI工作负载。由NetApp和VMware提供支持的NVIDIA AI Enterprise通过一个简单熟悉的软件包提供企业级AI工作负载和数据管理。</block>
  <block id="24c4078c95e6e2df55bd1d251c11f4aa" category="paragraph"><block ref="24c4078c95e6e2df55bd1d251c11f4aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">采用NetApp和VMware的NVIDIA AI Enterprise—技术概述</block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="section-title">NVIDIA AI Enterprise</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterprise是一款端到端云原生AI和数据分析软件套件、经过NVIDIA优化、认证和支持、可在采用NVIDIA认证系统的VMware vSphere上运行。此软件有助于在现代混合云环境中轻松快速地部署、管理和扩展AI工作负载。</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC提供了一个GPU优化软件目录、供AI从业者开发其AI解决方案。此外、还可以访问各种AI服务、包括用于模型培训的NVIDIA Base Command、用于部署和监控模型的NVIDIA Baset Command以及用于安全访问和管理专有AI软件的NGC私有注册表。此外、NVIDIA AI Enterprise客户还可以通过NGC门户申请支持。</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere是VMware的虚拟化平台、可将数据中心转变为包括CPU、存储和网络资源在内的聚合计算基础架构。vSphere将这些基础架构作为一个统一的操作环境进行管理、并为管理员提供用于管理参与该环境的数据中心的工具。</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">vSphere的两个核心组件是ESXi和vCenter Server。ESXi是一个虚拟化平台、管理员可以在此平台上创建和运行虚拟机和虚拟设备。vCenter Server是一项服务、管理员可以通过此服务管理连接到网络和池主机资源的多个主机。</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ONTAP 9是NetApp推出的最新一代存储管理软件、可帮助企业打造现代化的基础架构并过渡到云就绪数据中心。借助行业领先的数据管理功能，无论数据位于何处， ONTAP 都可以通过一组工具来管理和保护数据。您还可以将数据自由移动到需要的任何位置：边缘，核心或云。ONTAP 9包含许多功能、可简化数据管理、加快和保护关键数据、并在混合云架构中实现下一代基础架构功能。</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">NetApp DataOps工具包是一款基于Python的工具、可简化开发/培训工作空间和推理服务器的管理、这些工作空间和服务器由高性能横向扩展NetApp存储提供支持。主要功能包括：</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">快速配置新的高容量JupyterLab工作空间、这些工作空间以高性能横向扩展NetApp存储为后盾。</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">快速配置由企业级NetApp存储提供支持的新NVIDIA Triton推理服务器实例。</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">可近乎即时地克隆高容量JupyterLab工作空间、以便进行实验或快速迭代。</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">可近乎即时地保存高容量JupyterLab工作空间的快照、以实现备份和/或可追溯性/基线化。</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">近乎即时地配置、克隆和快照高容量、高性能数据卷。</block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">采用NetApp和VMware的NVIDIA AI Enterprise—架构</block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">此解决方案 基于经验证且熟悉的架构构建、该架构采用NetApp、VMware和NVIDIA认证系统。有关详细信息、请参见下表。</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">AI和数据分析软件</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">适用于VMware的NVIDIA AI Enterprise</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">虚拟化平台</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">计算平台</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">NVIDIA认证系统</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">数据管理平台</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="121c96ce43abda774fe95c1ccde1603e" category="paragraph"><block ref="121c96ce43abda774fe95c1ccde1603e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">采用NetApp和VMware的NVIDIA AI Enterprise—从何处查找追加信息</block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">采用VMware的NVIDIA AI Enterprise</block>
  <block id="5fad8e8f46a27398d761d66b0cb3f138" category="paragraph"><block ref="b79ccae54733d96b388303db61e85c7c" category="inline-link-rx"></block>]</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen、高级NetApp经理</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">NetApp系统管理员Ramesh Isaac</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">NetApp技术营销工程师Roney Daniel</block>
  <block id="ffdaf4e44bdc58181aaa1fb09d821794" category="summary">采用NetApp和VMware的NVIDIA AI Enterprise—使用NVIDIA NGC软件</block>
  <block id="a99b0f81ba7eb4c3316c034815d10d6f" category="doc">使用NVIDIA NGC软件</block>
  <block id="4161955dbf0998e264bc502f3cedc932" category="paragraph">本节介绍在NVIDIA AI Enterprise环境中使用NVIDIA NGC企业软件需要执行的任务。</block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">采用NetApp和VMware的NVIDIA AI Enterprise—使用NVIDIA NGC软件—设置</block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">本节介绍在NVIDIA AI Enterprise环境中使用NVIDIA NGC企业软件所需执行的初始设置任务。</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="inline-link-macro">初始设置</block>
  <block id="512338e48541699ec73dae999f67080a" category="paragraph">在执行本节所述的步骤之前、我们假定您已按照中所述的说明部署NVIDIA AI Entrprise主机软件 <block ref="a8e4d2617194ed990c0124f2cc8aee91" category="inline-link-macro-rx"></block> 页面。</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">使用vGPU创建Ubuntu子虚拟机</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">NVIDIA AI Enterprise部署指南</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">下载并安装NVIDIA子软件</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">NVIDIA AI Enterprise快速入门指南</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">接下来、您必须在上一步创建的子虚拟机中安装所需的NVIDIA子系统软件。要在子虚拟机中下载并安装所需的NVIDIA子软件、请按照中第5.1-5.4节所述的说明进行操作 <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>。</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">在执行第5.4节所述的验证任务时、您可能需要使用不同的CUDA容器映像版本标记、因为自编写本指南以来、CUDA容器映像已进行了更新。在我们的验证中、我们使用了"NVIDIA/CUDA：11.0.3-base-ubuntu20.04"。</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">下载AI/分析框架容器</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">安装和配置NetApp DataOps工具包</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">接下来、您必须在子虚拟机中安装适用于传统环境的NetApp DataOps工具包。NetApp DataOps工具包可用于直接从子虚拟机中的终端管理ONTAP 系统上的横向扩展数据卷。要在子虚拟机中安装NetApp DataOps工具包、请执行以下任务。</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">安装pip。</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">从子虚拟机终端中注销、然后重新登录。</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">配置NetApp DataOps工具包。要完成此步骤、您需要有关ONTAP 系统的API访问详细信息。您可能需要从存储管理员处获取这些信息。</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">创建子虚拟机模板</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">最后、您必须根据子虚拟机创建VM模板。您可以使用此模板快速创建子虚拟机、以便使用NVIDIA NGC软件。</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">要基于来宾VM创建VM模板、请登录到VMware vSphere、然后右键单击来宾VM名称、选择"克隆"、选择"克隆到模板..."、然后按照向导进行操作。</block>
  <block id="05e042a4870614727b5012704b95e5ec" category="paragraph"><block ref="05e042a4870614727b5012704b95e5ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">采用NetApp和VMware的NVIDIA AI Enterprise—使用NVIDIA NGC软件—示例用例—TensorFlow培训作业</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">示例用例—TensorFlow培训作业</block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">本节介绍在NVIDIA AI Enterprise环境中执行TensorFlow培训作业所需执行的任务。</block>
  <block id="cd33d31cec93ae54705bbc90e8ffbc09" category="paragraph">在执行本节所述的步骤之前、我们假定您已按照中所述的说明创建了子虚拟机模板 <block ref="8c165f1fe6ca595dd726d3af3dcdf541" category="inline-link-macro-rx"></block> 页面。</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">使用模板创建子虚拟机</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">首先、您必须使用上一节中创建的模板创建新的子虚拟机。要使用模板创建新的子虚拟机、请登录到VMware vSphere、然后右键单击模板名称、选择"从此模板新建虚拟机..."、然后按照向导进行操作。</block>
  <block id="9739d298a43441a49ece0169468d720e" category="paragraph"><block ref="9739d298a43441a49ece0169468d720e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">创建和挂载数据卷</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">接下来、您必须创建一个新的数据卷、用于存储培训数据集。您可以使用NetApp DataOps工具包快速创建新的数据卷。以下命令示例显示了如何创建容量为2 TB的名为"imagenet"的卷。</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">在为数据卷填充数据之前、必须先将其挂载到子虚拟机中。您可以使用NetApp DataOps工具包快速挂载数据卷。下面的示例命令显示了上一步创建的卷的布线。</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">填充数据卷</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">配置并挂载新卷后、可以从源位置检索培训数据集并将其放置在新卷上。这通常涉及从S3或Hadoop数据湖中提取数据、有时还需要数据工程师的帮助。</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">执行TensorFlow培训作业</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">现在、您已准备好执行TensorFlow培训作业。要执行TensorFlow培训作业、请执行以下任务。</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">提取NVIDIA NGC企业TensorFlow容器映像。</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">启动NVIDIA NGC企业版TensorFlow容器的实例。使用"-v"选项将数据卷连接到容器。</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">在容器中执行TensorFlow培训计划。下面的示例命令显示了容器映像中包含的示例RESNET-50培训计划的执行情况。</block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">采用NetApp和VMware的NVIDIA AI Enterprise—初始设置</block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">本节介绍在NetApp和VMware中使用NVIDIA AI Enterprise时需要执行的初始设置任务。</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">NVIDIA AI企业产品支持表</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">NetApp和VMware解决方案 文档</block>
  <block id="bf44a799ea99e6a60d34e10561a03e4e" category="paragraph">在执行本节所述的步骤之前、我们假定您已部署VMware vSphere和NetApp ONTAP。请参见 <block ref="7fc42871bfcfe7310a97a725dca473d8" category="inline-link-macro-rx"></block> 有关受支持的vSphere版本的详细信息。请参见 <block ref="627bf2e2dbf74de3f0be812563fb3ec4" category="inline-link-macro-rx"></block> 有关使用NetApp ONTAP 部署VMware vSphere的详细信息。</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">安装NVIDIA AI Enterprise Host软件</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">要安装NVIDIA AI Entrprise主机软件、请按照中第1-4节所述的说明进行操作 <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>。</block>
  <block id="56991209ac6bc77f76e9e1828103cdfc" category="cell">新增博客—利用Amazon FSX存储在混合云中实现Oracle数据库操作现代化</block>
  <block id="9f65880e605551f01ff1d2c03d3fa4c6" category="cell">2022年6月29日</block>
  <block id="304bc05c6debf3075c4f25dcffcf50bd" category="cell">添加了WP-7357：《基于EC2/FSX的Oracle数据库部署最佳实践》</block>
  <block id="befb671d4726ae8f3ef8dab781033dcc" category="inline-link-macro">使用存储快照克隆Oracle多租户可插拔数据库</block>
  <block id="aeb79a141f3c3f603cee05dfa64277aa" category="inline-link-macro">借助Amazon FSX存储在混合云中实现Oracle数据库运营现代化</block>
  <block id="a35641294527bf47526671d78d910a7e" category="list-text"><block ref="a35641294527bf47526671d78d910a7e" category="inline-link-macro-rx"></block></block>
  <block id="958dc0e3d1fcb4de4e8d506927ac81d3" category="sidebar">基于EC2/FSX的Oracle数据库部署最佳实践</block>
  <block id="9e2a9bc8a2f8e27bba893554318c300a" category="paragraph">存储库的所有主要更改（新解决方案，主要更新，新视频 / 演示等）都会在中进行跟踪 <block ref="62716531525ec9f2f5022745ce51b3a4" category="inline-link-macro-rx"></block>。</block>
  <block id="4d6f369fd362693ff1e7c02749ce60d9" category="example-title">如何为内部环境安装Jetstream DR</block>
  <block id="91a827791bf5a23c98b3d5c7a69fe4ac" category="example-title">如何在私有云中安装Jetstream DR for AVS</block>
  <block id="60e3a8b4e353d775c34a7d4d16b3d797" category="example-title">如何执行故障转移/故障恢复</block>
  <block id="a401c5c75859d12743686229123750bc" category="cell">2022年9月14日</block>
  <block id="1063ab954566d1fe67239a1e96653a34" category="cell">为AWS/VMC添加了补充NFS数据存储库选项</block>
  <block id="b7331610ced5770e91945f51e7656fcf" category="cell">为建议的ESXi和ONTAP 设置添加了"需要重新启动"信息</block>
  <block id="b6f0b1a9bd2c9c15cf02f97ead58d81f" category="list-text">FSX ONTAP 作为补充NFS数据存储库</block>
  <block id="aa98d71f784cc09bb41639407a3263d5" category="inline-link-macro">VMC的补充NFS数据存储库选项</block>
  <block id="7bf09ad035c9bf793d2fa043537aefb5" category="paragraph">查看详细信息 <block ref="cfba6c34c6cd33cf1694f8b48900db44" category="inline-link-macro-rx"></block>。查看详细信息 <block ref="a17693751f1eec7b9dedb49cf6a85cf2" category="inline-link-macro-rx"></block>。</block>
  <block id="483a9a3bc528f4d194f9f8f3d2a8411a" category="inline-link-macro">AVS的补充NFS数据存储库选项</block>
  <block id="026198900efc3d72ea20d8258c67523f" category="paragraph">查看详细信息 <block ref="c21bcdb7b1f85738a3211dff01d327ef" category="inline-link-macro-rx"></block>。查看详细信息 <block ref="266132cd9b913032bfeaea66cd238ea6" category="inline-link-macro-rx"></block>。</block>
  <block id="110493136fe9c9cec7895d42493cf949" category="doc">TR-4938：将Amazon FSX for ONTAP 作为NFS数据存储库挂载到AWS上的VMware Cloud中</block>
  <block id="fac58d9bf77947f6384b904919414388" category="paragraph">每个成功的组织都在转型和现代化的道路上。在此过程中、企业通常会利用现有的VMware投资来利用云优势、并探索如何尽可能无缝地迁移、突发、扩展和提供灾难恢复。迁移到云的客户必须评估弹性和突发、数据中心退出、数据中心整合、寿命终结情形、合并、 采集等。</block>
  <block id="040632d7dc15d3ff95c3010b585c825d" category="inline-link">近期集成</block>
  <block id="d790d297409e3864a7ea5e89c42f2281" category="paragraph">虽然基于AWS的VMware Cloud是大多数客户的首选选项、因为它可以为客户提供独特的混合功能、但有限的原生 存储选项限制了它对存储工作负载繁重的组织的有用性。由于存储与主机直接相关、因此扩展存储的唯一方法是添加更多主机、这样对于存储密集型工作负载、成本可能会增加35-40%或更多。这些工作负载需要额外的存储和隔离的性能、而不是额外的功率、而是需要为额外的主机付费。这就是<block ref="ce6e0c0e7e2ab2c5f159e9999125a0f1" category="inline-link-rx"></block> 适用于ONTAP 的FSX可通过AWS上的VMware Cloud方便地用于存储和性能密集型工作负载。</block>
  <block id="419a1659c567e39948d6e6e837c207d8" category="paragraph">我们来考虑以下情形：客户需要八台主机来提供功率(vCPU/vMem)、但他们也需要大量存储。根据他们的评估、他们需要16台主机来满足存储要求。这样可以提高总体TCO、因为他们必须购买所有这些额外的动力、而他们真正需要的只是更多的存储。这适用于任何使用情形、包括迁移、灾难恢复、突发、开发/测试、 等等。</block>
  <block id="477aa009d1d8f0ca50a38092473e92c8" category="paragraph">本文档将指导您完成在AWS上将适用于ONTAP 的FSX配置和连接为适用于VMware Cloud的NFS数据存储库所需的步骤。</block>
  <block id="dfc876546f6dc1183356f103bca8c9bf" category="section-title">连接选项</block>
  <block id="96ebe87ba2bf6e2436936fad5261faee" category="paragraph">本节介绍了高级连接架构以及实施解决方案 以扩展SDDC集群中的存储而无需添加其他主机所需的步骤。</block>
  <block id="f86935ff4bae98bba5454898ea941c13" category="paragraph"><block ref="f86935ff4bae98bba5454898ea941c13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5dfb62423539055e813d9c1ad0de5ec" category="paragraph">高级部署步骤如下：</block>
  <block id="a7e048390e1de16427d130135387bbfa" category="list-text">在新的指定VPC中创建适用于ONTAP 的Amazon FSx。</block>
  <block id="1f950f8c314491fa3429d8c2b47b567d" category="list-text">创建SDDC组。</block>
  <block id="564e0792e18e12a265348716dc476e35" category="list-text">创建VMware Transit Connect和Tgw.</block>
  <block id="6618150a8dc116ed81a57b9c0241d023" category="list-text">配置路由(AWS VPC和SDDC)和安全组。</block>
  <block id="657ef96833b0b326d08849a14b70424f" category="list-text">将NFS卷作为数据存储库连接到SDDC集群。</block>
  <block id="4950c77542ffaf6f7c4295f413cd34bf" category="inline-link-macro">在AWS上开始使用VMware Cloud</block>
  <block id="38cb82c3cccc048a7afcc98467fce2aa" category="paragraph">在将适用于ONTAP 的FSX配置和连接为NFS数据存储库之前、您必须先设置云SDDC环境或将现有SDDC升级到v1.20或更高版本。有关详细信息，请参见 <block ref="8f2441f58c4fdf4959e58cb9afc7d8c0" category="inline-link-macro-rx"></block>。</block>
  <block id="fcb9956e91549e3dd62d5abdb369413b" category="admonition">延伸型集群当前不支持适用于ONTAP 的FSX。</block>
  <block id="ee377d68ed297e79a44797bf1a95c224" category="paragraph">本文档介绍了在AWS上为适用于ONTAP 的Amazon FSX配置VMware云所需的步骤。Amazon FSX for ONTAP 提供了出色的选项、可用于部署和管理应用程序工作负载以及文件服务、同时通过将数据需求无缝地传输到应用程序层来降低TCO。无论使用何种情形、均可选择基于AWS的VMware云以及适用于ONTAP 的Amazon FSx、以快速实现云优势、从内部环境到AWS的一致基础架构和运营、工作负载的双向可移植性以及企业级容量和性能。这是用于连接存储的熟悉过程。请记住、随新名称一起更改的只是数据的位置；工具和流程都保持不变、Amazon FSx for ONTAP 有助于优化整体部署。</block>
  <block id="0f7e01a8024cd158b945c34799508470" category="paragraph">要了解有关此过程的更多信息、请随时观看详细的演练视频。</block>
  <block id="e4d49e783d07283d117d34b32c4415cd" category="doc">AWS中的补充NFS数据存储库选项</block>
  <block id="b2e86378d41d58201dddc613a82c81e2" category="paragraph">准备好VMware Cloud并连接到AWS VPC后、您必须将适用于NetApp ONTAP 的Amazon FSx部署到新指定的VPC中、而不是部署原始已连接或现有默认VPC。</block>
  <block id="b96e49fe229de5c473c616c913f822c8" category="inline-link">在VMware Cloud中配置SDDC组</block>
  <block id="ff5a4226923e95cf43bd31559660d1c8" category="paragraph">首先、在SDDC所在的区域和可用性区域部署一个额外的VPC、然后将适用于NetApp ONTAP 的Amazon FSX部署到新的VPC中。<block ref="5be76f2b0a93cb7fee056cbead96da1a" category="inline-link-rx"></block> 控制台可提供连接到新指定的VPC所需的网络配置选项、在此VPC中将部署FSX for ONTAP。</block>
  <block id="61a4d8e132eda51933073e665a4eac93" category="admonition">在与AWS SDDC上的VMware Cloud相同的可用区域中部署适用于ONTAP 的FSX。</block>
  <block id="55304a7521acfdd7143fb9cdb66a6344" category="paragraph">要创建和挂载适用于NetApp ONTAP 的Amazon FSX文件系统、请完成以下步骤：</block>
  <block id="1a8a81e4c4d14a95fc47e07b614950b5" category="list-text">打开位于`https://console.aws.amazon.com/fsx/`的Amazon FSX控制台、然后选择*创建文件系统*以启动*文件系统创建*向导。</block>
  <block id="ffd72149dd51740fcd4d150cabc5561f" category="list-text">在选择文件系统类型页面上、选择*适用于NetApp ONTAP 的Amazon FSx *、然后单击*下一步*。此时将显示*创建文件系统*页面。</block>
  <block id="e71747de43d70e18285f2764e5a036a6" category="paragraph"><block ref="e71747de43d70e18285f2764e5a036a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4817656b0e2a8e3ebdf2bd3377b2456" category="list-text">对于创建方法、请选择*标准创建*。</block>
  <block id="35eb19b4c782b6a9c50e35b42f8c1f8c" category="paragraph"><block ref="35eb19b4c782b6a9c50e35b42f8c1f8c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f47a2dd0d360703b1b45075c63cff1b" category="paragraph"><block ref="5f47a2dd0d360703b1b45075c63cff1b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="11dd82404551d7373785e4fcbc9b1005" category="list-text">在虚拟私有云(Virtual Private Cloud、VPC)的*网络*部分中、选择适当的VPC和首选子网以及路由表。在这种情况下、会从下拉菜单中选择Demo—FSxforontap-vPC。</block>
  <block id="a9bc1797cfb722fb8dbfec3b16f44cb9" category="paragraph"><block ref="a9bc1797cfb722fb8dbfec3b16f44cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a560e434862aec182aa626e0de6ca3a" category="list-text">在加密密钥的*安全性和加密*部分中、选择用于保护文件系统空闲数据的AWS密钥管理服务(AWS KMS)加密密钥。对于*文件系统管理密码*、输入fsxadmin用户的安全密码。</block>
  <block id="9626f8b41e6908a3873b72869026a9da" category="paragraph"><block ref="9626f8b41e6908a3873b72869026a9da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75f7834ca5cbd9bf6c7a2b2e5073b427" category="list-text">在*默认Storage Virtual Machine配置*部分中、指定SVM的名称。</block>
  <block id="7c32cf52ace07fb1672e72defde4ac61" category="admonition">自GA起、支持四个NFS数据存储库。</block>
  <block id="5c732cc058a6b6d4676b55223bf85f5f" category="paragraph"><block ref="5c732cc058a6b6d4676b55223bf85f5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51ac4bf63a0c6a9cefa7ba69b4154ef1" category="cell">正在设置 ...</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0%</block>
  <block id="a85c04491cb5bbcb534dc50b65b97530" category="cell">自动删除</block>
  <block id="4ec86a7059e3d1002a06c51cbec9ad47" category="cell">卷/ OLDEST_first</block>
  <block id="5987147997d274c5292cab0b0006bef1" category="cell">卷分层策略</block>
  <block id="902c737cbaa1a86889c41fec210c805f" category="cell">try_first</block>
  <block id="f4c25546f220bb5d07f94244c9303967" category="cell">自动增长</block>
  <block id="4c0abf2d4c54820b8d33061abaf30759" category="cell">快照策略</block>
  <block id="7c031a8d1af863155f52c6a16c34e0c1" category="paragraph"><block ref="7c031a8d1af863155f52c6a16c34e0c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3216fa1649258260fcc7fb0c291ff2fb" category="paragraph"><block ref="3216fa1649258260fcc7fb0c291ff2fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2d2529841aebb478d3748c5528b4696" category="list-text">查看*创建文件系统*页面上显示的文件系统配置。</block>
  <block id="a7f848b3fa508f3850a768505d8de438" category="list-text">单击*创建文件系统*。</block>
  <block id="8c63e014bdbc571ce93e6b93d628d4e2" category="paragraph"><block ref="8c63e014bdbc571ce93e6b93d628d4e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef936ea5a977520b22368e3dbad83818" category="paragraph"><block ref="ef936ea5a977520b22368e3dbad83818" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f36688b56a320d6a48574b6092329e26" category="paragraph">要了解适用于ONTAP 性能的Amazon FSX、请参见<block ref="45a884cbefaf34ae6fd7defa1c6be8c3" category="inline-link-rx"></block>。</block>
  <block id="6d3e0252631c98651b062c2fc85ad936" category="example-title">第2步：创建SDDC组</block>
  <block id="82fd9df68bd32ff1e24a66dc98b1e237" category="paragraph">创建文件系统和SVM后、请使用VMware控制台创建SDDC组并配置VMware Transit Connect。要执行此操作、请完成以下步骤、并记住您必须在VMware Cloud Console和AWS Console之间导航。</block>
  <block id="cfdf8bfdb817c09bbd04bc1f8aec640d" category="list-text">登录到VMC控制台、网址为`https://vmc.vmware.com`。</block>
  <block id="7959effd33c50a6257362d30f57326de" category="list-text">在*清单*页面上、单击* SDDC组*。</block>
  <block id="b8f684e055bd625606633c09969e9540" category="list-text">在* SDDC组*选项卡上、单击*操作*并选择*创建SDDC组*。出于演示目的、SDDC组称为`FSxONTAPDatastoreGrp`。</block>
  <block id="ab3ee4623c465cb9edfbfeccc6ca86ba" category="list-text">在成员网格中、选择要包括为组成员的SDDC。</block>
  <block id="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="paragraph"><block ref="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4fa61cc3be19123a586bd1f8e29e6e" category="list-text">验证是否已选中"为您的组配置VMware Transit Connect将对每个附件和数据传输产生费用"、然后选择*创建组*。完成此过程可能需要几分钟时间。</block>
  <block id="a3f9cb9f805a5c5abc39008c09a7f2b1" category="paragraph"><block ref="a3f9cb9f805a5c5abc39008c09a7f2b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b17d6992e86eba9b41dc8a123e6e8fb" category="example-title">第3步：配置VMware传输连接</block>
  <block id="dde50926302f7ec2015681d9c6a96817" category="inline-link">将外部VPC连接到组的说明</block>
  <block id="8ebb2eb5630a76b1fe25c564158f80f6" category="list-text">将新创建的指定VPC附加到SDDC组。选择*外部VPC*选项卡、然后按照进行操作<block ref="b29559f9008e4efd51a29ebaa2e02912" category="inline-link-rx"></block>。此过程可能需要10到15分钟才能完成。</block>
  <block id="ac3defa2f0f4566a77fa8a1608c03c29" category="paragraph"><block ref="ac3defa2f0f4566a77fa8a1608c03c29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633bd88abb0a911cad29e551387946b8" category="list-text">单击*添加帐户*。</block>
  <block id="cec0191b59ccf1e88591a2c33ced8c4b" category="list-text">提供用于为ONTAP 文件系统配置FSX的AWS帐户。</block>
  <block id="7dee7e783d13b6d5d415926ce0bfc306" category="list-text">单击 * 添加 * 。</block>
  <block id="6a61e881b78352ae03c966d62ea1556d" category="list-text">返回AWS控制台、登录到同一个AWS帐户并导航到*资源访问管理器*服务页面。您可以通过一个按钮来接受资源共享。</block>
  <block id="8fd6a12de6d9f24e91a89e003fe58ccd" category="paragraph"><block ref="8fd6a12de6d9f24e91a89e003fe58ccd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b5910ab3c7395246baf35589ead376f" category="admonition">在外部VPC过程中、系统会通过AWS控制台通过资源访问管理器提示您访问新的共享资源。共享资源是由VMware Transit Connect管理的AWS Transit Gateway。</block>
  <block id="48fb6ee0dcc903c5fcfb9d1b15f2e3ad" category="list-text">单击*接受资源共享*。</block>
  <block id="333af8dd6d2cdd37922abf85ebd7179a" category="paragraph"><block ref="333af8dd6d2cdd37922abf85ebd7179a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e8fd48c7d02ab11c26a3e1882fd465a" category="list-text">回到VMC控制台、您现在可以看到外部VPC处于关联状态。此操作可能需要几分钟时间才能显示出来。</block>
  <block id="49ba8c3245c3d07a0ed6167e466b43e1" category="example-title">第4步：创建传输网关连接</block>
  <block id="9db03aae4c3c9b489ffa8fc51242bb7e" category="list-text">在AWS控制台中、转至VPC服务页面并导航到用于配置FSX文件系统的VPC。在此、您可以单击右侧导航窗格上的*传输网关附件*来创建传输网关附件。</block>
  <block id="6d37c5b21f24bcca6d12fc5042185d45" category="list-text">在* VPC附件*下、确保已选中DNS支持、并选择部署了FSX for ONTAP 的VPC。</block>
  <block id="1dcf4f0eabbad36654447dfb34f237b4" category="paragraph"><block ref="1dcf4f0eabbad36654447dfb34f237b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc8975fcad9c69f295fb15e5a13f2e40" category="list-text">单击*创建**传输网关附件*。</block>
  <block id="89483e202d4e3f304f821390c4a7a7cc" category="paragraph"><block ref="89483e202d4e3f304f821390c4a7a7cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2e46cdc573277625faad22330cf154f" category="list-text">返回VMware Cloud Console、导航回SDDC组&gt;外部VPC选项卡。选择用于FSX的AWS帐户ID、然后单击VPC并单击*接受*。</block>
  <block id="36fdbe9831a4d114b9917bcd89fac4c2" category="paragraph"><block ref="36fdbe9831a4d114b9917bcd89fac4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d94f2f6e446adaf149684973d365ee" category="paragraph"><block ref="c3d94f2f6e446adaf149684973d365ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a81e35637833161072f4311f3cb32ac5" category="admonition">此选项可能需要几分钟才能显示。</block>
  <block id="08783cc975c3897f2fbd3671f2f82620" category="list-text">然后、在*路由*列的*外部VPC*选项卡中、单击*添加路由*选项并添加所需的路由：</block>
  <block id="028ce3dd99b949a311e20d5403f17103" category="list-text">适用于NetApp ONTAP 浮动IP的Amazon FSX浮动IP范围的路由。</block>
  <block id="40fd62af6ee711539f271fc7513146a5" category="paragraph"><block ref="40fd62af6ee711539f271fc7513146a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e007562e54d1b070168e2b77a1766fdc" category="paragraph"><block ref="e007562e54d1b070168e2b77a1766fdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="937e96f27b1c5759ad7123b60f3775db" category="example-title">第5步：配置路由(AWS VPC和SDDC)和安全组</block>
  <block id="b484a2377e56c4c768b99fa1ba1b950a" category="list-text">在AWS控制台中、通过在VPC服务页面中找到VPC并选择VPC的*主*路由表来创建返回SDDC的路由。</block>
  <block id="a563a48fad77850ec5058bda722b322a" category="list-text">浏览到下部面板中的路由表、然后单击*编辑路由*。</block>
  <block id="85f3b67e1c98b7869b12f779e5f02b51" category="paragraph"><block ref="85f3b67e1c98b7869b12f779e5f02b51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb26d090b870823ae62ed28050e3aa89" category="list-text">在*编辑路由*面板中、单击*添加路由*、然后通过选择*传输网关*以及关联的TGWID输入SDDC基础架构的CIDR。单击 * 保存更改 * 。</block>
  <block id="99388849296a3bbf649a9a953c7ce7d5" category="paragraph"><block ref="99388849296a3bbf649a9a953c7ce7d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74b3770eecc791f1748634fe7f30e559" category="paragraph"><block ref="74b3770eecc791f1748634fe7f30e559" category="inline-image-macro-rx" type="image"></block></block>
  <block id="358c085fce4b273ef954f6147feeb2c8" category="admonition">使用SDDC基础架构的CIDR块更新入站规则。</block>
  <block id="268ce11e03f9defefab0c436b3818aab" category="admonition">验证是否已更新适用于ONTAP 的FSX所在的VPC路由表、以避免出现连接问题。</block>
  <block id="a3debdddc4080cea8851b37aee79d278" category="admonition">更新安全组以接受NFS流量。</block>
  <block id="492fa7be92a68b15ae3479a6542a7774" category="example-title">第6步：将NFS卷作为数据存储库连接到SDDC集群</block>
  <block id="e91ba866f25c52426b4d551f9fa981ef" category="paragraph">配置文件系统并建立连接后、访问VMware Cloud Console以挂载NFS数据存储库。</block>
  <block id="3c4c5dd0c54ac8e289c4fb955dfe019e" category="list-text">在VMC控制台中、打开SDDC的*存储*选项卡。</block>
  <block id="b953143972b1f780c4334b7673a4c696" category="paragraph"><block ref="b953143972b1f780c4334b7673a4c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b525bd0f1409ea87d946684edb92331" category="list-text">单击*附加数据存储库*并填写所需的值。</block>
  <block id="ad7075e284143c915d4b8c07e499daa4" category="admonition">NFS服务器地址是NFS IP地址、可在AWS控制台中的FSX &gt; Storage Virtual Machine选项卡&gt;端点下找到。</block>
  <block id="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="paragraph"><block ref="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d13c0b52cc34c4f5571b5ea17a13e01" category="list-text">单击*连接数据存储库*将数据存储库连接到集群。</block>
  <block id="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="paragraph"><block ref="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3387672e6f02f40253d603226e4fd8" category="list-text">通过访问vCenter验证NFS数据存储库、如下所示：</block>
  <block id="30880d4531deb5f77cf22e65ed7f3bc8" category="paragraph"><block ref="30880d4531deb5f77cf22e65ed7f3bc8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff56eef7a458cc9250ee84cb0b8b3752" category="cell">FSX ONTAP<block ref="b9210f6aa16b7e370d59e02bd5b54f88" category="inline-link-macro-rx"></block></block>
  <block id="ef1e6887c579ba81dcedc3f4e3793cd2" category="section-title">audience</block>
  <block id="aca7234abb238eb8646973440eb294d3" category="paragraph">此解决方案 的测试/验证是在可能与最终部署环境匹配或可能不匹配的实验室中执行的。有关详细信息、请参见以下各节。</block>
  <block id="bb46e30937334302b789ae4644fdc412" category="image-alt">解决方案 架构图</block>
  <block id="39f3ba4cf87d6a47181e787c275344e5" category="section-title">硬件/软件组件</block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">* 硬件 *</block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*软件*</block>
  <block id="dd1d4adbfe73c3cd87fc248a003b05a0" category="section-title">解决方案 部署</block>
  <block id="00ec4042cd11b865f5a96645c8f6abca" category="sidebar">FSX ONTAP 作为补充NFS数据存储库：概述</block>
  <block id="74fed8860f1d0399cb4c6a16b2510cd1" category="sidebar">VMC的补充NFS数据存储库</block>
  <block id="d251fcb24842564580e4c994b283538e" category="cell">添加了指向FSxN/VMC和ANF/AVS的TCO计算器和模拟器的链接</block>
  <block id="8625e1de7be14c39b1d14dc03d822497" category="sidebar">工具</block>
  <block id="e5365f39437feb49b24eddfa73253c24" category="sidebar">适用于ONTAP 的FSx + VMC TCO计算器</block>
  <block id="4856ec39dcc21fb53484ef230701e66b" category="sidebar">适用于ONTAP + VMC模拟器的FSX</block>
  <block id="67c988a2e4a11132f6866cf0aff95568" category="sidebar">ANF + AVS TCO计算器</block>
  <block id="faeff2a13624e3552e026ffcba1c35dc" category="sidebar">ANF + AVS模拟器</block>
  <block id="714163a53d8c9c62964e7d6931c1c9ec" category="admonition">您不能在已连接的VPC中部署适用于ONTAP 的FSX。而是必须将其部署在新的指定VPC中、然后通过SDDC组将VPC连接到VMware托管传输网关(vTGW）。</block>
  <block id="d7641cecb55db2651063f3be07278b31" category="example-title">第1步：在新的指定VPC中创建适用于ONTAP 的Amazon FSX</block>
  <block id="4e0c93d8fb3b7cedc4f8d92d8d692e85" category="admonition">数据存储库大小因客户而异。虽然每个NFS数据存储库建议的虚拟机数量是主观的、但许多因素决定了可以放置在每个数据存储库上的最佳VM数量。虽然大多数管理员仅考虑容量、但发送到VMDK的并发I/O量是影响整体性能的最重要因素之一。使用内部环境中的性能统计信息相应地调整数据存储库卷的大小。</block>
  <block id="2f0865bd1a50874390d074524829bfc4" category="admonition">确保此VPC为新的指定VPC、而不是已连接的VPC。</block>
  <block id="55431364d6f307d0c1adb83c07425d6c" category="admonition">默认情况下、ONTAP 的FSX使用198.19.0.0/16作为文件系统的默认端点IP地址范围。确保端点IP地址范围不会与AWS SDDC上的VMC、关联的VPC子网和内部基础架构相冲突。如果不确定、请使用不存在冲突的非重叠范围。</block>
  <block id="505582b625e19e5637e0557ad61b581e" category="list-text">在*默认卷配置*部分中、指定数据存储库所需的卷名称和大小、然后单击*下一步*。此卷应为NFSv3卷。对于*存储效率*、选择*已启用*以启用ONTAP 存储效率功能(数据压缩、重复数据删除和数据缩减)。创建后、使用Shell使用*卷modify_*修改卷参数、如下所示：</block>
  <block id="9fdea1f4f5c62c2485312ab231c865ee" category="cell">卷保证(空间保证模式)</block>
  <block id="bd03fce695997bf49af026bcb349a578" category="cell">无(精简配置)—默认设置</block>
  <block id="9399f3b9e96901f84ac3bd68deec8850" category="cell">fractional_reserve (百分比预留)</block>
  <block id="6b3edd41659df403c04fb39ee40b0b0a" category="cell">0%—默认设置</block>
  <block id="dfa2ec9e60d8028b01d021f862fb77da" category="cell">snap_reserve (percent-snapshot-space)</block>
  <block id="80c2511d74ccaf27c63f1b6c3aafb2dc" category="cell">自动调整大小(autosize-mode)</block>
  <block id="535a7e7f6a8dd82fa6603e44982e0525" category="cell">Enabled—默认设置</block>
  <block id="df370ff95c6787552e774c17a2878b11" category="cell">Snapshot only—默认设置</block>
  <block id="f072855ce664b2c9dd19371c8f451e72" category="paragraph">使用以下SSH命令创建和修改卷：</block>
  <block id="82bf57f964fd07a578454495c4ae3a34" category="paragraph">*使用shell：*创建新数据存储库卷的命令</block>
  <block id="3fe80d288dea7b9265abdfe33f302a9a" category="paragraph">*注意：*通过shell创建的卷需要几分钟才能显示在AWS控制台中。</block>
  <block id="34b5a79399461f15942cc2bbb68ddb58" category="paragraph">*用于修改未默认设置的卷参数的命令：*</block>
  <block id="8f2384de60fd85d0b57b92b82a7b1835" category="admonition">在初始迁移场景中、默认快照策略可能会出现发生原因 数据存储库容量已满问题。要克服此问题、请根据需要修改快照策略。</block>
  <block id="a19c957e90534613b36e90008ac1736c" category="admonition">重复上述步骤、根据容量和性能要求创建更多的Storage Virtual Machine或文件系统以及数据存储库卷。</block>
  <block id="5659fbd7d9a7a1963d1f57717f874bcb" category="list-text">下一步是验证关联VPC中的安全组是否已使用正确的SDDC组CIDR入站规则进行更新。</block>
  <block id="381318b231b70d3c81a3bb05e8912be3" category="paragraph">这是准备连接到相应SDDC的最后一步。配置文件系统、添加路由以及更新安全组后、应挂载数据存储库。</block>
  <block id="e60de72a8067fd05498b03b24d9f93e7" category="paragraph">此解决方案 可解决以下使用情形：</block>
  <block id="71b51633ceea83cdf1136196fce39901" category="admonition">只支持使用来宾存储将Cloud Volumes ONTAP 连接到AWS VMC。</block>
  <block id="9761d5208d76a88ba5a08152c4431c2f" category="admonition">来宾存储是将Cloud Volumes ONTAP 连接到Azure VMware解决方案 的唯一受支持方法。</block>
  <block id="bb19e956b854f8e209f51237a29feb31" category="admonition">目前、只有来宾存储是将Cloud Volumes ONTAP (CVO)连接到AWS VMC的唯一受支持方法。</block>
  <block id="36c48411397a73fcbe7ccac93862641b" category="admonition">在编写本文档时，来宾存储是唯一可用的选项。随着NFS数据存储库支持的补充提供、我们将提供其他文档 <block ref="2feee9d08b57f121d415095bba26ae78" category="inline-link-macro-rx"></block>。</block>
  <block id="44db359cccfc9a14e67b800f405a2078" category="sidebar">设置自动化环境</block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">本技术报告使用了以下参考资料：</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Apache Spark架构和组件</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Apache Spark用例</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="506326e78695dcca6de9cbc14a77c5b7" category="list-text">Apache挑战</block>
  <block id="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link"><block ref="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link-rx"></block></block>
  <block id="a4047ab5c68e6bd8f8ad5dfc79e46847" category="paragraph"><block ref="a4047ab5c68e6bd8f8ad5dfc79e46847" category="inline-link-rx"></block></block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="list-text">激发NLP</block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">深度和跨网络、用于广告点击预测</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link"><block ref="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link-rx"></block></block>
  <block id="c0ce2c750c3848619c847bc001ba66be" category="paragraph"><block ref="c0ce2c750c3848619c847bc001ba66be" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">流式ETL</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">适用于Hadoop的NetApp E系列解决方案</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="6e1ead71812900db964474f24a84ff5e" category="list-text">《使用NetApp AI进行客户沟通时的情绪分析》</block>
  <block id="270a8289ec3296709282f87be3043182" category="inline-link"><block ref="270a8289ec3296709282f87be3043182" category="inline-link-rx"></block></block>
  <block id="5d6e0d6396516ff7be3c4a58b49ef3a7" category="paragraph"><block ref="5d6e0d6396516ff7be3c4a58b49ef3a7" category="inline-link-rx"></block></block>
  <block id="a435d889d8c30f88d959b581e585cb98" category="inline-link"><block ref="a435d889d8c30f88d959b581e585cb98" category="inline-link-rx"></block></block>
  <block id="2e0db0f40c94a679b5a5692c131d03f4" category="paragraph"><block ref="2e0db0f40c94a679b5a5692c131d03f4" category="inline-link-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">DataOps工具包</block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp拥有三种存储产品组合：FAS/AFF、E系列和Cloud Volumes ONTAP。我们已通过Apache Spark验证了适用于Hadoop解决方案的AFF 和采用ONTAP 的E系列存储系统。由NetApp提供支持的Data Fabric集成了数据管理服务和应用程序(组件)、可实现数据访问、控制、保护和安全性。</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">NetApp Spark解决方案概述</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">Data Fabric提供数据管理服务和应用程序。</block>
  <block id="84996abc8bbc3c77ef59d8a39c852d30" category="paragraph"><block ref="84996abc8bbc3c77ef59d8a39c852d30" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">* NetApp NFS 直接访问。 * 为最新的 Hadoop 和 Spark 集群提供对 NetApp NFS 卷的直接访问，而无需额外的软件或驱动程序要求。</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">* NetApp SnapMirror技术。*可在内部部署和ONTAP 云或NPS实例之间提供数据保护功能。</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">下图展示了采用NetApp存储的Spark解决方案。</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">利用NetApp存储激发解决方案。</block>
  <block id="0847e549ec9fd7e676ad66196c4210a2" category="paragraph"><block ref="0847e549ec9fd7e676ad66196c4210a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4d71ccd96e1b29bc3437c1cb6a245e" category="paragraph">ONTAP Spark解决方案 使用NetApp NFS直接访问协议进行原位分析、并通过访问现有生产数据来访问AI、ML和DL工作流。可供Hadoop节点使用的生产数据会导出、以执行原位分析和AI、ML和DL作业。您可以通过NetApp NFS直接访问或不使用它访问要在Hadoop节点中处理的数据。在具有独立或`yarn`集群管理器的Spark中、您可以使用`配置NFS卷<block ref="7667eac59549f5d64cbcc9214ea613f8" category="inline-link-rx"></block>。我们验证了使用不同数据集的三个用例。有关这些验证的详细信息、请参见"测试结果"一节。 (Xref)</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">下图展示了NetApp Apache Spark或Hadoop存储定位。</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">NetApp Apache Spark或Hadoop存储定位。</block>
  <block id="5af92584fa4ab2b78abca73f9bbdcf42" category="paragraph"><block ref="5af92584fa4ab2b78abca73f9bbdcf42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">我们确定了E系列Spark解决方案 、AFF/FAS ONTAP Spark解决方案 和StorageGRID Spark解决方案 的独特功能、并执行了详细的验证和测试。根据我们的观察结果、NetApp建议将E系列解决方案 用于全新安装和全新可扩展部署、并将AFF/FAS解决方案 用于使用现有NFS数据的原位分析、AI、ML和DL工作负载、并在需要对象存储时将StorageGRID 用于AI、ML和DL和现代数据分析。</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">为Spark推荐的NetApp解决方案。</block>
  <block id="d3deaa8bf3eb6619cb86d00d661a22e9" category="paragraph"><block ref="d3deaa8bf3eb6619cb86d00d661a22e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">数据湖是原生 形式的大型数据集的存储库、可用于分析、AI、ML和DL作业。我们为E系列、AFF/FAS和StorageGRID SG6060 Spark解决方案构建了数据湖存储库。E系列系统提供对Hadoop Spark集群的HDFS访问、而现有生产数据则通过NFS直接访问协议访问Hadoop集群。对于驻留在对象存储中的数据集、NetApp StorageGRID 可提供S3和S3a安全访问。</block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">此页面更详细地介绍了主要的AI、ML和DL用例和架构。</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">主要的AI、ML和DL用例和架构</block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">主要的AI、ML和DL用例和方法可分为以下几节：</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">激发NLP管道和TensorFlow分布式推理</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">以下列表列出了数据科学界在不同开发级别下采用的最受欢迎的开源NLP库：</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">自然语言工具包(NLTK)</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block>。适用于所有NLP技术的完整工具包。自21世纪初以来、该系统一直保持不变。</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">文本Blob</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block>。基于NLTK和模式构建的简单易用的NLP工具Python API。</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">斯坦福核心NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block>。由斯坦福NLP集团开发的Java中的NLP服务和软件包。</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">Gensim</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block>。人类主题建模最初是作为一组Python脚本在捷克数字数学库项目中推出的。</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">空间</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block>。采用Python和Cython的端到端工业NLP工作流、并为互感器提供GPU加速。</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">快速文本</block>
  <block id="07ad1b642fbcf4cbc6f67e8f5b7ce593" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block>。一个免费的轻型开源NLP库、用于由Facebook的AI Research (Ffair)实验室创建的字词学习嵌入和句子分类。</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">激发ML</block>
  <block id="27e7661d3fd9daf238bb981e30734c3c" category="paragraph">SPARK NLP是一个统一的解决方案 、可满足所有NLP任务和要求、可为实际生产用例提供可扩展、高性能和高准确性的NLP驱动软件。它利用传输学习、在研究领域和跨行业实施最新的一流算法和模型。由于Spark不能全面支持上述库、因此、Spark NLP是基于构建的<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> 利用Spark的通用内存分布式数据处理引擎作为任务关键型生产工作流的企业级NLP库。其标注器利用基于规则的算法、机器学习和TensorFlow为深度学习实施提供支持。其中包括常见的NLP任务、包括但不限于令牌化、lemization、stemming、部分语音标记、命名实体识别、 拼写检查和情感分析。</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">Transformers (Bert)提供的双向编码器表示是一种基于转换器的机器学习技术、适用于NLP。它推广了预训练和微调的概念。Bert中的转换器架构源自机器翻译、与基于神经网络(RNN)的经常性语言模型相比、该模型更好地模拟长期依赖关系。它还引入了屏蔽语言建模(Masked Language Modeling、MLM)任务、其中随机屏蔽了所有令牌的15%、模型对其进行预测、从而实现了真正的双向性。</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">完成</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">Reuters TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">金融租赁银行</block>
  <block id="575e9b077146ddbbac786ed0a40a1a21" category="inline-link">金融新闻情感分析</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">说明文档DL</block>
  <block id="8171f59448f55698ad8ecd07ce1633b6" category="paragraph">由于该领域的专业语言和缺少标记数据、财务情绪分析具有挑战性。<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>一种基于经过预先培训的Bert的语言模式、该语言模式已经过域调整<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block>一种财务资料、并使用标记的数据(<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block>)进行财务状况分类。研究人员从新闻文章中提取了4、500句话、并使用了财务术语。然后、16名具有财务背景的专家和硕士学生将这些句子标记为肯定、中立和否定。我们构建了一个端到端Spark工作流、用于分析2016年至2020年排名前10位的纳斯达克公司收益电话记录的情绪、使用FinBeert和另外两个经过预先培训的管道(<block ref="6d4ea12c876c5a993aa1b5d0f03f167f" category="inline-link-rx"></block>，<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block>)。</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">适用于Spark NLP的底层深度学习引擎是TensorFlow、它是一个端到端的开源机器学习平台、可轻松构建模型、随时随地进行强大的ML生产以及进行强大的研究试验。因此、在Spark `Yarn集群`模式下执行管道时、我们基本上是在集群上挂载的网络连接存储中运行分布式TensorFlow、并在一个主节点和多个辅助节点之间并行处理数据和模型。</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Horovod分布式培训</block>
  <block id="ba6c44669e2888938a004611469c95dc" category="inline-link">TR-3969：《适用于Hadoop的NetApp解决方案》</block>
  <block id="6f5ab42847eab5c573282c94e51100a9" category="paragraph">使用TeraGen、TeraSort、TeraValidate和DFSIO (读写)执行与MapReduce相关的性能的核心Hadoop验证。TeraGen和TeraSort验证结果显示在中<block ref="c56c49d0c7359320f900743306997a3c" category="inline-link-rx"></block> 对于E系列和AFF 的"存储分层"一节(xref)。</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Hovorod on Spark</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">根据客户的要求、我们认为使用Spark进行分布式培训是各种使用情形中最重要的一个。在本文档中、我们使用了<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> 使用NetApp全闪存FAS (AFF)存储控制器、Azure NetApp Files 和StorageGRID 验证NetApp内部部署、云原生和混合云解决方案的Spark性能。</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Horovod on Spark软件包为Horovod提供了一个方便的包装、使在Spark集群中运行分布式训练工作负载变得简单、从而实现了一个紧密的模型设计环路、其中数据处理、模型训练和模型评估都在训练和推理数据所在的Spark中完成。</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Kagle Rossmann商店销售人员</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">在Spark上运行Horovod有两种API：一种是高级估算器API、另一种是运行API。虽然这两种方法都使用相同的底层机制来启动Horovod on Spark执行程序、但Estimator API可对数据处理、模型训练循环、模型检查点、指标收集和分布式培训进行抽象化。我们使用Horovod Spark Estimators、TensorFlow和Keras基于进行端到端数据准备和分布式培训工作流<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> 竞争。</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">适用于每个主要用例的Python脚本。</block>
  <block id="94f33f4ba60c5f66bf0c60c3e391a81b" category="paragraph">可以在部分中找到脚本`keras_sock_horovod_rossmann_estimator.py` <block ref="9843d2ebe8b4d4385946214b6f8e40b8" category="inline-link-macro-rx"></block> 它包含三个部分：</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">第一部分对Kagger提供并由社区收集的一组初始CSV文件执行各种数据预处理步骤。输入数据将分为一个训练集、其中包含`Validation`子集和一个测试数据集。</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">第二部分定义了具有对数Sigma激活功能和Adam优化器的Keras深度神经网络(DNN)模型、并使用Horovod on Spark对该模型进行分布式培训。</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">第三部分使用最佳模型对测试数据集执行预测、以最大程度地减少验证集的整体平均绝对错误。然后、它将创建一个输出CSV文件。</block>
  <block id="ca1ff924f88675800b52c7c1b223b4a2" category="inline-link-macro">"机器学习"</block>
  <block id="a67083c66285446e108268f795b72b24" category="paragraph">请参见一节 <block ref="65cdc2076a502903b78fb8128fc1a214" category="inline-link-macro-rx"></block> 查看各种运行时比较结果。</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">利用Keras进行CTR预测的多员工深度学习</block>
  <block id="4debf96216c552af520b74d3d0d2f2dc" category="paragraph">随着 ML 平台和应用程序的最新发展，我们现在非常关注大规模学习。点击率（ CTR ）是指每 100 次在线广告曝光的平均点击次数（以百分比表示）。它已广泛用作各种行业垂直市场和用例的关键指标，包括数字营销，零售，电子商务和服务提供商。请参见我们的<block ref="5e9febd4c244550b32d7bb781b595741" category="inline-link-rx"></block> 有关CTR应用程序以及使用Kubernetes实施的端到端Cloud AI工作流、分布式数据ETL以及使用dask和CUDA ML的模型培训的更多详细信息。</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Trigeo Terabyte单击Logs dataset</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">在本技术报告中、我们使用了的变体<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (请参见TR-4904)、针对使用Keras的多员工分布式深度学习、使用深度和跨网(深度和跨网)模型构建Spark工作流、将其在日志丢失错误功能方面的性能与基线Spark ML物流回归模型进行比较。DCN可以 高效地捕获有界限的有效功能交互、学习高度非线性的交互、无需手动执行功能工程或全面搜索、并且计算成本较低。</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">网络级推荐系统的数据大多是离散的、分类的、导致功能空间庞大而稀疏、这对功能探索来说是一项挑战。这样、大多数大型系统就只能使用诸如物流回归等线性模型。但是、确定常见的预测功能并同时探索未知或罕见的交叉功能是做出良好预测的关键。线性模型简单、可解释且易于扩展、但其表达能力有限。</block>
  <block id="793743a945a26aaa07de844420d013af" category="paragraph">另一方面、交叉特征在提高模型的显示能力方面表现出了显著的意义。遗憾的是、它通常需要手动执行功能工程或全面搜索才能识别此类功能。通常很难将功能交互概括为不可见。使用像DCN这样 的交叉神经网络、可以通过自动明确应用功能交叉来避免特定于任务的功能工程。跨网络由多个层组成、其中最大程度的交互可通过层深度来确定。每个层都会根据现有层生成较高顺序的交互、并保留先前层的交互。</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">深度神经网络(DNN)有望捕获功能之间非常复杂的交互。但是、与DCN相比、它需要的参数数量几乎要多一个数量级、无法明确形成交叉功能、并且可能无法高效地了解某些类型的功能交互。跨网络可节省内存并易于实施。将交叉组件和DNN组件联合训练在一起、有效地捕获预测性功能交互、并在Criteo CTR数据集上提供一流的性能。</block>
  <block id="9830e1f81f623b33106acc186b93374e" category="inline-link">毫升</block>
  <block id="fefc70efb4580c1020c62303f76330f7" category="inline-link">mllib</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">DeepCTR</block>
  <block id="75e8e622ae2ef0cb646ef505a0b3f7be" category="paragraph">一个型号的DCN-首先是一个嵌入层和堆栈层、然后是一个跨网络和一个并行的深度网络。然后是最后一个组合层、该层将两个网络的输出相结合。您的输入数据可以是具有稀疏和密集功能的向量。在Spark中、这两者都是如此<block ref="e0c7aa0ef7a63ea331cba99be2697841" category="inline-link-rx"></block> 和<block ref="495fc8cfd173be827e5c6c8258a34e04" category="inline-link-rx"></block> 库的类型为`SparseVector`。因此、用户必须区分这两者、并在调用各自的功能和方法时要小心谨慎。在CTR预测等网络级建议系统中、输入主要是分类功能、例如`‘国家/地区=美国'`。此类功能通常编码为单热向量、例如、`‘`、1、0、…'。使用`SparseVector`的单热编码(OHEE)在处理实际数据集时非常有用、因为这些数据集的词义不断变化且不断增长。我们在中修改了示例<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> 要处理大型卷标、请在我们的DCN"嵌入和堆栈"层中创建嵌入载体。</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Criteo显示广告数据集</block>
  <block id="d05de658e793ee731e5a3782c453caa6" category="paragraph">。<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> 预测广告点击率。它具有13个整数功能和26个分类功能、其中每个类别的基数都很高。对于此数据集、由于输入大小较大、光泽度提高了0.001实际上是一项显著的改进。如果对大型用户群的预测准确性稍作提高、可能会导致公司收入大幅增加。该数据集包含7天内的11 GB用户日志、相当于大约4、100万条记录。我们使用Spark `dataFrame.Random拆 分()函数`随机拆分数据进行训练(80%)、交叉验证(10%)、其余10%用于测试。</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">在与Keras的TensorFlow上实施了DCN。在使用DCN-CN-CN-CN-CN-CN-CN-CN-A实施模型培训过程中、主要包含四个</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*数据处理和嵌入。*实际价值的功能通过应用日志转换进行标准化。为了获得明确的功能、我们将这些功能嵌入到维度6×(类别基数) 1/4的密集向量中。将所有嵌入项串联后、将生成维度1026的向量。</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*优化。*我们使用了Adam优化器进行了迷你批处理随机优化。批处理大小设置为512。对深度网络应用了批处理标准化、梯度线夹规范设置为100。</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*规范化。*由于未发现L2规范化或降级有效、我们使用了提前停止的方法。</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">*超参数。*我们根据对隐藏层数、隐藏层大小、初始学习速率和跨层数的网格搜索来报告结果。隐藏层的数量从2到5不等、隐藏层大小从32到1024不等。对于DCN、跨层数量为1到6。初始学习速率从0.0001调整为0.001、增量为0.0001。所有实验都在训练步骤150、000时进行了早期停止、超过此步骤后、开始发生过度安装。</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="ca099c15c1ba89f9956f37979064b6ea" category="inline-link">xDeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">自动内置</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCNv2</block>
  <block id="ebca0d5eb18ce917a3f0d2d49746eb3d" category="paragraph">除了使用了DCN之外、我们还测试了其他常见的深度学习模型来进行CTR预测、其中包括<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block>，<block ref="dc65ad48383bc08407486976f4411f66" category="inline-link-rx"></block>，<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block>，和<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block>。</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">用于验证的架构</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">在此验证中、我们使用了四个辅助节点和一个具有AF-A800 HA对的主节点。所有集群成员均通过10GbE网络交换机进行连接。</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">在此NetApp Spark解决方案 验证中、我们使用了三种不同的存储控制器：E5760、E5724和AFF-A800。E系列存储控制器通过12 Gbps SAS连接连接到五个数据节点。AFF HA对存储控制器通过与Hadoop工作节点的10GbE连接提供导出的NFS卷。Hadoop集群成员通过E系列、AFF 和StorageGRID Hadoop解决方案中的10GbE连接进行连接。</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">用于验证的架构。</block>
  <block id="2f2f17293788ab5e5b754a35afe8b3b5" category="paragraph"><block ref="2f2f17293788ab5e5b754a35afe8b3b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">本文档重点介绍与大数据分析和人工智能相关的Apache Spark架构、客户用例和NetApp存储产品组合。此外、它还会根据典型的Hadoop系统使用行业标准AI、机器学习和深度学习工具显示各种测试结果、以便您可以选择合适的Spark解决方案。</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570：《适用于Apache Spark的NetApp存储解决方案：架构、用例和性能结果》</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">NetApp公司Rick Huang、Karthikeyan Nagalingam</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">本文档重点介绍与大数据分析和人工智能(AI)相关的Apache Spark架构、客户用例和NetApp存储产品组合。此外、它还会根据典型的Hadoop系统使用行业标准AI、机器学习(ML)和深度学习(DL)工具显示各种测试结果、以便您可以选择适当的Spark解决方案。首先、您需要一个Spark架构、适当的组件以及两种部署模式(集群和客户端)。</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">本文档还提供了客户用于解决配置问题的用例、并概述了与大数据分析以及采用Spark的AI、ML和DL相关的NetApp存储产品组合。然后、我们将根据Spark专用用例和NetApp Spark解决方案 产品组合得出测试结果。</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">本节重点介绍客户在零售、数字营销、银行、离散式制造、流程制造等数据增长行业面临的大数据分析和AI/ML/DL挑战。 政府和专业服务。</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">性能不可预测</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">传统Hadoop部署通常使用商用硬件。要提高性能、您必须调整网络、操作系统、Hadoop集群、Spark等生态系统组件和硬件。即使您对每一层进行了调整、也很难达到所需的性能级别、因为Hadoop运行在并非为环境中的高性能而设计的商用硬件上。</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">介质和节点故障</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">即使在正常情况下、商用硬件也容易发生故障。如果数据节点上的一个磁盘发生故障、则默认情况下、Hadoop主节点会将该节点视为运行状况不正常。然后、它会通过网络将特定数据从该节点从副本复制到运行正常的节点。此过程会减慢任何Hadoop作业的网络数据包速度。然后、当运行状况不正常的节点恢复正常时、集群必须重新复制数据并删除过度复制的数据。</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Hadoop供应商锁定</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Hadoop分销商拥有自己的Hadoop分发软件包、并拥有自己的版本控制、这会使客户锁定到这些分发软件包中。但是、许多客户需要支持内存分析、而不会将客户与特定Hadoop分发版联系起来。他们需要自由地更改分发版本、同时仍能利用分析功能。</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">不支持多种语言</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">客户通常除了需要MapReduce Java程序支持多种语言之外、还需要支持多种语言才能运行其作业。SQL和脚本等选项可以更灵活地获取答案、提供更多的数据组织和检索选项、以及更快地将数据移动到分析框架中。</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">难以使用</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">一段时间以来、人们一直抱怨Hadoop难以使用。尽管Hadoop在每个新版本中变得更加简单、功能更强大、但这一评论仍然存在。Hadoop要求您了解Java和MapReduce编程模式、这是数据库管理员和具有传统脚本编写技能的人员面临的一项挑战。</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">复杂的框架和工具</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">企业AI团队面临多种挑战。即使具备专业的数据科学知识、适用于不同部署生态系统和应用程序的工具和框架也可能不会简单地从一个转变为另一个。数据科学平台应与基于Spark构建的相应大数据平台无缝集成、可轻松移动数据、实现可重复使用的模型、即装即用的代码以及支持原型制作、验证、版本控制、共享、重复使用的最佳实践的工具。 并将模型快速部署到生产环境中。</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">为什么选择NetApp？</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp可以通过以下方式改善您的Spark体验：</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">通过NetApp NFS直接访问(如下图所示)、客户无需移动或复制数据、即可对现有或新的NFSv3或NFSv4数据运行大数据分析作业。它可以防止多个数据副本，并且无需将数据与源进行同步。</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">存储效率更高、服务器复制更少。例如、NetApp E系列Hadoop解决方案 需要两个而非三个数据副本、而FAS Hadoop解决方案 则需要一个数据源、但不需要复制或复制数据。NetApp存储解决方案还可以减少服务器到服务器的流量。</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">在驱动器和节点发生故障期间、Hadoop作业和集群行为会更好。</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">提高数据载入性能。</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">其他Apache Spark配置。</block>
  <block id="ce1f5d61aacdba15be898e2d6408542f" category="paragraph"><block ref="ce1f5d61aacdba15be898e2d6408542f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">例如、在金融和医疗保健领域、数据从一个位置移动到另一个位置必须履行法律义务、这不是一项容易的任务。在此情景中、NetApp NFS直接访问功能会分析其原始位置的财务和医疗保健数据。另一个主要优势是、使用NetApp NFS直接访问可通过原生 Hadoop命令简化对Hadoop数据的保护、并通过NetApp丰富的数据管理产品组合启用数据保护工作流。</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">NetApp NFS直接访问为Hadoop/Spark集群提供了两种部署选项：</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">默认情况下、Hadoop或Spark集群使用Hadoop分布式文件系统(HDFS)进行数据存储和默认文件系统。NetApp NFS直接访问可以将默认HDFS替换为NFS存储作为默认文件系统、从而可以对NFS数据进行直接分析。</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">在另一种部署选项中、NetApp NFS直接访问支持在单个Hadoop或Spark集群中将NFS与HDFS配置为额外存储。在这种情况下，客户可以通过 NFS 导出共享数据，并从同一集群访问数据以及 HDFS 数据。</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">使用NetApp NFS直接访问的主要优势包括：</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">从当前位置分析数据、这样可以防止将分析数据移动到HDFS等Hadoop基础架构这一既耗时又耗性能的任务。</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">将副本数量从三个减少为一个。</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">使用户能够分离计算和存储以独立扩展。</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">利用ONTAP 丰富的数据管理功能提供企业数据保护。</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Hortonworks数据平台认证。</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">支持混合数据分析部署。</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">利用动态多线程功能缩短备份时间。</block>
  <block id="009b0bd3acc58fbc1c3db15692583fa9" category="paragraph">请参见<block ref="217abb9bc41aa22d30da41b7958b4152" category="inline-link-rx"></block> 用于将Hadoop数据备份、备份和灾难恢复从云备份到内部环境、对现有Hadoop数据启用DevTest、实现数据保护和多云连接、并加快分析工作负载的速度。</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">以下各节介绍了对Spark客户非常重要的存储功能。</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">存储分层</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">使用Hadoop存储分层、您可以根据存储策略存储具有不同存储类型的文件。存储类型包括`Hot`、`Cold`、`Warm`、`All_SSD`、`One_SSD`、 和`lazy_persist`。</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">下图显示了适用于Hadoop SSD的NetApp解决方案的性能。</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">对1 TB数据进行排序的时间。</block>
  <block id="55fdf8b2dd620bd73dcd37db50e0f0e5" category="paragraph"><block ref="55fdf8b2dd620bd73dcd37db50e0f0e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">TR-3969适用于Hadoop的NetApp E系列解决方案</block>
  <block id="8cdadd1c9614abebd1b476daba691f36" category="list-text">基线NL-SAS配置使用8个计算节点和96个NL-SAS驱动器。此配置在4分38秒内生成1 TB的数据。请参见<block ref="f08cd7da48b5d74d9eaab10199016f47" category="inline-link-rx"></block> 有关集群和存储配置的详细信息。</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">使用TeraGen、SSD配置生成的数据速度比NL-SAS配置快15.66倍。此外、SSD配置使用的计算节点数为计算节点数的一半、磁盘驱动器数的一半(总共24个SSD驱动器)。根据作业完成时间、该速度几乎是NL-SAS配置的两倍。</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">性能扩展—横向扩展</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">如果您需要AFF 解决方案 中Hadoop集群的更多计算能力、则可以添加具有适当数量存储控制器的数据节点。NetApp建议从每个存储控制器阵列四个数据节点开始、并根据工作负载特征将每个存储控制器的数据节点数增加到八个。</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF 和FAS 非常适合原位分析。根据计算要求、您可以添加节点管理器、而无中断操作允许您按需添加存储控制器、而无需停机。我们通过AFF 和FAS 提供丰富的功能、例如NVMe介质支持、有保障的效率、数据精简、QoS、预测性分析、 云分层、复制、云部署和安全性。为了帮助客户满足其需求、NetApp提供了文件系统分析、配额和机载负载平衡等功能、无需额外的许可证成本。与竞争对手相比、NetApp在并发作业数量方面的性能更好、延迟更短、操作更简单、每秒吞吐量也更高。此外、NetApp Cloud Volumes ONTAP 还可在所有三个主要云提供商上运行。</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">性能扩展—纵向扩展</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">通过纵向扩展功能、您可以在需要更多存储容量时向AFF 、FAS 和E系列系统添加磁盘驱动器。借助Cloud Volumes ONTAP 、将存储扩展到PB级别是两个因素的组合：将不常用的数据从块存储分层到对象存储、以及在不进行额外计算的情况下堆栈Cloud Volumes ONTAP 许可证。</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">多个协议</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">NetApp系统支持适用于Hadoop部署的大多数协议、包括SAS、iSCSI、FCP、InfiniBand、 和NFS。</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">运行和支持的解决方案</block>
  <block id="dc15faa991f0a6740734b42c6e08c347" category="inline-link">MapR</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">认证</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">合作伙伴</block>
  <block id="b1202a92f536818c64c3005cf78d8e35" category="paragraph">NetApp支持本文档中所述的Hadoop解决方案。这些解决方案还通过了主要Hadoop分销商的认证。有关信息、请参见<block ref="cc609e66e0173716d91f0397bfa09e1b" category="inline-link-rx"></block> 站点、<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> 站点和Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> 和<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> 站点。</block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">我们使用TeraGen基准测试工具中的TeraSort和TeraValidate脚本测量E5760、E5724和AFF-A800配置下的Spark性能验证。此外、还测试了三个主要用例：Spark NLP管道和TensorFlow分布式培训、Horovod分布式培训以及使用Keras进行DeepFM CTR预测的多员工深度学习。</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">测试结果</block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">我们使用TeraGen基准测试工具中的TeraSort和TeraValidate脚本测量E5760、E5724和AFF-A800配置下的Spark性能验证。此外、还测试了三个主要用例：SPARK NLP管道和TensorFlow分布式培训、Horovod分布式培训以及使用Keras通过DeepFM进行CTR预测的多员工深度学习。</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">对于E系列和StorageGRID 验证、我们使用Hadoop复制因子2。对于AFF 验证、我们仅使用一个数据源。</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">下表列出了用于Spark性能验证的硬件配置。</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Hadoop工作节点</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">驱动器类型</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">每个节点的驱动器数</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">存储控制器</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">（ SAS ）。</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">一个高可用性(HA)对</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">单个HA对</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">下表列出了软件要求。</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7.9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">OpenJDK运行时环境</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">OpenJDK 64位服务器VM</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25.302</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC或G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">激发</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlow</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">克罗斯</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3.</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">财务状况分析</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">NVIDIA Riva SDK</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">TAO框架</block>
  <block id="3f57666cb1b915db482629c0554b2d92" category="paragraph">我们发布了<block ref="36713788fc49ad5281ee4a8956df0b3b" category="inline-link-rx"></block>、其中使用构建了一个端到端对话AI管道<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>、AFF 存储和NVIDIA DGX系统。该管道利用DataOps工具包执行批量音频信号处理、自动语音识别(Automatic Speech Recognition、As1)、传输学习和情感分析。<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block>和<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block>。将情感分析用例扩展到金融服务行业、我们构建了SparkNLP工作流、加载了三个Bert模型来执行各种NLP任务、例如、命名实体识别、并在纳斯达克排名前10位的公司季度收益电话会议中获得了句子级的感受。</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">以下脚本`sentiment_analysis _sacp。py`使用FinBet模型处理HDFS中的脚本、并产生积极、中立和负面的情绪计数、如下表所示：</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">下表列出了2016年至2020年纳斯达克排名前10位的公司的收益情况、句子级别的情绪分析。</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">情感的数量和百分比</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">所有10家公司</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">不支持</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">GOOGL</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">INTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">MSFT</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">正数</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">空值</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">负计数</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787年</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253.</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213.</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84.</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189.</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282.</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89.</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">未分类计数</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196年</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76.</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">(总数)</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">就百分比而言、CEO和CFO所说的大多数句子都是事实、因此具有中立的情绪。在收益调查期间、分析师会提出可能会表达积极或负面情绪的问题。值得进一步量化调查负面或正面情绪对交易当天或第二天的股票价格有何影响。</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">下表列出了纳斯达克排名前10位的公司的句子级别情感分析、以百分比表示。</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">情绪百分比</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">肯定</block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10.13%</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18.06%</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8.69%</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5.24%</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9.07%</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12.08%</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11.44%</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13.25%</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6.23%</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">中立</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87.17%</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79.02%</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88.82%</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91.87%</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88.42%</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86.50%</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84.65%</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83.77%</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92.44%</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">否定</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2.43%</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2.92%</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2.49%</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1.52%</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2.51%</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1.42%</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3.91%</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2.96%</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1.33%</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">未分类</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0.27%</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1.37%</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0.01%</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">在工作流运行时间方面、我们发现从`本地`模式到HDFS中的分布式环境、有4.78倍的显著提升、而利用NFS则进一步提高了0.14%。</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">如下图所示、数据和模型并行性提高了数据处理和分布式TensorFlow模型推理速度。NFS中的数据位置会使运行时间略有提高、因为工作流瓶颈是下载经过预先训练的模型。如果增加脚本数据集大小、NFS的优势就会更加明显。</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">激发NLP情感分析端到端工作流运行时间。</block>
  <block id="bb9cd55aa92ceddf07506d9a2aaaa151" category="paragraph"><block ref="bb9cd55aa92ceddf07506d9a2aaaa151" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">分布式培训、提供Horovod性能</block>
  <block id="319e0ff7f30f4729140562f5e123c5cb" category="inline-link-macro">《适用于每个主要用例的Python脚本》</block>
  <block id="e37af8307fb97140dbcc0c8e2293d58f" category="paragraph">以下命令在Spark集群中使用一个`m`主节点生成运行时信息和日志文件、该节点包含160个执行器、每个执行器具有一个核心。执行器内存限制为5 GB、以避免内存不足错误。请参见一节 <block ref="033a864c436cdbcbe38983e75952a07f" category="inline-link-macro-rx"></block> 有关数据处理、模型训练和模型准确性计算的更多详细信息、请参见`keras_sock_horovod_Rossmann_estimator.py`。</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">由此产生的运行时间为十个训练时长、如下所示：</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">处理输入数据、训练DNN模型、计算准确性以及生成TensorFlow检查点和CSV文件以获得预测结果需要43分钟以上的时间。我们将培训时间限制为10个、实际上通常设置为100个、以确保模型的准确性。训练时间通常随时间间隔的数量呈线性增长。</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">接下来、我们会使用集群中的四个工作节点、并在`yarn`模式下使用HDFS中的数据执行同一个脚本：</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">生成的运行时间得到了以下改进：</block>
  <block id="206c83ab2ec1ea280656b18c0e2dc4dd" category="paragraph">借助Horovod在Spark中的模型和数据并行、我们发现运行时速度比`yarn`和`local`模式加快了5.29倍、并有十个训练时长。下图显示了这一点以及图例`HDFS`和`Local`。如果可以使用GPU、则可以进一步加快底层TensorFlow DNN模型培训的速度。我们计划执行此测试、并在未来的技术报告中公布测试结果。</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">我们的下一个测试将NFS中的输入数据的运行时间与HDFS进行了比较。AFF A800上的NFS卷已挂载在集群的五个节点(一个主节点、四个员工节点)上的`或sparemdemo/horovod`上。我们运行的命令与先前测试类似、其中`-data-dir`参数现在指向NFS挂载：</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">使用NFS生成的运行时如下：</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">此外、还实现了1.43倍的加速、如下图所示。因此、在将NetApp全闪存存储连接到集群后、客户可以享受到Horovod Spark工作流快速数据传输和分发的优势、与在单个节点上运行相比、速度加快了7.55倍。</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Horovod Spark Workflow Runtime。</block>
  <block id="56085b16b09d835f05c89b29473a0e73" category="paragraph"><block ref="56085b16b09d835f05c89b29473a0e73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">深度学习模型、用于控制器预测性能</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">对于旨在最大程度地提高CTR的推荐系统、您必须了解用户行为背后的复杂功能交互、这些交互可以从低顺序到高顺序进行数学计算。低顺序和高顺序功能交互对于良好的深度学习模型来说都同样重要、而不是相互影响。深度Factorization Machine (DeepFM)是一种基于面化机器的神经网络、它将面化机器结合在一起、在一个新的神经网络架构中提供建议、并进行深度学习以进行功能学习。</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">宽和高；深模型</block>
  <block id="4028a7777950de6e915d72e379bde75d" category="paragraph">虽然传统的面化机可以模拟成对的功能交互、将其作为功能之间潜在向量的内在产品、并可从理论上捕获高阶信息、但实际上、由于计算和存储复杂性较高、机器学习实践者通常只使用二级功能交互。Google等深度神经网络变体<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> 另一方面、通过将线性宽模型和深度模型相结合、可以在混合网络结构中学习复杂的功能交互。</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">此宽深模型有两个输入、一个用于底层宽模型、另一个用于深度、后者的后半部分仍需要专家级的功能工程、因此、技术在其他领域的推广程度较低。与宽深模型不同、DeepFM可以高效地进行原始功能培训、而无需任何功能工程、因为其宽部分和深部分共享相同的输入和嵌入向量。</block>
  <block id="03eaefcaa3f1aca8b4ffa8b95a4798b9" category="inline-link-macro">《适用于每个主要用例的Python脚本》。</block>
  <block id="105a0d9d76e001ecdab02b77ca3a98ae" category="paragraph">首先、我们使用部分中的`run_section_criteo_spark.py`将Criteo `trint.txt`(11GB)文件处理为CSV文件` ctrt_trint.csv`、该文件存储在NFS挂载中`/sparemodem/tr-4570-data` <block ref="43e008bfee5963b21d09b0af490bfdd7" category="inline-link-macro-rx"></block> 在此脚本中、函数`process_input_file`会执行多种字符串方法来删除选项卡并插入`‘、'`作为分隔符、并将`‘\n '`作为换行符。请注意、您只需处理原始的`Train .txt`一次、即可将代码块显示为注释。</block>
  <block id="c960954a8d119eab5ff32a80d7fcc8e8" category="paragraph">对于以下不同DL型号的测试、我们使用`ct_Train.csv`作为输入文件。在后续测试运行中、输入的CSV文件会读取到Spark DataFrame中、其架构包含`‘label '`、整型密集型功能`['I1'、'Ies'、'I3'、…、'I13']`、 和稀疏功能`、'c1"、'c2'、'cc3、…、'c26']`。以下`spart-Submit`命令将获取输入CSV、将DeepFM模型分成20%进行交叉验证、并在经过十次训练后选择最佳模型来计算测试集的预测准确性：</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">请注意、由于数据文件`CT_Train.csv`超过11 GB、因此您必须设置一个足够的`spara.driver.maxResult Size`、使其大于数据集大小、以避免出现错误。</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">Apache Arrow</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">在上述`SparkSession.Builder`配置中、我们还启用了<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block>、使用`D .parctoandas ()`方法将Spark DataFrame转换为熊猫DataFrame。</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">随机拆分后、训练数据集中的行数超过36M、而测试集中的样本数则超过9M：</block>
  <block id="e6219a2eedbe95f3aa16ed53c4733845" category="paragraph">由于本技术报告重点介绍CPU测试而不使用任何GPU、因此、您必须使用适当的编译器标志构建TensorFlow。此步骤可避免调用任何GPU加速库、并充分利用TensorFlow的高级矢量扩展(Advanced Vector Extension、AVX)和AVX2指令。这些功能专为线性代数计算而设计、例如矢量化添加、前馈或后传播DNN训练中的矩阵乘法。使用256位浮点(FP)注册的AVX2可提供融合乘法添加(FMA)指令、非常适合整数代码和数据类型、从而实现高达2倍的加速。对于FP代码和数据类型、与AVX相比、AVX2实现了8%的加速。</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">市场</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">要从源构建TensorFlow、NetApp建议使用<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block>。对于我们的环境、我们会在shell提示符处执行以下命令来安装`dnF`、`dnf-plugins`和azel。</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">要在构建过程中使用C+17功能、必须启用GCC 5或更高版本、此功能由RHEL和软件收集库(Software Collections Library、SCL)提供。以下命令可在RHEL 7.9集群上安装`devtoolset`和GCC 11.2.1：</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">文章</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">请注意、最后两个命令会启用`devtoolset-11`、它会使用`/opt/rg/devtoolset-11/root/usr/bin/gcc`(GCC 11.2.1)。此外、请确保您的`git`版本高于1.8.3 (RHEL 7.9随附此版本)。请参见此部分<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> 用于将`git`更新到2.24.1。</block>
  <block id="dc06a2e6ab4959266b8e70b6a4ecc45c" category="inline-link-macro">《针对每个主要用例的Python脚本》、</block>
  <block id="c55692ca5ecd175c73f55ba5b9319688" category="paragraph">我们假定您已克隆最新的TensorFlow主报告。然后、使用`workspace`文件创建`workspace`目录、以便使用AVX、AVX2和FMA从源构建TensorFlow。运行`configure`文件并指定正确的Python二进制位置。<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> 已在测试中禁用、因为我们未使用GPU。将根据您的设置生成`.bazelrc`文件。此外、我们还编辑了该文件并设置`build -def=no_hdfs_support=false`以启用HDFS支持。请参见一节中的`.bazelrc` <block ref="2aec9284f17908b1690444cda81e493c" category="inline-link-macro-rx"></block> 有关设置和标志的完整列表。</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">使用正确的标志构建TensorFlow后、运行以下脚本以处理Criteo显示广告数据集、训练DeepFM模型、并根据预测分数计算接收器运行特征曲线(ROC AUC)下的区域。</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">经过十次训练后、我们在测试数据集中获得了AUC分数：</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">我们采用与先前使用情形类似的方式、将Spark工作流运行时与驻留在不同位置的数据进行了比较。下图比较了Spark工作流运行时的深度学习CTR预测。</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">对Spark工作流运行时的深度学习CTR预测进行比较。</block>
  <block id="d27b678d975cf1fb0769c3e664f4f2dd" category="paragraph"><block ref="d27b678d975cf1fb0769c3e664f4f2dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">本节介绍了可能对此解决方案 的内容感兴趣的人员。</block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">分析和数据科学领域涉及IT和业务领域的多个领域：</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">DevOps工程师需要使用工具将新的AI和ML应用程序集成到其CI和CD管道中。</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">云管理员和架构师必须能够设置和管理混合云资源。</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">业务用户希望能够访问分析、AI、ML和DL应用程序。</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">在本技术报告中、我们将介绍NetApp AFF 、E系列、StorageGRID 、NFS直接访问、Apache Spark、 Horovod和Keras可以帮助这些角色为业务创造价值。</block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">本节总结了本文档中有关适用于Apache Spark的NetApp存储解决方案的内容。</block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">在本文档中、我们将讨论Apache Spark架构、客户用例以及与大数据、现代分析以及AI、ML和DL相关的NetApp存储产品组合。在我们基于行业标准基准测试工具和客户需求进行的性能验证测试中、NetApp Spark解决方案的性能优于原生 Hadoop系统。将本报告中提供的客户用例和性能结果相结合、可以帮助您为您的部署选择合适的Spark解决方案。</block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">现代企业数据中心是一种混合云、它可以在内部和/或多个公有 云中通过具有一致运营模式的持续数据管理平台连接多个分布式基础架构环境。要充分利用混合云、您必须能够在内部环境和多云环境之间无缝移动数据、而无需进行任何数据转换或应用程序重构。</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">混合云解决方案</block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">客户表示、他们开始混合云之旅的方式是将二级存储迁移到云以用于数据保护等使用情形、或者将应用程序开发和DevOps等业务关键型工作负载迁移到云。然后、它们会迁移到更关键的工作负载。Web和内容托管、开发运营和应用程序开发、数据库、分析和容器化应用程序是最受欢迎的混合云工作负载。企业人工智能项目的复杂性、成本和风险历来阻碍人工智能从实验阶段到生产阶段的采用。</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">借助NetApp混合云解决方案 、客户可以通过一个控制面板在分布式环境中管理数据和工作流、从而从集成的安全性、数据监管和合规性工具中受益、同时根据其使用情况优化总拥有成本。下图是一个云服务合作伙伴的示例解决方案 、该合作伙伴负责为客户的大数据分析数据提供多云连接。</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">云服务合作伙伴的解决方案 示例。</block>
  <block id="ad71e01672e98de491e72d22ba403059" category="paragraph"><block ref="ad71e01672e98de491e72d22ba403059" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">在这种情况下、在AWS中从不同来源接收的物联网数据存储在NetApp私有存储(NPS)的中央位置。NPS存储连接到AWS和Azure中的Spark或Hadoop集群、从而支持在多个云中运行的大数据分析应用程序访问相同的数据。此用例的主要要求和挑战包括：</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">数据必须通过不同的传感器和中心从内部和云环境等不同的源接收。</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">解决方案 必须高效且经济高效。</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">主要挑战是构建一个经济高效的解决方案 、以便在不同的内部环境和云环境之间提供混合分析服务。</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">我们的数据保护和多云连接解决方案 解决了在多个超大规模提供商之间部署云分析应用程序的难题。如上图所示，来自传感器的数据会通过 Kafka 流式传输并输入到 AWS Spark 集群中。数据存储在 NPS 中的 NFS 共享中， NPS 位于 Equinix 数据中心内的云提供商之外。</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">由于NetApp NPS分别通过Direct Connect和Express Route连接连接到Amazon AWS和Microsoft Azure、因此客户可以利用原位分析模块从Amazon和AWS分析集群访问数据。因此、由于内部和NPS存储均运行ONTAP 软件、<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> 可以将NPS数据镜像到内部集群、从而在内部和多个云之间提供混合云分析。</block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">此页面介绍了可使用此解决方案 的不同区域。</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">使用情形摘要</block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">流式传输数据</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark可以处理流式数据、用于流式提取、转换和加载(ETL)流程；数据丰富；触发事件检测；以及复杂会话分析：</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*流式ETL*数据在被推入数据存储库之前会持续清理和聚合。Netflix使用Kafka和Spark流式传输构建实时在线电影建议和数据监控解决方案 、每天可以处理来自不同数据源的数十亿个事件。但是、用于批处理的传统ETL的处理方式有所不同。首先读取此数据、然后将其转换为数据库格式、然后再写入数据库。</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*数据丰富。* Spark流可利用静态数据丰富实时数据、实现更实时的数据分析。例如、在线广告公司可以根据客户行为信息提供个性化的有针对性的广告。</block>
  <block id="e3c0d503686e9ab8960903bc80d3f700" category="list-text">*触发事件检测。*利用Spark流、您可以检测并快速响应可能指示潜在严重问题的异常行为。例如、金融机构使用触发器检测和停止欺诈交易、医院使用触发器检测患者生命迹象中检测到的危险健康变化。</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*会话分析复杂。* Spark流式传输会在登录到网站或应用程序后收集用户活动等事件、然后对这些事件进行分组和分析。例如、Netflix使用此功能提供实时电影建议。</block>
  <block id="61fb23ef88a4d1404b2410cf94238fb5" category="paragraph">有关流式数据配置、Confluent Kafka验证和性能测试的更多信息、请参见<block ref="10063fdbf72f58440f18bb49eb2309fe" category="inline-link-rx"></block>。</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">机器学习</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Spark集成框架可帮助您使用机器学习库(MLlib)对数据集重复运行查询。MLlib用于集群、分类和维度缩减等领域、用于某些常见的大数据功能、例如预测性智能、用于营销的客户细分以及情感分析。MLlib用于网络安全领域、用于实时检查数据包是否存在恶意活动迹象。它可以帮助安全提供商了解新威胁、在实时保护客户端的同时保持领先的黑客地位。</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">深度学习</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow是一个广泛应用于整个行业的深度学习框架。TensorFlow支持在CPU或GPU集群上进行分布式培训。通过这种分布式培训、用户可以在包含大量深层层的大量数据上运行此培训。</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">直到最近、如果我们要将TensorFlow与Apache Spark结合使用、我们需要在PySpark中对TensorFlow执行所有必要的ETL、然后将数据写入中间存储。然后、这些数据将加载到TensorFlow集群中、用于实际的培训过程。此工作流要求用户维护两个不同的集群、一个用于ETL、一个用于TensorFlow的分布式培训。运行和维护多个集群通常既繁琐又耗时。</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">早期版本的Spark中的DataFrame和RDD不适合深度学习、因为随机访问受限。在采用项目"氢"的Spark 3.0中、增加了对深度学习框架的原生 支持。此方法允许在Spark集群上进行非基于MapReduce的计划。</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">交互式分析</block>
  <block id="11bb4412e7e82514a739cb60053e30df" category="paragraph">Apache Spark速度非常快、无需使用包括SQL、R和Python在内的其他开发语言进行采样、即可执行探索性查询。SPARK使用可视化工具处理复杂数据并以交互方式将其可视化。利用结构化流技术激发用户对Web分析中的实时数据执行交互式查询、使您能够对Web访客的当前会话运行交互式查询。</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">建议系统</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">多年来、推荐系统为我们的生活带来了巨大的变化、因为企业和消费者已经对在线购物、在线娱乐和许多其他行业的巨大变化做出了响应。事实上、这些系统是人工智能在生产领域最明显的成功案例之一。在许多实际使用情形中、推荐系统与对话式AI或与NLP后端交互的聊天机器人相结合、以获取相关信息并生成有用的推断。</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">如今、许多零售商都在采用新的业务模式、例如在线购买和在店内取货、轮式取件、自助结账、扫描即用等。在COVID-19大流行病期间、这些模式变得更加突出、让消费者购物更加安全、更方便。AI对于这些不断增长的数字趋势至关重要、这些趋势受消费者行为的影响、反之亦然。为了满足消费者不断增长的需求、增强客户体验、提高运营效率并增加收入、NetApp帮助其企业客户和企业使用机器学习和深度学习算法设计更快、更准确的推荐系统。</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">提供建议时、可以使用多种常见的方法、包括协作筛选、基于内容的系统、深度学习建议模型(DLRM)和混合技术。之前、客户使用PySpark实施协作式筛选来创建建议系统。SPARK MLlib可实施最少交替方形(ALS)来进行协作筛选、这是DLRM兴起之前企业中非常流行的一种算法。</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">自然语言处理</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">通过自然语言处理(NLP)实现的对话AI是AI的分支、可帮助计算机与人类进行通信。NLP在从智能助手和聊天机器人到Google搜索和预测性文本的每个行业垂直市场和许多用例中都很普遍。根据 A<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> 预测、到2022年、70%的人将每天与对话式AI平台进行交互。要在人与机器之间进行高质量的对话、响应必须快速、智能且自然。</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">客户需要大量数据来处理和训练其NLP和自动语音识别(Automatic Speech Recognition、As1)模式。他们还需要跨边缘、核心和云移动数据、并且需要在数毫秒内执行推理的能力、以便与人类建立自然的通信。NetApp AI和Apache Spark是计算、存储、数据处理、模型训练、微调、 和部署。</block>
  <block id="33984e410ab674dcea1f21af4c5db4ec" category="paragraph">情感分析是NLP中的一个研究领域、其中从文本中提取积极、负面或中立的情绪。情感分析有多种使用情形、从确定支持中心员工在与调用方对话时的表现到提供适当的自动聊天机器人响应。它还用于根据公司代表与受众在季度收益电话会议上的互动情况预测公司的股票价格。此外、情感分析可用于确定客户对品牌提供的产品、服务或支持的看法。</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">John Snow Labs</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">金融新闻情感</block>
  <block id="322f98ff217f4c12ea8f1b3ea41f4024" category="paragraph">我们使用了<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> 库自<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> 从Transformer (Bert)型号加载经过预先训练的管道和双向编码器表示、包括<block ref="25bfdf207733b5ead40d4d36ea328e85" category="inline-link-rx"></block> 和<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>、大规模执行令牌化、命名实体识别、模型训练、拟合和情感分析。SPARK NLP是生产中唯一一个开源NLP库、可提供最先进的互感器、例如Bert、B俊 尔特、Electra、XNet、DistillBeert、 Roberta、DeBerta、XLM- Roberta、Longformerk、ELMOA、 通用句子编码器、Google t5、MarianMT和GPt2。该库不仅适用于Python和R、还适用于通过本机扩展Apache Spark实现规模化的JVM生态系统(Java、Scala和Kotlin)。</block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">本节介绍Apache Spark的性质和组件、以及它们对解决方案 的贡献。</block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark是一种常见的编程框架、用于编写直接与Hadoop分布式文件系统(HDFS)配合使用的Hadoop应用程序。SPARK可随时投入生产、支持流式数据处理、并且速度比MapReduce更快。Spark具有可配置的内存数据缓存功能、可实现高效迭代、而Spark shell可通过交互方式学习和探索数据。借助Spark、您可以在Python、Scala或Java中创建应用程序。激发应用程序由一个或多个具有一个或多个任务的作业组成。</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">每个Spark应用程序都有一个Spark驱动程序。在yar-Client模式下、驱动程序在本地客户端上运行。在yar-Cluster模式下、驱动程序在应用程序主节点上的集群中运行。在集群模式下、即使客户端断开连接、应用程序也会继续运行。</block>
  <block id="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="paragraph"><block ref="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">集群管理器有三种：</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*独立。*此管理器是Spark的一部分、可轻松设置集群。</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">* Apache Mesos.*这是一个通用集群管理器、也运行MapReduce和其他应用程序。</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">* Hadoop yaryar.*这是Hadoop 3中的资源管理器。</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">弹性分布式数据集(RDD)是Spark的主要组件。RDD会重新创建存储在集群内存中的数据中的丢失和缺失数据、并存储来自文件或通过编程方式创建的初始数据。可以使用文件、内存中的数据或其他RDD创建RDD。SPARK编程执行两项操作：转型和操作。转型将基于现有RDD创建新的RDD。操作将从RDD返回一个值。</block>
  <block id="06b482c7bd2522ec4a62ccc70b71c37e" category="paragraph">转换和操作也适用于Spark数据集和DataFrame。数据集是一组分布式数据、可提供RDD的优势(强类型、使用lambda函数)以及Spark SQL优化的执行引擎的优势。可以使用JVM对象构建数据集、然后使用功能转换(map、flatMap、filter等)进行操作。DataFrame是按命名列组织的数据集。它在概念上相当于关系数据库中的表或R/Python中的数据帧。DataFrame可以从多种源构建、例如结构化数据文件、Hive/HBase中的表、内部或云中的外部数据库或现有RDD。</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Spark应用程序包括一个或多个Spark作业。作业在执行器中运行任务、而执行器在YARN容器中运行。每个执行者在一个容器中运行、执行者在应用程序的整个生命周期内都存在。执行者在应用程序启动后得到修复、而yarn不会调整已分配的容器的大小。执行者可以同时对内存数据运行任务。</block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="doc">适用于每个主要用例的Python脚本</block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">以下三个Python脚本对应于所测试的三个主要用例。第一个是`sentiment_analysis _sparknlp.py`。</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">第二个脚本为`keras_sock_horovod_rossmann_estimator.py`。</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">第三个脚本为`run_clustery_Criteo_spn.py`。</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">使用情形摘要</block>
  <block id="f674169036173cc4a9f01e223c275c8d" category="open-title">自动化部署</block>
  <block id="329ecbed66c88e6c0c049d051ad6aa9a" category="paragraph">NetApp公司David Arnette和Sung-Han Lin</block>
  <block id="d940dfad6ae514d8235749f5f5bf92ed" category="paragraph">NVA-1151-design介绍了一种经过NetApp验证的架构、用于使用NetApp AFF A800存储系统、NVIDIA DGX A100系统和NVIDIA Mellanox网络交换机进行机器学习和人工智能工作负载。它还包括所实施架构的基准测试结果。</block>
  <block id="16550c71fdf2102ec8face86a5d82746" category="cell">2022年9月30日</block>
  <block id="8485ff07404cda7656a72c1d11b2e278" category="cell">添加了解决方案 、用于使用VMware HCX将工作负载迁移到FSxN数据存储库</block>
  <block id="bee0d36d9b0ec64a15bf59019a6ec2e2" category="cell">2022年9月29日</block>
  <block id="b6942044de91f49e700f684f12314907" category="cell">添加了解决方案 、用于使用VMware HCX将工作负载迁移到ANF数据存储库</block>
  <block id="fa3811ba5828de9b5ce35701ec38d154" category="list-text">检查VMC的可用性 <block ref="bd516ef46cad23535fac2e4d7f54defe" category="inline-link-macro-rx"></block>。</block>
  <block id="0ecaf171a89c41ea509c3f45896220b8" category="list-text">Amazon的定价指南提供了有关FSxN (FSX ONTAP)的可用位置的信息。您可以找到这些信息 <block ref="2d4b4b449ef448fbb3000f58e542f4ee" category="inline-link-macro-rx"></block>。</block>
  <block id="4573434025dab87886cfb0b766c70cb1" category="paragraph">最后更新日期：2022年9月28日。</block>
  <block id="d8cefe0428d28368238dbbeabef9c83f" category="open-title">混合多云(HMC)</block>
  <block id="493f775d3c83d2c658056477b1d58f74" category="paragraph">【下划线】#*适用于AWS/VMC*的视频#</block>
  <block id="638eb9310db06d086fac0c3c069669af" category="video-title">AWS上的VMware Cloud补充数据存储库、使用适用于NetApp ONTAP 的Amazon FSX</block>
  <block id="6f605e77e59dfe45ae918965ba0bd336" category="video-title">借助适用于NetApp ONTAP 的Amazon FSX、基于AWS的VMware Cloud可节省TCO</block>
  <block id="d7d56735bb43053ca43b2d9698b2623c" category="video-title">适用于VMC的VMware HCX部署和配置设置</block>
  <block id="e906083dc0b31806eab68df2c340504f" category="video-title">使用适用于VMC和FSxN的VMware HCX进行冷迁移演示</block>
  <block id="62184265581f788d642b26b13c273b93" category="paragraph">【下划线】#*适用于Azure/AVS*的视频#</block>
  <block id="62766d3266d403114a010bc02e7b4004" category="video-title">Azure NetApp Files 中的Azure VMware解决方案 补充数据存储库概述</block>
  <block id="4864ff1c07b9b500fd46c4a1c5918fd8" category="video-title">采用Cloud Volumes ONTAP 、SnapCenter 和Jetstream的Azure VMware解决方案 灾难恢复</block>
  <block id="8eb2fa7c0d2a676485a155077b770fdd" category="video-title">使用适用于AVS和ANF的VMware HCX进行冷迁移演示</block>
  <block id="664115ac899ebaf481e2b75540d5c56c" category="video-title">使用适用于AVS和ANF的VMware HCX进行VMotion演示</block>
  <block id="914c1d4cdf840b7b030978f1b07915d8" category="video-title">使用适用于AVS和ANF的VMware HCX进行批量迁移演示</block>
  <block id="9de15a07d3a8b75e451c50d7fa64fae9" category="example-title">采用Azure NetApp Files (ANF)的Azure上的Azure VMware服务</block>
  <block id="04a1b40e30ee3bddef53c85ca68c8b36" category="inline-link-macro">使用VMware HCX将工作负载迁移到Azure NetApp Files 数据存储库</block>
  <block id="edf47ba9dc6467e3104102f10bafe323" category="list-text"><block ref="edf47ba9dc6467e3104102f10bafe323" category="inline-link-macro-rx"></block></block>
  <block id="668f202e4850de68f941501493126dea" category="doc">TR-4940：《使用VMware HCX将工作负载迁移到Azure NetApp Files 数据存储库—快速入门指南》</block>
  <block id="ddfd90f2a10c16cbd6548844b07532c2" category="paragraph">作者：NetApp Solutions Engineering</block>
  <block id="e5baae71bfede792aee5ab0c09fbcd23" category="section-title">概述：迁移具有VMware HCX、Azure NetApp Files 数据存储库和Azure VMware解决方案 的虚拟机</block>
  <block id="45c532c5535fe16cf9a5868bbd9a3fcd" category="paragraph">Azure VMware解决方案 和Azure NetApp Files 数据存储库最常见的使用情形之一是迁移VMware工作负载。VMware HCX是首选选项、它提供了各种迁移机制、可将内部虚拟机(VM)及其数据移动到Azure NetApp Files 数据存储库。</block>
  <block id="a2ee24315378af7416f8fef29e0f0efa" category="paragraph">VMware HCX主要是一个迁移平台、旨在简化应用程序迁移、工作负载重新平衡、甚至跨云实现业务连续性。它作为Azure VMware解决方案 私有云的一部分提供、可通过多种方式迁移工作负载、并可用于灾难恢复(DR)操作。</block>
  <block id="227830ba037f63bb97cffeeb98e3a13e" category="paragraph">本文档提供了配置Azure NetApp Files 数据存储库以及下载、部署和配置VMware HCX的分步指导、其中包括内部部署和Azure VMware解决方案 端的所有主要组件、包括互连、网络扩展和WAN优化、用于启用各种VM迁移机制。</block>
  <block id="a7441e9f968c9ea792320876fd73622a" category="admonition">VMware HCX可用于任何数据存储库类型、因为迁移是在VM级别进行的。因此、本文档适用于计划在Azure VMware解决方案 中部署Azure NetApp Files 以实现经济高效的VMware云部署的现有NetApp客户和非NetApp客户。</block>
  <block id="0ba40ecb813b20bd8c3277c4afcbd451" category="example-title">高级步骤</block>
  <block id="9a40c0b2781fd2a3a99aa2a6c0c4616e" category="paragraph">此列表概括介绍了在Azure云端安装和配置HCX Cloud Manager以及在内部安装HCX Connector所需的步骤：</block>
  <block id="d7bfcf4345887ee24f2c3083038c6327" category="list-text">通过Azure门户安装HCX。</block>
  <block id="ea0d203a776b5c56ae3ed2c61269d2a9" category="list-text">在内部部署的VMware vCenter Server中下载并部署HCX Connector Open Virtualization Appliance (OVA)安装程序。</block>
  <block id="2be88e0d3f6d4e20f4bf2bcca7895d7b" category="list-text">使用许可证密钥激活HCX。</block>
  <block id="6a0721ebaaff6c0b1564863ac23c2509" category="list-text">将内部部署的VMware HCX连接器与Azure VMware解决方案 HCX Cloud Manager配对。</block>
  <block id="612a4c795715d17bfff4e0ba3a8f66d1" category="list-text">配置网络配置文件、计算配置文件和服务网格。</block>
  <block id="81feabec43f9f1bcb7230fd62f89fb76" category="list-text">(可选)执行网络扩展、以避免在迁移期间重新进行IP。</block>
  <block id="dbed86346a8d7cb3692ba413f7e14f56" category="list-text">验证设备状态并确保可以进行迁移。</block>
  <block id="2f2c97fb0d914a7fc7bcb2c8fad16868" category="list-text">迁移VM工作负载。</block>
  <block id="f2f281974ab353b606093268f9d5335e" category="paragraph">开始之前、请确保满足以下前提条件。有关详细信息，请参见此<block ref="88354f8e41d1a2e6cea84b3d932b3286" category="inline-link-rx"></block>。在满足包括连接在内的前提条件后、通过从Azure VMware解决方案 门户生成许可证密钥来配置和激活HCX。下载OVA安装程序后、按如下所述继续安装过程。</block>
  <block id="f52b030029e78590ca66fbf452dfcb14" category="admonition">默认选项为HCX高级版、VMware HCX Enterprise版本也可通过支持服务单获得、并且无需额外付费。</block>
  <block id="67863abb3ec8a28f54adf852298b392b" category="inline-link">NetApp链接</block>
  <block id="d2a5cfbad293008f62b5d4e58457a6d1" category="inline-link">Microsoft链接</block>
  <block id="e265f4db94070f55784ef698e7f4f29b" category="inline-link">设置站点到站点VPN或快速路由全局访问连接</block>
  <block id="bb764f1df90a85d77eec079e03bd9764" category="list-text">从启用了VMware vSphere的内部数据中心迁移VM和关联数据需要从数据中心到SDDC环境的网络连接。迁移工作负载之前、<block ref="31180ecf5c9f25ba891b891b395a9305" category="inline-link-rx"></block> 在内部环境和相应的私有云之间。</block>
  <block id="d08fd3825f77e870dd8e93463aea245d" category="list-text">从内部VMware vCenter Server环境到Azure VMware解决方案 私有云的网络路径必须支持使用vMotion迁移VM。</block>
  <block id="f3b5e5598d4c0c196bd2fd79b000637f" category="inline-link">防火墙规则和端口</block>
  <block id="e1be03b35dc8e9fb114970b06dcd6c18" category="list-text">确保满足所需<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> 允许内部vCenter Server与SDDC vCenter之间的vMotion流量。在私有云上、默认情况下会在vMotion网络上配置路由。</block>
  <block id="444617dcfe0d17ad386105e865d21113" category="list-text">Azure NetApp Files NFS卷应挂载为Azure VMware解决方案 中的数据存储库。请按照本节中详细介绍的步骤进行操作<block ref="1b959b45bbb3571141089802677ad765" category="inline-link-rx"></block> 将Azure NetApp Files 数据存储库连接到Azure VMware解决方案主机。</block>
  <block id="2f660e9fff52e5ac1b7818a029d3b447" category="example-title">高级架构</block>
  <block id="0048e42e38e4c6f587f210afe26fcb4a" category="inline-image-macro">此图显示了此解决方案 中使用的高级架构。</block>
  <block id="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="paragraph"><block ref="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84f7e9d42c2c0ee4f87ddeaa2e09bb2" category="paragraph">按照一系列步骤完成此解决方案 的部署：</block>
  <block id="4c8f77e6ab4a9e453faf4063978f94d5" category="example-title">第1步：使用加载项选项通过Azure门户安装HCX</block>
  <block id="f4ca86f94d0e12644ce102e7c48d6030" category="paragraph">要执行安装、请完成以下步骤：</block>
  <block id="7d4c34e9f83446ef58ad083cd2c29580" category="list-text">登录到Azure门户并访问Azure VMware解决方案 私有云。</block>
  <block id="16671eada5939f5c2129db7e8f9522a0" category="list-text">选择适当的私有云并访问附加项。可通过导航到*管理&gt;加载项*来完成此操作。</block>
  <block id="de23e32bd14f5f77d4178bb7d56c2eb0" category="list-text">在HCX工作负载移动性部分中、单击*开始使用*。</block>
  <block id="239ba3d7293041d0d4dcb4c5b538ea74" category="inline-image-macro">HCX工作负载移动部分的屏幕截图。</block>
  <block id="91a36107da2b4f5cbc4963027f871289" category="paragraph"><block ref="91a36107da2b4f5cbc4963027f871289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="de66be71be828600d682c9f0bdb03a18" category="list-text">选择*我同意条款和条件*选项、然后单击*启用并部署*。</block>
  <block id="e26184583d86572b90efcca3db66731e" category="admonition">默认部署为HCX Advanced。打开支持请求以启用Enterprise版本。</block>
  <block id="adafe418547291754cadbfc0d2c5c1dc" category="admonition">部署大约需要25到30分钟。</block>
  <block id="e39769185df95d6577314b0c683cf848" category="inline-image-macro">完成"HCX Workload移动性"部分的屏幕截图。</block>
  <block id="6df468c8490be1137779d8811f53bddb" category="paragraph"><block ref="6df468c8490be1137779d8811f53bddb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae33ed8b7695cc113850f5a13bab6e56" category="example-title">第2步：在内部vCenter Server中部署安装程序OVA</block>
  <block id="e957ef97a04368fda5e2652e51c19d1d" category="paragraph">要使内部连接器连接到Azure VMware解决方案 中的HCX管理器、请确保在内部环境中打开相应的防火墙端口。</block>
  <block id="0c216cee9411e03f1127e6ffc2bf025d" category="paragraph">要在内部vCenter Server中下载并安装HCX Connector、请完成以下步骤：</block>
  <block id="c28009ba42c1703c33046d99285a0a10" category="list-text">从Azure门户中、转到Azure VMware解决方案 、选择私有云、然后使用HCX选择*管理&gt;加载项&gt;迁移*、并复制HCX Cloud Manager门户以下载OVA文件。</block>
  <block id="3a858d6f55c84c77db797aafa874a8a5" category="admonition">使用默认CloudAdmin用户凭据访问HCX门户。</block>
  <block id="7efdfa090ad75b0c0f02e115ab8e56bd" category="inline-image-macro">用于下载HCX OVA文件的Azure门户的屏幕截图。</block>
  <block id="ab9fbdf98484d630980bec96dac55284" category="paragraph"><block ref="ab9fbdf98484d630980bec96dac55284" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d5565b77c91d5d6d289858e4d7ea91" category="list-text">使用jumphost通过mailto：cloudadmin@vsphere.local[ cloudadmin@vsphere.local^]访问HCX门户后、导航到*管理&gt;系统更新*、然后单击*请求下载链接*。</block>
  <block id="f6b26e036b373b18f11dc0da33ef5268" category="admonition">下载或复制到OVA的链接并将其粘贴到浏览器中、以开始下载要部署在内部vCenter Server上的VMware HCX Connector OVA文件。</block>
  <block id="894d2481892f65fcae6dfc0ac7b9ec0d" category="inline-image-macro">错误：OVA下载链接的屏幕截图。</block>
  <block id="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="paragraph"><block ref="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12e1c817f24a0aa94d2ae26ea6535479" category="list-text">下载OVA后、使用*部署OVF模板*选项将其部署到内部VMware vSphere环境中。</block>
  <block id="fc1a0933af5c68cc43dbb90b50c1b0d3" category="inline-image-macro">错误：用于选择正确OVA模板的屏幕截图。</block>
  <block id="d36fa73d8072d1ab34f185f12d5fede5" category="paragraph"><block ref="d36fa73d8072d1ab34f185f12d5fede5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ba87ef75729cfcffc74d93e0a0852a1" category="list-text">输入OVA部署所需的所有信息、单击*下一步*、然后单击*完成*以部署VMware HCX连接器OVA。</block>
  <block id="ed1aadd2fcd5906dd58f9a89179a638e" category="admonition">手动启动虚拟设备。</block>
  <block id="dca749083ce6c763573225ed6a46a64e" category="inline-link">《VMware HCX用户指南》</block>
  <block id="e10fbd147d2ee50fbbb460ad2f18fa14" category="paragraph">有关分步说明、请参见<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>。</block>
  <block id="6897bb7015f874baf69560eef515010c" category="example-title">第3步：使用许可证密钥激活HCX Connector</block>
  <block id="4aa14207b82768ed77473306cc7a65c2" category="paragraph">在内部部署VMware HCX Connector OVA并启动设备后、请完成以下步骤以激活HCX Connector。从Azure VMware解决方案 门户生成许可证密钥、并在VMware HCL Manager中激活它。</block>
  <block id="3535419e37127ca2de6abd9538414466" category="list-text">从Azure门户中、转到Azure VMware解决方案 、选择私有云、然后选择*管理&gt;加载项&gt;使用HCX*迁移。</block>
  <block id="436402d536d27aaa2091a54751a60036" category="list-text">在*使用HCX密钥与内部环境连接*下、单击*添加*并复制激活密钥。</block>
  <block id="0b053e667d8c9baa8cbb4a5402fe69e1" category="inline-image-macro">添加HCX密钥的屏幕截图。</block>
  <block id="5d9de146e997662a8510bd175e5c593a" category="paragraph"><block ref="5d9de146e997662a8510bd175e5c593a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03fc385dd3b54c80a78341c5aa2189a3" category="admonition">部署的每个内部HCX连接器都需要一个单独的密钥。</block>
  <block id="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link"><block ref="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link-rx"></block></block>
  <block id="b6d4af6a25f46f3687120681e525d833" category="list-text">登录到内部部署的VMware HCX Manager、网址为<block ref="f9ac10929d1e2f12c4fea5c57d73b3eb" category="inline-link-rx"></block> 使用管理员凭据。</block>
  <block id="b2719f92794cef282f9cd7684baca4c4" category="admonition">使用在OVA部署期间定义的密码。</block>
  <block id="a864855f2120d5c8d4793a4866b6a7bb" category="list-text">在许可中、输入从步骤3复制的密钥、然后单击*激活*。</block>
  <block id="e5c8d88f2fa7af9f1a719e04c4b17740" category="admonition">内部HCX连接器应可访问Internet。</block>
  <block id="ee746d79ab481579a8c0202a94e8d378" category="list-text">在*数据中心位置*下、提供最近的位置、以便在内部安装VMware HCX Manager。单击 * 继续 * 。</block>
  <block id="c72431b355c96ffdfb7baece307881f0" category="list-text">在*系统名称*下、更新名称并单击*继续*。</block>
  <block id="030627b8e0e3f6ba69c6a9e524d8e9c0" category="list-text">单击*是、继续*。</block>
  <block id="05399e57e0b2a25ce8cef32f3628b2e3" category="list-text">在*连接vCenter *下、提供vCenter Server的完全限定域名(FQDN)或IP地址以及相应的凭据、然后单击*继续*。</block>
  <block id="96b1cf77a862dc0408a3e2e9678b2165" category="admonition">使用FQDN以避免稍后出现连接问题。</block>
  <block id="390f6c76fee2d7fb6d09bcedc3622467" category="list-text">在*配置SSA/PSC*下、提供平台服务控制器的FQDN或IP地址、然后单击*继续*。</block>
  <block id="b070c615098fb975bc2bc3a9f6c67b3e" category="admonition">输入VMware vCenter Server FQDN或IP地址。</block>
  <block id="f4bb2b9a4de7e44c942457943977fd34" category="list-text">验证输入的信息是否正确、然后单击*重新启动*。</block>
  <block id="a565e4f9db7c03385f61c3bdb0f4b806" category="list-text">服务重新启动后、vCenter Server将在显示的页面上显示为绿色。vCenter Server和SSO都必须具有适当的配置参数、这些参数应与上一页相同。</block>
  <block id="457446477fbd3326ba80d1248eaca490" category="admonition">此过程大约需要10到20分钟、并且需要将此插件添加到vCenter Server中。</block>
  <block id="1181827ced4ce13f7bd91097d9b10dac" category="inline-image-macro">显示已完成过程的屏幕截图。</block>
  <block id="534d4f43f7a513cf2f2152686da775ae" category="paragraph"><block ref="534d4f43f7a513cf2f2152686da775ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0b94fcafcd5f76f4f84be761263d657" category="example-title">第4步：将内部VMware HCX Connector与Azure VMware解决方案 HCX Cloud Manager配对</block>
  <block id="ae37843769e741d076e2422772db5395" category="paragraph">在内部部署和Azure VMware解决方案 中安装HCX Connector后、通过添加配对来配置适用于Azure VMware解决方案 私有云的内部部署VMware HCX Connector。要配置站点配对、请完成以下步骤：</block>
  <block id="28b0363954066139335c413f28022037" category="list-text">要在内部vCenter环境和Azure VMware解决方案 SDDC之间创建站点对、请登录到内部vCenter Server并访问新的HCX vSphere Web Client插件。</block>
  <block id="f4f57342a1f5bfd667f7d19048c4aa85" category="inline-image-macro">HCX vSphere Web Client插件的屏幕截图。</block>
  <block id="1ecb33e8c47a03470ff03bb6c09a1d87" category="paragraph"><block ref="1ecb33e8c47a03470ff03bb6c09a1d87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302ca8cbe91eb456c9defb6fe514b81e" category="list-text">在基础架构下、单击*添加站点配对*。</block>
  <block id="cd6182a85ca09ca99bda2787165407d9" category="admonition">输入Azure VMware解决方案 HCX Cloud Manager URL或IP地址以及CloudAdmin角色访问私有云的凭据。</block>
  <block id="407d1d705e5bdedf2e1c5e9257c0c1ef" category="inline-image-macro">CloudAdmin角色的URL或IP地址和凭据屏幕截图。</block>
  <block id="6e861dfeca468a35e2aa6f6a42b2ad5f" category="paragraph"><block ref="6e861dfeca468a35e2aa6f6a42b2ad5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bccd838ddedeb361e65189136ac5c0f" category="list-text">单击 * 连接 * 。</block>
  <block id="7630a70e4d4511de5ac0f8ce18edd594" category="admonition">VMware HCX Connector必须能够通过端口443路由到HCX Cloud Manager IP。</block>
  <block id="ddea1cbf444f5d4e69d68b23eb0b4b59" category="list-text">创建配对后、新配置的站点配对将显示在HCX信息板上。</block>
  <block id="8cdce778f46399f121d65006767f466a" category="inline-image-macro">HCX信息板上已完成过程的屏幕截图。</block>
  <block id="a71387f99ef8fc06b56323de8e6a67e6" category="paragraph"><block ref="a71387f99ef8fc06b56323de8e6a67e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38bca9c1088c36da27f6910232836b09" category="example-title">第5步：配置网络配置文件、计算配置文件和服务网格</block>
  <block id="a030f25f2e21cc0db80d6a88646adb63" category="paragraph">VMware HCX互连服务设备可通过Internet以及与目标站点的专用连接提供复制和基于vMotion的迁移功能。互连可提供加密、流量工程和VM移动性。要创建互连服务设备、请完成以下步骤：</block>
  <block id="efb9332572aac00947298fc1ed65c0da" category="list-text">在基础架构下、选择*互连&gt;多站点服务网格&gt;计算配置文件&gt;创建计算配置文件*。</block>
  <block id="96e78a381f203820b7fb0d823994f764" category="admonition">计算配置文件定义了部署参数、包括部署的设备以及HCL服务可访问的VMware数据中心的哪个部分。</block>
  <block id="df03fa88f502c44f3476981d50c25ae4" category="inline-image-macro">vSphere客户端互连页面的屏幕截图。</block>
  <block id="0f7d2c9383c1f40641b39e9f65126dcf" category="paragraph"><block ref="0f7d2c9383c1f40641b39e9f65126dcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba9d884b8a48f110e052a2644f36c6bb" category="list-text">创建计算配置文件后、通过选择*多站点服务网格&gt;网络配置文件&gt;创建网络配置文件*来创建网络配置文件。</block>
  <block id="7e461f559c367396eca97f75c2262003" category="paragraph">网络配置文件定义了HCX用于其虚拟设备的IP地址和网络范围。</block>
  <block id="12618dff60108a0e440afb082e782c71" category="admonition">此步骤需要两个或更多IP地址。这些IP地址将从管理网络分配给互连设备。</block>
  <block id="9f137734809298c4fa85b07a7ddb6c5f" category="inline-image-macro">向vSphere客户端互连页面添加IP地址的屏幕截图。</block>
  <block id="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="paragraph"><block ref="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f78591a00b39059d077f422f8695286" category="list-text">此时、已成功创建计算和网络配置文件。</block>
  <block id="5e8122825414e5afe12c228e3afb9f77" category="list-text">在*互连*选项中选择*服务网格*选项卡以创建服务网格、然后选择内部和Azure SDDC站点。</block>
  <block id="efe6cc3fe15f7c67781cd956f1aa3b8e" category="list-text">服务网格用于指定本地和远程计算和网络配置文件对。</block>
  <block id="292b454f1874f04a4b6f9258b5f933e4" category="admonition">在此过程中、源站点和目标站点都会部署并自动配置HCX设备、以便创建安全的传输网络结构。</block>
  <block id="0433a192b31baf05b1deba1471c492ff" category="inline-image-macro">vSphere客户端互连页面上的服务网格选项卡的屏幕截图。</block>
  <block id="55551523a891564fc7b09d6dec2fe75f" category="paragraph"><block ref="55551523a891564fc7b09d6dec2fe75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9df03f8fa3fc5e40e9100c8ebbd3a2ad" category="list-text">这是配置的最后一步。完成部署大约需要30分钟。配置服务网格后、环境便已准备就绪、可以成功创建IPsec通道来迁移工作负载VM。</block>
  <block id="532b4e992bd2794e777d1c1320e94f98" category="inline-image-macro">vSphere Client互连页面上已完成过程的屏幕截图。</block>
  <block id="9158466ef9c7277d9287f86080b2c362" category="paragraph"><block ref="9158466ef9c7277d9287f86080b2c362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0e8a1058909962c26cdead8b3fab020" category="example-title">第6步：迁移工作负载</block>
  <block id="80ea378666ca268305d30933ca376035" category="paragraph">可以使用各种VMware HCX迁移技术在内部部署和Azure SDDC之间双向迁移工作负载。可以使用多种迁移技术将VM移入和移出VMware HCX激活的实体、例如HCX批量迁移、HCX vMotion、HCX冷迁移、HCX复制辅助vMotion (适用于HCX Enterprise版本)和HCX操作系统辅助迁移(适用于HCX Enterprise版本)。</block>
  <block id="94638809b72d557d4335dfce65f69e35" category="inline-link">VMware HCX迁移类型</block>
  <block id="aa52e427086548446f11ad8e43c6e998" category="paragraph">要了解有关各种HCX迁移机制的更多信息、请参见<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block>。</block>
  <block id="998d1ed8e82c8145e094c99bf11f8408" category="paragraph">*批量迁移*</block>
  <block id="15a3af99dcf6c8651b8f168e13625c61" category="paragraph">本节详细介绍了批量迁移机制。在批量迁移期间、HCX的批量迁移功能使用vSphere复制迁移磁盘文件、同时在目标vSphere HCX实例上重新创建VM。</block>
  <block id="181b4946601ef2026e3d3ca16145a722" category="paragraph">要启动批量VM迁移、请完成以下步骤：</block>
  <block id="76b01c506c1450a5b0ff6dccaeb0e9b7" category="list-text">访问*服务&gt;迁移*下的*迁移*选项卡。</block>
  <block id="bdfca72da9e5f7e7bfcd81aa9844aa45" category="inline-image-macro">vSphere客户端中的迁移部分的屏幕截图。</block>
  <block id="005bf2b00a4806639f3ea37ea4509f6b" category="paragraph"><block ref="005bf2b00a4806639f3ea37ea4509f6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc18384d5bbc3aa89ffea93d51abc451" category="list-text">在*远程站点连接*下、选择远程站点连接并选择源和目标。在此示例中、目标为Azure VMware解决方案 SDDC HCX端点。</block>
  <block id="251b1066293b131079328f5d09e33aca" category="list-text">单击*选择要迁移的虚拟机*。此操作将列出所有内部VM。根据match：value表达式选择VM、然后单击*添加*。</block>
  <block id="70dc92c7c0c3752e5757560b72fa8f04" category="list-text">在*传输和放置*部分中、更新必填字段(*集群*、*存储*、*目标*和*网络*)、包括迁移配置文件、然后单击*验证*。</block>
  <block id="009e0b54f8062ebadb85388889541f12" category="inline-image-macro">vSphere客户端的传输和放置部分的屏幕截图。</block>
  <block id="e5cde894c26fccdfef420936d570829b" category="paragraph"><block ref="e5cde894c26fccdfef420936d570829b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7599f8a3668b692ca7501152d4682c07" category="list-text">验证检查完成后、单击*执行*以启动迁移。</block>
  <block id="79af22f136dbfe3d3bf950a72f2c5f5b" category="inline-image-macro">启动迁移的屏幕截图。</block>
  <block id="c40f6796f391e80926e1a459f389859b" category="paragraph"><block ref="c40f6796f391e80926e1a459f389859b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c1969ef22141ce348651d2b0f4eb5dd8" category="admonition">在此迁移期间、会在目标vCenter中的指定Azure NetApp Files 数据存储库上创建一个占位磁盘、以便将源VM磁盘的数据复制到占位磁盘。系统会触发HBR以与目标完全同步、在基线完成后、将根据恢复点目标(RPO)周期执行增量同步。完整/增量同步完成后、除非设置了特定计划、否则会自动触发切换。</block>
  <block id="c0b39ee3609ffbaf676e9119dd912e9b" category="list-text">迁移完成后、通过访问目标SDDC vCenter来验证相同的。</block>
  <block id="5d882ffc756bfb07c0785abe30634c3c" category="paragraph"><block ref="5d882ffc756bfb07c0785abe30634c3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d785f8302edf28ffd50ba9bd9a1e3e5" category="paragraph">有关各种迁移选项以及如何使用HCX将工作负载从内部迁移到Azure VMware解决方案 的其他详细信息、请参见<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>。</block>
  <block id="128dd96b5323b02401db618a27f67394" category="paragraph">下面是HCX vMotion选项的屏幕截图。</block>
  <block id="d77e1c6edbcf98bc28017153ba737ae7" category="paragraph"><block ref="d77e1c6edbcf98bc28017153ba737ae7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="efb5f7e867e5fc98adcdcb1d219cdd4a" category="admonition">确保有足够的带宽来处理迁移。</block>
  <block id="6147587d84b933dcb429334a5e2594f9" category="admonition">目标ANF数据存储库应具有足够的空间来处理迁移。</block>
  <block id="d7372a0d2d0e1ec31f9e1d607d52e246" category="paragraph">无论您的目标是全云还是混合云、以及驻留在内部任何类型/供应商存储上的数据、Azure NetApp Files 和HCX都可以提供出色的选项来部署和迁移应用程序工作负载、同时通过将数据需求无缝地迁移到应用程序层来降低TCO。无论使用何种情形、都可以选择Azure VMware解决方案 和Azure NetApp Files 、以快速实现云优势、跨内部和多个云实现一致的基础架构和运营、工作负载的双向可移植性以及企业级容量和性能。使用VMware vSphere复制、VMware vMotion甚至网络文件复制(Network File Copy、NFCs)连接存储和迁移VM时、使用的过程与步骤相同。</block>
  <block id="7a7f4f94771d5c3f94a76599dcacb0cf" category="list-text">现在、您可以将Azure NetApp Files 用作Azure VMware解决方案 SDDC上的数据存储库。</block>
  <block id="44b43fa706a816b30490196d187959c4" category="list-text">您可以轻松地将数据从内部迁移到Azure NetApp Files 数据存储库。</block>
  <block id="bc6808bfb84f0a05f9640103114929fa" category="list-text">您可以轻松地扩展和缩减Azure NetApp Files 数据存储库、以满足迁移活动期间的容量和性能要求。</block>
  <block id="61af664797ae795435faba35dd141335" category="inline-link"><block ref="61af664797ae795435faba35dd141335" category="inline-link-rx"></block></block>
  <block id="ab19b6733f7a9500ff9d392433071ef2" category="paragraph"><block ref="ab19b6733f7a9500ff9d392433071ef2" category="inline-link-rx"></block></block>
  <block id="7c5ba33b986ba469d277c4ca9f906e55" category="inline-link-macro">使用VMware HCX将工作负载迁移到FSxN数据存储库</block>
  <block id="c037991d132128e15cdbfefe3ac8e997" category="list-text"><block ref="c037991d132128e15cdbfefe3ac8e997" category="inline-link-macro-rx"></block></block>
  <block id="086d898e7d4a481c2147d4eb71dff1f6" category="section-title">概述：迁移具有VMware HCX、FSX ONTAP 补充数据存储库和VMware Cloud的虚拟机</block>
  <block id="82778188ea3c0ca7871389afec5bfd03" category="paragraph">迁移VMware工作负载是Amazon Web Services (AWS)上的VMware Cloud (VMC)及其在Amazon FSx for NetApp ONTAP 上的补充NFS数据存储库的一个常见使用情形。VMware HCX是首选选项、它提供了多种迁移方法、用于将在任何VMware支持的数据存储库上运行的内部虚拟机(VM)及其数据移动到VMC数据存储库、其中包括适用于ONTAP 的FSX上的补充NFS数据存储库。</block>
  <block id="2fbfc2601ddccd56b7728df6f0a658e1" category="paragraph">VMware HCX主要是一个移动平台、旨在简化工作负载迁移、工作负载重新平衡以及跨云的业务连续性。它作为VMware Cloud on AWS的一部分提供、可通过多种方式迁移工作负载、并可用于灾难恢复(DR)操作。</block>
  <block id="aabc04eb6cd0b22670013ea8212b7a4f" category="paragraph">本文档提供了部署和配置VMware HCX的分步指导、其中包括其所有主要组件、内部部署和云数据中心端、从而支持各种VM迁移机制。</block>
  <block id="d493b7ce0e1cf6434fdce9bd4fa1c847" category="inline-link">HCX部署简介</block>
  <block id="274e6762dc6bf155637729306a74154b" category="inline-link">安装检查清单B—在AWS SDDC目标环境中使用VMware Cloud的HCX</block>
  <block id="1db2f90540d47d2fe14bfc6cad01537a" category="paragraph">有关详细信息，请参见<block ref="871067259283ae637dd3ddcf90a49e5d" category="inline-link-rx"></block> 和<block ref="b5449e907f27219538721e57c42a92c0" category="inline-link-rx"></block>。</block>
  <block id="18ad70c16d20c99de2753c4da7fb1291" category="paragraph">此列表概括介绍了安装和配置VMware HCX的步骤：</block>
  <block id="b9b7e6b65417eaac8eeb13d3f809942d" category="list-text">通过VMware Cloud Services Console为VMC软件定义的数据中心(SDDC)激活HCX。</block>
  <block id="76f775a9fe0b12df87ae0ad6b34efdd9" category="list-text">在内部vCenter Server中下载并部署HCX Connector OVA安装程序。</block>
  <block id="f970657dc986e56f66a60a02b1210c43" category="list-text">使用许可证密钥激活HCX。</block>
  <block id="2d7e8f746bd165e0f342b659b51cff2c" category="list-text">将内部部署的VMware HCX Connector与VMC HCX Cloud Manager配对。</block>
  <block id="a9f9ba84cb2c76d9b8033c6f9ad14642" category="list-text">(可选)执行网络扩展以扩展网络并避免重新IP。</block>
  <block id="f5633594a47ccbe1e89229d43cbce0ec" category="inline-link">准备安装HCX</block>
  <block id="ecdf05ad108113e6a7e36c14f4d8e596" category="paragraph">开始之前、请确保满足以下前提条件。有关详细信息，请参见<block ref="c59343d9a8c2798bf6815397e3f08bd3" category="inline-link-rx"></block>。具备连接等前提条件后、可从VMC的VMware HCX控制台生成许可证密钥来配置和激活HCX。激活HCX后、将部署vCenter插件、并可使用vCenter控制台进行访问以进行管理。</block>
  <block id="f0983a6fa9c97fbc87ff3ad43495e008" category="paragraph">在继续执行HCX激活和部署之前、必须完成以下安装步骤：</block>
  <block id="dba413fdbeffb35a4459e9d3f45be3bd" category="inline-link">VMware链接</block>
  <block id="67cff13cad47354f1f51ce3ef47c6ddc" category="list-text">从内部vCenter环境到VMC SDDC的网络路径必须支持使用vMotion迁移VM。</block>
  <block id="c9f9609ee5731fe3777e57937464dc54" category="list-text">确保满足所需<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> 允许用于内部vCenter Server与SDDC vCenter之间的vMotion流量。</block>
  <block id="915747189317f7496ecb2bcdc22e83b5" category="paragraph">出于测试目的、用于此验证的内部实验室环境通过站点到站点VPN连接到AWS VPC、从而可以通过外部传输网关在内部连接到AWS和VMware云SDDC。内部部署和VMware云目标SDDC之间的HCX迁移和网络扩展流量通过Internet传输。可以修改此架构以使用Direct Connect专用虚拟接口。</block>
  <block id="20c789c477f416c40ed37a0a96f352d5" category="paragraph">下图展示了高级架构。</block>
  <block id="9f4db1da9d84fe1111fd9ae7c377f786" category="paragraph"><block ref="9f4db1da9d84fe1111fd9ae7c377f786" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5189f076565998395f00538902b201d3" category="example-title">第1步：使用Add-ons选项通过VMC SDDC激活HCX</block>
  <block id="84d84827fbe9c4b33c9c3b806b314d3f" category="inline-link">vmc.vmware.com</block>
  <block id="db44791d0479a0d2c9f5549eac8850ad" category="list-text">登录到VMC控制台<block ref="98f8f917cb7f10ee415fb6ce242d9349" category="inline-link-rx"></block> 并访问清单。</block>
  <block id="049aac4163d4ee979d2ebd21434216a2" category="list-text">要选择适当的SDDC并访问附加项、请单击SDDC上的查看详细信息、然后选择添加项选项卡。</block>
  <block id="933c74bf858432dc81f521597cffbfbb" category="list-text">单击激活VMware HCX。</block>
  <block id="7335132a517aad5765c48773404c2687" category="admonition">完成此步骤最多需要25分钟。</block>
  <block id="be7b0f3d5e22843c4a2107342b36330b" category="paragraph"><block ref="be7b0f3d5e22843c4a2107342b36330b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcf3d539a908f48f7d82acf7470675f7" category="list-text">部署完成后、通过确认HCX Manager及其关联插件在vCenter Console中可用来验证部署。</block>
  <block id="8c0cff0c106bc3f5a4dd79c01c3de7a9" category="list-text">创建适当的管理网关防火墙、以打开访问HCX Cloud Manager所需的端口。HCX Cloud Manager现在已准备就绪、可以执行HCX操作。</block>
  <block id="6eac4c95d8f88bfb601f7b87770513ab" category="paragraph">要使内部连接器能够与VMC中的HCX Manager进行通信、请确保在内部环境中打开相应的防火墙端口。</block>
  <block id="185b9319145cb225cdb1256b494e0595" category="list-text">在VMC控制台中、导航到HCX信息板、转到管理、然后选择系统更新选项卡。单击"Request a Download Link"以获取HCX Connector OVA映像。</block>
  <block id="039b399de18508b9f1029358886fea99" category="list-text">下载HCX Connector后、在内部vCenter Server中部署OVA。右键单击vSphere集群并选择部署OVF模板选项。</block>
  <block id="bd18e96a29eec74967666d876a146937" category="paragraph"><block ref="bd18e96a29eec74967666d876a146937" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8df6b0257b180b48db7d56e06e4da54" category="list-text">在Deploy OVF Template向导中输入所需信息、单击Next、然后单击Finish以部署VMware HCX Connector OVA。</block>
  <block id="8925cbdefd949dca662858e368d4ccfb" category="list-text">手动启动虚拟设备。有关分步说明、请转至<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>。</block>
  <block id="fab9859fcf95f41f7bb654e91e6876b4" category="paragraph">在内部部署VMware HCX Connector OVA并启动设备后、请完成以下步骤以激活HCX Connector。从VMC上的VMware HCX控制台生成许可证密钥、并在设置VMware HCX Connector期间输入许可证。</block>
  <block id="fddda62632eb91015346909c9da3cf70" category="list-text">从VMware Cloud Console中、转到清单、选择SDDC、然后单击查看详细信息。在"Add Ons"选项卡的VMware HCX磁贴中、单击Open HCX。</block>
  <block id="51e51578490c90a69c673d41361b0070" category="list-text">从激活密钥选项卡中、单击创建激活密钥。选择System Type作为HCX Connector、然后单击Confirm以生成密钥。复制激活密钥。</block>
  <block id="e30847f53a6e375f1da81f871c44e963" category="paragraph"><block ref="e30847f53a6e375f1da81f871c44e963" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c410deb9d7b04917aff523f97f944894" category="admonition">部署在内部的每个HCX连接器都需要一个单独的密钥。</block>
  <block id="1111fa8f5187058abdce3daca03b7e32" category="inline-link"><block ref="1111fa8f5187058abdce3daca03b7e32" category="inline-link-rx"></block></block>
  <block id="d9432955aa7705a1f97c9e94c730fdc9" category="list-text">登录到内部部署的VMware HCX Connector、网址为<block ref="ece20a9f7dc6720cdeb30c7e7733cd22" category="inline-link-rx"></block> 使用管理员凭据。</block>
  <block id="f5f8371708aa6ae3ddb84d1f4d9b5d17" category="list-text">在许可部分中、输入从步骤2复制的激活密钥、然后单击激活。</block>
  <block id="404a7c7a7d73b870628663e76e974d09" category="admonition">要成功完成激活、内部HCX Connector必须能够访问Internet。</block>
  <block id="564ed09bba79e1d4262e37fc94987fbe" category="list-text">在数据中心位置下、提供在内部安装VMware HCX Manager所需的位置。单击 Continue （继续）。</block>
  <block id="61ce05ace76ff1424841e5e551873a97" category="list-text">在System Name下、更新此名称并单击Continue。</block>
  <block id="4bc852451f43c4b3df306f35e67e4178" category="list-text">选择是、然后继续。</block>
  <block id="7eefbebbdefe472b13ce5d0bce410737" category="list-text">在连接vCenter下、提供vCenter Server的IP地址或完全限定域名(FQDN)以及凭据、然后单击继续。</block>
  <block id="47a7ea3464363cf9baa528c91d3aa4dc" category="admonition">使用FQDN以避免稍后出现通信问题。</block>
  <block id="eb7e70dd1954a71454c2e6a0cb9ed5f8" category="list-text">在配置SSA/PSC下、提供平台服务控制器的FQDN或IP地址、然后单击继续。</block>
  <block id="1f2f2ed2ec24b1f1ab37799a6f27fa40" category="admonition">输入vCenter Server的IP地址或FQDN。</block>
  <block id="24b993e60859697b0875bc838cfe12aa" category="list-text">验证输入的信息是否正确、然后单击Restart。</block>
  <block id="b0fca3e3f2889bbec562577014fafd9a" category="list-text">完成后、vCenter Server将显示为绿色。vCenter Server和SSO都必须具有正确的配置参数、这些参数应与上一页相同。</block>
  <block id="8463d9f0fc95490bc0c65d3ba9063dea" category="admonition">此过程大约需要10–20分钟、并且要将此插件添加到vCenter Server中。</block>
  <block id="a56ac8f65b53b91dba588aafc428f8b2" category="paragraph"><block ref="a56ac8f65b53b91dba588aafc428f8b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65d6e263d26134bb05aeec17adc73a06" category="example-title">第4步：将内部VMware HCX Connector与VMC HCX Cloud Manager配对</block>
  <block id="f68b6001164eba9a9e765e551c59a3c1" category="list-text">要在内部vCenter Server和VMC SDDC之间创建站点对、请登录到内部vCenter Server并访问HCX vSphere Web Client插件。</block>
  <block id="10f9af0781b3c0a9d621bac0b8719365" category="paragraph"><block ref="10f9af0781b3c0a9d621bac0b8719365" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1af79e59a8d820cc101f77efa75cb01d" category="list-text">在基础架构下、单击添加站点配对。要对远程站点进行身份验证、请输入VMC HCX Cloud Manager URL或IP地址以及CloudAdmin角色的凭据。</block>
  <block id="1b49b2932a225dd49cc6f5298ad6cc8f" category="paragraph"><block ref="1b49b2932a225dd49cc6f5298ad6cc8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7c72a1b7e925abd687d2c7a4ac5a2f" category="admonition">可以从SDDC设置页面检索HCX信息。</block>
  <block id="1272226ee970b8e49c49d25af6f4b6b8" category="paragraph"><block ref="1272226ee970b8e49c49d25af6f4b6b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="838d70471e28171464ffd4fed8d9df3a" category="paragraph"><block ref="838d70471e28171464ffd4fed8d9df3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dbcfb2058c277401b0872487463fe313" category="list-text">要启动站点配对、请单击Connect。</block>
  <block id="2147cde45e80d7c6a5db679f7180eab4" category="admonition">VMware HCX Connector必须能够通过端口443与HCX Cloud Manager IP进行通信。</block>
  <block id="618a4f677a45dc2b53f7c464b5598c28" category="paragraph">VMware HCX互连(HCX-IX)设备可通过Internet提供安全通道功能、并可通过专用连接到目标站点、从而实现复制和基于vMotion的功能。互连可提供加密、流量工程和SD-WAN。要创建HCI-IX互连设备、请完成以下步骤：</block>
  <block id="f32fcca3303979d42a8f0be055fc36dd" category="list-text">在基础架构下、选择互连&gt;多站点服务网格&gt;计算配置文件&gt;创建计算配置文件。</block>
  <block id="46c0e6a1b2dbd6331bcea8e4726de843" category="admonition">计算配置文件包含部署互连虚拟设备所需的计算、存储和网络部署参数。它们还会指定HCX服务可访问VMware数据中心的哪个部分。</block>
  <block id="46a447d35c4917802c9d612dd8ede3b5" category="inline-link">创建计算配置文件</block>
  <block id="9fc475734bed02e370e17ea150a74fd3" category="paragraph">有关详细说明、请参见<block ref="3e2a71be9bcd47a34446e38d1b8f4987" category="inline-link-rx"></block>。</block>
  <block id="648388c6923f0b4fc45138b46fb56158" category="paragraph"><block ref="648388c6923f0b4fc45138b46fb56158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3c8534d57516f63a1f263c7e4a4c7a" category="list-text">创建计算配置文件后、通过选择多站点服务网格&gt;网络配置文件&gt;创建网络配置文件来创建网络配置文件。</block>
  <block id="52d18a4f9043fce9a1e9d57e92fc77a4" category="list-text">网络配置文件定义了一个IP地址和网络范围、HCX将使用这些地址和网络作为其虚拟设备。</block>
  <block id="2565e95c468130be3fbdbb45da6cadeb" category="admonition">这需要两个或更多IP地址。这些IP地址将从管理网络分配给虚拟设备。</block>
  <block id="f62f78e1c7b4b764032cbdad0c61a6d0" category="paragraph"><block ref="f62f78e1c7b4b764032cbdad0c61a6d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9fad750cff1511b959d686e3a0829f0" category="inline-link">创建网络配置文件</block>
  <block id="51cbf458571723275b781ce4b3fec323" category="paragraph">有关详细说明、请参见<block ref="fb1b37f7979e3209d40171b59e47f33b" category="inline-link-rx"></block>。</block>
  <block id="784e6023ad40986353535651f974e468" category="admonition">如果您要通过Internet连接到SD-WAN、则必须在"网络连接和安全"部分下预留公有 IP。</block>
  <block id="c1b5864550e5f67407a0efd2cbe55b67" category="list-text">要创建服务网格、请在互连选项中选择服务网格选项卡、然后选择内部和VMC SDDC站点。</block>
  <block id="295ecbce57290e03752d2e06d4575fff" category="paragraph">服务网格建立一个本地和远程计算和网络配置文件对。</block>
  <block id="1e21db3cc04207cfb46fd912cdfef571" category="paragraph"><block ref="1e21db3cc04207cfb46fd912cdfef571" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba94996b6f6f31ef7ea483dc8f0046c" category="admonition">此过程的一部分涉及部署将在源站点和目标站点上自动配置的HCX设备、从而创建安全的传输网络结构。</block>
  <block id="b7e93bb3e8f576437ca086d1702a7994" category="list-text">选择源和远程计算配置文件、然后单击Continue。</block>
  <block id="ef7ca07b9da6362e4aa341061333a66c" category="paragraph"><block ref="ef7ca07b9da6362e4aa341061333a66c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e42fcfe670e1a9e7a259fb3c9d3dad87" category="list-text">选择要激活的服务、然后单击Continue。</block>
  <block id="ff89555f65d5e42967fac9abcecb74c8" category="paragraph"><block ref="ff89555f65d5e42967fac9abcecb74c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8438ec331921e82a31eaa97deb5f8c0" category="admonition">复制辅助vMotion迁移、SRM集成和操作系统辅助迁移需要HCX Enterprise许可证。</block>
  <block id="9a44378d7dd14730acf075e18d7d8c29" category="list-text">为服务网格创建一个名称、然后单击完成以开始创建过程。完成部署大约需要30分钟。配置服务网格后、便创建了迁移工作负载VM所需的虚拟基础架构和网络。</block>
  <block id="725a12cf06f45e850e7588b816663c20" category="paragraph"><block ref="725a12cf06f45e850e7588b816663c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0de3992884fcc0e48531f19cce447e7" category="example-title">第6步：迁移工作负载</block>
  <block id="af65fc6bdee93e32363bfe5c2cf8ee3a" category="paragraph">HCX可在内部环境和VMC SDDC等两个或更多不同环境之间提供双向迁移服务。可以使用各种迁移技术将应用程序工作负载迁移到HCX激活的站点或从这些站点迁移到这些站点、例如HCX批量迁移、HCX vMotion、HCX冷迁移、HCX复制辅助vMotion (适用于HCX Enterprise版本)以及HCX操作系统辅助迁移(适用于HCX Enterprise版本)。</block>
  <block id="0afeac0ffbe358cc58864e34fc54c9b2" category="paragraph">要了解有关可用HCX迁移技术的更多信息、请参见<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block></block>
  <block id="97957dd6d4c5d792035241d68a97795e" category="paragraph">HCX-IX设备使用移动代理服务执行vMotion、冷迁移和复制辅助vMotion (RAV)迁移。</block>
  <block id="2234ed56b9cbb2a083fd5fe49a89bce1" category="admonition">HCX-IX设备会将移动代理服务添加为vCenter Server中的主机对象。此对象上显示的处理器、内存、存储和网络资源并不表示托管IX设备的物理虚拟机管理程序上的实际消耗量。</block>
  <block id="c3735752087d3a11c85329680057de55" category="paragraph"><block ref="c3735752087d3a11c85329680057de55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c14d0d24d8dccac2ac3ca3ddacf8ba8" category="example-title">VMware HCX vMotion</block>
  <block id="8f2dbd716f60bbee8012a3f0e361fc65" category="paragraph">本节介绍HCX vMotion机制。此迁移技术使用VMware vMotion协议将VM迁移到VMC SDDC。vMotion迁移选项用于一次迁移单个VM的VM状态。此迁移方法期间不会发生服务中断。</block>
  <block id="0c1394a246edcdcb98e3c5fe3cedabbb" category="admonition">应设置网络扩展(对于VM所连接的端口组)、以便在不更改IP地址的情况下迁移VM。</block>
  <block id="896f227a656a8b0f4a64aa3e12b2506e" category="list-text">从内部vSphere客户端中、转到清单、右键单击要迁移的虚拟机、然后选择HCX操作&gt;迁移到HCX目标站点。</block>
  <block id="d683c9596c42727fea13c654874f39be" category="paragraph"><block ref="d683c9596c42727fea13c654874f39be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4479366aca979ecb9be874cab7bc543" category="list-text">在迁移虚拟机向导中、选择远程站点连接(目标VMC SDDC)。</block>
  <block id="09ca4fea7b9ff384e38622ce7cc20a9c" category="paragraph"><block ref="09ca4fea7b9ff384e38622ce7cc20a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67358e55b470861e1e14c63c30156dd4" category="list-text">添加组名称、然后在传输和放置下更新必填字段(集群、存储和目标网络)、然后单击验证。</block>
  <block id="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="paragraph"><block ref="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a961199f9300128fcaa431e9245ac13" category="list-text">验证检查完成后、单击"Go"启动迁移。</block>
  <block id="f3d5cf5ffd51c9062748a6a292f749f7" category="inline-link">了解VMware HCX vMotion和冷迁移</block>
  <block id="136739244c82e4bdcdb6a1b1c3712d3b" category="admonition">vMotion传输会捕获VM活动内存、其执行状态、IP地址及其MAC地址。有关HCX vMotion的要求和限制的详细信息、请参见<block ref="011541f11351d17074bdfa0823ec743b" category="inline-link-rx"></block>。</block>
  <block id="f2ca81fdc3e7326c354dc180a98c7ef2" category="list-text">您可以从"HCX"&gt;"迁移"信息板监控vMotion的进度和完成情况。</block>
  <block id="b41362505f00e258d5e04636a0edaf7c" category="paragraph"><block ref="b41362505f00e258d5e04636a0edaf7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e4900648931ee918be9251a268e792c" category="example-title">VMware复制辅助vMotion</block>
  <block id="3bb995dd361711179fda278eb498a385" category="paragraph">正如您从VMware文档中可能注意到的那样、VMware HCX Replication Assised vMotion (RAV)结合了批量迁移和vMotion的优势。批量迁移使用vSphere Replication并行迁移多个VM—VM会在切换期间重新启动。HCX vMotion无需停机即可迁移、但它会在一个复制组中按顺序逐个虚拟机执行。RAV会并行复制虚拟机、并使其保持同步、直到切换窗口为止。在切换过程中、它一次迁移一个虚拟机、而不会造成虚拟机停机。</block>
  <block id="93e2f4753a86232a37f8bd57209f626d" category="paragraph">以下屏幕截图将迁移配置文件显示为复制辅助vMotion。</block>
  <block id="7c12abc7edfaeb45279b8ee126759269" category="paragraph"><block ref="7c12abc7edfaeb45279b8ee126759269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a740a2796b321475f6bd003fafa67e5b" category="paragraph">与少数虚拟机的vMotion相比、复制持续时间可能会更长。使用RAV时、请仅同步增量并包含内存内容。以下是迁移状态的屏幕截图—显示了每个虚拟机的迁移开始时间是如何相同的、结束时间是如何不同的。</block>
  <block id="27e8bd561ebb9d9ee4d23860c10a3883" category="paragraph"><block ref="27e8bd561ebb9d9ee4d23860c10a3883" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e61c2a41cf1924a0a1e3d5217e16a084" category="paragraph">有关追加信息 的HCX迁移选项以及如何使用HCX将工作负载从内部迁移到AWS上的VMware Cloud的信息、请参见<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>。</block>
  <block id="f261622b527cc27756d5ba83c22662f8" category="admonition">VMware HCX vMotion需要100 Mbps或更高的吞吐量功能。</block>
  <block id="60bd242580d7de82c0a2e6eee14d2f50" category="admonition">ONTAP 数据存储库的目标VMC FSx必须具有足够的空间来容纳迁移。</block>
  <block id="17e30673228b69814c7132c287c12ecb" category="paragraph">无论您是针对全云还是混合云、以及驻留在内部任何类型/供应商存储上的数据、Amazon FSx for NetApp ONTAP 以及HCX均可提供出色的选项来部署和迁移工作负载、同时通过将数据需求无缝迁移到应用程序层来降低TCO。无论使用何种情形、都可以选择VMC以及适用于ONTAP 数据存储库的FSx、以便快速实现云优势、一致的基础架构以及跨内部和多个云的操作、工作负载的双向可移植性以及企业级容量和性能。使用VMware vSphere复制、VMware vMotion甚至是NFCs副本连接存储和迁移VM所使用的过程与步骤相同。</block>
  <block id="273435500e4b837aea488094a233f579" category="list-text">现在、您可以使用Amazon FSX ONTAP 作为VMC SDDC的数据存储库。</block>
  <block id="cbbc4fc2bc12f5fd25f84b44f93fd5f3" category="list-text">您可以轻松地将数据从任何内部数据中心迁移到使用FSX for ONTAP 数据存储库运行的VMC</block>
  <block id="9004e09f6485129980daf3188affad35" category="list-text">您可以轻松地扩展和缩减FSX ONTAP 数据存储库、以满足迁移活动期间的容量和性能要求。</block>
  <block id="34e948a9d10cb991d2da187e3e54caef" category="list-text">VMware Cloud文档</block>
  <block id="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link"><block ref="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link-rx"></block></block>
  <block id="1427dee608f6801474787ea58df57a2c" category="paragraph"><block ref="1427dee608f6801474787ea58df57a2c" category="inline-link-rx"></block></block>
  <block id="cc788b7e72b2a734dd0985bd1e0e9fe3" category="list-text">Amazon FSX for NetApp ONTAP 文档</block>
  <block id="9c7174d13497f84bdd0b3e21af13794d" category="inline-link"><block ref="9c7174d13497f84bdd0b3e21af13794d" category="inline-link-rx"></block></block>
  <block id="05c89cf5b898c5c58986dac08f22a2a1" category="paragraph"><block ref="05c89cf5b898c5c58986dac08f22a2a1" category="inline-link-rx"></block></block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="6ff1dafebf930a9c5fef12bf43046987" category="example-title">企业级应用程序和数据库</block>
  <block id="4efd965058c15f138d2c4d43454c3012" category="list-text"><block ref="4efd965058c15f138d2c4d43454c3012" category="inline-link-macro-rx"></block></block>
  <block id="5bfc3700f5feddf9397449627edbbdb9" category="example-title">容器/Kubernetes</block>
  <block id="665b01682714e51e25b232a31a06b70e" category="inline-link-macro">NetApp与Google Anthos视频</block>
  <block id="668ed010c67826eb36328daf61db1909" category="inline-link-macro">NetApp与VMware Tanzu视频</block>
  <block id="19ec96fa965825479da361c5626b34f0" category="inline-link-macro">NetApp for DevOps视频</block>
  <block id="70fc473134508f4cbdb235049ab72bc6" category="inline-link-macro">NetApp与Red Hat OpenShift视频</block>
  <block id="f86f2e66a68f28ad563c787ff0145ba4" category="list-text"><block ref="f86f2e66a68f28ad563c787ff0145ba4" category="inline-link-macro-rx"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">本文档概述了使用分层存储基准测试套件的NetApp ONTAP 上的Confluent平台的性能基准测试。</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941：与NetApp ONTAP 存储控制器相结合</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam、Joe Scott、NetApp Rankesh Kumar、Confluent</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">NetApp ONTAP 数据管理软件集行业领先的创新技术于一身、无论数据位于何处、均可为Confluent提供诸多优势。</block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">此页面介绍了此解决方案 中使用的技术。</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">NetApp ONTAP 存储控制器</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP 是一款高性能企业级存储操作系统。</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8引入了对Amazon Simple Storage Service (S3) API的支持。ONTAP 支持部分Amazon Web Services (AWS) S3 API操作、并允许在云提供商(AWS、Azure和GCP)和内部环境中将数据表示为基于ONTAP的系统中的对象。</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">NetApp StorageGRID 软件是用于对象存储的旗舰级NetApp解决方案。ONTAP 通过在边缘提供载入和预处理点、扩展由NetApp提供支持的对象数据数据数据网络结构以及提高NetApp产品组合的价值、对StorageGRID 进行了补充。</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">可以通过授权的用户和客户端应用程序访问S3存储分段。下图显示了访问S3存储分段的应用程序。</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">此图显示了访问S3存储分段的应用程序。</block>
  <block id="6090835a60a6e1de5e0c995ca8c5e5f8" category="paragraph"><block ref="6090835a60a6e1de5e0c995ca8c5e5f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">主要用例</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">支持S3 API的主要目的是在ONTAP 上提供对象访问。ONTAP 统一存储架构现在支持文件(NFS和SMB)、块(FC和iSCSI)和对象(S3)。</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">原生 S3应用程序</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">越来越多的应用程序能够使用S3利用ONTAP 支持对象访问。虽然非常适合高容量归档工作负载、但原生 S3应用程序对高性能的需求正在快速增长、其中包括：</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">分析</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">人工智能</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">边缘到核心载入</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">现在、客户可以使用熟悉的易管理性工具(如ONTAP System Manager)快速配置高性能对象存储、以便在ONTAP 中进行开发和操作、同时充分利用ONTAP 的存储效率和安全性。</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">FabricPool 端点</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">从ONTAP 9.8开始、FabricPool 支持在ONTAP 中分层到分段、从而可以进行ONTAP到ONTAP分层。对于希望将现有FAS 基础架构重新用作对象存储端点的客户来说、这是一个绝佳的选择。</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool 支持通过两种方式分层到ONTAP ：</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*本地集群分层。*使用集群LIF将非活动数据分层到位于本地集群上的存储分段。</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*远程集群分层。*非活动数据将采用与传统FabricPool 云层类似的方式分层到远程集群上的存储分层、方法是在FabricPool 客户端上使用IC LIF和在ONTAP 对象存储上使用数据LIF。</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">如果您需要在现有集群上使用 S3 功能，而无需额外的硬件和管理，则 ONTAP S3 是合适的。对于300 TB以上的部署、NetApp StorageGRID 软件仍然是NetApp对象存储的旗舰级解决方案。使用ONTAP 或StorageGRID 作为云层时、不需要FabricPool 许可证。</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">适用于Confluent分层存储的NetApp ONTAP</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">每个数据中心都需要保持业务关键型应用程序持续运行、并确保重要数据的可用性和安全性。全新的NetApp AFF A900系统采用ONTAP 企业版软件和高弹性设计。我们全新的快如闪电的NVMe存储系统可消除任务关键型运营中断、最大限度地降低性能调整、并保护您的数据免受勒索软件攻击。</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">从初始部署到扩展Confluent集群、您的环境需要快速适应不会对业务关键型应用程序造成中断的变化。ONTAP 企业级数据管理、服务质量(Quality of Service、QoS)和性能支持您规划和适应您的环境。</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">将NetApp ONTAP 和Confluent分层存储结合使用、可将ONTAP 用作横向扩展存储目标、从而简化Apache Kafka集群的管理、并可为Confluent独立扩展计算和存储资源。</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">ONTAP S3服务器基于ONTAP 成熟的横向扩展存储功能构建。通过扩展S3存储分段、将新添加的节点添加到ONTAP 集群、可以无缝扩展ONTAP 集群。</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">使用ONTAP System Manager进行简单管理</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">ONTAP System Manager是一个基于浏览器的图形界面、可用于在一个管理平台中跨全球分布位置配置、管理和监控ONTAP 存储控制器。</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">此图显示了ONTAP System Manager工作空间。</block>
  <block id="45e8e67e3e5407c5dc518dd00eb8249b" category="paragraph"><block ref="45e8e67e3e5407c5dc518dd00eb8249b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">您可以使用System Manager和ONTAP 命令行界面配置和管理ONTAP S3。当您启用S3并使用System Manager创建存储分段时、ONTAP 会为简化的配置提供最佳实践默认值。如果您从CLI配置S3服务器和存储分段、则仍可根据需要使用System Manager对其进行管理、反之亦然。</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">使用 System Manager 创建 S3 存储分段时， ONTAP 会配置系统上可用性最高的默认性能服务级别。例如、在AFF 系统上、默认设置为"Extreme"。性能服务级别是预定义的自适应QoS策略组。您可以指定自定义 QoS 策略组，也可以不指定策略组，而不指定默认服务级别之一。</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">预定义的自适应QoS策略组包括以下内容：</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*至尊*。*用于需要最低延迟和最高性能的应用程序。</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*性能。*用于性能需求和延迟适中的应用程序。</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*值*。用于吞吐量和容量比延迟更重要的应用程序。</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*自定义。*指定自定义QoS策略或不指定QoS策略。</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">如果选择 * 用于分层 * ，则不会选择任何性能服务级别，系统会尝试为分层数据选择具有最佳性能的低成本介质。</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP 会尝试在磁盘最合适的本地层上配置此存储分段，以满足所选的服务级别。但是，如果需要指定要包含在存储分段中的磁盘，请考虑通过指定本地层（聚合）从 CLI 配置 S3 对象存储。如果您通过 CLI 配置 S3 服务器，则仍可根据需要使用 System Manager 对其进行管理。</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">如果您希望能够指定用于存储分段的聚合，则只能使用命令行界面来执行此操作。</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confuent Platform 是一个全面的数据流平台，可让您轻松地以持续的实时流的形式访问，存储和管理数据。Confluent 由 Apache Kafka 的原始创建者构建，通过企业级功能扩展了 Kafka 的优势，同时消除了 Kafka 的管理或监控负担。如今、《财富》100强企业中有80%以上的企业采用数据流技术、大多数企业都使用Confluent。</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">借助整合平台，您可以专注于如何从数据中获得业务价值，而不是担心底层机制，例如如何在不同系统之间传输或集成数据。具体而言， Confluent Platform 可简化将数据源连接到 Kafka 的过程，构建流式应用程序，以及保护，监控和管理 Kafka 基础架构。如今、Consfluent Platform已广泛用于各行各业的各种用例、从金融服务、全渠道零售和自动驾驶汽车到欺诈检测、微服务和物联网。</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">下图显示了Confluent Platform的组件。</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">此图显示了Confluent Platform的组件。</block>
  <block id="f64c3e5205853c0df35b5f05dcb208a1" category="paragraph"><block ref="f64c3e5205853c0df35b5f05dcb208a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Confluent事件流技术概述</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">Kafka</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">Confluent Platform 的核心是<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block>最受欢迎的开源分布式流式平台。Kafka的主要功能包括：</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Confluent平台企业功能概述</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*流畅控制中心*。一种基于UI的系统、用于管理和监控Kafka。您可以通过它轻松管理 Kafka Connect ，以及创建，编辑和管理与其他系统的连接。</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">*卡夫卡连接连接器。*连接器使用Kafka Connect API将Kafka连接到数据库、密钥值存储、搜索索引和文件系统等其他系统。Confluent Hub 提供可下载的连接器，用于最常用的数据源和数据池，包括这些连接器经过全面测试且受支持的版本以及 Confluent 平台。有关更多详细信息，请参见<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>。</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">* 自平衡集群。 * 提供自动化负载平衡，故障检测和自我修复功能。它还支持根据需要添加或停用代理、而无需手动调整。</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*流畅自动数据平衡器。*监控集群中的代理数量、分区大小、分区数量和导数。它允许您在集群中移动数据以创建均匀的工作负载，同时限制重新平衡流量，以便在重新平衡的同时最大限度地减少对生产工作负载的影响。</block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">在使用一个AFF A900 HA对NetApp存储控制器的生产用工作负载期间、我们使用五个或八个代理节点执行分层存储测试。根据我们的测试结果、完成时间和性能结果会随着代理节点的数量进行扩展、直到AFF A900资源利用率达到百分之一百为止。ONTAP 存储控制器设置至少需要一个HA对。</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">使用生产用工作负载生成器进行性能测试</block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">根据Confluent代理节点的数量、S3检索操作的性能呈线性增长。ONTAP 存储控制器在一个部署中最多支持12个HA对。</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">下图显示了具有五个或八个代理节点的S3分层流量组合。我们最大限度地提高了AFF A900单HA对的性能。</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">此数据图显示了具有五个或八个代理节点的S3分层流量组合。</block>
  <block id="388c51cbcac77b72c2e68dc334f9cf73" category="paragraph"><block ref="388c51cbcac77b72c2e68dc334f9cf73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">下图显示了Kafka吞吐量约为31.74 GBps。</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">此数据图显示了Kafka吞吐量约为31.74 GBps。</block>
  <block id="1dc39288e0903ff9947d26bba4d46cef" category="paragraph"><block ref="1dc39288e0903ff9947d26bba4d46cef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">我们还在ONTAP 存储控制器`perfstat`报告中观察到类似的吞吐量。</block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">此验证测试在使用NetApp ONTAP 存储控制器的Confluent上达到了31.74 GBps的分层吞吐量。</block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">此验证测试在使用NetApp ONTAP 存储控制器的Confluent上达到了31.74 GBps的分层吞吐量。</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">什么是Confluent？</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">ONTAP 最佳实践中的S3</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">S3对象存储管理</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">此页面介绍了在此解决方案 中提高性能的最佳实践。</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">性能最佳实践准则</block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">对于ONTAP 、如果可能、请使用GET大小&gt;=1MB。</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">通过在代理节点上的`server.properties`中增加`num.network.threads`和`num.io.threads`、您可以将更多的分层活动推送到S3层。这些结果会在`num.network.threads`和`num.io.threads`设置为32的情况下显示。</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">S3存储分段应针对每个成员聚合的八个成分卷。</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">驱动S3流量的以太网链路应尽可能在存储和客户端上使用9k的MTU。</block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">此页面介绍了在该解决方案 的参数范围内验证Confluent的性能。</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">融合性能验证</block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">我们已使用Confluent Platform对NetApp ONTAP 上的分层存储执行了验证。NetApp和Confluent团队共同执行了此验证、并运行了所需的测试用例。</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">设置冲突</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">在设置中、我们使用了三个Zookepers、五个代理和五个测试服务器、这些服务器具有256 GB RAM和16个CPU。对于NetApp存储、我们将ONTAP 与AFF A900 HA对结合使用。存储和代理通过100GbE连接进行连接。</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">下图显示了用于分层存储验证的配置的网络拓扑。</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">此图显示了用于分层存储验证的配置的网络拓扑。</block>
  <block id="e1265b0a6795e57b3d1df5094ecde2bb" category="paragraph"><block ref="e1265b0a6795e57b3d1df5094ecde2bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">工具服务器充当向Confluent节点发送或从Confluent节点接收事件的应用程序客户端。</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">我们使用了以下测试参数：</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">为了进行验证、我们将ONTAP 与HTTP协议结合使用、但HTTPS也可以正常工作。访问密钥和机密密钥存储在 `confuent.tier.s3.cred.file.path` 参数中提供的文件名中。</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">NetApp存储控制器—ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">我们在ONTAP 中配置了一个HA对配置以进行验证。</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">此图展示了如何将环境配置为一个HA对以进行验证。</block>
  <block id="0ccd17060e15591b9c8588dc7d974ecd" category="paragraph"><block ref="0ccd17060e15591b9c8588dc7d974ecd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">验证结果</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">我们已完成以下五个测试案例以进行验证。前两项是功能测试，其余三项是性能测试。</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">此测试使用API调用对用于分层存储的对象存储执行基本操作、例如GET、PUT和DELETE。</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">此测试将检查对象存储的端到端功能。它会创建一个主题，为新创建的主题生成一个事件流，等待代理将这些分段归档到对象存储，使用事件流，并验证已用流与已生成流的匹配情况。我们执行此测试时，无论是否注入了对象存储故障。我们通过在ONTAP 中的一个节点中停止服务管理器服务并验证端到端功能是否适用于对象存储来模拟节点故障。</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">生成并使用工作负载生成器</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">此测试会通过归档区块间接在对象存储上生成写入工作负载。读取工作负载（区块读取）是在使用者组提取区块时从对象存储生成的。此工作负载由TOCC脚本生成。此测试检查了并行线程中对象存储上的读写性能。与分层功能正确性测试一样，我们测试了是否存在对象存储故障注入。</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">保留工作负载生成器</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">此测试检查了在主题保留工作负载繁重的情况下对象存储的删除性能。保留工作负载是使用TOCC脚本生成的、该脚本会与测试主题并行生成许多消息。本测试主题使用主动式基于大小和基于时间的保留设置进行配置，此设置会导致从对象存储中持续清除事件流。然后，这些区块会归档。这导致代理在对象存储中删除了许多内容、并收集了对象存储删除操作的性能。</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">有关验证详细信息、请参见<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> 网站。</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">本节介绍在使用NetApp ONTAP 进行分层存储的Confluent Platform部署中用于性能验证的硬件和软件。下表介绍了解决方案 架构和基本组件。</block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">由ONTAP 提供支持的Confuent和NetApp AFF A900存储控制器是专为数据流设计的分布式系统。两者均可水平扩展、容错、并在负载下提供出色的性能。它们通过数据精简技术在分布式数据流和流处理方面相辅相成、并可降低存储成本、从而最大限度地减少数据占用空间。AFF A900存储控制器可提供出色的性能、同时允许分离计算和数据存储资源。这样可以简化系统管理并独立扩展资源。</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">解决方案 概述图。</block>
  <block id="52dff9f6353660d69eddc1e9fdee4a83" category="paragraph"><block ref="52dff9f6353660d69eddc1e9fdee4a83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">平台组件</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">环境配置</block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Confuent Platform 6.2版</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">3个Zookepers</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8个代理服务器</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5个工具服务器</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1个Grafana</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1个控制中心</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">所有节点上的操作系统</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">适用于温分段的NetApp ONTAP</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1个AFF A900高可用性(HA)对</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2个CPU；总共16个物理核心</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">Intel Xeon</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256 GB物理内存</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">100GbE双端口</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">Kafka与NetApp ONTAP 存储控制器相结合</block>
  <block id="93d153de96abb104b1cf0b56dddc7dfc" category="sidebar">使用VMware HCX将工作负载迁移到ANF数据存储库</block>
  <block id="9e925e9341b490bfd3b4c4ca3b0c1ef2" category="inline-link">这</block>
  <block id="b95b607ac94c4a8cb830243ecb537f59" category="cell">定义LDAP使用的会话安全级别(签名、签章或无)。如果Active Directory请求、CVS-Performance支持LDAP签名。CVS-SW不支持LDAP签名。对于这两种服务类型、目前不支持密封。</block>
  <block id="ce32836b59e052d959dee4d2358e5a21" category="paragraph">出于测试目的、用于此验证的内部实验室环境通过站点到站点VPN进行连接、从而可以在内部连接到Azure VMware解决方案。</block>
  <block id="0bcfdba2f090838df9da44d825fedc49" category="doc">TR 4942：使用VMware HCX将工作负载迁移到FSX ONTAP 数据存储库</block>
  <block id="dd5244d49dea74bb9effd68426155ca2" category="sidebar">使用VMware HCX将工作负载迁移到适用于ONTAP 数据存储库的FSX</block>
  <block id="c53dba1ad099d932b01eacd82bd500f2" category="doc">NVA-1155：《基于FlexPod 数据中心且采用Cisco UCS和基于FC的NetApp AFF A800的Oracle 19c RAC数据库—设计和部署指南》</block>
  <block id="547673676a9fdbc79f1364e749be4d0a" category="paragraph">NetApp公司Allen Cao</block>
  <block id="6e170e4c0b9eb50546a09aafc90dc157" category="doc">TR-4794：《基于NetApp EF系列的Oracle数据库》</block>
  <block id="9b6fc59469e9f5ee36cb85b08daacec3" category="paragraph">NetApp公司Ebin Kadavy的Mitch Blackburn</block>
  <block id="fa8b4902d0c1e464dcf9256a434920ba" category="paragraph">TR-4794旨在帮助存储管理员和数据库管理员在NetApp EF系列存储上成功部署Oracle。</block>
  <block id="611a4a6b98272a717f8e1f6bf5ba787b" category="paragraph">NetApp 公司 Marco Schoen</block>
  <block id="dbd408dfbba42c9529974244acc200aa" category="paragraph">TR-4467为客户和合作伙伴提供了部署集群模式NetApp Data ONTAP 以支持在Windows环境中的Microsoft SQL Server中运行SAP业务套件解决方案的最佳实践。</block>
  <block id="69015d285622bbd074d7bccf4ea12670" category="paragraph">在内部或云端优化运营并释放数据的潜能。</block>
  <block id="d9cd8ac988f5ea26e28a2da5f3485ff9" category="paragraph">NetApp公司Pat Sithusan Mitch Blackburn</block>
  <block id="9db08b91ae68a77b71af230b40b31325" category="paragraph">本最佳实践指南旨在帮助存储管理员和数据库管理员在NetApp EF系列存储上成功部署Microsoft SQL Server。</block>
  <block id="d5b9082efbf726d2e38c5042668ae4f0" category="doc">TR-4250：SAP与基于UNIX的Oracle和NFS以及适用于SAP 3.4的NetApp集群模式Data ONTAP 和SnapManager</block>
  <block id="bb8cd3f7aec777de29cee988f4ade068" category="paragraph">NetApp 公司 Nil Bauser</block>
  <block id="ea455e11718ea0bfb200c540f4e0c038" category="paragraph">TR-4250解决了设计存储解决方案以使用Oracle数据库支持SAP业务套件产品所面临的挑战。本文档的主要重点是使用最新一代 SAP 解决方案的业务和 IT 主管面临的常见存储基础架构设计，部署，操作和管理挑战。本文档中的建议是通用的；它们并不特定于 SAP 应用程序或 SAP 实施的规模和范围。TR-4250假定读者已基本了解NetApp和SAP产品的技术和操作。TR-4250是在NetApp、SAP、Oracle和我们的客户的技术人员互动的基础上开发的。</block>
  <block id="be52c99c6345cb49ab79a79b9565c737" category="doc">TR-4785：使用NetApp E系列和BeeGFS进行AI部署</block>
  <block id="36f4667e440709d475f1c5db4ecae97e" category="paragraph">Nagalakshmi Raju、Daniel Landes、Nathan Swartz、NetApp公司Amind本纳尼</block>
  <block id="c74f37bd5e8951b2feda7d19b03326e9" category="paragraph">人工智能(AI)、机器学习(ML)和深度学习(DL)应用程序涉及大型数据集和高计算。要成功运行这些工作负载、您需要一个灵活的基础架构、使您能够无缝地横向扩展存储和计算节点。本报告介绍了在分布式模式下运行AI训练模型的步骤、该模式允许无缝横向扩展计算和存储节点。该报告还包括各种性能指标、用于显示将NetApp E系列存储与BeeGFS并行文件系统相结合的解决方案 如何为AI工作负载提供灵活、经济高效且简单的解决方案。</block>
  <block id="4472645bc6fe350406624df126edf4ac" category="paragraph">NetApp公司的公司包括：Abdel Satek、Tim Chau、Joe McCormick和David Arnette</block>
  <block id="7d8f094cc030aec75a343f1baad8c19d" category="paragraph">本文档介绍了经过NetApp验证的机器学习(ML)和人工智能(AI)工作负载架构、这些架构使用NetApp EF600 NVMe存储系统、ThinkParQ BeeGFS并行文件系统、NVIDIA DGX A100系统和NVIDIA Mellanox Quantum QM8700 200 Gbps InfiniBand (IB)交换机。本文档还介绍了如何在部署完成后执行验证基准测试。</block>
  <block id="7bfbd6c5c294b7f81d430bd31f53aea3" category="paragraph">NVA-1153-design介绍了经过NetApp验证的机器学习(ML)和人工智能(AI)工作负载架构、该架构使用NetApp AFF A800存储系统、NVIDIA DGX A100系统和NVIDIA Mellanox Spectrum SN3700V 200 Gb以太网交换机。此设计采用基于融合以太网的RDMA (RoCE)作为计算集群互连网络结构、可为客户提供完全基于以太网的架构来处理高性能工作负载。本文档还包括所实施架构的基准测试结果。</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">NetApp公司David Arnette</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851展示了NetApp StorageGRID 对象存储是机器学习(ML)和深度学习(DL)软件开发的数据存储库和管理系统。本白皮书介绍了自动驾驶汽车软件开发的数据流和要求、以及简化数据生命周期的StorageGRID 功能。此 解决方案 适用场景 是ML和DL开发流程中典型的任何多阶段数据管道工作流。</block>
  <block id="290beddb4a567cd98ba4f9116eee11b4" category="paragraph">NVA-1151-deploy包括使用NetApp AFF A800存储系统、NVIDIA DGX A100系统和NVIDIA Mellanox网络交换机的适用于机器学习(ML)和人工智能(AI)工作负载的NetApp验证架构(NVA)的存储系统部署说明。此外、还提供了部署完成后运行验证基准测试的说明。</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">NetApp公司Ryan Rodine</block>
  <block id="3e22ed7172d7770cfa1457b7e70b2b06" category="doc">TR-4915：利用E系列和BeeGFS移动数据、实现人工智能和分析工作流</block>
  <block id="b85127cc663f1e3f1a6a366bb2732406" category="paragraph">NetApp公司Cody Harryman和Ryan Rodine</block>
  <block id="ff50db1ba0f8ba4a103a810e1ceb2afc" category="paragraph">NetApp公司的公司包括：NetApp公司的Abdel Satek、Tim Chau、Joe McCormick和David Arnette</block>
  <block id="1d78c2c26f50714898cd986ca8147756" category="paragraph">NVA-1156-design介绍了经过NetApp验证的机器学习(ML)和人工智能(AI)工作负载架构、该架构使用NetApp EF600 NVMe存储系统、BeeGFS并行文件系统、NVIDIA DGX A100系统和NVIDIA Mellanox Quantum QM8700 200 Gbps IB交换机。此设计采用200 Gbps InfiniBand (IB)作为存储和计算集群互连网络结构、为客户提供完全基于IB的架构来处理高性能工作负载。本文档还包括所实施架构的基准测试结果。</block>
  <block id="eae34d8ef755492887b6a7aa4362588d" category="paragraph">Rick Huang、Sung-Han Lin、Sathish Thyagarajan、NetApp JAcci Cenci、NVIDIA</block>
  <block id="c92ae00fd88c8477c24628d0f17deceb" category="paragraph">此参考架构可为使用NVIDIA DGX-2系统和NetApp AFF 存储构建人工智能(AI)基础架构以满足医疗保健用例的客户提供指导。其中包括有关在为医学诊断成像、经验证的测试案例和结果开发深度学习(DL)模型时所使用的高级工作流的信息。它还包括针对客户部署的规模估算建议。</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">本文档详细介绍了如何使用NetApp E系列存储系统设计StorNext并行文件系统解决方案。此解决方案 涵盖NetApp EF280全闪存阵列、NetApp EF300全闪存NVMe阵列、EF600全闪存NVMe阵列和NetApp E5760混合系统。它基于Frametest基准测试提供性能特征化、该工具广泛用于媒体和娱乐行业的测试。</block>
  <block id="a8b8bcca1cc81c47655f69efaea66280" category="paragraph">Karthikeyan Nagalingam、Sung-Han Lin、NetApp JAcci Cenci、NVIDIA</block>
  <block id="5e01fc0ba3a2133ea5de509bf81e119d" category="paragraph">此参考架构为使用NVIDIA DGX-1系统和NetApp AFF 存储构建人工智能基础架构以满足金融部门使用情形的客户提供了准则。其中包括有关在为金融服务测试案例和结果开发深度学习模型时所使用的高级工作流的信息。它还包括针对客户部署的规模估算建议。</block>
  <block id="5f2ab39ba2f8133927b3b4608a712d5b" category="paragraph">NetApp公司Fujitsu Takashhi Oishs的David Arnette</block>
  <block id="62c32325e658b728843c4f250b5d1547" category="paragraph">此解决方案 侧重于横向扩展架构、以便在NetApp存储系统和Fujitsu服务器上部署人工智能系统。解决方案 已通过使用Fujitsu GX2570服务器和NetApp AFF A800存储系统的MLperf v0.6型号培训基准测试的验证。</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">NetApp公司Chris Seirer</block>
  <block id="fdb4fdcbeafc3d334651614437516062" category="paragraph">TR-4859介绍了基于IBM的Spectrum Scale软件堆栈部署完整并行文件系统解决方案 的过程。TR-4859旨在提供有关如何安装Spectrum Scale、验证基础架构以及管理配置的详细信息。</block>
  <block id="5f4c1dd940d24299c2c5a80211b1e330" category="paragraph">NVA-1153-Deploy提供了适用于使用NetApp AFF A800存储系统、NVIDIA DGX A100系统和NVIDIA Mellanox Spectrum SN3700V 200 GB以太网交换机的经过NetApp验证的机器学习(ML)和人工智能(AI)工作负载架构的存储系统部署说明。此外、还提供了部署完成后执行验证基准测试的说明。</block>
  <block id="23b69f42a62554346d10d302e32866df" category="paragraph">NetApp Girish Chanchlani的Akash Gupta、Commvault</block>
  <block id="451f1cdad20049e4046b157a54826db1" category="paragraph">TR-4320概述了在Commvault Data Platform V11环境中使用NetApp E系列存储时的参考架构和最佳实践。Commvault和NetApp联合开发了此参考架构、为使用NetApp E系列存储的Commvault数据平台V11部署提供了指导、可加快应用此解决方案 的速度。</block>
  <block id="d223d0d947999082ea93b57a68b3614b" category="paragraph">NetApp的Akash Gupta和Principed Technologies</block>
  <block id="9c993f8d3d3aa7be9c86474635154c12" category="paragraph">TR-4704介绍了如何在NetApp E系列存储上部署Veritas NetBackup。</block>
  <block id="febdd047851001456a2f0c683cfcfd2b" category="paragraph">NetApp Shawn Lieu (美洲)、Stefan Renner (欧洲、中东和非洲)和Veeam Michael Cade (性能)</block>
  <block id="2de6bbd06654b0c6d7bd5a6f2bb218f8" category="paragraph">NetApp公司Abhinav Singh Arvind Ramakrishnan</block>
  <block id="6fdf0a62913845390e552b0f7d42cbf7" category="paragraph">NVA-1143介绍了如何设计和部署NetApp HCI 以满足国家标准和技术协会(NIST) SP 800-53修订版4的安全和隐私控制要求、这些控制对于私有云基础架构和多租户部署至关重要。</block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623：NetApp E系列E5700和Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">NetApp公司Mitch Blackburn</block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">现代数据分析—适用于不同分析策略的不同解决方案</block>
  <block id="8e1e8679efe4694874eb9820dff26af8" category="paragraph">本白皮书介绍了NetApp的现代数据分析解决方案 战略。其中包括有关业务成果、客户挑战、技术趋势、竞争传统架构、现代工作流、用例、行业、云、技术合作伙伴、数据移动者、NetApp Active IQ 、NetApp DataOps工具包、Hadoop to Spark、采用NetApp Astra Control的软件定义存储、容器、企业数据管理、归档和分层、以实现AI和分析的目标、以及NetApp和客户如何携手打造现代化的数据架构。</block>
  <block id="9b6f25534617a536120885c9ce2bf30b" category="inline-link">有关安装操作步骤 的信息、请参见Veeam文档</block>
  <block id="51c7ff4d9c3185f2df469eed762010d5" category="inline-link-macro">VMware云技术区</block>
  <block id="baab3b6c6024ccda908423e27d1a7d5b" category="admonition">VMware也提供了此解决方案。请访问 <block ref="e4f8fde8ba3579a04642cf870e6e362f" category="inline-link-macro-rx"></block> 有关详细信息 ...</block>
  <block id="dc32da64b7845bbbf4827a1513cd8daa" category="inline-link-macro">使用VMware HCX在AWS SDDC上使用适用于NetApp ONTAP 的FSX和VMware Cloud配置混合云</block>
  <block id="e51f186f2c7dd10d7f4c1196ab269d7c" category="list-text"><block ref="e51f186f2c7dd10d7f4c1196ab269d7c" category="inline-link-macro-rx"></block></block>
  <block id="3cf6cddd26350e6a84e8bef869102647" category="cell">2022年10月25日</block>
  <block id="2937ec3775c4b0354bf359a5892c53f7" category="cell">添加了有关使用VMware HCX在AWS SDDC上使用FSX ONTAP 和VMC配置混合云的博客参考</block>
  <block id="0676783b7d49061bfb23deb83b2d2f82" category="paragraph">*配置并启动作业模板。*</block>
  <block id="544348a8f04b16faced725115db5b6f3" category="section-title">为您的环境创建清单、组、主机和凭据</block>
  <block id="be86ca474df5e14056bc0f20d2cdb767" category="section-title">创建项目</block>
  <block id="d02a79fb6f05358e16f9d9cf02288ac3" category="section-title">配置全局变量</block>
  <block id="3506caa5fe966a4676faac2993bc1431" category="section-title">自动化攻略手册</block>
  <block id="ba985cf3c812e3ba064fedc7353bbb77" category="section-title">恢复Oracle数据库</block>
  <block id="fb467c38c5af2ca41ea3f09fe535144d" category="list-text">* RO/RW访问规则。*选择读/写或只读以控制对导出的访问级别。cvs-Performance提供了以下选项：</block>
  <block id="b42b7de139bf4398a5d4b048ecf30c9f" category="paragraph">此外、Cloud Volumes Service 还提供了扩展的组支持、可将支持的最大组数扩展到32个。这需要通过LDAP连接到包含有效UNIX用户和组身份的LDAP服务器。有关配置此的详细信息、请参见<block ref="744e76592290230cb7381c9b8a5414da" category="inline-link-rx"></block> 在Google文档中。</block>
  <block id="73867c3747b10f9f7b4b54a4597ff38b" category="paragraph">IAM为Cloud Volumes Service 提供内置的粒度权限。您可以找到<block ref="fefbe49b0be12af5b957eff3a3dc2826" category="inline-link-rx"></block>。</block>
  <block id="00aa2e143f3d3b00e94456b23d239a8d" category="paragraph">请参见<block ref="5d862676de2107050ea35e71368d2326" category="inline-link-rx"></block> 有关详细信息、请参见Google云文档。</block>
  <block id="4a0d70491e56eae6b1e0743d9c3a3777" category="paragraph">Cloud Volumes Service API使用基于REST的API、并使用HTTPS (TLSv1.2)作为底层网络传输。您可以找到最新的API定义<block ref="d30245d84ac801bb5beeb0b65de1621d" category="inline-link-rx"></block> 以及有关如何使用API的信息、请参见<block ref="00c944b7c7739b905457d5d21be6a7ef" category="inline-link-rx"></block>。</block>
  <block id="f84137720cfd9533352746a01677a6b2" category="paragraph">Cloud Volumes Service 采用与其他Google Cloud原生 服务类似的方式、例如CloudSQL、Google Cloud VMware引擎(GCVE)和文件存储库<block ref="0f93a99b9e468a051182b66dabbf3bed" category="inline-link-rx"></block> 交付服务。在PSA中、服务构建在服务生产者项目中、该项目使用<block ref="2d8d4488e7ed7b53a7aafab379ba8587" category="inline-link-rx"></block> 以连接到服务使用者。服务生产者由NetApp提供和运营、服务使用者是客户项目中的VPC、负责托管要访问Cloud Volumes Service 文件共享的客户端。</block>
  <block id="9448d83a67980a22f2db155347fa277c" category="paragraph">下图、引用自<block ref="6a8b5039754626811ee5b8fe5289e273" category="inline-link-rx"></block> 显示了Cloud Volumes Service 文档的概要视图。</block>
  <block id="a436da0007911ed6531e093688e82535" category="paragraph">使用共享VPC时、使用NFS Kerberos和/或进行动态加密 <block ref="639817e82862065dd236f0597e0b07ea" category="inline-link-macro-rx"></block> 可以屏蔽从跟踪中获取的大部分信息。但是、某些流量仍以纯文本形式发送、例如 <block ref="c2e2f225386e22bd13a8b4b174f478da" category="inline-link-macro-rx"></block> 和 <block ref="86c1c13023c15e9d9a6317a0b69e7ce3" category="inline-link-macro-rx"></block>。下图显示了从Cloud Volumes Service 发起的纯文本LDAP查询中捕获的数据包以及公开的潜在标识信息。Cloud Volumes Service 中的LDAP查询当前不支持加密或基于SSL的LDAP。如果Active Directory请求、CVS-Performance支持LDAP签名。CVS-SW不支持LDAP签名。</block>
  <block id="75956b9ee748b806549eeec3c9a81192" category="inline-link"><block ref="75956b9ee748b806549eeec3c9a81192" category="inline-link-rx"></block></block>
  <block id="6c84917a571a2282fd9fb2a6f058a11e" category="paragraph"><block ref="6c84917a571a2282fd9fb2a6f058a11e" category="inline-link-rx"></block></block>
  <block id="5bcf8cb715ebf788ba3e70915f4256c2" category="paragraph">请记住、每个区域仅允许一个Active Directory连接。</block>
  <block id="00d6cadb7a586713782bbffe59d5bc21" category="paragraph">Cloud Volumes Service 通过在不同端点之间分段服务管理(控制平面)和数据访问(数据平面)、在Google Cloud中提供一个安全的架构、这样两者都不会影响另一端(请参见一节) <block ref="d861c2ffd2960acc200167f08fd40005" category="inline-link-macro-rx"></block>）。它使用Google<block ref="1ac65cff0d913f26dd36736caeefd5b7" category="inline-link-rx"></block> (PSA)提供服务的框架。此框架区分由NetApp提供和运营的服务生产者和客户项目中托管要访问Cloud Volumes Service 文件共享的客户端的虚拟私有云(Virtual Private Cloud、VPC)服务使用者。</block>
  <block id="1e21a0f8a8012a10d3db8d473ba52502" category="paragraph">使用LDAP和Kerberos时、您应确定这些服务正在使用的网络端口。您可以在中找到Cloud Volumes Service 正在使用的端口的完整列表<block ref="0dc8f2243f86f97f7b6af9378a496f93" category="inline-link-rx"></block>。</block>
  <block id="811bec2d7b00d479640fbf3259346fe6" category="paragraph">有关为KMS配置CVS-Performance的信息、请参见<block ref="a0d8b07d63b271255da3bba6f51651a4" category="inline-link-rx"></block>。</block>
  <block id="c56328227fc3affbe6ed0ef4ba04f494" category="list-text"><block ref="c56328227fc3affbe6ed0ef4ba04f494" category="inline-link-rx"></block></block>
  <block id="c6563340810489dd712f25c2644eaed8" category="list-text"><block ref="c6563340810489dd712f25c2644eaed8" category="inline-link-rx"></block></block>
  <block id="150a343c955aa3114dca2e9c39571ad8" category="paragraph">此外、SMB、包含Kerberos的LDAP NFS以及双协议配置都需要访问Windows Active Directory域。Active Directory连接必须为<block ref="10ec0b3d8ec2c3b73be0dd7483e61c9e" category="inline-link-rx"></block> 按区域计算。Active Directory域控制器(DC)通过使用进行标识<block ref="821541d595f9fee8c67d91aa5da861b4" category="inline-link-rx"></block> 使用指定的DNS服务器。将使用返回的任何DC。可以通过指定Active Directory站点来限制符合条件的域控制器列表。</block>
  <block id="7a9b1188e66f0581af9bc76ec3099a55" category="paragraph">Cloud Volumes Service 会通过分配给的CIDR范围内的IP地址进行访问<block ref="3102e8199e828cb030b6f0ade5fc2cec" prefix=" " category="inline-code"></block> 命令<block ref="e8e0c669039859d9678de67879e03e1d" category="inline-link-rx"></block>。您可以使用此CIDR作为源地址来为Active Directory域控制器配置入站防火墙。</block>
  <block id="60bb23c83a123fdd2c99980eb34c8f80" category="paragraph">Active Directory域控制器必须<block ref="7b35a292c67c7ee0f89d3dd389e188e4" category="inline-link-rx"></block>。</block>
  <block id="fd313eaaaadfe56df9ec88896284165d" category="paragraph">有关如何为KMS配置CVS-Performance的详细信息、<block ref="905a3b34ffbfe930acdbf23dd47d698f" category="inline-link-rx"></block>。</block>
  <block id="9fd9d0ecc58c5d26f4934bc140ac2a41" category="list-text">CVS-Performance可跨区域卷复制到其他CVS-Performance卷。有关详细信息，请参见<block ref="ec408a29560fd662bec08bf50f9ff3d6" category="inline-link-rx"></block> 在Cloud Volumes Service 文档中。</block>
  <block id="6a7870f99b17bbb49636a1e7be9d4be1" category="list-text">CVS-SW提供服务本机卷备份/还原功能。有关详细信息，请参见<block ref="2377dc7e4548195ed704b70f3ce6250c" category="inline-link-rx"></block> 在Cloud Volumes Service 文档中。</block>
  <block id="344c8cea0d31ef9e8c7c56863c714a04" category="paragraph">此外、您还可以通过在Google Cloud中进行跨区域复制(CRR)管理来防止恶意管理操作、例如卷删除、Snapshot删除或Snapshot计划更改。这是通过创建自定义角色来实现的、这些角色会将卷管理员分隔开、这些管理员可以删除源卷、但不会中断镜像、因此无法从无法执行任何卷操作的CRR管理员中删除目标卷。请参见<block ref="bf2a9ccb864ad3a1fa1ddc1fec02a961" category="inline-link-rx"></block> 在Cloud Volumes Service 文档中、了解每个管理员组允许的权限。</block>
  <block id="99144970696c7e366271871a0e83b6cd" category="paragraph">出于所有这些原因、NetApp Cloud Volumes Service 均通过提供备份服务<block ref="253601e5d476a508040b734cbc7b3164" category="inline-link-rx"></block>。</block>
  <block id="57e8b261ab803839f73416e368f552bc" category="paragraph">Cloud Volumes Service 备份内置在Cloud Volumes Service 中作为选项。用户可以通过激活每个卷的Cloud Volumes Service 备份来确定要保护的卷。请参见<block ref="218d9dd384a48541f627c5084c286ade" category="inline-link-rx"></block> 有关备份的信息、请参见<block ref="d724a11e2928bd8489b8ad8fe1eac94b" category="inline-link-rx"></block>、计划和<block ref="31e05107512c82ef17df4f5c4b3fe0bd" category="inline-link-rx"></block>。</block>
  <block id="de8a90c8653195ed30cc4920de8c7921" category="paragraph">要管理Cloud Volumes Service 备份(创建、删除和还原备份)、用户必须具有<block ref="595f329bf934dbc7996bb735e9664896" category="inline-link-rx"></block> 角色。</block>
  <block id="6640e7cef3ca860543c49a5125ba4c5a" category="list-text">对于文件数量较多的工作负载、性能优于使用NFSv4.x时的krb5p。</block>
  <block id="11eb332ab75184a78c40c9174e16f520" category="paragraph-title">NetApp 和 VMware ：携手合作更好</block>
  <block id="58eaebf972358f1cf03d386a4ade1a0f" category="section-title">下一步是什么？</block>
  <block id="3603e14740d8edd319e72186341cb0af" category="cell">2022年6月12日</block>
  <block id="48461fa824ae344e0934144c7523c3f6" category="cell">添加了7个视频、用于在混合云中使用Amazon FSX存储实现Oracle数据库现代化</block>
  <block id="954a2b08ded0ca2c881930f5ebeee24a" category="example-title">人工智能(AI)和现代数据分析</block>
  <block id="369b9aec1beb25441dc7c7fb46bc0fc6" category="video-title">第2a部分—使用具有最大可用性的自动PDB重新定位将数据库从内部迁移到AWS</block>
  <block id="2edb94ef9695015c5cd01fec59bcc782" category="video-title">第2b部分—使用BlueXP控制台通过SnapMirror将数据库从内部迁移到AWS</block>
  <block id="59fa2b2110d3350efd262bd841c10975" category="video-title">第3部分—自动化数据库HA/DR复制设置、故障转移、重新同步</block>
  <block id="938d46c61cee67ddb1711167aba9f463" category="video-title">第4a部分—从复制的备用副本中使用SnapCenter UI进行开发/测试的数据库克隆</block>
  <block id="09b285fbf39efff75f085bbadedde45e" category="video-title">第4b部分—使用SnapCenter UI备份、还原和克隆数据库</block>
  <block id="45885d9d91879afc9c37a8b3e046aac4" category="video-title">第4c部分—数据库备份、使用BlueXP SaaS应用程序进行还原的备份和恢复</block>
  <block id="fe86efdcec6e779b5ef15f62d8f2bc90" category="paragraph-title">用于在AWS上部署NetApp CVO (单节点实例)的Terraform配置文件</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="paragraph-title">操作步骤</block>
  <block id="4e91e39d32f2399e7c90059f4eea5684" category="paragraph-title">收件人：</block>
  <block id="93726ca0be25ac3bef0f54da1e20751c" category="paragraph-title">用于在AWS上部署NetApp CVO (HA对)的Terraform配置文件</block>
  <block id="99661bfb937ca0c49c78878d8d2b0e77" category="paragraph-title">用于在AWS上部署NetApp ONTAP FSX的Terraform配置文件</block>
  <block id="1538b268d8f3b010dea63370c1a65935" category="paragraph-title">秘诀：</block>
  <block id="107933ea485144e916f16cd69884fea6" category="paragraph-title">用于在Azure上部署ANF卷的Terraform配置文件</block>
  <block id="c2d6144ea47815bb9e1c4e09c0918486" category="paragraph-title">用于在Azure上部署具有数据保护功能的ANF卷的Terraform配置文件</block>
  <block id="1ed1215fce9948e3bee78c99bf12de8d" category="paragraph-title">用于在Azure上使用双协议部署ANF卷的Terraform配置文件</block>
  <block id="15b915279743f1a43ce2c0f10062e69e" category="paragraph-title">用于从Azure上的Snapshot部署ANF卷的Terraform配置文件</block>
  <block id="664b1f8a02a683b16bb76004afb03be2" category="paragraph-title">用于在Azure上部署单节点CVO的Terraform配置文件</block>
  <block id="f06bfa867f111b72b9e71b8a75d661da" category="paragraph-title">用于在Azure上部署CVO HA的Terraform配置文件</block>
  <block id="e10db5a03ff1c5409d1b9ef0cf32ae11" category="paragraph-title">用于在GCP上部署NetApp CVO (单节点实例)的Terraform配置文件</block>
  <block id="1e95e8962dbf55d78e03e8da38f9f408" category="paragraph-title">用于在GCP上部署NetApp CVO (HA对)的Terraform配置文件</block>
  <block id="f39b5c8ffff4c5fccbc9ca01bf3bacf8" category="paragraph-title">用于在GCP上部署NetApp CVS卷的Terraform配置文件</block>
  <block id="934282d2b6cc731f63bcc3cdfbba32a1" category="paragraph">根据部署场景、需要部署的Veeam备份服务器、备份存储库和备份代理。在此使用情形下、无需为Veeam部署对象存储、也不需要横向扩展存储库。<block ref="3798d8f6f1f14581181abe3a5ef34dc1" category="inline-link-rx"></block></block>
  <block id="a94f1b9cbc89a005a38096b1750f907f" category="cell">2022年12月15日</block>
  <block id="754451201969a73231c286ef8f4b2fd6" category="cell">添加了TR-4923：《使用适用于NetApp ONTAP 的Amazon FSX在AWS EC2上运行SQL Server》</block>
  <block id="f53cfd73e0994740413d578c9dd6b36e" category="doc">TR-4923：使用适用于NetApp ONTAP 的Amazon FSX在AWS EC2上运行SQL Server</block>
  <block id="9aeea85747c176482897f26600d172d0" category="paragraph">作者：NetApp公司Pat Sithusan和Niyaz Mohamed</block>
  <block id="8bd093418d226733e085e856bd9165c8" category="paragraph">许多希望将应用程序从内部迁移到云的公司发现、内部存储系统和云存储服务提供的功能差异阻碍了这项工作。这一差距使迁移Microsoft SQL Server等企业级应用程序的问题变得更加严重。特别是、运行企业级应用程序所需的服务存在差距、例如强大的快照、存储效率功能、高可用性、可靠性和一致的性能、迫使客户在设计上做出取舍或放弃应用程序迁移。借助适用于NetApp ONTAP 的FSX、客户不再需要做出让步。适用于NetApp ONTAP 的FSX是由AWS销售、支持、计费和全面管理的本机(第一方) AWS服务。它利用NetApp ONTAP 的强大功能提供与NetApp 30年来在AWS中作为托管服务在内部提供的企业级存储和数据管理功能相同的功能。</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="inline-link">AWS FSX ONTAP</block>
  <block id="a2f7f68476a76b6aa359589e4d201707" category="paragraph">使用EC2实例上的SQL Server、数据库管理员可以访问和自定义其数据库环境和底层操作系统。EC2实例上的SQL Server与结合使用<block ref="3f737fd84a60fb425fdcdb5cf9a593da" category="inline-link-rx"></block> 要存储数据库文件、可以使用块级复制实现高性能、数据管理以及简单易用的迁移路径。因此、您可以在AWS VPC上运行复杂的数据库、只需简单的迁移方法、减少单击次数、无需转换架构即可。</block>
  <block id="cf79d59896c29cc7579cf75220c25c95" category="section-title">将适用于NetApp ONTAP 的Amazon FSx与SQL Server结合使用的优势</block>
  <block id="8908df00453997edbfc759829ecdf0d8" category="paragraph">适用于NetApp ONTAP 的Amazon FSX是AWS中SQL Server部署的理想文件存储。优势包括：</block>
  <block id="7b699f0e1a60e419ed7d9173339aa3f5" category="list-text">稳定一致的高性能和吞吐量以及低延迟</block>
  <block id="8a34b0f2109dd0aad0c0c9976717cdd3" category="list-text">采用NVMe缓存的智能缓存可提高性能</block>
  <block id="b10e27f9d68e001b8aa9369c8d308a8c" category="list-text">灵活的规模估算、可以随时增加或缩减容量、吞吐量和IOPS</block>
  <block id="169fee7c17564fc51aa8d2e77bcc1ce0" category="list-text">高效的内部到AWS块复制</block>
  <block id="fd140f04c5bc5f51aff3ea5e1619abaf" category="list-text">使用iSCSI、这是数据库环境中众所周知的协议</block>
  <block id="e2c00a563e0219fd93fa6f24606dee33" category="list-text">精简配置和零占用空间克隆等存储效率功能</block>
  <block id="4ac0316f1ba409d5cd9684222f9f8ada" category="list-text">备份时间从数小时缩短到数分钟、从而减少RTO</block>
  <block id="e3168d8a4383357a37460afad2f8878d" category="list-text">使用直观的NetApp SnapCenter UI对SQL数据库进行粒度备份和恢复</block>
  <block id="935da11069e36e124602b7e23a73ee06" category="list-text">能够在实际迁移之前执行多个测试迁移</block>
  <block id="15173984ed0ff615a3f0d55c8cd12291" category="list-text">通过文件级或I/O级副本缩短迁移期间的停机时间并克服迁移挑战</block>
  <block id="0de5f8d5cf18757efac074c02f16a0bb" category="list-text">在主要版本或修补程序更新后查找根发生原因 以减少MTTR</block>
  <block id="1a8e2e4ef765d6c61c4652659fb151ac" category="paragraph">在使用iSCSI协议的FSX ONTAP 上部署SQL Server数据库(通常在内部使用)可提供一个理想的数据库存储环境、该环境具有卓越的性能、存储效率和数据管理功能。如果使用多个iSCSI会话(假设工作集大小为5%)、则适合Flash Cache的FSX ONTAP 服务可提供超过100、000个IOPS。此配置可全面控制要求最苛刻的应用程序的性能。在连接到FSX for ONTAP 的较小EC2实例上运行的SQL Server可以与在较大的EC2实例上运行的SQL Server执行相同的操作、因为对于ONTAP 、只会应用网络带宽限制。减小实例大小还可以降低计算成本、从而实现TCO优化部署。SQL与iSCSI、SMB3.0以及FSX for ONTAP 上的多通道持续可用性共享相结合、为SQL工作负载提供了巨大的优势。</block>
  <block id="135b308ed83c53f1516b7c754566d1c4" category="section-title">开始之前</block>
  <block id="365a329d23604298414064b1bd2dba2f" category="paragraph">通过将适用于NetApp ONTAP 的Amazon FSx与EC2实例上的SQL Server相结合、可以创建企业级数据库存储设计、以满足当今最苛刻的应用程序要求。要优化这两种技术、了解SQL Server I/O模式和特征至关重要。SQL Server数据库的存储布局设计合理、可支持SQL Server的性能以及SQL Server基础架构的管理。良好的存储布局还可以使初始部署取得成功、并随着业务的增长使环境能够随时间平稳增长。</block>
  <block id="800d285a5a8ca10451f7ace50ac40de5" category="paragraph">在完成本文档中的步骤之前、您应具备以下前提条件：</block>
  <block id="69a7abd5a400936f0e1a89910dfa0ba1" category="list-text">AWS帐户</block>
  <block id="bfa061c0e7fe048c571ab15bc8d211a4" category="list-text">为ONTAP 配置EC2和FSX的相应IAM角色</block>
  <block id="a76b04166db341ceee35b584673698e9" category="list-text">EC2上的Windows Active Directory域</block>
  <block id="3084927119ae63d45676d527dfb4a882" category="list-text">所有SQL Server节点都必须能够彼此通信</block>
  <block id="b1ada0ca0559fff335d482de393b4c70" category="list-text">确保DNS解析有效且主机名可以解析。如果不是、请使用主机文件条目。</block>
  <block id="8413178222467ef68eb68a0644f11c42" category="list-text">SQL Server安装的一般知识</block>
  <block id="9c69c1668eca3541f0576cdc7fc730f0" category="paragraph">此外、要确保存储配置最佳、请参见NetApp针对SQL Server环境的最佳实践。</block>
  <block id="49c805233b94175c188c58ebf681a2b9" category="example-title">为EC2上的SQL Server环境配置最佳实践</block>
  <block id="d1d9da06ca1cde6106fef737b522df6e" category="paragraph">使用FSX ONTAP 、采购存储是最简单的任务、可通过更新文件系统来执行。这种简单的过程可以根据需要动态优化成本和性能、有助于平衡SQL工作负载、同时也是精简配置的有力推动因素。FSX ONTAP 精简配置旨在为运行SQL Server的EC2实例提供比文件系统中配置的更多逻辑存储。写入数据时、存储空间会动态分配给每个卷或LUN、而不是预先分配空间。在大多数配置中、当卷或LUN中的数据被删除(并且未被任何Snapshot副本保留)时、可用空间也会释放回。下表提供了用于动态分配存储的配置设置。</block>
  <block id="db1bfba30dab4f1ed4a13cc586837f1b" category="cell">无(默认设置)</block>
  <block id="f6445fd89b0b2c67f0304765c4c9a760" category="cell">LUN预留</block>
  <block id="f1e0735081bab920eff76b08a4600c76" category="cell">fractional_reserve</block>
  <block id="856ee920f3261cadbc1c3fc52171d071" category="cell">0%(默认设置)</block>
  <block id="99c0f62171e34b4ab6a79265f038e3af" category="cell">snap_reserve</block>
  <block id="7c68df7d17c446f99304ee1dc1498bfc" category="cell">自动调整大小</block>
  <block id="521c36a31c2762741cf0f8890cbe05e3" category="cell">开启</block>
  <block id="43c4c1dbc452be91829f25ee32c2a956" category="cell">卷分层策略</block>
  <block id="6d576caa9862f6db0177dfaff7abb095" category="cell">仅Snapshot</block>
  <block id="e08a486f204620eff1a08fc926316c68" category="paragraph">使用此配置时、卷的总大小可以大于文件系统中的实际可用存储。如果LUN或Snapshot副本所需的空间超过卷中的可用空间、则卷会自动增长、从而从包含的文件系统中占用更多空间。通过自动增长、FSX ONTAP 可以自动将卷大小增加到您预先确定的最大大小。包含的文件系统中必须有可用空间、才能支持卷的自动增长。因此、在启用自动增长的情况下、您应监控包含文件系统的可用空间、并在需要时更新文件系统。</block>
  <block id="82373a2016779f9c20fdc0d8b48101a7" category="inline-link">空间分配</block>
  <block id="0126eb1acda2ac795726d8bc5fe76a98" category="paragraph">同时、设置<block ref="9d6ca3a9a42127525354c85d54adc465" category="inline-link-rx"></block> 选项on lun to enabled、以便在卷空间用尽且卷中的LUN无法接受写入时、FSX ONTAP 向EC2主机发出通知。此外、通过此选项、当EC2主机上的SQL Server删除数据时、适用于ONTAP 的FSX可以自动回收空间。默认情况下、space-allocation选项设置为disabled。</block>
  <block id="afa7be61df3527a5c4b5b7369729dfbc" category="admonition">如果在无保证的卷中创建了空间预留LUN、则该LUN的行为与非空间预留LUN相同。这是因为无保证的卷没有可分配给LUN的空间；由于无保证、卷本身只能在写入时分配空间。</block>
  <block id="cf18df2432b44bda18f67ef6fc93e36f" category="paragraph">使用此配置时、FSX ONTAP 管理员通常可以对卷进行大小调整、以便他们必须管理和监控主机端和文件系统上LUN中的已用空间。</block>
  <block id="3e5fc395bc0727ee4a5d50bf7852e11e" category="admonition">NetApp建议对SQL Server工作负载使用单独的文件系统。如果文件系统用于多个应用程序、请监控文件系统和文件系统中卷的空间使用情况、以确保卷不会争用可用空间。</block>
  <block id="9bc03cfd47c7deb1375b7e700fba9c1a" category="admonition">自动删除选项不会删除用于创建FlexClone卷的Snapshot副本。</block>
  <block id="20292bb9591bce95b16e6ee1415023d3" category="admonition">对于任务关键型应用程序(例如SQL Server)、必须仔细考虑和管理过量使用存储的情况、即使发生极少的中断也无法容忍。在这种情况下、最好监控存储消耗趋势、以确定可以接受的过量使用量(如果有)。</block>
  <block id="e2ec94309dce197f199c6e60cd3070eb" category="list-text">使用精简配置时、需要进行适当的监控并制定有效的操作计划、以避免应用程序停机。</block>
  <block id="d7fbab8fe0fe681c9e815507bcdf85c8" category="list-text">请务必设置CloudWatch和其他监控工具警报、以便在存储填满时有足够的时间与用户联系以做出响应。</block>
  <block id="626a89ea253e84625436538e7249e94d" category="section-title">为SQL Server配置存储并为备份、还原和克隆操作部署SnapCenter</block>
  <block id="0a1c2236044192334a3fb3bbc0ab0dcd" category="paragraph">要使用SnapCenter 执行SQL Server操作、必须先为SQL Server创建卷和LUN。</block>
  <block id="0cf06bf086c162ff9027bab7f6f36c93" category="example-title">为SQL Server创建卷和LUN</block>
  <block id="ff6ef44023084895f5f22aaf568ee0e3" category="paragraph">要为SQL Server创建卷和LUN、请完成以下步骤：</block>
  <block id="0165fcfd32879eacf541aadf086338d2" category="list-text">打开Amazon FSX控制台、网址为<block ref="977f5adc4374191d0e48b9c0a8830158" category="inline-link-rx"></block></block>
  <block id="1e33ad7579c798ce6033c144ac99b840" category="list-text">使用创建方法下的标准创建选项为NetApp ONTAP 文件系统创建Amazon FSX。这样、您可以定义FSxadmin和vsadmin凭据。</block>
  <block id="a83755c47ff9159637d0666c65d8c544" category="paragraph"><block ref="a83755c47ff9159637d0666c65d8c544" category="inline-image-macro-rx" type="image"></block></block>
  <block id="269452df07db5e5d5fb10125ef2dfc42" category="list-text">指定fsxadmin的密码。</block>
  <block id="0939c7e9185662b3e54503cb12415c7a" category="paragraph"><block ref="0939c7e9185662b3e54503cb12415c7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dea5db34596930d023317e03284777e1" category="list-text">指定SVM的密码。</block>
  <block id="d2b251088e201058dd19119478e04523" category="paragraph"><block ref="d2b251088e201058dd19119478e04523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5a504f8d9fd87dc54c0f8a370eed579" category="inline-link">在适用于NetApp ONTAP 的FSX上创建卷</block>
  <block id="d0ff5f8be38ac60d217f9c007a52da0e" category="list-text">按照中列出的步骤创建卷<block ref="1146addad8000a8f0f70de9ea1e5f637" category="inline-link-rx"></block>。</block>
  <block id="17288ccd1a2a55fccc24e084bec74a89" category="list-text">禁用存储 Snapshot 副本计划和保留策略。而是使用NetApp SnapCenter 来协调SQL Server数据和日志卷的Snapshot副本。</block>
  <block id="c5023b4b04bc0ddc3d77e81fee7d99bb" category="list-text">在不同卷上的各个LUN上配置数据库、以利用快速、精细的还原功能。</block>
  <block id="6cb174042332f6d15cedab79c1f88bac" category="list-text">将用户数据文件(.mdf)放在不同的卷上、因为它们是随机读/写工作负载。通常、创建事务日志备份的频率比创建数据库备份的频率更高。因此、请将事务日志文件(.ldf)与数据文件放在一个单独的卷上、以便为每个文件创建独立的备份计划。这种分离还会将日志文件的顺序写入I/O与数据文件的随机读/写I/O隔离开来、并显著提高SQL Server性能。</block>
  <block id="0588cef8958d83f61aed452f853f5852" category="list-text">tempdb是Microsoft SQL Server使用的一个系统数据库、用作临时工作空间、尤其是用于I/O密集型DBCC CHECKDB操作。因此、请将此数据库放在专用卷上。在卷数量是一项挑战的大型环境中、您可以在仔细规划后将tempdb整合到较少的卷中、并将其与其他系统数据库存储在同一个卷中。tempdb的数据保护不是一个高优先级、因为每次重新启动Microsoft SQL Server时都会重新创建此数据库。</block>
  <block id="0f33b537ada1b2dcb95880741120d7b6" category="list-text">使用以下SSH命令创建卷：</block>
  <block id="4272c7e0323a62da36a59d8db2457c11" category="list-text">在Windows Server中使用提升的权限使用PowerShell启动iSCSI服务。</block>
  <block id="91d0d079f1c5a2183c1012cd2c2e59ab" category="list-text">在Windows Server中使用提升的权限使用PowerShell安装Multipath-IO。</block>
  <block id="4dee8d84e86540a5c4c302b3d75c32bc" category="list-text">在Windows Server中使用提升的权限查找具有PowerShell的Windows启动程序名称。</block>
  <block id="13aca4cbeddb191f6e28fc3dc5b50aca" category="paragraph"><block ref="13aca4cbeddb191f6e28fc3dc5b50aca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1fcce0650c7bce1532fc57b6af299dba" category="list-text">使用putty连接到Storage Virtual Machine (SVM)并创建iGroup。</block>
  <block id="a260444f9f7265e7da0cffa861246e93" category="list-text">使用以下SSH命令创建LUN：</block>
  <block id="0bf39861d87235a7c094d3de2e3a8840" category="paragraph"><block ref="0bf39861d87235a7c094d3de2e3a8840" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f5ef787d84b4ec1b5183cffdef5b56" category="list-text">要使用操作系统分区方案实现I/O对齐、请使用windows_2008作为建议的LUN类型。请参见<block ref="ff5fd3b71f5cd8b1a4e2fe23ad6d92ae" category="inline-link-rx"></block> 适用于追加信息 。</block>
  <block id="4f10474fd5677d7f5caee5944cfd1a79" category="list-text">使用以下SSH命令将igroup映射到刚刚创建的LUN。</block>
  <block id="e9cb77a7f24ef618789f32ace120d069" category="paragraph"><block ref="e9cb77a7f24ef618789f32ace120d069" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0108f548c7bfba3ca19e227db2ad81d9" category="list-text">对于使用Windows故障转移集群的共享磁盘、请运行SSH命令将同一个LUN映射到属于Windows故障转移集群中所有服务器的igroup。</block>
  <block id="88c4f29ad54bd37fb1b7a1491b7af990" category="list-text">将Windows Server连接到具有iSCSI目标的SVM。从AWS门户查找目标IP地址。</block>
  <block id="547003177db44afb512e9939c282d6c9" category="paragraph"><block ref="547003177db44afb512e9939c282d6c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df9eaa73034109b21c143e8c209823c2" category="list-text">从服务器管理器和工具菜单中、选择iSCSI启动程序。选择发现选项卡、然后选择发现门户。提供上一步中的iSCSI IP地址、然后选择高级。从本地适配器中、选择Microsoft iSCSI启动程序。从启动程序IP中、选择服务器的IP。然后选择确定以关闭所有窗口。</block>
  <block id="076e00306637258d0363c74566eb915d" category="paragraph"><block ref="076e00306637258d0363c74566eb915d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd432f2fc3bb1fab0023bf42f7b4108" category="list-text">对SVM中的第二个iSCSI IP重复步骤12。</block>
  <block id="5648333e8838336553b385e488639863" category="list-text">选择*目标*选项卡、选择*连接*、然后选择*启用多路径*。</block>
  <block id="4bff8ed7bd736139029b8aa4f639ccd9" category="paragraph"><block ref="4bff8ed7bd736139029b8aa4f639ccd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f94de8933712f5d52ca62caf7fef6eb5" category="list-text">为了获得最佳性能、请添加更多会话；NetApp建议创建五个iSCSI会话。选择*属性*&gt;*添加会话*&gt;*高级*并重复步骤12。</block>
  <block id="5636fa6e8685f1da20bf9489bcadc782" category="paragraph"><block ref="5636fa6e8685f1da20bf9489bcadc782" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a196b0bfd5261a81ff3d40a2043f792c" category="list-text">运行以下PowerShell命令以确保iSCSI会话保持不变。</block>
  <block id="58fbf35d4173787943d2fe31aed43341" category="paragraph"><block ref="58fbf35d4173787943d2fe31aed43341" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22ae84abced8e9e1236160d982616772" category="list-text">使用以下PowerShell命令初始化磁盘。</block>
  <block id="ac47df449db0c31d1ba6117a1dd19765" category="paragraph"><block ref="ac47df449db0c31d1ba6117a1dd19765" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b1e9edc2d6e907049df14a10a6fcc404" category="list-text">使用PowerShell运行创建分区和格式化磁盘命令。</block>
  <block id="79484e9f2e5f0589c78f273edd80759f" category="paragraph">您可以使用附录B中的PowerShell脚本自动创建卷和LUN也可以使用SnapCenter 创建LUN。</block>
  <block id="d05ae24753b4098046ae8369c5618b97" category="paragraph">定义卷和LUN后、您需要设置SnapCenter 才能执行数据库操作。</block>
  <block id="6309043436d4e7e5bad9a81c89ff15e4" category="example-title">SnapCenter 概述</block>
  <block id="419a08c6fdce80a29b8f8aeb7524f0e2" category="paragraph">NetApp SnapCenter 是适用于第1层企业级应用程序的下一代数据保护软件。SnapCenter 凭借其单一管理平台管理界面、可自动执行并简化与多个数据库和其他应用程序工作负载的备份、恢复和克隆相关的手动、复杂且耗时的流程。SnapCenter 利用NetApp技术、包括NetApp Snapshot、NetApp SnapMirror、SnapRestore 和NetApp FlexClone。通过这种集成、IT组织可以扩展其存储基础架构、满足日益严格的SLA承诺、并提高整个企业内管理员的工作效率。</block>
  <block id="aa7c84b8a1ac7c27cbd3e14740e96214" category="example-title">SnapCenter 服务器要求</block>
  <block id="4ee08603c9fd8ece4f670310954cdde6" category="paragraph">下表列出了在Microsoft Windows Server上安装SnapCenter 服务器和插件的最低要求。</block>
  <block id="05bbb43b3d923283e0b6ffafd088f41f" category="cell">组件</block>
  <block id="9b97b7bd5e0a87be7bf218224ada83cf" category="cell">要求</block>
  <block id="44e5a606cb3fbfaed79ce8eb853ed886" category="paragraph">最小 CPU 计数</block>
  <block id="ea54f01387bc5362f6e287ba66d656a8" category="paragraph">四核/vCPU</block>
  <block id="99880291d6a6b72b928a1847a6135c88" category="paragraph">最小值：建议8 GB：32 GB</block>
  <block id="96e1506a8b72a455b990ffe403eea2cf" category="paragraph">存储空间</block>
  <block id="39b4c2fc16a74430850f1b767f816bdd" category="paragraph">最小安装空间：10 Gb存储库最小空间：10 Gb</block>
  <block id="2e71b3fb71d89f18906d4807a6011e20" category="cell">支持的操作系统</block>
  <block id="00aae0645113cb861020a7a42ded48c2" category="list-text">Windows Server 2012</block>
  <block id="96bc7f42979153694e05a6a2b867772e" category="list-text">Windows Server 2012 R2</block>
  <block id="ed590cb2453f0683b64cb528f78610a2" category="list-text">Windows Server 2016</block>
  <block id="7c01fa88a74580e7e4f62ca6bfe7ee83" category="cell">软件包</block>
  <block id="aab81d3c2e898a19cf0f270cdb285a21" category="list-text">.NET 4.5.2或更高版本</block>
  <block id="43de0ba571a51d1adc60e6d05ecf8d70" category="list-text">Windows Management Framework （ WMF ） 4.0 或更高版本</block>
  <block id="fd6133b32592ca288e63c1b1257f656d" category="list-text">PowerShell 4.0 或更高版本</block>
  <block id="a19fb58a9ea7e8409b13e971960fdbf8" category="paragraph">有关版本兼容性、请参见<block ref="b7322bec4509d45107de6de43ca1f517" category="inline-link-rx"></block>。</block>
  <block id="00324c8ea6b2abc68414748e587e15ec" category="example-title">数据库存储布局</block>
  <block id="a02dce187534c84aa16d8849406a60eb" category="paragraph">下图介绍了使用SnapCenter 进行备份时创建Microsoft SQL Server数据库存储布局的一些注意事项。</block>
  <block id="4c246b141980a6574bc7f111fe7abef7" category="paragraph"><block ref="4c246b141980a6574bc7f111fe7abef7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ebfae4b9e090c4988616a73ffc71415e" category="list-text">将具有I/O密集型查询或大型数据库(例如500 GB或更大)的数据库放置在一个单独的卷上、以加快恢复速度。此卷还应通过单独的作业进行备份。</block>
  <block id="4916b57b0128fd5a0a4300f0a8763292" category="list-text">将不太重要或I/O要求较低的中小型数据库整合到一个卷。备份同一卷中的大量数据库会减少需要维护的Snapshot副本数量。此外、最佳做法是整合Microsoft SQL Server实例、以便使用相同的卷来控制所创建的备份Snapshot副本的数量。</block>
  <block id="8db6b23eddd61aa572ca93a39703d4a8" category="list-text">创建单独的LUN以存储完整的文本相关文件和文件流相关文件。</block>
  <block id="cb11fd215e0c541cb65535e582b9b273" category="list-text">为每个主机分配单独的LUN以存储Microsoft SQL Server日志备份。</block>
  <block id="48b8325fd70d83c2d4e99987e23b07ef" category="list-text">存储数据库服务器元数据配置和作业详细信息的系统数据库不会频繁更新。将系统数据库/tempdb放置在单独的驱动器或LUN中。请勿将系统数据库与用户数据库放置在同一个卷中。用户数据库具有不同的备份策略、系统数据库的用户数据库备份频率不同。</block>
  <block id="1be01a12dc77b3099b16d258c12db3f9" category="list-text">对于Microsoft SQL Server可用性组设置、请将副本的数据和日志文件置于所有节点上相同的文件夹结构中。</block>
  <block id="a586cfc38b79b6539a9723b4d2f5af66" category="paragraph">除了将用户数据库布局隔离到不同卷的性能优势之外、数据库还会显著影响备份和还原所需的时间。与托管多个用户数据文件的卷相比、为数据和日志文件配置单独的卷可以显著缩短还原时间。同样、I/O密集型应用程序较高的用户数据库也容易增加备份时间。本文档稍后将详细介绍备份和还原实践。</block>
  <block id="7f3611c256fabe67e4d74a6c70cfe9c5" category="admonition">从SQL Server 2012 (11.x)开始、系统数据库(主数据库、模型数据库、MSDB数据库和TempDB)、数据库引擎用户数据库可以作为存储选项随SMB文件服务器一起安装。此适用场景 既包括独立的SQL Server安装、也包括SQL Server故障转移集群安装。这样、您就可以将FSX for ONTAP 与所有性能和数据管理功能结合使用、包括卷容量、性能可扩展性和数据保护功能、SQL Server可以利用这些功能。应用程序服务器使用的共享必须使用持续可用属性集进行配置、并且应使用NTFS安全模式创建卷。NetApp SnapCenter 不能与FSX for ONTAP 中放置在SMB共享上的数据库结合使用。</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="admonition">对于不使用SnapCenter 执行备份的SQL Server数据库、Microsoft建议将数据和日志文件放置在不同的驱动器上。对于同时更新和请求数据的应用程序、日志文件会占用大量写入资源、而数据文件(取决于您的应用程序)会占用大量读/写资源。对于数据检索、不需要日志文件。因此、可以通过放置在其自己驱动器上的数据文件来满足数据请求。</block>
  <block id="41a264a984b034248073a80093913e60" category="admonition">创建新数据库时、Microsoft建议为数据和日志指定单独的驱动器。要在创建数据库后移动文件、必须使数据库脱机。有关Microsoft的详细建议、请参见将数据和日志文件放置在不同的驱动器上。</block>
  <block id="f4ea2029dd0e694cde33838315883930" category="example-title">安装和设置SnapCenter</block>
  <block id="d39d360863f3fda3c5d615dc978e14ae" category="inline-link">安装 SnapCenter 服务器</block>
  <block id="1155d165aa176b6275b67036497cd8e6" category="inline-link">安装适用于Microsoft SQL Server的SnapCenter 插件</block>
  <block id="067f687182a68fccec4a3840e67fc889" category="paragraph">按照<block ref="4144149cc24a91f915be2d3b14f23c22" category="inline-link-rx"></block> 和<block ref="7e24f6ba39e2c63512c07f20cb1a71c0" category="inline-link-rx"></block> 安装和设置SnapCenter。</block>
  <block id="3ab2ad2898088a813669db2948590562" category="paragraph">安装SnapCenter 后、请完成以下步骤进行设置。</block>
  <block id="dd0c654d5a8ede80984b9526335bddc9" category="list-text">要设置凭据、请选择*设置*&gt;*新增*、然后输入凭据信息。</block>
  <block id="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="paragraph"><block ref="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c790771cb60de4cb4a7212e8db25bf3c" category="list-text">通过选择存储系统&gt;新建并为ONTAP 存储信息提供适当的FSX来添加存储系统。</block>
  <block id="28e78cc4b0ec3be7790fc763323de0f6" category="paragraph"><block ref="28e78cc4b0ec3be7790fc763323de0f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0e0b904d3c7826b806c48118543142c" category="list-text">通过选择*主机*&gt;*添加*来添加主机、然后提供主机信息。SnapCenter 会自动安装Windows和SQL Server插件。此过程可能需要一些时间。</block>
  <block id="0f2c351522362209f5160c4794708c97" category="paragraph"><block ref="0f2c351522362209f5160c4794708c97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23dd2805cf2d7b26334d0678ab4e99b4" category="paragraph">安装完所有插件后、您必须配置日志目录。这是事务日志备份所在的位置。您可以通过选择主机并选择配置日志目录来配置日志目录。</block>
  <block id="5c5fb88ff793d01c8b1a283f1ee88749" category="admonition">SnapCenter 使用主机日志目录存储事务日志备份数据。这是在主机和实例级别进行的。SnapCenter 使用的每个SQL Server主机都必须配置一个主机日志目录才能执行日志备份。SnapCenter 具有一个数据库存储库、因此与备份、还原或克隆操作相关的元数据存储在一个中央数据库存储库中。</block>
  <block id="0fc057cb39ba1a444dbc365c0161d31f" category="paragraph">主机日志目录的大小计算如下：</block>
  <block id="e067558831f8381f0970051292e0a02a" category="paragraph">主机日志目录大小=((系统数据库大小+(最大数据库LDF大小×每日日志更改率%))×(Snapshot副本保留)÷(1–LUN开销空间%)</block>
  <block id="1b5bc043867e6da78577571c1070e56a" category="paragraph">主机日志目录大小调整公式假设以下条件：</block>
  <block id="fa7afec3a90f55ad9aea3b76f336302f" category="list-text">不包含tempdb数据库的系统数据库备份</block>
  <block id="f550013c290c4a21af7974f7440d758a" category="list-text">10%的LUN开销空间将主机日志目录置于专用卷或LUN上。主机日志目录中的数据量取决于备份的大小以及备份的保留天数。</block>
  <block id="83924e370463c681c401f53e2b4b3f2d" category="paragraph"><block ref="83924e370463c681c401f53e2b4b3f2d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd9dfb7fc6f502e70f86a8c1f2d66aa1" category="paragraph">如果已配置LUN、则可以选择挂载点来表示主机日志目录。</block>
  <block id="db38f16eb9374dba4590f05c202fa4a5" category="paragraph"><block ref="db38f16eb9374dba4590f05c202fa4a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a708f2af7ec6f7c7ae489cca832c811" category="paragraph">现在、您可以为SQL Server执行备份、还原和克隆操作了。</block>
  <block id="7bfeafaf85908b711b618c069c66e99c" category="example-title">使用SnapCenter 备份数据库</block>
  <block id="fc197cb26aec21d091eb6791c0d7cbff" category="paragraph">将数据库和日志文件放置在FSX ONTAP LUN上后、可以使用SnapCenter 备份数据库。以下过程用于创建完整备份。</block>
  <block id="f52f437d3282493fd1855bba366c482a" category="list-text">在SnapCenter 术语中、RPO可以标识为备份频率、例如、您希望计划备份的频率、以便将数据丢失减少到最长几分钟。使用SnapCenter 、您可以计划每五分钟进行一次备份。但是、在某些情况下、备份可能无法在事务高峰时间的五分钟内完成、或者数据更改率在给定时间内较高。最佳做法是计划频繁执行事务日志备份、而不是执行完整备份。</block>
  <block id="7b99ea666dfc26516833c088400741e6" category="list-text">可通过多种方法处理RPO和RTO。此备份方法的一种替代方法是、为不同间隔的数据和日志创建单独的备份策略。例如、在SnapCenter 中、每15分钟计划一次日志备份、每6小时计划一次数据备份。</block>
  <block id="14b0febccc904523871b9498c72ab705" category="list-text">使用资源组进行备份配置、以优化Snapshot以及要管理的作业数。</block>
  <block id="45be64dc5372d4c03684e301633c794c" category="list-text">选择*资源*、然后选择左上角下拉菜单中的* Microsoft SQL Server *。选择*刷新资源*。</block>
  <block id="94cc612f3fcbd977b78ea3b7a422c531" category="paragraph"><block ref="94cc612f3fcbd977b78ea3b7a422c531" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d99e4391045a563d9d1d2d78ddd2417a" category="paragraph"><block ref="d99e4391045a563d9d1d2d78ddd2417a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89f2e11b6c9317605c01622834d4853d" category="list-text">如有必要、选择验证服务器。此服务器是SnapCenter 在创建完整备份后运行DBCC CHECKDB的服务器。单击*下一步*进行通知、然后选择*摘要*进行查看。查看后、单击*完成*。</block>
  <block id="fc2d6f88564b6e12fc40b19f28b7420d" category="paragraph"><block ref="fc2d6f88564b6e12fc40b19f28b7420d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="919295932fd1084fb39c4a1be23b37ed" category="list-text">单击*立即备份*以测试备份。在弹出窗口中、选择*备份*。</block>
  <block id="93598d1ad688123817fda7d22fa0ac82" category="paragraph"><block ref="93598d1ad688123817fda7d22fa0ac82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c738a74e68034a98f4a38a1b41ef2d4" category="list-text">选择*监控*以验证备份是否已完成。</block>
  <block id="710fa04917c218b834664e1f0d37a48c" category="paragraph"><block ref="710fa04917c218b834664e1f0d37a48c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67459542a38abe56e00d4512bb475f05" category="list-text">从SnapCenter 备份事务日志备份、以便在还原过程中、SnapCenter 可以自动读取所有备份文件并按顺序还原。</block>
  <block id="54d8d459dfb725a307f3bb54495de3e3" category="list-text">如果使用第三方产品进行备份、请选择在SnapCenter 中复制备份以避免日志序列问题、并在投入生产之前测试还原功能。</block>
  <block id="83b7215bcd7cc73d11f34b95b4026718" category="example-title">使用SnapCenter 还原数据库</block>
  <block id="7172cc34c1510c3891870c7c009c94e1" category="paragraph">在EC2上将FSX ONTAP 与SQL Server结合使用的一个主要优势是、它能够在每个数据库级别快速执行粒度还原。</block>
  <block id="5afcacb3783eeead2b5317d1c455b3bc" category="paragraph">要使用SnapCenter 将单个数据库还原到特定时间点或最短时间、请完成以下步骤。</block>
  <block id="a028f8b44f91b1338df98ed3237d093a" category="list-text">选择资源、然后选择要还原的数据库。</block>
  <block id="b5f8165159678d41fab115d5a8f013d2" category="paragraph"><block ref="b5f8165159678d41fab115d5a8f013d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb395b310e199ca7ef6b36360302bc50" category="list-text">选择需要从中还原数据库的备份名称、然后选择还原。</block>
  <block id="e99d25ac3998e8701f51a1990c8d8785" category="list-text">按照*还原*弹出窗口还原数据库。</block>
  <block id="8bdb6d6fe719d2506b9b5f86bda88b43" category="list-text">选择*监控*以验证还原过程是否成功。</block>
  <block id="e445e84ca78cd7f21cdd70356d211583" category="paragraph"><block ref="e445e84ca78cd7f21cdd70356d211583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459c0a4ca065bbbedc6304d4c6903cc5" category="example-title">包含大量大小不一的数据库的实例的注意事项</block>
  <block id="0be8a2d7e2996a1641824fa4250d2fd3" category="paragraph">SnapCenter 可以在资源组中的一个实例或一组实例中备份大量规模较大的数据库。数据库大小不是备份时间的主要因素。备份的持续时间可能因每个卷的LUN数量、Microsoft SQL Server上的负载、每个实例的数据库总数、尤其是I/O带宽和使用量而异。在配置用于从实例或资源组备份数据库的策略时、NetApp建议将每个Snapshot副本备份的最大数据库数限制为每个主机100个。确保Snapshot副本总数不超过1、023个副本的限制。</block>
  <block id="33f3c567c61942e461392756abce64dc" category="paragraph">NetApp还建议对数据库数量进行分组、而不是为每个数据库或实例创建多个作业、以限制并行运行的备份作业。为了获得最佳备份持续时间性能、请将备份作业数量减少到一次可备份大约100个或更少数据库的数量。</block>
  <block id="ea2e6af969539b040884e9a2ec1fcb49" category="paragraph">如前所述、I/O使用量是备份过程中的一个重要因素。备份过程必须等待暂停、直到数据库上的所有I/O操作完成。I/O操作非常密集的数据库应延迟到另一备份时间、或者应与其他备份作业隔离、以避免影响要备份的同一资源组中的其他资源。</block>
  <block id="e5ad8f936997e1328b1b169bf5c6cc8b" category="paragraph">对于每个实例具有六个Microsoft SQL Server主机托管200个数据库的环境、假设每个主机具有四个LUN、并且每个卷创建了一个LUN、请将完整备份策略的每个Snapshot副本备份的最大数据库数设置为100。每个实例上的200个数据库布局为200个数据文件、在两个LUN上平均分布200个日志文件、在两个LUN上平均分布200个日志文件、即每个卷的每个LUN 100个文件。</block>
  <block id="7804dbf4b7a37ec699db9a31f21bbea7" category="paragraph">通过创建三个资源组来计划三个备份作业、每个资源组对总共包含400个数据库的两个实例进行分组。</block>
  <block id="e2ba702320599667af2b18f0fad307e0" category="paragraph">并行运行所有三个备份作业可同时备份1、200个数据库。根据服务器上的负载和I/O使用情况、每个实例上的开始和结束时间可能会有所不同。在这种情况下、总共会创建24个Snapshot副本。</block>
  <block id="2d0d5c636161f9ca31c8ffbfa5ee5d7c" category="paragraph">除了完整备份之外、NetApp还建议您为关键数据库配置事务日志备份。确保数据库属性设置为完全恢复模式。</block>
  <block id="aac1148375449745ddbbe1709a2375f5" category="list-text">请勿将tempdb数据库包括在备份中、因为它包含的数据是临时的。将tempdb放置在不会创建Snapshot副本的存储系统卷中的LUN或SMB共享上。</block>
  <block id="16c5de1581b82a1f8657a3a98ac8fd34" category="list-text">对于I/O密集型应用程序较高的Microsoft SQL Server实例、应在不同的备份作业中隔离、以减少其他资源的整体备份时间。</block>
  <block id="a9a558ac49f24a2b078812205f07179c" category="list-text">将要同时备份的一组数据库限制为大约100个、并错开其余一组数据库备份、以避免同时进行。</block>
  <block id="68086c26b8c1644dfe6ea7d6fb859641" category="list-text">请在资源组中使用Microsoft SQL Server实例名称、而不是使用多个数据库、因为每当在Microsoft SQL Server实例中创建新数据库时、SnapCenter 都会自动考虑要备份的新数据库。</block>
  <block id="5e5d80c17369e70061349fffb43b0aa8" category="list-text">如果更改数据库配置、例如将数据库恢复模型更改为完全恢复模型、请立即执行备份、以便执行最新的还原操作。</block>
  <block id="3dce7613a0d76dcf6fcb8e1daf396bbb" category="list-text">SnapCenter 无法还原在SnapCenter 外部创建的事务日志备份。</block>
  <block id="0007de7aba408b88984eb8eb18044303" category="list-text">克隆FlexVol 卷时、请确保您有足够的空间来容纳克隆元数据。</block>
  <block id="9416a94214ef699335d78087cd9f12c6" category="list-text">还原数据库时、请确保卷上有足够的可用空间。</block>
  <block id="86e3f69ee9647210c14858984e2649ef" category="list-text">创建一个单独的策略、以便每周至少管理和备份一次系统数据库。</block>
  <block id="330337562cd623f5deb5908d4e8af736" category="example-title">使用SnapCenter 克隆数据库</block>
  <block id="0a6bfc2082e52dc96430a6b7c0dfc7e7" category="paragraph">要将数据库还原到开发或测试环境中的其他位置或创建副本以进行业务分析、NetApp最佳实践是、利用克隆方法在同一实例或备用实例上创建数据库副本。</block>
  <block id="0f462cc9e20017ed0597a6a199f57035" category="paragraph">在FSX for ONTAP 环境中托管的iSCSI磁盘上克隆500 GB的数据库通常需要不到五分钟的时间。克隆完成后、用户可以对克隆的数据库执行所有必需的读/写操作。大部分时间用于磁盘扫描(diskpart)。无论数据库大小如何、NetApp克隆操作步骤 通常都只需不到2分钟的时间。</block>
  <block id="886ef20e3049a00bc0d9a1c734bb90da" category="paragraph">可以使用以下两种方法克隆数据库：您可以从最新备份创建克隆、也可以使用克隆生命周期管理功能在二级实例上提供最新副本。</block>
  <block id="870999fc556eadefd7740857b96209c3" category="paragraph">使用SnapCenter 可以将克隆副本挂载到所需磁盘上、以保持二级实例上文件夹结构的格式并继续计划备份作业。</block>
  <block id="b2face8e1d4561b0ed5b594bfc4c0063" category="example-title">将数据库克隆到同一实例中的新数据库名称</block>
  <block id="4a3135e25926365f40a59fd88af69a44" category="paragraph">可以使用以下步骤将数据库克隆到EC2上运行的同一SQL Server实例中的新数据库名称：</block>
  <block id="4655b3c9fecfc4d22a59068929be2bec" category="list-text">选择资源、然后选择需要克隆的数据库。</block>
  <block id="944b75c61851b0ebc427a8aedc83d6f3" category="list-text">选择要克隆的备份名称、然后选择克隆。</block>
  <block id="83d2194c2b06657769054af057f16b0a" category="list-text">按照备份窗口中的克隆说明完成克隆过程。</block>
  <block id="8fb624c33e03c9d016909a11c669125d" category="list-text">选择Monitor以确保克隆已完成。</block>
  <block id="0b075fd84c4c4a47346b99d43f9260be" category="example-title">将数据库克隆到EC2上运行的新SQL Server实例中</block>
  <block id="9451e65c3b1fc3fc6cf89a3fc9cf3cfd" category="paragraph">以下步骤用于将数据库克隆到EC2上运行的新SQL Server实例：</block>
  <block id="479cb4cd4ee76801e360aa03ddc20a3a" category="list-text">在同一VPC中的EC2上创建新的SQL Server。</block>
  <block id="163733cab5060ba4621bb642ba3870a0" category="list-text">启用iSCSI协议和MPIO、然后按照"为SQL Server创建卷和LUN "一节中的步骤3和4设置与适用于ONTAP 的FSX的iSCSI连接。</block>
  <block id="918269b8806c56ca4a0910482994e142" category="list-text">按照"安装和设置SnapCenter "一节中的步骤3将EC2上的新SQL Server添加到SnapCenter 中。</block>
  <block id="e7130318e065eddd45ec86565b727731" category="list-text">选择资源&gt;查看实例、然后选择刷新资源。</block>
  <block id="8be42b1e845c00bcb04c11269072f895" category="list-text">选择资源、然后选择要克隆的数据库。</block>
  <block id="459801927d3c0bd5ddec9c1513f213ec" category="list-text">选择要克隆的备份名称、然后选择克隆。</block>
  <block id="030603235fe06c85ee75276379fe5baa" category="paragraph"><block ref="030603235fe06c85ee75276379fe5baa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d50db35e68c1259b414779e24fdbf5" category="list-text">按照"从备份克隆"说明、在EC2上提供新的SQL Server实例和实例名称、完成克隆过程。</block>
  <block id="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="paragraph"><block ref="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20606e28a0d567be1dabd5cf50a2dc3b" category="section-title">附录</block>
  <block id="16dfbb688028526582ec31ab802b9589" category="example-title">附录A：用于云形成模板的YAML文件</block>
  <block id="4c76ae47de51751cc57a4033d14f2f2a" category="paragraph">以下.yaml文件可与AWS控制台中的云构成模板结合使用。</block>
  <block id="f6d8279768d195862ae69a3df8dd51ab" category="inline-link">此GitHub链接</block>
  <block id="00867e5f5ae22280c11a2626b65e657b" category="example-title">附录B：用于配置卷和LUN的PowerShell脚本</block>
  <block id="0826ee2b94a579e02e80bfcdf26c5648" category="paragraph">以下脚本用于配置卷和LUN、并根据上述说明设置iSCSI。有两个PowerShell脚本：</block>
  <block id="81e24f41fbaff249c9819985065173e3" category="list-text"><block ref="2a9a99327bbfb47d37ee76307e959506" prefix="" category="inline-code"></block></block>
  <block id="2ca8201f2a50e4aec0e5ba21f6afed4d" category="list-text"><block ref="d78c8f4fe63dbe3ffd666bbbaf054cd7" prefix="" category="inline-code"></block></block>
  <block id="6385631c0b330c166b540183cec5af78" category="paragraph">运行文件<block ref="d2dd03515102971189549a37cb42eb14" prefix=" " category="inline-code"></block> 首先、第二个脚本会在服务器重新启动后自动执行。由于对SVM的凭据访问、可以在执行这些PowerShell脚本后将其删除。</block>
  <block id="d82c21a48349085e4fd93fb6712e3789" category="inline-link"><block ref="d82c21a48349085e4fd93fb6712e3789" category="inline-link-rx"></block></block>
  <block id="c745303ee8000be162517c239783af70" category="paragraph"><block ref="c745303ee8000be162517c239783af70" category="inline-link-rx"></block></block>
  <block id="c6e485d51bc9da63bcac29189dac0f3c" category="list-text">适用于NetApp ONTAP 的FSX入门</block>
  <block id="90572737558e59a2ecdd4618af07d6f3" category="inline-link"><block ref="90572737558e59a2ecdd4618af07d6f3" category="inline-link-rx"></block></block>
  <block id="7545caf3d97477d3c569d56c512074fa" category="paragraph"><block ref="7545caf3d97477d3c569d56c512074fa" category="inline-link-rx"></block></block>
  <block id="ad65cae8cf2bbd15ac77769974a440ce" category="list-text">SnapCenter 界面概述</block>
  <block id="59cbc11e5ccd87939e1b70af73ec1f01" category="inline-link"><block ref="c0a7623803fcfb4ac66342d4ae76ffff" category="inline-link-rx"></block></block>
  <block id="7ab2e91ecb30982855aa0dde8b78a361" category="paragraph"><block ref="89ba280df4e8c5cfd9bcd0f8c80d8ba5" category="inline-link-rx"></block></block>
  <block id="1bdf7559e69b81c007496a063e71bca0" category="list-text">浏览SnapCenter 导航窗格选项</block>
  <block id="6d5097a2c320359a8d212d07ea067dac" category="inline-link"><block ref="6d5097a2c320359a8d212d07ea067dac" category="inline-link-rx"></block></block>
  <block id="e0ae39eeb7c7d78d56a1292229d1277a" category="paragraph"><block ref="e0ae39eeb7c7d78d56a1292229d1277a" category="inline-link-rx"></block></block>
  <block id="d29a9430434c2654cce06036a4a478b2" category="list-text">设置适用于SQL Server的SnapCenter 4.0插件</block>
  <block id="520419781af4d13a8b33c054a304985b" category="inline-link"><block ref="520419781af4d13a8b33c054a304985b" category="inline-link-rx"></block></block>
  <block id="c2580a05e81a19c4b782e51932415e30" category="paragraph"><block ref="c2580a05e81a19c4b782e51932415e30" category="inline-link-rx"></block></block>
  <block id="f781a682aea107fb2cdda3a0c1fd3ac5" category="list-text">如何使用带有SQL Server插件的SnapCenter 备份和还原数据库</block>
  <block id="285a27614fdeee7f22969646d33edc95" category="inline-link"><block ref="285a27614fdeee7f22969646d33edc95" category="inline-link-rx"></block></block>
  <block id="e1685ff793f13bbd2956f2156b0d5a67" category="paragraph"><block ref="e1685ff793f13bbd2956f2156b0d5a67" category="inline-link-rx"></block></block>
  <block id="c8e300ff66d94fe7668ff8d5d5e7f1c3" category="list-text">如何使用带有SQL Server插件的SnapCenter 克隆数据库</block>
  <block id="e482c7b116916a3d87aba2ab1365190b" category="inline-link"><block ref="e482c7b116916a3d87aba2ab1365190b" category="inline-link-rx"></block></block>
  <block id="b916fd292760d6ae01e337bf2a132edb" category="paragraph"><block ref="b916fd292760d6ae01e337bf2a132edb" category="inline-link-rx"></block></block>
  <block id="5d0dd45a93153403c2446a809dcb5fc3" category="sidebar">使用适用于NetApp ONTAP 的Amazon FSX的AWS EC2上的SQL Server</block>
  <block id="dc406f8350f51d99347d8d026c0435a5" category="list-text">总之、从旋转磁盘过渡到全闪存可提高性能。计算节点的数量不是瓶颈。借助NetApp全闪存存储、运行时性能可进行良好扩展。</block>
  <block id="67c8804409fa1f91b1b477b7c99d1d71" category="paragraph">作者：Chris Reno、Josh Powell和Suresh ThopPay—NetApp解决方案工程部</block>
  <block id="37242160d8bbd9ad700322c3c2499272" category="section-title">假设、前提条件和组件概述</block>
  <block id="3ea8c755cca91dd6bbeec88e906263e9" category="paragraph">在部署此解决方案 之前、请查看组件概述、部署解决方案 所需的前提条件以及在记录此解决方案 时所做的假设。</block>
  <block id="7bcf43f481a8076036689561dce0e62d" category="inline-link-macro">DR解决方案 要求、要求和规划</block>
  <block id="684b2b80ca970225e77585d96775fc95" category="section-title">使用SnapCenter 执行灾难恢复</block>
  <block id="782f10deb2809cc33e0082dbe9371f9b" category="paragraph">登录到控制台后、必须为备份SQL Server和Oracle数据库配置SnapCenter。</block>
  <block id="cf5c2d1e726e35ab57a75901cde43919" category="example-title">部署二级Veeam Backup &amp; amp；复制服务器</block>
  <block id="2b0e654aa884c8c50887b2eff59bc68f" category="example-title">配置二级Veeam Backup &amp; amp；复制服务器</block>
  <block id="ed8b9b5c064b716d4c1d3f30a595410f" category="example-title">Veeam Backup &amp; amp；复制</block>
  <block id="42c8c901c8d4c00c90f9f66d69df3cdb" category="example-title">Veeam Backup &amp; amp；复制服务器</block>
  <block id="17f0b02d31e76cb9b2878b4a08f19eb5" category="example-title">Veeam Backup &amp; amp；复制配置</block>
  <block id="3107c066ea7eeb48bd5f87594a08fd7a" category="paragraph">&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;HEAD我们对使用不同存储策略的SSD和SAS驱动器的NetApp AFF 存储控制器和E系列存储控制器上的Hadoop存储分层进行了验证。采用AF-A800的Spark集群具有四个计算辅助节点、而采用E系列的集群则具有八个。这主要是为了比较固态驱动器(SSD)与硬盘驱动器(HDD)的性能。</block>
  <block id="dba657bcaa661bcf5461e260c00e4f06" category="paragraph">我们对使用不同存储策略的SSD和SAS驱动器的NetApp AFF 存储控制器和E系列存储控制器上的Hadoop存储分层进行了验证。采用AF-A800的Spark集群具有四个计算辅助节点、而采用E系列的集群则具有八个。我们这样做的主要目的是将固态驱动器与硬盘驱动器磁盘的性能进行比较。&gt;&gt;&gt;&gt;&gt;a51c9ddf73ca69e1120ce05edc7b0b9607b96eae.</block>
  <block id="f14f651fb8150de92c527d88344df494" category="list-text">使用TeraSort、SSD配置的1 TB数据排序速度比NL-SAS配置快1138.36倍。此外、SSD配置使用的计算节点数为计算节点数的一半、磁盘驱动器数的一半(总共24个SSD驱动器)。因此、每个驱动器的速度大约是NL-SAS配置的三倍。&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 标题</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">这种方法正在从旋转磁盘过渡到全闪存、从而提高了性能。计算节点的数量不是瓶颈。借助NetApp的全闪存存储、运行时性能可进行良好扩展。</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">使用NFS时、数据在功能上相当于将全部池化在一起、这样可以根据您的工作负载减少计算节点的数量。更改计算节点数量时、Apache Spark集群用户无需手动重新平衡数据。</block>
  <block id="6ed171c4fe1ca516676ea457d91105b1" category="list-text">使用NFS、数据在功能上相当于将所有数据池在一起、这样可以根据您的工作负载减少计算节点的数量。Apache Spark集群用户在更改计算节点数量时无需手动重新平衡数据。&gt;&gt;&gt;&gt;&gt;a51c9ddf73ca69e1120ce05edc7b0b9607b96eae.</block>
  <block id="839a1261c70db1f3c149f86d56e21d15" category="cell">2023年12月1日</block>
  <block id="70542da4927194cf41c777029ebe56be" category="cell">新增博客：使用NetApp SnapCenter 和适用于NetApp ONTAP 的Amazon FSx保护SQL Server工作负载</block>
  <block id="577322186c067590a18f8891be57e7e4" category="inline-link-macro">使用NetApp SnapCenter 与适用于NetApp ONTAP 的Amazon FSX保护SQL Server工作负载</block>
  <block id="c1b7f59fc598d7a811682707bcd4eb40" category="list-text"><block ref="c1b7f59fc598d7a811682707bcd4eb40" category="inline-link-macro-rx"></block></block>
  <block id="88ac8db9784908706c34feb6caee9044" category="paragraph"><block ref="88ac8db9784908706c34feb6caee9044" category="inline-link-macro-rx"></block></block>
  <block id="03b125f503e8b797be1fe5a21a10d220" category="summary">本节介绍如何使用azacsnap工具以及快照备份、还原和快照分层到Azure Blob来保护Oracle数据库。</block>
  <block id="b47faaf85acf415e557bd0b669342659" category="doc">在Azure云中保护Oracle数据库</block>
  <block id="06a2961d48a854a133ddfe05c7912732" category="section-title">使用AzAcSnap工具使用Snapshot备份Oracle数据库</block>
  <block id="30462dbcf926561966ea824afd44e355" category="paragraph">Azure应用程序一致的Snapshot工具(AzAcSnap)是一个命令行工具、可通过处理在创建存储快照之前将第三方数据库置于应用程序一致状态所需的所有流程编排来为其提供数据保护、之后、它会将数据库恢复为运行状态。</block>
  <block id="07612935f16f2665ef52f490f9b1f43b" category="paragraph">对于Oracle、您可以将数据库置于备份模式以创建快照、然后将数据库退出备份模式。</block>
  <block id="070d0b63c9af5e43d43102c1869d4262" category="section-title">备份数据和日志卷</block>
  <block id="7dd57abd8929da4f18cc94d1940161a1" category="paragraph">可以使用执行snapshot命令的简单shell脚本在数据库服务器主机上设置备份。然后、可以计划从crontab运行此脚本。</block>
  <block id="087916fda35dba838b68193ed8bc3aeb" category="paragraph">通常、备份频率取决于所需的RTO和RPO。频繁创建快照会占用更多存储空间。备份频率与空间占用之间存在一定的权衡。</block>
  <block id="e2ece357797b760af1c814632edcf99d" category="paragraph">数据卷通常比日志卷占用更多的存储空间。因此、您可以每几小时在数据卷上创建一次快照、而每15到30分钟在日志卷上创建一次更频繁的快照。</block>
  <block id="2a2c2eb0d2bde8c24cc55a11862ca857" category="paragraph">请参见以下备份脚本和计划示例。</block>
  <block id="e048ccd48425229cea678849ba68a190" category="paragraph">对于数据卷快照：</block>
  <block id="f0d6345b8e5345f55c21610283eaeedd" category="paragraph">对于日志卷快照：</block>
  <block id="adf4ba1e0f3190afb18557f038ae1ecf" category="admonition">设置备份时<block ref="8ed8c6bfea85d72bc4a36772490109c7" prefix=" " category="inline-code"></block> 配置文件中、将所有数据卷(包括二进制卷)添加到<block ref="0fb9dff864caebba259b119756a2ce17" prefix=" " category="inline-code"></block> 以及所有日志卷<block ref="5e5fb0a2540d102aeebc3dac60712494" prefix=" " category="inline-code"></block>。快照的最大保留空间为250个副本。</block>
  <block id="a93091ed018686dcf478589ba04fd6f6" category="section-title">验证快照</block>
  <block id="8a46f2968d5dc184634cff75cd1b8b8e" category="paragraph">转至Azure门户&gt; Azure NetApp文件/卷以检查是否已成功创建快照。</block>
  <block id="3542e11f657b779fcef8cc387987e9f2" category="inline-image-macro">此屏幕截图显示了快照列表中的两个文件。</block>
  <block id="c2dd243538b072e19882bdcd6ac2c6c9" category="inline-image-macro">此屏幕截图显示了快照列表中的八个文件。</block>
  <block id="af143d815dcd69aae3ff8d8bdde9fd58" category="paragraph"><block ref="bf87ea8d7de67f1fdc628b6bb4b400e5" category="inline-image-macro-rx" type="image"></block>
<block ref="1d682e6513772285b95199f0646e28da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7479b02641600cb6142d8594c1360d11" category="section-title">Oracle从本地备份还原和恢复</block>
  <block id="76265d8fce7f282b6ff5a8581df8879c" category="paragraph">Snapshot备份的一个主要优势是、它与源数据库卷共存、并且主数据库卷几乎可以即时回滚。</block>
  <block id="878609e3e12819fffdd7247406f655be" category="section-title">在主服务器上还原和恢复Oracle</block>
  <block id="8733b7b64c8d2c32caa423c7eb2955fc" category="paragraph">以下示例演示了如何从同一Oracle主机上的Azure信息板和CLI还原和恢复Oracle数据库。</block>
  <block id="2817b9cf9fc0cd0d8bf9fb03acbfc93f" category="list-text">将此表放到快照备份之后。</block>
  <block id="09d4fe137595af1cc975247ba704462d" category="list-text">从Azure NetApp Files 信息板中、将日志卷还原到最后一个可用快照。选择*还原卷*。</block>
  <block id="33ba8417b2640d4172513bbf9cbc3e55" category="inline-image-macro">此屏幕截图显示了ANF信息板中卷的快照还原方法。</block>
  <block id="546b967f1ce32832a90c77282f0cdf2b" category="paragraph"><block ref="546b967f1ce32832a90c77282f0cdf2b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b728fe18b10b9b611a1d3ab6acc0df9" category="list-text">确认还原卷并单击*还原*以完成卷还原到最新可用备份的过程。</block>
  <block id="5c7deeb27ad1e0e4c1d6d52b2a2a1bfc" category="inline-image-macro">出现"Are you sure you want to do this？"快照还原页面。</block>
  <block id="ef80226ab5a9d2865852e606297da2cf" category="paragraph"><block ref="ef80226ab5a9d2865852e606297da2cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18b9906dd2c95b12fdb987b7c2aa9917" category="list-text">对数据卷重复相同的步骤、并确保备份包含要恢复的表。</block>
  <block id="a38e609b2fd5c2dee1b4ccb1cbbac7d4" category="inline-image-macro">此屏幕截图显示了ANF信息板中数据卷的快照还原方法。</block>
  <block id="f0d819988fad0119995986a2bdfd9ad6" category="paragraph"><block ref="f0d819988fad0119995986a2bdfd9ad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc824d4f774a64498f954eb2ebbc093b" category="list-text">再次确认卷还原、然后单击"还原"。</block>
  <block id="5e2296a09eabbd34b62da3492091ff33" category="inline-image-macro">出现"Are you sure you want to do this？"数据卷快照还原页面。</block>
  <block id="af5f9a99ee2d86856d0e2477e417dc4c" category="paragraph"><block ref="af5f9a99ee2d86856d0e2477e417dc4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="170b40e31285910539e0d464f2bf33a6" category="list-text">如果您有多个控制文件副本、请重新同步这些控制文件、并将旧控制文件替换为可用的最新副本。</block>
  <block id="bd99bc18393147b05e3f350eb6a61f47" category="list-text">登录到Oracle服务器VM并使用sqlplus运行数据库恢复。</block>
  <block id="8ad5254ade1fed8d3ccc482196b4c36c" category="paragraph">此屏幕显示已删除的表已使用本地快照备份进行恢复。</block>
  <block id="0c55b956af322a2409f5dd75af116fee" category="doc">WP-7357：《在EC2和FSX上部署Oracle数据库最佳实践》简介</block>
  <block id="b985336298cf9391b91c898572090625" category="summary">本节介绍使用Azure虚拟机和Azure NetApp Files 存储的Oracle数据库部署和数据保护解决方案 架构。</block>
  <block id="91e17bfb5f535513b5320d68f6afe1fc" category="paragraph">以下架构图展示了在Azure VM实例和Azure NetApp Files 存储上部署高可用性Oracle数据库的情况。</block>
  <block id="520c5c426000f1dbbd8ac385d5547603" category="paragraph">在环境中、Oracle计算实例通过Azure服务VM控制台进行部署。控制台提供了多种Azure实例类型。NetApp建议部署一个面向数据库的Azure VM实例、以满足您的预期工作负载。</block>
  <block id="9e20ded809aa2fa1bd072f48ceacfdd8" category="paragraph">另一方面、Oracle数据库存储则通过Azure控制台提供的Azure NetApp Files 服务进行部署。随后、Oracle二进制卷、数据卷或日志卷将显示并挂载到Azure VM实例Linux主机上。</block>
  <block id="6b5cae77dbc9c4b759bf654b117eb10b" category="inline-image-macro">此图显示了主站点、备用站点和每个站点的vNet对等之间的关系。这构成了四个独立的虚拟网络。</block>
  <block id="2246b51fdf61c77213e0ce37d743cd03" category="paragraph"><block ref="2246b51fdf61c77213e0ce37d743cd03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03aa17a1290e1122adecd07d53463cde" category="paragraph">在许多方面、在Azure云中实施Azure NetApp Files 与具有许多内置冗余功能(例如RAID和双控制器)的内部ONTAP 数据存储架构非常相似。对于灾难恢复、可以在不同区域设置备用站点、并且可以使用应用程序级复制(例如Oracle Data Guard)将数据库与主站点同步。</block>
  <block id="6f1714a5ced243b141295d01d4038364" category="paragraph">在我们对Oracle数据库部署和数据保护进行的测试验证中、Oracle数据库部署在一个Azure虚拟机上、如下图所示：</block>
  <block id="fef3344ae2f384e724a169b6e9d90be7" category="inline-image-macro">此图显示了一个Azure虚拟机的组织结构、该虚拟机采用vNet对等关系来创建两个单独的虚拟网络。</block>
  <block id="f3699a22a9267b8e767816c81f821522" category="paragraph"><block ref="f3699a22a9267b8e767816c81f821522" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69cf5342936c24c9fac1c6529c4f825f" category="paragraph">Azure Oracle环境可通过Ansible控制器节点进行管理、以便使用NetApp提供的用于数据库部署、备份、恢复和数据库迁移的工具包实现自动化。可以并行执行对Oracle Azure VM实例操作系统内核或Oracle修补的任何更新、以使主系统和备用系统保持同步。事实上、初始工具包可以轻松扩展、以便在需要时执行日常Oracle任务。如果您需要有关设置CLI Ansible控制器的帮助、请参见 <block ref="03bbd03f7d2552fa2076b42f86a04360" category="inline-link-macro-rx"></block> 开始使用。</block>
  <block id="41f2543265fcbcf566ce925409c1bfbb" category="summary">本节详细介绍了如何将Oracle数据库从内部迁移到Azure NetApp Files 、反之亦然。</block>
  <block id="3b99478aefcc6039ddcb29f19ce3f1ee" category="doc">将数据库从内部迁移到Azure云</block>
  <block id="3c2b924258f32094eb64883db57a778a" category="paragraph">由于Oracle决定逐步淘汰单实例数据库、许多组织已将单实例Oracle数据库转换为多租户容器数据库。这样、可以使用最大可用性选项将一组称为PDB的容器数据库轻松地重新定位到云、从而最大限度地减少迁移期间的停机时间。</block>
  <block id="a221bb2d4b0b28bb7e9aa40527e36333" category="paragraph">但是、如果您仍有一个Oracle数据库实例、则可以先将其转换为多租户容器数据库、然后再尝试PDB重新定位。</block>
  <block id="3312d9383c6e42558bb6c7ffa86498b5" category="paragraph">以下各节详细介绍了在这两种情况下将内部Oracle数据库迁移到Azure云的相关信息。</block>
  <block id="d7acbe14b605ece64e94636c2ac85151" category="section-title">将单个实例非CDB转换为多租户CDB中的PDB</block>
  <block id="b65ba7cc82289837e3a44b6025b8a104" category="paragraph">如果您仍有单实例Oracle数据库、则无论是否要将其迁移到云、都必须将其转换为多租户容器数据库、因为Oracle不久将停止支持单实例数据库。</block>
  <block id="60a4157f0722b484d4ce9ec02662db31" category="paragraph">以下过程会将单个实例数据库作为可插拔数据库或PDB插入容器数据库。</block>
  <block id="aefccbe3e9382cbdd83d84fee06a408d" category="list-text">在与单实例数据库相同的主机上单独构建Shell容器数据库<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>。</block>
  <block id="182e093a477c76844c12680be3deb7a4" category="list-text">关闭单个实例数据库并在只读模式下重新启动它。</block>
  <block id="48270a516aeb2dd47c2b7f5d897c3182" category="list-text">运行<block ref="707fc638546e97f4dca068fcf2fbe277" prefix=" " category="inline-code"></block> 用于生成数据库元数据的操作步骤。</block>
  <block id="61c2d2d903cc3e2bc374cc66b3a1572d" category="list-text">关闭单实例数据库。</block>
  <block id="d0e90ac40083de7010746f1c7afa8680" category="list-text">启动容器数据库。</block>
  <block id="c9b14b140c5af8df85a71e71e823fcd9" category="list-text">运行<block ref="6f6e7bfe46efb74f46338dcd4b8d7530" prefix=" " category="inline-code"></block> 用于确定非CDB是否与CDB兼容的函数。</block>
  <block id="b4579eff709cfd4a9e9d9b3c7823a470" category="paragraph">如果输出为Yes、则表示非CDB兼容、您可以继续执行下一步。</block>
  <block id="b788542aadbeda07cae67fad51f01ecf" category="paragraph">如果输出为no、则表示非CDB不兼容、您可以检查<block ref="40bcd9431704d488bfba8de25bdd0469" prefix=" " category="inline-code"></block> 查看其不兼容的原因。必须先更正所有违规、然后才能继续。例如、任何版本或修补程序不匹配的问题都应通过运行升级或opatch实用程序来解决。更正违规后、运行<block ref="6f6e7bfe46efb74f46338dcd4b8d7530" prefix=" " category="inline-code"></block> 再次确认、以确保非CDB与CDB兼容。</block>
  <block id="3dc81f6d88ee2f38ca30676e4b371634" category="list-text">插入单个实例非CDB。</block>
  <block id="10a9ce9a6e151e6ff04bee976e0cb1de" category="admonition">如果主机上没有足够的空间、则<block ref="4777c7eb130280b37f5b4b3abde7c586" prefix=" " category="inline-code"></block> 选项可用于创建PDB。在这种情况下、单实例非CDB在作为PDB插入后不可用、因为PDB已使用原始数据文件。请确保在转换之前创建备份、以便在发生任何错误时可以恢复运行。</block>
  <block id="03d9f2c68151dce9edd03b346e5b110c" category="list-text">如果源单实例非CDB与目标CDB之间的版本不同、则在转换后开始PDB升级。对于相同版本的转换、可以跳过此步骤。</block>
  <block id="81954d0087f2bc7590c39792b2d3ff79" category="paragraph">查看中的升级日志文件<block ref="8940bd010306ed7bc730469a2815003c" prefix=" " category="inline-code"></block> 目录。</block>
  <block id="65f9a981d9b9caaa37a227c9d787c280" category="list-text">打开可插拔数据库、检查PDB插件违规、然后重新编译无效对象。</block>
  <block id="f4d5586e12195159e664b1f0a78cccd3" category="list-text">执行<block ref="30636d635a272a80dff68679e08f1c7a" prefix=" " category="inline-code"></block> 更新数据词典。</block>
  <block id="182d7c995640cc8ef16b728a670fbe58" category="paragraph">关闭并重新启动容器数据库。ndb已退出受限模式。</block>
  <block id="d6af386b8be94481db3de6778b3fc24a" category="section-title">通过PDB重新定位将内部Oracle数据库迁移到Azure</block>
  <block id="a8efacce1c06e5f64504448dec25740a" category="list-text">在Azure公共云中使用相同版本和修补程序级别在Azure虚拟机上创建CDB。</block>
  <block id="0f09a4e81820f79a89d0b433bb0de6ca" category="list-text">从Ansible控制器克隆自动化工具包的副本。</block>
  <block id="33abd0ac6a3fb7ef8c104725e8360e85" category="list-text">阅读README文件中的说明。</block>
  <block id="59082266ab8171963eb8785041055ee1" category="list-text">为源和目标Oracle服务器配置Ansible主机变量文件、并为数据库服务器主机的配置文件配置名称解析。</block>
  <block id="166811e58fa2fd17b3ab3305ca4b1948" category="list-text">在Ansible控制器上安装Ansible控制器前提条件。</block>
  <block id="e40dd1f176a77cef20eb421dee4fea9f" category="list-text">对内部服务器执行任何迁移前任务。</block>
  <block id="aba7f3209eb8c49aca729c7368fb42fe" category="admonition">admin用户是内部Oracle服务器主机上具有sudo权限的管理用户。管理员用户使用密码进行身份验证。</block>
  <block id="a1da14dd2e192d36a7fe7bae327c2b23" category="list-text">执行从内部环境到目标Azure Oracle主机的Oracle PDB重新定位。</block>
  <block id="39f1871870cabd138bd313c450662e67" category="admonition">Ansible控制器可以位于内部或Azure云中。控制器需要连接到内部Oracle服务器主机和Azure Oracle VM主机。内部Oracle服务器主机和Azure Oracle VM主机之间的Oracle数据库端口(如1521)处于打开状态。</block>
  <block id="63a48a0f7ee4b39ef32c11b92acc2baa" category="section-title">其他Oracle数据库迁移选项</block>
  <block id="7619081ba13aebf0c83d5660f9bf01bb" category="inline-link-macro">Oracle数据库迁移决策过程</block>
  <block id="0257ad9cf0c221fcf0c611f835c027ca" category="paragraph">有关其他迁移选项、请参见Microsoft文档： <block ref="421a85ebca6e289a6eff559e7e35faf8" category="inline-link-macro-rx"></block>。</block>
  <block id="a73e5c65844b18c49122a8a79ef3fa65" category="doc">Azure VM和Azure NetApp Files 上的Oracle分步部署过程</block>
  <block id="cf2fb9f52eae11aaa1b6818cc22ade30" category="section-title">通过Azure门户控制台使用适用于Oracle的ANF部署Azure虚拟机</block>
  <block id="5e89dc82cb54763baa7cece42e7c3189" category="paragraph">如果您是Azure的新用户、则首先需要设置Azure帐户环境。这包括注册您的组织以使用Azure Active Directory。以下部分总结了这些步骤。有关详细信息、请参见特定于Azure的链接文档。</block>
  <block id="c743c9c56cd6cc2acf874405ef178af3" category="section-title">创建和使用Azure资源</block>
  <block id="cc59653114a0ca329e90c87f8de8f2da" category="paragraph">设置Azure环境并创建帐户并将其与订阅关联后、您可以使用帐户登录到Azure门户以创建运行Oracle所需的资源。</block>
  <block id="4848dfd418cc69fdc8a92da472ac41b8" category="section-title">1.创建虚拟网络或vNet</block>
  <block id="dd587303db328c6fc30f15fbf133eade" category="paragraph">Azure虚拟网络(vNet)是Azure中专用网络的基本组件。VNet支持Azure虚拟机(VM)等多种类型的Azure资源安全地相互通信、并与Internet和内部网络进行通信。在配置Azure VM之前、必须先配置vNet (部署VM的位置)。</block>
  <block id="2b9029fce84bbf7056c94e4b86015679" category="inline-link-macro">使用Azure门户创建虚拟网络</block>
  <block id="698a842fc17e080abbf6b6796628879b" category="paragraph">请参见 <block ref="f497c9708f9505977884a23053323735" category="inline-link-macro-rx"></block> 创建vNet。</block>
  <block id="66d98f4e89afee6dc557332b0e9ebe43" category="section-title">2.为ANF创建NetApp存储帐户和容量池</block>
  <block id="fecd60b0aedf111caefb4cf98b8d7be5" category="paragraph">在此部署场景中、Azure VM操作系统使用常规Azure存储进行配置、但ANF卷配置为通过NFS运行Oracle数据库。首先、您需要创建NetApp存储帐户和容量池来托管存储卷。</block>
  <block id="76dc01e3f39d83b88a3d3ad36c338654" category="inline-link-macro">设置Azure NetApp Files 并创建NFS卷</block>
  <block id="8a57d5f988c678cd141c2f704e110472" category="paragraph">请参见 <block ref="2337ae471c0cc5402cdba65ad3b4dc78" category="inline-link-macro-rx"></block> 设置ANF容量池。</block>
  <block id="ed39ba49be7769bdf483ae876d88cdff" category="section-title">3.为Oracle配置Azure VM</block>
  <block id="acb4908e71af4ce0945c90f9039d0fc2" category="paragraph">根据您的工作负载、确定您需要哪种类型的Azure VM以及要为Oracle部署的VM vCPU和RAM的大小。然后、在Azure控制台中、单击虚拟机图标以启动虚拟机部署工作流。</block>
  <block id="20d1e12ba2a72916f3917e44ff29b40a" category="list-text">在Azure VM页面中、单击*创建*、然后选择* Azure虚拟机*。</block>
  <block id="94f088d23454b3c408a17cfff3cb8989" category="inline-image-macro">此屏幕截图显示了可用Azure虚拟机的列表。</block>
  <block id="e28fc410c2020dcbd93af60f3d700d99" category="paragraph"><block ref="e28fc410c2020dcbd93af60f3d700d99" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78ba4b8df4acae5536f056217b16c353" category="list-text">选择部署的订阅ID、然后选择资源组、区域、主机名、VM映像、大小、和身份验证方法。转到磁盘页面。</block>
  <block id="cbbcba216ab68f94c8fab62d9c907a00" category="inline-image-macro">此屏幕截图显示了"Create a Virtual Machine"页面的输入。</block>
  <block id="825d4c0973e48f04ab75cc30df85bbdc" category="inline-image-macro">此屏幕截图显示了"Create a Virtual Machine"页面的其他输入。</block>
  <block id="84982a7e7b9cc89bde9621d68800978e" category="paragraph"><block ref="a493253d19b28a6711494154a3160350" category="inline-image-macro-rx" type="image"></block>
<block ref="81b338659efc8df55ae98546f396c5b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c435f9a03a03e7cff44b06c9efafa31" category="list-text">选择*高级SSD*以实现操作系统本地冗余、并将数据磁盘留空、因为数据磁盘是从ANF存储挂载的。转到网络连接页面。</block>
  <block id="04faa74bfe9ea34a9831d24d039dc159" category="inline-image-macro">此屏幕截图显示了"Create a Virtual Machine Disks"页面的输入。</block>
  <block id="2e21daafaa3607d62dda1a3411975b12" category="paragraph"><block ref="2e21daafaa3607d62dda1a3411975b12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9c5742f2bffff7dd4a50e578bfb093b" category="list-text">选择vNet和子网。为外部VM访问分配公共IP。然后转到"管理"页面。</block>
  <block id="0c0077e9a9d4700a64e70d30e9d110df" category="inline-image-macro">此屏幕截图显示了创建虚拟机页面的其他输入。</block>
  <block id="4aea6dbf72aa0b36bd98ced95acebcbd" category="paragraph"><block ref="4aea6dbf72aa0b36bd98ced95acebcbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5e4bb7568c6e8fb6a1f49aea08e975" category="list-text">保留Management的所有默认值、然后转到Advanced页面。</block>
  <block id="45291c6293e8de1084c3b8de71bfe120" category="inline-image-macro">此屏幕截图显示了"Create a Virtual Machine Management"页面的输入。</block>
  <block id="b031dac11379aafec2eb9832f71648ba" category="paragraph"><block ref="b031dac11379aafec2eb9832f71648ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22b5d3beb0289dfe21618d5664538321" category="list-text">保留"高级"页面的所有默认值、除非您需要在使用自定义脚本部署后自定义VM。然后转到"标记"页面。</block>
  <block id="1a911a2f1237ad150a29236bcfe044a0" category="inline-image-macro">此屏幕截图显示了"Create a Virtual Machine Advanced"页面的输入。</block>
  <block id="00d8612fb98dc237476c6ecd9e0f52c9" category="paragraph"><block ref="00d8612fb98dc237476c6ecd9e0f52c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46dfe2059392afeb84a872afb7cd09d5" category="list-text">如果需要、为虚拟机添加一个标记。然后、转到Review + create页面。</block>
  <block id="85e3843de649be49b63e3b04c6887bcd" category="inline-image-macro">此屏幕截图显示了"Create a Virtual Machine Tags "页面的输入。</block>
  <block id="ddeecdecd575fb71cf4e83d7f09717bc" category="paragraph"><block ref="ddeecdecd575fb71cf4e83d7f09717bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57a6346e9ebfe8164361d5e2facffb62" category="list-text">部署工作流将对配置运行验证、如果验证通过、请单击*创建*以创建虚拟机。</block>
  <block id="dec1fd75845506029d8751bb7979c797" category="inline-image-macro">"此屏幕截图显示了"Create a Virtual Machine review and create"页面的输入。</block>
  <block id="786b4cd98c208b72f71277850831c1aa" category="paragraph"><block ref="786b4cd98c208b72f71277850831c1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c18c3fe2e695bda0cb8b3e7ecccbdc4e" category="section-title">4.为Oracle配置ANF数据库卷</block>
  <block id="f162c2b2b89920293c1f24ac435c520e" category="paragraph">您必须分别为Oracle二进制卷、数据卷和日志卷的ANF容量池创建三个NFS卷。</block>
  <block id="09d8c19d5844128b31e1fa195808b215" category="list-text">在Azure控制台中的Azure服务列表下、单击Azure NetApp Files 以打开卷创建工作流。如果您有多个ANF存储帐户、请单击要从中配置卷的帐户。</block>
  <block id="733cf6b848c8e38a49b4b604225141a5" category="inline-image-macro">此屏幕截图显示了Azure服务页面、其中ANF突出显示。</block>
  <block id="cc553796f259bc80d8c801687c0c1cd0" category="paragraph"><block ref="cc553796f259bc80d8c801687c0c1cd0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8972cd5a80e6e385a27023ce45537a9" category="list-text">在NetApp存储帐户下、单击*卷*、然后单击*添加卷*以创建新的Oracle卷。</block>
  <block id="c8ce9170654447aba6747494e61bf3a2" category="inline-image-macro">此屏幕截图显示了NetApp存储帐户的登录屏幕。</block>
  <block id="b0d2d575f2aee1703b6e2896d43b72f9" category="inline-image-macro">此屏幕截图显示了可用于NetApp存储帐户的卷。</block>
  <block id="3371cc932d04403ab2cd0788634d63e5" category="paragraph"><block ref="7266705f76a6cb3a106c34a6e8dc5540" category="inline-image-macro-rx" type="image"></block>
<block ref="f59831fbf7eaa0d216e8685698d0c55b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbeaec71dc2b8275a14b23283d51cc04" category="list-text">作为一种良好做法、请先确定使用VM主机名作为前缀的Oracle卷、然后再确定主机上的挂载点、例如、对于Oracle二进制文件、可以使用u01表示Oracle数据、可以使用u02表示Oracle数据、也可以使用u03表示Oracle日志。为卷选择与VM相同的vNet。单击*下一步：协议&gt;*。</block>
  <block id="ce4ff1bdb6d954e6967a7c241ff89518" category="inline-image-macro">卷创建屏幕。</block>
  <block id="bacf4983022360caacd6f75352136f59" category="paragraph"><block ref="bacf4983022360caacd6f75352136f59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b50bdcda066df8ed373847c60bc2f546" category="list-text">选择NFS协议、将Oracle主机IP地址添加到允许的客户端、然后删除允许所有IP地址0.0.0.0/0的默认策略。然后单击*下一步：标记&gt;*。</block>
  <block id="f8bc211f91c2b350b268959a57418393" category="inline-image-macro">卷创建屏幕上的协议输入。</block>
  <block id="8ac138d8c4a217ce018b45be622db1ed" category="paragraph"><block ref="8ac138d8c4a217ce018b45be622db1ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fffcdc9cd5233d4718046c8f6d19c80b" category="list-text">根据需要添加卷标记。然后单击*审阅+创建&gt;*。</block>
  <block id="05864b350d713935d13966f3c8fcbcd7" category="inline-image-macro">卷创建屏幕上的标记输入。</block>
  <block id="9bead8568a27fcf83faf41e77f52b246" category="paragraph"><block ref="9bead8568a27fcf83faf41e77f52b246" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e574c0c875926f1fe654026995f3543" category="list-text">如果验证通过、请单击*创建*以创建卷。</block>
  <block id="4a585922412f050ac4a7fbcc34a2655b" category="inline-image-macro">查看并创建卷创建屏幕的阶段。</block>
  <block id="e9c713f1ad3a3f0b14801d722fb77f16" category="paragraph"><block ref="e9c713f1ad3a3f0b14801d722fb77f16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d2dbc217706d8bb1248bc209e0ab9da" category="section-title">使用ANF在Azure虚拟机上安装和配置Oracle</block>
  <block id="7beaf3d9487c79b7245a1d9ae42d46aa" category="paragraph">NetApp解决方案团队创建了许多基于Ansible的自动化工具包、可帮助您在Azure中顺利部署Oracle。按照以下步骤在Azure虚拟机上部署Oracle。</block>
  <block id="0c782f45b1de4e6d016eafeeb60d286f" category="section-title">设置Ansible控制器</block>
  <block id="58a105c56c05508f7233082bc282a654" category="paragraph">如果尚未设置Ansible控制器、请参见 <block ref="03bbd03f7d2552fa2076b42f86a04360" category="inline-link-macro-rx"></block>、其中详细说明了如何设置Ansible控制器。</block>
  <block id="ce9ef6052d2c6ac4b97c01049ee4ec2b" category="section-title">获取Oracle部署自动化工具包</block>
  <block id="52eae91ee8ea917bc73df6d9f1792469" category="paragraph">在您的主目录中、使用您用于登录到Ansible控制器的用户ID克隆一份Oracle部署工具包副本。</block>
  <block id="19cd6e3dfb797a7325548b346dc358f1" category="section-title">根据您的配置执行工具包</block>
  <block id="aa98393908153ea46a2cef869e7dd100" category="paragraph">请参见 <block ref="e7ab084e08308da08da1b2dd8151530b" category="inline-link-macro-rx"></block> 使用命令行界面执行攻略手册。从Azure控制台而非命令行界面创建数据库卷时、您可以忽略全局VARS文件中变量配置的ONTAP 部分。</block>
  <block id="24e16cc700e2ced028e529370af380e1" category="admonition">该工具包默认部署Oracle 19c和RU 19.8。它可以轻松地适应任何其他修补程序级别、并对默认配置进行少量更改。此外、默认的种子数据库活动日志文件也会部署到数据卷中。如果需要日志卷上的活动日志文件、应在初始部署后重新定位。如有必要、请联系NetApp解决方案 团队以获得帮助。</block>
  <block id="dd52a71d2066e527d28efdbd46784e07" category="section-title">为Oracle的应用程序一致快照设置AzAcSnap备份工具</block>
  <block id="211e60df4f320c617afaa9a96f62758f" category="paragraph">Azure应用程序一致的Snapshot工具(AzAcSnap)是一个命令行工具、可通过处理在创建存储快照之前将第三方数据库置于应用程序一致状态所需的所有流程编排来为第三方数据库提供数据保护。然后、它会将这些数据库返回到运行状态。NetApp建议在数据库服务器主机上安装此工具。请参见以下安装和配置过程。</block>
  <block id="40390144ce134a2e38bfef9f590f867b" category="section-title">安装AzAcSnap工具</block>
  <block id="c2d834909e264a2f3bf3d3facd27740b" category="inline-link-macro">AzArcSnap安装程序</block>
  <block id="aed9be57adbc2906c27b7f325e1322aa" category="list-text">获取的最新版本 <block ref="696590d44d21e9b71649cae0895a0bca" category="inline-link-macro-rx"></block>。</block>
  <block id="243004130aa732bde904924170fa2e5c" category="list-text">将下载的自安装程序复制到目标系统。</block>
  <block id="1aa45c54511185e4e2043ee91e8969bc" category="list-text">使用默认安装选项以root用户身份执行自安装程序。如有必要、请使用使文件可执行<block ref="48c01707d676030dd223de543c6beb09" prefix=" " category="inline-code"></block> 命令：</block>
  <block id="483944250a0e1f955ad6fec7c6578bde" category="section-title">配置Oracle连接</block>
  <block id="b6f7df8a3ada5b45cee3400740b83c9a" category="paragraph">快照工具与Oracle数据库进行通信、并且需要具有适当权限的数据库用户来启用或禁用备份模式。</block>
  <block id="6cd11918e51f60b6ce021e9d56c9e74a" category="section-title">1.设置AzAcSnap数据库用户</block>
  <block id="84fe6666ea577b7ede5c61912d97705e" category="paragraph">以下示例显示了Oracle数据库用户的设置以及使用sqlplus与Oracle数据库进行通信。示例命令用于在Oracle数据库中设置用户(AZACSNAP)、并根据需要更改IP地址、用户名和密码。</block>
  <block id="342df2b2fb63c81cdd53e5e7bc5d00b9" category="list-text">在Oracle数据库安装中、启动sqlplus以登录到数据库。</block>
  <block id="ab0840eee4ba613870ae404c907c1948" category="list-text">创建用户。</block>
  <block id="e90b9dc19df07f784e3fc408169077df" category="list-text">授予用户权限。此示例设置了AZACSNAP用户启用将数据库置于备份模式的权限。</block>
  <block id="f508d634fc1aa5df7fed84e6b58afce9" category="list-text">将默认用户的密码到期时间更改为无限制。</block>
  <block id="bc5fff092e99ce3d1966b94061cb5953" category="list-text">验证数据库的azacsnap连接。</block>
  <block id="8e0d0fb1cb3a50066ecd397700dfd22e" category="section-title">2.使用Oracle Wallet为数据库访问配置Linux用户azacsnap</block>
  <block id="7140a904f4b795616fdc3c3efbdcd066" category="paragraph">AzAcSnap默认安装会创建一个azacsnap操作系统用户。必须使用存储在Oracle Wallet中的密码为其Bash shell环境配置Oracle数据库访问。</block>
  <block id="c54cf7bb99b0e669ce6dc05ec8272470" category="list-text">以root用户身份运行<block ref="760381f8107a856bc583301b7b272917" prefix=" " category="inline-code"></block> 用于标识主机上的ORACLE_HOME和ORACLE_SID变量的命令。</block>
  <block id="2a4941dc3f20c8f34a09b066691e66a5" category="list-text">将ORACLE_HOME、ORACLE_SID、TNS_admin和路径变量添加到azacsnap用户bash配置文件中。根据需要更改变量。</block>
  <block id="e3c85fad3d30c470aac355430e98dc21" category="list-text">作为Linux用户azacsnap、创建电子钱包。系统将提示您输入电子邮件密码。</block>
  <block id="83617bd12022f2dd9ba94816c7e56670" category="list-text">将连接字符串凭据添加到Oracle Wallet。在以下示例命令中、AZACSNAP是AzAcSnap要使用的ConnectString、azacsnap是Oracle数据库用户、AzPasswd1是Oracle用户的数据库密码。系统会再次提示您输入电子邮件密码。</block>
  <block id="02f08719de6240015b4e67725107792a" category="list-text">创建<block ref="9de875b13677cf9b036a438bf9aedf5c" prefix=" " category="inline-code"></block> 文件在以下示例命令中、应将主机设置为Oracle数据库的IP地址、并将服务器SID设置为Oracle数据库SID。</block>
  <block id="0eec77cc5ed96c42afb08c83ea3f1e3b" category="list-text">创建<block ref="0501c2d94325e267bf15055591fb8157" prefix=" " category="inline-code"></block> 文件</block>
  <block id="cafefcc0e796f3e73bc39de23dfc6b68" category="list-text">使用Wallet测试Oracle访问。</block>
  <block id="54eb020b97d7e8a9f56d67e93754e270" category="section-title">配置ANF连接</block>
  <block id="8c9356aaf30e863db064ba22b7d4b204" category="paragraph">本节介绍如何启用与Azure NetApp Files (与VM)的通信。</block>
  <block id="d78964ac0334c0f69ef24aada9864028" category="list-text">在Azure Cloud Shell会话中、确保您已登录到默认要与服务主体关联的订阅。</block>
  <block id="8611ff0fcccf2f05ff0dbde909379c14" category="list-text">如果订阅不正确、请使用以下命令：</block>
  <block id="2d66e076b40e24c73ffa7a1704d985db" category="list-text">使用Azure命令行界面创建服务主体、如以下示例所示：</block>
  <block id="707cc085819c641d15b9ea2b3b13cb53" category="paragraph">预期输出：</block>
  <block id="c51a1e8c830ed4f63c489347dbcce1a7" category="list-text">剪切输出内容并将其粘贴到名为的文件中<block ref="b50999884a39c5efe8da46cd87acfeb2" prefix=" " category="inline-code"></block> 存储在Linux用户azacsnap用户箱目录中、并使用适当的系统权限保护文件。</block>
  <block id="211f39ae9cd979a9f01bb800eca0b832" category="admonition">请确保JSON文件的格式与上述格式完全相同、尤其是使用双引号(")括起的URL。</block>
  <block id="c1f6adfa882cba0dbd256d4909ac588c" category="section-title">完成AzAcSnap工具的设置</block>
  <block id="e0e7b63ff02eb3221940162934949dd0" category="paragraph">按照以下步骤配置和测试快照工具。成功测试后、您可以执行第一个数据库一致的存储快照。</block>
  <block id="fe615094ac9bb468d26149280e3769d7" category="list-text">更改为Snapshot用户帐户。</block>
  <block id="4ef9af49185e683998d060aa71c30e2b" category="list-text">更改命令的位置。</block>
  <block id="412d274adbc3fc7cb51ab315d7a77f82" category="list-text">配置存储备份详细信息文件。这将创建<block ref="8ed8c6bfea85d72bc4a36772490109c7" prefix=" " category="inline-code"></block> 配置文件。</block>
  <block id="d4c18f094b4959d27f52ee2a9709a6b9" category="paragraph">三个Oracle卷的预期输出：</block>
  <block id="72b0a1cda785576a979ca4ee2e3c8c62" category="list-text">以azacsnap Linux用户身份、对Oracle备份运行azacsnap test命令。</block>
  <block id="7be23e8f29bfc799fd8fbcdc55fe0e77" category="list-text">运行第一个快照备份。</block>
  <block id="87561d435f6cd79a59659b543d2991ca" category="summary">本节介绍了一个RDS Oracle自定义部署解决方案 架构、其中包含自定义的Oracle RDS和FSX ONTAP 存储。</block>
  <block id="312f941d9e8f224f54ae372016e8f35a" category="paragraph">在环境中、Oracle计算实例通过AWS EC2实例控制台进行部署。控制台提供了多种EC2实例类型。NetApp建议使用RedHat Enterprise Linux 8部署面向数据库的EC2实例类型、例如M5 Ami映像以及高达10Gps的网络带宽。</block>
  <block id="830579b4d0c33e9e4fa1f11c61cb73a7" category="inline-image-macro">此图显示了一个架构图示例、其中包括主HA集群-备用HA集群-管理节点以及相关连接节点。</block>
  <block id="73793421735093db194ae82163f894b3" category="paragraph"><block ref="73793421735093db194ae82163f894b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3d0f7ae75ed6e0e3b522ecc7cac710b" category="paragraph">FSX存储集群采用双冗余设计、因此主存储集群和备用存储集群都部署在两个不同的可用性区域中。对于所有Oracle二进制卷、数据卷和日志卷、数据库卷会按用户可配置的间隔从主FSX集群复制到备用FSX集群。</block>
  <block id="0008c12bed67fcf1f82ece8ff10b5c81" category="paragraph">此高可用性Oracle环境可通过Ansible控制器节点以及SnapCenter 备份服务器和UI工具进行管理。Oracle安装、配置和复制可使用基于Ansible攻略手册的工具套件实现自动化。可以并行执行对Oracle EC2实例内核操作系统或Oracle修补的任何更新、以使主系统和备用系统保持同步。事实上、初始自动化设置可以轻松地进行扩展、以便在需要时执行某些重复的日常Oracle任务。</block>
  <block id="1572d96530c843cddbe2d0a8b47abf8a" category="summary">本最佳实践指南详细介绍了在Azure NetApp文件存储和Azure VM上部署和保护Oracle数据库的解决方案。</block>
  <block id="2e0520fcae6cb49914d2308fbaf4e1a8" category="doc">TR-4954：《Azure NetApp Files 上的Oracle数据库部署和保护》</block>
  <block id="7e6f7643afec42d9c47efa933debef3e" category="paragraph">NetApp公司Allen Cao、Niyaz Mohamed</block>
  <block id="b2bd5134cf9b573edd93cbfe6ee4559d" category="paragraph">许多任务关键型Oracle企业数据库仍托管在内部、许多企业都希望将这些Oracle数据库迁移到公共云。这些Oracle数据库通常以应用程序为中心、因此需要用户专用配置、而许多数据库即服务公共云产品都缺少这一功能。因此、当前的数据库环境要求基于公共云的Oracle数据库解决方案 、该数据库是基于高性能、可扩展的计算和存储服务构建的、可满足独特的需求。Azure虚拟机计算实例和Azure NetApp Files 存储服务可能是这一难题中缺少的部分、您可以利用它构建任务关键型Oracle数据库工作负载并将其迁移到公共云。</block>
  <block id="a58dc8965e4de69beb97a33a5a1935ea" category="paragraph">Azure虚拟机是Azure提供的多种按需、可扩展计算资源之一。通常、如果您需要比其他选项更好地控制计算环境、则可以选择虚拟机。Azure虚拟机提供了一种快速简单的方法来创建运行Oracle数据库所需的特定配置的计算机、无论该数据库是用于计算密集型工作负载还是内存密集型工作负载。Azure虚拟网络中的虚拟机可以轻松连接到您组织的网络、例如、通过安全的VPN通道。</block>
  <block id="466d154dd31c873c4a2fd7113dc6b818" category="paragraph">Azure NetApp Files 是一项完全受管的Microsoft服务、它可以让您的数据库工作负载以前所未有的速度更安全地迁移到云中。它旨在满足在云中运行高性能工作负载(例如Oracle数据库)的核心要求、并提供了能够反映实际IOPS需求范围、低延迟、高可用性、高持久性、大规模易管理性的性能层。以及快速高效的备份、恢复和克隆。之所以能够提供这些功能、是因为Azure NetApp Files 基于在Azure数据中心环境中运行的物理全闪存NetApp ONTAP 系统。Azure NetApp Files 完全集成到Azure DC和门户中、客户可以使用与任何其他Azure对象相同的舒适图形界面和API来创建和管理共享文件。借助Azure NetApp文件、您可以在不增加风险、成本或时间的情况下充分发挥Azure的全部功能、并信任Azure自带的唯一企业级文件服务。</block>
  <block id="30106aaa3e986f62cbb327f935569bca" category="inline-link-macro">Microsoft Azure上的Oracle数据库</block>
  <block id="bdb41d103336edebf957f48add0f3554" category="inline-link-macro">NetApp-Automation</block>
  <block id="c2add34b573ef3798dd7c5b8972c008a" category="paragraph">本文档详细介绍了如何使用Azure虚拟机和Azure NetApp Files 存储服务部署、配置和保护Oracle数据库、该服务可提供与内部系统类似的性能和持久性。有关最佳实践指导、请参见TR-4780 <block ref="43d70d3cb7600babfb5820086b5480b6" category="inline-link-macro-rx"></block>。更重要的是、NetApp还提供了自动化工具包、可自动执行在Azure公共云中部署、配置、数据保护、迁移和管理Oracle数据库工作负载所需的大部分任务。这些自动化工具包可从NetApp公共GitHub站点下载： <block ref="1b9adaed0e4ba13a6d8f6edc7ab8f2d8" category="inline-link-macro-rx"></block>。</block>
  <block id="cffc2899d8dda4926e6563cef4e76608" category="summary">本节详细介绍了在Azure虚拟机和Azure NetApp Files 存储上部署Oracle数据库时需要考虑的因素。</block>
  <block id="1a6a6241c0105da34f664d1e12534598" category="paragraph">以下各节介绍在采用Azure NetApp Files 存储的Azure虚拟机实例上的Azure公共云中部署Oracle数据库时的主要注意事项。</block>
  <block id="c2b3b1e82aa97a133f0f6bbc12843085" category="section-title">VM类型和规模估算</block>
  <block id="4ca9712a9cd82ea80c8e225977fae1bb" category="inline-link-macro">Azure中虚拟机的大小</block>
  <block id="7c4a17715675ccfa7ce507eea6098318" category="paragraph">选择合适的VM类型和大小对于优化公共云中关系数据库的性能非常重要。Azure虚拟机提供了各种计算实例、可用于托管Oracle数据库工作负载。请参见Microsoft文档 <block ref="d854faa84ea41d8819c42ca3741a3561" category="inline-link-macro-rx"></block> 不同类型的Azure虚拟机及其规模估算。一般来说、NetApp建议使用通用Azure虚拟机来部署中小型Oracle数据库。对于部署大型Oracle数据库、适合使用经过内存优化的Azure VM。利用更多可用RAM、可以配置更大的Oracle SGA或智能闪存缓存、以减少物理I/O、进而提高数据库性能。</block>
  <block id="84942a15b69259aab0ff7c2620afcaf6" category="inline-link-macro">TR-4780：Microsoft Azure上的Oracle数据库</block>
  <block id="760a7b6c1bd4f6ebab6918d42feb4825" category="paragraph">Azure NetApp Files 用作连接到Azure虚拟机的NFS挂载、可提供更高的吞吐量、并通过本地存储克服存储优化的VM吞吐量限制。因此、在Azure NetApp Files 上运行Oracle可以减少可获得许可的Oracle CPU核心数量和许可成本。请参见 <block ref="b46cbe9b7b18b9ff8101a014c206465f" category="inline-link-macro-rx"></block>第7节—Oracle许可的工作原理</block>
  <block id="71b93ac808ac25bb511ebcbb028e32e8" category="paragraph">需要考虑的其他因素包括：</block>
  <block id="592bc946b588ad0e83c05f528895bcc8" category="list-text">根据工作负载特征选择正确的vCPU和RAM组合。随着VM上的RAM大小增加、vCPU核心数也会增加。由于Oracle许可证费用是按vCPU核心数收取的、因此应在某一时刻保持平衡。</block>
  <block id="fb9844eb7ee0ff341d6f7066f78918ff" category="list-text">向VM添加交换空间。默认Azure VM部署不会创建交换空间、而交换空间对于数据库来说并不是最佳选择。</block>
  <block id="81afc696937e3786d5701212de79c536" category="section-title">Azure NetApp Files 性能</block>
  <block id="c7bc5faed38f5284386f25a6fc3a5752" category="paragraph">Azure NetApp Files 卷从客户必须在其Azure NetApp Files 存储帐户中配置的容量池中分配。每个容量池的分配如下：</block>
  <block id="3af20f4cec87eac026d0990a8a3f4169" category="list-text">定义整体性能功能的服务级别。</block>
  <block id="dd1fb66595c069d1b267fb8ca87e46eb" category="list-text">最初为此容量池配置的存储容量或分层。一种服务质量(QoS)级别、用于定义每个已配置空间的总最大吞吐量。</block>
  <block id="9dc50220b7e70511b5aeebb862346fad" category="paragraph">服务级别和初始配置的存储容量决定了特定Oracle数据库卷的性能级别。</block>
  <block id="59b8b6b998c3c0fcd2f1b107a68c290a" category="section-title">1. Azure NetApp Files 的服务级别</block>
  <block id="f02ad1a8080bf1b50f8a15cb346ed483" category="paragraph">Azure NetApp Files 支持三种服务级别："超"、"高级"和"标准"。</block>
  <block id="3eec40f71dc46b07f32031c9703968ec" category="list-text">*超存储。*此层可为分配的卷配额的每1 TiB提供高达128 MiB的吞吐量。</block>
  <block id="1b0fa75a1e8b815e03fb38f8a90d2a73" category="list-text">*高级存储。*此层分配的卷配额每1 TiB可提供高达64 MiB的吞吐量。</block>
  <block id="00792f6ec40d3e2833834d90802a7aa5" category="list-text">*标准存储。*此层可为分配的卷配额的每1 TiB提供高达16 MiB的吞吐量。</block>
  <block id="7a720602d11a97fd37964c9979e2f1a5" category="section-title">2.容量池和服务质量</block>
  <block id="36ac84521252c58a4238292bf0c21d92" category="paragraph">每个所需的服务级别都与已配置容量相关、并包括一个服务质量(QoS)级别、用于定义已配置空间的总最大吞吐量。</block>
  <block id="7a93db9cf06fd65415faf241927e2087" category="paragraph">例如、具有高级服务级别的10 TiB配置单容量池可为该容量池中的所有卷提供10倍64 MBps的整体可用吞吐量、因此、640 MBps可提供40、000 (16 K)个IOPS或80、000 (8 K)个IOPS。</block>
  <block id="18dc8b2cbfb938a0ba32c141664fba0e" category="paragraph">最小容量池大小为4 TiB。您可以根据工作负载需求的变化以1 TiB为增量更改容量池的大小、以管理存储需求和成本。</block>
  <block id="8a26494cf7b0c3c3ca7cd38e89c068eb" category="section-title">3.计算数据库卷的服务级别</block>
  <block id="9ce59559a0b99338ee0bad0c153c961a" category="paragraph">Oracle数据库卷的吞吐量限制由以下因素组合决定：卷所属容量池的服务级别以及分配给卷的配额。</block>
  <block id="b87e1c6e437216fc2d3719c3dad93cb8" category="paragraph">下图显示了如何计算Oracle数据库卷的吞吐量限制。</block>
  <block id="1624b6f83446cd1719c94bae28cbbeb7" category="inline-image-macro">此图显示了应用于三个容量层以确定总吞吐量的等式。</block>
  <block id="4d06f88a6f007c9821ac2ea5741860c5" category="paragraph"><block ref="4d06f88a6f007c9821ac2ea5741860c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ce3321601c29c87cb29ae9817843b8d" category="paragraph">在示例1中、如果容量池中的高级存储层分配了2 TiB的配额、则该卷的吞吐量限制为128 MiBps (2 TiB * 64 MiBps)。无论容量池大小或实际卷占用情况如何、此方案都适用。</block>
  <block id="69da5d3e48cc26414a9177d843bd55d9" category="paragraph">在示例2中、如果容量池中的高级存储层分配了100 GiB的配额、则该卷的吞吐量限制为6.25 MiBps (0.09765625TiB * 64 MiBps)。无论容量池大小或实际卷占用情况如何、此方案都适用。</block>
  <block id="def2c2ae4fa72ee296eada07b44a0cc9" category="paragraph">请注意、最小卷大小为100GiB。</block>
  <block id="78ad659ec79d8ee9e7432271167d18d3" category="list-text">对于小型数据库、对所有Oracle文件使用单个卷布局。</block>
  <block id="51672f1f7a65c28f28e5e113376309bd" category="inline-image-macro">此图描绘了三个数据库(DB1、DB2和DB3)、每个数据库都包含数据文件、重做日志、归档日志和控制文件、这些文件都位于一个容量池中。</block>
  <block id="6dab61143f0fe37930fbd783e5c57c81" category="paragraph"><block ref="6dab61143f0fe37930fbd783e5c57c81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="816445ad7ba016a8c0be293c985f068b" category="list-text">对于大型数据库、建议的卷布局为多个卷：一个用于Oracle数据和一个重复的控制文件、一个用于Oracle活动日志、归档日志和控制文件。NetApp强烈建议为Oracle二进制文件而不是本地驱动器分配一个卷、以便可以将数据库重新定位到新主机并快速还原。</block>
  <block id="955db4ecf8716abf17a3ea3f8e113671" category="inline-image-macro">此图显示了两个数据库、每个数据库包含两个卷。第一个卷包含数据文件、而每个数据库的第二个卷包含重做日志、归档日志和控制文件。全部位于一个容量池中。</block>
  <block id="7432b939dcc290776a34b2e9610a2775" category="paragraph"><block ref="7432b939dcc290776a34b2e9610a2775" category="inline-image-macro-rx" type="image"></block></block>
  <block id="efeaafaa286e164985a0c325f0727cf1" category="paragraph">最常见的操作系统Linux具有原生 NFS功能。Oracle提供了一个直接NFS (DNFS)客户端、该客户端本机集成到Oracle中。Oracle DNFS可绕过操作系统缓存并启用并行处理以提高数据库性能。Oracle支持NFSv3的时间已超过20年、而Oracle 12.1.0.2及更高版本支持NFSv4。</block>
  <block id="be5ef2ba2540e077db09ca784b1ac18f" category="paragraph">通过使用DNFS (自Oracle 11g起提供)、在Azure虚拟机上运行的Oracle数据库可以比本机NFS客户端驱动更多的I/O。使用NetApp自动化工具包自动部署Oracle会自动在NFSv3上配置DNFS。</block>
  <block id="632bf0b812e05925eff22d7d0a7677c2" category="paragraph">下图展示了采用Oracle DNFS的Azure NetApp Files 上的SLOB基准测试。</block>
  <block id="08826656fd88155bdfaebbb292320e33" category="inline-image-macro">此图可显著显示DNFS比KNFS可提高数据库顺序文件延迟(毫秒)。</block>
  <block id="258bafba486e8ac35578ed4c5fff8ab1" category="paragraph"><block ref="258bafba486e8ac35578ed4c5fff8ab1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24019b0d54b5da3a46b400c6a6dfee77" category="paragraph">为了获得最佳性能并防止出现性能问题、请将控制TCP插槽表的内核参数调整为128。</block>
  <block id="754e164c2de7ed1f02667d5f74297a0e" category="list-text">下表提供了单个Linux NFSv3实例的建议NFS挂载选项。</block>
  <block id="fa7abb28d1b83f9ee23d95aff1d3123b" category="inline-image-macro">此表显示了以下文件类型、控制文件、数据文件、重做日志、ORACLE_HOME、和ORACLE_BASE。</block>
  <block id="082aad17dee7d03a3d502a422c1a8c53" category="paragraph"><block ref="082aad17dee7d03a3d502a422c1a8c53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0dfaca5f0573d672a0f4dc66997c002" category="doc">EC2和FSX Oracle数据库管理</block>
  <block id="4020b36b638694a9834cb01b53b25ffe" category="doc">AWS EC2和FSX上的Oracle分步部署过程</block>
  <block id="d842058c0e8814799a596324a98e5323" category="sidebar">在AWS EC2和FSX上部署Oracle数据库最佳实践</block>
  <block id="879f2366c198b1fc05740657cacebcc1" category="sidebar">Azure NetApp Files 上的Oracle数据库部署和保护</block>
  <block id="fc305603a3cb90ea71cabdf327aaf437" category="sidebar">数据库保护</block>
  <block id="2ca630161d7251bb59a9e458ddef241c" category="paragraph"><block ref="2ca630161d7251bb59a9e458ddef241c" category="inline-link-macro-rx"></block></block>
  <block id="68a03283d8017637709e60ab77052710" category="paragraph"><block ref="68a03283d8017637709e60ab77052710" category="inline-link-macro-rx"></block></block>
  <block id="fb558936249b78a9b426ac6a575ece20" category="paragraph"><block ref="fb558936249b78a9b426ac6a575ece20" category="inline-link-macro-rx"></block></block>
  <block id="c6f1106d361e6595d08ff6340c004516" category="paragraph"><block ref="c6f1106d361e6595d08ff6340c004516" category="inline-link-macro-rx"></block></block>
  <block id="3b872d3a96131109e4700e3031e4b158" category="inline-link-macro">NVA-1155：FlexPod Datacenter上的Oracle 19c RAC数据库、采用Cisco UCS和基于FC的NetApp AFF A800</block>
  <block id="202f51b1cd08b9562681a95f87429702" category="paragraph"><block ref="202f51b1cd08b9562681a95f87429702" category="inline-link-macro-rx"></block></block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="b46d6d6e100776ecf2985ff50a451beb" category="cell">2023年7月2日</block>
  <block id="6e6d4a2ed2ec59b98f8da1da20e890bb" category="cell">新增博客：宣布全面提供对Google Cloud VMware引擎的NetApp Cloud Volumes Service 数据存储库支持</block>
  <block id="7240c168839eaf56e1bc86326fb29d5b" category="cell">添加了TR-4955：使用适用于ONTAP 和VMC的FSX进行灾难恢复(AWS VMware Cloud)</block>
  <block id="dd4fe8081ff6ae9c7e9975937aff6576" category="list-text">Azure NetApp Files (ANF)作为补充NFS数据存储库</block>
  <block id="b2bf74ba9b2080c50a7214bcabdb670c" category="list-text">Cloud Volumes Service (CVS)作为补充NFS数据存储库</block>
  <block id="ef7615d9ff40c00e9893de8051347a72" category="cell">ANF<block ref="11e701f660af04a4005e56e6ac4b1c05" category="inline-link-macro-rx"></block></block>
  <block id="b577d5e5fe684be74c0fcbceb61e27d4" category="cell">CVS<block ref="2bc02f38a6be3889a69283e362618186" category="inline-link-macro-rx"></block></block>
  <block id="d7fe32206230432c446b09e24ab3f41a" category="doc">TR-4955：使用适用于ONTAP 和VMC的FSX进行灾难恢复(AWS VMware Cloud)</block>
  <block id="e99df6551992d3c39b8c5e87ee8a451f" category="paragraph">将灾难恢复到云是一种弹性且经济高效的方式、可保护工作负载免受站点中断和数据损坏事件(例如勒索软件)的影响。借助NetApp SnapMirror技术、可以将内部VMware工作负载复制到在AWS中运行的FSX for ONTAP。</block>
  <block id="c52f53db08961cb5fa061b55ca6812c7" category="paragraph">可以使用灾难恢复协调器(DRO；具有UI的脚本式解决方案)无缝恢复从内部复制到FSX for ONTAP 的工作负载。DRO可通过VM注册到VMC自动从SnapMirror级别恢复到直接在NSX-T上进行的网络映射所有VMC环境都包含此功能。</block>
  <block id="273c8112241e399eaf04dc840d119fb6" category="image-alt">此图展示了内部数据中心、AWS SDDC实例上的VMware云和适用于NetApp ONTAP 的Amazon FSx之间的结构和互连。其中包括SnapMirror复制、DRaaS操作流量、互联网或直接连接以及VMware Transit Connect。</block>
  <block id="246c1b44b3a8dc5d7fec2fdc031e49c5" category="section-title">在AWS上部署和配置VMware Cloud</block>
  <block id="c3b336e3bd0ee5f4a24fd28ce72d7dea" category="admonition">在初始版本中、DRO支持现有的试用集群。即将发布的版本将提供按需创建SDDC的功能。</block>
  <block id="09a69d8335838329a7615e73fa6b1fe0" category="section-title">为ONTAP 配置和配置FSX</block>
  <block id="7f38204cc308b0521e747e38f1cb0062" category="section-title">为适用于ONTAP 的FSX部署和配置SnapMirror</block>
  <block id="4a6b91648345db53156af03bcc00bde8" category="paragraph">下一步是使用NetApp BlueXP并发现在AWS实例上为ONTAP 配置的FSX、并以适当的频率将所需的数据存储库卷从内部环境复制到适用于ONTAP 的FSX并保留NetApp Snapshot副本：</block>
  <block id="6a4903522028d4e4bd24b3880afcf49f" category="image-alt">此图描绘了BlueXP画布关系映射、其中显示了已启用服务之间的各种交互。</block>
  <block id="45568e41c66e2e325c210961987178e7" category="paragraph">按照此链接中的步骤配置BlueXP。您也可以使用NetApp ONTAP 命令行界面计划通过此链接进行复制。</block>
  <block id="07f3fd5642ddcadbf716c250ccf987f0" category="admonition">SnapMirror关系是前提条件、必须事先创建。</block>
  <block id="8513f47f7075dac35da070dbceb25a2e" category="section-title">DRO安装</block>
  <block id="9f8fa80dd85e2409bd0b4495b821f0f3" category="paragraph">要开始使用DRO、请在指定EC2实例或虚拟机上使用Ubuntu操作系统、以确保满足前提条件。然后安装软件包。</block>
  <block id="7bf01cb2204f9dd0fdff029933600264" category="list-text">确保与源和目标vCenter以及存储系统建立连接。</block>
  <block id="4c915967cda97460076cfdb71bc58421" category="list-text">如果使用的是DNS名称、则应进行DNS解析。否则、您应使用vCenter和存储系统的IP地址。</block>
  <block id="3cfe50231d6e1ba1b199fc7421fb72e6" category="list-text">创建具有root权限的用户。您也可以将sudo与EC2实例结合使用。</block>
  <block id="6e968857b32243865ebf039c1facf6cf" category="section-title">操作系统要求</block>
  <block id="184e93a2064767475a538c600a47eb17" category="list-text">指定代理VM上必须安装以下软件包：</block>
  <block id="1dfe00693fad27f5da719e6aeea58ef6" category="list-text">Docker构成</block>
  <block id="31b4674ec2f7760117c224c883183141" category="list-text">JQ</block>
  <block id="240f5270a2e18be8a75b0712b343d07a" category="paragraph">更改上的权限<block ref="b1360c159d030cf3e3075d3ec21faf46" prefix=" " category="inline-code"></block>：<block ref="e89a7e38128b2d546718b48d40d827f7" prefix=" " category="inline-code"></block>。</block>
  <block id="76af5eb969b6b58ab010f271730ae0ee" category="admonition">。<block ref="60254338249f657a0a83f98258a56bfe" prefix=" " category="inline-code"></block> 此脚本将执行所有必需的前提条件。</block>
  <block id="478159949d5b4b537a6ca19613ae98bf" category="section-title">安装软件包</block>
  <block id="54d75811a77a2a9b1526f372bc0a733e" category="list-text">在指定虚拟机上下载安装包：</block>
  <block id="97c5338b12461548bb0ceefccd562486" category="admonition">该代理可以安装在内部环境中、也可以安装在AWS VPC中。</block>
  <block id="2d2a358ce62dfc056eddea09ea87d1d1" category="list-text">解压缩软件包、运行部署脚本、然后输入主机IP (例如10.10.10.10)。</block>
  <block id="4e26021fda30753473246136bacc8094" category="list-text">导航到目录并按如下所示运行Deploy脚本：</block>
  <block id="f1f49b31dc9a5d88e8029b9d361b9059" category="image-alt">Disaster Recovery Orchestrator登录屏幕。</block>
  <block id="7b7ad84593d701138003778be3b6079f" category="section-title">DRO配置</block>
  <block id="e9ff74e9030350261c678f0da3a354ee" category="paragraph">正确配置适用于ONTAP 的FSX和VMC之后、您可以开始配置DRO、以便使用适用于ONTAP 的FSX上的只读SnapMirror副本自动将内部工作负载恢复到VMC。</block>
  <block id="0a99b6b57603a6a9f7dc56799a0fdd8e" category="paragraph">NetApp建议在AWS中部署DRO代理、并将其部署到部署了FSX for ONTAP 的同一VPC上(也可以通过对等连接)。这样、DRO代理便可通过网络与内部组件以及适用于ONTAP 的FSX和VMC资源进行通信。</block>
  <block id="c7c5a0daa14b8062f69791fd594efd37" category="paragraph">第一步是发现内部资源和云资源(vCenter和存储)并将其添加到DRO中。在支持的浏览器中打开DRO、并使用默认用户名和密码(admin/admin)以及添加站点。也可以使用发现选项添加站点。添加以下平台：</block>
  <block id="16ee49909b80df9050959890b8f578cb" category="list-text">内部vCenter</block>
  <block id="e7aed9ec7e7600627310e041dbd517f7" category="list-text">ONTAP 存储系统</block>
  <block id="e3691c446d2915370eb25cbc68a6521a" category="list-text">VMC vCenter</block>
  <block id="36df1b975561708b246ef1801ea416e5" category="list-text">适用于 ONTAP 的 FSX</block>
  <block id="c532da281c4c378954b0254be09c051b" category="image-alt">临时占位符图像问题描述。</block>
  <block id="3506b8840bdbadcda795249c636510c4" category="image-alt">包含源站点和目标站点的DRO站点概述页面。</block>
  <block id="cf5e0df8cb3adb3df51d336ec0b2211a" category="paragraph">添加后、DRO将执行自动发现、并显示具有从源存储到适用于ONTAP 的FSX的相应SnapMirror副本的VM。DRO会自动检测VM使用的网络和端口组并对其进行填充。</block>
  <block id="abf7897bce5034c7714d0b7757ccac4c" category="image-alt">包含219个VM和10个数据存储库的自动发现屏幕。</block>
  <block id="8ad855ec9cdd9c029c645af01c256999" category="paragraph">下一步是将所需的VM分组到功能组中、以用作资源组。</block>
  <block id="cdac0221d4dabd98123be4284952f872" category="section-title">资源分组</block>
  <block id="7546309b604714e5c864eef677efcd63" category="paragraph">添加平台后、您可以将要恢复的VM分组到资源组中。使用DRO资源组、您可以将一组依赖虚拟机分组到逻辑组中、这些逻辑组包含启动顺序、启动延迟以及可在恢复时执行的可选应用程序验证。</block>
  <block id="265d81bb1af077020a501dcc75af41e1" category="paragraph">要开始创建资源组、请完成以下步骤：</block>
  <block id="a226ebee500532f5a9b1a5cbcb1db6d9" category="list-text">访问*资源组*、然后单击*创建新资源组*。</block>
  <block id="cfc3c82954c855841a78a216dec1b32b" category="list-text">在*新建资源组*下、从下拉列表中选择源站点、然后单击*创建*。</block>
  <block id="c47c9ace957accd98c45c515282fb851" category="list-text">提供*资源组详细信息*并单击*继续*。</block>
  <block id="5e4c1f12f71cc535b41e76690fd718e3" category="list-text">使用搜索选项选择相应的VM。</block>
  <block id="de5c4b583db3aa4040c8d082ee2d1bcd" category="list-text">选择选定虚拟机的启动顺序和启动延迟(秒)。通过选择每个VM并设置其优先级来设置启动顺序。所有VM的默认值均为3。</block>
  <block id="c32b3a0f06aa80c00476ddcabd88fde1" category="paragraph">选项如下：</block>
  <block id="a89a043e6faeacde759612c6bfa5cc1c" category="paragraph">1—第一个启动的虚拟机3—默认值5—最后一个启动的虚拟机</block>
  <block id="84a63bc4997af6ded1933281f4b8babb" category="list-text">单击*创建资源组*。</block>
  <block id="0942dfbe3d3b0a1d41f357604f7e9fb2" category="image-alt">包含两个条目的资源组列表的屏幕截图：Test和DemoRG1。</block>
  <block id="a8fc43ecd23ee9eb5e9efa5c60cb20b9" category="section-title">复制计划</block>
  <block id="901831e404573eb9a2cc09f43d42e661" category="paragraph">您需要制定计划、以便在发生灾难时恢复应用程序。从下拉列表中选择源和目标vCenter平台、然后选择要包含在此计划中的资源组、以及应用程序应如何还原和启动的分组(例如、域控制器、第1层、第2层等)。此类计划有时也称为蓝图。要定义恢复计划、请导航到*复制计划*选项卡、然后单击*新建复制计划*。</block>
  <block id="f2e437ba3d91f90c4bd8d4b35ce32b78" category="paragraph">要开始创建复制计划、请完成以下步骤：</block>
  <block id="7e2b1b88ae2fef26c3f9f94bc389f0d1" category="list-text">访问*复制计划*、然后单击*创建新复制计划*。</block>
  <block id="84ef8711a6a318c8bf4b8acfd4f1551c" category="image-alt">复制计划屏幕的屏幕截图、其中包含一个名为DemoRP的计划。</block>
  <block id="b9493784814dfebf88fc26091f72b601" category="list-text">在*新复制计划*下、为计划提供一个名称、并通过选择源站点、关联的vCenter、目标站点和关联的vCenter来添加恢复映射。</block>
  <block id="88cedf638ed2d7e4779e1c47ee7c5ea1" category="image-alt">复制计划详细信息的屏幕截图、包括恢复映射。</block>
  <block id="d360387ddbca9636208f2b8a948f56b0" category="list-text">恢复映射完成后、选择集群映射。</block>
  <block id="57e1d9c7da09c1484785ce5de748a5a4" category="list-text">选择*资源组详细信息*、然后单击*继续*。</block>
  <block id="28a5e1b451c50affbe5e71d787ef2818" category="list-text">设置资源组的执行顺序。使用此选项可以选择存在多个资源组时的操作顺序。</block>
  <block id="35e931afb6f8f9ea976030c41d20091d" category="list-text">完成后、选择指向相应网段的网络映射。应已在VMC中配置这些区块、因此请选择适当的区块以映射虚拟机。</block>
  <block id="4279ce58393302704e1d9f4ef8e18ca2" category="list-text">根据VM的选择、系统会自动选择数据存储库映射。</block>
  <block id="920e197d79d1f4f66caaef11426066ba" category="admonition">SnapMirror处于卷级别。因此、所有VM都会复制到复制目标。确保选择属于数据存储库的所有VM。如果未选择这些虚拟机、则仅会处理属于复制计划的虚拟机。</block>
  <block id="76074b4a55fc86674d98cacd953dd720" category="list-text">在VM详细信息下、您可以选择调整VM的CPU和RAM参数大小；在将大型环境恢复到较小的目标集群或执行灾难恢复测试而无需配置一对一物理VMware基础架构时、这会非常有用。此外、您还可以修改资源组中所有选定虚拟机的启动顺序和启动延迟(秒)。如果需要对资源组启动顺序选择期间选择的启动顺序进行任何更改、还可以选择修改启动顺序。默认情况下、系统会使用在选择资源组期间选择的启动顺序；但是、在此阶段可以执行任何修改。</block>
  <block id="61b06cf38207274281ff2f90f66b49fa" category="list-text">单击*创建复制计划*。</block>
  <block id="8066d08fcf99bee6a3bb8bc060a5d031" category="paragraph">创建复制计划后、可以根据需要使用故障转移选项、test-failover选项或migrate选项。在故障转移和测试-故障转移选项期间、将使用最新的SnapMirror Snapshot副本、或者可以从时间点Snapshot副本中选择特定的Snapshot副本(按照SnapMirror的保留策略)。如果您遇到勒索软件等损坏事件、而最新副本已被泄露或加密、则时间点选项可能会非常有用。DRO显示所有可用时间点。要使用复制计划中指定的配置触发故障转移或测试故障转移、可以单击*故障转移*或*测试故障转移*。</block>
  <block id="9f6a9153365f1438c116145bc14ba9a9" category="image-alt">在此屏幕中、系统会为您提供卷快照详细信息、您可以在使用最新快照和选择特定快照之间进行选择。</block>
  <block id="45c261be0b43693546955e87bd6ac10f" category="paragraph">可以在任务菜单中监控复制计划：</block>
  <block id="0225a4a711bba4eb595e835ad67356fc" category="image-alt">任务菜单显示复制计划的所有作业和选项、还允许您查看日志。</block>
  <block id="8d2831d40faa91653285bd44edc3917d" category="paragraph">触发故障转移后、可以在VMC vCenter中看到恢复的项目(VM、网络、数据存储库)。默认情况下、VM将恢复到工作负载文件夹。</block>
  <block id="d45215d9339daaa38e8c825812d30a02" category="paragraph">可以在复制计划级别触发故障恢复。对于测试故障转移、可以使用卸载选项回滚更改并删除FlexClone关系。与故障转移相关的故障恢复过程分为两步。选择复制计划并选择*反向数据同步*。</block>
  <block id="5f3ce61b7a4ffe23687402e421b81e18" category="image-alt">复制计划概述的屏幕截图、其中包含Reverse Data Sync选项的下拉列表。</block>
  <block id="acd827a33a3e445ce9d2c9d94ff63886" category="paragraph">完成后、您可以触发故障恢复以移回原始生产站点。</block>
  <block id="0c86039a87483290f146f9170e80b40b" category="image-alt">复制计划概述的屏幕截图、其中包含故障恢复选项的下拉列表。</block>
  <block id="503c1e37074b31fdcd74fbffb13e3983" category="image-alt">原始生产站点已启动且正在运行的DRO摘要页面的屏幕截图。</block>
  <block id="0d95c1c8686951d59b82bdc816a93231" category="paragraph">在NetApp BlueXP中、我们可以看到相应卷(已映射到VMC的读写卷)的复制运行状况已中断。在测试故障转移期间、DRO不会映射目标卷或副本卷。相反、它会为所需的SnapMirror (或Snapshot)实例创建一个FlexClone副本、并公开FlexClone实例、这样不会占用适用于ONTAP 的FSX的额外物理容量。此过程可确保卷不会被修改、并且即使在灾难恢复测试或鉴别工作流期间、副本作业也可以继续执行。此外、此过程还可确保在发生错误或恢复损坏的数据时、可以清理恢复过程、而不会造成副本被销毁的风险。</block>
  <block id="648a04436d5621ca9c7c65c66c55cb79" category="section-title">勒索软件恢复</block>
  <block id="f1d63aa61bd9bd59550523eea84313e8" category="paragraph">从勒索软件中恢复可能是一项艰巨的任务。具体而言、IT组织很难确定安全的返回点、一旦确定、就很难保护已恢复的工作负载、防止再次发生攻击、例如、休眠的恶意软件或容易受到攻击的应用程序。</block>
  <block id="c6ceeada99ad37301b94760e7f4bcab8" category="paragraph">DRO可帮助您从任何可用时间点恢复系统、从而解决这些问题。您还可以将工作负载恢复到正常运行且彼此隔离的网络、以便应用程序可以在不受北-南流量影响的位置彼此运行和通信。这样、您的安全团队就可以安全地进行取证、并确保没有隐藏或休眠的恶意软件。</block>
  <block id="468a6beafe68b7f0e997ea3b22eaf021" category="list-text">使用高效且具有故障恢复能力的SnapMirror复制。</block>
  <block id="8dc2f1e4e39bbf8b271892846d90aee7" category="list-text">使用Snapshot副本保留功能恢复到任何可用时间点。</block>
  <block id="6aaf12643047ec9787cc07db9f7e812a" category="list-text">完全自动化执行从存储、计算、网络和应用程序验证步骤中恢复成百上千个VM所需的所有步骤。</block>
  <block id="3067ce32bcf775ef4562f0900ee04ccf" category="list-text">使用ONTAP FlexClone技术执行工作负载恢复、方法不会更改复制的卷。</block>
  <block id="6359f2b426c28e13cbb7b8382496081c" category="list-text">避免卷或Snapshot副本发生数据损坏的风险。</block>
  <block id="cd08b15dd8bc6a19026ca47b4bcd618d" category="list-text">将灾难恢复数据与云计算资源一起用于灾难恢复以外的工作流、例如DevTest、安全测试、修补或升级测试以及修复测试。</block>
  <block id="7d73fdff5300d11e557be0d55023b8e8" category="list-text">CPU和RAM优化、可通过恢复到较小的计算集群来帮助降低云成本。</block>
  <block id="d923ff878d26dac68fc7ac0c94a428f0" category="inline-link-macro">使用适用于ONTAP 和VMC的FSX进行灾难恢复(DRO)</block>
  <block id="46d1e37416bef4df8c1962b95c983bb0" category="sidebar">GCVE + CVS TCO估算工具</block>
  <block id="15a2a7497ac6041e1b73d7cb41406245" category="doc">TR-4811：《适用于医疗保健的NetApp ONTAP AI参考架构：诊断映像—解决方案 设计》</block>
  <block id="5c6168ae6047f496e6903dde0fd3033c" category="paragraph"><block ref="5c6168ae6047f496e6903dde0fd3033c" category="inline-link-macro-rx"></block></block>
  <block id="4adfb8f589471885ed2256c4719146a6" category="doc">TR-4815：适用于AI和ML型号培训工作负载的NetApp AFF A800和Fujitsu服务器PRIMERGY GX2570 M5</block>
  <block id="d6f6c54736f64c202c28a1736214c268" category="paragraph"><block ref="d6f6c54736f64c202c28a1736214c268" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-设计：《采用NetApp E系列系统的Quantum StorNext》设计指南</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="7054aac0ed39fa340a2d8034700f7366" category="doc">NVA-1151-design：采用NVIDIA DGX A100的NetApp ONTAP AI系统设计指南</block>
  <block id="c3e7dfc3691f26701d35cccf4caf7151" category="paragraph"><block ref="c3e7dfc3691f26701d35cccf4caf7151" category="inline-link-macro-rx"></block></block>
  <block id="c95fe91ba2d256285401bdabdd666ca7" category="doc">NVA-1151-Deploy：采用NVIDIA DGX A100系统的NetApp ONTAP AI</block>
  <block id="3f8a5951b902f50dcbc39690406ade15" category="paragraph"><block ref="3f8a5951b902f50dcbc39690406ade15" category="inline-link-macro-rx"></block></block>
  <block id="83c4efb371f86415987632c0baa2d086" category="doc">NVA-1156设计：采用NVIDIA DGX A100系统和BeeGFS的NetApp EF系列AI</block>
  <block id="2003f72965a4dbc9f31bdaa3da5deaa2" category="paragraph"><block ref="2003f72965a4dbc9f31bdaa3da5deaa2" category="inline-link-macro-rx"></block></block>
  <block id="716c8038f7ef1bc60bc3fe6c036e2d3b" category="doc">TR-4807：适用于金融服务工作负载的NetApp ONTAP AI参考架构—解决方案 设计</block>
  <block id="96ac76dbb46fec3f4db7ec194dc52d2a" category="paragraph"><block ref="96ac76dbb46fec3f4db7ec194dc52d2a" category="inline-link-macro-rx"></block></block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851：适用于自动驾驶工作负载的NetApp StorageGRID 数据湖—解决方案 设计</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-Deploy：《采用NetApp E系列系统的Quantum StorNext部署指南》</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="837896d23c0eee81106906ab4cef7a6d" category="doc">TR-4799-design：适用于自主驱动工作负载的NetApp ONTAP AI参考架构</block>
  <block id="63e3877ed0a830d2fb8beed8fffb2df4" category="paragraph">NVIDIA DGX系统系列是全球首款专为企业AI打造的集成人工智能(AI)平台。NetApp AFF 存储系统可提供极致性能和行业领先的混合云数据管理功能。NetApp和NVIDIA合作创建了NetApp ONTAP AI参考架构、为客户提供了一个统包解决方案 、可为AI和机器学习(ML)工作负载提供企业级性能、可靠性和支持。</block>
  <block id="873b0fe1ee8adb4c5e6401e2fabf0734" category="paragraph"><block ref="873b0fe1ee8adb4c5e6401e2fabf0734" category="inline-link-macro-rx"></block></block>
  <block id="b7c82ef45da5d640a92ce6fb8fb757b7" category="doc">NVA-1153-design：采用NVIDIA DGX A100系统和Mellanox Spectrum以太网交换机的NetApp ONTAP AI</block>
  <block id="3dbdc92d258dcfc8f4fb9e2723a77875" category="paragraph"><block ref="3dbdc92d258dcfc8f4fb9e2723a77875" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859：使用NetApp E系列存储部署IBM Spectrum Scale—安装和验证</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="9892437a073c63ca6232150c28b21c7b" category="doc">NVA-1156-Deploy：采用NVIDIA DGX A100系统和BeeGFS的NetApp EF系列AI</block>
  <block id="ac6445146035971ff06dde08fd7cd295" category="paragraph"><block ref="ac6445146035971ff06dde08fd7cd295" category="inline-link-macro-rx"></block></block>
  <block id="9708ffc88c964c7e13b023f7eba9396b" category="doc">NVA-1153-Deploy：采用NVIDIA DGX A100系统和Mellanox Spectrum以太网交换机的NetApp ONTAP AI</block>
  <block id="50f2d8c31ffcba4aeffd6f55fd0f8bd2" category="paragraph"><block ref="50f2d8c31ffcba4aeffd6f55fd0f8bd2" category="inline-link-macro-rx"></block></block>
  <block id="3c2e1436532e8615aa8fdb7bb7432f80" category="paragraph">如果内部Oracle数据库位于ONTAP 存储阵列上、则可以使用AWS FSX ONTAP 存储中内置的NetApp SnapMirror技术更轻松地设置复制以进行数据库迁移。可以使用NetApp BlueXP控制台协调迁移过程。</block>
  <block id="ed7c233990ddaa2e7103a9f5b77ee3de" category="list-text">切换时、关闭主应用程序以停止所有事务。在Oracle sqlplus命令行界面中、执行Oracle联机日志切换并允许SnapMirror同步将最后一个归档日志推送到目标卷。</block>
  <block id="094ef1326e70f1212e06a1b5d65d2922" category="paragraph">以下视频演示了如何使用NetApp BlueXP控制台和SnapMirror复制将Oracle数据库从内部迁移到AWS FSX/EC2。</block>
  <block id="e54801d4a4497c3566a98c0ef4ec6f18" category="section-title">使用PDB重新定位将内部Oracle数据库迁移到AWS FSX/EC2、并最大程度地提高可用性</block>
  <block id="16d584a60d17de3de7cd0dcc0828fee9" category="paragraph">这种迁移方法最适合已部署在PDB或CDB多租户模式下的Oracle数据库、并且ONTAP 存储在内部不可用。PDB重新定位方法利用Oracle PDB热克隆技术在源CDB和目标CDB之间移动PDB、同时最大程度地减少服务中断。</block>
  <block id="c5bd16be343bf2e5a3c081284c6c799b" category="paragraph">首先、在AWS FSX/EC2中创建CDB、并为其提供足够的存储空间来托管要从内部迁移的PDB。可以一次重新定位一个多个内部部署的PDB。</block>
  <block id="a6c9ea7b4477a21ac635b1db86abae5e" category="list-text">如果内部数据库部署在单个实例中、而不是部署在多租户PDB或CDB模式中、请按照中的说明进行操作 <block ref="1a6a40cd2cc4844be72d5fbe9fd5f1e6" category="inline-link-macro-rx"></block> 将单个实例转换为多租户PDB或CDB。然后、按照下一步将转换后的PDB迁移到AWS FSX/EC2中的CDB。</block>
  <block id="92c29ab4b5bfbc6de30e29363bc9aea7" category="inline-link-macro">通过PDB重新定位将内部Oracle数据库迁移到云</block>
  <block id="522ca40aa0d528d119dec226eb9719b8" category="list-text">如果已在多租户PDB或CDB模式中部署内部数据库、请按照中的说明进行操作 <block ref="02137814e079cdfea8552a492195c829" category="inline-link-macro-rx"></block> 以执行迁移。</block>
  <block id="499d7c245aad786a568d21227b5b65d8" category="paragraph">以下视频演示了如何使用PDB重新定位将Oracle数据库(PDB)迁移到FSX/EC2并最大程度地提高可用性。</block>
  <block id="c0d2cea4b49d55201605052121b68ca7" category="inline-link-macro">将内部Oracle PDB迁移到具有最大可用性的AWS CDB</block>
  <block id="e3d2de69302b3f20931015cece4526e4" category="paragraph"><block ref="5deefe7b3e78f7f08541c2e7b5b56e54" category="inline-link-macro-rx"></block></block>
  <block id="5eae2f4290a9e1f77061f80c6c015bc6" category="admonition">尽管第1步和第2步中的说明在Azure公共云环境中进行了说明、但这些过程适用于AWS云、不会发生任何更改。</block>
  <block id="41099d15ad008ac11d04538ef8e57575" category="paragraph">NetApp解决方案自动化团队提供了一个迁移工具包、可帮助Oracle数据库从内部迁移到AWS云。使用以下命令下载用于PDB重新定位的Oracle数据库迁移工具包。</block>
  <block id="eef7539c8eab25bfe5c089aab85ec418" category="paragraph">要了解有关解决方案 和用例的更多信息、请观看以下概述视频：</block>
  <block id="0df1fe5dfbca17caa87c91ffea49223a" category="inline-link-macro">利用AWS和FSX ONTAP 中的混合云打造现代化的Oracle数据库、第1部分—用例和解决方案 架构</block>
  <block id="adf8d1fc36b4704904a6251fde19535e" category="paragraph"><block ref="bab032e290776958656c886d774a2bf6" category="inline-link-macro-rx"></block></block>
  <block id="3282bd4b5c29b5e9be65469e592bba18" category="doc">打造现代化的Microsoft SQL Server环境</block>
  <block id="b5b095487ccabae138c7872353cadbe6" category="paragraph"><block ref="b5b095487ccabae138c7872353cadbe6" category="inline-link-macro-rx"></block></block>
  <block id="ebcadd0d5b1096e72d18133b1e0e3098" category="doc">TR-4467：SAP与Windows上的Microsoft SQL Server—使用NetApp集群模式Data ONTAP 和SnapCenter 的最佳实践</block>
  <block id="d90b6dfa1c90883fc207f3309f98b1bf" category="paragraph"><block ref="d90b6dfa1c90883fc207f3309f98b1bf" category="inline-link-macro-rx"></block></block>
  <block id="046c9e52934c311f81497ca664d86a24" category="doc">TR-4764：《采用NetApp EF系列的Microsoft SQL Server最佳实践》</block>
  <block id="730874cec0e792d7ebad5a796a90b3be" category="paragraph"><block ref="730874cec0e792d7ebad5a796a90b3be" category="inline-link-macro-rx"></block></block>
  <block id="ffaaa5a04a78a6ce5d807980dbf83e64" category="paragraph">本《基于Cisco UCS的FlexPod Datacenter上的Oracle 19c RAC数据库设计和部署指南》以及《基于FC的NetApp AFF A800》详细介绍了在采用Oracle Linux 8.2的最新FlexPod Datacenter基础架构上托管Oracle RAC数据库的解决方案 设计以及分步部署过程操作系统和Red Hat兼容内核。</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623介绍了NetApp E系列和Splunk设计的集成架构。针对节点存储平衡、可靠性、性能、存储容量和密度进行了优化、此设计采用Splunk集群索引节点模式、可扩展性更高、TCO更低。通过将存储与计算分离、可以单独扩展每个存储、从而节省过度配置一个或另一个存储的成本。此外、本文档还总结了从Splunk计算机日志事件模拟工具获得的性能测试结果。</block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-Deploy：采用NetApp Storage解决方案 的Apache Spark工作负载</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-Deploy介绍了在NetApp NFS AFF 存储系统上验证Apache Spark SQL的性能和功能。本文档将根据各种场景审查配置、架构和性能测试、并提出将Spark与NetApp ONTAP 数据管理软件结合使用的建议。此外、本指南还介绍了仅基于一组磁盘(JBOD)与NetApp AFF A800存储控制器的测试结果。</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="2eded16d414f6935c27c95495a25eb53" category="cell">2023年1月24日</block>
  <block id="d75c9f4acb46fbd1cc7aeecbd376940e" category="cell">添加了TR-4954：《Azure NetApp Files 上的Oracle数据库部署和保护》</block>
  <block id="f0a30c2a34036665913459cc735f4786" category="doc">TR-4704：使用NetApp E系列存储部署Veritas NetBackup</block>
  <block id="7ff53b7713dd7f38a4729f8a1a48f24e" category="paragraph"><block ref="7ff53b7713dd7f38a4729f8a1a48f24e" category="inline-link-macro-rx"></block></block>
  <block id="5e8c99d8eb1f9fde413c715abb6fa392" category="doc">TR-4320：NetApp E系列和Commvault数据平台V11—参考架构和存储最佳实践</block>
  <block id="b5132c157b5da84909699e1aad5ea13d" category="inline-link-macro">TR-4320：NetApp E系列和Commvault数据平台V11—参考架构和存储最佳实践</block>
  <block id="65c8e697e97b6ce1bd59d8334eaaab6f" category="paragraph"><block ref="65c8e697e97b6ce1bd59d8334eaaab6f" category="inline-link-macro-rx"></block></block>
  <block id="849bdf40e7fa0e2cab1cb845682e6f56" category="doc">TR-4471：E系列和EF系列参考架构以及Veeam Backup &amp; Replication 9.5的存储最佳实践</block>
  <block id="3bad2cd66e539f0136fbf484133914dd" category="paragraph">TR-4471概述了在Veeam Backup &amp; Replication 9.5环境中使用NetApp E系列存储时的参考架构和最佳实践。</block>
  <block id="f86686bed105d7053fbb06167a05f38e" category="inline-link-macro">TR-4471：E系列和EF系列参考架构以及Veeam Backup &amp; amp；Replication 9.5的存储最佳实践</block>
  <block id="8a9473d2b45da95a2d08524f5b182c4d" category="paragraph"><block ref="30941a222a593c860776bbf0831d36d0" category="inline-link-macro-rx"></block></block>
  <block id="97b39392e3b66691f26174f9392c96d0" category="doc">NVA-1143：NetApp HCI —适用于采用HyTrust的多租户基础架构的FISMA的NIST安全控制—NVA设计和部署</block>
  <block id="86e20b04ba1f19de7a30d7843155e285" category="paragraph"><block ref="86e20b04ba1f19de7a30d7843155e285" category="inline-link-macro-rx"></block></block>
  <block id="7c3806f623157e3b19cc1801dd72a85d" category="inline-link-macro">适用于Google Cloud VMware Engine (NetApp)的NetApp Cloud Volumes Service 数据存储库支持</block>
  <block id="5e25da2b2b250c19fcd7efe36b782cc9" category="list-text"><block ref="5e25da2b2b250c19fcd7efe36b782cc9" category="inline-link-macro-rx"></block></block>
  <block id="c540d1dfacf4a64cc435acb640f4cbd4" category="inline-link-macro">如何使用NetApp CVS作为Google Cloud VMware Engine (Google)的数据存储库</block>
  <block id="4a8385e4a45d508eea692800bf2323d9" category="list-text"><block ref="4a8385e4a45d508eea692800bf2323d9" category="inline-link-macro-rx"></block></block>
  <block id="8031035e3922dbc188f876cc6fb8434d" category="inline-link-macro">适用于Google Cloud VMware Engine的NetApp Cloud Volumes Service 数据存储库支持(NetApp博客)</block>
  <block id="71f1bcf72187cb460ce8534fd5439962" category="inline-link-macro">如何使用NetApp CVS作为Google Cloud VMware Engine的数据存储库(Google博客)</block>
  <block id="5ca70e1272bcfe0644f6a52e2d971039" category="paragraph">了解更多信息 <block ref="0d04aae7b3b1a3149a54ebc44d21fc72" category="inline-link-macro-rx"></block> 或 <block ref="c1e740ec580b7430a1cc324eec4af172" category="inline-link-macro-rx"></block></block>
  <block id="b4fd1d48279ed0bed231fbd3b96a1e3a" category="list-text">Ubuntu 20.04 (LTS)、至少具有2 GB和4个vCPU</block>
  <block id="049e44fe327f7679318c6cf222207da7" category="list-text">使用以下命令访问UI：</block>
  <block id="b7bd19f19df4ca5ef3102741951e7a1b" category="paragraph">使用以下默认凭据：</block>
  <block id="d644796f5eb5712add7807df8829ee58" category="admonition">可以使用"更改密码"选项更改密码。</block>
  <block id="653a98af1c9a004c51b4e7358f06db9a" category="summary">解决方案 概述了PostgreSQL数据库部署以及基于FSX ONTAP 存储产品中内置的NetApp SnapMirror技术和AWS中的NetApp Ansible自动化工具包的HA/DR设置、故障转移和重新同步的详细信息。</block>
  <block id="e5f44d648a9d8c4db4e2b580d3370fbf" category="doc">TR-4956：在AWS FSX/EC2中自动部署PostgreSQL高可用性和灾难恢复</block>
  <block id="03784a7c5600d29113972955e602a944" category="inline-link-macro">数据库引擎</block>
  <block id="1d8f1bdc206db1d9edd9fa46f02aa08c" category="paragraph">PostgreSQL是一种广泛使用的开源数据库、在排名前十位最受欢迎的数据库引擎中排名第四 <block ref="6e2d0e5987102894082cbdb135303e4d" category="inline-link-macro-rx"></block>。一方面、PostgreSQL从其无许可证的开源模式中获得了广泛的使用、同时它仍具有复杂的功能。另一方面、由于它是开源的、因此在高可用性和灾难恢复(HA/DR)领域、特别是在公共云中、缺乏有关生产级数据库部署的详细指导。通常、很难为典型的PostgreSQL HA/DR系统设置热备用和热备用、流复制等。通过提升备用站点并切换回主站点来测试HA/DR环境可能会对生产造成中断。在流式热备用系统上部署读取工作负载时、主系统上存在大量已记录的性能问题。</block>
  <block id="e2543d0568626be8ab6adad9d9a78652" category="paragraph">此解决方案 基于经验证的成熟NetApp SnapMirror存储级别复制技术构建、该技术可在适用于PostgreSQL HA/DR的AWS本机FSX ONTAP 云存储中使用。借助NetApp解决方案团队提供的自动化工具包、可以轻松实施。借助基于应用程序级别流式传输的HA/DR解决方案 、它可以提供类似的功能、同时消除主站点上的复杂性和性能阻力。可以轻松部署和测试解决方案 、而不会影响活动主站点。</block>
  <block id="f67bd3c0833b1d6bf90bb26a55f0a9ce" category="list-text">在公共AWS云中为PostgreSQL部署生产级HA/DR</block>
  <block id="420a5f3809172bb0dc9d501758fe94d2" category="list-text">在公共AWS云中测试和验证PostgreSQL工作负载</block>
  <block id="c9d6a5076f52c5abce5f2003446ab211" category="list-text">测试和验证基于NetApp SnapMirror复制技术的PostgreSQL HA/DR策略</block>
  <block id="82aa3e78c2089a2941fb745bb8c72f01" category="paragraph">此解决方案 适用于以下人员：</block>
  <block id="4a7bde15fa2753ce507cef621fd789b2" category="list-text">有兴趣在公共AWS云中使用HA/DR部署PostgreSQL的DBA。</block>
  <block id="c5e04df584e0992a5dbdae10d89ded97" category="list-text">数据库解决方案 架构师、负责在公共AWS云中测试PostgreSQL工作负载。</block>
  <block id="ba083ee91407315383bac538162833ff" category="list-text">存储管理员、负责部署和管理部署到AWS FSX存储的PostgreSQL实例。</block>
  <block id="73ad058c671f3e1e105d92585f5ece7a" category="list-text">有意在AWS FSX/EC2中建立PostgreSQL环境的应用程序所有者。</block>
  <block id="d17a638ff086388dc5bfbe98528ccfab" category="section-title">解决方案 测试和验证环境</block>
  <block id="863fb5b3a3b3b63b57a387bab70de0a9" category="paragraph">此解决方案 的测试和验证是在AWS FSX和EC2环境中执行的、该环境可能与最终部署环境不匹配。有关详细信息，请参见一节 <block ref="8ea96e516bccf9a47ca2d74131eb7519" category="inline-xref-macro-rx"></block>。</block>
  <block id="bfa420253f0a67626a51ce1fa045944c" category="image-alt">此图详细展示了PostgreSQL混合云解决方案 的组织结构、包括内部部署端和AWS站点。</block>
  <block id="34d0b9b49aa480630e91a3619ba7ffb2" category="section-title">硬件和软件组件</block>
  <block id="a09dc18a1bff4fa8388afca4627d0911" category="cell">FSX ONTAP 存储</block>
  <block id="011fedf4050817b8826f95a53d9555b2" category="cell">当前版本</block>
  <block id="0b70cdec9293f5625e5aaae9cdd38526" category="cell">与主HA集群和备用HA集群位于同一VPC和可用性区域中的两个FSX HA对</block>
  <block id="6a79356b19d3b59e92b358357c5b9053" category="cell">用于计算的EC2实例</block>
  <block id="cc4def82629f09f253176dba801a85f0" category="cell">t2.xlarge/4vCPU/16G</block>
  <block id="e3d6d4b94f9415561957f8c22f5fea2e" category="cell">两个EC2 t2 xlarge作为主计算实例和备用计算实例</block>
  <block id="3008feb4272787858d4d27f7e8acb08b" category="cell">Ansible控制器</block>
  <block id="26b9568eac10de69d574b84626735921" category="cell">内部CentOS VM/4vCPU/8G</block>
  <block id="7f151fffe66dad0021b1918085977654" category="cell">用于在内部或云中托管Ansible自动化控制器的VM</block>
  <block id="8b56d55f3caeb71ab2513c28fb1a52fc" category="cell">RedHat Linux</block>
  <block id="52359c9653f33c68cd1b454f7d05a27b" category="cell">rhel-8.6.0_hvm-20220503-x86_64-2-Hourly2-gp2</block>
  <block id="fe6120dacb84838d71b1f43da1a3a514" category="cell">已部署RedHat订阅以进行测试</block>
  <block id="8003cafa06ec27e11cb235ec9544ef74" category="cell">CentOS Linux</block>
  <block id="04cd32c57cf3229ae9374fc80cd50d96" category="cell">CentOS Linux 8.2.2004版(核心)</block>
  <block id="63b6df5ba9d257bb0f6fbda5541d9171" category="cell">托管部署在内部实验室中的Ansible控制器</block>
  <block id="399bd1ee587245ecac6f39beaa99886f" category="cell">PostgreSQL</block>
  <block id="a3c20b719830dc5fda947c7b6f3e42be" category="cell">版本14.5%</block>
  <block id="f8c3d3a84c62eb07a1009aacdc46a50f" category="cell">自动化从PostgreSQL .ora yum repo.中提取最新可用的PostgreSQL版本</block>
  <block id="202351f581b52c61061d29151c81d061" category="cell">版本2.10.3</block>
  <block id="d222003898249e4a560d569acb0b5563" category="cell">使用要求攻略手册安装的所需集合和库的前提条件</block>
  <block id="cd1aedf83959dd52fc058b9120f500e3" category="section-title">部署注意事项的关键因素</block>
  <block id="b062352f67359ac6729601c60a9a57a2" category="list-text">* PostgreSQL数据库备份、还原和恢复。* PostgreSQL数据库支持多种备份方法、例如使用pg-dump的逻辑备份、使用pG_basebackup或较低级别的操作系统备份命令的物理联机备份以及存储级别一致的快照。此解决方案 使用NetApp一致性组快照在备用站点上备份、还原和恢复PostgreSQL数据库数据和WAL卷。NetApp一致性组卷快照会在写入存储时对I/O进行排序、并保护数据库数据文件的完整性。</block>
  <block id="a28c157802547f294e145f164007d752" category="list-text">* EC2计算实例。*在这些测试和验证中、我们对PostgreSQL数据库计算实例使用了AWS EC2 T2.xlarge实例类型。NetApp建议在部署中使用M5类型的EC2实例作为PostgreSQL的计算实例、因为它针对数据库工作负载进行了优化。备用计算实例应始终部署在为FSX HA集群部署的被动(备用)文件系统所在的分区中。</block>
  <block id="d7aed04148f8b6ba1b91a7ed84d3fd10" category="list-text">* FSX存储HA集群单区域或多区域部署。*在这些测试和验证中、我们在一个AWS可用性区域中部署了一个FSX HA集群。对于生产部署、NetApp建议在两个不同的可用性区域中部署一个FSX HA对。如果主存储系统与备用存储系统之间需要特定距离、则可以在其他区域设置用于实现业务连续性的灾难恢复备用HA对。FSX HA集群始终配置在一个HA对中、该HA对在一对主动-被动文件系统中进行同步镜像、以提供存储级别的冗余。</block>
  <block id="c6f1f46bc7e80b73e6d77a7f862e0625" category="list-text">* PostgreSQL数据和日志放置。*典型的PostgreSQL部署共享同一个或多个根目录、用于存储数据和日志文件。在测试和验证中、我们将PostgreSQL数据分离、并登录到两个单独的卷中以提高性能。数据目录中使用软链接指向托管PostgreSQL WAL日志和归档WAL日志的日志目录或卷。</block>
  <block id="6e6dddb70c24cf218d0163faa3fb6a8f" category="list-text">* PostgreSQL服务启动延迟计时器。*此解决方案 使用NFS挂载的卷存储PostgreSQL数据库文件和WAL日志文件。在数据库主机重新启动期间、如果未挂载卷、PostgreSQL服务可能会尝试启动。这会导致数据库服务启动失败。要使PostgreSQL数据库正常启动、需要10到15秒的计时器延迟。</block>
  <block id="ee79ca09fee704e63d972baa3c1319a2" category="list-text">*用于业务连续性的RPO/RTO。*用于灾难恢复的FSX数据从主节点复制到备用节点基于异步、这意味着RPO取决于Snapshot备份和SnapMirror复制的频率。Snapshot副本和SnapMirror复制的频率越高、RPO就越低。因此、在发生灾难时的潜在数据丢失与增加的存储成本之间可以取得平衡。我们已确定、对于RPO、Snapshot副本和SnapMirror复制的实施间隔可低至5分钟、而对于RTO、PostgreSQL通常可在灾难恢复备用站点的一分钟内恢复。</block>
  <block id="cbeb123cc0c2c950a65a0c39f8412dc4" category="list-text">*数据库备份。*在实施PostgreSQL数据库或将该数据库从未命中数据中心迁移到AWS FSX存储后、该数据会自动同步镜像到FSX HA对中以进行保护。发生灾难时、可以使用复制的备用站点进一步保护数据。为了实现长期备份保留或数据保护、NetApp建议使用内置的PostgreSQL pG_basebackup实用程序运行可移植到S3 Blob存储的完整数据库备份。</block>
  <block id="d2598d7d09e212cad1231cd233c5f7dc" category="paragraph">可以使用基于NetApp Ansible的自动化工具包按照以下详细说明自动完成此解决方案 的部署。</block>
  <block id="7cfbd2a753781ece3080a48b0a56dad2" category="inline-link-macro">NA_PostgreSQL _AWS_deploy_HADR</block>
  <block id="fce91619a13ef0fd71e3ffe1da6b5724" category="list-text">阅读自动化工具包readme.md中的说明 <block ref="139722adb31b9bbcb8f923b221d78595" category="inline-link-macro-rx"></block>。</block>
  <block id="9a1c6815d4b1e7dc53acf5a926ab662e" category="list-text">观看以下视频逐步介绍。</block>
  <block id="c73ece4b7be6bb88143afe096ded59aa" category="list-text">配置所需的参数文件 <block ref="85cf4e6d42a71e693fd780c8b29accdd" prefix="(" category="inline-code"></block>，<block ref="0c83664bfb17d8d2c0bbc3551297e488" prefix=" " category="inline-code"></block>，<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block>)、在相关部分的模板中输入用户专用参数。然后、使用复制按钮将文件复制到Ansible控制器主机。</block>
  <block id="00aaa5ff8fbd0841ab311f7d9b1e4e78" category="section-title">自动化部署的前提条件</block>
  <block id="fd10b9eacfe4eed8040bda8cae9ea050" category="paragraph">部署需要满足以下前提条件。</block>
  <block id="e7491272f69c8efda69a595782f44d45" category="list-text">已设置AWS帐户、并已在您的AWS帐户中创建必要的VPC和网段。</block>
  <block id="f71558e9ad22e37a70099d8b5d8ac06c" category="inline-link-macro">Linux实例用户指南</block>
  <block id="eb03aa8f939650517c1c56a6d0b9ad2f" category="list-text">在AWS EC2控制台中、您必须部署两个EC2 Linux实例、一个在主站点上作为主PostgreSQL DB服务器、一个在备用灾难恢复站点上。要在主灾难恢复站点和备用灾难恢复站点实现计算冗余、请另外部署两个EC2 Linux实例作为备用PostgreSQL DB服务器。有关环境设置的详细信息、请参见上一节中的架构图。另请查看 <block ref="32934851360be4fd00506586c2cbc221" category="inline-link-macro-rx"></block> 有关详细信息 ...</block>
  <block id="933d3e5f984811b21da2922f3deb56c4" category="list-text">在AWS EC2控制台中、部署两个FSX ONTAP 存储HA集群来托管PostgreSQL数据库卷。如果您不熟悉FSX存储的部署、请参见相关文档 <block ref="d73b8b529985c5c89147bd81cb29dbfb" category="inline-link-macro-rx"></block> 了解分步说明。</block>
  <block id="7053a216e34d0f83be18a65f22ce62ce" category="list-text">构建CentOS Linux VM以托管Ansible控制器。Ansible控制器可以位于内部或AWS云中。如果它位于内部、则必须通过SSH连接到VPC、EC2 Linux实例和FSX存储集群。</block>
  <block id="d1186b859105640e1dc347ae7b714afa" category="list-text">按照资源中的"为RHEL/CentOS上的CLI部署设置Ansible控制器"一节所述设置Ansible控制器 <block ref="a9149ecc8f33f363a4eae3089d5c6cb7" category="inline-link-macro-rx"></block>。</block>
  <block id="007fa0067fff9abdcd3e5b9ce9f20c06" category="list-text">从NetApp GitHub公共站点克隆自动化工具包的副本。</block>
  <block id="0ca21e6da2c89e765706d9a77f412898" category="list-text">从工具包根目录中、执行前提条件攻略手册、为Ansible控制器安装所需的集合和库。</block>
  <block id="df40cb16c4a24c991c143fbddeedd0bc" category="list-text">检索DB主机变量文件所需的EC2 FSX实例参数<block ref="ea858a411f1af6150f14b84176148712" prefix=" " category="inline-code"></block> 和全局变量文件<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block> Configuration</block>
  <block id="57c7844b0a299340cf9b625ce4a0745a" category="section-title">配置hosts文件</block>
  <block id="ed578fbfbec5634c4fa508cde5bc4e85" category="paragraph">将主FSX ONTAP 集群管理IP和EC2实例主机名称输入到hosts文件中。</block>
  <block id="6ef214427ca7b42201d0b0508f56df98" category="section-title">在host_vars文件夹中配置host_name.yml文件</block>
  <block id="77ac1da2cd356e327eb4bfc4c5a21bcc" category="section-title">在vars文件夹中配置全局FSx_vars.yml文件</block>
  <block id="d56625a35762821798a2f3dd55ead05d" category="section-title">PostgreSQL部署和HA/DR设置</block>
  <block id="943a124028d8f011631df765453640dc" category="paragraph">以下任务将在主EC2 DB服务器主机的主站点上部署PostgreSQL DB服务器服务并初始化数据库。然后、在备用站点上设置备用主EC2 DB服务器主机。最后、将数据库卷从主站点FSX集群复制到备用站点FSX集群、以便进行灾难恢复。</block>
  <block id="08f6dd070ef1adfcbe3d7f3c70b08905" category="list-text">在主FSX集群上创建数据库卷、并在主EC2实例主机上设置PostgreSQL。</block>
  <block id="bf22091495c9a041dcbdba3a97795095" category="list-text">设置备用DR EC2实例主机。</block>
  <block id="f2dd18dfc82378171d01bdd3f956bc6f" category="list-text">设置FSX ONTAP 集群对等和数据库卷复制。</block>
  <block id="d681aef28cf1f863d0683a6896f12995" category="list-text">将上述步骤整合为一步式PostgreSQL部署和HA/DR设置。</block>
  <block id="fe217a2e30a79cebc71db6d5cb676a71" category="list-text">要在主站点或备用站点设置备用PostgreSQL DB主机、请在hosts文件(dr_PostgreSQL)部分中注释掉所有其他服务器、然后使用相应的目标主机(例如、主站点的psql_01ps或备用EC2计算实例)执行PostgreSQL standby_setup.yml攻略手册。请确保使用主机参数文件、例如<block ref="7c0f59fa275836ef9c4f28bec839acca" prefix=" " category="inline-code"></block> 在下配置<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> 目录。</block>
  <block id="d3ecdce9695eacdb90ec80fa276865d4" category="section-title">将PostgreSQL数据库快照备份和复制到备用站点</block>
  <block id="3b320790a7f864b473e3baa86de785fe" category="paragraph">可以在Ansible控制器上按用户定义的时间间隔控制并执行PostgreSQL数据库快照备份和到备用站点的复制。我们已验证此间隔可低至5分钟。因此、如果主站点发生故障、则在下次计划的快照备份之前发生故障、可能会丢失5分钟的数据。</block>
  <block id="421057a9fa982de2a1c1f79f5f03d750" category="section-title">故障转移到备用站点进行灾难恢复</block>
  <block id="6ddcc779c247e4adb5b5a56a34edd75d" category="paragraph">要将PostgreSQL HA/DR系统测试为灾难恢复练习、请执行以下攻略手册、在备用站点上的主备用EC2 DB实例上执行故障转移和PostgreSQL数据库恢复。在实际灾难恢复情形中、对实际故障转移到灾难恢复站点执行相同的操作。</block>
  <block id="724a617bc1dcc9b26fedb732f63a569d" category="section-title">在故障转移测试后重新同步复制的数据库卷</block>
  <block id="6a08e960bd12a4fcddfd08082fbece4b" category="paragraph">在故障转移测试后运行resync以重新建立数据库-卷SnapMirror复制。</block>
  <block id="145966bc8e38b26c384abaf4e450f6a7" category="section-title">由于EC2计算实例故障、从主EC2数据库服务器故障转移到备用EC2数据库服务器</block>
  <block id="73bc97f640d8c1cae3fa624183216b41" category="inline-link-macro"><block ref="73bc97f640d8c1cae3fa624183216b41" category="inline-link-rx"></block></block>
  <block id="40285fa8e3dc4d66bfadb679f67dfde6" category="paragraph"><block ref="40285fa8e3dc4d66bfadb679f67dfde6" category="inline-link-macro-rx"></block></block>
  <block id="68253b5715937494905ba0cb9db91d2e" category="inline-link-macro"><block ref="be48c1546d351a5e48dcf4f28738754b" category="inline-link-rx"></block></block>
  <block id="6dcfba5adaa9302bd59dd5a601b947a2" category="paragraph"><block ref="95bfcff1050e9160bb2bd645993e8c18" category="inline-link-macro-rx"></block></block>
  <block id="031004dd1775e5fd9d35b534e33217ea" category="paragraph">【下划线】#*开源数据库视频*</block>
  <block id="5b70a7f45ddd32cacfe28af238662d3d" category="video-title">PostgreSQL自动部署、HA/DR复制设置、故障转移、重新同步</block>
  <block id="61c8e892dd7e1908020eb0a312fd4bbb" category="cell">2023年2月15日</block>
  <block id="2ee6a0567aa163f6ace02183cb041cbd" category="cell">在AWS FSX/EC2中添加了PostgreSQL高可用性部署和灾难恢复功能</block>
  <block id="a54420e6e0f519f841f4280cf2545365" category="sidebar">开源数据库</block>
  <block id="1ae3eccde141a365ede8f18b188ae588" category="sidebar">在AWS FSX/EC2中自动部署PostgreSQL HA和灾难恢复</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">本节介绍详细的测试操作步骤 结果。</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">测试操作步骤 和详细结果</block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">在ONTAP 中使用RESNET进行图像识别培训</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">我们使用一台和两台SR670V2服务器运行ResNet50基准测试。此测试使用了MXNet 22.04-py3 NGC容器来运行培训。</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">在此验证中、我们使用了以下测试操作步骤 ：</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">在运行脚本之前、我们已清除主机缓存、以确保数据尚未缓存：</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">我们在服务器存储(本地SSD存储)以及NetApp AFF 存储系统中使用ImageNet数据集运行了基准测试脚本。</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">我们使用验证了网络和本地存储性能<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> 命令：</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">对于单节点运行、我们使用了以下命令：</block>
  <block id="014e128029d9142b6957ca4f1b291090" category="list-text">对于分布式运行、我们使用了参数服务器的并行化模型。我们为每个节点使用了两个参数服务器、并将epodchs的数量设置为与单节点运行相同。之所以这样做、是因为分布式培训往往需要更多的时间、因为各个流程之间的同步不完美。不同数量的时间间隔可能会使单节点案例与分布式案例之间的比较偏差。</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">数据读取速度：本地存储与网络存储</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">已使用测试读取速度<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> 对ImageNet数据集的其中一个文件执行命令。具体来说、我们对本地数据和网络数据运行以下命令：</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">这两个值都相似、表明网络存储可以以类似于本地存储的速率提供数据。</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">共享使用情形：多个独立的并发作业</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">此测试模拟了此解决方案 的预期用例：多作业、多用户AI培训。每个节点在使用共享网络存储时都进行了自己的培训。下图显示了这些结果、其中显示了解决方案 案例在所有作业以与单个作业基本相同的速度运行时提供了出色的性能。总吞吐量随节点数线性扩展。</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">此图显示了每秒的聚合映像数。</block>
  <block id="5224aacbc4b8472eb40ead3ee8856b90" category="paragraph"><block ref="5224aacbc4b8472eb40ead3ee8856b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">此图显示的是运行时(以分钟为单位)。</block>
  <block id="8255e8c790967568129f1f898048f1c5" category="paragraph"><block ref="8255e8c790967568129f1f898048f1c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">这些图以分钟为单位显示了计算节点的运行时间、每秒聚合映像数、这些计算节点在100 GbE客户端网络上使用了每个服务器的八个GPU、并结合了并发训练模型和单个训练模型。此训练模型的平均运行时间为35分9秒。单个运行时间分别为34分32秒、36分21秒、34分37秒、35分25秒和34分31秒。训练模型的平均每秒图像数为22、673个、每秒单个图像数为21、764个、23、438个、22、556个、22、264个和22、548个。</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">根据我们的验证、一个采用NetApp数据运行时的独立训练模型为34分54秒、每秒显示22、231个图像一个采用本地数据(DAS)运行时间的独立训练模型为34分21秒、每秒显示22、102个图像在这些运行期间、平均GPU利用率为96%、如NVIDIA-SMI上所观察到的那样。请注意、此平均值包括测试阶段、在此阶段、不使用GPU、而使用mpstat测量的CPU利用率为40%。这表明、在每种情况下、数据交付率都足以满足要求。</block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">用于验证的设置可以根据其他使用情形进行调整。</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">架构调整</block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">可根据其他使用情形调整用于此验证的设置。</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">CPU调整</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">我们按照联想的建议、使用Skylake Intel Xeon Platinum 8360Y处理器进行此验证。我们预计同等的级联湖CPU (Intel Xeon Gold 6330处理器)的性能将相似、因为此工作负载不受CPU限制。</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">存储容量增加</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">根据您的存储容量需求、您可以按需增加共享存储(NFS卷)、但前提是您拥有更多的磁盘架和控制器型号。您可以通过CLI或存储控制器的NetApp Web界面以管理员用户身份执行此操作。</block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">在此验证中、我们按照MLPerf v2.0的要求执行了映像识别培训。具体来说、我们使用ImageNet数据集对RESNET v2.0模型进行了培训。主要指标是达到所需准确性的时间。我们还会报告每秒图像数的训练带宽、以便更好地判断横向扩展效率。</block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">在此验证中、我们按照MLPerf v2.0的要求执行了映像识别培训。具体来说、我们使用ImageNet数据集对RESNET v2.0模型进行了培训、直到达到76.1%的准确性。主要指标是达到所需准确性的时间。我们还会报告每秒图像数的训练带宽、以便更好地判断横向扩展效率。</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">主测试案例评估了多个同时运行的独立培训流程(每个节点一个)。此操作可模拟主要使用情形、即由多位数据科学家使用的共享系统。第二个测试用例评估了横向扩展效率。</block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">本解决方案 侧重于使用针对人工智能工作负载优化的NetApp存储和联想服务器的入门级和中端集群架构。它适用于大多数计算作业为单节点(单或多GPU)或分布在几个计算节点上的中小型团队。这不是一个主要限制、因为大多数日常AI培训作业都是单节点的。</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810：《采用联想ThinkSystem SR670V2的NetApp AFF A400人工智能和ML模型培训》</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">此解决方案 采用针对人工智能(AI)工作负载优化的NetApp存储和联想服务器、提供了一个中端集群架构。它适用于大多数计算作业为单节点(单GPU或多GPU)或分布在几个计算节点上的中小型企业。此解决方案 可与许多企业的大多数日常AI培训工作保持一致。</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">本文档介绍了对由八GPU联想SR670V2服务器、中端NetApp AFF A400存储系统和100GbE互连交换机组成的计算和存储配置的测试和验证。为了衡量性能、我们将ResNet50与ImageNet数据集结合使用、批大小为408、半精度、CUDA和cuDNN。这种架构为中小型企业提供了一个高效且经济高效的解决方案 、这只是从需要NetApp ONTAP 云连接数据存储的企业级功能的AI计划开始。</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">数据科学家、数据工程师、数据管理员和AI系统开发人员</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">设计AI模型开发解决方案的企业架构师</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">正在寻找高效方法实现深度学习(DL)和机器学习(ML)开发目标的数据科学家和数据工程师</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">希望以最快速度将AI计划推向市场的业务主管和OT/IT决策者</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">这款采用联想ThinkSystem服务器的解决方案 以及采用AFF 存储的NetApp ONTAP 专为处理大型数据集的AI培训而设计、可利用GPU与传统CPU的处理能力。此验证通过横向扩展架构展示了高性能和最佳数据管理、该架构使用一个、两个或四个联想SR670V2服务器以及一个NetApp AFF A400存储系统。下图提供了架构概述。</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">此图显示了一个以太网交换机、该交换机由管理服务器围绕、四个SR670V2 (每个GPU具有八个GPU)以及一个NetApp ONTAP 存储系统。</block>
  <block id="d0d5bc4c21e600127e347c093cc29e80" category="paragraph"><block ref="d0d5bc4c21e600127e347c093cc29e80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">并行执行多个培训作业时、性能高效且经济高效</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">可根据不同数量的联想服务器和不同型号的NetApp存储控制器扩展性能</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">强大的数据保护功能、可满足低恢复点目标(RPO)和恢复时间目标(RTO)的要求、而不会丢失任何数据</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">利用快照和克隆优化数据管理、以简化开发工作流</block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">本节总结了在此解决方案 中测试的结果。</block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">下表总结了对此解决方案 执行的所有测试的结果。</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">测试问题描述</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">结果摘要</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">映像识别培训：多个并发作业</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">高效率性能。即使集群已完全使用、所有作业也会以全速运行。NetApp存储系统可提供与本地SSD存储相当的训练性能、同时可在服务器之间轻松共享数据。</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">图像识别培训：横向扩展</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">效率高、最多可支持四个节点。当时、横向扩展效率较低、但仍然可行。使用速度更快的计算网络可提高可扩展性。NetApp存储系统可提供与本地SSD存储相当的训练性能、同时可在服务器之间轻松共享数据。</block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">本节介绍测试的配置、网络基础架构、SR670V2服务器以及存储配置详细信息。</block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">本节介绍测试的配置、网络基础架构、SR670V2服务器以及NetApp存储配置详细信息。</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">我们使用下表中列出的解决方案 组件进行了此验证。</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">两个SR670V2服务器、每个服务器具有八个NVIDIA A100 80 GB GPU卡</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">每台服务器包含2个Intel Xeon Platinum 8360Y CPU (28个物理核心)和1 TB RAM</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux (Ubuntu—20.04与CUDA 11.8)</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">NetApp AFF 存储系统(HA对)</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">NetApp ONTAP 9.10.1软件</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">每个控制器1个接口组(ifgrp)、挂载点有四个逻辑IP地址</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">在此验证中、我们使用的是RESNET v2.0、并且ImageNet基础设置为由MLPerf v2.0指定的基础。数据集存储在采用NFS协议的NetApp AFF 存储系统中。SR670s通过100GbE交换机连接到NetApp AFF A400存储系统。</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNet是一个常用的映像数据集。它包含近130万个映像、总大小为144 GB。平均映像大小为108 KB。</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">下图显示了测试配置的网络拓扑。</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">此图展示了计算层、联想ThinkSystem SR670V2、网络层、联想以太网交换机和存储层、即NetApp AFF A400存储控制器。包括所有网络连接。</block>
  <block id="1ee331a29f95ebce1684e5e998f3e70c" category="paragraph"><block ref="1ee331a29f95ebce1684e5e998f3e70c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">下表列出了存储配置。</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">聚合大小</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">卷大小</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">操作系统挂载点</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100g</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9.9 TB</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19 TB</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">/a400-100g文件夹包含用于RESNET验证的数据集。</block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">这款NetApp和联想解决方案 是一款灵活的横向扩展架构、非常适合入门级中型企业AI。NetApp存储可提供与本地SSD存储相同或更好的性能、并为数据科学家、数据工程师和IT决策者带来以下优势。</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">可独立扩展的计算和存储、最大限度地降低成本并提高资源利用率。</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">利用集成快照和克隆简化开发和部署工作流、实现瞬时且节省空间的用户工作空间、集成版本控制和自动化部署。</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">企业级数据保护、可实现灾难恢复和业务连续性。</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">NetApp技术营销工程师Karthikeyan Nagalingam</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">联想AI实验室系统部门管理员Jarrett Upton</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">NetApp全闪存阵列产品页面</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">NetApp AFF A400页面</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">NetApp ONTAP 数据管理软件产品页面</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI (NVIDIA-SMI)</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">本节将更详细地介绍此解决方案 的主要组件。</block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">借助NetApp AFF 存储系统、企业可以通过行业领先的性能、卓越的灵活性、云集成和一流的数据管理功能满足企业级存储需求。AFF 系统专为闪存而设计、有助于加速、管理和保护业务关键型数据。</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">此图显示了NetApp AFF A400存储控制器的正面。</block>
  <block id="55f69aa150e5e2d9b4339594dbb70471" category="paragraph"><block ref="55f69aa150e5e2d9b4339594dbb70471" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">此图展示了NetApp AFF A400存储控制器的背面。</block>
  <block id="e83035ebe127e618e86974c913d42589" category="paragraph"><block ref="e83035ebe127e618e86974c913d42589" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">最大横向扩展：2-24个节点(12个HA对)</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">支持25GbE和16GB FC主机</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">通过融合以太网(RoCE)连接到NVMe扩展存储架的100GbE RDMA</block>
  <block id="2f5979909b8c4a0d58f13de4881feaf1" category="list-text">如果未连接NVMe磁盘架、则可以使用100GbE RoCE端口进行主机网络连接</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">完整的12 Gbps SAS连接扩展存储架</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">提供两种配置：</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">以太网：4个25 Gb以太网(SFP28)端口</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">光纤通道：4个16 Gb FC (SFP+)端口</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">100% 8 KB随机读取@.4毫秒400、000次IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">适用于入门级AI/ML部署的NetApp AFF A250功能包括：</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">最大有效容量：35 PB</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">最大横向扩展：2-24个节点(12个HA对)</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">基于最新的NetApp ONTAP 版本ONTAP 9.8或更高版本构建</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">两个25 Gb以太网端口、用于HA和集群互连</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">此外、NetApp还提供了其他存储系统、例如AFF A800和AFF A700、可为大规模AI/ML部署提供更高的性能和可扩展性。</block>
  <block id="b2c0ed3ea756cb47f24ee9aef32e0f01" category="paragraph">ONTAP 9是NetApp推出的最新一代存储管理软件、可帮助企业打造现代化的基础架构并过渡到云就绪数据中心。借助行业领先的数据管理功能，无论数据位于何处， ONTAP 都可以通过一组工具来管理和保护数据。数据也可以自由移动到需要的任何位置：边缘、核心或云。ONTAP 9包含许多功能、可简化数据管理、加快和保护关键数据、以及跨混合云架构打造适应未来需求的基础架构。</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">* ONTAP FabricPool。*此功能可自动将冷数据分层到公共云和私有云存储选项、包括Amazon Web Services (AWS)、Azure和NetApp StorageGRID 对象存储。</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">* 性能和低延迟。 * ONTAP 可提供尽可能高的吞吐量，并尽可能降低延迟。</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9有助于满足不断变化的苛刻业务需求：</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*无缝扩展和无中断运行。* ONTAP 支持向现有控制器以及横向扩展集群无中断添加容量。客户可以升级到 NVMe 和 32 Gb FC 等最新技术，而无需进行成本高昂的数据迁移或中断。</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*与新兴应用程序集成。* ONTAP 使用支持现有企业级应用程序的相同基础架构、为OpenStack、Hadoop和MongoDB等下一代平台和应用程序提供企业级数据服务。</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">NetApp FlexGroup 卷</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">培训数据集通常是一组可能包含数十亿个文件的集合。文件可以包括文本，音频，视频以及其他形式的非结构化数据，这些数据必须进行存储和处理才能并行读取。存储系统必须存储许多小文件、并且必须并行读取这些文件、以便执行顺序和随机I/O</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">FlexGroup 卷(下图)是一个由多个成分卷组成的命名空间、存储管理员可以对其进行管理、使其与NetApp FlexVol 卷类似。FlexGroup 卷中的文件将分配给各个成员卷，并且不会在卷或节点之间进行条带化。它们支持以下功能：</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">为高元数据工作负载提供高达20 PB的容量和可预测的低延迟</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">同一命名空间中最多可容纳4000亿个文件</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">在CPU、节点、聚合和成分卷之间的NAS工作负载中执行并行操作FlexVol</block>
  <block id="19adba666d12642fc956c8a4c4607a66" category="inline-image-macro">"此图显示了一个存储控制器HA对、其中包含许多卷以及FlexGroup 中的主文件。</block>
  <block id="67243c21916276b166b8cad21f937c57" category="paragraph"><block ref="3998ac0cd0b54d5528002049c9fb6e1f" category="inline-image-macro-rx" type="image"></block>"</block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">联想ThinkSystem产品组合</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">部署联想ThinkSystem服务器的主要优势包括：</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">高度可扩展的模块化设计、可随业务发展而扩展</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">在 AI 领域，联想正在采取切实可行的方法帮助企业了解 ML 和 AI 的优势并将其用于工作负载。联想客户可以在联想 AI 创新中心探索和评估联想 AI 产品，以充分了解其特定用例的价值。为了缩短实现价值的时间、这种以客户为中心的方法可以为客户提供解决方案 开发平台的概念验证、这些平台已准备就绪、可供AI使用并进行优化。</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">联想SR670V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">联想ThinkSystem SR670V2机架式服务器可为加速AI和高性能计算(HPC)提供最佳性能。SR670V2最多可支持八个GPU、适合ML、DL和推理的计算密集型工作负载要求。</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">此图显示了三种SR670"配置。第一个显示了四个SXM GPU、其中包含八个2.5英寸HS驱动器和两个PCIe I/O插槽。第二个显示了四个双宽或八个单宽GPU插槽以及两个PCIe I/O插槽、其中包含八个2.5英寸或四个3.5英寸HS驱动器。第三个显示了八个双宽GPU插槽、其中包括六个EDSFF HS驱动器和两个PCIe I/O插槽。</block>
  <block id="f3ebf0cd9319acd4d10b09be0d9220c2" category="paragraph"><block ref="f3ebf0cd9319acd4d10b09be0d9220c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">借助支持高端GPU (包括NVIDIA A100 80 GB PCIe 8x GPU)的最新可扩展Intel Xeon CPU、ThinkSystem SR670V2可为AI和HPC工作负载提供经过优化的加速性能。</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">由于越来越多的工作负载使用加速器的性能、因此对GPU密度的需求也在增加。零售、金融服务、能源和医疗保健等行业正在使用GPU通过ML、DL和推理技术获得更深入的见解并推动创新。</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">ThinkSystem SR670V2是一款经过优化的企业级解决方案 、可在生产环境中部署加速的HPC和AI工作负载、在最大程度地提高系统性能的同时、还能为采用下一代平台的超级计算集群保持数据中心密度。</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">其他功能包括：</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">支持GPU直接RDMA I/O、其中高速网络适配器直接连接到GPU、以最大程度地提高I/O性能。</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">支持GPU直接存储、其中NVMe驱动器直接连接到GPU、以最大程度地提高存储性能。</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf 是用于评估 AI 性能的行业领先基准套件。在此验证中、我们使用了最受欢迎的AI框架之一MXNet的图像分类基准。我们使用了MXNet_Benchmarks培训脚本来推动AI培训。该脚本包含多种常见传统模式的实施、设计速度尽可能快。它可以在一台计算机上运行、也可以在多台主机上以分布式模式运行。</block>
  <block id="f0cbafc85a7a8d2836dd3a3d51266f61" category="sidebar">采用联想ThinkSystem SR670V2的NetApp AFF A400人工智能和ML模型培训</block>
  <block id="3ba3cda3d91af072810327bfd691205c" category="paragraph">在本文档中、我们将演示如何取消应用程序级别的PostgreSQL流式HA/DR解决方案 、以及如何使用存储级别复制基于AWS FSX ONTAP 存储和EC2计算实例构建PostgreSQL HA/DR解决方案。与传统的PostgreSQL应用程序级HA/DR流复制相比、解决方案 可创建一个更简单、更具可比性的系统、并提供同等的结果。</block>
  <block id="32d16eeba786f125b3c1e4750ad34e08" category="paragraph">NetApp建议运行手动故障转移或使用成熟的操作系统集群软件、这些软件可能需要许可证。</block>
  <block id="0a6f7f4424be62bd8f9208328496eeaf" category="inline-link-macro"><block ref="0a6f7f4424be62bd8f9208328496eeaf" category="inline-link-rx"></block></block>
  <block id="b898d8d538a4529dfdb2b8bf025323c2" category="paragraph"><block ref="b898d8d538a4529dfdb2b8bf025323c2" category="inline-link-macro-rx"></block></block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Sathish Thyagarajan、David Arnette、NetApp Mircea Troaca、Lenovo</block>
  <block id="c12ff13215c1f6de4c6dad4b8a475398" category="paragraph">【下划线】#* SQL Server数据库视频*</block>
  <block id="785e5e204bcb101e73976a8c3ad22887" category="paragraph">要了解有关此过程的更多信息、请观看以下视频：</block>
  <block id="c91dcf7c665570f3603fa32cb3a8c644" category="list-text">如果需要、可对容量受限的工作负载使用高级或标准层、而对性能受限的工作负载使用超高级或标准层、同时对默认vSAN存储进行补充。</block>
  <block id="60ce6ba5fcd445684c9982883f234b8c" category="paragraph">要了解按大小或配额显示的Azure NetApp Files 卷性能、请参见 <block ref="62d66f64400ed6e4ba5e012bbe140a31" category="inline-link-macro-rx"></block>。</block>
  <block id="a01ca5d7b443422e0bc655c4d457707f" category="inline-link-macro">Microsoft提供的链接</block>
  <block id="37028a2422f1f35ed56a07f1003896d1" category="admonition">可以使用Azure门户将Azure NetApp Files 卷附加到您的私有云。请遵循此操作 <block ref="c627cf01abf17d7b29d4322a9f16e21d" category="inline-link-macro-rx"></block> 使用Azure门户挂载Azure NetApp Files 数据存储库的分步方法。</block>
  <block id="7dfe1e95238cceec93165ab8ff605d28" category="paragraph">请参见此部分 <block ref="06f6144b70bdd3c5a376672271533656" category="inline-link-macro-rx"></block> 了解可在规模估算过程中使用的详细性能基准。</block>
  <block id="b1404b6b3614fe54358fb1bdb8bd294a" category="list-text">使用数据存储库卷的高级或标准层可获得最佳容量和性能。如果需要性能、则可以使用超层。</block>
  <block id="1048ee221e43763386324d16721681fc" category="list-text">对于子系统挂载要求、请使用高级或超高级层；对于子系统VM的文件共享要求、请使用标准或高级层卷。</block>
  <block id="e421004f0e3e2303f272ef4b0fa6c089" category="list-text">对于具有"标准"网络功能的Azure NetApp Files 卷、支持ExpressRoute快速路径。启用此选项后、FastPath将网络流量直接发送到Azure NetApp Files 卷、从而绕过网关、从而提供更高的带宽和更低的延迟。</block>
  <block id="80a4a92a47a4b87bb9d0fcf9ded1dda8" category="list-text">未启用VAAI。</block>
  <block id="94e2529c9624e06356bacdc7dc76dab9" category="admonition">有关如何使用ANF数据存储库的信息、请联系您所在地区的NetApp或Microsoft解决方案 架构师以获取追加信息。</block>
  <block id="a8a748d1990bd3dbc648c22396cec9c4" category="admonition">基于AWS的VMware Cloud支持适用于ONTAP 的FSX的多AZ和单AZ部署。</block>
  <block id="c3b1da56e0792b4ce28bc91a4bf79841" category="inline-link-macro">使用VMware HCX将工作负载迁移到NetApp Cloud Volume Service NFS数据存储库</block>
  <block id="c2dd2858771476e1bd26526be2c1f5ad" category="list-text"><block ref="c2dd2858771476e1bd26526be2c1f5ad" category="inline-link-macro-rx"></block></block>
  <block id="7ca47d49ee6c57c993203315ea11c82b" category="doc">使用VMware HCX -快速入门指南将工作负载迁移到Google Cloud VMware Engine上的NetApp Cloud Volume Service数据存储库</block>
  <block id="925d41ba352b91ef0de674e109988a23" category="section-title">概述：迁移具有VMware HCX、NetApp Cloud Volume Service数据存储库和Google Cloud VMware Engine (GCVE)的虚拟机</block>
  <block id="ecca6d9dd6ca6c76191faa472f8c6df9" category="paragraph">Google Cloud VMware引擎和Cloud Volume Service数据存储库最常见的使用情形之一是迁移VMware工作负载。VMware HCX是首选选项、可通过各种迁移机制将内部虚拟机(VM)及其数据移动到Cloud Volume Service NFS数据存储库。</block>
  <block id="d5230db8260d991194ad332af34aa9de" category="paragraph">VMware HCX主要是一个迁移平台、旨在简化应用程序迁移、工作负载重新平衡、甚至跨云实现业务连续性。它是Google Cloud VMware Engine Private Cloud的一部分、提供了多种迁移工作负载的方法、可用于灾难恢复(DR)操作。</block>
  <block id="cac5c7468f43bdedfbaa5b47e384516c" category="paragraph">本文档分步指导您配置Cloud Volume Service数据存储库、然后下载、部署和配置VMware HCX、包括内部部署和Google Cloud VMware Engine端的所有主要组件、包括互连、网络扩展和WAN优化、以启用各种VM迁移机制。</block>
  <block id="256044a3a14b99a48569af0ee614f2c4" category="admonition">VMware HCX可用于任何数据存储库类型、因为迁移是在VM级别进行的。因此、本文档适用于计划通过Google Cloud VMware Engine部署Cloud Volume Service以实现经济高效的VMware云部署的现有NetApp客户和非NetApp客户。</block>
  <block id="b0568534d9aa25692e3a5fe6337361bc" category="paragraph">此列表概括介绍了将VM与内部HCX Connector配对并迁移到Google Cloud VMware Engine端的HCX Cloud Manager所需的步骤：</block>
  <block id="08ac9dd8c46a01de111ff552302c4b8b" category="list-text">通过Google VMware引擎门户准备HCX。</block>
  <block id="c51c3de337c64144b065b508d7092f70" category="list-text">将内部VMware HCX Connector与Google Cloud VMware Engine HCX Cloud Manager配对。</block>
  <block id="b8da85496a56d9f8f2c4db60c06b6c4a" category="paragraph">开始之前、请确保满足以下前提条件。有关详细信息，请参见此<block ref="d195855fe41d7993983c9e07318b9bad" category="inline-link-rx"></block>。满足包括连接在内的前提条件后、从Google Cloud VMware Engine门户下载HCX许可证密钥。下载OVA安装程序后、按如下所述继续安装过程。</block>
  <block id="e2f64bf47a1540374c40a3ede73573e5" category="admonition">默认选项为HCX高级版、VMware HCX Enterprise版本也可通过支持服务单获得、并且无需额外付费。请参见<block ref="d860d3a39c377ffee7e9262276d5a062" category="inline-link-rx"></block></block>
  <block id="8cea371309574d6004c96292961aae25" category="inline-link">Google链接</block>
  <block id="792178f6051d02890db289c3d249504a" category="inline-link">设置Cloud VPN或Cloud Interconnect连接</block>
  <block id="136020259e42699a5f3259ade2d1a34f" category="list-text">从启用了VMware vSphere的内部数据中心迁移VM和关联数据需要从数据中心到SDDC环境的网络连接。迁移工作负载之前、<block ref="bef4838acfa84f7c195dab1fed38f189" category="inline-link-rx"></block> 在内部环境和相应的私有云之间。</block>
  <block id="b62ace404956042129e3b88bdf88cc9d" category="list-text">从内部VMware vCenter Server环境到Google Cloud VMware Engine私有云的网络路径必须支持使用vMotion迁移VM。</block>
  <block id="20ced0e16abf47f28e1313f368ad6f6f" category="list-text">确保满足所需<block ref="75de7fce953864ac8abf1081d395e485" category="inline-link-rx"></block> 允许内部vCenter Server与SDDC vCenter之间的vMotion流量。</block>
  <block id="2991589cdf3c2d6d60db9953585e1b04" category="list-text">Cloud Volume Service NFS卷应作为数据存储库挂载到Google Cloud VMware Engine中。请按照本节中详细介绍的步骤进行操作<block ref="5c088b3a89e196aaeb81f75ec6428544" category="inline-link-rx"></block> 将Cloud Volume Service数据存储库连接到Google Cloud VMware Engines主机。</block>
  <block id="4d74daf8e004df493e26c50161d35bd9" category="paragraph">出于测试目的、用于此验证的内部实验室环境通过云VPN进行连接、从而可以在内部连接到Google Cloud VPC。</block>
  <block id="44197d2707e0d62a7cdddb22b96b5d73" category="paragraph"><block ref="44197d2707e0d62a7cdddb22b96b5d73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdd8ea25a7e8ed9b55cbe0a3d16b342d" category="paragraph">有关HCX的更多详细图表、请参见<block ref="7d6a057cc94389224fa6745cc76b1870" category="inline-link-rx"></block></block>
  <block id="cd7d4a329d381d6c2399222be4a728d6" category="example-title">第1步：通过Google VMware引擎门户准备HCX</block>
  <block id="5435b8e0738b76228bad99efecb45790" category="paragraph">在使用VMware Engine配置私有云时、会自动安装HCX Cloud Manager组件。要准备站点配对、请完成以下步骤：</block>
  <block id="f6f646bebf3c14227b9b610041749d2b" category="list-text">登录到Google VMware引擎门户并登录到HCX Cloud Manager。</block>
  <block id="f3c4e020173d4055af3d73eabb546a5f" category="inline-image-macro">通过GCVE资源上的链接访问HCX控制台</block>
  <block id="d481d49ad5e07c065daa1b652e1e93f6" category="inline-image-macro">使用FQDN链接访问HCX控制台</block>
  <block id="1509189c3a021030c9c75afd5e0ee142" category="paragraph">您可以通过单击HCX版本链接登录到HCX控制台<block ref="e0eabfd77e9b6a166bd62bce317f2ca6" category="inline-image-macro-rx" type="image"></block>或者单击vSphere Management Network选项卡下的HCX FQDN。<block ref="1bc7b537d1e927f2f5e06674a9fb9636" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72580ca988ce9234d221d19195a8ced9" category="list-text">在HCX Cloud Manager中、转到*管理&gt;系统更新*。</block>
  <block id="4477d36b1c0d580b9493616b9a3cdc6a" category="inline-image-macro">请求下载链接</block>
  <block id="e3428ddcd1ea8611a819b5a63134abdd" category="list-text">单击*请求下载链接*并下载OVA文件。<block ref="b27b0af334d354a85d901dbf7f557880" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b2574bff5f52ebae3e52462b6f64628" category="list-text">将HCX Cloud Manager更新为可从HCX Cloud Manager UI获得的最新版本。</block>
  <block id="71c11944a5e7c7a2e01d85bf931a4e0c" category="paragraph">要使内部连接器连接到Google Cloud VMware Engine中的HCX Manager、请确保在内部环境中打开相应的防火墙端口。</block>
  <block id="cded3ab78e1131b2cb252673847fc8cd" category="list-text">按照上一步所述、从Google Cloud VMware Engine上的HCX控制台下载ova。</block>
  <block id="80177ed47e2799b2f8133ec987c4f413" category="paragraph"><block ref="80177ed47e2799b2f8133ec987c4f413" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f35d393de16f7f328d28c3c3f9a36fd" category="paragraph">有关分步说明、请参见<block ref="6281ad4977a05e5987f07e864fefe4fe" category="inline-link-rx"></block>。</block>
  <block id="3981acf431a0cb2b387f1fc62e246114" category="paragraph">在内部部署VMware HCX Connector OVA并启动设备后、请完成以下步骤以激活HCX Connector。从Google Cloud VMware Engine门户生成许可证密钥、并在VMware HCX Manager中激活它。</block>
  <block id="842413b7e215b2d5b82a5bb3dd7a07cd" category="inline-image-macro">下载HCX许可证</block>
  <block id="61b61b56e3a9ddaa25f900492dbfaafc" category="list-text">在VMware引擎门户中、单击资源、选择私有云、然后*单击HCX Manager Cloud Version*下的下载图标。<block ref="be9330ae20074d9fd27022c3077c5923" category="inline-image-macro-rx" type="image"></block>打开下载的文件并复制许可证密钥字符串。</block>
  <block id="8680173d99521ba5a429ed524d3615e3" category="admonition">使用在OVA部署期间定义的hcxmanagerIP和密码。</block>
  <block id="35c93ae128c86187e819ac86d8df4979" category="list-text">在*配置SSE/PSC*下、提供平台服务控制器(PSC)的FQDN或IP地址、然后单击*继续*。</block>
  <block id="6098ad379dba0c94396b9b690b83b1b0" category="admonition">对于嵌入式PSC、输入VMware vCenter Server FQDN或IP地址。</block>
  <block id="09bf9812f77e2e14861b7f3360ca026c" category="paragraph"><block ref="09bf9812f77e2e14861b7f3360ca026c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b23a293b550e17ca6e836b05c01b4a76" category="example-title">第4步：将内部VMware HCX Connector与Google Cloud VMware Engine HCX Cloud Manager配对</block>
  <block id="47234b871b1edd33168f7394e72a5b4d" category="paragraph">在内部vCenter上部署和配置HCX Connector后、通过添加配对来建立与Cloud Manager的连接。要配置站点配对、请完成以下步骤：</block>
  <block id="594e3fbccf355af479f921ff2a455e68" category="list-text">要在内部vCenter环境和Google Cloud VMware Engine SDDC之间创建站点对、请登录到内部vCenter Server并访问新的HCX vSphere Web Client插件。</block>
  <block id="bf29c65588093243bdcd92d7e57d228c" category="paragraph"><block ref="bf29c65588093243bdcd92d7e57d228c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b3c5cdedf84c785d5ee65ca00324e36" category="admonition">输入拥有云所有者角色特权的用户访问私有云的Google Cloud VMware Engine HCX Cloud Manager URL或IP地址以及凭据。</block>
  <block id="6b5c33ae4600df59658bcd86a24ca532" category="inline-image-macro">CloudOwner角色的URL或IP地址和凭据屏幕截图。</block>
  <block id="b7b6a499bbb533c0e3da098fa71d75c8" category="paragraph"><block ref="b7b6a499bbb533c0e3da098fa71d75c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3874f23d22312a1be0f07b98dda866c" category="paragraph"><block ref="a3874f23d22312a1be0f07b98dda866c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="593c226b2f1fa412557c01630aaaafa0" category="paragraph"><block ref="593c226b2f1fa412557c01630aaaafa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="575a0d0e1243eeff47338ea176157139" category="inline-image-macro">网络配置文件的屏幕截图。</block>
  <block id="47a6f72e73b15b7be0f3c4cf577c9229" category="paragraph"><block ref="47a6f72e73b15b7be0f3c4cf577c9229" category="inline-image-macro-rx" type="image"></block></block>
  <block id="179a1380fec15d2ca58ae44d36bc70ea" category="list-text">在*互连*选项中选择*服务网格*选项卡以创建服务网格、然后选择内部站点和GCVE SDDC站点。</block>
  <block id="4200f06936ac63230a0663a772209a07" category="paragraph"><block ref="4200f06936ac63230a0663a772209a07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="347a982d83a0b2cce2d1ec814a70ae8f" category="inline-image-macro">vSphere客户端互连页面上的HCX设备的屏幕截图。</block>
  <block id="26c83c715efad97126cacdaebf25d274" category="paragraph"><block ref="26c83c715efad97126cacdaebf25d274" category="inline-image-macro-rx" type="image"></block></block>
  <block id="070b97376b0c0aea0c9cb598600c4662" category="paragraph">可以使用各种VMware HCX迁移技术在内部部署和GCVE SDDC之间双向迁移工作负载。可以使用多种迁移技术将VM移入和移出VMware HCX激活的实体、例如HCX批量迁移、HCX vMotion、HCX冷迁移、HCX复制辅助vMotion (适用于HCX Enterprise版本)和HCX操作系统辅助迁移(适用于HCX Enterprise版本)。</block>
  <block id="a50268e48a4ee751d804978922edf189" category="paragraph">要了解有关各种HCX迁移机制的更多信息、请参见<block ref="78adb493f3638835899da003743379e3" category="inline-link-rx"></block>。</block>
  <block id="de5218d95fb66ad99c822109709a45af" category="paragraph">* HCX vMotion*</block>
  <block id="803853313afe589d091d3f55583d78c2" category="paragraph">本节介绍HCX vMotion机制。此迁移技术使用VMware vMotion协议将VM迁移到GCVE。vMotion迁移选项用于一次迁移单个VM的VM状态。此迁移方法期间不会发生服务中断。</block>
  <block id="6b253c8fd6849183f558040da38608cb" category="paragraph"><block ref="6b253c8fd6849183f558040da38608cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="844c529dbe1866abc23447f68eb60ba6" category="list-text">在迁移虚拟机向导中、选择远程站点连接(目标GCVE)。</block>
  <block id="4e862b96a802868c38004aa7c404252b" category="paragraph"><block ref="4e862b96a802868c38004aa7c404252b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2a3abee640eaa37034e3ce3f7b7075e" category="list-text">更新必填字段(集群、存储和目标网络)、然后单击验证。</block>
  <block id="dbccaf1da09c1555918b6548737f4c62" category="paragraph"><block ref="dbccaf1da09c1555918b6548737f4c62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a88d0b48c0e4e339e4f73353d906d12" category="admonition">vMotion传输会捕获VM活动内存、其执行状态、IP地址及其MAC地址。有关HCX vMotion的要求和限制的详细信息、请参见<block ref="23e132bfd0fa1c0804ce8b87a8fad5cd" category="inline-link-rx"></block>。</block>
  <block id="9292100550c5fda83387e2e78b8a2a2a" category="paragraph"><block ref="9292100550c5fda83387e2e78b8a2a2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38f70a328b4ae90f9650bc4c029b6a3f" category="admonition">目标CVS NFS数据存储库应具有足够的空间来处理迁移。</block>
  <block id="2de1e2776c8a8d3b752e50dc8c6550df" category="paragraph">无论您的目标是全云还是混合云、以及驻留在内部任何类型/供应商存储上的数据、Cloud Volume Service和HCX都可以提供出色的选项来部署和迁移应用程序工作负载、同时通过将数据需求无缝地迁移到应用程序层来降低TCO。无论使用何种情形、都可以选择Google Cloud VMware Engine以及Cloud Volume Service、以便快速实现云优势、一致的基础架构以及跨内部和多个云的运营、工作负载的双向可移植性以及企业级容量和性能。使用VMware vSphere复制、VMware vMotion甚至网络文件复制(Network File Copy、NFCs)连接存储和迁移VM时、使用的过程与步骤相同。</block>
  <block id="6bb8d723218f4efa76cd05165c603ac6" category="list-text">现在、您可以在Google Cloud VMware Engine SDDC上使用Cloud Volume Service作为数据存储库。</block>
  <block id="06b37831abeee3229c61a3285dc4100c" category="list-text">您可以轻松地将数据从内部迁移到Cloud Volume Service数据存储库。</block>
  <block id="dcb763cc64570798740f3e41b84fff0e" category="list-text">您可以轻松地扩展和缩减Cloud Volume Service数据存储库、以满足迁移活动期间的容量和性能要求。</block>
  <block id="267029140dfbe181dd69e7d084de9b69" category="section-title">Google和VMware提供的视频供参考</block>
  <block id="e35dee203b7c81af1f3954054112ba15" category="example-title">来自Google</block>
  <block id="50144090c2258cae139ecf6022e7367b" category="inline-link-macro">使用GCVE部署HCX Connector</block>
  <block id="b7b1de0b057bbef976725c6fff3da9b9" category="list-text"><block ref="b7b1de0b057bbef976725c6fff3da9b9" category="inline-link-macro-rx"></block></block>
  <block id="328f11633999c58a7b282b8632e2797d" category="inline-link-macro">使用GCVE配置HCX ServiceMesh</block>
  <block id="79cb5f4e657f45df30765c695fd1925a" category="list-text"><block ref="79cb5f4e657f45df30765c695fd1925a" category="inline-link-macro-rx"></block></block>
  <block id="7a749829f023d0ee25c026f4f6bbba9a" category="inline-link-macro">将具有HCX的VM迁移到GCVE</block>
  <block id="a53a9cd13cd53b632a558fc3657092ab" category="list-text"><block ref="a53a9cd13cd53b632a558fc3657092ab" category="inline-link-macro-rx"></block></block>
  <block id="252de7413389db6514f76f43d66fd8e3" category="example-title">来自VMware</block>
  <block id="13e623e9a14240dd859556650e9b531a" category="inline-link-macro">适用于GCVE的HCX Connector部署</block>
  <block id="d323fc5e6199a5240de090ee56887d79" category="list-text"><block ref="d323fc5e6199a5240de090ee56887d79" category="inline-link-macro-rx"></block></block>
  <block id="691fd2fc5f5666a82025c09044b4227e" category="inline-link-macro">适用于GCVE的HCX ServiceMeshy配置</block>
  <block id="1d057bc0c304f69e3c2b912a056d3823" category="list-text"><block ref="1d057bc0c304f69e3c2b912a056d3823" category="inline-link-macro-rx"></block></block>
  <block id="f27a9b33e86b3a166fd93f5581d2fd88" category="inline-link-macro">HCX工作负载迁移到GCVE</block>
  <block id="4ac5ecc506f53d87d5405d25cca52053" category="list-text"><block ref="4ac5ecc506f53d87d5405d25cca52053" category="inline-link-macro-rx"></block></block>
  <block id="b5375bdf07e11b544fe361d241528cd4" category="list-text">Google Cloud VMware Engine文档</block>
  <block id="cc7538adb5f65b8e12ceeea77a9fe2b4" category="inline-link"><block ref="cc7538adb5f65b8e12ceeea77a9fe2b4" category="inline-link-rx"></block></block>
  <block id="c403f0f0cd3710f7ff6a40c31193feef" category="paragraph"><block ref="c403f0f0cd3710f7ff6a40c31193feef" category="inline-link-rx"></block></block>
  <block id="19e28367f565bf74c0b929f09ffdeb90" category="list-text">Cloud Volume Service文档</block>
  <block id="87a450a8cc5c8bc3aa98266544b13aeb" category="inline-link"><block ref="87a450a8cc5c8bc3aa98266544b13aeb" category="inline-link-rx"></block></block>
  <block id="bc99ee2635f4933c3a1ae1a2d397722f" category="paragraph"><block ref="bc99ee2635f4933c3a1ae1a2d397722f" category="inline-link-rx"></block></block>
  <block id="92cbc7969081067fa7972b77f8b4c803" category="inline-link"><block ref="92cbc7969081067fa7972b77f8b4c803" category="inline-link-rx"></block></block>
  <block id="dccf3c5043aaab19b4c6eed2cd51be7e" category="paragraph"><block ref="dccf3c5043aaab19b4c6eed2cd51be7e" category="inline-link-rx"></block></block>
  <block id="204c2f72244c7b6bb96fa507fcbfdde0" category="sidebar">使用VMware HCX将工作负载迁移到Cloud Volume Service NFS数据存储库</block>
  <block id="fbaad71632f1f86a6aec0eb25bf981d7" category="list-text">为了获得最佳存储性能、请将文件系统容量配置为数据库总使用量的1.35倍。</block>
  <block id="697ac904ffe5f281c2b20466e99a46ec" category="paragraph"><block ref="697ac904ffe5f281c2b20466e99a46ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ea2cbade31de8af1dca89093e681575" category="paragraph">以下视频演示了本文档中介绍的一些功能：</block>
  <block id="1780877562a197bb240c255e7ebc64a6" category="paragraph"><block ref="1780877562a197bb240c255e7ebc64a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f281f23fa0eaa9fab3de640f4c4ed29" category="cell">1.14</block>
  <block id="b2311a2cf7a04db2bfe860c3fa17635c" category="cell">硬件组件</block>
  <block id="7b42b4827c459034b51ee8ce9f497ca3" category="cell">交换机(数据网络)</block>
  <block id="d5cbf018e46e897c3774dc4576d35dbe" category="cell">交换机(管理网络)</block>
  <block id="4c6ba3c2ecfdab7b2b5151a4715c51c0" category="cell">AFF 存储系统</block>
  <block id="eba1f3287bdc33dfa25c084b5e15a4c5" category="cell">9.12.1</block>
  <block id="8dfda84fc7f59655e20a770603bf9231" category="cell">23.01</block>
  <block id="a6eee2bc9df13513ff08680b88b5140c" category="paragraph">在NetApp执行Anthos Ready平台验证期间、实验室环境是基于下图构建的、通过该图、我们可以使用各种NetApp ONTAP 存储后端测试多种场景。</block>
  <block id="3001330ca359a25f2bb0fb3a80b81f98" category="inline-link"><block ref="3001330ca359a25f2bb0fb3a80b81f98" category="inline-link-rx"></block></block>
  <block id="ce31d50048cf83e159c11cdf9571f300" category="paragraph"><block ref="ce31d50048cf83e159c11cdf9571f300" category="inline-link-rx"></block></block>
  <block id="e961adb60321df286b916effec21c9d5" category="paragraph">NetApp拥有多个存储平台、这些平台已通过我们的Astra Trident Storage Orchestrator认证、可为作为容器部署的应用程序配置存储。</block>
  <block id="82dc86caf99045e3dfd059ffe973d587" category="list-text">NetApp Cloud Volumes Service (GCP)和Azure NetApp Files 可在云中提供基于文件的存储。</block>
  <block id="e0219edd422866b0cdb0aaa5f2b9352e" category="list-text">Amazon FSX for NetApp ONTAP 是AWS上的一项完全托管服务、可为基于文件的使用情形提供存储。</block>
  <block id="8490bfef5919608f9d8461a6bb270666" category="paragraph">NetApp每季度定期遵守有关验证我们的Astra Trident CSI兼容存储流程编排程序和ONTAP 存储系统是否使用Anthos版本的请求。</block>
  <block id="594e1ec3daa27e540baa061f731f028f" category="cell">ONTAP 9.12.1</block>
  <block id="7f7813d8ff1a7fae9bca0ef452fb1346" category="cell">Multiwriter、卷扩展、快照、PVCDataSource</block>
  <block id="8c56d327dfefc3dfd3c4c4fbe25a8bd1" category="cell">原始块、卷扩展、快照、PVCDataSource</block>
  <block id="9fe6d7d50b2c6958117a19834e038c82" category="cell">1.13</block>
  <block id="775d4bb28d257a6aa23992563a82c458" category="cell">22.10</block>
  <block id="74eb178224c5fa701fbcd96998feaafe" category="cell">ONTAP 9.9.1</block>
  <block id="e0076fd5294e757abc41b2328ed8c57d" category="cell">要素 12.3</block>
  <block id="001a38f118eab6df015a51079735d9c9" category="paragraph">有关 Anthos 的详细信息，请参见位于的 Anthos 网站<block ref="984918f1ee4e70aa6181e0564d0768e7" category="inline-link-rx"></block>。</block>
  <block id="dbadbc59fa29afd33e371d5285fde4cf" category="paragraph">NetApp公司Banu Sundharand Suresh ThopPay</block>
  <block id="94806f6a6daed15d3a6ea4f0146cf8ee" category="paragraph">NetApp 拥有多个存储系统，非常适合企业数据中心和混合云部署。NetApp产品组合包括适用于NetApp ONTAP 存储系统的NetApp ONTAP 、Cloud Volumes ONTAP 、Cloud Volumes Service 、Azure NetApp Files 、FSxN、所有这些产品均可为容器化应用程序提供永久性存储。</block>
  <block id="57f64c5c85667657a2c67b472c545e5a" category="paragraph">请参见<block ref="0c665fc00d0d39d9ca9d157ca926b271" category="inline-link-rx"></block> 已验证版本的支持列表。</block>
  <block id="8986a7e5e5d0b79b5251a648f9f67ef6" category="paragraph">Astra Trident是一款完全受支持的开源存储编排程序、适用于容器和Kubernetes分发版、包括Anthos。Trident可与包括NetApp ONTAP 在内的整个NetApp存储产品组合配合使用、并且还支持NFS和iSCSI连接。Trident 允许最终用户从其 NetApp 存储系统配置和管理存储，而无需存储管理员干预，从而加快了 DevOps 工作流的速度。</block>
  <block id="5be08e29583206baf8c89778e711c743" category="paragraph"><block ref="5be08e29583206baf8c89778e711c743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e79464fd5ecc0abac7a7f768780ea0f4" category="paragraph">有关最新版本的Astra Trident的文档、请参见<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>。已测试的 Trident 版本的支持列表，可在该支持列表中找到 Kubernetes 分发版本<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>。</block>
  <block id="dee50dd9c6fd0b4d11789e8a074455c0" category="paragraph">有关Astra Trident安装的详细信息、请参见<block ref="df28848dc0c60e349970187bfd75a0df" category="inline-link-rx"></block>。</block>
  <block id="6cfca408e9e3b476e6440302dbe3a550" category="section-title">创建存储系统后端</block>
  <block id="6d82ca16bfbce249e1f9ea541bff13ff" category="inline-link-macro">创建后端。</block>
  <block id="1e449644660ede384d0f8370105c8852" category="paragraph">完成 Astra Trident 操作员安装后，您必须为所使用的特定 NetApp 存储平台配置后端。请单击以下链接继续设置和配置Astra Trident。<block ref="0510ad325b52db9e306380d77ace3c72" category="inline-link-macro-rx"></block></block>
  <block id="14f4c7abe09c4481722f1fa6563f2604" category="section-title">创建存储类。</block>
  <block id="69dd4ff02a34defa6f31ed5f8bb209f6" category="paragraph">创建后端后、您必须创建一个存储类、Kubernetes用户需要卷时将指定此类。Kubernetes用户使用按名称指定存储类的永久性卷声明(Persistent Volume Claim、PVC)来配置卷。请单击以下链接创建存储类。<block ref="034759ff187a64d8fb38f587d14777c0" category="inline-link-macro-rx"></block></block>
  <block id="50cbd0d28725f746b370915ee052232c" category="section-title">动态配置卷</block>
  <block id="72407fd74e9ce26b706ed85bc90bd124" category="inline-link-macro">创建PVC</block>
  <block id="35a0b000c0ba5920cef3268fee2323b4" category="paragraph">要动态配置卷、您必须使用存储类创建Kubernetes永久性卷声明(PVC)对象。按照以下链接创建PVC对象。<block ref="0af94896212bb2843496226f6871904c" category="inline-link-macro-rx"></block></block>
  <block id="279865aaa331ec925a99c3272eb45478" category="section-title">使用卷</block>
  <block id="fed9c63a200801110024280f08877e16" category="inline-link-macro">将卷挂载到Pod中</block>
  <block id="d822bbb4d6960be49b781e594679db64" category="paragraph">应用程序可以通过在POD中挂载卷来使用上述步骤中配置的卷。以下链接显示了一个示例。<block ref="48fadb04c46cf19aa1b5e274dd9b5da9" category="inline-link-macro-rx"></block></block>
  <block id="34ea6423c17a78bdf284132538078bac" category="summary">本文档介绍以下主题、错误重命名问题和解决方案 验证、降低CPU利用率以缩短I/O等待时间、加快Kafka代理恢复时间以及提高云和内部环境的性能。</block>
  <block id="47e33b895b285760d0d1bcb64e42e5d0" category="doc">TR-4947：Apache Kafka工作负载与NetApp NFS存储—功能验证和性能</block>
  <block id="62233ad21bd81bbbff938616c0106477" category="paragraph">NetApp公司Shantanu Chakole、Karthikeyan Nagalingam和Joe Scott</block>
  <block id="8150fcf9bdcb89b4901e10f34571667e" category="paragraph">Kafka是一个分布式发布订阅消息传送系统、具有一个强大的队列、可以接受大量消息数据。借助Kafka、应用程序可以非常快速地对主题进行数据写入和读取。由于Kafka具有容错能力和可扩展性、因此通常在大数据空间中使用它作为快速载入和移动多个数据流的可靠方式。使用情形包括流处理、网站活动跟踪、指标收集和监控、日志聚合、实时分析等。</block>
  <block id="91bd7e3ce9e18912d60b1c4cd3f9f7d2" category="inline-link">重命名操作不明智</block>
  <block id="7453e2e58a9df0c80d79a8fd0ab4ed1e" category="paragraph">虽然NFS上的正常Kafka操作运行良好、但<block ref="99770e723960c674a5dd9394155d2111" category="inline-link-rx"></block> 在调整NFS上运行的Kafka集群的大小或重新分区期间、问题描述 会使应用程序崩溃。这是一个重要的问题描述 、因为出于负载平衡或维护目的、必须调整Kafka集群的大小或对其进行重新分区。您可以找到其他详细信息<block ref="eff8c14b44ddf611b2ff09607d7665a2" category="inline-link-rx"></block>。</block>
  <block id="229b214236b3c346dc9f6c75d096604b" category="paragraph">本文档介绍了以下主题：</block>
  <block id="995fd45f2f5174bc9a5d8029655c1b88" category="list-text">错误重命名问题和解决方案 验证</block>
  <block id="7c9e8a4fdb767e60565e9c4b4d95eed2" category="list-text">降低CPU利用率以缩短I/O等待时间</block>
  <block id="915a1ce7d578786f5aa93e503452d2b9" category="list-text">Kafka代理恢复时间更快</block>
  <block id="5810e3ce10e4e8edfee5f25cae3459c1" category="list-text">云端和内部环境中的性能</block>
  <block id="7910f734d679965fb4e725f87dcb3c61" category="section-title">为什么要对Kafka工作负载使用NFS存储？</block>
  <block id="932e5edaa1f66c6b109d045d3c7ba0bc" category="paragraph">生产应用程序中的Kafka工作负载可以在应用程序之间流式传输大量数据。此数据会保留并存储在Kafka集群中的Kafka代理节点中。Kafka也以可用性和并行性而闻名、它通过将主题划分为分区、然后在整个集群中复制这些分区来实现这一点。这最终意味着、流经Kafka集群的大量数据通常会成倍增加。NFS可以随着代理数量的变化轻松快速地重新平衡数据。对于大型环境、在代理数量发生变化时跨DAS重新平衡数据非常耗时、在大多数Kafka环境中、代理数量经常发生变化。</block>
  <block id="a49afd0b2827b8f1d1b83a36f75d3efc" category="paragraph">其他优势包括：</block>
  <block id="889d2761ec65245a621931da633b8cfe" category="list-text">*成熟度。* NFS是一种成熟的协议、这意味着实施、保护和使用NFS的大部分方面都已被充分理解。</block>
  <block id="c231daeb716325a2bca62a5e30431c8d" category="list-text">*开放式* NFS是一种开放式协议、其持续开发已作为一种免费的开放式网络协议记录在互联网规格中。</block>
  <block id="6526aeb62806bf842c7ab66949c2de0c" category="list-text">*经济高效。* NFS是一种用于网络文件共享的低成本解决方案 、由于它使用现有网络基础架构、因此易于设置。</block>
  <block id="8c70ad2ab84f33f7d462109fc8edc329" category="list-text">*集中管理。*集中管理NFS可减少单个用户系统上对添加软件和磁盘空间的需求。</block>
  <block id="dbb4f7d4eb0147816ffd5d84e4a79e19" category="list-text">*分布式。* NFS可用作分布式文件系统、从而减少了对可移动介质存储设备的需求。</block>
  <block id="37377984e38462f1628867b8e7a1e772" category="section-title">为什么选择NetApp来处理Kafka工作负载？</block>
  <block id="300fdb82e8f9a8b6ebb6d42a92483544" category="paragraph">NetApp NFS实施被视为该协议的黄金标准、用于无数企业级NAS环境。除了NetApp的信誉之外、它还具有以下优势：</block>
  <block id="f7e7d6aebe6163c0f639238b2e1a0333" category="list-text">可靠性和效率</block>
  <block id="735980c2ea138788423c50ba2ef7c6c5" category="list-text">可扩展性和性能</block>
  <block id="a8fbd78750bfdd72ecb8371fa5fa9648" category="list-text">高可用性(NetApp ONTAP 集群中的HA配对节点)</block>
  <block id="e005f1a13de2a01927e39ecb29ff1a7c" category="list-text">*灾难恢复(NetApp SnapMirror)。*您的站点发生故障、或者您希望从其他站点跳转并从您离开的位置继续。</block>
  <block id="81757222cee28779fe25327e8ef3f5a2" category="list-text">存储系统的易管理性(使用NetApp OnCommand 进行管理和管理)。</block>
  <block id="7d411cbcfa7cf122ac8423795b89a4b8" category="list-text">*负载平衡。*集群允许您从不同节点上托管的数据LIF访问不同的卷。</block>
  <block id="6c38013b179499c32ccf05a98b927de6" category="list-text">*无中断操作。* LIF或卷移动对NFS客户端是透明的。</block>
  <block id="cc2e9a005ff6b9d50a1fca9914e8eac0" category="summary">本节介绍了对问题描述 进行的愚蠢重命名以及NFS服务器和NFS客户端为处理问题描述 而需要进行的更改。</block>
  <block id="0d5e61a5d0c056718a15d6df7037a50c" category="doc">NetApp解决方案 for fly将问题描述 for NFS重命名为Kafka工作负载</block>
  <block id="e5ee0fc73f4f4f38e75acb2c0b2343be" category="paragraph">Kafka的构建假定底层文件系统符合POSIX标准：例如XFS或ext4。Kafka资源重新平衡会在应用程序仍在使用文件时删除这些文件。符合POSIX的文件系统允许取消链接以继续。但是、它仅会在对文件的所有引用均消失后删除该文件。如果底层文件系统已通过网络连接、则NFS客户端将截获取消链接调用并管理工作流。由于正在取消链接的文件存在待定打开状态、因此NFS客户端会向NFS服务器发送重命名请求、并在未链接的文件最后一次关闭时对已重命名的文件执行删除操作。此行为通常称为NFS愚蠢的重命名、它由NFS客户端进行编排。</block>
  <block id="f17efbdff90d69935a8d84a6215665a5" category="paragraph">由于此行为、使用NFSv3服务器中存储的任何Kafka代理都会遇到问题。但是、NFSv4.x协议具有一些功能、可以通过允许服务器对打开的未链接文件负责来解决此问题描述。支持此可选功能的NFS服务器会在文件打开时将所有权功能传递给NFS客户端。然后、当打开并等待处理时、NFS客户端将停止取消链接管理、并允许服务器管理此流。虽然NFSv4规范提供了实施准则、但到目前为止、还没有任何已知的NFS服务器实施支持此可选功能。</block>
  <block id="219af746424bba4643138d0820ab40b5" category="paragraph">NFS服务器和NFS客户端需要进行以下更改、才能处理愚蠢的重命名问题描述 ：</block>
  <block id="36efd47a4ba95b58e3b2a0f2ed7420ad" category="list-text">*对NFS客户端(Linux)所做的更改。*打开文件时、NFS服务器会通过一个标志进行响应、指示能够处理已打开文件的解除链接。NFS客户端更改允许NFS服务器在存在标志的情况下处理解除链接。NetApp已使用这些更改更新了开源Linux NFS客户端。更新后的NFS客户端现在在RHEL8.7和RHEL9.1中普遍可用。</block>
  <block id="f400588f268c9f90112ff6290a81575a" category="list-text">*对NFS服务器所做的更改。* NFS服务器会跟踪打开情况。现在、服务器会管理现有打开文件的取消链接、以匹配POSIX语义。关闭上次打开的文件后、NFS服务器会启动文件的实际删除、从而避免了愚蠢的重命名过程。ONTAP NFS服务器已在其最新版本ONTAP 9.12.1.中实施此功能。</block>
  <block id="21a87b96dd7bfc9863d6bca5fc12f005" category="paragraph">通过对NFS客户端和服务器进行上述更改、Kafka可以安全地获得网络连接NFS存储的所有优势。</block>
  <block id="bf06620c2cdf1b79a1673e62b409eae0" category="summary">针对错误重命名问题的NetApp解决方案 为以前与NFS不兼容的工作负载提供了一种简单、廉价且集中管理的存储形式。</block>
  <block id="d4baa2e552beefa00e93883ed51f3ba2" category="summary">在内部部署中、我们使用NetApp AFF A900存储控制器和ONTAP 9.12.1RC1来验证Kafka集群的性能和扩展能力。我们使用的测试平台与先前使用ONTAP 和AFF 的分层存储最佳实践中的测试平台相同。</block>
  <block id="1e753c720a0b773dd9d69024ca734577" category="doc">使用AFF A900内部部署进行性能概述和验证</block>
  <block id="94391d4f56386aadb6f39e1a596f2427" category="paragraph">在内部部署中、我们使用NetApp AFF A900存储控制器和ONTAP 9.12.1RC1来验证Kafka集群的性能和扩展能力。我们使用的测试平台与先前使用ONTAP 和AFF 的分层存储最佳实践中的测试平台相同。</block>
  <block id="b1e7584c9874b52caeb25c3646e8f273" category="paragraph">我们使用Confluent Kafka 6.2.0对AFF A900进行了评估。集群具有八个代理节点和三个Zookeeper节点。在性能测试中、我们使用了五个OMB辅助节点。</block>
  <block id="e41e134e8e174865d04443048e1866af" category="paragraph"><block ref="e41e134e8e174865d04443048e1866af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="637d24b49cc32320a5e44ea905f65d10" category="paragraph">我们使用NetApp FlexGroup实例为日志目录提供了一个命名空间、从而简化了恢复和配置。我们使用NFSv4.1和pNFS为日志段数据提供直接路径访问。</block>
  <block id="50ff5e789ae0742f2485b5147c072643" category="section-title">客户端调整</block>
  <block id="fc3a7751877b7f4e9a71c82ad3da7e44" category="paragraph">每个客户端都使用以下命令挂载FlexGroup 实例。</block>
  <block id="a5b2794b174e20f0b6dd9350cba3df82" category="paragraph">此外、我们还增加了<block ref="44d907b0e69e5aa31320f9e86a7ef440" prefix=" " category="inline-code"></block> 默认值<block ref="ea5d2f1c4608232e07d3aa3d998e5135" prefix=" " category="inline-code"></block> to<block ref="045117b0e0a11a242b9765e79cbf113f" prefix=" " category="inline-code"></block>。这与ONTAP 中的默认会话插槽限制匹配。</block>
  <block id="31305973da10c7b492918a2ad2b3deee" category="section-title">Kafka代理调整</block>
  <block id="8f9087ae165490f7d809fb8ffd625bba" category="paragraph">为了最大程度地提高测试系统中的吞吐量、我们显著增加了某些关键线程池的默认参数。对于大多数配置、我们建议遵循Confluent Kafka最佳实践。此调整用于最大程度地提高存储未处理I/O的并发性。可以根据代理的计算资源和存储属性调整这些参数。</block>
  <block id="0e80721091b1e58209e2877462ebbd21" category="section-title">工作负载生成器测试方法</block>
  <block id="9707ee58e22a2478985c56025e656cad" category="paragraph">我们使用的OMB配置与对吞吐量驱动程序和主题配置进行云测试相同。</block>
  <block id="dbdfae7d08a693255815e0890397b78f" category="list-text">已在AFF 集群上使用Ansible配置FlexGroup 实例。</block>
  <block id="6c2577e00543c33096c33e1b2e79742d" category="list-text">已在ONTAP SVM上启用pNFS。</block>
  <block id="7fe5c7aaf126c7432ba86d9e145f59a4" category="list-text">此工作负载是使用与Cloud Volumes ONTAP 相同的工作负载配置通过吞吐量驱动程序触发的。请参见第节"<block ref="f628eac6c1ff8c1b0462e81ea7b2efc1" category="inline-xref-macro-rx"></block>"。工作负载使用的复制系数为3、这意味着在NFS中维护了三个日志段副本。</block>
  <block id="dfe2c8a29d6798ed2d2dae4af3b4e5e7" category="inline-xref">探索存储限制</block>
  <block id="c2a038ea3f35076598b99806cd90a3c5" category="list-text">最后、我们使用积压数据完成了测量、以衡量消费者是否能够跟上最新消息的步伐。OMB通过在测量开始期间暂停使用者来构建积压。这会产生三个不同的阶段：创建积压(仅限生产商的流量)、积压耗尽(消费者在一个主题中遇到未完成的事件时会遇到大量耗时的阶段)和稳定状态。请参见第节"<block ref="a2eee99fc052f067d68a9273d62093f1" category="inline-xref-macro-rx"></block>"了解更多信息。</block>
  <block id="158bb82f009332b2fe16aba7bebc0c15" category="section-title">稳定状态性能</block>
  <block id="216824b7a5a0da585075bc35333402f6" category="paragraph">我们使用Open消息 基准测试对AFF A900进行了评估、以提供与AWS中的Cloud Volumes ONTAP 和AWS中的DAS类似的比较结果。所有性能值均表示生产商和消费者级别的Kafka-cluster吞吐量。</block>
  <block id="34121e3b81b5330bbb499603af5609e6" category="paragraph">借助Confluent Kafka和AFF A900实现稳定的状态性能、生产者和使用者的平均吞吐量均超过3.4 GBps。在整个Kafka集群中、此消息超过340万条。通过直观地显示BrokerTopicMetrics的持续吞吐量(以字节/秒为单位)、我们可以看到AFF A900所支持的出色稳定状态性能和流量。</block>
  <block id="c99b1e0f8a1447330448c8c7dc3df6b6" category="inline-image-macro">此图显示了代理网络吞吐量。</block>
  <block id="0b01283779b69987a07a2c2d50ccb15d" category="paragraph"><block ref="0b01283779b69987a07a2c2d50ccb15d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9877d3e22635e0b37f0b74ab2d832d05" category="paragraph">这与每个主题所传送消息的视图非常一致。下图按主题显示了细分情况。在测试的配置中、我们在四个主题中看到了每个主题近900、000条消息。</block>
  <block id="a0a1dff924171568d861731a12802528" category="paragraph"><block ref="a0a1dff924171568d861731a12802528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc35bf5a15bb7c42ab972c7038f773f5" category="section-title">极致性能并探索存储限制</block>
  <block id="58b4fe8d21ee892b9633349960eaa7ab" category="paragraph">对于AFF 、我们还使用积压功能对OMB进行了测试。在Kafka集群中创建积压事件时、积压功能会暂停使用者订阅。在此阶段、仅会发生生成方流量、此流量会生成提交到日志的事件。这最能模拟批处理或脱机分析工作流；在这些工作流中、用户订阅会启动、并且必须读取已从代理缓存中逐出的历史数据。</block>
  <block id="5519a4dc3c42cae95400800bbaeaecfc" category="paragraph">为了了解此配置中对使用者吞吐量的存储限制、我们测量了纯生产者阶段、以了解A900可以吸收多少写入流量。请参见下一节"<block ref="dbf93a9130703fe2432219c42c2bf311" category="inline-xref-macro-rx"></block>了解如何利用这些数据。</block>
  <block id="feec11a45c1fd079250c6f3603d708cd" category="paragraph">在本次测量中、我们发现、在仅用于生产商的部分、峰值吞吐量会突破A900性能的限制(此时、其他代理资源不会饱和地为生产商和消费者提供服务)。</block>
  <block id="364db2a868997ed12ba4b16039b53a68" category="paragraph"><block ref="364db2a868997ed12ba4b16039b53a68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f237b36d09d10702066fb620cf352dcf" category="admonition">我们将此度量值的消息大小增加到16k、以限制每条消息的开销、并最大程度地提高NFS挂载点的存储吞吐量。</block>
  <block id="9e1dbe9319ed19b15341f3000f56398a" category="paragraph">Confluent Kafka集群的生产商吞吐量峰值为4.03 GBps。</block>
  <block id="3355268f822f520fe03b272691c2e428" category="paragraph">在OMB完成事件积压填充后、使用者流量将重新启动。在对积压量进行测量期间、我们在所有主题中观察到消费者峰值吞吐量超过20 Gbps。存储OMB日志数据的NFS卷的总吞吐量接近~30Gbps。</block>
  <block id="157a25969caf77d231e319ce70f0b637" category="section-title">规模估算指南</block>
  <block id="2e4bacad236b9e36d868b929042e2bad" category="inline-link">规模估算指南</block>
  <block id="eec877a6f9c2530996fae2423259c2c6" category="paragraph">Amazon Web Services提供了<block ref="e9ae0e8f89540055129f0fae422bdb9a" category="inline-link-rx"></block> 用于Kafka集群规模估算和扩展。</block>
  <block id="cc4abcaa3ba3e4f795b82759d3dcd056" category="paragraph">此规模估算为确定Kafka集群的存储吞吐量要求提供了一个有用的公式：</block>
  <block id="f2fb73fb163775775c1145d28c68ad20" category="paragraph">对于复制因子为r的tcluster集群生成的聚合吞吐量、代理存储收到的吞吐量如下：</block>
  <block id="0acbbdd0cc159664d8baab43c6d168bd" category="paragraph">这一点可以进一步简化：</block>
  <block id="28c949d6bdead032a1410c176cbf74cb" category="paragraph">使用此公式、您可以根据Kafka热层需求选择合适的ONTAP 平台。</block>
  <block id="df3f8ed04b35156def4360bb05a77cc1" category="paragraph">下表说明了A900的预期生产者吞吐量以及不同的复制因素：</block>
  <block id="329589e3ff014cb50ee2238aecc6a867" category="cell">复制因子</block>
  <block id="75ec49708cc8881a7762e3740e342ca3" category="cell">生产者吞吐量(GPP)</block>
  <block id="c2b3050f7fde2050bb86e4e9ef0f7567" category="cell">3 (测量值)</block>
  <block id="31053ad0506e935470ca21b43cae98cf" category="cell">3.4</block>
  <block id="a9d9d1b0257dda96d595bd00149cccdb" category="cell">10.2</block>
  <block id="8a1762b0db0285b0ca6661669e3a9aec" category="summary">在功能验证方面、我们显示了具有NFSv3存储挂载的Kafka集群无法执行分区重新分配等Kafka操作、而具有修复程序的NFSv4上挂载的另一个集群可以执行相同的操作而不会造成任何中断。</block>
  <block id="2b1635c7ae2a72d0b26454157a03e197" category="doc">功能验证—错误的重命名修复</block>
  <block id="a8ead7a6a54d47ea0a38e64908ab321f" category="section-title">验证设置</block>
  <block id="e087dbbdc5792f1e574cdf41c135d858" category="paragraph">此设置将在AWS上运行。下表显示了用于验证的不同平台组件和环境配置。</block>
  <block id="cccdd75af54f32ac7f570bbcca39f516" category="cell">Confuent Platform 7.2.1版</block>
  <block id="185b9d1a84206af090c5f70ac68f24ad" category="list-text">3个Zookepers—T3.xlarge</block>
  <block id="6677060ff0c6c4620e427121a576713c" category="list-text">4个代理服务器—r3.xlarge</block>
  <block id="61e62294effd3d2046982e7d5a22b824" category="list-text">1个Grafana—T3.xlarge</block>
  <block id="1e2657a43dca2051e4684eb73c2a856c" category="list-text">1个控制中心—T3.xlarge</block>
  <block id="2dcca349e332f9e312cebc29485dadf0" category="list-text">3个生产者/使用者</block>
  <block id="00ecb59dfdd1b1378b38c6b7bf8e91dc" category="cell">RHEL8.7或更高版本</block>
  <block id="4f04a8a7e04e79aafa7150a5ae2bab1b" category="cell">NetApp Cloud Volumes ONTAP 实例</block>
  <block id="d09d15c71c68b596f76c57a87a19e0e5" category="cell">单节点实例—M5.2xLarge</block>
  <block id="3ba4ec8d167c12be652d6829ce6e51d8" category="paragraph">下图显示了此解决方案 的架构配置。</block>
  <block id="b3c6c8984f5671892932b2a7eacc5bf4" category="inline-image-macro">此图显示了AWS拓扑、其中包含三个专用子网、分别包含一个生产者Swarm、Kafka集群和CVO实例。</block>
  <block id="2eee6b516bfba2cd7f7f3bbe52d98104" category="paragraph"><block ref="2eee6b516bfba2cd7f7f3bbe52d98104" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d580bb4c55b441a712ec6c9dc12d38b" category="section-title">架构流程</block>
  <block id="82c8c0c94e152cc00496c6c5a1fa76b0" category="list-text">*计算。*我们使用了一个四节点Kafka集群、其中三节点Zookeeper集合在专用服务器上运行。</block>
  <block id="e236bd14d5d59a952978645a606dd7f9" category="list-text">*监控。*我们将两个节点用于Prometheus-Grafana组合。</block>
  <block id="c375f003dbf6b1accc45fd3811ce2b82" category="list-text">*工作负载。*为了生成工作负载、我们使用了一个单独的三节点集群、该集群可以生成并使用此Kafka集群。</block>
  <block id="ada284cbb65ff7bad5814ecb0c6ecb2f" category="list-text">*存储。*我们使用了一个单节点NetApp Cloud Volumes ONTAP 实例、该实例连接了两个500 GB GP2 AWS-EBS卷。然后、这些卷会通过LIF作为一个NFSv4.1卷公开到Kafka集群中。</block>
  <block id="e86dc7584f98dc172fd46661ef8b935a" category="paragraph">已为所有服务器选择Kafka的默认属性。Zookeeper Swarm也是如此。</block>
  <block id="91c26176df142d17ab999313541632c5" category="section-title">测试方法</block>
  <block id="5ca41832794ba1f8118f718465d6ffe4" category="list-text">创建了两个类似的Kafka集群、但差别如下：</block>
  <block id="fc1a46a26a283c18443e516b58cb0a58" category="list-text">*集群1.*运行生产就绪型ONTAP 9.12.1的后端NFS v4.1服务器由NetApp CVO实例托管。这些代理上安装了RHEL 8.7/RHEL 9.1。</block>
  <block id="183a9a6c4f97a876554696844cf5cd19" category="list-text">*集群2.*后端NFS服务器是手动创建的通用Linux NFSv3服务器。</block>
  <block id="8dac413f2b3b7fdfc73d642ae6e79a33" category="list-text">在这两个Kafka集群上都创建了一个演示主题。</block>
  <block id="dc30a10b7f3dac3bcce7b54e12502e89" category="paragraph">集群1：</block>
  <block id="0cdb385ae4a7f7449cf10919962c71c8" category="inline-image-macro">此屏幕截图显示了在集群1上创建的演示主题。</block>
  <block id="c99c5591acf7724aed404fdd225a51d6" category="paragraph"><block ref="c99c5591acf7724aed404fdd225a51d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83655cf6beab33b344c9ae17bec532d0" category="paragraph">集群2：</block>
  <block id="772ab3218dd37dea5c304575fe358498" category="inline-image-macro">此屏幕截图显示了在集群2上创建的演示主题。</block>
  <block id="1fd29f3ac81f16a73dae3761643fac74" category="paragraph"><block ref="1fd29f3ac81f16a73dae3761643fac74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb392c27040a7eb25cfeb1d96323917e" category="list-text">数据已加载到这两个集群的新创建主题中。这是使用默认Kafka软件包中提供的producer-perf-test工具包实现的：</block>
  <block id="bd5bb4c79c0fd5aea6e14277bbd9c5fe" category="list-text">已使用telnet对每个集群的Broker-1执行运行状况检查：</block>
  <block id="ec97e8f78ae99ff145018ede90a47c77" category="list-text">Telnet<block ref="da440d4c50d5bbb0ffa4021d6db8332c" prefix=" " category="inline-code"></block></block>
  <block id="a93dad1338160e3b828529ad6a585d13" category="list-text">Telnet<block ref="2a3da46f5894b7e15be0ea3be46975cc" prefix=" " category="inline-code"></block></block>
  <block id="a7892fb38856d45eb1f6cd89d3118830" category="paragraph">下一个屏幕截图显示了两个集群上的代理的成功运行状况检查：</block>
  <block id="855ba5b1fb4b822400c8e412d08df6e4" category="inline-image-macro">此屏幕截图显示了对两个代理成功执行运行状况检查时的读取结果。</block>
  <block id="0017223ce5bee33d9165b88b478ac306" category="paragraph"><block ref="0017223ce5bee33d9165b88b478ac306" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a63ad47b1692dcaccf39fb2a5c42e393" category="list-text">为了触发导致使用NFSv3存储卷的Kafka集群崩溃的故障情况、我们在这两个集群上启动了分区重新分配过程。分区重新分配是使用执行的<block ref="5cbd65bd2e4824bbb4876b792e513e10" prefix=" " category="inline-code"></block>。详细过程如下：</block>
  <block id="9ea6b7d5de4fbe3c468699ad3c8bb6ef" category="list-text">为了为Kafka集群中的某个主题重新分配分区、我们生成了建议的重新分配配置JSON (这是为这两个集群执行的)。</block>
  <block id="c4c8306a70b22c96715a3f79fe60eca9" category="list-text">生成的重新分配JSON随后保存在中<block ref="d773b1c180323b61e54dc5acaa6fb66f" prefix=" " category="inline-code"></block>。</block>
  <block id="05e65fb821eccc3b4cb26cc7285d75f8" category="list-text">实际分区重新分配过程由以下命令触发：</block>
  <block id="83c299e30316ef5659e9b3bbd34b40ad" category="list-text">在完成重新分配几分钟后、对代理进行的另一项运行状况检查显示、使用NFSv3存储卷的集群运行到一个错误的重命名问题描述 中并发生崩溃、而使用NetApp ONTAP NFSv4.1存储卷的集群1则在修复后继续运行、而不会造成任何中断。</block>
  <block id="197bc98012d3a74f45e086c86b7237bc" category="inline-image-macro">此屏幕截图显示了崩溃代理的输出。</block>
  <block id="b32b7199140b7e4479d72c3f0c8c506b" category="paragraph"><block ref="b32b7199140b7e4479d72c3f0c8c506b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7796cd6b11de5af34093097d2db9b94f" category="list-text">cluster1-Broker-1处于活动状态。</block>
  <block id="fef78f6445fec5a3c0d0cb2008e6c34e" category="list-text">CLUSTER2-Broker-1已失效。</block>
  <block id="e413a6c934b14b11c478c905d8c0489b" category="list-text">检查Kafka日志目录后、可以明显看出、使用NetApp ONTAP NFSv4.1存储卷并进行修复的集群1分配了干净的分区、而使用通用NFSv3存储的集群2则不是由于错误的重命名问题而导致崩溃。下图显示了集群2的分区重新平衡、这会导致在NFSv3存储上对问题描述 进行重命名、操作很不明智。</block>
  <block id="1c2cca9f5ca8cce4b11ebdc970e4a78c" category="inline-image-macro">此屏幕截图显示了集群2崩溃的日志输出。</block>
  <block id="14b7c5d09f2ae8862c1f59ee1823a5e3" category="paragraph"><block ref="14b7c5d09f2ae8862c1f59ee1823a5e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43fea21bb45bdea6ebc007efbf3c0053" category="paragraph">下图显示了使用NetApp NFSv4.1存储重新平衡集群1的全新分区。</block>
  <block id="1ac73d9186e013f2157d22422bc044ff" category="inline-image-macro">此屏幕截图显示了成功为集群1分配清理分区的日志输出、而</block>
  <block id="bdab654bf4d623f517718ee0c01ce4f2" category="paragraph"><block ref="bdab654bf4d623f517718ee0c01ce4f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8eac57fa6403d9c896c24cb94767e954" category="summary">现在、在使用Kafka的NFS存储中、有一个解决方案 用于愚蠢地重命名问题描述 、您可以创建强大的部署、利用NetApp ONTAP 存储来处理Kafka工作负载。这样不仅可以显著降低运营开销、还可以为Kafka集群带来以下优势。</block>
  <block id="76827cff700415303c6b7420a1869192" category="doc">为什么选择适用于Kafka工作负载的NetApp NFS？</block>
  <block id="984b2b530f32710e640393a80677e426" category="paragraph">现在、在使用Kafka的NFS存储中、有一个解决方案 用于愚蠢地重命名问题描述 、您可以创建强大的部署、利用NetApp ONTAP 存储来处理Kafka工作负载。这样不仅可以显著降低运营开销、还可以为Kafka集群带来以下优势：</block>
  <block id="2dbec01439aed1c5b5fbe8a521623f2d" category="list-text">*降低Kafka代理的CPU利用率。*使用分解的NetApp ONTAP 存储可将磁盘I/O操作与代理分离、从而减少其CPU占用空间。</block>
  <block id="24c6011da569f3cc3fede5c4eafff91e" category="list-text">*代理恢复时间更快。*由于分离式NetApp ONTAP 存储在Kafka代理节点之间共享、因此与传统Kafka部署相比、新的计算实例可以在任意时间点替换损坏的代理、而无需重建数据。</block>
  <block id="04615fed33ad7a5a209c685460f2c557" category="list-text">*存储效率。*由于应用程序的存储层现在通过NetApp ONTAP 进行配置、因此客户可以利用ONTAP 带来的存储效率的所有优势、例如实时数据压缩、重复数据删除和数据缩减。</block>
  <block id="c7444ea1ca211e0d3dd1b89c4f792d00" category="paragraph">我们在本节详细讨论的测试案例中对这些优势进行了测试和验证。</block>
  <block id="454cd026e1a6a7761ee25bf6682aeb2b" category="section-title">降低了Kafka代理的CPU利用率</block>
  <block id="70c59ac3ed6ee89fe977676b2dba2f05" category="paragraph">我们发现、当我们在两个sperate Kafka集群上运行类似的工作负载时、总CPU利用率低于其DAS对应项、这两个集群的技术规格相同、但存储技术却不同。当Kafka集群使用ONTAP 存储时、不仅整体CPU利用率较低、而且CPU利用率的增加也显示出比基于DAS的Kafka集群更温和的梯度。</block>
  <block id="029bc8dc2b20f11a166635df18b0a419" category="section-title">架构设置</block>
  <block id="c9d177e7e6018d464567bf6a8f9773e7" category="paragraph">下表显示了用于展示CPU利用率降低情况的环境配置。</block>
  <block id="5ed4a4dbe122b39d7103642bff11de54" category="cell">Kafka 3.2.3基准工具：OpenMessaging</block>
  <block id="e2322efe17a0927e7f855686b9597301" category="list-text">3个Zookepers—T2.Small</block>
  <block id="ea55ea3b374458b5777457efaf0db679" category="list-text">3个代理服务器—i3en.2xlarge</block>
  <block id="d521f24278937c9ada520622e97168d8" category="list-text">1个Grafana—c5n.2xlarge</block>
  <block id="3cb61b8b67329a8a20d9128458cf6633" category="list-text">4个生产者/使用者—c5n.2xlarge</block>
  <block id="d34010cfee0f2a6d774e450acd135088" category="cell">RHEL 8.7或更高版本</block>
  <block id="bce5fbe7fa89f635a887c6af2f95a9be" category="cell">单节点实例—M5.2xLarge</block>
  <block id="a27bb92a9fdd5b8b4c084b824b810232" category="section-title">基准测试工具</block>
  <block id="d483516be45a355eab4c7f9b129540c9" category="inline-link">Open消息 传送</block>
  <block id="0a48e066bcee681066419fb01ccd9f16" category="paragraph">此测试案例中使用的基准测试工具是<block ref="3990ab384d3299fd4c655b02444eb5d6" category="inline-link-rx"></block> 框架。Openmessaging不受供应商限制、不受语言限制；它为金融、电子商务、物联网和大数据提供行业指导；它有助于跨异构系统和平台开发消息传送和流式传输应用程序。下图展示了Open消息 客户端与Kafka集群的交互。</block>
  <block id="ac6d62ee86368b8c24366434f9b5d5a1" category="inline-image-macro">此图显示了Open消息 客户端与Kafka集群的交互。</block>
  <block id="370c47f03f13e0b2954d14225811e64c" category="paragraph"><block ref="370c47f03f13e0b2954d14225811e64c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6250495e61aa2eb3c47f71d21f58c6f8" category="list-text">*计算。*我们使用了一个三节点Kafka集群、其中三节点Zookeeper集合在专用服务器上运行。每个代理都通过一个专用LIF将两个NFSv4.1挂载点连接到NetApp CVO实例上的一个卷。</block>
  <block id="f91ee5c5359f2260d72c50f2c8009925" category="list-text">*监控。*我们将两个节点用于Prometheus-Grafana组合。为了生成工作负载、我们提供了一个单独的三节点集群、该集群可以生成并使用此Kafka集群。</block>
  <block id="e2b1493c4214be739b2c9349a2c481ef" category="list-text">*存储。*我们使用了一个单节点NetApp Cloud Volumes ONTAP 实例、该实例上挂载了六个250 GB GP2 AWS-EBS卷。然后、这些卷会通过专用LIF作为六个NFSv4.1卷公开到Kafka集群中。</block>
  <block id="ede634748bd4515e69245593cfc4478c" category="list-text">*配置。*本测试用例中的两个可配置元素是Kafka代理和Open消息 工作负载。</block>
  <block id="b053d1656e3b9dcaa2b4834fbdc4fb86" category="list-text">*代理配置*为Kafka代理选择了以下规格。我们对所有测量结果使用了复制因子3、如下所示。</block>
  <block id="d5ee20b40da2061d10bff33a6f13467a" category="inline-image-macro">此图显示了为Kafka代理选择的规格。</block>
  <block id="d0255d634f4013c1da82b391ac0fa7f5" category="paragraph"><block ref="d0255d634f4013c1da82b391ac0fa7f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82f54619faeaa86063f362102c160601" category="list-text">提供了以下规格：* Open消息 基准测试(OMB)工作负载配置*。我们指定了一个目标生产者比率、并在下面重点说明了这一比率。</block>
  <block id="da43f96a4bfe17af8039df6b15f4f6da" category="inline-image-macro">此图显示了为Open消息 基准工作负载配置选择的规格。</block>
  <block id="39e4197e665f900596d0136c11eaa851" category="paragraph"><block ref="39e4197e665f900596d0136c11eaa851" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6067cc387407f4d8dc9d623c770cfd" category="list-text">创建了两个类似的集群、每个集群都有自己的一组基准集群Swarms。</block>
  <block id="c85bb905404dda665035e21b11ab1a58" category="list-text">*集群1.*基于NFS的Kafka集群。</block>
  <block id="9ed0b3eccef17299a0119b0f28568e78" category="list-text">*集群2.*基于DAS的Kafka集群。</block>
  <block id="a38c46362b3feb9b3bb5f53b1957d50f" category="list-text">使用Open消息 命令、在每个集群上触发类似的工作负载。</block>
  <block id="c18ed3feb8720fe4fc76d90a9fa6a6e3" category="list-text">生产率配置在四次迭代中增加、CPU利用率记录在Grafana中。生产率设置为以下级别：</block>
  <block id="04207e7bb62b9b5d14bdb603f74e683c" category="list-text">10、000</block>
  <block id="e19784a5420512b2876c7b24680652b5" category="list-text">40,000</block>
  <block id="e57650a6c15f273334d41da58fa72111" category="list-text">80、000</block>
  <block id="ee70718f6a92d6c1b099a6942f594963" category="list-text">100、000</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">观察结果</block>
  <block id="524fdb84d137ea63c19f5efab343f82b" category="paragraph">将NetApp NFS存储与Kafka结合使用具有两个主要优势：</block>
  <block id="612e27ad9fd383437f1445cf80d554b1" category="list-text">*您可以将CPU利用率降低近三分之一。*与DAS SSD相比、NFS在类似工作负载下的整体CPU利用率更低；节省量从较低生产率的5%到较高生产率的32%不等。</block>
  <block id="bc31b9852409e970a3a4659fef4b4f93" category="list-text">*在较高的生产率下、CPU利用率漂移减少了三倍。*正如预期的那样、随着生产率的增加、CPU利用率的增加也出现了上升趋势。但是、使用DAS的Kafka代理的CPU利用率从较低生产率的31%上升到较高生产率的70%、即增加39%。但是、在NFS存储后端、CPU利用率从26%上升到38%、增加了12%。</block>
  <block id="6299b9c8f7a14a0a0ca7407cbb9a187a" category="inline-image-macro">此图显示了基于DAS的集群的行为。</block>
  <block id="1e669d4d02de91a94a05137bdd1dc491" category="paragraph"><block ref="1e669d4d02de91a94a05137bdd1dc491" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60e393621d29424b529201d4bc48e3b4" category="inline-image-macro">此图显示了基于NFS的集群的行为。</block>
  <block id="68437c53e33bd5423258ea6fd20a35f5" category="paragraph"><block ref="68437c53e33bd5423258ea6fd20a35f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d4293a3bcf73010216e2f0399fd571" category="paragraph">此外、当消息达到100、000时、DAS显示的CPU利用率比NFS集群高。</block>
  <block id="a0e6052c526d2d343fa217b609c943a6" category="inline-image-macro">此图显示了一个基于DAS的集群在收到100、000条消息时的行为。</block>
  <block id="7c994cd9d5150762faf629fff71db6c6" category="paragraph"><block ref="7c994cd9d5150762faf629fff71db6c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9d76c4aeb68cf4d7ef9bf3ce121bdd2" category="inline-image-macro">此图显示了一个基于NFS的集群在收到100、000条消息时的行为。</block>
  <block id="0dd7c57e19e01e516dc697178954bfd5" category="paragraph"><block ref="0dd7c57e19e01e516dc697178954bfd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60a5caa55d79e52e0af298cf19b5c73d" category="section-title">代理恢复速度更快</block>
  <block id="bc0ed21388f4042414a88362de068e14" category="paragraph">我们发现、Kafka代理在使用共享NetApp NFS存储时恢复速度更快。当Kafka集群中的代理崩溃时、可以使用具有相同代理ID的运行状况良好的代理来替换此代理。执行此测试案例后、我们发现、对于基于DAS的Kafka集群、集群会在新添加的运行状况良好的代理上重建数据、这非常耗时。对于基于NetApp NFS的Kafka集群、替代代理将继续从先前的日志目录读取数据并以更快的速度恢复。</block>
  <block id="61c964c4267b0fa60eeaa1a7ccdf706e" category="paragraph">下表显示了使用NAS的Kafka集群的环境配置。</block>
  <block id="f874b8bfe50ce846d8156aabe96e5a34" category="cell">Kafka 3.2.3</block>
  <block id="687972ccb765e5204fa2220ba3dff130" category="list-text">4个生产者/使用者—c5n.2xlarge</block>
  <block id="31638173210d76d464e93c8f3f53711c" category="list-text">1个备份Kafka节点—i3en.2xlarge</block>
  <block id="5d27021addda02398c54d28a4ceee767" category="cell">RHEL8.7或更高版本</block>
  <block id="6c2cacbcd5f4927358fee9d8a0b60252" category="paragraph">下图展示了基于NAS的Kafka集群的架构。</block>
  <block id="78f0f1d311c4aae35de324851ecea08a" category="inline-image-macro">此图显示了基于NAS的Kafka集群的架构。</block>
  <block id="f11ab4a9f30f1c13023294b83c1968fb" category="paragraph"><block ref="f11ab4a9f30f1c13023294b83c1968fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64898c42d1ced91d44ff2e383b066de3" category="list-text">*计算。*一种三节点Kafka集群、其中三节点zookeeper集合在专用服务器上运行。每个代理都有两个NFS挂载点、可通过专用LIF连接到NetApp CVO实例上的一个卷。</block>
  <block id="06e870f499bc90bbe828323be8625621" category="list-text">*监控。* Prometheus-Grafana组合的两个节点。在生成工作负载时、我们会使用一个单独的三节点集群来生成此Kafka集群并将其使用。</block>
  <block id="1a5c8241b05feb71d0733c2cc2f073c2" category="list-text">*存储。*一个单节点NetApp Cloud Volumes ONTAP 实例、该实例上挂载了六个250 GB GP2 AWS-EBS卷。然后、这些卷会通过专用LIF作为六个NFS卷公开到Kafka集群中。</block>
  <block id="1f4b2c66cbc586fa9658b18333582240" category="list-text">*代理配置。*本测试用例中的一个可配置元素是Kafka代理。为Kafka代理选择了以下规格。。<block ref="2aa7cd054835892b354c130576c17b61" prefix=" " category="inline-code"></block> 设置为高值、因为这决定了从ISR列表中删除特定节点的速度。在不良节点和运行状况良好的节点之间切换时、您不希望从ISR列表中排除该代理ID。</block>
  <block id="d6068b616491b51ff179d0138965bba4" category="inline-image-macro">此图显示了为Kafka代理选择的规格。</block>
  <block id="4bc3bbed275832f042bf33735b245eee" category="paragraph"><block ref="4bc3bbed275832f042bf33735b245eee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f6ea5961f5640ce4fa828022abc91c1" category="list-text">创建了两个类似的集群：</block>
  <block id="71754d8c640cd0a117a3c82af0bd3646" category="list-text">基于EC2的融合集群。</block>
  <block id="c4b4e0617e4a38a83a00fc9bd8083465" category="list-text">基于NetApp NFS的融合集群。</block>
  <block id="fbbf8c78f6f01371b1caa7b79bfa91b9" category="list-text">创建了一个备用Kafka节点、其配置与原始Kafka集群中的节点相同。</block>
  <block id="b2d04ce59538c1ba125aa91697b3854f" category="list-text">在每个集群上创建了一个示例主题、并在每个代理上填充了大约110 GB的数据。</block>
  <block id="25bb70a763a5456f70f68d98646ecbd6" category="list-text">基于* EC2的集群。*已映射Kafka代理数据目录<block ref="8463a3643fa4431218a88d6e1e85f064" prefix=" " category="inline-code"></block> (在下图中、为cluster1的Broker-1 (左端子)。</block>
  <block id="bbec1799f53d01620bdd78881b0f0310" category="list-text">*基于NetApp NFS的集群。* Kafka代理数据目录挂载在NFS点上<block ref="ecabd55f704fe0f0dcc41be6e7e7ab83" prefix=" " category="inline-code"></block> (在下图中、为cluster2的Broker-1 [右端子])。</block>
  <block id="86f85a2a5eed8a784f9a06a8fe205c9a" category="inline-image-macro">此图显示了两个终端屏幕。</block>
  <block id="390d46f539d5037b90b3b548ca4abc79" category="paragraph"><block ref="390d46f539d5037b90b3b548ca4abc79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02296aafa9e3a6424418dd97a673e931" category="list-text">在每个集群中、Broker-1都已终止、以触发失败的代理恢复过程。</block>
  <block id="fe4c3f604a59eb786f64f0fc5a7cfa01" category="list-text">代理终止后、代理IP地址将作为二级IP分配给备用代理。之所以需要这样做、是因为Kafka集群中的代理可通过以下方式进行标识：</block>
  <block id="597bfb23e3e10c354a661882e4728565" category="list-text">通过将故障代理IP重新分配给备用代理来分配* IP地址*。</block>
  <block id="d86a6ec6cd64cd7365ad5d46f7c32d85" category="list-text">*代理ID*。此ID已在备用代理中配置<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block>。</block>
  <block id="c71af5d75ff28fc80b8aa2c6c6832c39" category="list-text">分配IP后、在备用代理上启动了Kafka服务。</block>
  <block id="e6f0e1804a85ff41f08342fa0cd0e8c5" category="list-text">一段时间后、服务器日志被提取、用于检查在集群中的替代节点上构建数据所用的时间。</block>
  <block id="b4e6de827ba8af76c3d7cf0e11dee63e" category="paragraph">Kafka代理恢复速度几乎是原来的九倍。我们发现、与在Kafka集群中使用DAS SSD相比、使用NetApp NFS共享存储时、恢复发生故障的代理节点所需的时间要快得多。对于1 TB的主题数据、基于DAS的集群的恢复时间为48分钟、而基于NetApp-NFS的Kafka集群的恢复时间不到5分钟。</block>
  <block id="fcd5351f741ba27a03aeaa4aff141fde" category="paragraph">我们发现、基于EC2的集群需要10分钟才能在新代理节点上重建110 GB的数据、而基于NFS的集群则需要3分钟才能完成恢复。我们还在日志中观察到、EC2分区的使用者偏移量为0、而在NFS集群上、使用者偏移量是从先前的代理中获取的。</block>
  <block id="01a0d5c558a836a74adf3dc3fe1de25d" category="section-title">基于DAS的集群</block>
  <block id="542ac5d9dd4769eb5fb4a8a7da3aa594" category="list-text">备份节点从08：55：53、730开始。</block>
  <block id="b5f0acf8be0dd329b7dae7c96c9b3dc8" category="inline-image-macro">此图显示了基于DAS的集群的日志输出。</block>
  <block id="04b616f87a48976d96105dd8da106220" category="paragraph"><block ref="04b616f87a48976d96105dd8da106220" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d48d1996a0b89fc5aa313e48f1c2c149" category="list-text">数据重建过程于09：05：24、860结束。处理110 GB的数据大约需要10分钟。</block>
  <block id="56e5a0f063355e55045e219c7ff3cae3" category="paragraph"><block ref="56e5a0f063355e55045e219c7ff3cae3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d10d1e0d7dc7546ca2ee585553c90f24" category="section-title">基于NFS的集群</block>
  <block id="e163d6812be40c2618b43cc9d2ed21a1" category="list-text">备份节点的启动时间为09：39：17、213。下面突出显示了起始日志条目。</block>
  <block id="1af763f7fe72be73a16f6a9010023e1f" category="inline-image-macro">此图显示了基于NFS的集群的日志输出。</block>
  <block id="97d0b1f6f9620cf3ad52778c81887d14" category="paragraph"><block ref="97d0b1f6f9620cf3ad52778c81887d14" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459f0a82f7fc8505de6db94698f5e9c8" category="list-text">数据重建过程于09：42：29、115结束。处理110 GB的数据大约需要3分钟。</block>
  <block id="f21adb2cdf95034f20ec22d797a2b2be" category="paragraph"><block ref="f21adb2cdf95034f20ec22d797a2b2be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24c9b21a2ca87ae467a56b044593521b" category="paragraph">对于包含大约1 TB数据的代理、重复执行此测试、对于DAS、此测试需要大约48分钟、对于NFS、此测试需要3分钟。下图显示了这些结果。</block>
  <block id="6994918ac91afbe69dd9a20ab257afa1" category="inline-image-macro">此图显示了根据基于DAS的集群或基于NFS的集群的代理上加载的数据量进行代理恢复所需的时间。</block>
  <block id="a853fdd02599082a126937405a2c304c" category="paragraph"><block ref="a853fdd02599082a126937405a2c304c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f94ef2603834178da773ec5ccd97683b" category="paragraph">由于Kafka集群的存储层是通过NetApp ONTAP 配置的、因此我们获得了ONTAP 的所有存储效率功能。测试方法是、在Cloud Volumes ONTAP 上配置了NFS存储的Kafka集群上生成大量数据。我们可以看到、由于ONTAP 功能、空间显著减少。</block>
  <block id="747684069b5286f0282d40e544a04812" category="list-text">4个生产者/使用者—c5n.2xlarge *</block>
  <block id="d1030267f4090d953bd3cabbb565b51b" category="cell">单节点实例—M5.2xLarge</block>
  <block id="717373873e977ccdc16d9a371e92b55b" category="list-text">*计算。*我们使用了一个三节点Kafka集群、其中三节点Zookeeper集合在专用服务器上运行。每个代理都通过一个专用LIF在NetApp CVO实例上有两个NFS挂载点到一个卷。</block>
  <block id="493b3bd02a683f505d957bb27957e1b6" category="list-text">*监控。*我们将两个节点用于Prometheus-Grafana组合。为了生成工作负载、我们使用了一个单独的三节点集群、该集群可能会生成此Kafka集群并将其占用。</block>
  <block id="cce21f164c30f5ce10f914c4542e252f" category="list-text">*存储。*我们使用了一个单节点NetApp Cloud Volumes ONTAP 实例、该实例上挂载了六个250 GB GP2 AWS-EBS卷。然后、这些卷会通过专用LIF作为六个NFS卷公开到Kafka集群中。</block>
  <block id="68f29d01fbebb4ad998127522e13950b" category="list-text">*配置。*此测试案例中可配置的元素是Kafka代理。</block>
  <block id="86e1dede1fc5701676bec82003409aff" category="paragraph">在生产商端关闭了数据压缩、从而使生产商能够生成高吞吐量。而是由计算层处理存储效率。</block>
  <block id="7da10cbdbba2e826cd4954054b5c1843" category="list-text">已按照上述规格配置Kafka集群。</block>
  <block id="e857c1394ce43b04a9548d5a3dec0ee5" category="list-text">在集群上、使用Open消息 基准工具生成了大约350 GB的数据。</block>
  <block id="efc4a3d9bfed3a9a80b0caea9016ca6c" category="list-text">工作负载完成后、将使用ONTAP 系统管理器和命令行界面收集存储效率统计信息。</block>
  <block id="9c9850d81b369454a9610d48c5bfe8a0" category="paragraph">对于使用OMB工具生成的数据、我们发现空间节省~33%、存储效率比率为1.70：1。如下图所示、生成的数据所使用的逻辑空间为420.3 GB、用于存放数据的物理空间为281.7 GB。</block>
  <block id="f11c8594ca77ceb3e0ab124768dd061d" category="inline-image-macro">此图显示了VMDISK中的空间节省。</block>
  <block id="e9cfd3a2897ae25384f04fb11643ac21" category="paragraph"><block ref="e9cfd3a2897ae25384f04fb11643ac21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3afbd9828e011526955ca93b48b57524" category="inline-image-macro">屏幕截图</block>
  <block id="1509f2dafd7ef601c7bf6b69e651ebaf" category="paragraph"><block ref="1509f2dafd7ef601c7bf6b69e651ebaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="419c9cc44cd35123f9e118ff58d18c8d" category="paragraph"><block ref="419c9cc44cd35123f9e118ff58d18c8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc0316be7ba1d2f8b53c282f09f9b532" category="summary">基于AWS云中的性能对存储层挂载在NetApp NFS上的Kafka集群进行了基准测试。以下各节将介绍这些基准测试示例。</block>
  <block id="02b742a6a1f227191aecb81d8822d2ee" category="doc">AWS中的性能概述和验证</block>
  <block id="28e2dfa4242e2b504727dab8605d1432" category="section-title">采用NetApp Cloud Volumes ONTAP 的AWS云中的Kafka (高可用性对和单节点)</block>
  <block id="1dc7a426b0cbf7d35c5edda73f68403d" category="paragraph">采用NetApp Cloud Volumes ONTAP (HA对)的Kafka集群已通过AWS云性能基准测试。以下各节将介绍此基准测试。</block>
  <block id="a0d574b61a80df70bd921b269853cc18" category="cell">RHEL8.6</block>
  <block id="462fed98d4e5a4d1be4d08b1fdd3f0df" category="cell">HA对实例—m5dn.12x插入x双节点单节点实例—m5dn.12x插入x 1个节点</block>
  <block id="29e8b4fdf26266c94b184b76858f935e" category="section-title">NetApp集群卷ONTAP 设置</block>
  <block id="febbbf2a22b781c8cb2d828a8cbf52d6" category="list-text">对于Cloud Volumes ONTAP HA对、我们在每个存储控制器的每个聚合上创建了两个聚合、其中包含三个卷。对于单个Cloud Volumes ONTAP 节点、我们会在一个聚合中创建六个卷。</block>
  <block id="72bcc37cf8850d4e74a6305d71727956" category="inline-image-macro">此图显示了aggr3和aggr22的属性。</block>
  <block id="3fb62725866c106a90b2f81d00b4bfd8" category="paragraph"><block ref="3fb62725866c106a90b2f81d00b4bfd8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="518fcf406a83698c4ba5d2f41cafab41" category="inline-image-macro">此图显示了aggr2的属性。</block>
  <block id="2ec040888274c50ed4f2140a40ff8b70" category="paragraph"><block ref="2ec040888274c50ed4f2140a40ff8b70" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a6501fcefae41cda9ecf425cdc1ef15" category="list-text">为了提高网络性能、我们为HA对和单个节点启用了高速网络连接。</block>
  <block id="a4de9e1c332b656e2e19024cce28f939" category="inline-image-macro">此图显示了如何启用高速网络连接。</block>
  <block id="ebfcaff376ca9e4653f751fb35b6ff05" category="paragraph"><block ref="ebfcaff376ca9e4653f751fb35b6ff05" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678217b29dc6cbf917f08c79a1819f92" category="list-text">我们注意到ONTAP NVRAM的IOPS较多、因此将Cloud Volumes ONTAP 根卷的IOPS更改为2350。Cloud Volumes ONTAP 中的根卷磁盘大小为47 GB。以下ONTAP 命令适用于HA对、同一步骤适用于单个节点。</block>
  <block id="71ac6dbf3d671b6b9db5497aad37fc67" category="inline-image-macro">此图显示了如何修改卷属性。</block>
  <block id="a278e7398c9bee17762c3a92d2e6f247" category="paragraph"><block ref="a278e7398c9bee17762c3a92d2e6f247" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a5f2ebf87b5aa37d2e02d041ede98e4f" category="list-text">*计算。*我们使用了一个三节点Kafka集群、其中三节点Zookeeper集合在专用服务器上运行。每个代理都通过一个专用LIF与Cloud Volumes ONTAP 实例上的一个卷具有两个NFS挂载点。</block>
  <block id="dcb39d8372b01f5eb051372b3d943fbd" category="list-text">*存储。*我们使用了一个HA对Cloud Volumes ONTAP 实例、该实例上挂载了一个6 TB的GP3 AWS-EBS卷。然后、该卷会通过NFS挂载导出到Kafka代理。</block>
  <block id="e4d534a810d0b173e29dc8ae17ae8e30" category="paragraph"><block ref="e4d534a810d0b173e29dc8ae17ae8e30" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cce0ad6ab772599285bd32c539025c1f" category="section-title">OpenMessage基准配置</block>
  <block id="6a1fe63829e046313e1b3073459bf538" category="list-text">为了提高NFS性能、我们需要在NFS服务器和NFS客户端之间建立更多的网络连接、这些连接可以使用nconnect来创建。运行以下命令、使用nconnect选项在代理节点上挂载NFS卷：</block>
  <block id="a973eefced896f4a698ed64af6dc0199" category="list-text">在Cloud Volumes ONTAP 中检查网络连接。从单个Cloud Volumes ONTAP 节点使用以下ONTAP 命令。同一步骤也适用于Cloud Volumes ONTAP HA对。</block>
  <block id="828ed34406e4dab30166070e0af1f142" category="list-text">我们使用以下Kafka<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> 在Cloud Volumes ONTAP HA对的所有Kafka代理中。。<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 每个代理的属性都不同、其余属性对于代理是通用的。对于Broker1、为<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 值如下：</block>
  <block id="66ddebf2d4ab98ff8682a008dc466ce6" category="list-text">对于Broker2、为<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 属性值如下：</block>
  <block id="fcfc381980a9ed554f51cbfd5b77616a" category="list-text">对于Broker3、为<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 属性值如下：</block>
  <block id="00d57462d7009374713be86d6c491d89" category="list-text">对于单个Cloud Volumes ONTAP 节点、为Kafka<block ref="21d5034d4d99d6ca0da314367f1cccd6" prefix=" " category="inline-code"></block> 与Cloud Volumes ONTAP HA对相同、但不包括<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 属性。</block>
  <block id="cf168cce281f1eccdc9f9fb55c933d29" category="list-text">对于Broker1、为<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 值如下：</block>
  <block id="1692ac5191f19e15cf0e3a8af0820752" category="list-text">对于Broker2、为<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 值如下：</block>
  <block id="4b0728fa62359454465b3a26a608d83c" category="list-text">OMB中的工作负载配置了以下属性：<block ref="9a97642a426510e31f49e0a98ed35e46" prefix=" " category="inline-code"></block>。</block>
  <block id="433b44cf3e6084d97e5162a06d481873" category="paragraph">。<block ref="f21d26061df60c086aedb156e38f66b5" prefix=" " category="inline-code"></block> 可能因使用情形而异。在性能测试中、我们使用了3 K。</block>
  <block id="bd9348653b0cfa7f0962b694fa058428" category="paragraph">我们使用OMB中的两个不同驱动程序Sync或Throughput在Kafka集群上生成工作负载。</block>
  <block id="50e5861dab89d00bf88787e044b2c24f" category="list-text">用于Sync驱动程序属性的YAML文件如下所示<block ref="46c2adf6b9dc6e5883c47b1d76feb008" prefix=" " category="inline-code"></block>：</block>
  <block id="9ae100f8fb1875133a485c355266af55" category="list-text">用于吞吐量驱动程序属性的YAML文件如下所示<block ref="658e4b47fcd8812e9b0b2886af867717" prefix=" " category="inline-code"></block>：</block>
  <block id="a887b430cb278fa8f52827a223308324" category="list-text">Kafka集群是按照上述规范使用Terraform和Ansible配置的。Terraform用于使用适用于Kafka集群的AWS实例构建基础架构、Ansible在这些实例上构建Kafka集群。</block>
  <block id="d9a3b4ca51b8378374ab25c3f90ec2a2" category="list-text">已使用上述工作负载配置和Sync驱动程序触发OMB工作负载。</block>
  <block id="3f6a85702112dff5bcd0970b7ceb3f02" category="list-text">使用相同工作负载配置的吞吐量驱动程序触发了另一个工作负载。</block>
  <block id="5f2da6c069f19294c52f39a18639f0d2" category="paragraph">我们使用了两种不同类型的驱动程序来生成工作负载、以便对在NFS上运行的Kafka实例的性能进行基准测试。驱动程序之间的区别在于日志刷新属性。</block>
  <block id="59f70e2d523801f5ede7c9bb7b48cc76" category="paragraph">对于Cloud Volumes ONTAP HA对：</block>
  <block id="ffb03fd768825b381d478b114716f8cf" category="list-text">Sync驱动程序一致生成的总吞吐量：~1236 MBps。</block>
  <block id="84c96e7c92d1f10aac5f3600c7df9299" category="list-text">为吞吐量驱动程序生成的总吞吐量：峰值~1412 MBps。</block>
  <block id="5896e2cd1e01fb8ef69cdf280a9a38e3" category="paragraph">对于单个Cloud Volumes ONTAP 节点：</block>
  <block id="d3c9dedf3eb9fce5e9a983948c3cef0e" category="list-text">Sync驱动程序一致生成的总吞吐量：~ 1962MBps。</block>
  <block id="86acf2bdaf8de60bbc77d3dc8f0e1b12" category="list-text">吞吐量驱动程序生成的总吞吐量：峰值~1660MBps</block>
  <block id="4bb1ab47e2a029960970bd2e246f9a57" category="paragraph">同步驱动程序可以在日志即时转储到磁盘时生成一致的吞吐量、而吞吐量驱动程序则在将日志批量提交到磁盘时生成突发的吞吐量。</block>
  <block id="920a7d00fe9032493a9a70c1e6c8972a" category="paragraph">这些吞吐量数字是为给定的AWS配置生成的。为了满足更高的性能要求、可以进一步扩展和调整实例类型、以提高吞吐量。总吞吐量或总速率是生产者和使用者速率的组合。</block>
  <block id="c5616509b949bfcdee10d7e87918ec9d" category="inline-image-macro">此处显示了四个不同的图形。CVO-HA对吞吐量驱动程序。CVO-HA对Sync驱动程序。CVO单节点吞吐量驱动程序。CVO单节点同步驱动程序。</block>
  <block id="0e33cf4077892dd25c1212a135870c2b" category="paragraph"><block ref="0e33cf4077892dd25c1212a135870c2b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c6ad6fcb6db991d86273d33ed35d3c9" category="paragraph">在执行吞吐量或同步驱动程序基准测试时、请务必检查存储吞吐量。</block>
  <block id="22156e4cc2df3388f0f9dfe0c178db37" category="inline-image-macro">此图显示了延迟、IOPS和吞吐量方面的性能。</block>
  <block id="cd86eb722445699d358d0ded28ff649a" category="paragraph"><block ref="cd86eb722445699d358d0ded28ff649a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="996099c5b9fa96634feb727528db335e" category="list-text">什么是Apache Kafka？</block>
  <block id="64512a184434b7e7734cf3c0a7283f2a" category="list-text">什么是愚蠢的重命名？</block>
  <block id="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link"><block ref="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link-rx"></block></block>
  <block id="0bf644a00aca415462aeb30f96e502cf" category="paragraph"><block ref="0bf644a00aca415462aeb30f96e502cf" category="inline-link-rx"></block></block>
  <block id="4a15e598cdac14bbb90bb0e4020f4a79" category="list-text">正在为流式应用程序读取ONATP。</block>
  <block id="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link"><block ref="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link-rx"></block></block>
  <block id="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="paragraph"><block ref="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="inline-link-rx"></block></block>
  <block id="6a12d786416c40632fb0604b5414460b" category="list-text">愚蠢—将问题描述 重命名为Kafka。</block>
  <block id="e31eb904be590e91ff0fbce5199e738b" category="inline-link"><block ref="e31eb904be590e91ff0fbce5199e738b" category="inline-link-rx"></block></block>
  <block id="0c1546e70acde7c8a21a85e45df7d5a1" category="paragraph"><block ref="0c1546e70acde7c8a21a85e45df7d5a1" category="inline-link-rx"></block></block>
  <block id="e861ab8ac55c9110672ee8b4ba3c5990" category="list-text">什么是NFS？</block>
  <block id="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link"><block ref="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link-rx"></block></block>
  <block id="6b6d6a7e1bfbb25506c4af7f443a7b25" category="paragraph"><block ref="6b6d6a7e1bfbb25506c4af7f443a7b25" category="inline-link-rx"></block></block>
  <block id="9fee8c35c177577e85d941aa2c9dedc4" category="list-text">什么是Kafka分区重新分配？</block>
  <block id="2363cdcf0f5fc9a387ed87b925979747" category="inline-link"><block ref="2363cdcf0f5fc9a387ed87b925979747" category="inline-link-rx"></block></block>
  <block id="12b4d09f121a118c1b63eba5f3523fa2" category="paragraph"><block ref="12b4d09f121a118c1b63eba5f3523fa2" category="inline-link-rx"></block></block>
  <block id="f06a814ac7d838a2d019219102377120" category="list-text">什么是Open消息 基准？</block>
  <block id="9466397f90b4d13297982537f7f1f157" category="inline-link"><block ref="9466397f90b4d13297982537f7f1f157" category="inline-link-rx"></block></block>
  <block id="f42769fbe9abef93dd4da40d8f886c4a" category="paragraph"><block ref="f42769fbe9abef93dd4da40d8f886c4a" category="inline-link-rx"></block></block>
  <block id="bcc483eab76f7252a6d3060ae223f024" category="list-text">如何迁移Kafka代理？</block>
  <block id="7702dea2646d94249d97c22a4dcb6f96" category="inline-link"><block ref="7702dea2646d94249d97c22a4dcb6f96" category="inline-link-rx"></block></block>
  <block id="ebdd7bc6eaa2157f5f400c61c1826417" category="paragraph"><block ref="ebdd7bc6eaa2157f5f400c61c1826417" category="inline-link-rx"></block></block>
  <block id="3f7e227a8b3d0fc0cdcbf84e2bc565ac" category="list-text">您如何监控与Prometheus的Kafka代理？</block>
  <block id="2d2cb8fe8b8d32b7fb984622e41036f1" category="paragraph"><block ref="2d2cb8fe8b8d32b7fb984622e41036f1" category="inline-link-rx"></block></block>
  <block id="7d576967253ca2f566f9693183407367" category="sidebar">Apache Kafka工作负载与NetApp NFS存储</block>
  <block id="a5428e6b4b42638886ab5870a883efb9" category="sidebar">NetApp解决方案 for fly将NFS中的问题描述 重命名为Kafka工作负载</block>
  <block id="0d7c7eeec9388fceaff3d06e03b45fe9" category="sidebar">使用AFF 内部部署进行性能概述和验证</block>
  <block id="c31fea06105fe5260bb879284c6181e0" category="list-text">更新<block ref="9733772c7c0780d4ef7a6a8d6a9dbd7d" prefix=" " category="inline-code"></block> 到Kafka卷、如下所示：</block>
  <block id="8be4a12c21ef3f52e24811e4ffe0d444" category="summary">此页面介绍了有关监控AWS FSxN以及根据阈值自动调整大小的自动化操作。</block>
  <block id="cd2c2a58f3cb485687fd1f77834654e5" category="doc">使用AWS Lambda功能进行ONTAP 监控和自动调整大小的FSX</block>
  <block id="77b2a3f373c1bcab9cefd635e81303eb" category="section-title">概述：通过AWS Lambda功能监控和自动调整适用于ONTAP 的FSX的大小</block>
  <block id="8799f4655655a26ca808c044ad467a88" category="paragraph">解决方案 提供了以下功能：</block>
  <block id="c342d53b891fb460586d3a137ff99a6e" category="list-text">能够监控：</block>
  <block id="138be07c6f8ee03d211e5f345546b7af" category="list-text">适用于ONTAP 的FSX的整体存储容量的使用情况</block>
  <block id="e0f2ee8f41ba7bcb505bbabfcab0c31d" category="list-text">每个卷的使用情况(精简配置/厚配置)</block>
  <block id="34b7d0bb9429625764e4da258f94ae19" category="list-text">每个LUN的使用情况(精简配置/厚配置)</block>
  <block id="685d6918f18b4d0d12cf6582187aff57" category="list-text">能够在违反用户定义的阈值时调整上述任意值的大小</block>
  <block id="91602eeac7d8a4cc46329128033d33d3" category="list-text">能够获取关联的FlexClone卷和快照列表</block>
  <block id="dd0679a0ea834bda0a34b306e7a09346" category="paragraph">开始之前、请确保满足以下前提条件：</block>
  <block id="561d599e4e659439d1b142dbe29b15c7" category="list-text">已部署适用于ONTAP 的FSx</block>
  <block id="7f42d2e23aac4d85dca59633ff2cf58d" category="list-text">已为ONTAP 的FSX设置"fsxadmin"密码</block>
  <block id="eb99e653d349f732eb98619784a340ac" category="list-text">AWS Lambda功能可通过API调用FSX for ONTAP 、以检索和更新存储容量、卷和LUN的大小。</block>
  <block id="3eac8a068c2043f39b9aec5a2b7ee6af" category="list-text">AWS SES (简单电子邮件服务)用于在发生调整大小事件时通知最终用户。</block>
  <block id="432a24ba141fb90355a80ec4c6d3825e" category="paragraph"><block ref="432a24ba141fb90355a80ec4c6d3825e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="974bba02716a5e7c8414499dd06bbb62" category="example-title">第1步：克隆GitHub存储库</block>
  <block id="3233c0d0dc9395d6085fb8167fdd8393" category="paragraph">在本地系统上克隆GitHub存储库：</block>
  <block id="06df343d3a431a2f511aa7fef58e4a23" category="paragraph">导航到AWS控制台&gt;*参数存储*、然后单击*创建参数*。</block>
  <block id="1cefa861aa6d9ba408841133e7325545" category="inline-image-macro">此图显示了AWS控制台上的SSM参数创建窗口。</block>
  <block id="a19e362ed1a0d7ca174a7abf2c59853a" category="paragraph"><block ref="a19e362ed1a0d7ca174a7abf2c59853a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcd5fa3fbab9dadf361d9eba36b8382c" category="paragraph">导航到AWS控制台&gt;*简单电子邮件服务(SES)*、然后单击*创建身份*。</block>
  <block id="60461626b891b858b74da97b0ee89b6e" category="paragraph">单击*创建身份*</block>
  <block id="af9b6260888bf7e72d2766823e7a2bb6" category="inline-image-macro">此图显示了AWS控制台上的SES身份创建窗口。</block>
  <block id="59f38a9e267a3ea7e5d173c163613f58" category="paragraph"><block ref="59f38a9e267a3ea7e5d173c163613f58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb625a560eb6c02ecd5a6a9f47d5d768" category="list-text">使用默认的*从头开始*作者并更新以下字段：</block>
  <block id="8af4ad16f59e1ac333921353c65b1492" category="paragraph">单击*创建功能*。</block>
  <block id="957437001751593737e6afeb8cd3163b" category="inline-image-macro">此图显示了AWS控制台上的Lambda创建窗口。</block>
  <block id="e6242cbb73c003c124d84270c0afe97a" category="paragraph"><block ref="e6242cbb73c003c124d84270c0afe97a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="417809fda70cc9785afc8e3ceec62dff" category="paragraph"><block ref="417809fda70cc9785afc8e3ceec62dff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38752522b6aecd6cdf7355a1cdaa38ad" category="inline-image-macro">此图显示了AWS Lambda功能控制台上的添加层按钮。</block>
  <block id="cc07bde473345c3ce0ae0c8fc7097fdc" category="paragraph"><block ref="cc07bde473345c3ce0ae0c8fc7097fdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc8034a8cc3761841b945895d5bb5e74" category="list-text">单击*层源*下的*创建新层*</block>
  <block id="44dec222c0e2e40e9770472e89813d69" category="inline-image-macro">此图显示了AWS控制台上的创建新层窗口。</block>
  <block id="1a144f1799018bb0e4a3aff87c3ae15f" category="paragraph"><block ref="1a144f1799018bb0e4a3aff87c3ae15f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="018f803496bf51d7eca913d543f61cdc" category="inline-image-macro">此图显示了AWS Lambda功能控制台上的添加层窗口。</block>
  <block id="74aec608a6fed03dea60e0a7998ac4c6" category="paragraph"><block ref="74aec608a6fed03dea60e0a7998ac4c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6dcc7aaf4ab69d9f33228c8aca077bf7" category="inline-image-macro">此图显示了AWS Lambda功能控制台上添加的层。</block>
  <block id="87fcbd11f44be8b210a0adbfafc5f083" category="paragraph"><block ref="87fcbd11f44be8b210a0adbfafc5f083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="92997aae940f33750d6c43a65315fc0d" category="list-text">导航到Lambda函数的*权限*选项卡、然后单击分配的角色。在角色的权限选项卡中、单击*添加权限*&gt;*创建实时策略*。</block>
  <block id="e80446ca49af46cfdbc8af6661176f5b" category="list-text">单击JSON选项卡、然后从GitHub repo粘贴文件policy.json的内容。</block>
  <block id="85aff31d07a1ff90ecd6d3dc6401eed0" category="list-text">将每次出现的$｛AWS：：AccountId｝替换为您的帐户ID、然后单击*审核策略*</block>
  <block id="de61df97ff6dba72d275469c25e01fe2" category="list-text">为策略提供一个名称、然后单击*创建策略*</block>
  <block id="d36a4ee86f07b3ab1dac130b43608573" category="list-text">在AWS Lambda函数代码源部分中、将* fsxn_monitoring_resizing lambda.py*的内容从git repo*复制到* lambda_Function.py*。</block>
  <block id="aa2c2b9170ac97be5915c92e4d3d9624" category="list-text">创建一个与lambda_function.py级别相同的新文件并将其命名为* vars.py*、然后将vars.py的内容从git repo复制到lambda函数vars.py文件。更新vars.py中的变量值。请参考下面的变量定义、然后单击*部署*：</block>
  <block id="1b1b65a5b121a97f06bd0f40bfe04db2" category="cell">* fsxMgmtIp*</block>
  <block id="48aa922c7ed8d2e7d073ec505c5a679a" category="cell">(必需)从AWS上的ONTAP 的FSX控制台输入"管理端点- IP地址"。</block>
  <block id="b458b0d72a95d6bd9cfcb7a5c23dcb1b" category="cell">* fsxId*</block>
  <block id="da337ce29255b2b81cd9e3a3204bbcfe" category="cell">(必需)从AWS上的FSX for ONTAP 控制台输入"文件系统ID"。</block>
  <block id="68318b373e71a3da8e3dd4430fda3f2b" category="cell">*用户名*</block>
  <block id="c0f05dbdc8c950570df5006e05838a13" category="cell">(必需)从ONTAP 上的ONTAP 控制台输入FSX for ONTAP 的"FSX管理员用户名"。</block>
  <block id="66139124af54a9bd769c36d775836d70" category="cell">*调整大小阈值*</block>
  <block id="8c09ed6e498d70309d841ab06df44a38" category="cell">(必需)输入0-100之间的阈值百分比。此阈值将用于测量存储容量、卷和LUN的使用量、如果超过此阈值的任何使用量百分比增加、则会发生调整大小活动。</block>
  <block id="497a76ab2a24f6810806482af6d4b406" category="cell">*发件人电子邮件*</block>
  <block id="e003b9f112112808c978c5154fda4ca5" category="cell">(必需)输入在SES上注册的电子邮件ID、lambda功能将使用该ID发送与监控和调整大小相关的通知警报。</block>
  <block id="fb154fba377735ccf71f62d4f67db056" category="cell">*收件人电子邮件*</block>
  <block id="84d1d8bc0deec1274356da96f7409f5a" category="cell">(必需)输入要接收警报通知的电子邮件ID。</block>
  <block id="e405587a28590f4765b9cca9a439aee0" category="cell">* FSx_password_SSM_parameter*</block>
  <block id="fd6fdc9b8903fcc41d72463456f66547" category="cell">(必需)输入在AWS参数存储中用于存储"fsxadmin"密码的路径名称。</block>
  <block id="a2b399451f43de7415c9c8d2f2430019" category="cell">*警告通知*</block>
  <block id="4a011a0efb5e78112e4ed7930b4d4ac6" category="cell">*启用_snapshot_deletion*</block>
  <block id="f2a43adf70fef2a5bca3a335b60d96ec" category="cell">(必需)将此变量设置为True、以便为早于"snapshot_age_threshold_in_days"中指定值的快照启用卷级快照删除。</block>
  <block id="d7cef1097d40a983ff6c131976641be8" category="cell">* snapshot_age_threshold_in_days*</block>
  <block id="be6cbc09482802bc252464f7f9dc5176" category="cell">(必需)输入要保留的卷级别快照的天数。任何早于提供值的快照都将被删除、并通过电子邮件通知此快照。</block>
  <block id="8983bb09e5de73133d38fd252364a173" category="inline-image-macro">此图显示了AWS Lambda功能控制台上的lambda代码。</block>
  <block id="8355eb726273f03ca5f55fd35b0a710a" category="paragraph"><block ref="8355eb726273f03ca5f55fd35b0a710a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44903daf5480dcfa1bb48a9ba24e0617" category="list-text">成功测试后、导航到*配置*&gt;*触发器*&gt;*添加触发器*。</block>
  <block id="6bb73947635f7fd1d1f74c0544fa89a6" category="paragraph">单击添加。</block>
  <block id="e12ebba9179a3c37608a804ce282348d" category="inline-image-macro">此图显示了AWS Lambda功能控制台上的事件网桥创建窗口。</block>
  <block id="4e8d49756f1c9d97f6044f5c9c1c5d02" category="paragraph"><block ref="4e8d49756f1c9d97f6044f5c9c1c5d02" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c8219112931de58f84e7a14a0d24d1ce" category="list-text">适用于Apache Kafka的托管平台</block>
  <block id="a96e98488edf9123c2fb5281e71c6ec2" category="paragraph"><block ref="a96e98488edf9123c2fb5281e71c6ec2" category="inline-link-rx"></block></block>
  <block id="0cb1f340d12ba20e283d00e1e0823526" category="list-text">支持Apache Kafka</block>
  <block id="14bb5ca8b6287991417f8f43b4d9eb0c" category="paragraph"><block ref="14bb5ca8b6287991417f8f43b4d9eb0c" category="inline-link-rx"></block></block>
  <block id="9d5591555b2fbddd314212720dc97729" category="list-text">Apache Kafka的咨询服务</block>
  <block id="583ea5ea8c7ad81fed86a1925483124c" category="paragraph"><block ref="583ea5ea8c7ad81fed86a1925483124c" category="inline-link-rx"></block></block>
  <block id="0ab328bbf8073ef01a9d54504bf7b317" category="paragraph">NetApp存储可以通过多种方式在3个主要超大规模主机中的每一个上作为子系统连接或作为补充NFS数据存储库加以利用。</block>
  <block id="f53db24f3a12ed8109f77a0f93c877af" category="paragraph">本节介绍每个云提供商如何在其各自的公共云产品中支持VMware软件定义的数据中心(SDDC)和/或VMware Cloud Foundation (VCF)堆栈。</block>
  <block id="4557eca5dd55b5b5ecc0b0ef61f1dd21" category="cell">2023年3月31日</block>
  <block id="71cc1ac63221b4b22fee5b3615ed204b" category="cell">在AWS FSX/EC2中添加了使用iSCSI/ASM的Oracle数据库部署和保护功能</block>
  <block id="5df30196a94efca9537353cd93678f3a" category="cell">添加了使用SnapCenter 服务进行Oracle数据库备份、还原和克隆的功能</block>
  <block id="86d943d0743178f4b51317bf89a99ff7" category="summary">解决方案 提供了有关在AWS FSX ONTAP 存储和EC2计算实例中部署和保护Oracle数据库的概述和详细信息、其中使用ASM作为卷管理器单独重新启动时配置了iSCSI协议和Oracle数据库。</block>
  <block id="4f3c9d31ccf189b3cb7f494f26684484" category="doc">TR-4965：《使用iSCSI/ASM在AWS FSX/EC2中部署和保护Oracle数据库》</block>
  <block id="418241bdca49e4aec92c0ff810e8e099" category="paragraph">ASM (自动存储管理)是一种受欢迎的Oracle存储卷管理器、广泛应用于许多Oracle安装。这也是Oracle建议的存储管理解决方案。它提供了传统卷管理器和文件系统的替代方案。自Oracle 11g以来、ASM已随网格基础架构打包、而不是数据库打包在一起。因此、要在不使用RAC的情况下使用Oracle ASM进行存储管理、您必须在独立服务器中安装Oracle网格基础架构、也称为Oracle Restart。这样做确实会在以其他方式简化Oracle数据库部署过程中增加更多的复杂性。但是、顾名思义、在重新启动模式下部署Oracle时、任何出现故障的Oracle服务都会在主机重新启动后重新启动、而无需用户干预、从而提供一定程度的高可用性或HA功能。</block>
  <block id="47a7a6100cb8ee47f5b0126bacce0e8f" category="paragraph">在本文档中、我们将演示如何在使用EC2计算实例的Amazon FSX for ONTAP 存储环境中部署采用iSCSI协议的Oracle数据库和Oracle ASM。我们还演示了如何通过NetApp BlueXP控制台使用NetApp SnapCenter 服务来备份、还原和克隆Oracle数据库、以便在AWS公共云中进行开发/测试或其他存储效率数据库操作用例。</block>
  <block id="2dda300300a9a8c69d259bcce9dff4f3" category="list-text">在Amazon FSX中部署Oracle数据库、用于使用iSCSI/ASM的ONTAP 存储和EC2计算实例</block>
  <block id="a47b73991317ed980de57441ff2ec0b0" category="list-text">使用iSCSI/ASM在公共AWS云中测试和验证Oracle工作负载</block>
  <block id="7776a288eb4d92068f227343e40955be" category="list-text">测试和验证AWS中部署的Oracle数据库重新启动功能</block>
  <block id="c7940228c5d339083ac147fb2a5041de" category="list-text">希望使用iSCSI/ASM在AWS公共云中部署Oracle的DBA。</block>
  <block id="53a21d50adb7cce93e4304c816d40c51" category="list-text">一名数据库解决方案 架构师、希望在AWS公共云中测试Oracle工作负载。</block>
  <block id="b316baf0d21d8e459e4220a2cf5102a5" category="list-text">希望部署和管理部署到AWS FSX存储的Oracle数据库的存储管理员。</block>
  <block id="6b41622d6a121d89a6342fe9ff47665c" category="list-text">希望在AWS FSX/EC2中建立Oracle数据库的应用程序所有者。</block>
  <block id="60eafe38e4de145948f4622ffcf3fecf" category="image-alt">此图详细展示了AWS公共云中使用iSCSI和ASM的Oracle部署配置。</block>
  <block id="f90fb2d1bd04ce25f4b6a79bead231a3" category="cell">AWS提供的当前版本</block>
  <block id="ceafc9f8393b625e8cce03cbeba6e867" category="cell">一个FSX HA集群位于同一VPC和可用性区域中</block>
  <block id="0fcdacbce30d770260160f025dfa97ef" category="cell">两个EC2 t2 xlarge EC2实例、一个用作主数据库服务器、另一个用作克隆数据库服务器</block>
  <block id="357401b243915afd7226703258f54f69" category="cell">Oracle网格基础架构</block>
  <block id="8cbabca4a2c1b4268e8c216b1710182d" category="cell">版本19.18</block>
  <block id="4cd47afc935feac95110477afb324f6f" category="cell">已应用RU修补程序p34762026_190000_Linux-x86-64.zip</block>
  <block id="a7c40910ade029baa6baa8b8e613db65" category="cell">已应用RU修补程序p34765931_190000_Linux-x86-64.zip</block>
  <block id="a8b401bad03767cc28230a30d6556c5b" category="cell">Oracle OPatch</block>
  <block id="cc61533b1a42263eaadfd935441bb4b5" category="cell">版本12.2.0.1.36</block>
  <block id="8091f15fd8b9f1a609b3a98e8bcdda81" category="cell">最新修补程序p6880880_190000_Linux-x86-64.zip</block>
  <block id="fed6fa1f1b675c268f8b78258e2545a7" category="cell">SnapCenter 服务</block>
  <block id="313d712dbc391a0b9d6dca3efe0d2608" category="cell">v2.3.1.2324</block>
  <block id="b1a9b82f5c1b9e62aff87e622f684e76" category="list-text">* EC2计算实例。*在这些测试和验证中、我们对Oracle数据库计算实例使用了AWS EC2 T2.xlarge实例类型。NetApp建议在生产部署中使用M5类型的EC2实例作为Oracle的计算实例、因为它针对数据库工作负载进行了优化。您需要根据实际工作负载要求根据vCPU数量和RAM量适当调整EC2实例的大小。</block>
  <block id="11a64b78983fb952ba99933c98fc56df" category="list-text">* FSX存储HA集群单区域或多区域部署。*在这些测试和验证中、我们在一个AWS可用性区域中部署了一个FSX HA集群。对于生产部署、NetApp建议在两个不同的可用性区域中部署一个FSX HA对。FSX HA集群始终配置在一个HA对中、该HA对在一对主动-被动文件系统中进行同步镜像、以提供存储级别的冗余。多区域部署可在单个AWS区域发生故障时进一步提高高可用性。</block>
  <block id="660a107d1d4a80542a6c11d9a1ed2db4" category="list-text">* FSX存储集群规模估算。*适用于ONTAP 存储文件系统的Amazon FSX可提供高达160、000个原始SSD IOPS、高达4 Gbps吞吐量以及最大192 TiB容量。但是、您可以根据部署时的实际要求、根据已配置的IOPS、吞吐量和存储限制(最小1、024 GiB)来调整集群的大小。可以动态调整容量、而不会影响应用程序可用性。</block>
  <block id="0907de49479565aae7dd2f8a84ef2915" category="list-text">* Oracle数据和日志布局。*在测试和验证中、我们分别为数据和日志部署了两个ASM磁盘组。在+data ASM磁盘组中、我们在一个数据卷中配置了四个LUN。在+logs ASM磁盘组中、我们在一个日志卷中配置了两个LUN。通常、在适用于ONTAP 的Amazon FSX卷中部署多个LUN可提高性能。</block>
  <block id="db1de135a2e3ba870a8f80ce78d2d05e" category="list-text">*要为创建的每个Oracle ASM磁盘组使用的Oracle ASM冗余级别。*由于FSX已在FSX集群级别镜像存储、因此应使用外部冗余、这意味着该选项不允许Oracle ASM镜像磁盘组的内容。</block>
  <block id="e35fd1c687443b2da6a609bba53616b4" category="list-text">*数据库备份。* NetApp提供SaaS版本的SnapCenter 软件服务、用于在云中备份、还原和克隆数据库、该服务可通过NetApp BlueXP控制台UI访问。NetApp建议实施此类服务、以实现快速(不到一分钟)的快照备份、快速(几分钟)的数据库还原和数据库克隆。</block>
  <block id="77e4d80ae2f4257081e17476b146608a" category="section-title">解决方案 部署</block>
  <block id="2398118900b3388f97d9931571f1bbda" category="paragraph">下一节介绍了分步部署过程。</block>
  <block id="782bd8949cb40c80fd3f3126eccab35a" category="section-title">部署的前提条件</block>
  <block id="2cb106b524fea2beb3ee19372f04427b" category="list-text">在AWS EC2控制台中、您必须部署两个EC2 Linux实例、一个用作主Oracle数据库服务器、另一个用作可选的克隆目标数据库服务器。有关环境设置的详细信息、请参见上一节中的架构图。另请查看 <block ref="b75ecbbec453f67f58d497ccd97a8075" category="inline-link-macro-rx"></block> 有关详细信息 ...</block>
  <block id="11f86864c5928690c88625e77eb1a480" category="list-text">在AWS EC2控制台中、部署适用于ONTAP 存储HA集群的Amazon FSX以托管Oracle数据库卷。如果您不熟悉FSX存储的部署、请参见相关文档 <block ref="17d8b312d287f0afd6f44b3f25c4f20b" category="inline-link-macro-rx"></block> 了解分步说明。</block>
  <block id="dd303169f721e79331b3683ddafddcc1" category="list-text">可以使用以下Terraform自动化工具包执行步骤2和步骤3、该工具包会创建一个名为的EC2实例<block ref="460dc55b5ffb0266f2c889b06ee73344" prefix=" " category="inline-code"></block> 和名为的FSX文件系统<block ref="8cbb7b3050d3c3aa08a529f429bc4555" prefix=" " category="inline-code"></block>。执行前、请仔细阅读该说明并根据您的环境更改变量。</block>
  <block id="62ee860e3d0c08c6573d2e328543e8de" category="section-title">EC2实例内核配置</block>
  <block id="5a8cdca62a149c76be848350ba5cbfd0" category="list-text">创建暂存目录<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> 文件夹并设置<block ref="f1c1592588411002af340cbaedd6fc33" prefix=" " category="inline-code"></block> 权限。</block>
  <block id="e252f38e51fe6c121fdf68268f7365b7" category="list-text">将Oracle二进制安装文件和其他所需的rpm文件下载并暂存到<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> 目录。</block>
  <block id="2463a0e4e0f5e0cae480165d25c3d218" category="paragraph">请参见以下要在中说明的安装文件列表<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> 在EC2实例上。</block>
  <block id="7b25ef659963c88fe23b78fc4712aabf" category="list-text">安装Oracle 19c预安装RPM、以满足大多数内核配置要求。</block>
  <block id="1527576f8dc9eea4d63eb05b809aaa52" category="list-text">下载并安装缺少的<block ref="d2e5af6ee2b267de9dac1b472a03adf3" prefix=" " category="inline-code"></block> 在Linux 8中。</block>
  <block id="b2371ec5566671ad5a4ad4a5ea6cba11" category="list-text">从NetApp下载并安装NetApp主机实用程序。</block>
  <block id="b6e7702627b94eaa3030b577d6d705bc" category="list-text">安装<block ref="c8dff58175a7ddfedf00d77953ef42dd" prefix=" " category="inline-code"></block>、在EC2实例中不可用。</block>
  <block id="9a16a877dc258dab15fccea468433118" category="list-text">安装Open JDK 1.8版。</block>
  <block id="1684a037c41a5a896a961b99be3d79c7" category="list-text">安装iSCSI启动程序实用程序。</block>
  <block id="c9d53c5d17f956afae2225c70107de12" category="list-text">安装<block ref="4c17da57a03262c55ed7eaf9b11476b4" prefix=" " category="inline-code"></block>。</block>
  <block id="390748df672cba58066187eedd5aae0e" category="list-text">安装<block ref="a3938eeca32dce6ca3908d2eae163c75" prefix=" " category="inline-code"></block>。</block>
  <block id="8d5128c24aba40267289419650d61baf" category="list-text">在当前系统中禁用透明页面。</block>
  <block id="0410d25eb8075ef0d6eb88ced58d20d0" category="paragraph">在中添加以下行<block ref="08561da4afe8299be4016c92bfe83435" prefix=" " category="inline-code"></block> 以禁用<block ref="d78ade61a64b6a278ed6278e7cfd91f3" prefix=" " category="inline-code"></block> 重新启动后：</block>
  <block id="ac762383bc7427decd2147abbadaccaa" category="list-text">通过更改禁用SELinux<block ref="cb42f4736bc8f64983eeffc1e0b4f44a" prefix=" " category="inline-code"></block> to<block ref="52647e37ec523adfcaa3fec9bcef128e" prefix=" " category="inline-code"></block>。要使更改生效、必须重新启动主机。</block>
  <block id="2d1601e142ebdb74931ee9a254b65262" category="list-text">将以下行添加到<block ref="8b5eec1c5f63341b700263cc37cbae02" prefix=" " category="inline-code"></block> 设置不带引号的文件描述符限制和堆栈大小<block ref="fcc3d7489d15ef49dbbf735234234cf7" prefix=" " category="inline-code"></block>。</block>
  <block id="410eaf64cdfb52cb0921ea732490d0db" category="list-text">按照以下说明向EC2实例添加交换空间： <block ref="53c9867a131506eab4afe1a1678bb974" category="inline-link-macro-rx"></block> 要添加的确切空间量取决于RAM大小、最高可达16G。</block>
  <block id="c9f7be60d92cf42de8f14f5ab8547971" category="list-text">更改<block ref="b7e6d8bff01730e41b7d91437e6a25d0" prefix=" " category="inline-code"></block> 在中<block ref="c30b27a1b058924e30212c72bb553665" prefix=" " category="inline-code"></block> 配置文件的时间从120秒到5秒不等。</block>
  <block id="bca8f765f0293b09679dd10ece969e68" category="list-text">在EC2实例上启用并启动iSCSI服务。</block>
  <block id="3cb574654986fcf318668b4bf3313724" category="list-text">检索要用于数据库LUN映射的iSCSI启动程序地址。</block>
  <block id="d5dbcd1ace089fec7f75fa03e884cb93" category="list-text">添加要用于ASM sysasm组的ASM组</block>
  <block id="f7b4c2e912a168f005ed7cc2b4799c08" category="list-text">修改Oracle用户以将ASM添加为二级组(Oracle用户应在安装Oracle预安装RPM后创建)。</block>
  <block id="8d3a75a7cdef66372dcf58e6278bba70" category="list-text">重新启动EC2实例。</block>
  <block id="64014fc61a9016f43a5537d6da141cc1" category="section-title">配置数据库卷和LUN并将其映射到EC2实例主机</block>
  <block id="c848cfd9c04d86e7b9919e11add79f6c" category="list-text">以fsxadmin用户身份通过SSH登录到FSX集群。</block>
  <block id="eff24d82c422927b06fd0cacd430b653" category="list-text">执行以下命令为Oracle二进制文件创建卷。</block>
  <block id="569cffa50e6428a06bffa2e19d12e0e3" category="list-text">执行以下命令为Oracle数据创建卷。</block>
  <block id="9985026df910c788cb47555f7d72a68e" category="list-text">执行以下命令为Oracle日志创建卷。</block>
  <block id="cc70e928fff63a76ca8cf30a05d95a80" category="list-text">在数据库二进制卷中创建二进制LUN。</block>
  <block id="dc4301dd6be2058cb9d1a1e3408388eb" category="list-text">在数据库数据卷中创建数据LUN。</block>
  <block id="49cf66e4521ade9e7ffc2aae313ee978" category="list-text">在数据库日志卷中创建日志LUN。</block>
  <block id="3e408df5c51ac33acd5978f1f48cab19" category="list-text">使用从上述EC2内核配置的步骤14中检索到的启动程序为EC2实例创建一个igroup。</block>
  <block id="ceed9a3dd22f247b70bb6774943f9284" category="list-text">将LUN映射到上述创建的igroup。按顺序增加卷中每个附加LUN的LUN ID。</block>
  <block id="18519dc23f47343cf516e789bf2e818b" category="list-text">验证LUN映射。</block>
  <block id="3208f25d37711dd9ffc43d93ada2a3cc" category="paragraph">这将返回：</block>
  <block id="35c1914e41e83f92dd8779f5708f3224" category="section-title">数据库存储配置</block>
  <block id="47d78479fc855bd2f99f02fb94118789" category="paragraph">现在、为EC2实例主机上的Oracle网格基础架构和数据库安装导入并设置FSX存储。</block>
  <block id="a7939166c08e8ac6da1530309825a401" category="list-text">使用任一SVM iSCSI IP地址发现FSX iSCSI端点。然后、更改为您的环境专用门户地址。</block>
  <block id="1bc103d13645d8a07f4a05f2eee064f8" category="list-text">登录到每个目标以建立iSCSI会话。</block>
  <block id="fc5113f60b8b0390133d7abda7290515" category="paragraph">命令的预期输出为：</block>
  <block id="c541a8df6ddefee9ae370e31bf1109cc" category="list-text">查看并验证活动iSCSI会话的列表。</block>
  <block id="efe44c0a293be7b9e3d17291e1bd0fce" category="paragraph">返回iSCSI会话。</block>
  <block id="e4a8008161f8d488131b8bf10831bf6c" category="list-text">验证LUN是否已导入到主机中。</block>
  <block id="f467f5c5010c383146b412ebc7d2a967" category="paragraph">此操作将从FSX返回Oracle LUN的列表。</block>
  <block id="08b7a2f63e8caee3c8d0f32a3d9dd5ea" category="list-text">配置<block ref="9ac80d53ede05256c28cf9e043eb423c" prefix=" " category="inline-code"></block> 包含以下默认条目和黑名单条目的文件。</block>
  <block id="794a654f60052714db9eba2a7ff4b608" category="list-text">启动多路径服务。</block>
  <block id="65b4cea56e6d27de22dc85622fe6a7fb" category="paragraph">现在、多路径设备将显示在中<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> 目录。</block>
  <block id="d282577e5b16ee7f17ce7cd0f718be4c" category="list-text">通过SSH以fsxadmin用户身份登录到FSX集群、以检索每个LUN的序列号十六进制值、该值以6c574xxx开头...、十六进制值以3600a0980开头、即AWS供应商ID。</block>
  <block id="2720e08c2a6367757e2dc57afee1620c" category="paragraph">并返回如下内容：</block>
  <block id="ecf2aff9ad02b9026ff22f4fc6a68e73" category="list-text">更新<block ref="bacd7d75ae434c4a777b1baef0e31f36" prefix=" " category="inline-code"></block> 文件、用于为多路径设备添加用户友好名称。</block>
  <block id="75104fff60881baaf37dcb441594f8a1" category="paragraph">包含以下条目：</block>
  <block id="e73e686392436f1038dd926c4a775f24" category="list-text">重新启动多路径服务以验证下的设备<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> 已更改为LUN名称与串行十六进制ID。</block>
  <block id="5f9e8fcf665ea0cca4e1c6eea45645e4" category="paragraph">检查<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> 返回如下内容：</block>
  <block id="6f6e08574875efd99672521b7c49bd5f" category="list-text">使用一个主分区对二进制LUN进行分区。</block>
  <block id="d90e8b8ea181e08e8bf690f2c3143681" category="list-text">使用XFS文件系统格式化分区的二进制LUN。</block>
  <block id="999ccfc779bcbed2a3561bff37f884d1" category="list-text">将二进制LUN挂载到<block ref="a8946fa5f211c5345e3610710e471cb4" prefix=" " category="inline-code"></block>。</block>
  <block id="22e45c04a42f3d5d2b9ca76b19445949" category="list-text">更改<block ref="a8946fa5f211c5345e3610710e471cb4" prefix=" " category="inline-code"></block> 将点所有权挂载到Oracle用户及其所属的主组。</block>
  <block id="a7d5cd359d07f4d25f07c14cac7c892f" category="list-text">查找二进制LUN的UUI。</block>
  <block id="419b15da0e06224d0919aaf7cf7c0394" category="list-text">将挂载点添加到<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block>。</block>
  <block id="4f86d8e0be25b09fa4c4f087139fcd0d" category="paragraph">添加以下行。</block>
  <block id="b79f3809b435063f1d43819c9baaf816" category="admonition">请务必仅使用UUID和nodfail选项挂载二进制文件、以避免在EC2实例重新启动期间可能出现根锁定问题。</block>
  <block id="ad7b51bb9b820412dddd78b34ccf36ea" category="list-text">以root用户身份为Oracle设备添加udev规则。</block>
  <block id="8e7c7ff83f0da1eceabb8c7fbb255de4" category="paragraph">包括以下条目：</block>
  <block id="d347f5dbb8625ab56eb3b8ad0f1ed6ca" category="list-text">以root用户身份重新加载udev规则。</block>
  <block id="967abd537fdc45fbfc59ee4d5fbd70d2" category="list-text">以root用户身份触发udev规则。</block>
  <block id="aeead6d2d9990fef69ffefd2efd88b90" category="list-text">以root用户身份重新加载multipathd。</block>
  <block id="3cadabe14e57cb049891c97e754906d7" category="section-title">Oracle网格基础架构安装</block>
  <block id="2ba967266d1ac37f6ee2c138c7a219f1" category="list-text">通过SSH以EC2-user身份登录到EC2实例、并通过取消注释启用密码身份验证<block ref="cd94e87e5216cd088acdc4de0e9c30f1" prefix=" " category="inline-code"></block> 然后进行注释<block ref="f18918133cfc22e041baab71b051c41f" prefix=" " category="inline-code"></block>。</block>
  <block id="f919e378a236907726426311e1222ca5" category="list-text">重新启动sshd服务。</block>
  <block id="886890ea240491bd5c7fbf2ad26038e0" category="list-text">重置Oracle用户密码。</block>
  <block id="312dbdb4917346c5535b58edeb72d5d8" category="list-text">以Oracle Restart软件所有者用户(Oracle)身份登录。按如下所示创建Oracle目录：</block>
  <block id="2fce107e9da63a27050a1b7738518797" category="list-text">更改目录权限设置。</block>
  <block id="de76f7d30e13c7b0fac443a1b582500b" category="list-text">创建网格主目录并进行更改。</block>
  <block id="ca3eab9cf7a8f03f19d82f95a9ccebc0" category="list-text">解压缩网格安装文件。</block>
  <block id="4cb0c768cefd4361adc66dd3dfac2ad8" category="list-text">从网格主页中、删除<block ref="29b6fb214b3224ca10c7261aa01e44b5" prefix=" " category="inline-code"></block> 目录。</block>
  <block id="572656c141066b10c23d5205e70be53b" category="list-text">从网格主页复制<block ref="63628571f2dfaeb6f0a0a676290e6e82" prefix=" " category="inline-code"></block> 到grid_home、然后将其解压缩。</block>
  <block id="5d940bd40ee32694345bce5774d5c678" category="list-text">从网格主页修改<block ref="ef8657f0a0a00af93ba7f1c8885339ca" prefix=" " category="inline-code"></block>、取消注释并替换<block ref="bb7738211dd8eb3dbadf4cc63ae8eb8a" prefix=" " category="inline-code"></block> 使用<block ref="b2affc1a941fe7e5e65933911250249c" prefix=" " category="inline-code"></block>。</block>
  <block id="e4dae708382daa7f76913b9e5b686a1c" category="list-text">准备<block ref="77d9f4d56c58834c8dacf6d0cb94e085" prefix=" " category="inline-code"></block> 文件以进行静默安装、并将rsp文件置于中<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> 目录。rsp文件应涵盖A、B和G部分、并提供以下信息：</block>
  <block id="72eab9d7fc33889fd5bf6a85943c4e4a" category="list-text">以root用户身份登录到EC2实例并进行设置<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> 和<block ref="456a3c82b7208b5c2a000597b1330564" prefix=" " category="inline-code"></block>。</block>
  <block id="d134d418859128801ec294cd10bcbd8e" category="list-text">配置磁盘设备以与Oracle ASM筛选器驱动程序结合使用。</block>
  <block id="3e6c5f0c8e9c1310879c66839bb0f8d5" category="list-text">安装<block ref="a27b4e2b8f4a0b0419894dfeac36419e" prefix=" " category="inline-code"></block>。</block>
  <block id="cfdbf231484c64b98bc4f3569cd7b324" category="list-text">未设置<block ref="c0c2c8394b04a929ffc60091aa1f72ca" prefix=" " category="inline-code"></block>。</block>
  <block id="9817d9ff96af960709b8094b73294545" category="list-text">以Oracle用户身份登录到EC2实例、然后在中提取修补程序<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> 文件夹。</block>
  <block id="5de6732dda1e7bccbd8e8b367ad248dd" category="paragraph">忽略有关网格基础架构的错误组的警告。我们正在使用一个Oracle用户来管理Oracle Restart、因此这是预期的。</block>
  <block id="7dff0a250c79eafa071ee2d5713b7123" category="list-text">以Oracle用户身份执行以下命令以完成配置：</block>
  <block id="3f2a67de0c5824d878c62c0bc347e09b" category="list-text">以Oracle用户身份创建日志磁盘组。</block>
  <block id="f71fbb7ff86224d636aac5f9bb42f27d" category="list-text">以Oracle用户身份、在安装配置后验证网格服务。</block>
  <block id="f9ba171dd47a8cef31bac8aa17eeb44d" category="list-text">Valiate ASM筛选器驱动程序状态。</block>
  <block id="b7e3e332087b6a041c83ce22cce9043c" category="section-title">Oracle数据库安装</block>
  <block id="9250c441cd32cef9ac89c4aaea3311e2" category="list-text">以Oracle用户身份登录并取消设置<block ref="88ee3ad336791517a935931e1e50382a" prefix=" " category="inline-code"></block> 和<block ref="1548c2f12948ef1485a923f5891a3489" prefix=" " category="inline-code"></block> 如果已设置。</block>
  <block id="9c1b98a904b357f470c8d87cf837d8cf" category="list-text">创建Oracle DB主目录并进行更改。</block>
  <block id="74d5f0f080c7e7c4f0011e6b16a1072f" category="list-text">解压缩Oracle数据库安装文件。</block>
  <block id="1fdd02c9779c06712368af7ed65c00dd" category="list-text">从数据库主目录中、删除<block ref="29b6fb214b3224ca10c7261aa01e44b5" prefix=" " category="inline-code"></block> 目录。</block>
  <block id="948ac6ddaa5b19c62366a04abf60547d" category="list-text">从数据库主页复制<block ref="63628571f2dfaeb6f0a0a676290e6e82" prefix=" " category="inline-code"></block> to<block ref="22f5bd75d60d3065afc99a50bc98d9ae" prefix=" " category="inline-code"></block>、然后将其解压缩。</block>
  <block id="d86c0eec890e4216540c2b834f6339f5" category="list-text">在数据库主页中、修改<block ref="ef8657f0a0a00af93ba7f1c8885339ca" prefix=" " category="inline-code"></block>和取消注释并替换<block ref="bb7738211dd8eb3dbadf4cc63ae8eb8a" prefix=" " category="inline-code"></block> 使用<block ref="b2affc1a941fe7e5e65933911250249c" prefix=" " category="inline-code"></block>。</block>
  <block id="95233719931805924ded9cd671e036df" category="list-text">从<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> 目录中、解压缩DB 19.18 RU修补程序。</block>
  <block id="0181cf4258f052eaf2d48f78cd4fed7b" category="list-text">在中准备DB静默安装rsp文件<block ref="2d9ffa0a3db25b02bcd0091245449764" prefix=" " category="inline-code"></block> 具有以下值的目录：</block>
  <block id="05472424b7ce7bd118009f6cde3a0614" category="list-text">设置Oracle用户<block ref="9e0037ad71166970bde5f910189cc94a" prefix=" " category="inline-code"></block>。</block>
  <block id="cadaa91ab9001028d3a153b4325f10a5" category="list-text">添加以下条目：</block>
  <block id="ab5f5bab123b3441fc9c838b46ff1150" category="list-text">验证已创建的CDB/PDB。</block>
  <block id="a0b58d032d36bf0801e5ca3a2aa515d9" category="list-text">使用sqlplus登录到数据库并启用归档日志模式。</block>
  <block id="0a31d377857a1d2e24f8e85950a44aac" category="paragraph">至此、在适用于ONTAP 和EC2计算实例的Amazon FSX上完成Oracle 19c版本19.18重新启动部署。如果需要、NetApp建议将Oracle控制文件和联机日志文件重新定位到+logs磁盘组。</block>
  <block id="4d3617697efd9a8201cb07f5e610e306" category="section-title">自动化部署选项</block>
  <block id="3809b24192da05cb9bdf6fc7f86ce5d6" category="paragraph">NetApp将随Ansible发布一个完全自动化的解决方案 部署工具包、以便于实施此解决方案。请查看此工具包的可用性。发布后、此处将发布一个链接。</block>
  <block id="6cf7e59477fa5c8722c79a0910c40cd8" category="section-title">使用SnapCenter 服务备份、还原和克隆Oracle数据库</block>
  <block id="a0c9cf73752e72933d08cadbcdf8c05a" category="inline-link-macro">适用于Oracle的SnapCenter 服务</block>
  <block id="916b48729c536f6a12c2122673bc394a" category="paragraph">请参见 <block ref="3e99507ec3d2036a04c899dadd6c66e9" category="inline-link-macro-rx"></block> 有关使用NetApp BlueXP控制台备份、还原和克隆Oracle数据库的详细信息。</block>
  <block id="aa5a3d07c03024007dadc921fdbe67cb" category="paragraph">要了解有关本文档中所述信息的更多信息，请查看以下文档和 / 或网站：</block>
  <block id="5424ed1a1b4c4815e1d1676f23aa1da4" category="list-text">在安装新数据库的情况下为独立服务器安装Oracle网格基础架构</block>
  <block id="a7410994d191ba6c350f0f764df86934" category="inline-link-macro"><block ref="a7410994d191ba6c350f0f764df86934" category="inline-link-rx"></block></block>
  <block id="094328bca120efd3d6fba90d69b806f8" category="paragraph"><block ref="094328bca120efd3d6fba90d69b806f8" category="inline-link-macro-rx"></block></block>
  <block id="8ae84196c6f373ef488c40b0b95e030d" category="list-text">使用响应文件安装和配置Oracle数据库</block>
  <block id="ee622e67d0075e37fff43bbf337e98b2" category="inline-link-macro"><block ref="ee622e67d0075e37fff43bbf337e98b2" category="inline-link-rx"></block></block>
  <block id="2d94d091f5afb89e4f1aab002cef14a3" category="paragraph"><block ref="2d94d091f5afb89e4f1aab002cef14a3" category="inline-link-macro-rx"></block></block>
  <block id="6845898fa7e9ec1fa3b8934d8e91b0c1" category="summary">解决方案 提供了有关使用BlueXP控制台使用NetApp SnapCenter SaaS进行Oracle数据库备份、还原和克隆的概述和详细信息。</block>
  <block id="8ae5c33b293249b4befae60cdc1d6364" category="paragraph">SnapCenter 服务是一款SaaS版本的经典SnapCenter 数据库管理UI工具、可通过NetApp BlueXP云管理控制台访问。它是NetApp云备份和数据保护产品不可或缺的一部分、适用于在NetApp云存储上运行的Oracle和HANA等数据库。这种基于SaaS的服务简化了传统的SnapCenter 独立服务器部署、该部署通常需要在Windows域环境中运行的Windows服务器。</block>
  <block id="05530a14144f96daea2a6f96bb61b38b" category="paragraph">在本文档中、我们将演示如何设置SnapCenter 服务来备份、还原和克隆部署到Amazon FSX for ONTAP 存储和EC2计算实例的Oracle数据库。虽然设置和使用起来要简单得多、但SnapCenter 服务可提供传统SnapCenter UI工具中提供的主要功能。</block>
  <block id="d47397f53e6c7682397a8f8688daddcc" category="list-text">为Amazon FSX for ONTAP 中托管的Oracle数据库执行数据库备份和快照</block>
  <block id="403ca933973134cbaf8f9354830b4d9c" category="list-text">发生故障时恢复Oracle数据库</block>
  <block id="6f2d8b46ec98e47be22d4747b82a02d2" category="list-text">为开发/测试环境或其他使用情形快速、高效地克隆主数据库</block>
  <block id="de98fb1438e12380191eaa97d6c6b90d" category="paragraph">本解决方案 面向以下受众：</block>
  <block id="bdc080d1f53262a817a1472a559d75dd" category="list-text">管理在适用于ONTAP 存储的Amazon FSX上运行的Oracle数据库的DBA</block>
  <block id="d6e066caa1ab2a9ead96779ac0a95670" category="list-text">解决方案 架构师、负责在公共AWS云中测试Oracle数据库备份、还原和克隆</block>
  <block id="3e05bb0c3eae0733dd3f5b6eda0da89e" category="list-text">支持和管理适用于ONTAP 存储的Amazon FSX的存储管理员</block>
  <block id="e55870c74749ffe7a1d8b4c1a9cb5b60" category="list-text">拥有部署到Amazon FSX for ONTAP 存储的应用程序的应用程序所有者</block>
  <block id="86fae68c14c723bf36942c2c83e8a847" category="list-text">*连接器应与数据库和FSX部署在同一VPC中。*如果可能、应将连接器部署在同一AWS VPC中、以便能够连接到FSX存储和EC2计算实例。</block>
  <block id="16d04337973f389d2f7da86eac115afd" category="paragraph">我们提供了大量的NetApp文档、范围更广、可帮助您保护云原生应用程序数据。本文档的目标是提供有关使用SnapCenter 控制台部署ONTAP 服务的分步过程、以保护部署到Amazon FSX for和EC2计算实例中的Oracle数据库。本文档将填写一些可能在一般说明中缺少的详细信息。</block>
  <block id="20c4c0cc24d7fc086bd9c72220d4827f" category="paragraph">要开始使用、请完成以下步骤：</block>
  <block id="eb5668f5c3459c84cc715cf197e7c91a" category="inline-link-macro">保护您的Cloud原生 应用程序数据</block>
  <block id="fba4ab9f47a6aa18ae1b02fb3d8f6db1" category="list-text">阅读一般说明 <block ref="ac041fb7031b2bcbcb203adcabf84a4f" category="inline-link-macro-rx"></block> 以及与Oracle和Amazon FSX for ONTAP 相关的章节。</block>
  <block id="f2f7f5c9af8a75d22b9aca95d23faad9" category="list-text">观看以下视频演练。</block>
  <block id="80478dbd4349cfca50f458d912a95795" category="section-title">部署SnapCenter 服务的前提条件</block>
  <block id="ee260886ab2b6b27905543032620ac6f" category="list-text">EC2实例上的主Oracle数据库服务器、其中Oracle数据库已完全部署且正在运行。</block>
  <block id="ab12a73272bb7f9d19f02c65ce057f61" category="inline-link-macro">使用iSCSI/ASM在AWS FSX/EC2中部署和保护Oracle数据库</block>
  <block id="b8b1139d652a0eeb20f8d04852ac0ff4" category="section-title">加入BlueXP准备阶段</block>
  <block id="1273c8a63109161e6fd1f18d6998523f" category="inline-link-macro">NetApp BlueXP</block>
  <block id="87d337785ad5798c5ccb41300628991a" category="list-text">使用链接 <block ref="f796c57cbc184209dde3e35268bc382f" category="inline-link-macro-rx"></block> 注册访问BlueXP控制台。</block>
  <block id="ead8f2b206d64f3dc022b5aff7ebf5ef" category="inline-image-macro">在图形用户界面中显示此步骤的屏幕截图。</block>
  <block id="f6d580bf790e26134ef61bf9d6fe18fe" category="paragraph"><block ref="f6d580bf790e26134ef61bf9d6fe18fe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e23d889dea00cd09a68857a66540a2" category="section-title">为SnapCenter 服务部署连接器</block>
  <block id="ff983eb1cf4195dbceed01ba6d95f4bd" category="paragraph"><block ref="ff983eb1cf4195dbceed01ba6d95f4bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c47cec29fcf0d8e782f2c91ad12914b4" category="list-text">单击*添加连接器*以启动连接器配置工作流。</block>
  <block id="06daec2780fc4a5c0089241439b6abc4" category="paragraph"><block ref="06daec2780fc4a5c0089241439b6abc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bb78288dc7f5beb506e79a3af8041de" category="list-text">选择您的云提供商(此处为* Amazon Web Services*)。</block>
  <block id="8087e08b633357d4802bcc914799e1e0" category="paragraph"><block ref="8087e08b633357d4802bcc914799e1e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="06a5177c61e31798acfdd25d766ef121" category="list-text">如果您已在AWS帐户中设置了*权限*、*身份验证*和*网络*步骤、请跳过这些步骤。如果没有、则必须先配置这些组件、然后再继续。您还可以从此处检索上一节中引用的AWS策略的权限"<block ref="2204dd011c923b13eaa19e758c798231" category="inline-xref-macro-rx"></block>。 "</block>
  <block id="79463376ddcde3119f1d61ab3e8ace01" category="paragraph"><block ref="79463376ddcde3119f1d61ab3e8ace01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a45e1d81bff2e550eac67a6a5fa7cbf" category="paragraph"><block ref="6a45e1d81bff2e550eac67a6a5fa7cbf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="712e596a90ac38ed31c6d4d55347a559" category="list-text">为连接器实例命名、然后在*详细信息*下选择*创建角色*。</block>
  <block id="98c5e6a562ea83f6e395b91667156df3" category="paragraph"><block ref="98c5e6a562ea83f6e395b91667156df3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fde599fe1b1ccfb7275d4e17f0b4fc17" category="paragraph"><block ref="fde599fe1b1ccfb7275d4e17f0b4fc17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3d2711238be85fe0acd7b353cb0571c" category="paragraph"><block ref="e3d2711238be85fe0acd7b353cb0571c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f067570884442aa68da666583a8530cc" category="list-text">查看摘要页面、然后单击*添加*以开始创建连接器。完成部署通常需要大约10分钟。完成后、此连接器实例将显示在AWS EC2信息板中。</block>
  <block id="165138d0d406e2c17d45e777fc26ebc5" category="paragraph"><block ref="165138d0d406e2c17d45e777fc26ebc5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb46d1e3b94fe670b59ad65582cc45d9" category="section-title">SnapCenter 服务设置</block>
  <block id="3ecf7d7cbb172543fe0f740496cfb9b0" category="list-text">在*我的工作环境*中、单击*添加工作环境*以发现AWS中部署的FSX。</block>
  <block id="537b713708147506a182f9e62348c997" category="paragraph"><block ref="537b713708147506a182f9e62348c997" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4daeb16c1a9b1a0d173181068ef06541" category="list-text">选择* Amazon Web Services*作为位置。</block>
  <block id="25949fd8842fc6d4e2a3d0e74bbc18d9" category="paragraph"><block ref="25949fd8842fc6d4e2a3d0e74bbc18d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="beb3aca877ee917cc965b653f4f954c2" category="list-text">单击*适用于ONTAP 的Amazon FSx *旁边的*发现现有*。</block>
  <block id="669e7983bcf1791e42789eb5557823c1" category="paragraph"><block ref="669e7983bcf1791e42789eb5557823c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2dd86f2e91e85ccea46f244108988758" category="paragraph"><block ref="2dd86f2e91e85ccea46f244108988758" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c90af5467bb4ade93f516a477fab6ce" category="list-text">选择部署了Amazon FSX for ONTAP 的AWS区域、选择托管Oracle数据库的FSX集群、然后单击添加。</block>
  <block id="39accbdb3a3b52363e35c6bd0a5768d8" category="paragraph"><block ref="39accbdb3a3b52363e35c6bd0a5768d8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6a9497923f20e49ad508a714878556d" category="list-text">此时、发现的Amazon FSX for ONTAP 实例将显示在工作环境中。</block>
  <block id="b996189c5d6c6476140b17331222eaf4" category="paragraph"><block ref="b996189c5d6c6476140b17331222eaf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5abed4635dac308091151770538f31f6" category="list-text">您可以使用fsxadmin帐户凭据登录到FSX集群。</block>
  <block id="a0297da6f92a68d1492ecdf77c4949fb" category="paragraph"><block ref="a0297da6f92a68d1492ecdf77c4949fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72788f45d9fca0c46cf26a1728176b48" category="list-text">登录到Amazon FSX for ONTAP 后、请查看数据库存储信息(例如数据库卷)。</block>
  <block id="8a51384a3ecf5b098e9facdac7fd4742" category="paragraph"><block ref="8a51384a3ecf5b098e9facdac7fd4742" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04353f9112bb1b7ff1621abd8ff0ef5b" category="list-text">从控制台的左侧边栏中、将鼠标悬停在保护图标上、然后单击*保护*&gt;*应用程序*以打开应用程序启动页面。单击*发现应用程序*。</block>
  <block id="c174305d25dc1c3ea7e6fd64534c302d" category="paragraph"><block ref="c174305d25dc1c3ea7e6fd64534c302d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="598fd5b506ddf6b5a73368a488fa16c0" category="list-text">选择*云原生*作为应用程序源类型。</block>
  <block id="4645a6f0abb4aa3edf2172708fd672e0" category="paragraph"><block ref="4645a6f0abb4aa3edf2172708fd672e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bfcedcc06ce70b69b0c25371a7b68359" category="list-text">选择* Oracle *作为应用程序类型。</block>
  <block id="d90ff0259aa21df9ff992d15f1efcbd2" category="paragraph"><block ref="d90ff0259aa21df9ff992d15f1efcbd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a91f39c3d22fe697afbaa8e861c6f1e1" category="paragraph"><block ref="a91f39c3d22fe697afbaa8e861c6f1e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9958dec2bab238d2e917ab477e6687a5" category="paragraph">至此、适用于Oracle的SnapCenter 服务的初始设置完成。本文档接下来的三节将介绍Oracle数据库备份、还原和克隆操作。</block>
  <block id="7f7c0dda9cb78e17432e91abc3c9a290" category="section-title">Oracle数据库备份</block>
  <block id="d243d925299e4128a453e9d54b57e25d" category="list-text">单击数据库*保护状态*旁边的三点、然后单击*策略*以查看可应用于保护Oracle数据库的默认预加载数据库保护策略。</block>
  <block id="f5ec19f9ff10edc4aa6fc1c116c6b23e" category="paragraph"><block ref="f5ec19f9ff10edc4aa6fc1c116c6b23e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44fa14fc437558bfdfce0d0ac643d1e2" category="list-text">如果您对策略配置满意、则可以分配所选的策略来保护数据库。</block>
  <block id="2bf8224a90f863c821d826f3501d5c0a" category="paragraph"><block ref="2bf8224a90f863c821d826f3501d5c0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4861abebdaa3d58ada4e621adac79010" category="list-text">选择要分配给数据库的策略。</block>
  <block id="c6f05663d6855c56941461ecc27d6b12" category="paragraph"><block ref="c6f05663d6855c56941461ecc27d6b12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da1635fa4036afa9fa39c868740e8560" category="list-text">应用此策略后、数据库保护状态将更改为*受保护*、并带有绿色复选标记。</block>
  <block id="0d63626c21bc3f6eaeff860db7839e8e" category="paragraph"><block ref="0d63626c21bc3f6eaeff860db7839e8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7474327f9583bb0f2aa4aa276aa11e53" category="list-text">数据库备份按预定义的计划运行。您还可以运行一次性按需备份、如下所示。</block>
  <block id="3adad6846dd8bf1ff91c627d2f4bea27" category="paragraph"><block ref="3adad6846dd8bf1ff91c627d2f4bea27" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7ba3fa48656ab6088ca8f9f4c64578f" category="list-text">可以通过单击菜单列表中的*查看详细信息*来查看数据库备份详细信息。其中包括备份名称、备份类型、SCN和备份日期。备份集涵盖数据卷和日志卷的快照。日志卷快照会在数据库卷快照之后立即发生。如果要在长列表中查找特定备份、则可以应用筛选器。</block>
  <block id="c76057368e5767af8f13e84e53b3194f" category="paragraph"><block ref="c76057368e5767af8f13e84e53b3194f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fd0ba63e6574c7326fb2e810b4537e0" category="section-title">Oracle数据库还原和恢复</block>
  <block id="d747acf93ee8abac3afd574a32b975fe" category="list-text">对于数据库还原、请按SCN或备份时间选择合适的备份。单击数据库数据备份中的三个点、然后单击*还原*以启动数据库还原和恢复。</block>
  <block id="7331f40ac7ceea61fa15e6868eba99e7" category="paragraph"><block ref="7331f40ac7ceea61fa15e6868eba99e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ced09bd050d5fa98df8a41ef04173e0" category="list-text">选择还原设置。如果您确定备份后物理数据库结构中没有任何变化(例如添加数据文件或磁盘组)、则可以使用*强制原位还原*选项、该选项通常速度更快。否则、请勿选中此框。</block>
  <block id="2684b5e65a8e3b537bd594678549bc4e" category="paragraph"><block ref="2684b5e65a8e3b537bd594678549bc4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d58c0a59c722f81b5e2d0f77ffc4e126" category="list-text">查看并启动数据库还原和恢复。</block>
  <block id="9ab34ce0349fd7db7573bad83c07a487" category="paragraph"><block ref="9ab34ce0349fd7db7573bad83c07a487" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e370cf26e04645138a40a3379e743fb7" category="list-text">在*作业监控*选项卡中、您可以查看恢复作业的状态以及运行期间的任何详细信息。</block>
  <block id="e9214106e8bbcaae5a214e937af349e6" category="paragraph"><block ref="e9214106e8bbcaae5a214e937af349e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd84eda02c29b3672e3476ed8c8be12d" category="paragraph"><block ref="bd84eda02c29b3672e3476ed8c8be12d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9dc2f50af584776a2ecc51a0ebcdded2" category="section-title">Oracle数据库克隆</block>
  <block id="35526fc92bd49edc3a11a0affafeae3b" category="paragraph">要克隆数据库、请从同一数据库备份详细信息页面启动克隆工作流。</block>
  <block id="71f8cd32cfa279d796f673879629f671" category="list-text">选择正确的数据库备份副本、单击三点以查看菜单、然后选择*克隆*选项。</block>
  <block id="b858b9fa0a1f0db13263cc0c2cc5cf3d" category="paragraph"><block ref="b858b9fa0a1f0db13263cc0c2cc5cf3d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d552bd00a2d8ed3e1872a0f795180b9f" category="list-text">如果不需要更改任何克隆的数据库参数、请选择*基本*选项。</block>
  <block id="867de7ff195f530db4a1e5643a75c689" category="paragraph"><block ref="867de7ff195f530db4a1e5643a75c689" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90b931da49f7db8ce97de89c2b7ea8d5" category="list-text">或者、也可以选择*规格文件*、这样您可以选择下载当前的init文件并进行更改、然后将其上传到作业。</block>
  <block id="f89a131e2cb4beb2f5dc697ac61b460f" category="paragraph"><block ref="f89a131e2cb4beb2f5dc697ac61b460f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b9252d48a9fcf8c03ec68f357e943a" category="list-text">查看并启动作业。</block>
  <block id="77281e34749b6599332dd1416b12f533" category="paragraph"><block ref="77281e34749b6599332dd1416b12f533" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d388d0f32172ebe7aea2c3eeae0dfc4" category="list-text">从*作业监控*选项卡监控克隆作业状态。</block>
  <block id="827b60b27e967d900114ade1f31eed53" category="paragraph"><block ref="827b60b27e967d900114ade1f31eed53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e0fb0a8b932b4f05d487ea8a5748901" category="list-text">验证EC2实例主机上的克隆数据库。</block>
  <block id="d139cf7562ab53c3922d5a0a6804786c" category="paragraph"><block ref="d139cf7562ab53c3922d5a0a6804786c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f12aeeed0f164c86af69a57fddb01689" category="list-text">设置和管理BlueXP</block>
  <block id="74e12c8bec754bf4a9feb44c8cada2dc" category="inline-link-macro"><block ref="74e12c8bec754bf4a9feb44c8cada2dc" category="inline-link-rx"></block></block>
  <block id="54d1b98b8cdfd12e2afc7f08278645ba" category="paragraph"><block ref="54d1b98b8cdfd12e2afc7f08278645ba" category="inline-link-macro-rx"></block></block>
  <block id="ed133d2d4bade971a41aae35897a0bd2" category="inline-link-macro"><block ref="ed133d2d4bade971a41aae35897a0bd2" category="inline-link-rx"></block></block>
  <block id="21af149e524c5f7a8eb5e23197309e60" category="paragraph"><block ref="21af149e524c5f7a8eb5e23197309e60" category="inline-link-macro-rx"></block></block>
  <block id="7e7efb7e7b278c5ce5253a775d1c8313" category="sidebar">在AWS FSX/EC2中自动部署PostgreSQL高可用性和灾难恢复</block>
  <block id="d36111f9de8e485ef98facff50b6fd6e" category="sidebar">使用iSCSI/ASM部署和保护Oracle数据库</block>
  <block id="5ed492cbbbf7e6d167035a7c10478daa" category="summary">采用NetApp HCI 的VMware最终用户计算是一种经过预先验证的最佳实践数据中心架构、可用于在企业级部署虚拟桌面工作负载。</block>
  <block id="b4a3c2c985fcfc0d0e59c8d9c3259eb0" category="doc">NVA-1129-Deploy：采用NetApp HCI 和NVIDIA GPU的VMware最终用户计算</block>
  <block id="8b3f1e47da9509d2edf2f21012c6ec7e" category="paragraph">采用NetApp HCI 的VMware最终用户计算是一种经过预先验证的最佳实践数据中心架构、用于在企业级部署虚拟桌面工作负载。本文档介绍如何以可靠且无风险的方式在生产环境中部署解决方案</block>
  <block id="ba999af3664a8f6c5b43a92bc11de64a" category="paragraph"><block ref="ba999af3664a8f6c5b43a92bc11de64a" category="inline-link-macro-rx"></block></block>
  <block id="85864e2699dfaceb7f8d1f85448939fe" category="doc">NVA-1132设计：采用NetApp HCI 的VMware最终用户计算</block>
  <block id="52940073ac3f539b3c6d9ac1e41d5f06" category="paragraph">采用NetApp HCI 的VMware最终用户计算是一种经过预先验证的最佳实践数据中心架构、可用于在企业级部署虚拟桌面工作负载。本文档介绍了可靠且无风险地在生产环境中部署解决方案 的架构设计和最佳实践。</block>
  <block id="8c40c45c2332a47a83ae257f42af2331" category="paragraph"><block ref="8c40c45c2332a47a83ae257f42af2331" category="inline-link-macro-rx"></block></block>
  <block id="cb4afc4348edbcbc0ddb144315301438" category="summary">查看FlexPod 设计指南、了解有关FlexPod 虚拟化解决方案的更多信息。</block>
  <block id="4de89e2522c54dd93e1f7435cd5845e9" category="doc">FlexPod 桌面虚拟化解决方案</block>
  <block id="99f9c871e415b6401535b222011ec217" category="inline-link-macro">FlexPod 设计指南</block>
  <block id="2de05ca96bfd006d0687e6e5b3edfcad" category="paragraph">要了解有关FlexPod 虚拟化解决方案的更多信息、请查看 <block ref="7464c5c011fed90b6d391ce107d84818" category="inline-link-macro-rx"></block></block>
  <block id="36f00397200c227ebfe56599e7bafcd5" category="doc">NVA-1129-design：采用NetApp HCI 和NVIDIA GPU的VMware最终用户计算</block>
  <block id="8a36e2f35bf4a10959caf61f15d8df63" category="paragraph"><block ref="8a36e2f35bf4a10959caf61f15d8df63" category="inline-link-macro-rx"></block></block>
  <block id="be493f1fc0b02ae45602c7c13f7b5dc7" category="summary">TR-4792为在由NVIDIA图形处理单元(GPU)和虚拟化软件提供支持的VMware Horizon环境中使用NetApp HCI 615C处理3D图形工作负载提供了指导。</block>
  <block id="ff1d278a485c443dc5d8fc9f10f1a702" category="doc">适用于采用VMware Horizon 7的虚拟桌面基础架构的NetApp HCI —为高级用户提供3D图形功能</block>
  <block id="e3162938e0d7b1bbc74111cc5b5871c5" category="paragraph">TR-4792提供了在由NVIDIA图形处理单元(GPU)和虚拟化软件提供支持的VMware Horizon环境中使用NetApp H615C计算节点处理3D图形工作负载的指导。此外、还提供了对H615C的SPECviewperf 13进行的初步测试的结果。</block>
  <block id="1de37c09602b46db5de57a946efe2768" category="paragraph"><block ref="1de37c09602b46db5de57a946efe2768" category="inline-link-macro-rx"></block></block>
  <block id="6e74710636e2da95cda4899adcdf891e" category="summary">数据在NFS中可用、并可从AWS SageMaker的S3访问。</block>
  <block id="8394db253ec71ed9d59b9429983b8eb4" category="doc">数据科学家和其他应用程序的数据双重性</block>
  <block id="f4900d1d4a0a26325c4c9514e57c2c75" category="paragraph">您需要使用NetApp BlueXP、NetApp Cloud Volumes ONTAP 和AWS SageMaker笔记本电脑作为数据双用用例。</block>
  <block id="6e6b6052efed2574e2dc05cbdc5d66d5" category="paragraph">下表列出了实施此用例所需的软件组件。</block>
  <block id="9b9477e579c3b44dd623d5a6e1ea8d78" category="cell">BlueXP</block>
  <block id="dda9f6d67571441afa5cfb6b54b70873" category="cell">AWS SageMaker笔记本电脑</block>
  <block id="cc5f7f3bee6dcb16913051d6fc267977" category="paragraph">部署数据双率解决方案 涉及以下任务：</block>
  <block id="6bb1f60bf0d00924a1bba54557e1feae" category="list-text">BlueXP连接器</block>
  <block id="cf25fa6cf104cc1a67119acb6d4d364d" category="list-text">用于机器学习的数据</block>
  <block id="5a1439989b12745b5a4ed4b944539247" category="list-text">AWS SageMaker</block>
  <block id="59b20c2117a395af59d54a6533498e99" category="list-text">通过Jupyter笔记本电脑经验证的机器学习</block>
  <block id="46e0bb4f28dbf5013a68a8a69a3cf9f5" category="section-title">BlueXP连接器</block>
  <block id="de3e31c5aaf9bdeca7bc072f649ddc2e" category="paragraph">在此验证中、我们使用了AWS。它也适用于Azure和Google Cloud。要在AWS中创建BlueXP Connector、请完成以下步骤：</block>
  <block id="4d7b48a5181bdd203b2ff52910c67d94" category="list-text">我们根据BlueXP中的mcarl-marketplace-subscription使用了这些凭据。</block>
  <block id="c0caffb5ab49caead75d39f6416ba841" category="list-text">选择适合您环境的区域(例如us-east-1 [N.Virginia)、然后选择身份验证方法(例如、假设角色或AWS密钥)。在此验证中、我们将使用AWS密钥。</block>
  <block id="86b72593a2ce2f4e46e7669ced916111" category="list-text">提供连接器的名称并创建角色。</block>
  <block id="71ffd00d3592df40d0db94a71ceab12d" category="list-text">根据您是否需要公共IP、提供VPC、子网或密钥对等网络详细信息。</block>
  <block id="b5b37cef840fa0a17af0ef55c09a0e1f" category="list-text">提供安全组的详细信息、例如从源类型访问HTTP、HTTPS或SSH、例如Anywhere和IP范围信息。</block>
  <block id="45b20434e20aeebd5991cd84f2cf11c9" category="list-text">查看并创建BlueXP Connector。</block>
  <block id="92043f8a1dc0b0180854c25bcf5ff79d" category="list-text">确认在AWS控制台中运行的是BlueXP EC2实例状态、然后从*网络连接*选项卡中检查IP地址。</block>
  <block id="7044ee6a43ee2152ca6d008fcb8228c3" category="list-text">从BlueXP门户登录到连接器用户界面、或者您也可以使用IP地址从浏览器进行访问。</block>
  <block id="064d933c0c02c4fe7ef1a07ad3a537d7" category="paragraph">要在BlueXP中创建Cloud Volumes ONTAP 实例、请完成以下步骤：</block>
  <block id="da6e487de6af8700c3cf58ffb20a876c" category="list-text">创建新的工作环境、选择云提供商、然后选择Cloud Volumes ONTAP 实例的类型(例如、适用于ONTAP 的单CVO、HA或Amazon FSxN)。</block>
  <block id="dcb89e397dde3dedb1a32224f0c15b78" category="list-text">提供Cloud Volumes ONTAP 集群名称和凭据等详细信息。在此验证中、我们创建了一个名为的Cloud Volumes ONTAP 实例<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block>。</block>
  <block id="9cf479af21359b2928a1b672d60577f2" category="list-text">选择Cloud Volumes ONTAP 所需的服务。在此验证中、我们选择仅监控、因此禁用了*数据感知与合规性*和*备份到云服务*。</block>
  <block id="cb95ef3838d59d553c71f50b1cadee27" category="list-text">在*位置和连接*部分中、选择AWS区域、VPC、子网、安全组、SSH身份验证方法、 以及密码或密钥对。</block>
  <block id="fdd5d37c21ee01084537317345b3d78b" category="list-text">选择充电方法。我们使用*专业版*进行此验证。</block>
  <block id="00efec60d606ea6ad0bafe93bc77df92" category="list-text">您可以选择预配置的软件包、例如* POC和小型工作负载*、*数据库和应用程序数据生产工作负载*、*经济高效的灾难恢复*或*最高性能生产工作负载*。在此验证中、我们选择了* POC和小型工作负载*。</block>
  <block id="f22934293c2f2a761ea26fa4ae1828e1" category="list-text">创建具有特定大小、允许的协议和导出选项的卷。在此验证中、我们创建了一个名为的卷<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block>。</block>
  <block id="f2706214c4a60177d14fb8495cbc6924" category="list-text">选择配置文件磁盘类型和分层策略。在此验证中、我们禁用了*存储效率*和*通用SSD–动态性能*。</block>
  <block id="40d3f73a73f67ce67b286aef7a5d3ecb" category="list-text">最后、查看并创建Cloud Volumes ONTAP 实例。然后等待15到20分钟、让BlueXP创建Cloud Volumes ONTAP 工作环境。</block>
  <block id="a8b538b74c3f662c2248af9c6d4742db" category="list-text">配置以下参数以启用双率协议。ONTAP 9支持双度协议(NFS/S3)。12：1及更高版本。</block>
  <block id="15b53c14b58ee146309847451d1eb90a" category="list-text">在此验证中、我们创建了一个名为的SVM<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> 和卷<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block>。</block>
  <block id="3514969b2381af83551c246e34b74403" category="list-text">验证SVM是否支持NFS和S3协议。如果不支持、请修改SVM以支持它们。</block>
  <block id="e41c06ffff0f8c9cadbc7f8bb37f8ae5" category="list-text">根据需要创建并安装CA证书。</block>
  <block id="0395f8062a8a7f4af05113bae8133737" category="list-text">创建服务数据策略。</block>
  <block id="6e16e110899749a795fe713253d850e7" category="list-text">检查聚合详细信息。</block>
  <block id="5d3f8e127103f0d5cf3de305db892b4d" category="list-text">创建用户和组。</block>
  <block id="efa22127bde2d3ab2e4f5b9a42d14814" category="list-text">在NFS卷上创建存储分段。</block>
  <block id="c3fd6f44bf88d3f0eae4742edb58eafc" category="paragraph">要从AWS SageMaker创建AWS笔记本电脑、请完成以下步骤：</block>
  <block id="31378aab1ee6190e0b7fe33c501a5625" category="list-text">确保正在创建笔记本实例的用户具有AmazonSageMakerFullAccess IAM策略或属于具有AmazonSageMakerFullAccess权限的现有组。在此验证中、用户属于现有组。</block>
  <block id="13c1455885d16af64f1bb96c4e48680a" category="list-text">请提供以下信息：</block>
  <block id="bb8101aed18120fa18dedaa994ffeea0" category="list-text">笔记本实例名称。</block>
  <block id="6239d232142a089e53e7a13fa721237a" category="list-text">实例类型。</block>
  <block id="37056dac7373f7e1b74382036d25b69e" category="list-text">平台标识符。</block>
  <block id="38e2059c32c628cf89e90a6844a93800" category="list-text">选择具有AmazonSageMakerFullAccess权限的IAM角色。</block>
  <block id="55d7da5ede713135b1c2ebd7a615c3b4" category="list-text">root访问—启用。</block>
  <block id="8f0e92e4434abc32ff62a914ae9f2ba6" category="list-text">加密密钥-不选择自定义加密。</block>
  <block id="8b77028d248afd826900d895636b4e98" category="list-text">保留其余默认选项。</block>
  <block id="78456ee20793f732edfa9105bbb4e490" category="list-text">在此验证中、SageMaker实例详细信息如下所示：</block>
  <block id="e90e797343ea3f751b0c32e808edaff8" category="inline-image-macro">描述步骤的屏幕截图。</block>
  <block id="07d5be91bebaccd4767fcceff99f3dde" category="paragraph"><block ref="07d5be91bebaccd4767fcceff99f3dde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69e41ee119a70fc66edf204cbcf365b1" category="paragraph"><block ref="69e41ee119a70fc66edf204cbcf365b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4789a9ab6472480889e111503d068623" category="list-text">启动AWS笔记本电脑。</block>
  <block id="faf1aea43a6d3bd1af488b8baa828561" category="paragraph"><block ref="faf1aea43a6d3bd1af488b8baa828561" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfbebd805ee7945ad38bc26f8fa9f1b" category="list-text">打开Jupyter实验室。</block>
  <block id="bcca330921c0ce477877bc982c12a6fb" category="paragraph"><block ref="bcca330921c0ce477877bc982c12a6fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab3269ab0de58f5611205f6ace06f3af" category="list-text">登录到终端并挂载Cloud Volumes ONTAP 卷。</block>
  <block id="cc0649b0871fde24c4a46e09186a36e0" category="list-text">使用AWS命令行界面命令检查在Cloud Volumes ONTAP 卷上创建的存储分段。</block>
  <block id="4f31ff9815d3a8a959e7c557213068d6" category="paragraph">在此次验证中、我们使用了一个来自大众社区的DBipedia的数据集、从各种Wikimedia项目中创建的信息中提取结构化内容。</block>
  <block id="06d6ccf33b49ed20a34cdc26b6820253" category="list-text">从DBipedia GitHub位置下载数据并提取数据。请使用上一节中使用的相同终端。</block>
  <block id="7f50b7f719282741fdf7ce5b8ca1f3dd" category="list-text">将数据复制到Cloud Volumes ONTAP 位置、并使用AWS命令行界面从S3存储分段中进行检查。</block>
  <block id="0ecfbac978ab3f5979ec31eb5574d93e" category="list-text">执行基本验证以确保读取/写入功能在S3存储分段上正常工作。</block>
  <block id="877169a066e14f0512d5f119945ef14d" category="section-title">验证从Jupyter笔记本电脑学习机器的情况</block>
  <block id="6f73420916237ed836932ccf967d82ba" category="paragraph">以下验证使用以下SageMaker BlazingText示例、通过文本分类提供机器学习构建、培训和部署模型：</block>
  <block id="3cf03767e04159d1ec88e7fb0827b487" category="list-text">安装boto3和SageMaker软件包。</block>
  <block id="b1282d58a4dcde0a2015d98ad33afd4c" category="paragraph">输出：</block>
  <block id="39017441ac701ebaef8de7116e7f71a0" category="list-text">在以下步骤中、将显示数据 <block ref="0a726fdd06082d233cd4eade40f12612" prefix="(" category="inline-code"></block>)下载<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> 机器学习中使用的Jupyter笔记本实例。</block>
  <block id="a270350e3527fea9a36815fa5fe04ba0" category="list-text">以下代码将创建从整数索引到类标签的映射、用于在推理期间检索实际类名称。</block>
  <block id="d17fa3d0aed3f8aaa5e78b447054126d" category="paragraph">输出将列出中的文件和文件夹<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> 用于AWS SageMaker机器学习验证的数据分段。</block>
  <block id="0cfbf64679378e3e5367734fd2bd69aa" category="list-text">启动数据预处理阶段、将训练数据预处理为空格分隔的令牌化文本格式、BlazingText算法和Nultk库可以使用该格式来标记DBPedia数据集的输入语句。下载nltk令牌程序和其他库。。<block ref="6d49a792c1080aa5b33d27ec694621b6" prefix=" " category="inline-code"></block> 并行应用于每个数据实例时、会使用Python多处理模块。</block>
  <block id="d68566815a7248bae03e105c2db8853a" category="list-text">将格式化的训练数据集上传到S3、以便SageMaker可以使用它来执行训练作业。然后、使用Python SDK将两个文件上传到存储分段和前缀位置。</block>
  <block id="bc41af112e1f02120a4a6e16f34767ef" category="list-text">在S3上设置加载模型项目的输出位置、以便项目可以作为算法训练作业的输出。创建<block ref="6e3281884db83f9ee468a6e798b6bdfb" prefix=" " category="inline-code"></block> 用于启动培训作业的对象。</block>
  <block id="41215e143c2b3810b37c4e4f47819077" category="list-text">定义SageMaker<block ref="a0b1f5f7b93af313b6e2452f52c8f3f6" prefix=" " category="inline-code"></block> 通过资源配置和超参数、在c4.4xlarge实例上使用受监控模式在DBPedia数据集上训练文本分类。</block>
  <block id="6c773c4d6e4a7dda7e00352894786bdb" category="list-text">准备数据通道和算法之间的握手。为此、请创建<block ref="0e021845d2c0e4ad94a91ce444c13681" prefix=" " category="inline-code"></block> 数据通道中的对象、并将其保留在词典中、以供算法使用。</block>
  <block id="3b29bef19a742b8ab66cddf620871d31" category="list-text">作业完成后、将显示作业完成消息。您可以在设置为的S3存储分段中找到经过培训的型号<block ref="212ad7a4c11069727ffd02f333d7d8b1" prefix=" " category="inline-code"></block> 在估算器中。</block>
  <block id="6cb5683d87e53b375bd915572f960759" category="list-text">培训完成后、将经过培训的模型部署为Amazon SageMaker实时托管端点、以进行预测。</block>
  <block id="4254a612097ca58653de7c0c39da8df2" category="list-text">默认情况下、模型返回一个概率最高的预测。以检索顶部<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> 预测、设置<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> 在配置文件中。</block>
  <block id="67be4f1bb90039baec0d8f73ff82a47e" category="list-text">请先删除端点、然后再关闭此笔记本。</block>
  <block id="7caace9abf76a798c629a9134d1bb259" category="summary">NFS和S3的双协议访问的一个潜在用例是机器学习和数据科学领域。例如、数据科学家团队可能正在使用AWS SageMaker执行机器学习项目、该项目要求访问以NFS格式存储的数据。但是、可能还需要通过S3存储分段访问和共享数据、以便与其他团队成员协作或与使用S3的其他应用程序集成。</block>
  <block id="ee8cf3bf54dea46135e299d79fa1c179" category="paragraph">此解决方案 利用以下技术：</block>
  <block id="a03ea23912d3b35c875ff398aa4888af" category="list-text">* AWS SageMaker Notebook.*为开发人员和数据科学家提供机器学习功能、帮助他们高效地创建、训练和部署高质量的ML模型。</block>
  <block id="bbe2552dc6295d353c02fd85c243f334" category="list-text">* NetApp BlueXp。*支持发现、部署和操作内部以及AWS、Azure和Google Cloud上的存储。它可以防止数据丢失、网络威胁和计划外中断、并优化数据存储和基础架构。</block>
  <block id="aa6fa71ab9848c5875470d36bbc2138a" category="list-text">* NetApp Cloud Volumes ONTAP。*在AWS、Azure和Google Cloud上提供采用NFS、SMB/CIFS、iSCSI和S3协议的企业级存储卷、使用户可以更灵活地访问和管理云中的数据。</block>
  <block id="eea496572a01ca3e5ced1dfe99a5809c" category="paragraph">NetApp Cloud Volumes ONTAP 是从BlueXP创建的、用于存储ML数据。</block>
  <block id="923baf107dc23ca10f968a4fdecd4f4f" category="paragraph">下图显示了解决方案的技术组件。</block>
  <block id="8afbfe3aeb9c594404d5c244cf8f6024" category="inline-image-macro">此图显示了解决方案 的技术组件。</block>
  <block id="eaf4eb821a18e60305e45cf9cce407dd" category="paragraph"><block ref="eaf4eb821a18e60305e45cf9cce407dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55c5281d80934f950192f768715495f0" category="paragraph">通过使用NetApp Cloud Volumes ONTAP 、该团队可以将数据存储在一个位置、并可通过NFS和S3协议访问这些数据。数据科学家可以直接从AWS SageMaker访问NFS格式的数据、而其他团队成员或应用程序则可以通过S3存储分段访问相同的数据。</block>
  <block id="f8ba1b513231e9ca54a5c3b94733c28d" category="paragraph">这种方法可以轻松高效地访问和共享数据、而无需在不同的存储解决方案之间进行额外的软件或数据迁移。此外、它还可以简化工作流并在团队成员之间进行协作、从而更快、更有效地开发机器学习模型。</block>
  <block id="16147684eb6910d9d73a43bb83091da4" category="summary">数据科学家和工程师通常需要访问以NFS格式存储的数据、但在AWS SageMaker中直接从S3协议访问此数据可能会面临挑战、因为AWS仅支持S3存储分段访问。但是、NetApp ONTAP 通过为NFS和S3启用双协议访问来提供解决方案。借助此解决方案 、数据科学家和工程师可以通过NetApp Cloud Volumes ONTAP 的S3存储分段从AWS SageMaker笔记本电脑访问NFS数据。这种方法可以轻松地从NFS和S3访问和共享相同的数据、而无需额外的软件。</block>
  <block id="e8ce8afdd7d335aed5b93d4a41ae0115" category="doc">TR-4967：《使用NetApp文件对象双处理和AWS SageMaker进行云数据管理》</block>
  <block id="af7ba099603ccd4070a5102166f2c998" category="summary">根据此验证、数据科学家和工程师可以通过NetApp Cloud Volumes ONTAP 的S3存储分段从AWS SageMaker Jupyter笔记本电脑访问NFS数据。这种方法可以轻松地从NFS和S3访问和共享相同的数据、而无需额外的软件。</block>
  <block id="8053f00cf5e08f449b7cafe189c73a39" category="list-text">使用SageMaker BlazingText进行文本分类</block>
  <block id="7fba377195a6600e8ac2b2d5a433e7d3" category="inline-link"><block ref="7fba377195a6600e8ac2b2d5a433e7d3" category="inline-link-rx"></block></block>
  <block id="d8908a1e1cf55570441dd5a42baadacc" category="paragraph"><block ref="d8908a1e1cf55570441dd5a42baadacc" category="inline-link-rx"></block></block>
  <block id="d6667429b7c60bcbf5e5d593e91d6cae" category="list-text">S3 对象存储的 ONTAP 版本支持</block>
  <block id="91ef54d96688b56bf968f57803df6675" category="inline-link"><block ref="91ef54d96688b56bf968f57803df6675" category="inline-link-rx"></block></block>
  <block id="53a581d907d105a589be9419e91b16fa" category="paragraph"><block ref="53a581d907d105a589be9419e91b16fa" category="inline-link-rx"></block></block>
  <block id="1d2114df6a9f8f5d7e8f597e9c70a6c1" category="sidebar">借助NetApp文件对象双处理能力和AWS SageMaker实现云数据管理</block>
  <block id="74ed7031eb75ffbb784ebe9ffbd6be6a" category="cell">更新了博客《使用AWS Lambda/Function进行ONTAP 监控和自动调整大小FSx》、其中提供了私有/公共部署选项以及手动/自动部署选项。</block>
  <block id="2ab02c4627e2022ecdf98de0e3b6b18d" category="cell">添加了博客：FSx for ONTAP 监控和使用AWS Lambda-Function自动调整大小</block>
  <block id="8e8aff933e5047a57263663f8a18e3c3" category="list-text">能够定期监控检查</block>
  <block id="e2b4916d6d7f53cde2d5633fd6119cc4" category="list-text">可以使用解决方案 访问互联网、也可以不访问互联网</block>
  <block id="a90d7c3c15ad351b936f52283c3587ef" category="list-text">可以手动部署或使用AWS CloudFormation模板进行部署</block>
  <block id="1526ea467258021d67f8f59298e57f70" category="list-text">连接到FSx for ONTAP 的专用子网</block>
  <block id="5215f5ee52e78e416520bfecaf294472" category="paragraph">按照一系列步骤完成此解决方案 的自动部署：</block>
  <block id="6436b05fc0216b37135d2a66a585e96f" category="example-title">第2步：设置AWS S3存储分段</block>
  <block id="7d54d293b4849834117fc9160feb6cbc" category="list-text">导航到AWS控制台&gt;*。s3*并单击*创建存储分段*。使用默认设置创建存储分段。</block>
  <block id="66b09b43432fbb9814d51e48e9a98ade" category="inline-image-macro">此图显示了正在上传zip文件的S3窗口</block>
  <block id="0f71a8c9bb8a785323461956bf9e217a" category="paragraph"><block ref="0f71a8c9bb8a785323461956bf9e217a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ea6ef5eae0a05760ec8bf19495d8645" category="example-title">第3步：AWS SES SMTP设置(如果无法访问Internet、则需要此设置)</block>
  <block id="972167638becf55a9af0b4e5c414a75e" category="list-text">导航到AWS控制台&gt;*AWS Simple Email Service (SES)*&gt; SMTP Settings，然后单击*Create SMTP crederations*</block>
  <block id="68d59bd0e9b2839f0843ab1b2d6b136f" category="list-text">输入IAM用户名或将其保留为默认值、然后单击创建。保存用户名和密码以供将来使用。</block>
  <block id="796d9a158268a6ea8a7895c4fc08b2f7" category="admonition">如果SES SMTP设置已到位、请跳过此步骤。</block>
  <block id="c492e5ad14c10d85050111f49b9ccd32" category="inline-image-macro">此图显示了AWS SES下的创建SMTP凭据窗口</block>
  <block id="311486bd300a1e6b104a8c2d1edc4b1d" category="paragraph"><block ref="311486bd300a1e6b104a8c2d1edc4b1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53f52a194e6b0e83b281c128d8c9536d" category="example-title">第4步：AWS CloudFormation部署</block>
  <block id="d2edefb4d7f05ffadcc2ce87ffde5e98" category="list-text">导航到AWS控制台&gt;* CloudFormation*&gt;创建堆栈&gt;使用新资源(标准)。</block>
  <block id="f9555c9e4ee9872bd73e1554f90b137c" category="inline-image-macro">此图显示了AWS CloudFormation创建堆栈窗口</block>
  <block id="302a433b27874ed6225d3a3553f31fdb" category="paragraph"><block ref="302a433b27874ed6225d3a3553f31fdb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a65108ded0e706a6c44742b2f313e4e" category="paragraph">单击下一步</block>
  <block id="ef7b077619d0583a71ba9fda28bc53fc" category="list-text">输入堆栈详细信息。单击Next、选中I Accloned that AWS CloudFormation m赡 会创建IAM资源复选框、然后单击Submit。</block>
  <block id="1b61f2cbcfae90671dbb048e72bb8918" category="admonition">如果"VPC是否可访问互联网？" 设置为False、需要提供"AWS SES的SMTP用户名"和"AWS SES的SMTP密码"。否则、可以将其留空。</block>
  <block id="1f5aede37b8170af3cfbd901f22d591e" category="inline-image-macro">此图显示了AWS CloudFormation堆栈详细信息窗口</block>
  <block id="7e2652655cc5cfead2ca4bff65032215" category="paragraph"><block ref="7e2652655cc5cfead2ca4bff65032215" category="inline-image-macro-rx" type="image"></block></block>
  <block id="113624fc80b505576882228d73fc03c5" category="paragraph"><block ref="113624fc80b505576882228d73fc03c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13069c8f4182a2f6ab810369ebe8b0ad" category="paragraph"><block ref="13069c8f4182a2f6ab810369ebe8b0ad" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd90b3549ddb2a170121e2cae9d2e442" category="paragraph"><block ref="bd90b3549ddb2a170121e2cae9d2e442" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d22d74b4244b97ca549876dbaf6e5906" category="list-text">CloudFormation堆栈部署完成后、如果出现任何警告/通知、系统将向收件人电子邮件ID发送一封电子邮件、其中包含通知详细信息。</block>
  <block id="bb44dcc303804fcbbf13971e05b223b4" category="inline-image-macro">此图显示了通知可用时收到的电子邮件通知</block>
  <block id="80b7092ae7ee31bafccb6f27ea2a5603" category="paragraph"><block ref="80b7092ae7ee31bafccb6f27ea2a5603" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e482488f8434036ccb78ddb9cea595f" category="paragraph"><block ref="5e482488f8434036ccb78ddb9cea595f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ae845e97e60673c293edce9fe3a65f9" category="section-title">手动部署</block>
  <block id="d4f4ecbc346d14b30240c605c5884282" category="paragraph">按照一系列步骤完成此解决方案 的手动部署：</block>
  <block id="c960dffe03501c470f4219bb16fab5ef" category="example-title">第2步：AWS SES SMTP设置(如果无法访问Internet、则需要此设置)</block>
  <block id="0aa7c69c57f475cc1f055c49b0e3136e" category="example-title">第3步：为fsxadmin密码创建SSM参数</block>
  <block id="8a7ca52152a916f189b032d05768ed10" category="paragraph">如果在不访问Internet的情况下部署解决方案 、则执行相同的步骤来存储SMTP用户名和SMTP密码。否则、跳过添加这2个参数。</block>
  <block id="06e0a02f6ce962b7038b6b2918585271" category="example-title">第4步：设置电子邮件服务</block>
  <block id="71bb5fff33b1866d7266866fb9c94f45" category="list-text">导航到AWS控制台&gt;* VPC*&gt;*端点*并单击*创建端点*并输入以下详细信息：</block>
  <block id="6683864f2c9e5bbb1fa4128837ed8eab" category="paragraph">单击创建端点。</block>
  <block id="5f80bfe9763fe273a3a7722c1c647604" category="inline-image-macro">此图显示了VPC端点创建窗口</block>
  <block id="9a4cd1bb8a39a7c230290453794b4429" category="paragraph"><block ref="9a4cd1bb8a39a7c230290453794b4429" category="inline-image-macro-rx" type="image"></block></block>
  <block id="603ef5b528d0bd1def7291cf6417ff56" category="paragraph"><block ref="603ef5b528d0bd1def7291cf6417ff56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a07090d2d501e8e696338339ab098115" category="example-title">第6步：创建和设置AWS Lamb编制 函数</block>
  <block id="785e900d8ea09cab57830ac6967cb709" category="cell">*internet_access*</block>
  <block id="24498a6850ca31bfb18f639aae517582" category="cell">(必需)如果部署了此兰德的子网可以访问Internet、请将此变量设置为True。否则、请将其设置为False。</block>
  <block id="cd9e7c04a0bb02c275868aa4344613da" category="cell">*SMT_REARAY*</block>
  <block id="4a892fb521dc4ec57f770f02637e0d0d" category="cell">(可选)如果"internet_access"变量设置为False、请输入部署了兰德的区域。例如us-east-1 (采用此格式)</block>
  <block id="07dba5c28924867968d12040d14d8b57" category="cell">*SMT_USERNAME_SSM_Parameter*</block>
  <block id="611e6e1c3920f2514daecc54ecfb79d1" category="cell">(可选)如果"internet_access"变量设置为False、请输入AWS参数存储中用于存储SMTP用户名的路径名称。</block>
  <block id="00dc34bddd9d78c3a39608fed34bb12c" category="cell">*SMT_password_SSM_parameter*</block>
  <block id="7d7fbea26b1aa16fe546b51310bfd752" category="cell">(可选)如果"internet_access"变量设置为False、请输入AWS参数存储中用于存储SMTP密码的路径名称。</block>
  <block id="675f82a779038c3f679b04bc0aadca1a" category="list-text">将以下内容粘贴到终端中</block>
  <block id="56ee829a33ac57c3b6d427e35b3b2e86" category="list-text">将以下内容粘贴到终端中</block>
  <block id="8650b39d5e09def4c11e24f034a41e67" category="doc">TR-4955：《使用Azure NetApp Files (ANF)和Azure VMware解决方案 (AVS)进行灾难恢复》</block>
  <block id="899cca084f1a1bf69adac32c1398adb6" category="paragraph">作者：Jsh Powell—NetApp解决方案工程部</block>
  <block id="227cecf5e7044ae569299b6dacc2a687" category="paragraph">Veeam Backup &amp; Replication是一款高效可靠的解决方案 、用于保护VMware Cloud中的数据。此解决方案 演示了使用Veeam备份和复制在VMware Cloud中备份和还原FSx for ONTAP NFS数据存储库上的应用程序VM的正确设置和配置。</block>
  <block id="c4b912446bf11dcde10ac980b8819578" category="paragraph">VMware Cloud (在AWS中)支持使用NFS数据存储库作为补充存储、而FSx for NetApp ONTAP 是一款安全解决方案 、适用于需要为云应用程序存储大量数据的客户、该数据存储库可以独立于SDDC集群中的ESXi主机数量进行扩展。这项集成的AWS存储服务可提供具有所有传统NetApp ONTAP 功能的高效存储。</block>
  <block id="75043beff1323591f4f4edb731c5ce37" category="list-text">使用FSx for NetApp ONTAP 作为备份存储库、备份和还原VMC中托管的Windows和Linux虚拟机。</block>
  <block id="575860316b82ab24561ab5cd41209029" category="list-text">使用FSx for NetApp ONTAP 作为备份存储库来备份和还原Microsoft SQL Server应用程序数据。</block>
  <block id="014dac3ed531510f50fc4dcf086101bd" category="list-text">使用FSx for NetApp ONTAP 作为备份存储库来备份和还原Oracle应用程序数据。</block>
  <block id="1a160f6d5e4c0f03da493f0b6d7548ff" category="section-title">使用Amazon FSx for ONTAP 的NFS数据存储库</block>
  <block id="36b4e7f3463e2ead8679ebc34829ef59" category="paragraph">此解决方案 中的所有虚拟机都位于FSx上、用于ONTAP 补充NFS数据存储库。使用FSx for ONTAP 作为补充NFS数据存储库具有若干优势。例如、它允许您：</block>
  <block id="c40ee4ce6dfe0563d18cf384ace88765" category="list-text">在云中创建可扩展且高度可用的文件系统、而无需复杂的设置和管理。</block>
  <block id="e745aa1d0e918c96cea168491895d6fb" category="list-text">与现有VMware环境集成、支持您使用熟悉的工具和流程来管理云资源。</block>
  <block id="43cd0f845dc959949e9ac1e3a35e45bf" category="list-text">利用ONTAP 提供的高级数据管理功能(例如快照和复制)保护数据并确保其可用性。</block>
  <block id="9b6e4c8a49f0160a14314bd62bfe0a69" category="paragraph">此列表简要介绍了配置Veeam备份和复制、使用FSx for ONTAP 作为备份存储库执行备份和还原作业以及还原SQL Server和Oracle VM和数据库所需的步骤：</block>
  <block id="e871c13ae67a9af23b556e907002fa12" category="list-text">创建FSx for ONTAP 文件系统、用作Veeam Backup &amp; Replication的iSCSI备份存储库。</block>
  <block id="989dd576e8b1eb03cbf28639a2931613" category="list-text">部署Veeam代理以分布备份工作负载并挂载FSx for ONTAP 上托管的iSCSI备份存储库。</block>
  <block id="b60278b7e91394afcc745ae75fa44aa4" category="list-text">配置Veeam备份作业以备份SQL Server、Oracle、Linux和Windows虚拟机。</block>
  <block id="1b245e740482771d5d3992478a82d724" category="list-text">还原SQL Server虚拟机和各个数据库。</block>
  <block id="13cd489b0849b840f8ab36d74b8293ec" category="list-text">还原Oracle虚拟机和各个数据库。</block>
  <block id="a7170e8fda73e91fa62b13d3622ef444" category="paragraph">本解决方案 的目的是演示在VMware Cloud中运行的虚拟机以及由FSx for NetApp ONTAP 托管的NFS数据存储库中的虚拟机的数据保护。此解决方案 假定已配置以下组件并可供使用：</block>
  <block id="307f5c37781c29657edae5fb925162a2" category="list-text">一个或多个NFS数据存储库连接到VMware Cloud的FSx for ONTAP 文件系统。</block>
  <block id="f868183ec79787eaaf74ea89a47669dc" category="list-text">安装了Veeam Backup &amp; Replication软件的Microsoft Windows Server VM。</block>
  <block id="5736f2ed579d3ef6cf3f20fb689ab01e" category="list-text">Veeam Backup &amp; Replication服务器已使用其IP地址或完全限定域名发现vCenter Server。</block>
  <block id="331f1124497c0ac124ff038480809c69" category="list-text">在解决方案 部署期间、要与Veeam备份代理组件一起安装的Microsoft Windows Server VM。</block>
  <block id="3a3f8abc64509c161ec11b01ef580eb2" category="list-text">VMDK和应用程序数据驻留在FSx for ONTAP NFS数据存储库上的Microsoft SQL Server VM。对于此解决方案 、我们在两个单独的VMDK上有两个SQL数据库。</block>
  <block id="8dfe3f043b3df38e0413e36fbd24db7f" category="list-text">注意：作为最佳实践、数据库和事务日志文件应放置在单独的驱动器上、因为这样可以提高性能和可靠性。这部分是由于事务日志是按顺序写入的、而数据库文件是随机写入的。</block>
  <block id="8be960cd9539642d1747f77549b61640" category="list-text">包含VMDK和应用程序数据的Oracle数据库VM驻留在FSx上、用于ONTAP NFS数据存储库。</block>
  <block id="1a181903b99cf17676f681159276eb0f" category="list-text">VMDK驻留在FSx上的Linux和Windows文件服务器VM、用于ONTAP NFS数据存储库。</block>
  <block id="363652c12cab9d20a25160a8429e6749" category="inline-link">适用于VMware vSphere的Veeam备份和复制用户指南</block>
  <block id="ef67d6716f36cc4d904840c87baf49e8" category="list-text">Veeam需要使用特定的TCP端口在备份环境中的服务器和组件之间进行通信。在Veeam备份基础架构组件上、系统会自动创建所需的防火墙规则。有关网络端口要求的完整列表、请参阅的端口部分<block ref="a201e119e9bf364010037d27795ac7b3" category="inline-link-rx"></block>。</block>
  <block id="35d6eccff0f72c28cfe3309ffa950add" category="paragraph">本解决方案 的目的是演示在VMware Cloud中运行的虚拟机以及由FSx for NetApp ONTAP 托管的NFS数据存储库中的虚拟机的数据保护。此解决方案 假定已配置以下组件并可供使用：</block>
  <block id="2296042ba6aa3359318593608ca0345d" category="list-text">Microsoft Windows VM位于FSx for ONTAP NFS数据存储库上</block>
  <block id="c6d1f5be073c9cd0daaf474564f8467c" category="list-text">Linux (CentOS) VM位于FSx for ONTAP NFS数据存储库上</block>
  <block id="b3320f54be7deb0784e4a01661688928" category="list-text">Microsoft SQL Server VM位于FSx for ONTAP NFS数据存储库上</block>
  <block id="4adae5f55535a5ee71371da1efc9ca6d" category="list-text">两个数据库托管在不同的VMDK上</block>
  <block id="8722af64f7207084921888f7b8dc2619" category="list-text">Oracle VM位于FSx for ONTAP NFS数据存储库上</block>
  <block id="ab74fd995780c1e0c54a3d450fdc334f" category="paragraph">在本解决方案 中、我们详细说明了如何使用Veeam备份和复制软件部署和验证解决方案 、以便在AWS上的VMware Cloud SDDC中对SQL Server、Oracle以及Windows和Linux文件服务器虚拟机执行备份和恢复。此解决方案 中的虚拟机位于FSx for ONTAP 托管的补充NFS数据存储库中。此外、还会使用一个单独的FSx for ONTAP 文件系统来托管要用于Veeam备份存储库的iSCSI卷。</block>
  <block id="1d11ec5b678e358544414cea998244f1" category="paragraph">我们将通过FSx创建ONTAP 文件系统、挂载要用作备份存储库的iSCSI卷、创建和运行备份作业以及执行VM和数据库还原。</block>
  <block id="f5fadf616d77899c034abd76a2af86c2" category="inline-link">FSx for ONTAP 用户指南</block>
  <block id="5a7878288054d2ea7843552720ab553e" category="paragraph">有关FSx for NetApp ONTAP 的详细信息、请参见<block ref="3c0b139db5fd16e7a1648aeb8ddd690b" category="inline-link-rx"></block>。</block>
  <block id="392249183bc4f33aaba419554722c65a" category="paragraph">有关Veeam备份和复制的详细信息、请参见<block ref="83de5255f1620c94ccf67b2665aee6d6" category="inline-link-rx"></block> 站点</block>
  <block id="f8de66c023a023128fae72baff4768e8" category="inline-link">基于AWS的VMware Cloud和基于Dell EMC支持的VMware Cloud。注意事项和限制</block>
  <block id="01956504f12da2e314d3cbcbcae47df8" category="paragraph">有关将Veeam Backup and Replication与VMware Cloud on AWS结合使用时的注意事项和限制、请参见<block ref="4e47976d7d0e280800947db2b44c65e3" category="inline-link-rx"></block>。</block>
  <block id="6ed4923c81194d5cd4fe3073f7f77b05" category="section-title">部署Veeam代理服务器</block>
  <block id="c7da1d365711815b85fa18bc74f530d0" category="paragraph">Veeam代理服务器是Veeam Backup &amp; Replication软件的一个组件、充当源与备份或复制目标之间的中介。代理服务器通过在本地处理数据来帮助优化和加速备份作业期间的数据传输、并且可以使用不同的传输模式通过VMware vStorage API进行数据保护或通过直接存储访问来访问数据。</block>
  <block id="8f061a3a51bbd5c953777928783cb5a8" category="paragraph">在选择Veeam代理服务器设计时、请务必考虑并发任务的数量以及所需的传输模式或存储访问类型。</block>
  <block id="9a2d7db98a8dc31fcc50b3e57a8fe217" category="inline-link">Veeam VMware vSphere最佳实践指南</block>
  <block id="e204b26976814adc33c2b02aff3edb3d" category="paragraph">有关代理服务器数量的规模估算及其系统要求、请参见<block ref="c614dc8f78d8f8492061379ec6b8259d" category="inline-link-rx"></block>。</block>
  <block id="1da132279065b63629529e4a20b86a40" category="paragraph">Veeam Data Mover是Veeam代理服务器的一个组件、它利用传输模式从源获取VM数据并将其传输到目标。传输模式是在配置备份作业期间指定的。通过使用直接存储访问、可以提高从NFS数据存储库备份的效率。</block>
  <block id="6056e2661738180a6bfcef495f66a14c" category="paragraph">有关运输模式的详细信息、请参阅<block ref="6493e4830783387b4fb12861d9b0db3d" category="inline-link-rx"></block>。</block>
  <block id="4f3a320d9cc1654fb192fa3ef09e777d" category="paragraph">在下面的步骤中、我们将介绍如何在VMware Cloud SDDC中的Windows VM上部署Veeam代理服务器。</block>
  <block id="c38e42cbd3153669c49509cb5921ef27" category="example-title">部署Veeam代理以分布备份工作负载</block>
  <block id="6c805e2bd591e34c8b2c7b40ce3ae66c" category="paragraph">在此步骤中、Veeam代理将部署到现有Windows VM。这样便可在主Veeam备份服务器和Veeam代理之间分布备份作业。</block>
  <block id="9d4fc0a95b3ccfd4aa30cfdd72dabd57" category="list-text">在Veeam Backup and Replication服务器上、打开管理控制台并选择左下方菜单中的*备份基础架构*。</block>
  <block id="40244b4ec6aa1e9698b8539fe85f2496" category="list-text">右键单击*备份代理*，然后单击*添加VMware备份代理...*以打开向导。</block>
  <block id="7436617703d50f796dbea213fcf40927" category="image-alt">打开添加Veeam备份代理向导</block>
  <block id="5bbbf82976c13ef8e6e1a11e418b2c5b" category="list-text">在*Add VMware Proxy*向导中，单击*Add New...*按钮以添加新的代理服务器。</block>
  <block id="78666bc2e843e9cef4d24aefc5a57856" category="image-alt">选择以添加新服务器</block>
  <block id="b3dd2563d84571dcc5398bd076e4521e" category="list-text">选择以添加Microsoft Windows、然后按照提示添加服务器：</block>
  <block id="7024d72957ee528cd2aa6a4d4c3d7adb" category="list-text">填写DNS名称或IP地址</block>
  <block id="a8efba444dcd5af95bbb5c5b3817a600" category="list-text">选择要用于新系统上的凭据的帐户或添加新凭据</block>
  <block id="a191caed54c4b1c1063d3b9968aef212" category="list-text">查看要安装的组件，然后单击*Apply*开始部署</block>
  <block id="bd5b42eeb98d5eb2694cb6f0f4d108b1" category="image-alt">填写添加新服务器的提示</block>
  <block id="50067741ebd921230d3dbab184bf075e" category="list-text">返回“*新建VMware代理*”向导，选择传输模式。在本例中，我们选择了*自动选择*。</block>
  <block id="9185b2ae21b13d792b77c630bcacd8b5" category="image-alt">选择传输模式</block>
  <block id="d9aa13b7d3b607b0cfa63839ed5459bc" category="list-text">选择希望VMware代理直接访问的已连接数据存储库。</block>
  <block id="07aea82b8f0e111675ae303b4a9efb09" category="image-alt">为VMware代理选择一个服务器</block>
  <block id="4eafd51f0a87b847a7d38cd8f86c0b0a" category="image-alt">选择要访问的数据存储库</block>
  <block id="e983b249a5363ad45edfeec5ed46dfff" category="list-text">根据需要配置和应用任何特定网络流量规则、例如加密或限制。完成后，单击*Apply*按钮完成部署。</block>
  <block id="3ab7229eb48fbece0f1af78a35a3bb94" category="image-alt">配置网络流量规则</block>
  <block id="185ecac0c5555658a5a82a00b0d2ddb4" category="section-title">配置存储和备份存储库</block>
  <block id="d739ffc348078951ba9d7b0cb18da383" category="paragraph">主Veeam备份服务器和Veeam代理服务器可访问直连存储形式的备份存储库。在本节中、我们将介绍如何创建适用于ONTAP 文件系统的FSx、如何将iSCSI LUN挂载到Veeam服务器以及如何创建备份存储库。</block>
  <block id="ab86a3c6c49221029e087069c67afde4" category="example-title">为ONTAP 文件系统创建FSx</block>
  <block id="b1482c3c8ddb524e489f598fb1682bec" category="paragraph">创建FSx for ONTAP 文件系统、用于托管Veeam备份存储库的iSCSI卷。</block>
  <block id="63dadfa2e7bb649f2cf37a4f5bb57234" category="list-text">在AWS控制台中，转到FSx，然后选择*Create file system*</block>
  <block id="e92c790de743d72c9d5e30676ffc92a6" category="image-alt">为ONTAP 文件系统创建FSx</block>
  <block id="2d70ffe1aef831779c654e87ef9a61cb" category="list-text">选择*Amazon FSx for NetApp ONTAP FS*，然后选择*Next*继续。</block>
  <block id="da42c7b111f6ebbd0e83be11785bb4a8" category="image-alt">选择Amazon FSx for NetApp ONTAP</block>
  <block id="7d660d9d9190db31e2bd116860682a0e" category="list-text">填写文件系统名称、部署类型、SSD存储容量以及FSx for ONTAP 集群将驻留的VPC。此VPC必须配置为与VMware Cloud中的虚拟机网络进行通信。单击“*下一步*”。</block>
  <block id="04bdd1dac84aa4ac8a5de06bed454bec" category="image-alt">填写文件系统信息</block>
  <block id="d2cc66e895c715b9d24a0f9e0e3b88f0" category="list-text">查看部署步骤，然后单击*Create File System*开始文件系统创建过程。</block>
  <block id="c119c68e0942c93c70a5ca74df29411e" category="example-title">配置和挂载iSCSI LUN</block>
  <block id="04bce2f95605efb88d967dab73395d7a" category="paragraph">在FSx for ONTAP 上创建和配置iSCSI LUN、然后挂载到Veeam备份和代理服务器。这些LUN稍后将用于创建Veeam备份存储库。</block>
  <block id="5005cc580f96bbd1531e77d5532a5d64" category="admonition">在FSx for ONTAP 上创建iSCSI LUN是一个多步骤过程。创建卷的第一步可以在Amazon FSx控制台中完成、也可以使用NetApp ONTAP 命令行界面完成。</block>
  <block id="dcf268d2cfc916821c6b6f5555261152" category="admonition">有关使用FSx for ONTAP 的详细信息、请参见<block ref="3c0b139db5fd16e7a1648aeb8ddd690b" category="inline-link-rx"></block>。</block>
  <block id="66ddf6562e817e09542dfdb3581a772c" category="list-text">在NetApp ONTAP 命令行界面中、使用以下命令创建初始卷：</block>
  <block id="2135d9bb62fb8c3d2e8360df647e4580" category="list-text">使用上一步中创建的卷创建LUN：</block>
  <block id="143a3308766e722bc51c4a272aef9459" category="list-text">通过创建包含Veeam备份和代理服务器的iSCSI IQN的启动程序组来授予对LUN的访问权限：</block>
  <block id="4a829a8db516d06fa3598fcf317a2bdf" category="admonition">要完成上述步骤、您需要先从Windows服务器上的iSCSI启动程序属性检索IQN。</block>
  <block id="46aba17afdc1c5c75177648e448e9e73" category="list-text">要挂载iSCSI LUN、请登录到Veeam Backup &amp; Replication Server并打开iSCSI启动程序属性。进入*Discover (*发现)*选项卡并输入iSCSI目标IP地址。</block>
  <block id="a1410f742ec3c6b9771b8b56e4f74397" category="image-alt">iSCSI启动程序发现</block>
  <block id="7896ed45c3a165871425e5e7a7754068" category="list-text">在*目标*选项卡上，突出显示非活动LUN并单击*Connect*。选中*启用多路径*框，然后单击*确定*以连接到LUN。</block>
  <block id="cfe06ced4041dba025b5783050223aa6" category="image-alt">将iSCSI启动程序连接到LUN</block>
  <block id="1e1ae1e60a8dfc7ed96a6ca196efb3f7" category="list-text">在磁盘管理实用程序中、初始化新的LUN并使用所需的名称和驱动器盘符创建卷。选中*启用多路径*框，然后单击*确定*以连接到LUN。</block>
  <block id="91fb417f634afe2d6560149b5394c9c9" category="image-alt">Windows磁盘管理</block>
  <block id="ec7c7f1a4620a0e2176556c71854ae66" category="list-text">重复上述步骤、将iSCSI卷挂载到Veeam代理服务器上。</block>
  <block id="7d038f3b910671baddd68728149b7c4b" category="example-title">创建Veeam备份系统信息源</block>
  <block id="2f1071c15bba30d1cb3ebab14b3bfe35" category="paragraph">在Veeam Backup and Replication控制台中、为Veeam Backup和Veeam Proxy服务器创建备份存储库。这些存储库将用作虚拟机备份的备份目标。</block>
  <block id="f2aa8c30f4a71e2af740c1d46fbebaa7" category="list-text">在Veeam Backup and Replication控制台中、单击左下方的*备份基础架构*、然后选择*添加存储库*</block>
  <block id="889057427ca75e67d9ad9b5449ed0210" category="image-alt">创建新的备份存储库</block>
  <block id="7f5523627751b57497ad0cf5c9b3f765" category="list-text">在"New Backup Repository (新建备份存储库)"向导中、输入存储库的名称、然后从下拉列表中选择服务器、并单击*填充*按钮以选择要使用的NTFS卷。</block>
  <block id="9968b60de9291c8910745941617de5c4" category="image-alt">选择备份存储库服务器</block>
  <block id="2525a35c51623cb0a8ed1199138d6828" category="list-text">在下一页上、选择执行高级还原时用于挂载备份的挂载服务器。默认情况下、此服务器与存储库存储连接在一起。</block>
  <block id="b57ba393732dc8f80d3571ae4ec575f5" category="list-text">查看您的选择，然后单击*Apply*开始创建备份存储库。</block>
  <block id="939d6e1647073b59730a25661269ba57" category="image-alt">选择挂载服务器</block>
  <block id="f2f54d55f13232525ba25b2714e262c6" category="list-text">对任何其他代理服务器重复上述步骤。</block>
  <block id="891594a875e25ad7383fe31f29b45c3c" category="section-title">配置Veeam备份作业</block>
  <block id="9920c3a0639f4da25555907aea043dc5" category="paragraph">应使用上一节中的备份系统信息栏创建备份作业。创建备份作业是任何存储管理员的常规任务、此处不会介绍所有步骤。有关在Veeam中创建备份作业的详细信息、请参见<block ref="83de5255f1620c94ccf67b2665aee6d6" category="inline-link-rx"></block>。</block>
  <block id="6bfc66c2628109275c896a988b4526ba" category="paragraph">在此解决方案 中、为以下项创建了单独的备份作业：</block>
  <block id="e3903b9e363074bac4445648a8709a9d" category="list-text">Microsoft Windows SQL Server</block>
  <block id="55eae047caeecf8cc118db0747f7d743" category="list-text">Oracle数据库服务器</block>
  <block id="097f33de9b678c4fc9f275c0df2b1a05" category="list-text">Windows文件服务器</block>
  <block id="ae1149b4824a31c171106b9190f70a09" category="list-text">Linux文件服务器</block>
  <block id="6725114ce430d926feb402a2063ab9bc" category="example-title">配置Veeam备份作业时的一般注意事项</block>
  <block id="bf4caa458a928f51528c2f10b31b3e10" category="list-text">启用应用程序感知型处理、以创建一致的备份并执行事务日志处理。</block>
  <block id="3c7c53d645ec38808c26ca2d19b9a4d4" category="list-text">启用应用程序感知型处理后、请向应用程序添加具有管理员权限的正确凭据、因为此凭据可能与子操作系统凭据不同。</block>
  <block id="1c4fdcc86146f7632fdc110e81c00e02" category="image-alt">应用程序处理设置</block>
  <block id="f773d224b5cf1a1dbd085266d448b926" category="list-text">要管理备份的保留策略，请选中*将某些完整备份保留更长的时间以供归档使用*，然后单击*配置...*按钮以配置策略。</block>
  <block id="8598cf5b5d0f91f3236081af11f8057b" category="image-alt">长期保留策略</block>
  <block id="15d9da9e054f4fa32f65f8287f31988f" category="section-title">使用Veeam完全恢复还原应用程序VM</block>
  <block id="f71bd591b9504e7e051735f31e3e8297" category="paragraph">使用Veeam执行完全还原是执行应用程序还原的第一步。我们验证了已启动的VM的完全恢复以及所有服务均正常运行。</block>
  <block id="b63970925e7df13313ea4e9bfb20d25b" category="paragraph">还原服务器是任何存储管理员职责的正常组成部分、此处不会介绍所有步骤。有关在Veeam中执行完全恢复的更多完整信息、请参见<block ref="83de5255f1620c94ccf67b2665aee6d6" category="inline-link-rx"></block>。</block>
  <block id="d5b892977fb8e256e082bc08621c1e91" category="section-title">还原SQL Server数据库</block>
  <block id="4dbf9d1e20e42b8ceb9eb7b9bfacaf26" category="paragraph">Veeam Backup &amp; Replication提供了多种还原SQL Server数据库的选项。在此验证中、我们使用Veeam Explorer for SQL Server with Instant Recovery执行SQL Server数据库还原。SQL Server即时恢复是一项功能、可用于快速还原SQL Server数据库、而无需等待完整的数据库还原。这种快速恢复过程可最大限度地减少停机时间并确保业务连续性。工作原理如下：</block>
  <block id="f7f8bb0d8f1bc9a76e9d24b9755056e3" category="list-text">Veeam Explorer *挂载包含要还原的SQL Server数据库的备份*。</block>
  <block id="32184bfa3ec6d72ef5157d490eef9b42" category="list-text">软件*直接从装载的文件发布数据库*，使其可作为目标SQL Server实例上的临时数据库访问。</block>
  <block id="147b6b44a29d176cd64d9f1f8a347346" category="list-text">在使用临时数据库时、Veeam Explorer *将用户查询*重定向到此数据库、以确保用户可以继续访问和使用数据。</block>
  <block id="fc87b31ab41cb9094fdafe90e5c33ee8" category="list-text">在后台、Veeam *执行完整数据库还原*、将数据从临时数据库传输到原始数据库位置。</block>
  <block id="326bd27551ad96c083a3af1d636fba2f" category="list-text">完整数据库还原完成后、Veeam Explorer *将用户查询切换回原始*数据库并删除临时数据库。</block>
  <block id="53d7653e886de31f64f1934f6106967b" category="example-title">使用Veeam Explorer即时恢复还原SQL Server数据库</block>
  <block id="62efbbf0b1972f3db725ff341efb5b9e" category="list-text">在Veeam备份和复制控制台中、导航到SQL Server备份列表、右键单击某个服务器并选择*还原应用程序项*、然后选择* Microsoft SQL Server数据库...*。</block>
  <block id="cb2c84aa5dd5450ed2bb5c2e9e182122" category="list-text">在Microsoft SQL Server数据库还原向导中，从列表中选择还原点，然后单击*Next*。</block>
  <block id="83f3bf3328f655dc26285ddf3e56f6a0" category="image-alt">从列表中选择还原点</block>
  <block id="7d09cc51774cd8dd944f427698b0e331" category="list-text">如果需要、输入*恢复原因*、然后在摘要页面上、单击*浏览*按钮以启动Veeam Explorer for Microsoft SQL Server。</block>
  <block id="93ef50124e2b75448543f1fceee8720d" category="image-alt">单击浏览以启动Veeam Explorer</block>
  <block id="23f91d399193160e78b4a9a09a5e29cf" category="list-text">在Veeam Explorer中展开数据库实例列表、右键单击并选择*即时恢复*、然后选择要恢复到的特定还原点。</block>
  <block id="91848752ef347f0a72d0ffcaf6514993" category="image-alt">选择即时恢复还原点</block>
  <block id="3dc0ac32b83cfdecc3c501fdf7c091f3" category="list-text">在即时恢复向导中、指定切换类型。这可以是自动执行的、停机时间最短、也可以是手动执行的、也可以是在指定时间执行的。然后单击*recover (恢复)*按钮开始恢复过程。</block>
  <block id="4e2a44728723140f9ba14c7275424bd9" category="image-alt">选择切换类型</block>
  <block id="23cf892bc742964f8ed1e855683c6670" category="list-text">可以从Veeam Explorer监控恢复过程。</block>
  <block id="e974549c6230612aab13ea02dd581e36" category="image-alt">监控SQL Server恢复过程</block>
  <block id="098837e218303bd96735334e58cfc2cc" category="inline-link">《Veeam Explorers用户指南》</block>
  <block id="ab470be1706ecee3652bec4686980395" category="paragraph">有关使用Veeam Explorer执行SQL Server还原操作的详细信息、请参阅中的Microsoft SQL Server一节<block ref="b3e7ff59f86494dde184c05b201d855e" category="inline-link-rx"></block>。</block>
  <block id="1b6a2be6f12549e32286e4f2dc12e2c7" category="section-title">使用Veeam Explorer还原Oracle数据库</block>
  <block id="0313e321d89b71cf80cc311103cca603" category="paragraph">Veeam Explorer for Oracle数据库支持使用即时恢复执行标准Oracle数据库还原或无中断还原。它还支持发布数据库、以便快速访问、恢复Data Guard数据库以及从RMAN备份中恢复。</block>
  <block id="b534180c333f658f337d96b0a9665fef" category="paragraph">有关使用Veeam Explorer执行Oracle数据库还原操作的详细信息、请参阅中的Oracle一节<block ref="d86e2dea88de74702b776a7b6a2794dc" category="inline-link-rx"></block>。</block>
  <block id="bb3c66c1da92cedc05fe3488c730b18c" category="example-title">使用Veeam Explorer还原Oracle数据库</block>
  <block id="3b195aff157bd167f1dd37a9fcd0b60d" category="paragraph">本节将介绍如何使用Veeam Explorer将Oracle数据库还原到其他服务器。</block>
  <block id="be228e79b0bceacb5ae08d8a6461bbc8" category="list-text">在Veeam Backup and Replication控制台中、导航到Oracle备份列表、右键单击某个服务器并选择*还原应用程序项*、然后选择* Oracle数据库...*。</block>
  <block id="71a36e1ed26cc0d0e6741bc701e2b712" category="image-alt">还原Oracle数据库</block>
  <block id="cece11bd872faf4c7efa691216eaeea2" category="list-text">在Oracle数据库恢复向导中，从列表中选择一个还原点，然后单击*Next*。</block>
  <block id="896155df2e0009da3f3945055f1978bf" category="list-text">如果需要、输入*恢复原因*、然后在摘要页面上、单击*浏览*按钮以启动Veeam Explorer for Oracle。</block>
  <block id="e2665092e2db451c18c439aa87b1ab45" category="list-text">在Veeam Explorer中展开数据库实例列表、单击要还原的数据库、然后从顶部的*还原数据库*下拉菜单中选择*还原到另一台服务器...*。</block>
  <block id="6059785cc38cd2515737ba8afc9e5c4a" category="image-alt">选择还原到其他服务器</block>
  <block id="5f920b9ccb9fe5c395400fdf2d9fbb88" category="list-text">在“恢复向导”中，指定要从中恢复的还原点，然后单击“*下一步*”。</block>
  <block id="e1d921ef21984b10f12b79b9ee5dcc16" category="image-alt">选择还原点</block>
  <block id="408c26bdfc2d93171c71473e59ea7851" category="list-text">指定数据库将还原到的目标服务器和帐户凭据，然后单击*Next*。</block>
  <block id="90414640ba0911f4dc486ddcb8b1d8e0" category="image-alt">指定目标服务器凭据</block>
  <block id="ed368a5b1fde6fe23e70c02279ab0ada" category="list-text">最后，指定数据库文件的目标位置，然后单击*Restore*按钮开始恢复过程。</block>
  <block id="6d9d046bf4302de591ebf5af70c02969" category="image-alt">指定目标位置</block>
  <block id="0b461fa79920c88a3497485474af2292" category="list-text">数据库恢复完成后、请检查Oracle数据库是否在服务器上正确启动。</block>
  <block id="8810f2f9802fa165dfd359b5b76b6b7b" category="example-title">将Oracle数据库发布到备用服务器</block>
  <block id="5e066f91cc8d7f9491f75664f7e20dd6" category="paragraph">在本节中、数据库会发布到备用服务器、以便在不启动完全还原的情况下快速访问。</block>
  <block id="2e9ce0916306fede470954bd646f1cdc" category="list-text">在Veeam Explorer中展开数据库实例列表、单击要还原的数据库、然后从顶部的*发布数据库*下拉菜单中选择*发布到另一台服务器...*。</block>
  <block id="3139a1fa03fe835f5f536efc10409e11" category="list-text">在发布向导中，指定发布数据库的还原点，然后单击*Next*。</block>
  <block id="b8a6d62ddfa6710c97f1e494dc9e45ac" category="list-text">最后，指定目标Linux文件系统位置，然后单击*发布*开始恢复过程。</block>
  <block id="1b421299cbc14ee7afd66f3aa0c1f358" category="list-text">发布完成后、登录到目标服务器并运行以下命令、以确保数据库正在运行：</block>
  <block id="cfd3a34ff975bc1959bfb5793e2b6ff8" category="paragraph">VMware Cloud是一个功能强大的平台、用于运行业务关键型应用程序和存储敏感数据。对于依赖VMware Cloud的企业来说、安全的数据保护解决方案 对于确保业务连续性并帮助抵御网络威胁和数据丢失至关重要。通过选择可靠且强大的数据保护解决方案 、企业可以确信无论什么情况、其关键数据都是安全可靠的。</block>
  <block id="a72d18c7f6b828d17adc2b0ed2dedd79" category="paragraph">本文档中提供的使用情形重点介绍经验证的数据保护技术、这些技术重点介绍了NetApp、VMware和Veeam之间的集成。在AWS中、FSx for ONTAP 可用作VMware Cloud的补充NFS数据存储库、并可用于所有虚拟机和应用程序数据。Veeam Backup &amp; Replication是一款全面的数据保护解决方案 、旨在帮助企业改进、自动化和简化备份和恢复流程。Veeam可与FSx for ONTAP 上托管的iSCSI备份目标卷结合使用、为驻留在VMware Cloud中的应用程序数据提供安全且易于管理的数据保护解决方案。</block>
  <block id="825bcb57c4a920b6ec1b4c96c593210a" category="paragraph">要详细了解此解决方案 中提供的技术、请参阅以下追加信息。</block>
  <block id="391429dd9e1e9b2ff88f428c7b849eb7" category="list-text"><block ref="391429dd9e1e9b2ff88f428c7b849eb7" category="inline-link-rx"></block></block>
  <block id="b7d636e1b78edc933a4c14acff575931" category="list-text"><block ref="d130370c3ed147d52bd7d669d0f774b8" category="inline-link-rx"></block></block>
  <block id="a20d2f7d44a6fc788ac6dbb4daa7fd01" category="sidebar">VMware Cloud中的Veeam备份和还原、采用AWS FSx for NetApp ONTAP</block>
  <block id="13549bdeea4691de1cb8770ad340fe98" category="inline-link-macro">使用FSx for ONTAP 在VMC中执行Veeam备份和还原(&amp;A)</block>
  <block id="c7e33bfa2affc748125a7a3ac5add080" category="list-text"><block ref="a4040abe827501c59f63af5f8c85d98b" category="inline-link-macro-rx"></block></block>
  <block id="d32927c975622dda9841402f1a1c8526" category="cell">2023年4月27日</block>
  <block id="7624970b07a1f223fd6ce63511968dd0" category="cell">使用AWS FSx for ONTAP 在VMware Cloud中添加了Veeam备份和还原功能</block>
  <block id="8daba132ddff8c3d3fd4757eab8dd47a" category="cell">2023年3月29日</block>
  <block id="1260fc391141c4810f2e3a97eaef162e" category="cell">2023年3月22日</block>
  <block id="ba7124a5ffeb6501794efa91cdcb129b" category="cell">添加了将FSx ONTAP 作为NFS数据存储库的VMware文档链接</block>
  <block id="1f791cf07735c71bdb472a0ccd42abc7" category="cell">2023年5月4日</block>
  <block id="35cec0f40dca2af7a6d3c73676c4629d" category="cell">添加了"VMware vSphere 8新增功能"内容</block>
  <block id="8b5fd5c25439f60370c36458db046f5e" category="doc">VMware vSphere 8的新增功能</block>
  <block id="d64ac18d7cdc111af11284a04f9e8b1e" category="paragraph">作者：NetApp解决方案工程部Chris Reno</block>
  <block id="5a16d86949ce13083d30d1c331be09cb" category="paragraph">NetApp与VMware技术的集成已有20年的历史、耗时数千小时。随着vSphere 8和ONTAP 9.12的出现、这两家公司都提供了能够满足最苛刻的客户工作负载要求的产品。将这些产品组合到解决方案中后、无论是在内部还是在公有云中、都能解决客户面临的实际挑战。将这些产品组合到解决方案中后、无论是在内部还是在公有云中、都可以解决客户面临的实际挑战。</block>
  <block id="4eba71964e65640552100b4af7c50e86" category="paragraph">为了帮助您确定产品、协议、操作系统等的支持能力、请查看以下资源：</block>
  <block id="bab924f6f70545a4aab5c02282b4321d" category="list-text">。<block ref="cdfba3111aed90ef850f414330a864eb" category="inline-link-rx"></block> IMTIMT 定义了可用于构建FC/FCoE、iSCSI、NFS和CIFS配置以及与其他插件和软件产品集成的合格组件和版本。</block>
  <block id="e08175c6fa64cba68719dea85ebd9d34" category="inline-link">VMware 兼容性指南</block>
  <block id="e96d25b875cbad01256de32331620fce" category="list-text">。<block ref="132c849774dbad448418b619a953cbd1" category="inline-link-rx"></block>。《VMware兼容性指南》列出了系统、I/O、存储/SAN、备份与VMware Infrastructure和软件产品的兼容性等。</block>
  <block id="cca95a1e810067767564618ea73079be" category="list-text"><block ref="ec744c32e869920be1556ab8ebc057ef" category="inline-link-rx"></block>。适用于VMware vSphere的ONTAP 工具是一个vCenter Server插件、其中包括Virtual Storage Console (VSC)、VASA Provider和Storage Replication Adapter (SRA)扩展。OTV 9.12完全受VMware vSphere 8支持、每天都能为客户带来真正的价值。</block>
  <block id="ae33d50ae700fed2ee8028004d9fa2d8" category="section-title">NetApp ONTAP 和VMware支持的版本</block>
  <block id="ed126bbe4f371826a7c7c9d6fdd35e54" category="admonition">在下表中选择链接时、请让页面扩展。</block>
  <block id="e450cac7ca4b207e6cb6c51eeb3c76dd" category="cell">*VMware vSphere版本*</block>
  <block id="54d1b3917151f3d89ddbd7aef9f811dd" category="cell">* SAN *</block>
  <block id="b4ccd4984cce17a35c772737cf9415b1" category="cell">* NFS *</block>
  <block id="ea2b80d118e24f4d3328c20552636f22" category="cell">*OTV*</block>
  <block id="dccf9c2e4a699b348abaf0369603c1a0" category="cell">* SnapCenter *</block>
  <block id="b97d2c4e1a2a118c500af6e32504301f" category="cell">*vSphere 8*</block>
  <block id="3c30688c35eac25f7729ec4ee134e7e3" category="cell"><block ref="f010a57a1b1362e74ef056cd949b4f6b" category="inline-link-rx"></block></block>
  <block id="c538764856660dbf5ac35d08c5b7bcdf" category="cell"><block ref="5983a3bb611cf1b4562bfd78f97ed318" category="inline-link-rx"></block></block>
  <block id="a140bde1e447ebe74a0b6b693d05d3c6" category="cell"><block ref="c14e144a71a125f874ca16b78c671347" category="inline-link-rx"></block></block>
  <block id="8d153eb947f0747c73debd6aa0564387" category="cell"><block ref="9e4cfb7f25d7fb71f62ac8aad4b23fac" category="inline-link-rx"></block></block>
  <block id="87efc48b7f668d33418b1f846e08a0bf" category="cell">*vSphere 8u1*</block>
  <block id="adebed85a7d92b0f3fc4b5cfc97078b6" category="cell"><block ref="bdb3662ee535fb90a843ab7d85efbd16" category="inline-link-rx"></block></block>
  <block id="055cce5491290ec858a19e499e0d9e71" category="cell"><block ref="bd210893ee82e4c865fcf08bbaf31838" category="inline-link-rx"></block></block>
  <block id="1f0f8c35492e97597c98b9dc82afa362" category="cell">*存储系统/协议*</block>
  <block id="e90637603dd7a81f8a9115bb4ffd28f9" category="cell">*OTV - SRA*</block>
  <block id="d7d7d2428ec9c1791dc7f644b043a8d4" category="cell">*OTV–VASA Provider*</block>
  <block id="81e3cc47d6ed146bbe1096018a69f40c" category="cell">*适用于VMware vSphere的SnapCenter 插件*</block>
  <block id="1a718e68b847d8b2043c7f76af9a4858" category="cell"><block ref="34ab3c79d36e5a654b9402fe2fcf7f3b" category="inline-link-rx"></block></block>
  <block id="391de35bbb4cf1a51813527b129bb11e" category="cell"><block ref="e3a74d6b6b54621583ac737da6124d3a" category="inline-link-rx"></block></block>
  <block id="47c5c0877638b8f808901039637b1474" category="cell"><block ref="8ef8fc61fd753b52cc179e3463e5820b" category="inline-link-rx"></block></block>
  <block id="b8145535eda5b8ac300fd64bfa74cc26" category="cell"><block ref="64c621ea990d75acd1bb8fba7b272f2c" category="inline-link-rx"></block></block>
  <block id="315a0755b344c41b2a45eb62f3868930" category="cell"><block ref="c0dded1a1fb8dd474b19235d36c5c4c7" category="inline-link-rx"></block></block>
  <block id="1e6ad53e48d26e8f800d9e60c340e84d" category="sidebar">VMware vSphere 8的新增功能</block>
  <block id="1e0561f6acd458eaa1243b2cd1f781e1" category="inline-link">VMware Cloud on AWS支持。注意事项和限制</block>
  <block id="2d57bbd81ef9a580a0f2d6b36c8d86c2" category="list-text"><block ref="2d57bbd81ef9a580a0f2d6b36c8d86c2" category="inline-link-rx"></block></block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">本文档详细介绍了如何在NetApp E系列存储系统中部署StorNext并行文件系统解决方案。此解决方案 涵盖NetApp EF280全闪存阵列、NetApp EF300全闪存NVMe阵列、NetApp EF600全闪存NVMe阵列和NetApp E5760混合系统。它基于Frametest基准测试提供性能特征化、该工具广泛用于媒体和娱乐行业的测试。</block>
  <block id="e48febb9ce9511ad6a07eb2feefcf987" category="doc">TR-4951：《AWS FSx for ONTAP 上Microsoft SQL Server的备份和恢复》</block>
  <block id="89801e66cf61a843ac015db626c0ecde" category="paragraph">作者：Niyaz Mohammed、Carine Ngwekwe - NetApp解决方案工程部</block>
  <block id="a5ddf739ea634e933770ce212cd12b29" category="paragraph">本文档介绍了在AWS FSx for ONTAP 上使用SnapCenter 对Microsoft SQL Server执行备份和恢复所需的步骤。其中包括以下信息：</block>
  <block id="5bf8a1308ebd487796bd4db12222cf4a" category="list-text">NetApp SnapCenter 配置</block>
  <block id="ecc57313124902e4c42227ae61bb9bf1" category="list-text">SnapCenter 备份操作</block>
  <block id="d939d79ed61dbf23169c4f7badcc1788" category="list-text">FCI数据库的备份操作</block>
  <block id="cb9f91cd2f1ab77ae604d05be34c3d59" category="list-text">多个数据库的备份操作</block>
  <block id="6be8f3086a30e59e908d53eb620b51dd" category="list-text">还原和恢复</block>
  <block id="9fa83b367c23a5d2579b5aebdddebe77" category="section-title">SnapCenter 配置</block>
  <block id="f979bf3f98ebe58fd55555efea856e3f" category="paragraph">要配置SnapCenter 和保护Microsoft SQL Server资源、必须执行以下步骤。以下各节将详细介绍以下每个步骤。</block>
  <block id="7c1e7491c7e3588e56a0b05940cc2840" category="list-text">为SQL Server备份和还原用户配置sysadmin凭据。</block>
  <block id="d6442b5b8ad78236b2966fc5c1191c1e" category="list-text">配置存储设置。提供Amazon Web Services (AWS)管理凭据、以便从SnapCenter 访问适用于NetApp ONTAP Storage Virtual Machine (SVM)的Amazon FSx。</block>
  <block id="bf1e7185f6bb09e0f2b1527acbbb47df" category="list-text">将SQL Server主机添加到SnapCenter。部署并安装所需的SnapCenter 插件。</block>
  <block id="1e5b163165e28d2c04a5c2cc25406fa0" category="list-text">配置策略。定义备份操作类型、保留和可选的Snapshot备份复制。</block>
  <block id="7839511c8247bb78354925ce2771284a" category="list-text">配置和保护Microsoft SQL Server数据库。</block>
  <block id="1719e3b1afdebd05d1f71b0881a7083c" category="section-title">新安装的SnapCenter 用户界面</block>
  <block id="97504cb249856d98431bd413caeb43ce" category="paragraph">为SQL Server备份配置凭据、并使用sysadmin权限还原用户。</block>
  <block id="cdff526b5e5a4339e5ad188cb61b446f" category="paragraph"><block ref="cdff526b5e5a4339e5ad188cb61b446f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a8b4eaab7153d620e4be3372cee492d" category="paragraph">NetApp建议使用基于角色的访问控制(Role-Based Access Control、RBAC)将数据保护和管理功能委派给SnapCenter 和Window主机中的各个用户。用户必须有权访问托管数据库的SQL Server。对于多个主机、不同主机的用户名和密码必须相同。此外、要使SnapCenter 能够在SQL Server主机上部署所需的插件、您必须为SnapCenter 注册域信息以验证凭据和主机。</block>
  <block id="2f5eb1bcad8467d8b1a3a761e7a52e7c" category="paragraph">展开以下各节、查看有关如何完成每个步骤的详细说明。</block>
  <block id="36bc52aaebad43ec3e49ed9a0efacd43" category="example-title">添加凭据</block>
  <block id="994e670ad871a1a1a8968ef47fce1bd2" category="paragraph">进入*Settings*，选择*凭证*，然后单击(*+*)。</block>
  <block id="9816a3711fba5a6da62899f4fa6ce522" category="paragraph"><block ref="9816a3711fba5a6da62899f4fa6ce522" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ef34a5260859bfffb6bf580955ffb1e" category="paragraph">新用户必须对SQL Server主机具有管理员权限。</block>
  <block id="bcd04483b0b1e054777058931ef7d117" category="paragraph"><block ref="bcd04483b0b1e054777058931ef7d117" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d25223f4065ca21361aff2e7cdc61203" category="example-title">配置存储</block>
  <block id="8d4520cc707d4607fe5abe132aecdbf2" category="paragraph">要在SnapCenter 中配置存储、请完成以下步骤：</block>
  <block id="17b1ba0b70ebf5f6fcfd2f39e760ac1c" category="list-text">在SnapCenter UI中，选择*Storage Systems*。存储类型有两种：* ONTAP SVM*和* ONTAP Cluster*。默认情况下，存储类型为* ONTAP SVM*。</block>
  <block id="84bf89b0b19fc811dad7c11f9b65802e" category="list-text">单击(*+*)添加存储系统信息。</block>
  <block id="09710a8bb6b2b53186f42bcfb4cdf2d7" category="paragraph"><block ref="09710a8bb6b2b53186f42bcfb4cdf2d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="517cf06d127b73ca2104c46eedc40e4e" category="list-text">提供*FSx for ONTAP 管理*端点。</block>
  <block id="ecbf2692688ddd1d8cffae4eb2adae87" category="paragraph"><block ref="ecbf2692688ddd1d8cffae4eb2adae87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c99ac5cbe66f4968da17288cff14037" category="list-text">现在、已在SnapCenter 中配置SVM。</block>
  <block id="193ab9cc10d32956324c73a0aad32ece" category="paragraph"><block ref="193ab9cc10d32956324c73a0aad32ece" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f4cf5450244ae3361ec7b130b139860" category="example-title">将SQL Server主机添加到SnapCenter</block>
  <block id="865ea603dd93a3a23cc7e80825b29624" category="paragraph">要添加SQL Server主机、请完成以下步骤：</block>
  <block id="e14bea01dc3a10ca47f216a08f68fa85" category="list-text">在主机选项卡中，单击(*+*)以添加Microsoft SQL Server主机。</block>
  <block id="f2a1bec0c1120023662a8abe57c12c35" category="paragraph"><block ref="f2a1bec0c1120023662a8abe57c12c35" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c802780a0f54f5e4f22e25de9fa33be" category="list-text">提供远程主机的完全限定域名(FQDN)或IP地址。</block>
  <block id="fb62a23910339f3168b6b89b4e0f77b7" category="admonition">默认情况下、这些凭据会进行填充。</block>
  <block id="65d9345f77faaa3bf7bb8031bb92f814" category="list-text">选择Microsoft Windows和Microsoft SQL Server的选项、然后选择提交。</block>
  <block id="42a8898b70e0495a43f4df86d0f689cd" category="paragraph"><block ref="42a8898b70e0495a43f4df86d0f689cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53b2d796e625fe393f84e48a5c6c6e91" category="paragraph">此时将安装SQL Server软件包。</block>
  <block id="b7778c4b2da8a542de9529435e8ec22a" category="paragraph"><block ref="b7778c4b2da8a542de9529435e8ec22a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af3617c8e674a62860e153751b1b62d8" category="list-text">安装完成后，转到*Resource*选项卡以验证所有FSx for ONTAP iSCSI卷是否都存在。</block>
  <block id="c919f693c37c2d168175e649e14c3293" category="paragraph"><block ref="c919f693c37c2d168175e649e14c3293" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b83af25a71030e8f59b11202c70c1a4" category="example-title">配置日志目录</block>
  <block id="144931b7282f9d86fce2e97aa69aa046" category="paragraph">要配置主机日志目录、请完成以下步骤：</block>
  <block id="089f0c00b86bab7c6ce3e455e39b4111" category="list-text">单击复选框。此时将打开一个新选项卡。</block>
  <block id="a4ce6f0dbf75e4ef516f57614792a907" category="paragraph"><block ref="a4ce6f0dbf75e4ef516f57614792a907" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57fab4c72318fea3bba8b3c321098ab3" category="list-text">单击*configure log directory*链接。</block>
  <block id="d6c8cb16951a3c787db9f20c0fb09057" category="paragraph"><block ref="d6c8cb16951a3c787db9f20c0fb09057" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b06cca5c441f86e0c4ad342dc4949c5" category="list-text">为主机日志目录和FCI实例日志目录选择驱动器。单击 * 保存 * 。对集群中的第二个节点重复相同过程。关闭窗口。</block>
  <block id="24519841c3d33e14f5bb7d209d673a35" category="paragraph"><block ref="24519841c3d33e14f5bb7d209d673a35" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c36dc3499eaa7955922477da928c37d" category="paragraph">主机现在处于running状态。</block>
  <block id="820630e9a1c808068eda3661f49042cf" category="paragraph"><block ref="820630e9a1c808068eda3661f49042cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21ff17f2a463836d33f1c25b922e2aad" category="list-text">在“*资源*”选项卡中，我们有所有的服务器和数据库。</block>
  <block id="076c245e9e02588c21d76bd30de179dd" category="paragraph"><block ref="076c245e9e02588c21d76bd30de179dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e2457547c492c6001e30b828b6540e" category="section-title">配置备份策略</block>
  <block id="febe42e6f9b7fb03483725eb94b7dc4f" category="paragraph">备份策略是一组规则、用于控制如何管理、计划和保留备份。它有助于根据贵公司的SLA确定备份类型和频率。</block>
  <block id="e28ebacaa4299d5022a9ce52d607c076" category="example-title">配置FCI数据库的备份操作</block>
  <block id="41cc72961a6c592ec36223498c3bd705" category="paragraph">要为FCI数据库配置备份策略、请完成以下步骤：</block>
  <block id="55e9263abc7e93fbc1274424af911693" category="list-text">进入*Settings*并选择左上方的*Policies*。然后单击*New*。</block>
  <block id="adf5449547fda2e595556e9d231a2066" category="paragraph"><block ref="adf5449547fda2e595556e9d231a2066" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00f0ce22eac68a6bd05a1b0f221c4870" category="list-text">输入策略名称和问题描述。单击 * 下一步 * 。</block>
  <block id="f2eb0a484f9105201d7b6af1e010db00" category="paragraph"><block ref="f2eb0a484f9105201d7b6af1e010db00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55efa7fad4afc963d783654da41300bf" category="list-text">选择*完整备份*作为备份类型。</block>
  <block id="23b0ad9ad1f66315e2659ed3b39e490e" category="paragraph"><block ref="23b0ad9ad1f66315e2659ed3b39e490e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8270c99b48ebbc3928233b0365c4aeef" category="list-text">选择计划频率(此频率基于公司SLA)。单击 * 下一步 * 。</block>
  <block id="24207525bc0e567d54fbd4c12e87169e" category="paragraph"><block ref="24207525bc0e567d54fbd4c12e87169e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="de3ec07218c2ba18d85a3130b6583520" category="list-text">配置备份的保留设置。</block>
  <block id="b05832e4c7bab22b79bc5802800a0dab" category="paragraph"><block ref="b05832e4c7bab22b79bc5802800a0dab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e0b22898b3d80ad22f4aec2ecdb63d6" category="list-text">配置复制选项。</block>
  <block id="14b05e91fa711b3a9719853be184206c" category="paragraph"><block ref="14b05e91fa711b3a9719853be184206c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44ea4d24c42b8fec22a7b9816f31e892" category="list-text">指定要在运行备份作业之前和之后运行的运行脚本(如果有)。</block>
  <block id="eac922e5175c542119573b500882c077" category="paragraph"><block ref="eac922e5175c542119573b500882c077" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b94cb3e0f4abcd010f6711fe214e35a" category="list-text">根据备份计划运行验证。</block>
  <block id="4608b019002a2c4ec256372aa8480a1a" category="paragraph"><block ref="4608b019002a2c4ec256372aa8480a1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfa414efc5d445675fd9077ba0c56b3" category="list-text">“*摘要*”页面提供了备份策略的详细信息。可以在此处更正任何错误。</block>
  <block id="b8b8dbdb6cb7e67fa35e47b550da474f" category="paragraph"><block ref="b8b8dbdb6cb7e67fa35e47b550da474f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8e93df919756b105bc83306d032d098" category="section-title">配置和保护MSSQL Server数据库</block>
  <block id="27db30e5a59f8be2fcb99cf63599a91c" category="list-text">设置备份策略的开始日期和到期日期。</block>
  <block id="34dd0aa3564bb913360badbaaaa83faa" category="paragraph"><block ref="34dd0aa3564bb913360badbaaaa83faa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="db43ab486fbd21378315f50453a84170" category="list-text">定义备份计划。为此，请单击(*+*)配置一个计划。输入*开始日期*和*到期日期*日期。根据公司的SLA设置时间。</block>
  <block id="f27c76657d54395e925b36cbee1be886" category="paragraph"><block ref="f27c76657d54395e925b36cbee1be886" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cae5bd999deab910421c886467a77f95" category="list-text">配置验证服务器。从下拉菜单中选择服务器。</block>
  <block id="1984132ea5425099c6b2573e487c3814" category="paragraph"><block ref="1984132ea5425099c6b2573e487c3814" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eafe5ed3ae193bf0df0699f63047967c" category="list-text">单击加号确认已配置的计划、然后进行确认。</block>
  <block id="acbb9c633debb26a3e087f175b289654" category="list-text">提供电子邮件通知信息。单击 * 下一步 * 。</block>
  <block id="6da5c045f179e9f4b7f9a93a743e59bb" category="paragraph"><block ref="6da5c045f179e9f4b7f9a93a743e59bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12c3e31e09364bc821b8b38bfe3fa90b" category="paragraph">现在、SQL Server数据库的备份策略摘要已配置完毕。</block>
  <block id="2da07f989d7b3e93f17cf4dc6237a9ff" category="paragraph"><block ref="2da07f989d7b3e93f17cf4dc6237a9ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f93a0490c2398c42ac8bc4c8027da25b" category="paragraph">要创建按需SQL Server备份、请完成以下步骤：</block>
  <block id="a27b159fa260ee860202b1a37efb3a24" category="list-text">从*资源*视图中，选择资源并选择*立即备份*。</block>
  <block id="1d8d5b0070c26adc7cbd7d50e2ad9bd4" category="paragraph"><block ref="1d8d5b0070c26adc7cbd7d50e2ad9bd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8ebbd547f5d127b496961a116deba1b" category="list-text">在*Backup*对话框中，单击*Backup*。</block>
  <block id="ec9b7af4f9e32bbcc3462f3f0651d17e" category="paragraph"><block ref="ec9b7af4f9e32bbcc3462f3f0651d17e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28a70f29b174bb67f6ba18c34afe8917" category="list-text">此时将显示确认屏幕。单击*是*进行确认。</block>
  <block id="aa3b467bd6d728ef126ee24085996989" category="paragraph"><block ref="aa3b467bd6d728ef126ee24085996989" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f8452076484ec284c5858e0a7826acc" category="section-title">监控备份作业</block>
  <block id="3c171063c0a7e42fe17578dc53e1a362" category="list-text">从*Monitor*选项卡中，单击作业并选择右侧的*Details*以查看作业。</block>
  <block id="0a5505b752196a5d3967276a8e020bec" category="paragraph"><block ref="0a5505b752196a5d3967276a8e020bec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a78488fda38cb0f6c33d06d8774309cb" category="paragraph"><block ref="a78488fda38cb0f6c33d06d8774309cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="187d97d7f4855a2e10ce27f378db96dd" category="paragraph">备份完成后、"Topology"视图中将显示一个新条目。</block>
  <block id="134678acd20d853075ff197c7c9c3fcb" category="paragraph">要为多个SQL Server数据库配置备份策略、请完成以下步骤以创建资源组策略：</block>
  <block id="95fea20057274bffe889a463c6617053" category="list-text">在*View*菜单的*Resources*选项卡中，使用下拉菜单更改为资源组。</block>
  <block id="5179400c083eea1a5c874c9ced10a4f3" category="paragraph"><block ref="5179400c083eea1a5c874c9ced10a4f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d30ce7f1b8370331622f388e31ba9fd" category="list-text">单击(*+*)可选择新的资源组。</block>
  <block id="29b5c325b4a3721982a139efeaa22354" category="paragraph"><block ref="29b5c325b4a3721982a139efeaa22354" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2267ba30d8bc4b2cb24be81ba224b9a0" category="list-text">请提供名称和标记。单击 * 下一步 * 。</block>
  <block id="49a74a15bbe124a186a4b3154b4d2b61" category="paragraph"><block ref="49a74a15bbe124a186a4b3154b4d2b61" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71128d86107d5d3be141764b52ec6e0a" category="list-text">将资源添加到资源组：</block>
  <block id="6938eb21ffd3468679899baee35fc02c" category="list-text">*Host.*从托管数据库的下拉菜单中选择服务器。</block>
  <block id="d9cab3ec910c4d091f194a6fbe1ce649" category="list-text">*Resource type.*从下拉菜单中选择*Database。</block>
  <block id="9d00adb9ff02c740bad1655a08befbc8" category="list-text">*SQL Server实例。*选择服务器。</block>
  <block id="e5b057829741e7d66ccb84dd34659d15" category="paragraph"><block ref="e5b057829741e7d66ccb84dd34659d15" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52cbd1487d8eb5aca62ae227f26154cd" category="paragraph">默认情况下，已选中*option * Auto select all the Resources from the sall Storage Volumes*。清除该选项并仅选择需要添加到资源组的数据库，单击要添加的箭头并单击*Next*。</block>
  <block id="a390f1ac44166070ca9168d6db494a3c" category="paragraph"><block ref="a390f1ac44166070ca9168d6db494a3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc914d30c298d5a1be5b17d60f91d32" category="list-text">在策略上，单击(*+*)。</block>
  <block id="c8012ccb0cf9aea5ab3d75c5946839bc" category="paragraph"><block ref="c8012ccb0cf9aea5ab3d75c5946839bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0503c62843919fd6d77d98333ddc0d46" category="list-text">输入资源组策略名称。</block>
  <block id="773774cec41f86cf7c812856bb5532f4" category="paragraph"><block ref="773774cec41f86cf7c812856bb5532f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="84c7b78e63b4d35a0da59b9c1547859f" category="list-text">根据贵公司的SLA，选择*完整备份*和计划频率。</block>
  <block id="439033b0e525dcfb01f503bce465bab7" category="paragraph"><block ref="439033b0e525dcfb01f503bce465bab7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d3f39805e6cab1e0c8e41e3a8045d4" category="list-text">配置保留设置。</block>
  <block id="b33d774bbfed75c94879fc316e7bcd21" category="paragraph"><block ref="b33d774bbfed75c94879fc316e7bcd21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d3b49aed2989d78ff906ce8d5d3dd65" category="paragraph"><block ref="0d3b49aed2989d78ff906ce8d5d3dd65" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b438cf4e498dc0e4f65b8cf167949153" category="list-text">配置要在执行备份之前运行的脚本。单击 * 下一步 * 。</block>
  <block id="cf4f12ed143c80bc6af35a01c1fe98be" category="paragraph"><block ref="cf4f12ed143c80bc6af35a01c1fe98be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6504e635a92d1b0a8c52749c309ce7f6" category="list-text">确认验证以下备份计划。</block>
  <block id="30f1d3b33a552e64394acbb9a8039813" category="paragraph"><block ref="30f1d3b33a552e64394acbb9a8039813" category="inline-image-macro-rx" type="image"></block></block>
  <block id="06919ef230a779cfc26a7b40e58c155f" category="list-text">在*Summary (摘要)*页上，验证信息，然后单击*Finish (完成)*。</block>
  <block id="6ec4de8e33fceb0e3382dbba9a3e7fef" category="paragraph"><block ref="6ec4de8e33fceb0e3382dbba9a3e7fef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03db038251d30409b163cac10e15fb64" category="section-title">配置和保护多个SQL Server数据库</block>
  <block id="60d1f006544fc2635c785f35a2bb75fa" category="list-text">单击(*+*)符号以配置开始日期和到期日期。</block>
  <block id="90a0be0d18aa1385f7d629b041ec3586" category="paragraph"><block ref="90a0be0d18aa1385f7d629b041ec3586" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1709dfd12096305753ee7705ead06515" category="list-text">设置时间。</block>
  <block id="abce8a42e2fe798102907c89873652ff" category="paragraph"><block ref="abce8a42e2fe798102907c89873652ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="34af8b580bd3f78a0594fd1a6ed33f72" category="paragraph"><block ref="34af8b580bd3f78a0594fd1a6ed33f72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1dc4c7af7fe0f51e864695931afcc5d" category="list-text">从*验证*选项卡中，选择服务器，配置计划，然后单击*下一步*。</block>
  <block id="0a04449841d608c1b828876aade9dd57" category="paragraph"><block ref="0a04449841d608c1b828876aade9dd57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b91c4ea39a59e7c5891197a3b275c62c" category="list-text">配置通知以发送电子邮件。</block>
  <block id="c9d11c4594f1660f0438901255de824c" category="paragraph"><block ref="c9d11c4594f1660f0438901255de824c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="017b37b38c310ea0d90dccec6f86d049" category="paragraph">现在、该策略已配置为备份多个SQL Server数据库。</block>
  <block id="7a6908a4518e7d0a99f7991bcede071d" category="paragraph"><block ref="7a6908a4518e7d0a99f7991bcede071d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86b13e5f17a2bd60ebf403962a656abb" category="section-title">为多个SQL Server数据库触发按需备份</block>
  <block id="f7dde35cb7209b4eae92eb8ec9dbe3ea" category="list-text">从*Resource*选项卡中，选择“查看”。从下拉菜单中选择*Resource Group*。</block>
  <block id="9179022dda578f3bced2dd96da8c87ff" category="paragraph"><block ref="9179022dda578f3bced2dd96da8c87ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdbf213e9f1bcad7fef14029eb9b537b" category="list-text">选择资源组名称。</block>
  <block id="1ac4dec59e8f8197fb29b8bfa0237d91" category="list-text">单击右上角的*立即备份*。</block>
  <block id="1cecf31da10780e2d39609c010d3df62" category="paragraph"><block ref="1cecf31da10780e2d39609c010d3df62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d29aeb4de3166648265a417a3ebdfa8d" category="list-text">此时将打开一个新窗口。单击*备份后验证*复选框，然后单击备份。</block>
  <block id="9e877656fc311f532df6e62273e160d5" category="paragraph"><block ref="9e877656fc311f532df6e62273e160d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b01a18ba54b03ab361195cda9e11a04" category="list-text">此时将显示一条确认消息。单击 * 是 * 。</block>
  <block id="06ec3c59d97a4c7d9984adda2108135e" category="paragraph"><block ref="06ec3c59d97a4c7d9984adda2108135e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c39edf183648c1d5db4f2c93fb4eb28" category="section-title">监控多数据库备份作业</block>
  <block id="1010c73c274c132c818aa34d45372dd5" category="paragraph">从左侧导航栏中，单击*Monitor*，选择备份作业，然后单击*Details*以查看作业进度。</block>
  <block id="50d14527999ad5610803d042f0537b0b" category="paragraph"><block ref="50d14527999ad5610803d042f0537b0b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf2af39d79fe9b75d3b016a40a1cb886" category="paragraph">单击*Resource*选项卡查看完成备份所需的时间。</block>
  <block id="e1aa3da997feec6419955ef32aa87bdc" category="paragraph"><block ref="e1aa3da997feec6419955ef32aa87bdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b702b14abe98f98e647cd791bcb90f8d" category="section-title">用于多数据库备份的事务日志备份</block>
  <block id="26d8c1709e6a02cee73b16f5c2acf6dc" category="paragraph">SnapCenter 支持完整、庞大日志记录和简单恢复模式。简单恢复模式不支持事务日志备份。</block>
  <block id="a60ccf2e4a30da040f5a49732187a6b7" category="paragraph">要执行事务日志备份、请完成以下步骤：</block>
  <block id="be7235e7e6dc252e8daebedf54c3b6c7" category="list-text">从*Reseres*选项卡中，将“视图”菜单从*Database *更改为*Resource group*。</block>
  <block id="e0fa4309d306e577eb4ee7fae977e8ec" category="paragraph"><block ref="e0fa4309d306e577eb4ee7fae977e8ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c48d8cc9d4f748c135f5b4812c1d7412" category="list-text">选择已创建的资源组备份策略。</block>
  <block id="f38bbe0d9131c48ea9ee602675754140" category="list-text">选择右上角的*修改资源组*。</block>
  <block id="2c49b9da12e1f8828a27c12785ae9fc3" category="paragraph"><block ref="2c49b9da12e1f8828a27c12785ae9fc3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d4b5ab9594400df9f8e77cbab0abea7" category="list-text">默认情况下，*Name*部分使用备份策略名称和标记。单击 * 下一步 * 。</block>
  <block id="9a35ea0c782dad0d67865885d193f274" category="paragraph">"*Resores*(资源*)"选项卡突出显示要配置事务备份策略的基准。</block>
  <block id="11b8d03d27b3abc5c6b6e021930b3e9e" category="paragraph"><block ref="11b8d03d27b3abc5c6b6e021930b3e9e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6daf111fad11fdef17162a8f8bf18b9c" category="list-text">输入策略名称。</block>
  <block id="22f2c4c423feb263d1b0200d62e77858" category="paragraph"><block ref="22f2c4c423feb263d1b0200d62e77858" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f993771df9dbe7cf6b38a0f84b409d7" category="list-text">选择SQL Server备份选项。</block>
  <block id="ac47af84d5357e6141e59c1659b4ffb1" category="list-text">选择日志备份。</block>
  <block id="1cf75fb83a264d296888dbfc66c1e24c" category="list-text">根据公司的RTO设置计划频率。单击 * 下一步 * 。</block>
  <block id="3da946d8c357e8d3ba7d9dee6d9c48fc" category="paragraph"><block ref="3da946d8c357e8d3ba7d9dee6d9c48fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6a1a00356a0947050a129ae89c585c9" category="list-text">配置日志备份保留设置。单击 * 下一步 * 。</block>
  <block id="eca8085a550a32e2ea75af78dde57b58" category="paragraph"><block ref="eca8085a550a32e2ea75af78dde57b58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46caf3d6b884d110f60cf7f4937e7519" category="list-text">(可选)配置复制选项。</block>
  <block id="6e942622a4fc392b1c732fcb6128144f" category="paragraph"><block ref="6e942622a4fc392b1c732fcb6128144f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1a4bc0234ce8dfcbb64e7eeee67fad6" category="list-text">(可选)配置要在执行备份作业之前运行的任何脚本。</block>
  <block id="b1537af3c8af0a513d927136e6069e69" category="paragraph"><block ref="b1537af3c8af0a513d927136e6069e69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec35f0f916d59604b82ba19007187115" category="list-text">(可选)配置备份验证。</block>
  <block id="a5b416c5101ea80de98741569ba40ad8" category="paragraph"><block ref="a5b416c5101ea80de98741569ba40ad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4a7ecfa93fa04065caa7a2ead6d3d113" category="list-text">在“*摘要*”页上，单击“*完成*”。</block>
  <block id="85f4218eb49261c9a10c3ae757a7673e" category="paragraph"><block ref="85f4218eb49261c9a10c3ae757a7673e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21c62f698c67203ca218e38cedd9fd4a" category="section-title">配置和保护多个MSSQL Server数据库</block>
  <block id="851434acbe50444b77cc093290088e54" category="list-text">单击新创建的事务日志备份策略。</block>
  <block id="aab3313d777fdf9a008349b1c52a3b38" category="paragraph"><block ref="aab3313d777fdf9a008349b1c52a3b38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dc5a42c40277ce2884bea86757d8dda" category="list-text">设置*开始日期*和*到期日期*日期。</block>
  <block id="2137cef28d44fe16621167c38bd398e5" category="list-text">根据SLA、RTP和RPO输入日志备份策略的频率。单击确定。</block>
  <block id="699cfd55473b1a08a3afc68cdd6c0bc0" category="paragraph"><block ref="699cfd55473b1a08a3afc68cdd6c0bc0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eef345e42eb1ff7b7177a232bb1d1247" category="list-text">您可以看到这两个策略。单击 * 下一步 * 。</block>
  <block id="f0f5bc22b5d1f8a0d6c00b4127875d56" category="paragraph"><block ref="f0f5bc22b5d1f8a0d6c00b4127875d56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d3d450b94383f42a06333f58c0ffb5a" category="list-text">配置验证服务器。</block>
  <block id="df8d18ae668699fdea57fa8103444b04" category="paragraph"><block ref="df8d18ae668699fdea57fa8103444b04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9b705cea4d9eb8b1497ffce97bfe3609" category="list-text">配置电子邮件通知。</block>
  <block id="46e4cfc3ee8ac0fcf4621b3b601fae9e" category="paragraph"><block ref="46e4cfc3ee8ac0fcf4621b3b601fae9e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="722243257c592026b8405ff352c17887" category="paragraph"><block ref="722243257c592026b8405ff352c17887" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ea4baaafde2e79cfcd31d97b84b1a12" category="section-title">触发多个SQL Server数据库的按需事务日志备份</block>
  <block id="a75cd7342eb195ccea0a0f5ef399cb13" category="paragraph">要为多个SQL Server数据库触发事务日志按需备份、请完成以下步骤：</block>
  <block id="f790ac7cb18962dff9c720679845e234" category="list-text">在新创建的策略页面上，选择页面右上角的*立即备份*。</block>
  <block id="44991ec351e06a97a765cfca75d312af" category="paragraph"><block ref="44991ec351e06a97a765cfca75d312af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1552095f0c2d2521f14458e1899ee71b" category="list-text">从*Policy*选项卡的弹出窗口中，选择下拉菜单，选择备份策略，然后配置事务日志备份。</block>
  <block id="5baef8fc5a836fc8dce7a8277d0ebc84" category="paragraph"><block ref="5baef8fc5a836fc8dce7a8277d0ebc84" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0df35ef9b242c9f422a4cc2e1784903" category="list-text">单击 * 备份 * 。此时将显示一个新窗口。</block>
  <block id="b16f685ee226b95caaad151608f96a19" category="list-text">单击*Yes*确认备份策略。</block>
  <block id="a8f620ad18e6f3f85da2b7be0f178e00" category="paragraph"><block ref="a8f620ad18e6f3f85da2b7be0f178e00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0ccd5722bd3156105a495a57a9fcc19" category="paragraph">移动到*Monitoring*选项卡并监控备份作业的进度。</block>
  <block id="1a289d2ae0641f0084f363bc4bf29ed2" category="paragraph"><block ref="1a289d2ae0641f0084f363bc4bf29ed2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4a58eef11580db01b6b09289a7975b6" category="paragraph">请参见在SnapCenter 中还原SQL Server数据库所需的以下前提条件。</block>
  <block id="7ddc4eb994d251e5502d17ee020d88ad" category="list-text">目标实例必须联机且正在运行、才能完成还原作业。</block>
  <block id="4c5a871f473eb2bc6ade24dc7c9abda4" category="list-text">必须禁用计划对SQL Server数据库运行的SnapCenter 操作、包括在远程管理或远程验证服务器上计划的任何作业。</block>
  <block id="542e99a23c6a8ebaa0cc7df2db932223" category="list-text">如果要将自定义日志目录备份还原到备用主机、则SnapCenter 服务器和插件主机必须安装相同版本的SnapCenter。</block>
  <block id="81ec57bf05a69240771c922d647a651c" category="list-text">您可以将系统数据库还原到备用主机。</block>
  <block id="ec5b173df4b3313050ca64425e06f516" category="list-text">SnapCenter 可以在不使SQL Server集群组脱机的情况下还原Windows集群中的数据库。</block>
  <block id="042d132354b0d48ad24ee674bebdb6af" category="section-title">将SQL Server数据库上已删除的表还原到某个时间点</block>
  <block id="4b4968094e7a3d8c79f9bc8caa8b22e4" category="paragraph">要将SQL Server数据库还原到某个时间点、请完成以下步骤：</block>
  <block id="6df13174e00d0f623a406e9148d1548c" category="list-text">以下屏幕截图显示了SQL Server数据库在删除表之前的初始状态。</block>
  <block id="dbc2a72710499aa1cf69652093b3b999" category="paragraph"><block ref="dbc2a72710499aa1cf69652093b3b999" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d61cd88cd62206db3a9f9cab1565d3ad" category="paragraph">屏幕截图显示已从表中删除20行。</block>
  <block id="515d7eb17c3e413f271bddce4ba5f6bd" category="paragraph"><block ref="515d7eb17c3e413f271bddce4ba5f6bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d3c565402042673af1d4898a8ff52a9" category="list-text">登录到SnapCenter 服务器。从*Resues*选项卡中，选择数据库。</block>
  <block id="4863869b2ef5500a5ca305ffb9127ade" category="paragraph"><block ref="4863869b2ef5500a5ca305ffb9127ade" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a69269402d35f0cccddfd918911a97d9" category="list-text">选择最新的备份。</block>
  <block id="583e868d2c26244722b015fea16af076" category="list-text">在右侧，选择*Restore*。</block>
  <block id="6b153885f2f75c1ff541921d0081d74b" category="paragraph"><block ref="6b153885f2f75c1ff541921d0081d74b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39435af0deb93996df3394c1b2036fd8" category="list-text">此时将显示一个新窗口。选择*Restore*选项。</block>
  <block id="d7020dd530a8bef5050168b840079b00" category="list-text">将数据库还原到创建备份的同一主机。单击 * 下一步 * 。</block>
  <block id="5a718f24061d92ae97e1314ea8cb5fde" category="paragraph"><block ref="5a718f24061d92ae97e1314ea8cb5fde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="503e2d366ad9c17a4f549670670ad33e" category="list-text">对于*恢复类型*，请选择*所有日志备份*。单击 * 下一步 * 。</block>
  <block id="979629b8cf5823b370da8e731560f8cb" category="paragraph"><block ref="979629b8cf5823b370da8e731560f8cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68a3564e8eebf683090a9b209db57831" category="paragraph"><block ref="68a3564e8eebf683090a9b209db57831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e63cae13f4b41b3fe8c7e3fec3319f06" category="paragraph">*还原前选项:*</block>
  <block id="de181095a646159b289fbcdbcf419e7b" category="list-text">选择选项*在还原期间覆盖同名数据库*。单击 * 下一步 * 。</block>
  <block id="ad55b8f82ca21417dc4da683b1de0924" category="paragraph"><block ref="ad55b8f82ca21417dc4da683b1de0924" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed71c6a01179057b2d9bf0077204c6b" category="paragraph">*还原后选项:*</block>
  <block id="9cfc344a514e0de0c6b807382b26c075" category="list-text">选择选项*可操作、但不可用于还原其他事务日志*。单击 * 下一步 * 。</block>
  <block id="3ca7aa8d51b34a6dc37b4a42b98be1fe" category="paragraph"><block ref="3ca7aa8d51b34a6dc37b4a42b98be1fe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8420a5fc7b326a91c636b314aa454ec6" category="list-text">提供电子邮件设置。单击 * 下一步 * 。</block>
  <block id="735c30c428c3e84050f483061752691e" category="paragraph"><block ref="735c30c428c3e84050f483061752691e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8778317b34992e7e7c0354762cf0db9f" category="paragraph"><block ref="8778317b34992e7e7c0354762cf0db9f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4506debb4b8eeba79855725078a52afb" category="section-title">监控还原进度</block>
  <block id="9aff1c679025b15fa483f8f730686633" category="list-text">在*监控*选项卡中，单击恢复作业详细信息以查看恢复作业的进度。</block>
  <block id="1e062bc4b91bf77257da0f6d3b81e64d" category="paragraph"><block ref="1e062bc4b91bf77257da0f6d3b81e64d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2f265e204d2aa866e88f009e207aa68" category="list-text">还原作业详细信息。</block>
  <block id="1a50192540a2e763a60070967a8a04fd" category="paragraph"><block ref="1a50192540a2e763a60070967a8a04fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c5d988b8258420ba376fd703ae323bd" category="list-text">返回到SQL Server主机&gt;数据库&gt;表存在。</block>
  <block id="f3048bb52b66a41d7be00e28a6eaf957" category="paragraph"><block ref="f3048bb52b66a41d7be00e28a6eaf957" category="inline-image-macro-rx" type="image"></block></block>
  <block id="425103b894468ffe6015f984f2683d74" category="inline-link">TR-4714：《使用NetApp SnapCenter 的Microsoft SQL Server最佳实践指南》</block>
  <block id="9c42feba6d2410200720e2ceda752e13" category="list-text"><block ref="9c42feba6d2410200720e2ceda752e13" category="inline-link-rx"></block></block>
  <block id="ee50ef71e7fa5dbc3292cb856c5f8ee5" category="inline-link"><block ref="ee50ef71e7fa5dbc3292cb856c5f8ee5" category="inline-link-rx"></block></block>
  <block id="822d30d1b5bfcb219aa830739d5b89a0" category="paragraph"><block ref="822d30d1b5bfcb219aa830739d5b89a0" category="inline-link-rx"></block></block>
  <block id="818095849ac39056a1077a0f3a155684" category="inline-link">还原数据库的要求</block>
  <block id="0305a2a48c225d49081b5bccd776b23d" category="list-text"><block ref="0305a2a48c225d49081b5bccd776b23d" category="inline-link-rx"></block></block>
  <block id="9f413d2e154ecad28af03b6125df6837" category="inline-link"><block ref="9f413d2e154ecad28af03b6125df6837" category="inline-link-rx"></block></block>
  <block id="98c7a90e9f834e61987ed9dd4072a0f3" category="paragraph"><block ref="98c7a90e9f834e61987ed9dd4072a0f3" category="inline-link-rx"></block></block>
  <block id="9b256b378583dbf8a4aea7e4d96460ff" category="list-text">了解克隆的数据库生命周期</block>
  <block id="a35c63f82a8b880dd7d77b8868394548" category="inline-link"><block ref="a35c63f82a8b880dd7d77b8868394548" category="inline-link-rx"></block></block>
  <block id="622d6fd30919e1009adf5b3b6a9b61c4" category="paragraph"><block ref="622d6fd30919e1009adf5b3b6a9b61c4" category="inline-link-rx"></block></block>
  <block id="3a20c678f6addcc9b8fec17f91c8cfa4" category="cell">2023年5月5日</block>
  <block id="957df08ed5fbb9ca926ca88b2c974f4f" category="cell">新TR-4951：《AWS FSx for ONTAP 上Microsoft SQL Server的备份和恢复》</block>
  <block id="d5ae477fb23aecff7256445ae91344bc" category="sidebar">在AWS FSx for ONTAP 上备份和恢复Microsoft SQL Server</block>
  <block id="0f7a8130eb652cd33a4fa9cdefc41cc6" category="admonition">确保您已在EC2实例根卷中至少分配50G、以便有足够的空间来暂存Oracle安装文件。</block>
  <block id="f352a88dccea452ec98375dda0311257" category="paragraph">在配置了前提条件的情况下、以EC2-user身份登录到EC2实例、并使用sudo to root user配置Linux内核以进行Oracle安装。</block>
  <block id="35e176617d52dd956b8015d8ca19c32d" category="paragraph">使用FSx集群管理IP通过ssh以fsxadmin用户身份登录FSx集群、从命令行配置三个卷、以托管Oracle数据库二进制文件、数据和日志文件。</block>
  <block id="aa218771b85a8ecc41cc249ba90ea5f8" category="list-text">以EC2用户身份使用SSH密钥和EC2实例IP地址通过SSH登录到EC2实例。</block>
  <block id="71d434c6aec8c195bc1cd610cf2aadf7" category="list-text">重新启动EC2实例主机。</block>
  <block id="5fa683f35265bf7469d9de8c3afc1f42" category="list-text">从Grid home /u01/app/oracle/product/19.0.0/grid中、以Oracle用户身份启动<block ref="30c950549715985c6b7c7cd6990d0f4b" prefix=" " category="inline-code"></block> 用于网格基础架构安装。</block>
  <block id="26f36488ec442bab2ba0cda087d435eb" category="list-text">以root用户身份执行以下脚本：</block>
  <block id="ada113db66e2b1b6ed982918830cd12e" category="list-text">以root用户身份重新加载multipathd。</block>
  <block id="bdae34f2df30f19488bd87890188b905" category="list-text">从db1 home /u01/app/oracle/product/19.0.0/db1中、执行无提示纯软件DB安装。</block>
  <block id="f9db0d5335309d4958e09e8149d7de4d" category="list-text">以root用户身份运行<block ref="08030ad08b2b991d61b424afd8828758" prefix=" " category="inline-code"></block> 在仅安装软件后编写脚本。</block>
  <block id="2bba715ff3b85da75ce86da55f5d9173" category="list-text">以Oracle用户身份创建<block ref="c170c347c737b82ad62c48db1f7bff3c" prefix=" " category="inline-code"></block> 包含以下条目的文件：</block>
  <block id="c96739fe831515243fc940e9ee867ea3" category="list-text">以Oracle用户身份、使用dbca启动数据库创建。</block>
  <block id="2a00dbe4c39e81805212ab123d0995df" category="list-text">以Oracle用户身份、在创建数据库后验证Oracle Restart HA服务。</block>
  <block id="6c55fdff3e1fbf1476c8edd9169f1f2c" category="cell">添加了TR-4955：《使用Azure NetApp Files (ANF)和Azure VMware解决方案 (AVS)进行灾难恢复》</block>
  <block id="a7fb28a136e66b85611d0ab47d44e747" category="list-text">要使用部署Astra控制中心的Ansible攻略手册、您必须安装装有Ansible的Ubuntu或RHEL计算机。按照步骤进行操作<block ref="33c646d34972887e04f4f11763cd42b6" category="inline-link-rx"></block> 适用于Ubuntu和RHEL。</block>
  <block id="c9e4df26177106ff846782e8ee98f56a" category="list-text">要使用Ansible攻略手册部署Astra控制中心、您需要安装安装有Ansible的Ubuntu或RHEL计算机。按照步骤进行操作<block ref="33c646d34972887e04f4f11763cd42b6" category="inline-link-rx"></block> 适用于Ubuntu和RHEL。</block>
  <block id="8319a8c7a5b0b686057dbf3e7b4068f2" category="paragraph">有关裸机硬件和软件上的 Anthos 要求，请参见<block ref="ee9c468e431b4e6c834acacee08b5282" category="inline-link-rx"></block> 页面。</block>
  <block id="9b368ea783a99ed08472f5ee27e26dc9" category="paragraph">要确定用于手动配置客户端的网关地址，请参见<block ref="65651a617c871e663f36b036935811c9" category="inline-link-rx"></block>。</block>
  <block id="e88bacbfc81933567e64c9db4797fe2a" category="paragraph">作者：Niyaz Mohamed、NetApp解决方案工程部</block>
  <block id="b9f6e76ebb09998e4efe8f7d8cdfc1a1" category="paragraph">在云中的各个区域之间使用块级复制进行灾难恢复、是一种具有故障恢复能力且经济高效的方法、可以保护工作负载免受站点中断和数据损坏事件(例如勒索软件)的影响。通过Azure NetApp Files (ANF)跨区域卷复制、可以将在Azure VMware解决方案 (AVS) SDDC站点上使用Azure NetApp Files 卷作为主AVS站点上的NFS数据存储库运行的VMware工作负载复制到目标恢复区域中的指定二级AVS站点。</block>
  <block id="6d3f247317af532e62e79af4e327e266" category="paragraph">灾难恢复编排程序(Disaster Recovery Orchestrator、DRO)(一种具有UI的脚本解决方案)可用于无缝恢复从一个AVS SDDC复制到另一个AVS SDDC的工作负载。DRO可通过中断复制对等关系、然后将目标卷挂载为数据存储库、通过向AVS注册VM、直接在NSX-T (包括在所有AVS私有云中)上映射网络来自动恢复。</block>
  <block id="20e61ee0f35516bf40c8c03f94d14f55" category="paragraph"><block ref="20e61ee0f35516bf40c8c03f94d14f55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54c0031f2ddfceeed5c28d8d32afd359" category="section-title">前提条件和一般建议</block>
  <block id="608e90a0df6dcf86f27467ce0c8ce54a" category="inline-link">为Azure NetApp Files 创建卷复制</block>
  <block id="d855c43d14116e9cb3ec0930fee2f0dd" category="list-text">通过创建复制对等来验证是否已启用跨区域复制。请参见<block ref="56da0221e637860c42ff0ac193595610" category="inline-link-rx"></block>。</block>
  <block id="83fefb057e39fc350c2c2f61a5961065" category="list-text">您必须在源Azure VMware解决方案 私有云和目标Azure VMware私有云之间配置ExpressRoute全局范围。</block>
  <block id="6dce98a4bb089817cf9567558449180b" category="list-text">您必须具有可访问资源的服务主体。</block>
  <block id="aebc7c3350448dc30015a87c3d89c2b2" category="list-text">支持以下拓扑：主AVS站点到辅AVS站点。</block>
  <block id="f29fabe637a472bf5222b12a0bc5df77" category="inline-link">复制</block>
  <block id="83fd61302a69aa66e69339e94e4ca2cf" category="list-text">配置<block ref="6d62eaf7384c288add248477bcaf361d" category="inline-link-rx"></block> 根据业务需求和数据变更率为每个卷制定适当的计划。</block>
  <block id="7379a17a14e118aac108f1550bda8e15" category="admonition">不支持级联和扇入及扇出拓扑。</block>
  <block id="5f06c97396f318992ec4285e547a7199" category="section-title">部署Azure VMware解决方案</block>
  <block id="2d8e14d52496d7d3ab1bad5b1a8b0495" category="paragraph">。<block ref="b39fc18162263c3a663125bcc24a1d36" category="inline-link-rx"></block> (AVS)是一种混合云服务、可在Microsoft Azure公共云中提供功能全面的VMware SDDC。AVS是由Microsoft全面管理和支持并经过VMware验证的第一方解决方案 、它使用Azure基础架构。因此、客户可以获得用于计算虚拟化的VMware ESXi、用于超融合存储的vSAN以及用于网络连接和安全的NSX、同时充分利用Microsoft Azure的全球影响力、同类领先的数据中心设施以及与丰富的原生Azure服务和解决方案生态系统的邻近性。Azure VMware解决方案 SDDC与Azure NetApp Files 相结合、可提供最佳性能、同时将网络延迟降至最低。</block>
  <block id="c83dbf8bbfc81d6ea552177583a233a5" category="admonition">在初始版本中、DRO支持现有AVS SDDC集群。即将发布的版本将提供按需创建SDDC的功能。</block>
  <block id="96b758bcd58744b4e5415c3fbccd1a69" category="section-title">配置和配置Azure NetApp Files</block>
  <block id="2b636a8d03864ac97b7c30dc68f6f5a5" category="paragraph"><block ref="b56d3f248ea42ace920423401847f715" category="inline-link-rx"></block> 是一种高性能的企业级计量文件存储服务。按照中的步骤进行操作<block ref="1b959b45bbb3571141089802677ad765" category="inline-link-rx"></block> 配置Azure NetApp Files 并将其配置为NFS数据存储库、以优化AVS私有云部署。</block>
  <block id="2b1f9ff65c4506ccd4f1f6fb38649e87" category="section-title">为Azure NetApp Files提供支持的数据存储库卷创建卷复制</block>
  <block id="5b95256d6ffa7467ef57d3c3f61ac38e" category="paragraph">第一步是使用适当的频率和保留值为所需的数据存储库卷设置从AVS主站点到AVS二级站点的跨区域复制。</block>
  <block id="0ebe5ac118b62c003b65a9b3c4f80ef6" category="paragraph"><block ref="0ebe5ac118b62c003b65a9b3c4f80ef6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca34c3e14ec19e036e86327c18ee97ff" category="inline-link">修改服务级别</block>
  <block id="1ac65c0a16d2eabb709d6d5b908f1745" category="paragraph">按照中的步骤进行操作<block ref="57cbb08765e0326150e1717bd79f16bf" category="inline-link-rx"></block> 通过创建复制对等来设置跨区域复制。目标容量池的服务级别可以与源容量池的服务级别匹配。但是、对于此特定使用情形、您可以选择标准服务级别、然后选择<block ref="bacca1ab9fb985a705f3d2cbf4a7d58d" category="inline-link-rx"></block> 发生实际灾难或灾难恢复模拟时。</block>
  <block id="d9b36624eeaef41c5bf0404b4f9667f6" category="admonition">跨区域复制关系是前提条件、必须事先创建。</block>
  <block id="08735c190fa885a2bf1b7f36e1a2e8f3" category="paragraph">要开始使用DRO、请在指定的Azure虚拟机上使用Ubuntu操作系统、并确保满足前提条件。然后安装软件包。</block>
  <block id="265472db458c37e522224c854e725fa5" category="paragraph">*前提条件:*</block>
  <block id="2d2a5bfbd24c72950efbb0e05ff2c550" category="list-text">可以访问资源的服务主体。</block>
  <block id="291877ab9f9a26d5f7df0bcddeab5117" category="list-text">确保与源和目标SDDC以及Azure NetApp Files 实例建立了适当的连接。</block>
  <block id="5b0500a3592d99943c80ff54a25e978a" category="list-text">如果使用的是DNS名称、则应进行DNS解析。否则、请使用vCenter的IP地址。</block>
  <block id="f06e54cea384d49e828ee5affd70c17f" category="paragraph">*操作系统要求：*</block>
  <block id="a3b6d9fb713cfc6d2e0a7693c132f7a7" category="list-text">Ubuntu Focal 20.04 (LTS)指定的代理虚拟机上必须安装以下软件包：</block>
  <block id="0de0c471eabb6df904aed1160e17e5d0" category="list-text">Docker—编写</block>
  <block id="c8a224d936a830223e7341615d656cb8" category="list-text">JqChange<block ref="b1360c159d030cf3e3075d3ec21faf46" prefix=" " category="inline-code"></block> 对此新权限：<block ref="e89a7e38128b2d546718b48d40d827f7" prefix=" " category="inline-code"></block>。</block>
  <block id="dac09e97665f1ce51b0eda57eb8d689f" category="admonition">。<block ref="60254338249f657a0a83f98258a56bfe" prefix=" " category="inline-code"></block> 脚本会执行所有必需的前提条件。</block>
  <block id="8b389947da1beb9b783d0f6d93ff7379" category="paragraph">步骤如下：</block>
  <block id="198238f0cb3b3c1ae0f172d5550ed1b1" category="admonition">代理必须安装在二级AVS站点区域或主AVS站点区域中、其AZ不能与SDDC相同。</block>
  <block id="0034cd44b3a2a2ebcd2491e08285c630" category="list-text">解压缩软件包、运行部署脚本、然后输入主机IP (例如、 <block ref="53c2d28edefdf501ab7c92e02a0c1687" prefix=" " category="inline-code"></block>）。</block>
  <block id="e458c281a9aec07ea6c3bbd3fd4dee05" category="list-text">使用以下凭据访问UI：</block>
  <block id="257b3e8f9b30327f40243dfa0e6c25da" category="list-text">用户名：<block ref="21232f297a57a5a743894a0e4a801fc3" prefix=" " category="inline-code"></block></block>
  <block id="1b97f2409234d30285a10523ee6223cf" category="list-text">密码：<block ref="21232f297a57a5a743894a0e4a801fc3" prefix=" " category="inline-code"></block></block>
  <block id="0300b90d969cf3be8deea87c973b7034" category="paragraph"><block ref="0300b90d969cf3be8deea87c973b7034" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4a41f8b4753b15c1780f1b356cc4d36" category="paragraph">正确配置Azure NetApp Files 和AVS后、您可以开始配置DRO、以便自动将工作负载从主AVS站点恢复到二级AVS站点。NetApp建议在二级AVS站点中部署DRO代理并配置ExpressRoute网关连接、以便DRO代理可以通过网络与相应的AVS和Azure NetApp Files 组件进行通信。</block>
  <block id="fd44f09b19421de944f8952f94dfe971" category="paragraph">第一步是添加凭据。DRO需要具有发现Azure NetApp Files 和Azure VMware解决方案 的权限。您可以通过创建和设置Azure Active Directory (AD)应用程序以及获取DRO所需的Azure凭据来为Azure帐户授予所需权限。您必须将服务主体绑定到Azure订阅、并为其分配具有所需相关权限的自定义角色。添加源和目标环境时、系统会提示您选择与服务主体关联的凭据。您需要先将这些凭据添加到DRO、然后才能单击添加新站点。</block>
  <block id="0ea5490a5da4ab07ce30763f4395b20a" category="paragraph">要执行此操作、请完成以下步骤：</block>
  <block id="e496bc8a09ef0bff2ed49dfc9746a61f" category="list-text">在支持的浏览器中打开DRO、并使用默认用户名和密码 <block ref="21232f297a57a5a743894a0e4a801fc3" prefix="(" category="inline-code"></block><block ref="21232f297a57a5a743894a0e4a801fc3" prefix="/" category="inline-code"></block>）。首次登录后、可以使用更改密码选项重置密码。</block>
  <block id="4ad2c508aa57459523225fea48cf2928" category="list-text">在DRO控制台的右上角，单击*Settings*图标，然后选择*凭 据*。</block>
  <block id="9a9321b8db1cac9beeecfa829e763dbe" category="list-text">单击Add New凭据、然后按照向导中的步骤进行操作。</block>
  <block id="f61fc6d956a5905e154da7bdc578662b" category="list-text">要定义凭据、请输入有关授予所需权限的Azure Active Directory服务主体的信息：</block>
  <block id="a5f3bff0d7667c1bb37c185dbaac3ff8" category="list-text">凭据名称</block>
  <block id="7131a7a6bfe81200d21d5a33c64847b6" category="list-text">租户ID</block>
  <block id="1b4739e491387ef5d8a546854308e5fe" category="list-text">客户端密钥</block>
  <block id="9bf79c7f10eadd0b612b8c354ad19bdc" category="list-text">订阅ID</block>
  <block id="3fb6b543576d4e6de4d8330552086cbf" category="paragraph">创建AD应用程序时、您应已捕获此信息。</block>
  <block id="7c0994c6d36bea4a46a67ee7be492a0c" category="list-text">确认有关新凭据的详细信息、然后单击添加凭据。</block>
  <block id="860e0c902a247fd6fc5ba818a2e4c119" category="paragraph"><block ref="860e0c902a247fd6fc5ba818a2e4c119" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a569d23d0a18f8e5cdf96a9dbe0b318" category="paragraph">添加凭据后、即可发现主AVS站点和二级AVS站点(vCenter和Azure NetApp Files 存储帐户)并将其添加到DRO中。要添加源站点和目标站点、请完成以下步骤：</block>
  <block id="01822078d676b28b71765f19b2abc174" category="list-text">转到*Discover (发现)*选项卡。</block>
  <block id="27976ab4d078e6248b695907df6518a4" category="list-text">单击*添加新站点*。</block>
  <block id="aed2a8b3a917727d4b43e29919cfccde" category="list-text">添加以下主AVS站点(在控制台中指定为*Source*)。</block>
  <block id="889354880d57dd4dd4f8f3038526d974" category="list-text">SDDC vCenter</block>
  <block id="05f07fc27436b04820daaf552aae5b87" category="list-text">Azure NetApp Files 存储帐户</block>
  <block id="996c97afe4bc38c9853d27530a3df15e" category="list-text">添加以下二级AVS站点(在控制台中指定为*目标*)。</block>
  <block id="a4005489f8d17cfe23209801e4384811" category="paragraph"><block ref="a4005489f8d17cfe23209801e4384811" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e505f2bafbc80afa614f045310efd28" category="list-text">通过单击*源*添加站点详细信息，输入友好的站点名称，然后选择连接器。然后单击 * 继续 * 。</block>
  <block id="a8984cd143f24c2d3e7b4079bac3b8d6" category="admonition">为了便于演示、本文档将介绍如何添加源站点。</block>
  <block id="03cb7c845b27b00d2fd5fcd6ca22399f" category="list-text">更新vCenter详细信息。为此、请从主AVS SDDC的下拉列表中选择凭据、Azure区域和资源组。</block>
  <block id="ae848f14f01425473dd19fd9cfcc5fa9" category="list-text">DRO列出了该区域内的所有可用SDDC。从下拉列表中选择指定的私有云URL。</block>
  <block id="c02b7f0ffcc1d4da79302adf29a66e56" category="list-text">输入<block ref="2a07e8a0872e7f8458933397e500f4e7" prefix=" " category="inline-code"></block> 用户凭据。可从Azure门户访问此内容。请按照本中所述的步骤进行操作<block ref="9a765fe55ce09b5bcc5b9862623e77f3" category="inline-link-rx"></block>。完成后，单击*继续*。</block>
  <block id="4cc62b4cb463cf57b77ddc7d6cb1e329" category="paragraph"><block ref="4cc62b4cb463cf57b77ddc7d6cb1e329" category="inline-image-macro-rx" type="image"></block></block>
  <block id="becc83b5605c625633fe2d8e0b8b380e" category="list-text">通过选择Azure资源组和NetApp帐户、选择源存储详细信息(ANF)。</block>
  <block id="5296858fb0caa0a11f03202fcd7425e6" category="list-text">单击*创建站点*。</block>
  <block id="81f0a9cde4a335215c94ace73a76a98a" category="paragraph"><block ref="81f0a9cde4a335215c94ace73a76a98a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b43e8d7859f4e668e88bbec1012614f" category="paragraph">添加后、DRO将执行自动发现、并显示具有从源站点到目标站点的相应跨区域副本的VM。DRO会自动检测VM使用的网络和网段并将其填充。</block>
  <block id="5b775ba0f30d059b52a43b406cc2e7c3" category="paragraph"><block ref="5b775ba0f30d059b52a43b406cc2e7c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e9078f0eac4eabfab52411e25a94a45" category="paragraph">下一步是将所需的VM作为资源组分组到其功能组中。</block>
  <block id="fd8b6f30869f4dd563c888ca814a33a9" category="paragraph">添加平台后、将要恢复的VM分组到资源组中。使用DRO资源组、您可以将一组依赖虚拟机分组到逻辑组中、这些逻辑组包含启动顺序、启动延迟以及可在恢复时执行的可选应用程序验证。</block>
  <block id="d77884116359bfb00f05bd00d3e8d049" category="paragraph">要开始创建资源组，请单击*Create New Resource Group*菜单项。</block>
  <block id="86cf73bd568d170320c05da514d80d57" category="list-text">访问*Resource Group*ps并单击*Create New Resource Group*。</block>
  <block id="d05668f7a7c152b43c71f4e10ff83eb2" category="paragraph"><block ref="d05668f7a7c152b43c71f4e10ff83eb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="729041edea69eb39efcf6d3bb4958c20" category="list-text">在“新建资源组”下，从下拉列表中选择源站点，然后单击*Create*。</block>
  <block id="8b2c5e430ee578e1098fd0dd29ed3832" category="list-text">提供资源组详细信息，然后单击*Continue*。</block>
  <block id="2036968de3c8690e533f2393b6eb23f2" category="list-text">使用搜索选项选择适当的VM。</block>
  <block id="9bdc69df94caa6e66eeb26bc6f11fe0b" category="list-text">为所有选定虚拟机选择*引导顺序*和*引导延迟*(秒)。通过选择每个虚拟机并设置其优先级来设置启动顺序。所有虚拟机的默认值均为3。选项如下：</block>
  <block id="7bf779821eb857b7312d9fd21e28409c" category="list-text">要启动的第一个虚拟机</block>
  <block id="7a1920d61156abc05a60135aefe8bc67" category="list-text">Default</block>
  <block id="d3e1ce3079804318222f44cc5797acb6" category="list-text">要启动的最后一个虚拟机</block>
  <block id="aae5a12fc4a2fe256183b387a6d13520" category="paragraph"><block ref="aae5a12fc4a2fe256183b387a6d13520" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2ca70125ce517c525f91333e5647c922" category="paragraph"><block ref="2ca70125ce517c525f91333e5647c922" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01768278e2504e3e5697ae9ff4974842" category="paragraph">您必须制定在发生灾难时恢复应用程序的计划。从下拉列表中选择源和目标vCenter平台、选择要包含在此计划中的资源组、同时还包括应用程序应如何还原和启动的分组(例如、域控制器、第1层、第2层等)。计划通常也称为蓝图。要定义恢复计划，请导航到“复制计划”选项卡，然后单击*New Replication Plan*。</block>
  <block id="578c9ba6f5077731855dfceecbaaa69e" category="list-text">导航到*复制计划*，然后单击*创建新复制计划*。</block>
  <block id="ab134bc6f5a247f30cd04a21a42a6e3e" category="paragraph"><block ref="ab134bc6f5a247f30cd04a21a42a6e3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc4a81ccf4d35c2d79e13b8d9e764ac3" category="list-text">在*New Replication Plan*上，为该计划提供一个名称，并通过选择源站点、关联的vCenter、目标站点和关联的vCenter来添加恢复映射。</block>
  <block id="111af38498fbc99787f757630f9b6502" category="paragraph"><block ref="111af38498fbc99787f757630f9b6502" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb0d3f2303ecd179cbb41b4a89ce5c67" category="list-text">恢复映射完成后，选择*Cluster Mapping*。</block>
  <block id="e7c6ba3de84b5549973968926ac0d23b" category="paragraph"><block ref="e7c6ba3de84b5549973968926ac0d23b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2246eeda2d9dd58b6d0c476b7f59257" category="list-text">完成后、将网络映射设置为相应的网段。区块应已在二级AVS集群上配置、要将虚拟机映射到这些区块、请选择适当的区块。</block>
  <block id="853f23cf3569d309e9916974d1a51876" category="list-text">系统会根据所选虚拟机自动选择数据存储库映射。</block>
  <block id="cbbdb677d49130a99047900675796b52" category="admonition">跨区域复制(CRR)在卷级别进行。因此、驻留在相应卷上的所有VM都会复制到CRR目标。请确保选择属于数据存储库的所有虚拟机、因为只会处理属于复制计划的虚拟机。</block>
  <block id="8799c7fd170fa15c94184f5e4db288d8" category="paragraph"><block ref="8799c7fd170fa15c94184f5e4db288d8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="884f1298b3bdd040ffb399dbc04901f0" category="list-text">在VM详细信息下、您可以选择调整VM CPU和RAM参数的大小。如果您要将大型环境恢复到较小的目标集群、或者在执行灾难恢复测试时无需配置一对一物理VMware基础架构、则此功能非常有用。此外、还可以修改资源组中所有选定VM的启动顺序和启动延迟(秒)。如果需要对您在资源组引导顺序选择期间选择的内容进行任何更改，则还可以使用一个附加选项来修改引导顺序。默认情况下、系统会使用在资源组选择期间选择的引导顺序、但在此阶段可以执行任何修改。</block>
  <block id="f178cb66ab34b8fced158ec43b1b9b9d" category="paragraph"><block ref="f178cb66ab34b8fced158ec43b1b9b9d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be14c33c0e1307565b1b4265090e6004" category="list-text">单击*创建复制计划*。创建复制计划后，您可以根据需要执行故障转移、测试故障转移或迁移选项。</block>
  <block id="3d1083389392951c6f9506a1a837c338" category="paragraph"><block ref="3d1083389392951c6f9506a1a837c338" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eabe44ce43c0d27a3c7ed6090f8da8fe" category="paragraph">在故障转移和测试故障转移选项期间、将使用最新的快照、或者可以从时间点快照中选择特定快照。如果您正面临勒索软件等损坏事件、其中最新副本已被泄露或加密、则时间点选项非常有用。DRO显示所有可用的时间点。</block>
  <block id="b7ff5d05bb51bb1ba1f1948430b7f0ea" category="paragraph"><block ref="b7ff5d05bb51bb1ba1f1948430b7f0ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b20ccdef37c2fb3ba1dd6564f66dfd75" category="paragraph">要使用复制计划中指定的配置触发故障转移或测试故障转移，可以单击*Failover或*Test Failover。您可以在任务菜单中监控复制计划。</block>
  <block id="a2d45a6a3294c0f5907fc2a39cdf9427" category="paragraph"><block ref="a2d45a6a3294c0f5907fc2a39cdf9427" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c599217b8b3d1ed882a32d34779619f5" category="paragraph">触发故障转移后、可以在二级站点AVS SDDC vCenter (VM、网络和数据存储库)中看到恢复的项目。默认情况下、VM会恢复到工作负载文件夹。</block>
  <block id="22ab0c39f2f3febca61797b34cd8fabf" category="paragraph"><block ref="22ab0c39f2f3febca61797b34cd8fabf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b1403207c6b26d5ba9741226bc07955f" category="paragraph">可以在复制计划级别触发故障恢复。如果发生测试故障转移、可使用拆卸选项回滚更改并删除新创建的卷。与故障转移相关的故障恢复过程分为两步。选择复制计划并选择*反向数据同步*。</block>
  <block id="d653f5939cefc7bad010a2de7775f6b3" category="paragraph"><block ref="d653f5939cefc7bad010a2de7775f6b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85ee6e66825baba0f8198b3dd30e87f0" category="paragraph">完成此步骤后、触发故障恢复以移回主AVS站点。</block>
  <block id="2cf097957a2bdcb5522a184f3700c7cc" category="paragraph"><block ref="2cf097957a2bdcb5522a184f3700c7cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="080e59f9730db0f9835804935f719573" category="paragraph"><block ref="080e59f9730db0f9835804935f719573" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5272991f0466fbd09b9b828354b71fbf" category="paragraph">从Azure门户中、我们可以看到、已将作为读/写卷映射到二级站点AVS SDDC的相应卷的复制运行状况已断开。在测试故障转移期间、DRO不会映射目标卷或副本卷。相反、它会为所需的跨区域复制快照创建一个新卷、并将该卷公开为数据存储库、这样会占用容量池中的额外物理容量、并确保源卷不会被修改。值得注意的是、复制作业可以在灾难恢复测试或鉴别工作流期间继续运行。此外、此过程还可确保在发生错误或恢复损坏的数据时、可以清除恢复、而不会造成副本被销毁的风险。</block>
  <block id="a5f63dad4856a347b9b7fc5a308fa216" category="paragraph">从勒索软件中恢复可能是一项艰巨的任务。具体而言、IT组织可能难以确定安全返回点、以及在确定安全返回点后、如何确保恢复的工作负载不会再次受到攻击(例如、恶意软件休眠或通过易受攻击的应用程序)。</block>
  <block id="0dd7fb82cd5ca2189a0483762c3ad4cd" category="paragraph">DRO允许组织从任何可用时间点进行恢复、从而解决了这些问题。然后、工作负载将恢复到正常运行但又孤立的网络、以便应用程序可以正常运行并相互通信、但不会受到任何南北流量的影响。此过程为安全团队提供了一个安全的地方来进行取证并识别任何隐藏或休眠的恶意软件。</block>
  <block id="97873cb64dd3b9de78b8dbf3541c1cb7" category="paragraph">Azure NetApp Files 和Azure VMware灾难恢复解决方案 为您提供以下优势：</block>
  <block id="ea9b3d561aaa24c619c8bd8b411ed6df" category="list-text">利用高效且有弹性的Azure NetApp Files 跨区域复制。</block>
  <block id="616f4cdbcb09376a462dda8ef67bbb64" category="list-text">通过保留快照恢复到任何可用时间点。</block>
  <block id="848e2ec26d0beb2339e91c67f385d9d3" category="list-text">完全自动执行所有必要步骤、以便从存储、计算、网络和应用程序验证步骤中恢复成百上千个VM。</block>
  <block id="5248044020773fc0da962da4f0c97062" category="list-text">工作负载恢复利用"从最新快照创建新卷"过程、但不会处理复制的卷。</block>
  <block id="c197954fd8a0b84ad03ef564ae13bcf5" category="list-text">避免卷或快照上的任何数据损坏风险。</block>
  <block id="a709ce349016e4ae3d5d0c4d9dfbd871" category="list-text">在灾难恢复测试工作流期间避免复制中断。</block>
  <block id="95a8950fc6379e50b04cfa6f61a36d11" category="list-text">将灾难恢复数据和云计算资源用于灾难恢复之外的工作流、例如开发/测试、安全测试、修补和升级测试以及修复测试。</block>
  <block id="8f3b531b04dadc9320674c0e42b1a487" category="list-text">CPU和RAM优化支持恢复到较小的计算集群、有助于降低云成本。</block>
  <block id="f64a0d6a033b67f67edba41e1bd8152c" category="inline-link"><block ref="f64a0d6a033b67f67edba41e1bd8152c" category="inline-link-rx"></block></block>
  <block id="5b7bf21e5e287cfaa11c6e67e2073b27" category="paragraph"><block ref="5b7bf21e5e287cfaa11c6e67e2073b27" category="inline-link-rx"></block></block>
  <block id="7b6802bdcfa19b11a01e1fa2b2f6010d" category="list-text">跨区域复制Azure NetApp Files 卷</block>
  <block id="0bfb405aa5c708395d0f8a337e30b65e" category="inline-link"><block ref="0bfb405aa5c708395d0f8a337e30b65e" category="inline-link-rx"></block></block>
  <block id="a931d15f7c97401d5f17df4edb5f3ad6" category="paragraph"><block ref="a931d15f7c97401d5f17df4edb5f3ad6" category="inline-link-rx"></block></block>
  <block id="3de91620717e92c6908e156194bcf68a" category="list-text"><block ref="3de91620717e92c6908e156194bcf68a" category="inline-link-rx"></block></block>
  <block id="4af3bddf434f9895d84aceb3a82b8c71" category="inline-link"><block ref="4af3bddf434f9895d84aceb3a82b8c71" category="inline-link-rx"></block></block>
  <block id="e01e170739dafe7d8690e443b02ffa37" category="paragraph"><block ref="e01e170739dafe7d8690e443b02ffa37" category="inline-link-rx"></block></block>
  <block id="e0d783f10c59be2d7b43e92ef42c1540" category="list-text">部署和配置Azure VMware解决方案</block>
  <block id="164a8b646e75ab3984103d6026f5a8f3" category="inline-link"><block ref="164a8b646e75ab3984103d6026f5a8f3" category="inline-link-rx"></block></block>
  <block id="42bdffc2ff584c6491929199aa95fdef" category="paragraph"><block ref="42bdffc2ff584c6491929199aa95fdef" category="inline-link-rx"></block></block>
  <block id="e41aedb86788cb5e4409a06bc4b16279" category="inline-link-macro">借助ANF和AVS实现灾难恢复(Disaster Recovery、DRO)</block>
  <block id="fa907e97b7f9d454ad88521e57137cfe" category="paragraph">有关使用Veeam还原VM的详细信息、请参见一节 <block ref="00a6103995562d7a2009f890514665b7" category="inline-link-macro-rx"></block>。</block>
  <block id="6afeb7a829e309830236eb7d13dafb4b" category="list-text">已建立二级SnapCenter 服务器、并已使用一节中所述的步骤完成SnapCenter 数据库还原和配置 <block ref="c05666153a222d3eb881a4a76532fde4" category="inline-link-macro-rx"></block></block>
  <block id="7ddf1a9656f14a9883540ea830093e20" category="list-text">已建立二级SnapCenter 服务器、并已使用本节所述的步骤还原SnapCenter 数据库和配置文件 <block ref="c05666153a222d3eb881a4a76532fde4" category="inline-link-macro-rx"></block></block>
  <block id="52463fc86a53e3e78c2a77069889838f" category="paragraph">有关驻留在AWS中的SnapCenter 服务器上要完成的步骤列表、请参见一节 <block ref="1d252dd870179a0ef2258cd4837b106d" category="inline-link-macro-rx"></block>。</block>
  <block id="5de00fbb5f941e4a6da089a424224039" category="paragraph">有关完成应用程序VM故障转移所需步骤的完整列表、请参见一节 <block ref="26a23d90f8b49a2bef24fd9bd32f1a97" category="inline-link-macro-rx"></block>。</block>
  <block id="5fe36f3a6d3cc4a34d1f045b7cd14ac3" category="paragraph">命令的预期输出：</block>
  <block id="8c649830ad367719c501f8fc9ba4d387" category="inline-link-macro">单击此处了解详细说明</block>
  <block id="d2068521e0b773365643b7537a1caa7f" category="list-text">配置 Linux 主机，以便用作 Ansible 控制主机<block ref="27248a019dbeee842c240071693b6fb8" category="inline-link-macro-rx"></block></block>
  <block id="8ac2da66fa1da7b6cb74292caea13c74" category="sidebar">借助Azure NetApp Files 和AVS实现灾难恢复(Disaster Recovery、DRO)</block>
  <block id="e44925cb6b49254bb6fed8c411e15c4f" category="cell">2023年5月19日</block>
  <block id="889806f0e07f1d0dd0672d1a1cd2cddf" category="cell">2023年5月16日</block>
  <block id="cc03678283413ffdf1b4ab27cc12e6d9" category="cell">采用Red Hat OpenShift的混合多云</block>
  <block id="b04739a706412f23675293cb0bce6e3d" category="cell">在侧栏中添加了新标题和新内容</block>
  <block id="0963e46246e2115e2405b677b6116fd3" category="cell">已添加新内容</block>
  <block id="eb4f0aac15f7c10d0cae14b084022516" category="cell">2023年5月10日</block>
  <block id="7e9f968a139a25a62b6f7f581469c718" category="doc">其他文档</block>
  <block id="8b35ba920859760c3b7ab07c1f52df88" category="inline-link-macro">OpenShift容器平台产品文档</block>
  <block id="010bce66eda52af8597098e33d12e767" category="inline-link-macro">安装OpenShift容器平台集群</block>
  <block id="9e4f27bab2ba4dcc223eabe15d060c22" category="inline-link-macro">高级集群管理产品文档</block>
  <block id="1a28b2dbd24896f9ae4e7ea905e79d07" category="inline-link-macro">使用ACM创建集群</block>
  <block id="88c39d9e07dd53d7dfe71bcc634dd892" category="inline-link-macro">在OpenShift上部署Red Hat Quay</block>
  <block id="9c634046a90a62883b122e76b9afcef2" category="inline-link-macro">Astra 控制中心</block>
  <block id="8c9552895e8b32d168c001c8cb0d41ac" category="inline-link-macro">NetApp Verda</block>
  <block id="d2154db2b88b25388e0f4a7a9080bfc9" category="inline-link-macro">基于AWS的Red Hat OpenShift服务</block>
  <block id="fb01274428608cf188d499747738ea90" category="doc">适用于Red Hat OpenShift容器工作负载的NetApp混合云解决方案</block>
  <block id="8de8322672190a0154e15dd15a2de38b" category="paragraph">NetApp发现、越来越多的客户正在利用围绕Kubnetes构建的容器和流程编排平台来打造现代化的传统企业级应用程序以及构建新应用程序。Red Hat OpenShift容器平台就是我们看到许多客户采用的一个示例。</block>
  <block id="91971d724db8a4834abc9e257cf521ab" category="paragraph">随着越来越多的客户开始在企业中采用容器、NetApp已做好充分准备、可以满足有状态应用程序的持久存储需求以及数据保护、数据安全和数据迁移等传统数据管理需求。但是、可以使用不同的策略、工具和方法来满足这些需求。</block>
  <block id="46b942b569445b51bc9a3813940e581b" category="paragraph">**NetApp ONTAP 基于下面列出的存储选项，可为容器和部署提供安全性、数据保护、可靠性和灵活性。</block>
  <block id="d8b17b6efcac44f3002f0754abe68b9a" category="list-text">内部环境中的自行管理存储：</block>
  <block id="fc86d68de50b558bf0e36b38845f3b9e" category="list-text">NetApp光纤连接存储(FAS)、NetApp全闪存FAS 阵列(AFF)、NetApp全SAN阵列(ASA)和ONTAP Select</block>
  <block id="427332fc886acd822d0fc6c0ee1a74f8" category="list-text">内部部署中由提供商管理的存储：</block>
  <block id="bce509449eda5b3850faf5d2f827807a" category="list-text">NetApp Keystone 提供存储即服务(STaaS)</block>
  <block id="3e828a47721931842418753fbd6ce4a9" category="list-text">云中的自行管理存储：</block>
  <block id="9e41a33f3c647aba754b638fb834ccb6" category="list-text">NetApp Cloud Volumes ONTAP (CVO)可在超大容量云中提供自行管理的存储</block>
  <block id="23c3c663b762f1321d6375c1b3ce61f8" category="list-text">云中由提供商管理的存储：</block>
  <block id="51420fda4b100ff1cec3007a9f85615d" category="list-text">Cloud Volumes Service for Google Cloud (CVS)、Azure NetApp Files (ANF)、Amazon FSx for NetApp ONTAP 可在超云中提供完全托管的存储</block>
  <block id="7737d05ae0cdd6b2fbe4cd4e6c7b3873" category="paragraph"><block ref="7737d05ae0cdd6b2fbe4cd4e6c7b3873" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3fffb84816afb046037dcf3d52d23a4" category="paragraph">**NetApp BlueXP**使您能够从一个控制平台/接口管理所有存储和数据资产。</block>
  <block id="a28e6578744ceeb545878235d414e497" category="paragraph">您可以使用BlueXP创建和管理云存储(例如Cloud Volumes ONTAP 和Azure NetApp Files)、移动、保护和分析数据以及控制许多内部和边缘存储设备。</block>
  <block id="ccc05eb250d1954656f9e96b38186f1f" category="paragraph">**NetApp Asta Trident**是一款符合CSI的存储编排程序，支持快速、轻松地使用由上述各种NetApp存储选项提供支持的永久性存储。它是由NetApp维护和支持的开源软件。</block>
  <block id="4f1e9419dd2093869735a950da6bb17d" category="paragraph"><block ref="4f1e9419dd2093869735a950da6bb17d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5c4a3945e0cdaa7b705b00128180df4" category="paragraph">业务关键型容器工作负载所需的不仅仅是永久性卷。他们的数据管理要求也需要保护和迁移应用程序Kubbernetes对象。</block>
  <block id="e57b3f1bdaee7a2b21647555142e9653" category="admonition">除了用户数据之外、应用程序数据还包括Kubenetes对象：以下是一些示例： - Kubenetes对象、例如Pod规格、PVC、部署、服务-自定义配置对象、例如配置映射和密钥-持久数据、例如Snapshot副本、备份、克隆-自定义资源、例如CRS和CRD</block>
  <block id="4b675e54aa1095b2b20f8c4019de37b0" category="inline-link-macro">Astra 文档</block>
  <block id="dadb28b9e22a0754b9d16e0e88a88c13" category="paragraph">**NetApp Asta Control**作为完全托管和自我管理软件提供，可提供流程编排，实现强大的应用程序数据管理。请参见 <block ref="40f1af172b66f2d17da6144d50df0f84" category="inline-link-macro-rx"></block> 有关Asta系列产品的更多详细信息。</block>
  <block id="f15a63879d079401ef5fb8794ae8190d" category="paragraph">本参考文档使用NetApp Asta Control Center验证了在RedHat OpenShift容器平台上部署的基于容器的应用程序的迁移和保护。此外、解决方案 还提供了有关部署和使用Red Hat高级集群管理(ACM)来管理容器平台的详细信息。本文档还重点介绍了使用Asta Trident CSI配置程序将NetApp存储与Red Hat OpenShift容器平台集成的详细信息。Astra Control Center部署在集线器集群上、用于管理容器应用程序及其永久性存储生命周期。最后、它还提供了一个解决方案 、用于在AWS (ROSA)中使用Amazon FSx for NetApp ONTAP (FSxN)作为永久性存储的受管Red Hat OpenShift集群上对容器工作负载进行复制、故障转移和故障恢复。</block>
  <block id="bd61a264427ea5719a7598c9842bbdfc" category="summary">采用Red Hat OpenShift容器平台的NetApp混合多云解决方案是一组战略和技术功能、这些功能展示了为内部和公共云中有状态容器工作负载轻松安排数据保护和迁移功能。</block>
  <block id="05a4585adb3c11a4d6ec744287d9c477" category="doc">采用Red Hat OpenShift容器工作负载的NetApp混合云</block>
  <block id="a52f1a39d266680457efce511e919b88" category="doc">解决方案 验证中使用的各种组件的版本</block>
  <block id="5516d7182615c828448d9b348501eb1e" category="paragraph">解决方案 使用OpenShift容器平台、OpenShift高级集群管理器、NetApp ONTAP 和NetApp Asta控制中心测试和验证迁移和集中式数据保护。</block>
  <block id="b4244340f0935c1a99a9f6b1a5c587ed" category="cell">* 组件 *</block>
  <block id="45cc01ab5f209e8760027e9c30097025" category="cell">* 版本 *</block>
  <block id="26ec1d0c63ce9794e6d0c6b5a70689a1" category="cell">*VMware*</block>
  <block id="9b458d345f0a59c6e2e7426349b2c81a" category="cell">vSphere Client 8.0.0.10200 VMware ESXi、8.0.0、20842819</block>
  <block id="02693cb8abf2b367ad7f12a7028387d0" category="cell">*集线器集群*</block>
  <block id="d47e05659d8c9961d0025578f9bedf81" category="cell">OpenShift 4.11.34</block>
  <block id="6f63ca7a8d1582f6c5aecf3d98e15fea" category="cell">*源集群和目标集群*</block>
  <block id="e777190715e6ef3eedd09080d17156dc" category="cell">OpenShift 4.12.9、在内部和AWS中</block>
  <block id="2740a3f02c7241398a3bd90d72be7a23" category="cell">*NetApp Asta三端*</block>
  <block id="52bed1949aec792e351725583d586e38" category="cell">TRIdent服务器和客户端23.04.0</block>
  <block id="9dbea4b6bf9a3c7db93960270b06cf21" category="cell">*NetApp Astra Control Center*</block>
  <block id="2bc5b4067c51b6d01052f2895cd2802f" category="cell">ACC 22.11.0-82</block>
  <block id="ac0df33e7e9d7127f5798ad2f7ea1e57" category="cell">*NetApp ONTAP *</block>
  <block id="dc590521b479337b3c16fdc9b86fa862" category="cell">*AWS FSx for NetApp ONTAP *</block>
  <block id="725b1ab4e3e24634a0c63fe0aacf72c9" category="cell">单可用性(AZ)</block>
  <block id="602738666fc517b0fa1a28acbaa8753f" category="doc">适用于Red Hat OpenShift容器工作负载的NetApp混合云解决方案的价值主张</block>
  <block id="4995f10735f80116c1a9e76d0483dea0" category="paragraph">大多数客户并不只是在没有任何现有基础架构的情况下开始构建基于Kubennet的环境。他们可能是一家传统的IT公司、在虚拟机(例如、在大型VMware环境中)上运行大多数企业级应用程序。然后、他们开始构建基于容器的小型环境、以满足现代应用程序开发团队的需求。这些计划通常从小规模入手、随着团队学习这些新技术和技能、并开始认识到采用这些新技术和技能的诸多优势、这些计划开始变得越来越普及。对客户来说、好消息是NetApp可以满足这两种环境的需求。这套采用Red Hat OpenShift的混合多云解决方案将赋予NetApp客户采用现代云技术和服务的能力、而无需全面革新整个基础架构和组织。无论客户应用程序和数据托管在内部环境、云中、虚拟机上还是容器上、NetApp都可以提供一致的数据管理、保护、安全性和可移动性。借助这些新解决方案、NetApp数十年来在内部数据中心环境中提供的相同价值将在整个企业数据范围内实现、而无需投入大量资金来重新利用、获得新技能或组建新团队。无论客户处于云之旅的哪个阶段、NetApp都能很好地帮助他们解决这些业务挑战。</block>
  <block id="d22e1212d6861bd9f5154f99bd42f075" category="paragraph">采用Red Hat OpenShift的NetApp混合多云：</block>
  <block id="f4a12877ded47f570208ae2fd2860bd6" category="list-text">为客户提供经验证的设计和实践、展示在将Red Hat OpenShift与基于NetApp的存储解决方案结合使用时、客户管理、保护、保护和迁移其数据和应用程序的最佳方式。</block>
  <block id="67eaac350e7deee0d9da0da55965c85d" category="list-text">为在VMware环境、裸机基础架构或这两者的组合中使用NetApp存储运行Red Hat OpenShift的客户提供最佳实践。</block>
  <block id="069709db14b900262db621bbd5187e74" category="list-text">演示内部环境和云环境以及同时使用这两者的混合环境的策略和选项。</block>
  <block id="6f83ad56268110343d9aef0022b7f493" category="doc">适用于Red Hat OpenShift容器工作负载的受支持NetApp混合云解决方案</block>
  <block id="e0484d0d50bc76897c6ed88afa8d69bf" category="paragraph">解决方案 使用OpenShift容器平台(OCP)、OpenShift高级集群管理器(ACM)、NetApp ONTAP 、NetApp BlueXP和NetApp Asta控制中心(ACC)测试和验证迁移和集中数据保护。</block>
  <block id="0196288da3234f0b3a984fb859dbbe2e" category="paragraph">对于此解决方案 、NetApp会对以下情形进行测试和验证。根据以下特征、解决方案 可分为多种情形：</block>
  <block id="97a114682aee9996b96ccab927de04d7" category="list-text">内部部署</block>
  <block id="a1234b3161b4fbfdfb96dd576b65bbea" category="list-text">云</block>
  <block id="fc5b68fff5369eab614cea8a097a9da3" category="list-text">自行管理的OpenShift集群和自行管理的NetApp存储</block>
  <block id="6192817a2c883017154233f79143b526" category="list-text">提供商管理的OpenShift集群和提供商管理的NetApp存储</block>
  <block id="346cce4487319e1b8f55333f07a7bfe6" category="paragraph">**我们将在未来构建更多的解决方案和用例。**</block>
  <block id="642056fd59cfcf2e5c6ac845b30f8a89" category="section-title">方案1：使用ACC在内部环境中保护和迁移数据</block>
  <block id="e750828e5900c9e9e0080da69c59deee" category="paragraph">**内部：自行管理的OpenShift集群和自行管理的NetApp存储**</block>
  <block id="c0eaf6c42fe00cd346ed6b6e3840a87b" category="list-text">使用ACC创建Snapshot副本、备份和恢复以保护数据。</block>
  <block id="5bbe9f387a62f7e6da1a3479bae84aaf" category="list-text">使用ACC对容器应用程序执行SnapMirror复制。</block>
  <block id="d42e8fbcf79f7de1303918aafa7d9fa7" category="section-title">场景 1</block>
  <block id="f0489d547da7e6c7860d78bc0e76b3fc" category="paragraph"><block ref="f0489d547da7e6c7860d78bc0e76b3fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="011c4a5ba5680b65be39323642e0c6e5" category="paragraph">**内部：自行管理的OpenShift集群和自行管理的存储** AWS云：自行管理的OpenShift集群和自行管理的存储**</block>
  <block id="6c440a8e8c4732064f0a2fe22d438916" category="list-text">使用ACC执行备份和恢复以保护数据。</block>
  <block id="3d2b891e87f58587dcf56e520915afef" category="section-title">场景 2</block>
  <block id="cb4581e6ea0741c82604502d38c43995" category="paragraph"><block ref="cb4581e6ea0741c82604502d38c43995" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02626a2e6e765a5df4816a825234dc2e" category="paragraph">**内部：自行管理的OpenShift集群和自行管理的存储**** AWS云：提供商管理的OpenShift集群(ROSA)和提供商管理的存储(FSxN)**</block>
  <block id="5c1c8d2602eef78d62342564281ce1e2" category="list-text">使用BlueXP执行永久性卷复制(FSxN)。</block>
  <block id="87536fdb761ec9bd49af92d0cf39f302" category="list-text">使用OpenShift GitOps重新创建应用程序元数据。</block>
  <block id="c2447154da8ea0e9f40104cfe84c986a" category="section-title">方案3.</block>
  <block id="d50912075fbd317709a0c7722c0c765e" category="paragraph"><block ref="d50912075fbd317709a0c7722c0c765e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1522c369fc33aa74294fbd0cd08a1b03" category="paragraph">有关在MetroCluster 配置中使用ONTAP 时的注意事项、请参见 <block ref="5b6304ea4373a975ac8b2f8302d3d44b" category="inline-link-macro-rx"></block>。</block>
  <block id="16ef23462b663a9c6034549a75db04f2" category="doc">支持NetApp存储与Red Hat Open Shift容器的集成</block>
  <block id="46d3c033f73d0ee2be1fd01fd7b3bc9b" category="paragraph">无论Red Hat Open Shift容器是在VMware上运行还是在超大型机中运行、NetApp A作用 力三端均可用作其支持的各种后端NetApp存储的CSI配置程序。</block>
  <block id="b9f60c4d5e949aec928443832fd0f567" category="paragraph">下图展示了可使用NetApp Asta Dent与OpenShift集群集成的各种后端NetApp存储。</block>
  <block id="d115671a64afa53f0714cdf802de2a28" category="paragraph"><block ref="d115671a64afa53f0714cdf802de2a28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c57009523536c8cf1126736d023db8fd" category="paragraph">ONTAP Storage Virtual Machine (SVM)可提供安全多租户。一个OpenShift集群可以连接到一个或多个SVM、甚至可以连接到多个ONTAP 集群。存储类会根据参数或标签筛选后端存储。存储管理员可定义使用三级联后端配置连接到存储系统所需的参数。成功建立连接后、它将创建三项技术后端并填充存储类可以筛选的信息。</block>
  <block id="f7a2c532baf0284a5077caf9cad8791a" category="paragraph">存储器和后端之间的关系如下所示。</block>
  <block id="efe36ae733078bbe9a7d4971388b61df" category="inline-image-macro">存储类到ONTAP 关系</block>
  <block id="0442e65b325d60f7fc9c602b320dd58c" category="paragraph"><block ref="0442e65b325d60f7fc9c602b320dd58c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90b82350db9212bd4d0c57a640d19232" category="paragraph">应用程序所有者使用存储类请求永久性卷。存储类用于筛选后端存储。POD与后端存储之间的关系如下所示。</block>
  <block id="a0f5fccacb6f4513b350db2e44d0a52f" category="inline-image-macro">POD与ONTAP 卷之间的关系</block>
  <block id="d9c6f609f7c707469f70a6b148f408a7" category="paragraph"><block ref="d9c6f609f7c707469f70a6b148f408a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e8c8ed944bd179a7ed5014748fb31de" category="section-title">容器存储接口(CSI)选项</block>
  <block id="b79382adbee98b6603cb4ac95885af9e" category="paragraph">在vSphere环境中、客户可以选择VMware CSI驱动程序和/或Astra三端CSI与ONTAP 集成。使用VMware CSI时、永久性卷会用作本地SCSI磁盘、而使用三端技术时、则会使用网络。由于VMware CSI不支持使用ONTAP 的rwx访问模式、因此如果需要rwx模式、应用程序需要使用TRIDent CSI。对于基于FC的部署、首选使用VMware CSI、而SnapMirror业务连续性(SMBC)可提供区域级高可用性。</block>
  <block id="d2cba3ef557d6500cd0420d9bb36a4c7" category="section-title">VMware CSI支持</block>
  <block id="216cd0f470eb203964b09af554b2f66c" category="list-text">基于核心块的数据存储库(FC、FCoE、iSCSI、NVMeoF)</block>
  <block id="dc64cd64093452f4efadcc36b20344a3" category="list-text">基于核心文件的数据存储库(NFS v3、v4)</block>
  <block id="1d89948bfc7a49c7c24ea6c174ba238a" category="list-text">vVol数据存储库(块和文件)</block>
  <block id="f4d669ddd2fadaee50bf3d976dc303fc" category="section-title">通过以下驱动程序、可以支持ONTAP</block>
  <block id="d34166b81b6a41af7f7e68ab1a706647" category="list-text">ONTAP SAN (专用卷)</block>
  <block id="51f8b538584089b7767162debcf8e4b8" category="list-text">ONTAP SAN经济模式(共享卷)</block>
  <block id="0a8ce2b6a8e563cf981d283355ab4fec" category="list-text">ONTAP NAS (专用卷)</block>
  <block id="d3fb6fce8725812eb61f50ddb9a7d2d2" category="list-text">ONTAP—NAS—经济型(共享卷)</block>
  <block id="715a2804377bea12c12d2dfc86a3dcfc" category="list-text">ONTAP—NAS—Flexgroup (专用大规模卷)</block>
  <block id="3d8c841d5d9cfab6bcaea8932fb26d33" category="paragraph">对于VMware CSI和Asta三端CSI、ONTAP 均支持对NFS使用nconnect、会话中继、Kerberos等、对块协议使用多路径、chap身份验证等。</block>
  <block id="86c5dadebaa1ddb48e303ff25ad2a146" category="inline-link-macro">AWS性能准则</block>
  <block id="8e9cfb71a7e863c2f209d5480941fd78" category="inline-image-macro">在多可用性分区和单可用性分区之间进行复制</block>
  <block id="935ca08bdd64725cdd1088c0fb91776b" category="inline-link-macro">管理FSx ONTAP Storage Virtual Machine</block>
  <block id="0aa0b6b72c2288a10c437f6fd4b333b9" category="paragraph">有关FSx ONTAP 支持的SVM数量、请参见 <block ref="0a6e802412081ec42f8b1e7e94aea7a2" category="inline-link-macro-rx"></block></block>
  <block id="8ac66023d6d64852e30505c1e8d60986" category="doc">NetApp解决方案 在AWS上运行托管Red Hat OpenShift容器平台工作负载</block>
  <block id="242d6ccbbd71ec647ddb86909c24827d" category="paragraph">客户可能"生于云"、也可能正处于现代化之旅的某一时刻、准备将部分选定工作负载或所有工作负载从数据中心迁移到云。他们可以选择在云中使用提供商管理的OpenShift容器和提供商管理的NetApp存储来运行工作负载。他们应该在云中规划和部署托管Red Hat OpenShift容器集群(ROSA)、以便为其容器工作负载提供一个成功的生产就绪环境。在AWS云中、他们还可以部署FSx for NetApp ONTAP 来满足存储需求。</block>
  <block id="51affed0f08c3d6d7d172db839089ac6" category="paragraph">FSx for NetApp ONTAP 可为AWS中的容器部署提供数据保护、可靠性和灵活性。Asta三端存储作为动态存储配置程序、用于为客户的有状态应用程序使用永久性FSxN存储。</block>
  <block id="16b422dedaa305f1e883d55d28f2d211" category="paragraph">由于可以在HA模式下部署ROSA、并且控制平台节点分布在多个可用性区域中、因此FSx ONTAP 还可以配置Multi-AZ选项、以提供高可用性并防止出现AZ故障。</block>
  <block id="aac86419bd7742807d0b65436a4fdcf2" category="admonition">从文件系统的首选可用性区域(AZ)访问Amazon FSx文件系统时、无需支付数据传输费用。有关定价的详细信息、请参见 <block ref="2d4b4b449ef448fbb3000f58e542f4ee" category="inline-link-macro-rx"></block>。</block>
  <block id="804119dcd90c16f9cbe72822ed4932e7" category="section-title">适用于OpenShift容器工作负载的数据保护和迁移解决方案</block>
  <block id="9b2f9698f9a33314b6eb0d86eb8929c9" category="doc">在AWS上部署和配置托管Red Hat OpenShift容器平台</block>
  <block id="5887e8ade129892a39138d21f25b97a8" category="paragraph">本节简要介绍了在AWS (ROSA)上设置托管Red Hat OpenShift集群的工作流。其中显示了Asta三端存储使用托管FSx for NetApp ONTAP (FSxN)作为存储后端来提供永久性卷。其中详细介绍了如何使用BlueXP在AWS上部署FSxN。此外、还提供了有关使用BlueXP和OpenShift GitOps (Argo CD)为ROSA集群上有状态应用程序执行数据保护和迁移活动的详细信息。</block>
  <block id="f8c6204c5d3f0767c18bf3dfb691b015" category="paragraph">下图展示了在AWS上部署并使用FSxN作为后端存储的ROSA集群。</block>
  <block id="538b589a3f0d2786d874e26e9b3b3bee" category="inline-link-macro">资源部分</block>
  <block id="7429532c11d9b70502be86adcd09ecfc" category="admonition">此解决方案 已通过在AWS中的两个VPC中使用两个ROSA集群进行验证。每个ROSA集群都使用Asta Trdent与FSxN集成。可以通过多种方法在AWS中部署ROSA集群和FSxN。此高级设置问题描述 提供了所用特定方法的文档链接。您可以在中提供的相关链接中参考其他方法 <block ref="ec30323d5c1ba24d6aabb0b3df901fd1" category="inline-link-macro-rx"></block>。</block>
  <block id="776e644936fa311303e288b8df968fc8" category="example-title">安装ROSA集群</block>
  <block id="b3e83e12e2309b03bb799e34f55ac838" category="list-text">创建两个VPC并在VPC之间设置VPC对等连接。</block>
  <block id="8d550961a2333f8c7184c49f43b11441" category="list-text">请参见 <block ref="703596d786038115126420be8929a2a3" category="inline-link-macro-rx"></block> 有关安装ROSA集群的说明。</block>
  <block id="6248f27e630f632c6a0b111e3a22f0c7" category="example-title">安装FSxN</block>
  <block id="f378af26f16afdc1dc513c07113ad747" category="list-text">从BlueXP在vPC上安装FSxN。请参见 <block ref="34abba7bef53102fd63639b9b9679762" category="inline-link-macro-rx"></block> 以便创建BlueXP帐户并开始使用。请参见 <block ref="2295d3162905f9dd45d3ca6c8a209ad1" category="inline-link-macro-rx"></block> 用于安装FSxN。请参见 <block ref="34abba7bef53102fd63639b9b9679762" category="inline-link-macro-rx"></block> 用于在AWS中创建连接器以管理FSxN。</block>
  <block id="f346bc83ad170b8604a8f8d59eb15587" category="list-text">使用AWS部署FSxN。请参见 <block ref="96729d098c0f6096edb6c44f431ce934" category="inline-link-macro-rx"></block> 适用于使用AWS控制台进行部署。</block>
  <block id="f8f96d37b9a3120cb1bb4a037d8195bd" category="example-title">在ROSA集群上安装TRIDent (使用Helm图表)</block>
  <block id="7564d67237d9db6138e99e2acdb8a0cf" category="list-text">使用Helm图表在ROSA集群上安装三端存储。Helm图表的URL：<block ref="dc0bfce78007eb90bab021eec0605ecf" category="inline-link-rx"></block></block>
  <block id="d9d7e23123aa2f2b6b36f2538c7079da" category="admonition">当所有受管集群使用ApplicationSet注册到ArgoCD时、可以使用OpenShift GitOps将Asta Trident CSI部署到这些集群。</block>
  <block id="d77de958b0e511ac432517a88ccba762" category="paragraph"><block ref="d77de958b0e511ac432517a88ccba762" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b98c9ae66bee7ebb9143fb1f97c635a" category="example-title">使用TRIDIent创建后端和存储类(适用于FSxN)</block>
  <block id="3dda1221f6e371517cb4fad0b6f46878" category="list-text">请参见 <block ref="9086b317542fa4fec3c7a94ae13e221d" category="inline-link-macro-rx"></block> 有关创建后端和存储类的详细信息、请参见。</block>
  <block id="a13d721aed664ec4974349a0a4cd1184" category="list-text">从OpenShift控制台使用默认的三端CSI为FsxN创建存储类。请参见以下屏幕截图：</block>
  <block id="ca6d43e36ba3ff60ddddd0b3dc9b39d0" category="paragraph"><block ref="ca6d43e36ba3ff60ddddd0b3dc9b39d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb2978b82e7eef8973a778154ed9d1d8" category="example-title">使用OpenShift GitOps部署应用程序(Argo CD)</block>
  <block id="28832d59ac5a06d16e97fd07fb21b521" category="list-text">在集群上安装OpenShift GitOps Operator。请参阅说明 <block ref="946032aa50bddc23d84d8e7c39ffd30b" category="inline-link-macro-rx"></block>。</block>
  <block id="356be904a2ad4050250d6fe2a3227030" category="list-text">为集群设置新的Argo CD实例。请参阅说明 <block ref="119b4b110537aa2ea9e3e33df43cde60" category="inline-link-macro-rx"></block>。</block>
  <block id="abe8993411729ddd001265652209bf86" category="paragraph">打开Argo CD的控制台并部署应用程序。例如、您可以使用带有Helm Chart的Argo CD部署Jenkins应用程序。创建应用程序时、系统会提供以下详细信息：Project：default cluster：<block ref="9f21a485a51630661e0fefa38fbbf6ca" category="inline-link-rx"></block>命名空间：Jenkins Helm图表的URL：<block ref="0e94db883459a2938e67dc90b6e8375d" category="inline-link-rx"></block></block>
  <block id="c6900348e4c35229bfdef15cd046933d" category="paragraph">Helm参数：globL.storageClass：fsxn-nas</block>
  <block id="5866b98c049a53ea6dc7f50f9349f434" category="doc">数据迁移</block>
  <block id="7314163a6d61f383fe22eabc7f7478f4" category="paragraph">此页面显示了使用FSx for NetApp ONTAP 作为永久性存储的托管Red Hat OpenShift集群上容器工作负载的数据迁移选项。</block>
  <block id="82352e8a86338ccc54d2fbc2c403810e" category="paragraph">AWS上的Red Hat OpenShift服务以及适用于NetApp ONTAP 的FSx (FSxN)是AWS服务产品组合的一部分。FSxN可用于单AZ或多AZ选项。Multi-Az选项可防止数据受到可用性区域故障的影响。FSxN可以与Asta Trdent集成、为ROSA集群上的应用程序提供永久性存储。</block>
  <block id="36aedde0793f8012855859992c3f80c7" category="section-title">使用Helm将FSxN与TRIdent集成图表</block>
  <block id="529a6fab29dd793a36ea8d9e3d36c756" category="paragraph">容器应用程序的迁移涉及：</block>
  <block id="dc01e4c3cbb8b6d977325df7eebba531" category="list-text">永久性卷：可使用BlueXP来实现。另一种选择是使用Astra Control Center处理从内部环境到云环境的容器应用程序迁移。自动化也可以用于相同目的。</block>
  <block id="04a50198afad51829cb74fca31795282" category="list-text">应用程序元数据：可以使用OpenShift GitOps (Argo CD)来实现。</block>
  <block id="39078498a020eaae2ab6f60a30c1cd6d" category="section-title">使用FSxN对ROSA集群上的应用程序进行故障转移和故障恢复、以实现永久性存储</block>
  <block id="0733a4864ff0a27098003f35528fda51" category="doc">NetApp解决方案 与混合云中的Red Hat OpenShift容器平台工作负载</block>
  <block id="7f224be1115f0425cbeb3e707e64be2a" category="paragraph">当客户准备将部分选定工作负载或所有工作负载从其数据中心迁移到云时、他们可能正处于现代化之旅的一个阶段。出于各种原因、他们可能会选择在云中使用自行管理的OpenShift容器和自行管理的NetApp存储。他们应在云中规划和部署Red Hat OpenShift容器平台(OCP)、以便打造一个成功的生产就绪环境、从而从数据中心迁移容器工作负载。他们的OCP集群可以部署在数据中心的VMware或裸机上、也可以部署在云环境中的AWS、Azure或Google Cloud上。</block>
  <block id="dcf5b4626b26141690124b4d983c76d9" category="paragraph">NetApp Cloud Volumes ONTAP 存储可为AWS、Azure和Google Cloud中的容器部署提供数据保护、可靠性和灵活性。Asta三端存储作为动态存储配置程序、用于为客户的有状态应用程序使用永久性Cloud Volumes ONTAP 存储。Astra Control Center可用于编排有状态应用程序的许多数据管理要求、例如数据保护、迁移和业务连续性。</block>
  <block id="ea1e0c0a154a2c9c52d9f60007ce5d91" category="section-title">使用Astra控制中心在混合云中为OpenShift容器工作负载提供数据保护和迁移解决方案</block>
  <block id="ef11f1b3f77b7a623cf6c1f337f19810" category="doc">在AWS上部署和配置Red Hat OpenShift容器平台</block>
  <block id="ab7b4d146c15537b9acf20d97bff117a" category="paragraph">本节简要介绍了如何在AWS中设置和管理OpenShift集群以及在这些集群上部署有状态应用程序的工作流。其中展示了如何利用NetApp Cloud Volumes ONTAP 存储在Asta三端存储的帮助下提供永久性卷。本节详细介绍了如何使用Astra Control Center为有状态应用程序执行数据保护和迁移活动。</block>
  <block id="e98f4c710f7c9113ed0fca838ffa71f4" category="admonition">可以通过多种方法在AWS上部署Red Hat OpenShift容器平台集群。此高级设置问题描述 提供了所用特定方法的文档链接。您可以在中提供的相关链接中参考其他方法 <block ref="ec30323d5c1ba24d6aabb0b3df901fd1" category="inline-link-macro-rx"></block>。</block>
  <block id="15e2aee2febe456536514c300a17d5c9" category="paragraph">下图展示了在AWS上部署并使用VPN连接到数据中心的集群。</block>
  <block id="a4763dc99c168c3d5c2cdff5c671fe06" category="example-title">通过高级集群管理在AWS上安装OCP集群。</block>
  <block id="23ef950cd8b1e5468c8e76f96c176bf8" category="list-text">创建具有站点到站点VPN连接的VPC (使用pfSense)以连接到内部网络。</block>
  <block id="5240532c2919e7351934292a18054058" category="list-text">内部网络具有Internet连接。</block>
  <block id="2f9a622f50ad91f20ea33eb464dffed5" category="list-text">在3个不同的AZs中创建3个专用子网。</block>
  <block id="3bc0575c716ca54e3e3f3c18896d2073" category="list-text">为VPC创建Route 53专用托管区域和DNS解析程序。</block>
  <block id="78e681da9aa719a4fa341bfefe7241dc" category="paragraph">使用高级集群管理(ACM)向导在AWS上创建OpenShift集群。请参阅说明 <block ref="a8dc968cbec7f22006c56d08b612b183" category="inline-link-macro-rx"></block>。</block>
  <block id="308c1e3e719191b8ced2d38fd974ca8e" category="admonition">您也可以从OpenShift混合云控制台在AWS中创建集群。请参见 <block ref="2273fb526f12aab77cc8d6457769ac6c" category="inline-link-macro-rx"></block> 有关说明，请参见。</block>
  <block id="fdb3ae874409cbcef80a6d9bfeb5f048" category="admonition">使用ACM创建集群时、您可以在表单视图中填写详细信息后编辑YAML文件、从而自定义安装。创建集群后、您可以通过ssh登录到集群节点、以便进行故障排除或其他手动配置。使用您在安装期间提供的ssh密钥和username core进行登录。</block>
  <block id="09896a8f2d501b8991dc697c7cbfa3db" category="example-title">使用BlueXP在AWS中部署Cloud Volumes ONTAP。</block>
  <block id="aac68d095e2a2a598854689d3a9118c3" category="list-text">在内部VMware环境中安装连接器。请参阅说明 <block ref="09bba0e8799e65970cd5db9fc029a18c" category="inline-link-macro-rx"></block>。</block>
  <block id="75cbb3865e297e8d229f20aefa0bc024" category="list-text">使用连接器在AWS中部署CVO实例。请参阅说明 <block ref="789a1549fecc83ae6bfb4929c9c8d23c" category="inline-link-macro-rx"></block>。</block>
  <block id="2b71954d9c6d4c94a1ae68bbecd1cce4" category="admonition">该连接器也可以安装在云环境中。请参见 <block ref="0631eaff036ce3419223357fb2a90da7" category="inline-link-macro-rx"></block> 适用于追加信息 。</block>
  <block id="31206dca8344fc90e6fae444b4ed25ac" category="example-title">在OCP集群中安装Asta Trdent</block>
  <block id="201de1e883240abf227c15e36805365c" category="list-text">使用Helm部署三级联操作员。请参阅说明 <block ref="2b02799a23e3b4104fc737b9e328001b" category="inline-link-macro-rx"></block></block>
  <block id="26081a5f3033e3f0db9e432902c6f047" category="list-text">创建后端和存储类。请参阅说明 <block ref="9086b317542fa4fec3c7a94ae13e221d" category="inline-link-macro-rx"></block>。</block>
  <block id="872bd3e42a2bdb9c97d84fb9206f5b75" category="example-title">将AWS上的OCP集群添加到Asta Control Center。</block>
  <block id="a2212fb9750ffed08e422fed3ae5804c" category="paragraph">将AWS中的OCP集群添加到Astra Control Center。</block>
  <block id="bb476886963857408a744eea2885622d" category="paragraph-title">对多区域架构使用三元数据的CSI拓扑功能</block>
  <block id="7ed73bdf4c4e2c0d457afe6f9f4031b0" category="paragraph">如今、云提供商支持Kubbernetes/OpenShift集群管理员生成基于分区的集群节点。节点可以位于一个区域内的不同可用性区域中，也可以位于不同区域之间。为了便于在多区域架构中为工作负载配置卷， Astra Trident 使用了 CSI 拓扑。使用 CSI 拓扑功能，可以根据区域和可用性区域将对卷的访问限制为一小部分节点。请参见 <block ref="d4105e96f5d39fa667250cc3420bb2fe" category="inline-link-macro-rx"></block> 了解更多详细信息。</block>
  <block id="638d185133876c481f9c7c55d167ce46" category="admonition">Kubarnetes支持两种卷绑定模式：-将**_VolumeBindingMode_设置为_Immediate_**(默认)时、Asta Trident会在没有任何拓扑感知功能的情况下创建卷。创建永久性卷时，不会依赖于请求的 Pod 的计划要求。-当**_VolumeBindingMode_设置为_WaitForFirstConsumer_**时，为PVC创建和绑定永久性卷的操作会延迟，直到计划和创建使用PVC的Pod为止。这样，卷就会根据拓扑要求强制实施的计划限制来创建。Astra三叉设计存储后端可以根据可用性区域选择性地配置卷(拓扑感知型后端)。对于使用此后端的 StorageClasses ，只有在受支持区域 / 区域中计划的应用程序请求时，才会创建卷。(拓扑感知型存储类)请参见 <block ref="d4105e96f5d39fa667250cc3420bb2fe" category="inline-link-macro-rx"></block> 了解更多详细信息。</block>
  <block id="cdfa8f082e2d7715023a35b2735fceea" category="doc">使用Astra Control Center保护数据</block>
  <block id="67ceaf3250ac3044e5b1ac1d959d53dd" category="paragraph">此页面显示了使用Asta Control Center (ACC)在VMware vSphere上运行的基于Red Hat OpenShift容器的应用程序的数据保护选项。</block>
  <block id="77e741d4de2fa0a2ebeda0f3879c7e2c" category="paragraph">随着用户利用Red Hat OpenShift对其应用程序进行现代化改造、应制定数据保护策略、以防止意外删除或任何其他人为错误。出于监管或合规目的、通常还需要制定保护策略来保护数据免受灾难的影响。</block>
  <block id="2b4ffa904eb16d68fecf846cc9767cb0" category="paragraph">数据保护的要求各不相同、从还原到时间点副本、到自动故障转移到其他故障域、无需任何人为干预。许多客户选择ONTAP 作为其Kubernetes应用程序的首选存储平台、因为它具有丰富的功能、例如多租户、多协议、高性能和高容量产品、适用于多站点位置的复制和缓存、以及安全性和灵活性。</block>
  <block id="5cef3ebd5669ef6dbcf6372fe453664b" category="paragraph">客户可以将云环境设置为其数据中心扩展、以便充分利用云的优势、并做好在未来移动工作负载的准备。对于这类客户而言、将其OpenShift应用程序及其数据备份到云环境是不可避免的选择。然后、他们可以将应用程序和关联数据还原到云中的OpenShift集群或数据中心。</block>
  <block id="07a40de4830379d3ca7cc7f192a93312" category="section-title">使用ACC进行备份和恢复</block>
  <block id="dff765515118d2dd275007616171d14f" category="paragraph">应用程序所有者可以查看和更新ACC发现的应用程序。ACC可以使用CSI创建Snapshot副本、并使用时间点Snapshot副本执行备份。备份目标可以是云环境中的对象存储。可以为计划的备份和要保留的备份版本数配置保护策略。最小RPO为1小时。</block>
  <block id="3df2258e47bca7a3ee653a9c77641629" category="section-title">使用ACC从备份还原应用程序</block>
  <block id="7c19c7318d54689f3bdb297f7e23fe89" category="inline-image-macro">A作用 控制中心还原选项</block>
  <block id="304b64e420b615d88c3bdee212c8bd06" category="paragraph"><block ref="304b64e420b615d88c3bdee212c8bd06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27ec99b325314a79ea3e5d3ca1942278" category="section-title">特定于应用程序的执行挂钩</block>
  <block id="dc4b99b300d94b30cac207327eca6b3e" category="paragraph">尽管可以使用存储阵列级别的数据保护功能、但通常需要执行额外的步骤才能使备份和还原应用程序保持一致。应用程序专用的其他步骤可能包括：-创建Snapshot副本之前或之后。-创建备份之前或之后。-从Snapshot副本或备份还原之后。Astra Control可以执行这些应用程序专用步骤、这些步骤编码为称为执行挂钩的自定义脚本。</block>
  <block id="6fc65b336c93cbda7e7e6a16b1cbb001" category="inline-link-macro">开源项目Verda</block>
  <block id="0108cbf1d785343393582518165b2acc" category="paragraph">NetApp的 <block ref="e8ef64368a60db519469fe3915b513cd" category="inline-link-macro-rx"></block> 为常见的云原生应用程序提供执行挂钩、使保护应用程序变得简单、强大且易于编排。如果您有足够的信息来支持存储库中没有的应用程序、请随时为该项目做出贡献。</block>
  <block id="58d3e072cfa16653345a754a5a6d1448" category="section-title">为Redis应用程序创建Snapshot前创建副本的示例执行挂钩。</block>
  <block id="b85d4f3b9ce88f321496fccb2f71f0af" category="image-alt">Asta Control Center执行挂钩</block>
  <block id="d41736970e54ce96afd763ad67dc252f" category="section-title">使用ACC复制</block>
  <block id="511daa26775075560fb655c151291f95" category="paragraph">为了实现区域保护或实现低RPO和RTO解决方案 、可以将应用程序复制到在其他站点(最好是在其他区域)运行的另一个Kubornetes实例。ACC利用ONTAP async SnapMirror并将RPO低至5分钟。请参见 <block ref="c38cfe7448528c0b52ee969f596aee97" category="inline-link-macro-rx"></block> 有关SnapMirror设置说明、请参见。</block>
  <block id="009a4d257485880614dc216576d57125" category="section-title">采用ACC的SnapMirror</block>
  <block id="9a1444b1c133e42ccb1d97ee2025cdac" category="image-alt">Asta Control Center复制</block>
  <block id="e9ff139910647d633d54b0fb5f970c3b" category="admonition">SAN经济型和NAS经济型存储驱动程序不支持复制功能。请参见 <block ref="96b7ca19fdc8212e6e1a7f647be86fd3" category="inline-link-macro-rx"></block> 了解更多详细信息。</block>
  <block id="5bed57ec15ba93e341876bf95c852684" category="section-title">演示视频：</block>
  <block id="096b02f12256f3c6a5dbd2bf4dae6b48" category="inline-link-macro">使用Asta Control Center进行灾难恢复的演示视频</block>
  <block id="21d6e2c6b83f85bd50777e293ae89572" category="paragraph"><block ref="21d6e2c6b83f85bd50777e293ae89572" category="inline-link-macro-rx"></block></block>
  <block id="19c3bde99c8bff6dc76fef4a1ef18a79" category="paragraph">有关Astra Control Center数据保护功能的详细信息、请参见 <block ref="5701e901fa686ac904f6ef8d7c56219a" category="inline-link-macro-rx"></block></block>
  <block id="fa6385abcbadab3651d099cbb8ffd292" category="doc">使用Astra Control Center迁移数据</block>
  <block id="74262b249ea38631222f476198103a48" category="paragraph">此页面显示了使用Asta Control Center (ACC)的Red Hat OpenShift集群上容器工作负载的数据迁移选项。具体而言、客户可以使用ACC将部分选定工作负载或所有工作负载从内部数据中心迁移到云、将应用程序克隆到云中进行测试、或者从数据中心迁移到云</block>
  <block id="2a529d0b05bbacac50f8502fe2e670bc" category="paragraph">要将应用程序从一个环境迁移到另一个环境、您可以使用ACC的以下功能之一：</block>
  <block id="d046134dbee59ceee559caaee740734e" category="list-text">**复制**</block>
  <block id="7502d56aa1646347152e86a4fc41e691" category="list-text">**备份和恢复**</block>
  <block id="92e06daec8f56328236212e3cc1589f2" category="list-text">**克隆**</block>
  <block id="434bfe3fa874ac271fe4a58864eed525" category="inline-link-macro">数据保护部分</block>
  <block id="2fbabbb6a6a4b39c94d7ff214be366fb" category="paragraph">请参见 <block ref="3db733da05bd3e3967dc04592cc322a8" category="inline-link-macro-rx"></block> 用于**复制、备份和恢复**选项。请参见 <block ref="b17026f8b157d793dc85ba49db8a185d" category="inline-link-macro-rx"></block> 有关**克隆**的更多详细信息。</block>
  <block id="ff34f2d1d3b4a8e19535d52fa3161174" category="admonition">只有通过三元容器存储接口(CSI)才能使用Astra复制功能。但是、NAS经济型和SAN经济型驱动程序不支持复制。</block>
  <block id="decf4ba07de4c0c590f687d6f4ae20c0" category="section-title">使用ACC执行数据复制</block>
  <block id="e4deb8e6d2d122cb9d8c89b367b4142c" category="paragraph"><block ref="e4deb8e6d2d122cb9d8c89b367b4142c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c097e1da19d035d4f07228f6b8e13793" category="doc">NetApp解决方案 在VMware上运行Red Hat OpenShift容器平台工作负载</block>
  <block id="7ce666810e087fc109e0f94f94ad56a7" category="paragraph">如果客户需要在私有数据中心的基础架构上运行现代化容器化应用程序、他们可以做到这一点。他们应规划和部署Red Hat OpenShift容器平台(OCP)、以便为部署容器工作负载打造一个成功的生产就绪环境。其OCP集群可以部署在VMware或裸机上。</block>
  <block id="04f13ada6e0062bf07f4a6bc4cfd0473" category="paragraph">NetApp ONTAP 存储可为容器部署提供数据保护、可靠性和灵活性。Asta三端存储作为动态存储配置程序、用于为客户的有状态应用程序使用永久性ONTAP 存储。Astra Control Center可用于编排有状态应用程序的许多数据管理要求、例如数据保护、迁移和业务连续性。</block>
  <block id="908657a98fea35209f3c29956a9b2bed" category="paragraph">在VMware vSphere中、NetApp ONTAP 工具提供了一个vCenter插件、可用于配置数据存储库。应用标记并将其与OpenShift结合使用、以存储节点配置和数据。基于NVMe的存储可降低延迟并提高性能。</block>
  <block id="5f24f5e6df026620962ac23d496e7362" category="paragraph">此解决方案 提供了有关使用Astra控制中心保护数据和迁移容器工作负载的详细信息。对于此解决方案 、容器工作负载部署在内部环境中vSphere上的Red Hat OpenShift集群上。注意：未来、我们将为裸机上OpenShift集群上的容器工作负载提供解决方案。</block>
  <block id="3037e288b8ba9d6259fa6ad9d3398b8f" category="section-title">使用Astra控制中心为OpenShift容器工作负载提供数据保护和迁移解决方案</block>
  <block id="cb217a1a44f4d5fc78bf80f3442587fb" category="doc">在VMware上部署和配置Red Hat OpenShift容器平台</block>
  <block id="ddd0b62f849b8e4ce53f6b702e4ec4a1" category="paragraph">本节将简要介绍如何设置和管理OpenShift集群以及管理其中有状态应用程序的工作流。其中展示了如何在Asta三端存储的帮助下使用NetApp ONTAP 存储阵列来提供永久性卷。本节详细介绍了如何使用Astra Control Center为有状态应用程序执行数据保护和迁移活动。</block>
  <block id="fdee92074ebfb0479bebaa75f729f428" category="admonition">部署Red Hat OpenShift容器平台集群的方法有多种。此高级设置问题描述 提供了所用特定方法的文档链接。您可以在中提供的相关链接中参考其他方法 <block ref="ec30323d5c1ba24d6aabb0b3df901fd1" category="inline-link-macro-rx"></block>。</block>
  <block id="7157150173a2ad98f77ee0aaf3fd209c" category="paragraph">下图展示了在数据中心内VMware上部署的集群。</block>
  <block id="ebee9d089ff5b775b007cf6049a2a17e" category="example-title">部署和配置CentOS VM</block>
  <block id="cff8c3267077ed69174aa3527d1dc36e" category="list-text">它部署在VMware vSphere环境中。</block>
  <block id="cb1b5e668fc45052f3f24868ad7e60bc" category="list-text">此VM用于部署某些组件、例如NetApp Asta三端磁盘和适用于解决方案 的NetApp Asta控制中心。</block>
  <block id="bc6be57de293aecbdd76179b49cf3d18" category="list-text">在安装期间、会在此虚拟机上配置一个root用户。</block>
  <block id="32049ccafae47776aabbbc616d0f03c3" category="example-title">在VMware vSphere上部署和配置OpenShift容器平台集群(集线器集群)</block>
  <block id="8f723b78972cfa193e65ef9f3a2344c8" category="inline-link-macro">辅助部署</block>
  <block id="4032722c8375f3d8648bf18cdf7871cd" category="paragraph">请参见的说明 <block ref="c391027f88ae10e0813918c42a205aa9" category="inline-link-macro-rx"></block> 部署OCP集群的方法。</block>
  <block id="6f236f58666ae998668d5afce2ac9348" category="admonition">请记住以下内容：-创建ssh公共密钥和专用密钥以提供给安装程序。如果需要、这些密钥将用于登录到主节点和工作节点。-从辅助安装程序下载安装程序。此程序用于启动您在VMware vSphere环境中为主节点和工作节点创建的VM。-虚拟机应满足最低CPU、内存和硬盘要求。(请参阅上的vm create命令 <block ref="1caa15c4f6b987248682d9b97caf205a" category="inline-link-macro-rx"></block> 提供此信息的主节点和工作节点的页面)—应在所有VM上启用diskUUID。-至少为主节点创建3个节点、为工作节点创建3个节点。-安装程序发现它们后、打开VMware vSphere集成切换按钮。</block>
  <block id="5ee7e5d095a85988457e6852e94af6e8" category="example-title">在集线器集群上安装高级集群管理</block>
  <block id="643c48205940ae10b1f2c5f6f8aa5f64" category="paragraph">可使用集线器集群上的高级集群管理操作员进行安装。请参阅说明 <block ref="4bb39576c102d9630dc961b3998ecbd9" category="inline-link-macro-rx"></block>。</block>
  <block id="e32925fd5960e69787470b8e8050f9e4" category="example-title">在集线器集群上安装内部Red Hat Quay注册表。</block>
  <block id="d35063583c4a1472426b44ab39cf1289" category="list-text">要推送Asta映像、需要使用内部注册表。在集线器集群中使用Operator安装Quay内部注册表。</block>
  <block id="e9376ceddbd8c3199dd0f9b58f969db1" category="list-text">请参阅说明 <block ref="106db11ac4ec29af57ae501212b90c65" category="inline-link-macro-rx"></block></block>
  <block id="c0090a527266898baf1b6d9a9978eeb3" category="example-title">安装两个额外的OCP集群(源和目标)</block>
  <block id="a4fcf9c2586b5e93f63d9c1290438839" category="list-text">可以使用集线器集群上的ACM部署其他集群。</block>
  <block id="24ed1bd1ba2dc78d194e4186a2a7b0a1" category="list-text">请参阅说明 <block ref="61a11e403c83c9c41ff797a7a780dbff" category="inline-link-macro-rx"></block>。</block>
  <block id="4cb2dca6265c22cd883513131d603c5f" category="example-title">配置NetApp ONTAP 存储</block>
  <block id="31114fdb67ca9ac1afd2af9e1a830e4e" category="list-text">在VMware环境中安装可连接到OCP VM的ONTAP 集群。</block>
  <block id="15a89333d6100097518836f27ebc981d" category="list-text">创建SVM。</block>
  <block id="5c9914884527913b8fccd217cc6c8b11" category="list-text">配置NAS数据lf以访问SVM中的存储。</block>
  <block id="7becc4cb9c4df5e8d5cb90ed1d181394" category="example-title">在OCP集群上安装NetApp Trident</block>
  <block id="f086eaa0b9f8b360a31c94f637c0d0b4" category="list-text">在集线器、源和目标集群这三个集群上安装NetApp三项功能</block>
  <block id="388489f610963550b7669f0a1294b958" category="list-text">请参阅说明 <block ref="36ef4218bf5578859a7215d49db6401a" category="inline-link-macro-rx"></block>。</block>
  <block id="c80ffbf15474d7b48c471b4be5c7eea6" category="list-text">为ONTAP－NAS创建存储后端。</block>
  <block id="29dfff8b62823a687037af3caba8bde0" category="list-text">为ONTAP NAS创建存储类。</block>
  <block id="6fa9ba2800ce8267575f3934fc7a7c46" category="list-text">请参阅说明 <block ref="9086b317542fa4fec3c7a94ae13e221d" category="inline-link-macro-rx"></block>。</block>
  <block id="bae25119b826b9ac3f0139d60666c5a2" category="example-title">安装NetApp Asta Control Center</block>
  <block id="dcc7f9c17c22a8d859c7d80bbab266fd" category="list-text">NetApp Asta Control Center可使用集线器集群上的Asta Operator进行安装。</block>
  <block id="d38e5dd6bd81bc5e1d30960b2bcd4937" category="list-text">请参阅说明 <block ref="badde8c82c638a4d205deac0f9dfbab6" category="inline-link-macro-rx"></block>。</block>
  <block id="8c41383f8ea827ed90aaea3cad2a266e" category="paragraph">请记住：*从支持站点下载NetApp Asta Control Center映像。*将图像推送到内部注册表。*请参阅此处的说明。</block>
  <block id="f1695603df9eff6b0631c2c5a3e023e5" category="example-title">在源集群上部署应用程序</block>
  <block id="fc9da6996070c267e36ead9d0ec7feb9" category="paragraph">使用OpenShift GitOps部署应用程序。(例如Postgres, Ghost)</block>
  <block id="9528b255237a8d325a14e2000be97573" category="example-title">将源集群和目标集群添加到Astra控制中心。</block>
  <block id="09361c7ad370c2e7e53d015ad4fab4b0" category="inline-link-macro">开始管理Astra Control Center的应用程序部分</block>
  <block id="78fa07ec3b9ba9f22e548694264fe880" category="paragraph">将集群添加到Astra Control管理后、您可以在集群上安装应用程序(Astra Control之外)、然后转到Astra Control中的"应用程序"页面定义应用程序及其资源。请参见 <block ref="c613c6401833c4841b0ab26745eb0b8c" category="inline-link-macro-rx"></block>。</block>
  <block id="378b41ea55cc0a1ff844e4ab0f04524d" category="paragraph">下一步是使用Astra Control Center进行数据保护、并将数据从源集群迁移到目标集群。</block>
  <block id="9645795f561430b8c7c8af462727e1c7" category="doc">使用Astra保护数据</block>
  <block id="dfea6c0fea6ed37acf9e75b6a4549abb" category="paragraph">ONTAP 中的数据保护可通过临时或策略控制的方式实现-**快照**-**备份和恢复**</block>
  <block id="32645e18d7f4247905ad6890e438a838" category="paragraph">Snapshot副本和备份均可保护以下类型的数据：-**表示应用程序状态的应用程序元数据**-**与应用程序关联的任何永久性数据卷**-**属于应用程序的任何资源项目**</block>
  <block id="60e419ba4534554b327dcc9d08a88051" category="section-title">使用ACC创建Snapshot</block>
  <block id="b0be27a64b0f61f58d3aec742f01fbad" category="paragraph">可以使用Snapshot和ACC捕获数据的时间点副本。保护策略用于定义要保留的Snapshot副本数。可用的最小计划选项为每小时。与计划内Snapshot副本相比、可以随时创建按需手动Snapshot副本、创建时间间隔也更短。Snapshot副本存储在与应用程序相同的已配置卷上。</block>
  <block id="f70c55e82154bf66a6f83cb62a68c5d4" category="section-title">使用ACC配置Snapshot</block>
  <block id="05a7ec3be5c459fbf39f36ddf3c800c8" category="image-alt">Astra Control Center Snapshot视图</block>
  <block id="251a2148a5d4efac4cff711b46a52b21" category="paragraph">备份基于Snapshot。ACC可以使用CSI创建Snapshot副本、并使用时间点Snapshot副本执行备份。备份存储在外部对象存储中(任何兼容S3、包括位于不同位置的ONTAP S3)。可以为计划的备份和要保留的备份版本数配置保护策略。最小RPO为1小时。</block>
  <block id="eec7737a80f326b19b44d829e47c31f7" category="paragraph">ACC从存储备份的S3存储分段还原应用程序。</block>
  <block id="92dab9911cf33fb36633339932ea1aa4" category="paragraph">此外、还可以将执行挂钩配置为与托管应用程序的数据保护操作结合运行。尽管提供了存储阵列级别的数据保护功能、但通常还需要执行额外的步骤才能使备份和还原保持应用程序一致。应用程序专用的其他步骤可能包括：-创建Snapshot副本之前或之后。-创建备份之前或之后。-从Snapshot副本或备份还原之后。</block>
  <block id="ebbdb911301d0ec7cb4da5dc83c333d4" category="paragraph">Astra Control可以执行这些应用程序专用步骤、这些步骤编码为称为执行挂钩的自定义脚本。</block>
  <block id="0370124d48bfc5af2def19c48f433283" category="inline-link">NetApp Verda GitHub项目</block>
  <block id="039a30c0463c68f7f8e1c222726b8bdd" category="paragraph"><block ref="9ad3989601b59e755170866a5329554c" category="inline-link-rx"></block> 为常见的云原生应用程序提供执行挂钩、使保护应用程序变得简单、强大且易于编排。如果您有足够的信息来支持存储库中没有的应用程序、请随时为该项目做出贡献。</block>
  <block id="3d03d2aa94bb04967bc567d16b813d26" category="paragraph">为了实现区域保护或实现低RPO和RTO解决方案 、可以将应用程序复制到在其他站点(最好是在其他区域)运行的另一个Kubornetes实例。ACC利用ONTAP async SnapMirror并将RPO低至5分钟。复制操作是通过复制到ONTAP 来完成的、然后进行故障转移会在目标集群中创建Kubbernetes资源。</block>
  <block id="74713319c86022082cfafb127b906d08" category="admonition">请注意、复制与备份和还原不同、在备份和还原中、备份将转到S3并从S3执行还原。请访问以下链接：https://docs.netapp.com/us-en/astra-control-center/concepts/data-protection.html#replication-to-a-remote-cluster[here]、了解有关这两种类型的数据保护之间差异的更多详细信息。</block>
  <block id="12e6f760044e842eeeed770fe1f045e0" category="paragraph">请参见 <block ref="c38cfe7448528c0b52ee969f596aee97" category="inline-link-macro-rx"></block> 有关SnapMirror设置说明、请参见。</block>
  <block id="3e27528a048bdb90c1e5af896157ebcf" category="section-title">借助MetroCluster 实现业务连续性</block>
  <block id="75173a4bfbc4b9d0487876943898d53a" category="paragraph">我们大多数适用于ONTAP 的硬件平台都具有高可用性功能、可防止设备发生故障、从而避免执行灾难恢复。但是、为了防止火灾或任何其他灾难、并在零RPO和低RTO的情况下继续开展业务、通常会使用MetroCluster 解决方案。</block>
  <block id="841630d0dba0d69babf2a06681abb90a" category="paragraph">当前拥有ONTAP 系统的客户可以通过在距离限制范围内添加受支持的ONTAP 系统来扩展到MetroCluster 、从而提供区域级灾难恢复。Asta三端存储接口(CSI、容器存储接口)支持NetApp ONTAP 、包括MetroCluster 配置以及Cloud Volumes ONTAP 、Azure NetApp Files 、AWS FSx for NetApp ONTAP 等其他选项 Astra三端存储为ONTAP 提供了五个存储驱动程序选项、所有这些选项均支持MetroCluster 配置。请参见 <block ref="4ff141ef41caefdf95879d6959762462" category="inline-link-macro-rx"></block> 有关Asta三端存储驱动程序支持的ONTAP 存储驱动程序的更多详细信息。</block>
  <block id="fdf1e99fd6fe9f1b22f62f0c5ff36829" category="paragraph">MetroCluster 解决方案 需要第2层网络扩展或功能才能从两个容错域访问相同的网络地址。MetroCluster 配置到位后、解决方案 对应用程序所有者是透明的、因为MetroCluster SVM中的所有卷都受到保护、并可获得SyncMirror 的优势(零RPO)。</block>
  <block id="56142cf6bea785ab85e06c15d7593392" category="inline-image-macro">采用MetroCluster 的业务连续性解决方案</block>
  <block id="e7a2e49de12de237d96c8edc922e5ad9" category="paragraph"><block ref="e7a2e49de12de237d96c8edc922e5ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4fcddfe6dfd1a15c842a3b7017dffec" category="admonition">对于三元数据后端配置(TBC)、在使用MetroCluster 配置时、请勿指定dataLIF和SVM。为管理LIF指定SVM管理IP并使用vsadmin角色凭据。</block>
  <block id="0299f9898fbd6ab90ab2fb9535d62b7e" category="paragraph">此页面显示了使用Asta Control Center (ACC)的Red Hat OpenShift集群上容器工作负载的数据迁移选项。</block>
  <block id="225f5856aa99c18e009bcb24f919f963" category="paragraph">通常需要在不同环境之间移动Kubirnetes应用程序。要迁移应用程序及其永久性数据、可以使用NetApp ACC。</block>
  <block id="b94dad5a79b4605eb1c357e1088d3d57" category="section-title">在不同的Kubbernetes环境之间迁移数据</block>
  <block id="86c59e7ba36ae51135e600ddf9fb2bad" category="paragraph">ACC支持各种Kubernetes类型、包括Google Anthos、Red Hat OpenShift、Tanzu Kubernetes Grid、Grancher Kubernetes Engine、Upstream Kubernetes、 等等 有关更多详细信息、请参见 <block ref="0ceb66317efc123a6d617c493c18fdeb" category="inline-link-macro-rx"></block>。</block>
  <block id="a54acb3fa05f851f3ce9e93ed8a6fcee" category="paragraph">要将应用程序从一个集群迁移到另一个集群、您可以使用ACC的以下功能之一：</block>
  <block id="6ce65fc39d3572cc5ced699e841dc354" category="paragraph">Jupyter 笔记本电脑服务器是一款开源 Web 应用程序，数据科学家可以利用它创建类似于维基的文档，这些文档称为 Jupyter 笔记本电脑，其中包含实时代码以及描述性测试。Jupyter 笔记本电脑在 AI 和 ML 社区中广泛使用，可用于记录，存储和共享 AI 和 ML 项目。Kubeflow 可简化 Kubernetes 上 Jupyter 笔记本电脑服务器的配置和部署。有关 Jupyter 笔记本电脑的详细信息，请访问<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block>。有关 Kubeflow 环境中 Jupyter 笔记本电脑的详细信息，请参见<block ref="273f9b54e4f57ca19b4597f14d191196" category="inline-link-rx"></block>。</block>
  <block id="a4113bc79b3920d11274d7bf9cfafe10" category="paragraph"><block ref="a4113bc79b3920d11274d7bf9cfafe10" category="inline-link-rx"></block></block>
  <block id="4be8ecb3320915437222a84e9761bcec" category="paragraph">首先、您必须使用vGPU创建Ubuntu 20.04子虚拟机。要使用vGPU创建Ubuntu 20.04子虚拟机、请按照中概述的说明进行操作 <block ref="2009ba36309e23fc0bb68cec4d4a3e0d" category="inline-link-macro-rx"></block>。</block>
  <block id="939ac3b79a18fc027a13bea0aeebcd3c" category="paragraph">接下来、您必须从NVIDIA NGC下载所需的AI或分析框架容器映像、以便它们可以在子虚拟机中使用。要在子虚拟机中下载框架容器、请按照中所述的说明进行操作 <block ref="7ea494a5b1819fa63a0ad0f42cf94b43" category="inline-link-macro-rx"></block>。</block>
  <block id="898dfcda591317ac60dd8d6af3aff189" category="list-text">将您的型号存储在中的新永久性卷上<block ref="2001a6caf72de652d98c6c64bc75a4e8" category="inline-link-rx"></block> 这可由NVIDIA Triton推理服务器识别。</block>
  <block id="80d1c0ba73b8e2e8e0f305b42a776a1f" category="summary">解决方案 提供了有关在使用NFS协议的AWS FSx ONTAP 存储和EC2计算实例中部署和保护Oracle数据库的概述和详细信息、并在使用ASM作为卷管理器的独立重新启动中配置Oracle数据库。</block>
  <block id="9c0bba5590ee70c0f934655cb253d4dd" category="paragraph">Oracle ASM通常部署在FC、iSCSI存储协议和LUN中作为原始存储设备。但是、Oracle也支持基于NFS协议和NFS文件系统的ASM配置。在本文档中、我们将演示如何在使用EC2计算实例的Amazon FSx for ONTAP 存储环境中部署采用NFS协议和Oracle ASM的Oracle 19c数据库。我们还演示了如何通过NetApp BlueXP控制台使用NetApp SnapCenter 服务来备份、还原和克隆Oracle数据库、以便在AWS公共云中进行开发/测试或其他存储效率数据库操作用例。</block>
  <block id="d8c9422483ecfd8d391fbc179e1ff90f" category="list-text">在Amazon FSx中部署Oracle数据库、用于使用NFS/ASM的ONTAP 存储和EC2计算实例</block>
  <block id="86e62b62bb73c1d45af1018c5f546fa2" category="list-text">使用NFS/ASM在公共AWS云中测试和验证Oracle工作负载</block>
  <block id="b1868e5a46a34f2e4894103a18fa6e75" category="list-text">希望使用NFS/ASM在AWS公共云中部署Oracle的数据库助理。</block>
  <block id="6e5a8ef13e1f2826df29bb4025ed6544" category="list-text">* Oracle数据和日志布局。*在测试和验证中、我们分别为数据和日志部署了两个ASM磁盘组。在+data ASM磁盘组中、我们在一个数据NFS文件系统挂载点配置了四个磁盘。在+logs ASM磁盘组中、我们在日志NFS文件系统挂载点配置了两个磁盘。对于大型数据库部署、可以构建ASM磁盘组、使其跨越多个FSx文件系统、并通过固定在FSx文件系统上的多个NFS挂载点分布ASM NFS磁盘。此特定设置旨在满足超过4 Gbps吞吐量和16万次原始SSD IOPS的数据库吞吐量要求。</block>
  <block id="e2d21e7b1ae9a8e7d20087f0084bf01a" category="list-text">*DNFS配置。* DNFS内置在Oracle内核中、众所周知、在将Oracle部署到NFS存储时、它可以显著提高Oracle数据库性能。DNFS打包到Oracle二进制文件中、但默认情况下不启用。对于NFS上的任何Oracle数据库部署、都应启用此功能。对于大型数据库的多FSx文件系统部署、应正确配置DNFS多路径。</block>
  <block id="bc229d9916fc3cb8de0f67f3e5d86528" category="list-text">*要用于创建的每个Oracle ASM磁盘组的Oracle ASM冗余级别。*由于FSx已在FSx集群级别镜像存储、因此您应执行此操作<block ref="7ea763007de155a1d5ac7192d220c274" prefix=" " category="inline-code"></block> 使用外部冗余、这意味着该选项不允许Oracle ASM镜像磁盘组的内容。这一点尤其重要、因为用于Oracle数据库数据存储的NFS需要硬NFS挂载选项、而在Oracle级别镜像ASM内容时、这种方法并不理想。</block>
  <block id="d953285f2eeac9b2766ac055d81bf48a" category="list-text">安装NFS-utils。</block>
  <block id="04c0abfa4d590dbcf8140c900090b7d4" category="section-title">配置和导出要挂载到EC2实例主机的NFS卷</block>
  <block id="a245b068ccb33c4feb57be67c4c4929e" category="list-text">验证已创建的数据库卷。</block>
  <block id="f6a4694211343b15651db8fdd5f16222" category="list-text">创建/u01目录以挂载Oracle二进制文件系统</block>
  <block id="aabf104e3877a3141576892889ebcfd2" category="list-text">将二进制卷挂载到<block ref="a8946fa5f211c5345e3610710e471cb4" prefix=" " category="inline-code"></block>，已更改为FSx NFS lip地址。如果您已通过NetApp自动化工具包部署FSx集群、则在资源配置执行结束时、输出中将列出FSx虚拟存储服务器NFS lif IP地址。否则、可以从AWS FSx控制台UI中检索。</block>
  <block id="6dc5f678e8b8446afe039edff2864ef0" category="list-text">更改<block ref="a8946fa5f211c5345e3610710e471cb4" prefix=" " category="inline-code"></block> Oracle用户及其关联主组的挂载点所有权。</block>
  <block id="6e5bf17d6cb7ff829494e09654c5fdc2" category="list-text">创建/oradATA目录以挂载Oracle数据文件系统</block>
  <block id="41096b5d68af7d413deac705db2e3bab" category="list-text">将数据卷挂载到<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block>，已更改为FSx NFS lip地址</block>
  <block id="90231d3bb492c7fb529e3500cdcef778" category="list-text">更改<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> Oracle用户及其关联主组的挂载点所有权。</block>
  <block id="fbe05a889a0659f00644b0c25e984066" category="list-text">创建/orlogs目录以挂载Oracle日志文件系统</block>
  <block id="0e94479bef4fdce94a31a913e4a90ea4" category="list-text">将日志卷挂载到<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block>，已更改为FSx NFS lip地址</block>
  <block id="cd48bd706e8c70912f675dc9f17a75be" category="list-text">更改<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> Oracle用户及其关联主组的挂载点所有权。</block>
  <block id="06b5412c6ada2efb7e05e7a7454e34df" category="list-text">sudo to Oracle user、创建ASM文件夹以存储ASM磁盘文件</block>
  <block id="f6ebe7eea328062998e8b597d1de48e4" category="list-text">作为Oracle用户、创建ASM数据磁盘文件、将计数更改为与具有块大小的磁盘大小匹配。</block>
  <block id="3abcbe76f32bdac63b7e132c5d06ccb4" category="list-text">作为root用户、将数据磁盘文件权限更改为640</block>
  <block id="9b424f5bec397927a45cc70947221c7d" category="list-text">作为Oracle用户、创建ASM日志磁盘文件、并更改为计数、以便与具有块大小的磁盘大小匹配。</block>
  <block id="dbd66f2c49aae90d1e55e84df32a83da" category="list-text">作为root用户、更改会将磁盘文件权限记录为640</block>
  <block id="196c642f2925757377d21779d79ba748" category="list-text">以root用户身份登录到EC2实例。</block>
  <block id="a6774a54a715f893108bd2d2bc05062e" category="admonition">根据EC2实例主机中的可用内存设置总内存。Oracle会分配75%的<block ref="834709f36a11a38a80fe0dc57054ec20" prefix=" " category="inline-code"></block> 数据库实例SGA或缓冲区缓存。</block>
  <block id="c8c683d0737e702e38c962f83ab25c3f" category="list-text">以Oracle用户身份、更改为Oracle数据库主目录/u01/app/oracle/product/19.0.0/db1并启用DNFS</block>
  <block id="f60c53adcb933554319040836143101b" category="list-text">在oracle_home中配置oranfstab文件</block>
  <block id="e3821eca2ea743978a8041832aa25596" category="list-text">以Oracle用户身份、从sqlplus登录到数据库、并将数据库恢复大小和位置设置为+logs.磁盘组。</block>
  <block id="78f987fb432bce81eba18cab51620826" category="list-text">启用归档日志模式并重新启动Oracle DB实例</block>
  <block id="2311b19efeffe5f795b74cc4dddf6246" category="list-text">在实例重新启动后验证数据库日志模式和DNFS</block>
  <block id="db852220e8f70b72373f5e4a21bd9a45" category="list-text">验证Oracle ASM</block>
  <block id="8705d70129ca2e423b28fad13ebb5bf5" category="paragraph">作者：NetApp公司Allen Cao、Niyaz Mohamed</block>
  <block id="ca1f43ed95dcff37918897f15b054794" category="section-title">Azure虚拟机</block>
  <block id="4865c175ece72354a657ed5ee2b256eb" category="paragraph">最常见的操作系统Linux具有原生 NFS功能。Oracle提供的Direct NFS (DNFS)客户端本机集成到Oracle中。Oracle支持NFSv3已超过20年。所有Oracle版本的NFSv3均支持DNFS。遵循NFSv4标准的所有操作系统均支持NFSv4。NFSv4的DNFS支持需要Oracle 12.1.0.2或更高版本。NFSv4.1需要特定的操作系统支持。有关受支持的操作系统、请参见NetApp互操作性表工具(IMT)。NFSv4.1的DNFS支持需要Oracle 19.3.0.0或更高版本。</block>
  <block id="a3f8d7c738bb455d9c0506663213b244" category="paragraph">使用NetApp自动化工具包自动部署Oracle会自动在NFSv3上配置DNFS。</block>
  <block id="5088352a7b028bc873f55b1b666d7cd8" category="admonition">在使用DNFS之前、请验证是否已安装Oracle文档1495104.1中所述的修补程序。NetApp针对NFSv3和NFSv4的支持列表不包括特定的操作系统。支持所有符合RFC的操作系统。在联机IMT 中搜索NFSv3或NFSv4支持时、请勿选择特定操作系统、因为不会显示任何匹配项。常规策略隐式支持所有操作系统。</block>
  <block id="c0340939954e1026bd670680d03fe329" category="paragraph">crontab计划：</block>
  <block id="e0ffc65e6881a5936afffc4b840e9cd5" category="list-text">在要还原的数据库中创建一个测试表。</block>
  <block id="8b211d4c76db32ffc96c88ef826c76ac" category="example-title">采用Red Hat OpenShift的混合多云</block>
  <block id="7726892a5c5734a343a1539f3b3f6b28" category="video-title">使用A作用 力控制服务进行罗莎灾难恢复</block>
  <block id="585d77f28be6ed7195a002752abf2272" category="video-title">将FSxN与Asta Trdent集成在一起</block>
  <block id="bcb10d9a12c5b72d4b9a3e3af5c448bd" category="video-title">使用FSxN对ROSA上的应用程序进行故障转移和故障恢复</block>
  <block id="365ee461cb4c118a8bc7c388fee3410a" category="sidebar">价值主张</block>
  <block id="46d480fc201dd71bbb912a8bd377a13c" category="sidebar">经验证的解决方案</block>
  <block id="10a64a41f3a83289d75b9eb6ee0c0961" category="sidebar">经验证的版本</block>
  <block id="29656b7894a4e22578d8ffdacb29e484" category="sidebar">内部工作负载</block>
  <block id="fdf2b7bbfae8a8d27a7457a3a248684e" category="sidebar">内部解决方案</block>
  <block id="7c444e839aacd68c963d533d2f1a2ef1" category="sidebar">配置环境</block>
  <block id="9572c488eb363be83451418a6ff48c7f" category="sidebar">使用ACC保护数据</block>
  <block id="5936437437dba0b49462bb1b4e9dcf6b" category="sidebar">使用ACC进行数据迁移</block>
  <block id="c115e2b85b46823abe897a674f212329" category="sidebar">混合云工作负载(自行管理的组件)</block>
  <block id="1ab1e2e36ef5b181341692ea36b79b5d" category="sidebar">具有自行管理组件的混合云解决方案</block>
  <block id="b99e808ac7f025e225519c5d70ae9489" category="sidebar">混合云工作负载(提供商托管组件)</block>
  <block id="de8191a0431e18dd95f1a5c6258b7076" category="sidebar">具有提供商托管组件的混合云解决方案</block>
  <block id="b43e25cad1f62f3428d20945ecbc7879" category="sidebar">使用ACS保护数据</block>
  <block id="4776eb5da1441e8a2d19f5026a1a536d" category="sidebar">使用BlueXP进行数据迁移</block>
  <block id="885f346093197ca6295f5ac1ded93d82" category="sidebar">Oracle 19c在使用NFS/ASM的AWS FSX/EC2上独立重新启动</block>
  <block id="d8db237e75bdba6ccaea8d2944877403" category="sidebar">采用Red Hat的NetApp混合云</block>
  <block id="bcea83da6f4b543efcfb552bffdd3b9c" category="sidebar">采用Red Hat OpenShift的NetApp混合云</block>
  <block id="0fca8d17afc46bb08bd2d70a26cdf886" category="sidebar">内部部署</block>
  <block id="2a39f365b05b58e7a535b6b047620174" category="sidebar">在VMware上配置Red Hat OpenShift容器工作负载</block>
  <block id="609cb9f7998ec5bb4269ca1df422d4aa" category="sidebar">保护VMware上的容器工作负载</block>
  <block id="ec18322cbcfcc1ee3cdbe8a12013b96e" category="sidebar">在VMware上迁移容器工作负载</block>
  <block id="2a9707187bf8d0351412172cebd38919" category="sidebar">在AWS上配置Red Hat OpenShift容器工作负载</block>
  <block id="46d9362234fd1fb8fdbf3aff5d62f108" category="sidebar">保护AWS上的容器工作负载</block>
  <block id="effcc9c0e3cea8d66e69bb552e757275" category="sidebar">采用提供商托管组件的混合云</block>
  <block id="b432f68713f4ab09d27d581993480c2d" category="sidebar">在AWS上迁移容器工作负载</block>
  <block id="e43c7c28921efd6b3b8317da66940803" category="inline-link-macro">使用VMware HCX for VMC和FSxN进行VMotion迁移演示</block>
  <block id="304d5a3dcf64bf05141ead00f7ec768a" category="paragraph">*最佳实践*</block>
  <block id="f890e0e534ac6a9b784c8bb0400fff41" category="cell">2023年5月23日</block>
  <block id="3999d762a7e0bf52c3b5bb4c81e69fa3" category="cell">添加了TR-4400：《采用NetApp ONTAP 的VMware vSphere虚拟卷(vvol)》</block>
  <block id="cbed44df5ec7c45f2ff978c1548b0a51" category="cell">添加了新的TR-4974：《Oracle 19c在使用NFS/ASM的AWS FSX/EC2上独立重新启动》</block>
  <block id="a0c46f7ca88d42325d9a279391f96391" category="inline-link-macro">Astra Control Center在CI/CD管道中保护数据</block>
  <block id="6b8847bb26c687aff3755cd309c49318" category="inline-link-macro">利用Astra Control和NetApp FlexClone技术加快软件开发速度</block>
  <block id="92a855a1b8d950731fa531dc04dd0f9d" category="paragraph">以下视频演示了本文档中介绍的一些功能：</block>
  <block id="a52898916cc1d93c0528b275e6753070" category="inline-link-macro">借助Astra Control和NetApp FlexClone技术加快软件开发速度—采用NetApp的Red Hat OpenShift</block>
  <block id="c96541f511f34e58176bb7aa13511ea5" category="inline-link-macro">使用Asta控制中心迁移工作负载—采用NetApp的Red Hat OpenShift</block>
  <block id="f572afcba8a95128ddd328e44a23a189" category="inline-link-macro">安装OpenShift虚拟化—使用NetApp的Red Hat OpenShift</block>
  <block id="c9e349766e4968ee277d240ff7b169e6" category="inline-link-macro">使用OpenShift虚拟化部署虚拟机—采用NetApp的Red Hat OpenShift</block>
  <block id="e110e2333a8febc7917146824eb919fd" category="inline-link-macro">基于 Red Hat 虚拟化的适用于 Red Hat OpenShift 的 NetApp HCI</block>
  <block id="176e18501cba531e3471815ba9a59850" category="inline-link-macro">使用Asta Trident在VMware Tanzu中配置持久存储-使用NetApp的VMware Tanzu</block>
  <block id="c16700d624be3fd2dae451c45971452e" category="inline-link-macro">使用Asta控制中心克隆VMware Tanzu中的应用程序- VMware Tanzu与NetApp</block>
  <block id="fa7c3c752a982d726108dc5492181d9f" category="inline-link-macro">在裸机上部署Anthos—采用NetApp的Anthos</block>
  <block id="627b3c41fe5df988246e05db6908af86" category="inline-link-macro">空间和规模估算要求</block>
  <block id="ff1acb029b62c5c8f2a7b9fa9cd89004" category="doc">TR-4974：《Oracle 19c在使用NFS/ASM的AWS FSX/EC2上独立重新启动》</block>
  <block id="883c8d1cbd39f9d229e4d41d04637d5c" category="sidebar">采用NetApp ONTAP 的VMware vSphere虚拟卷(Vvol)</block>
  <block id="09ee2ff894d42056476c4e659964e53d" category="cell">8.4.2105.</block>
  <block id="fdd2aab0f0128709917906c63ac4ead9" category="cell">18.04.5 LTS (内核5.4.0-81-通用)</block>
  <block id="c8d51ff28b5d8ab2f7a2a108c7318d3e" category="cell">20.04.2 LTS</block>
  <block id="60c153e0ec5ee4601950a2256ca730fa" category="cell">9.11.1P4.</block>
  <block id="93edfe5491b7772fd10045fef48289e7" category="cell">23.01.0</block>
  <block id="1126fba791a29eca6a914fb9cc520b2d" category="inline-image-macro">Anthos BareMetal物理硬件图</block>
  <block id="59c347a74805b3b681ca29fc54f07d9f" category="paragraph"><block ref="59c347a74805b3b681ca29fc54f07d9f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f95cad6e29b1c5d602bd5bc840867b18" category="inline-image-macro">Anthos BareMetal逻辑网络图</block>
  <block id="ba294d7813cac4403ec9802c03c3e6aa" category="paragraph"><block ref="ba294d7813cac4403ec9802c03c3e6aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e45cce163df251494c8f01f0567f19c" category="paragraph">在大多数情况下、IPI安装方法是首选方法、因为它可以为开发、测试和生产环境快速部署OpenShift集群。</block>
  <block id="4f7c519d1404e63966706278645a0036" category="list-text"><block ref="4f7c519d1404e63966706278645a0036" category="inline-link-macro-rx"></block></block>
  <block id="f23bceee6cf81e0ef3be6d7e6bcaf5eb" category="example-title">将NetApp云卷服务补充数据存储库部署到GCVe</block>
  <block id="26e746bc6f0371ea1606252ec0320808" category="inline-link-macro">操作步骤使用NetApp CVS将补充NFS数据存储库部署到GCVE</block>
  <block id="6363706a3d4242814214f34d0a0d95b4" category="paragraph">请参见 <block ref="12b74f3014529a1b0755580c98a2f796" category="inline-link-macro-rx"></block></block>
  <block id="7c6dbeb8c0da7ef167c17ae1deacef5b" category="summary">客户可以使用NFS补充数据存储库和NetApp云卷服务扩展Google Cloud VMware Engine上的存储容量。</block>
  <block id="eaff656171abe2e7fbcd9cf008f47de0" category="doc">Google Cloud VMware引擎使用NetApp云卷服务补充NFS数据存储库</block>
  <block id="ad3063d1e136fbb6b0aa8d973b354a53" category="paragraph">如果客户需要在其Google Cloud VMware Engine (GCVe)环境中增加存储容量、则可以使用NetApp云卷服务挂载为补充NFS数据存储库。
通过将数据存储在NetApp云卷服务上、客户可以在不同区域之间进行复制、以防止灾难。</block>
  <block id="89dd65df8b2e23b93feebcdefc96a124" category="inline-image-macro">GCVe上的NetApp云卷服务NFS数据存储库</block>
  <block id="e45c1ba91f77ec23748e6411749f39b1" category="paragraph"><block ref="e45c1ba91f77ec23748e6411749f39b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="908b73164b0ab6ebed32f6197a9f9a22" category="section-title">从NetApp CVS在GCVE)上挂载NFS数据存储库的部署步骤</block>
  <block id="2063b92ec4e32f4072e9a1f354ed52f8" category="example-title">配置CVS性能卷</block>
  <block id="aa4c7c45a6f8058db33abfdb3c13122c" category="inline-link-macro">使用Google Cloud Console</block>
  <block id="06cc57ef2fb1f7cc541876ed541bdfa3" category="inline-link-macro">使用NetApp BlueXP门户或API</block>
  <block id="36f5e36d6dd9ee516d76ba67d085fd4f" category="paragraph">NetApp云卷服务卷可以通过进行配置
<block ref="0beb29edbd200a8e1a7829716a36a1c5" category="inline-link-macro-rx"></block>
<block ref="deefdf7aceb221b5aa34627c3ed5425f" category="inline-link-macro-rx"></block></block>
  <block id="de962206d528becf1b1d1a7b83d67225" category="example-title">将该CVS卷标记为不可删除</block>
  <block id="87aa7edcbc3a9d608cd91b08f5f46648" category="inline-image-macro">NetApp CVS不可删除选项</block>
  <block id="2f4970f700f71764030682ac3fccec7b" category="inline-link-macro">正在创建NFS卷</block>
  <block id="243a6a9082c93b4348fde49b0dfca718" category="paragraph">为了避免在VM运行期间意外删除卷、请确保将此卷标记为不可删除、如下面的屏幕截图所示。
<block ref="6776b749fe9faeb6db2e1c7e891b69ac" category="inline-image-macro-rx" type="image"></block>
有关详细信息、请参见 <block ref="3c3943aac8a82fc401a825d72b8ce909" category="inline-link-macro-rx"></block> 文档。</block>
  <block id="32e9a102f4ab39bcedd2699b54cdd636" category="example-title">确保NetApp CVS租户VPC在GCVA上存在专用连接。</block>
  <block id="5869986e7860a605ef636fe89f5ec914" category="inline-link-macro">如何设置专用服务访问</block>
  <block id="fb6e92c242829041448f7a30377d6603" category="paragraph">要挂载NFS数据存储库、GCVA和NetApp CVS项目之间应存在专用连接。
有关详细信息、请参见 <block ref="80db979a388944e99548c1ab943bf1c9" category="inline-link-macro-rx"></block></block>
  <block id="4897dfe64517b66ff8469914a8a7a68d" category="example-title">挂载NFS数据存储库</block>
  <block id="fed02037cdea8d04980173f1be258942" category="inline-link-macro">如何使用NetApp CVS创建NFS数据存储库</block>
  <block id="dd291592921907843daa0fdc420645ce" category="paragraph">有关如何在GCVE)上挂载NFS数据存储库的说明，请参阅 <block ref="e0275b80a9a4c503263138dbfa6ab14e" category="inline-link-macro-rx"></block></block>
  <block id="44100666d4adf71a7c851a82cd21aca6" category="inline-link-macro">GCP上支持的最大MTU大小</block>
  <block id="65cc8127fe1b919327fba84ecb3a56f3" category="admonition">由于vSphere主机由Google管理、因此您无权安装NFS vSphere API for Array Integration (VAAI) vSphere安装包(VIB)。
如果您需要虚拟卷(VVOl)支持、请告知我们。
如果要使用巨型帧，请参阅 <block ref="1aed01f13efb6ca82e14bdeed2aecafd" category="inline-link-macro-rx"></block></block>
  <block id="481d629fc05d4e8e203966787bfcdb89" category="section-title">借助NetApp云卷服务实现节省</block>
  <block id="f294342aa71551905185899001dac18d" category="inline-link-macro">NetApp ROI计算器</block>
  <block id="55714df5d4337e0732dca80183cdb33f" category="paragraph">要详细了解NetApp云卷服务可为您的GCVe存储需求节省的空间、请查看 <block ref="4b034931b1f465c160674bfcd2413eb6" category="inline-link-macro-rx"></block></block>
  <block id="8a65075e73c1f173820f496a08f45d2e" category="section-title">参考链接</block>
  <block id="eecb1dc8d2a35b48a6856fd7b943ec11" category="inline-link-macro">Google博客—如何使用NetApp CVS作为Google Cloud VMware Engine的数据存储库</block>
  <block id="fc131a77f564b85c6e0f39d49730ad3a" category="list-text"><block ref="fc131a77f564b85c6e0f39d49730ad3a" category="inline-link-macro-rx"></block></block>
  <block id="479b57eeda0da535fade92e57295e7c9" category="inline-link-macro">NetApp博客—将存储丰富的应用程序迁移到Google Cloud的更好方法</block>
  <block id="4587279425a64cfc00b685b8bfc28bf4" category="list-text"><block ref="4587279425a64cfc00b685b8bfc28bf4" category="inline-link-macro-rx"></block></block>
  <block id="a467f9898c9bd46c0215f239e96d9d7f" category="summary">当前使用Veeam满足数据保护要求的客户将继续使用该解决方案将工作负载迁移到GCVe、并享受NetApp云卷服务NFS数据存储库的优势。</block>
  <block id="da26232384f9873fda3a4fd63089c627" category="doc">使用Veeam复制功能将VM迁移到Google Cloud VMware Engine上的NetApp云卷服务NFS数据存储库</block>
  <block id="966250d27ccde849eed916bcf99f421e" category="paragraph">可以利用Veeam复制功能将VMware vSphere上运行的VM工作负载迁移到Google Cloud VMware Engine (GCVE)。</block>
  <block id="fe347bde2ba33effb7ca84c5de52b248" category="paragraph">本文档提供了一种使用NetApp云卷服务、Veeam和Google Cloud VMware引擎(GCVe)设置和执行VM迁移的分步方法。</block>
  <block id="5eb9b34fe3bcb638785afd04d02b57e7" category="inline-image-macro">Veeam VM复制架构</block>
  <block id="67fc7ef5f7bcdec62b9ea1c923e16ecf" category="paragraph"><block ref="67fc7ef5f7bcdec62b9ea1c923e16ecf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e87e6df9f96983da7a629a9c57b086b" category="paragraph">本文档假设您已具备Google Cloud VPN或Cloud Inter连 或其他网络选项、可用于建立从现有vSphere服务器到Google Cloud VMware Engine的网络连接。</block>
  <block id="b0cd7667098b2a3439c52ba1f9334faa" category="inline-link-macro">Google Cloud文档</block>
  <block id="d73eb7ea02aa759492afa1a49ba8e1d9" category="admonition">将内部数据中心连接到Google Cloud有多种方式、这使我们无法在本文档中概述特定工作流。
请参见 <block ref="a2909d5e052dccf2b8e974222b85d3e8" category="inline-link-macro-rx"></block> 了解适当的内部到Google连接方法。</block>
  <block id="fcd7ad1afa6eda3536c4d2408bbb2425" category="section-title">部署迁移解决方案</block>
  <block id="1e796379d1ad06751419d29cb282b4df" category="list-text">确保NetApp云卷服务中的NFS数据存储库已挂载到GCVe vCenter上。</block>
  <block id="21b1d58e0367f036a4bce61284adf6a3" category="list-text">确保在现有VMware vSphere环境中部署Veeam Backup Recovery</block>
  <block id="5d094ed5d9a04f576cb2f326ad6191bd" category="list-text">创建复制作业以开始将虚拟机复制到Google Cloud VMware Engine实例。</block>
  <block id="7609547e1c12109be4e20bfc621f0d51" category="list-text">对Veeam复制作业执行故障转移。</block>
  <block id="6e9bc9bbf651a11728b5f8805227ca18" category="list-text">在Veeam上执行永久故障转移。</block>
  <block id="f6f281df61871bbb829a20cf44af7717" category="section-title">确保NetApp云卷服务中的NFS数据存储库已挂载到GCVe vCenter上</block>
  <block id="17e75be22e4ed090ea89ef24947447df" category="inline-link-macro">将NetApp CVS挂载为GCVE)上的NFS数据存储库</block>
  <block id="24818bd478a5787e847714a16d917c6f" category="paragraph">登录到GCVEvCenter并确保具有足够空间的NFS数据存储库可用。
如果不是、请参见 <block ref="597389d00dfaba0aebcbbfd5b0ccc85d" category="inline-link-macro-rx"></block></block>
  <block id="0fcc18fb6b4186729491b28d61677fa9" category="inline-link-macro">Veeam复制组件</block>
  <block id="e6cf3758328ed305a1aeabe684835836" category="paragraph">请参阅 <block ref="685b00a5b621271828eefd848a7ac460" category="inline-link-macro-rx"></block> 安装所需组件的文档。</block>
  <block id="283aced028eb926a337377cf12ed15c0" category="inline-link-macro">配置复制作业</block>
  <block id="81e39e6b94a49ee8515b00df5fa9c457" category="paragraph">内部vCenter和GCVE vCenter都需要向Veeam注册。 <block ref="dab83a0eaa9b39c4fb90759f84bddb0f" category="inline-link-macro-rx"></block>
下面是一个介绍如何操作的视频
<block ref="a7dab1cd07b0b275add97512f42f1c54" category="inline-link-macro-rx"></block>。</block>
  <block id="c8c14bc140865f9eec1f2be9ae57ddb7" category="admonition">副本VM可以与源VM具有不同的IP、也可以连接到不同的端口组。有关更多详细信息、请观看上面的视频。</block>
  <block id="e52e8c25c503fe83f52b83797bf5ed36" category="section-title">对Veeam复制作业执行故障转移</block>
  <block id="269e833e197a53bf44d5a74095c2d305" category="inline-link-macro">执行故障转移</block>
  <block id="abd58a64d78572bfd8172f76fd238d61" category="paragraph">要迁移VM、请执行 <block ref="71a94456e7bcf2677d5604335b22861d" category="inline-link-macro-rx"></block></block>
  <block id="febf5114aacaff40100b610da536c2c4" category="inline-link-macro">永久故障转移</block>
  <block id="668e876e9eed2f87a7fbd8e16b87c4c6" category="paragraph">要将GCVE)视为新的源环境，请执行 <block ref="0695848a05014de99beaa134ecfe9fc7" category="inline-link-macro-rx"></block></block>
  <block id="7bada670a5d96330b3cc5b4226117845" category="list-text">可以利用现有Veeam备份基础架构进行迁移。</block>
  <block id="026c786a5713ed32f97b3a1c71a8043d" category="list-text">Veeam Replication允许更改目标站点上的VM IP地址。</block>
  <block id="27c28d76f86b3a51f9b28bb58d5621ac" category="list-text">能够重新映射从Veeam外部复制的现有数据(例如从BlueXP复制的数据)</block>
  <block id="b1b545fa1c1d073a0a99975e8650ed38" category="list-text">能够在目标站点上指定不同的网络端口组。</block>
  <block id="5cf62b559bb55e287f26ce4e443c36eb" category="list-text">可以指定VM的启动顺序。</block>
  <block id="7a7fc85fd2a8652e3ffd0810c561d007" category="list-text">利用VMware变更块跟踪最大限度地减少通过WAN发送的数据量。</block>
  <block id="9a671f7e22584927e482caf1f06de5fa" category="list-text">能够执行复制前和后脚本。</block>
  <block id="c626cdc93b50bc2aafedd04132869400" category="list-text">能够为快照执行前处理脚本和后处理脚本。</block>
  <block id="851dac4b1345e0ccadba8627535b367f" category="paragraph">NetApp云卷服务支持GCVe的补充NFS数据存储库。</block>
  <block id="8fced49651f8edb1ed7cb7c2250e3ab9" category="inline-link-macro">全球区域地图</block>
  <block id="31969d30ed8941afd34b4f569af50693" category="admonition">GCVENFS数据存储库只能使用CVS性能卷。
有关可用位置、请参见 <block ref="114500608caafd105661702e9c719a36" category="inline-link-macro-rx"></block></block>
  <block id="9cb67c09c21102b158c77fd8f26f2d8e" category="paragraph">Google Cloud VMware Engine可从以下位置获得 <block ref="03c8edd87403436a0af9311e6f28c836" category="inline-image-macro-rx" type="image"></block>
为了最大限度地减少延迟、NetApp CVS卷和要挂载该卷的GCVe应位于同一可用性区域。
与Google和NetApp 解决方案 架构师合作、实现可用性和TCO优化。</block>
  <block id="14b069ab9b4b1d29e582d674ff5339f3" category="inline-link-macro">通过NetApp SnapCenter和Veeam复制到GCVE上的NetApp CVS实现应用程序一致的灾难恢复</block>
  <block id="2f59dd9e0b553b7131e799417f9de1bf" category="list-text"><block ref="2f59dd9e0b553b7131e799417f9de1bf" category="inline-link-macro-rx"></block></block>
  <block id="d4db60666d0bca1239bcf825c67ebba2" category="inline-link-macro">使用Veeam将VM复制到NetApp云卷服务NFS数据存储库</block>
  <block id="e5dddbe11413ebab2116c05917829048" category="list-text"><block ref="e5dddbe11413ebab2116c05917829048" category="inline-link-macro-rx"></block></block>
  <block id="1e0ca2c939f1202a6c9917d681392e66" category="cell">2023年6月8日</block>
  <block id="cea94ce8ecefdf8a3b125e5c7f48c740" category="cell">添加了GCVE与CVS—使用NetApp SnapCenter和Veeam复制实现应用程序一致的灾难恢复</block>
  <block id="534853073422fd7521d38a66a2fdd19e" category="cell">添加了GCVE和CVS—使用Veeam复制功能将VM迁移到Google Cloud上的NetApp卷服务NFS数据存储库</block>
  <block id="2b75fc01c341e766c861bae07f9691ef" category="sidebar">NetApp CVS作为补充NFS数据存储库：概述</block>
  <block id="17dacd3ffb283be4436f911a23b786a3" category="sidebar">为Google Cloud中的NetApp CVS NFS数据存储库提供区域支持</block>
  <block id="f85911ca45d526eb7110f5ecb60cde99" category="sidebar">使用Veeam复制将VM工作负载迁移到NetApp云卷服务NFS数据存储库</block>
  <block id="22b709bc5fad16ed1504aec13a141b13" category="sidebar">GCVE)的补充NFS数据存储库</block>
  <block id="7d14043e2cdfe5f80dbf7456184b3298" category="sidebar">使用Veeam进行灾难恢复(补充NFS数据存储库)</block>
  <block id="92ef9ceb20c6f7456f4a032dfc9b936a" category="sidebar">使用Veeam (子系统连接存储)进行灾难恢复</block>
  <block id="38943740bfb1c9d0f91a2b9c5f28c5d3" category="sidebar">NetApp CVS NFS数据存储库的区域支持</block>
  <block id="676b3c6fe52210ed7050e0d913efabed" category="list-text"><block ref="676b3c6fe52210ed7050e0d913efabed" category="inline-link-macro-rx"></block></block>
  <block id="d95d4cfa2b3fc19757cbb653dedde17d" category="paragraph">在AWS中、FSx for NetApp ONTAP (FSxN)可以部署在单个可用性区域(AZ)或多个可用性区域(AZ)中。对于需要高可用性的生产工作负载、与单个AZ相比、多可用性可提供分区级容错、并具有更好的NVMe读取缓存。有关详细信息、请查看 <block ref="e4c9b635745c064746324939979ac3ba" category="inline-link-macro-rx"></block>。
为了节省灾难恢复站点的成本、可以使用一个AZ FSx ONTAP。
<block ref="d945e872f3d86016e69cb70542c0cc6a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37e3bd7a04a12d6d16389a7dc22d774d" category="summary">解决方案提供了有关快速恢复和克隆部署到AWS EC2计算实例并在FSx ONTAP上使用NFS挂载的Oracle VLDB的概述和详细信息、用于暂存待机数据文件副本、以便通过RMAN不断地进行增量合并。</block>
  <block id="64f97bbd42c9b6469781d976c191546b" category="doc">TR-4973：《在AWS FSx ONTAP上使用增量合并快速恢复和克隆Oracle VLDB》</block>
  <block id="a84ee4fe6800b14e1fd53326196750bc" category="paragraph">使用Oracle Recovery Manager (RMAN)备份工具在Oracle中恢复超大型数据库(VLDB)可能是一项极具挑战性的任务。发生故障时从备份介质还原数据库的过程可能会非常耗时、从而会延迟数据库恢复、并可能显著影响服务级别协议(Service Level Agreement、SLA)。但是、从10g开始、Oracle引入了RMAN功能、允许用户在DB服务器主机上的其他磁盘存储上创建Oracle数据库数据文件的暂存映像副本。这些映像副本可以每天使用RMAN进行增量更新。如果发生故障、数据库管理员(Database Administrator、DBA)可以快速将Oracle数据库从故障介质切换到映像副本、而无需进行完整的数据库介质恢复。结果是SLA得到了大幅改进、尽管成本是所需数据库存储的两倍。</block>
  <block id="177658bcb07f8fd6c738b1a97efaf173" category="paragraph">如果您热衷于VLDB的SLA、并考虑将Oracle数据库迁移到AWS等公共云、则可以使用AWS FSx ONTAP等资源设置类似的数据库保护结构来暂存备用数据库映像副本。在本文档中、我们将演示如何从AWS FSx ONTAP配置和导出NFS文件系统、以挂载到Oracle数据库服务器上、从而暂存备用数据库副本、以便在主存储发生故障时快速恢复。</block>
  <block id="05b4b318195ab79f80fbe6580b2e69e1" category="paragraph">更好的是、我们还会介绍如何利用NetApp FlexClone为同一暂存NFS文件系统创建一份副本、以用于其他使用情形、例如使用此备用数据库映像副本建立开发或测试Oracle环境、而无需额外的存储投资。</block>
  <block id="84ab5c2cbea62bfae267ddfcc8e16749" category="list-text">通过AWS FSx ONTAP存储上的NFS挂载点上的RMAN执行Oracle VLDB映像副本增量合并。</block>
  <block id="805ef53e3765a75fb2ee210066e9298e" category="list-text">发生故障时、通过切换到FSx ONTAP存储上的数据库映像副本快速恢复Oracle VLDB。</block>
  <block id="3b5601d0dfed112b4d701ea7222195d0" category="list-text">克隆FSx ONTAP NFS文件系统卷、用于存储Oracle VLDB映像副本、以便为其他使用情形建立另一个数据库实例。</block>
  <block id="2513056d37fad5d51b1b7e5067126d74" category="list-text">在AWS中通过RMAN设置Oracle VLDB映像副本增量合并以加快数据库恢复的数据库提供商。</block>
  <block id="ce3231fc55ffa9da7d06a7bf71808aaf" category="list-text">一名数据库解决方案架构师、负责在AWS公共云中测试Oracle工作负载。</block>
  <block id="1fd08bfacb23a868822b5aa42dc89a45" category="list-text">负责管理部署到AWS FSx ONTAP存储的Oracle数据库的存储管理员。</block>
  <block id="0ba3984693a0095424864d883f786d47" category="list-text">希望在AWS FSX/EC2环境中设置Oracle数据库的应用程序所有者。</block>
  <block id="6aa71922f1bb725cfd6b590fdc90b3bc" category="paragraph">此解决方案的测试和验证是在AWS FSx ONTAP和EC2环境中执行的、此环境可能与最终部署环境不匹配。有关详细信息，请参见一节 <block ref="8ea96e516bccf9a47ca2d74131eb7519" category="inline-xref-macro-rx"></block>。</block>
  <block id="4d1cde643f467fc80a436e88c5524a5a" category="image-alt">此图详细展示了使用FSxN在AWS公有云中实施的Oracle VLDB增量合并。</block>
  <block id="b9d28943555d6006f17f4fe05f964039" category="list-text">*用于RMAN增量合并的Oracle VLDB存储布局。*在我们的测试和验证中、用于Oracle增量备份和合并的NFS卷是从一个FSx文件系统中分配的、该文件系统的吞吐量为4Gbps、原始SSD IOPS为160000、容量限制为192 TiB。对于超过阈值的部署、可以将多个FSx文件系统与多个NFS挂载点并行连接、以提供更高的容量。</block>
  <block id="9d662dbb0e0bb83274ad069971f2189b" category="list-text">*使用RMAN增量合并的Oracle可恢复性。* RMAN增量备份和合并通常根据RTO和RPO目标以用户定义的频率执行。如果主数据存储和/或归档日志完全丢失、则可能会发生数据丢失。Oracle数据库可以恢复到FSx数据库备份映像副本中提供的最后一次增量备份。为了最大限度地减少数据丢失、可以在FSx NFS挂载点上设置Oracle闪存恢复区域、并将归档日志与数据库映像副本一起备份到FSx NFS挂载。</block>
  <block id="6848d8d3126dc1284b4005ec1fce94d8" category="list-text">*在FSx NFS文件系统之外运行Oracle VLDB。*与用于数据库备份的其他批量存储不同、AWS FSx ONTAP是一款支持云的生产级存储、可提供高级别的性能和存储效率。一旦Oracle VLDB从主存储切换到FSx ONTAP NFS文件系统上的映像副本、在解决主存储故障的同时、数据库性能可以保持较高水平。您可以放心地知道、主存储故障不会影响用户应用程序体验。</block>
  <block id="ec7cebb9325ac3cb6f40aefad20e03bd" category="list-text">*适用于其他使用情形的FlexClone NFS卷的Oracle VLDB映像副本。* AWS FSx ONTAP FlexClone可为同一个NFS数据卷提供可写的共享副本。因此、它们可用于许多其他使用情形、同时仍可保持暂存Oracle VLDB映像副本的完整性、即使Oracle数据库已切换也是如此。这样可以大幅减少VLDB存储占用空间、从而显著节省存储成本。NetApp建议在数据库从主存储切换到数据库映像副本时尽量减少FlexClone活动、以便将Oracle性能保持在较高水平。</block>
  <block id="e02cfd91d47eca501c65adf66254d387" category="list-text">*EC2计算实例。*在这些测试和验证中，我们使用AWS EC2 T2.xlea占用 空间实例作为Oracle数据库计算实例。NetApp建议在生产部署中使用M5类型的EC2实例作为Oracle的计算实例、因为它已针对数据库工作负载进行了优化。您需要根据实际工作负载要求根据vCPU数量和RAM量适当调整EC2实例的大小。</block>
  <block id="dbb60fc24045befe2579b82399376e53" category="list-text">*DNFS配置。* DNFS内置在Oracle内核中、众所周知、在将Oracle部署到NFS存储时、它可以显著提高Oracle数据库性能。DNFS打包到Oracle二进制文件中、但默认情况下不启用。对于NFS上的任何Oracle数据库部署、都应启用此功能。对于VLDB的多FSx文件系统部署、应正确配置指向不同FSx NFS文件系统的DNFS多路径。</block>
  <block id="674b2923f5f187bec3e7e8410e0b215b" category="paragraph">我们假定您已在VPC中的AWS EC2环境中部署Oracle VLDB。如果您需要有关在AWS中部署Oracle的帮助、请参阅以下技术报告以获取帮助。</block>
  <block id="31a24635ce69dd426c0b029c4fcdc98d" category="inline-link-macro">基于EC2和FSx的Oracle数据库部署最佳实践</block>
  <block id="b03e58dfabab0447bab001f326e6a595" category="list-text"><block ref="b03e58dfabab0447bab001f326e6a595" category="inline-link-macro-rx"></block></block>
  <block id="b667d29e77263bc81c5be8e70e7e2a49" category="list-text"><block ref="b667d29e77263bc81c5be8e70e7e2a49" category="inline-link-macro-rx"></block></block>
  <block id="ecd21491d14a4e28b3455daf967f0d92" category="list-text"><block ref="ecd21491d14a4e28b3455daf967f0d92" category="inline-link-macro-rx"></block></block>
  <block id="dac14712639b383d9fbc2ddd7e8fa676" category="paragraph">您的Oracle VLDB可以在FSx ONTAP上运行、也可以在AWS EC2生态系统中的任何其他可选存储上运行。下一节将分步介绍如何设置RMAN增量合并到Oracle VLDB的映像副本、该副本暂存在AWS FSx ONTAP存储的NFS挂载中。</block>
  <block id="e662355029a2dd517af0a229f7df7092" category="list-text">从AWS EC2控制台中、部署Amazon FSx for ONTAP存储HA集群、以托管用于存储Oracle数据库备用映像副本的NFS卷。如果您不熟悉FSX存储的部署、请参见相关文档 <block ref="17d8b312d287f0afd6f44b3f25c4f20b" category="inline-link-macro-rx"></block> 了解分步说明。</block>
  <block id="3445b7a1a574c2ac22f90caa85f25371" category="list-text">可以使用以下Terraform自动化工具包执行步骤2和步骤3、该工具包会创建一个名为的EC2实例<block ref="460dc55b5ffb0266f2c889b06ee73344" prefix=" " category="inline-code"></block> 和名为的FSX文件系统<block ref="8cbb7b3050d3c3aa08a529f429bc4555" prefix=" " category="inline-code"></block>。执行前、请仔细阅读该说明并根据您的环境更改变量。您可以根据自己的部署要求轻松修改此模板。</block>
  <block id="669ff3f2ba7dca6171b6cc4738349f3f" category="section-title">配置和导出要挂载到EC2数据库实例主机的NFS卷</block>
  <block id="beef8e24f1fb09f50fd25f29a0576680" category="paragraph">在此演示中、我们将展示如何通过命令行配置NFS卷、方法是以fsxadmin用户身份通过FSx集群管理IP以ssh登录到FSx集群。或者、也可以使用AWS FSx控制台分配卷。如果设置了多个FSx文件系统以适应数据库大小、请在其他FSx文件系统上重复上述过程。</block>
  <block id="2a1085209859c9d5c2d99b39ef5f9808" category="list-text">首先、以fsxadmin用户身份通过SSH登录到FSx集群、通过命令行界面配置NFS卷。更改为FSx集群管理IP地址、此地址可从AWS FSx ONTAP UI控制台检索。</block>
  <block id="09d6e7935025f34dae85044f7e4870bf" category="list-text">创建与主存储大小相同的NFS卷、用于存储主Oracle VLDB数据库数据文件映像副本。</block>
  <block id="7df4f92cb03e6715a6c7d330de46b589" category="list-text">或者、也可以从AWS FSx控制台UI中使用以下选项配置此卷：存储效率<block ref="00d23a76e43b46dae9ec7aa9dcbebb32" prefix=" " category="inline-code"></block>，安全模式<block ref="6ec1bd1ea6a5d67a63b20c8f6172bddd" prefix=" " category="inline-code"></block> 、Snapshot策略<block ref="6adf97f83acf6453d4a6a4b1070f3754" prefix=" " category="inline-code"></block>和存储层<block ref="e564cced6db6df25023e6429cf11a291" prefix=" " category="inline-code"></block> 如下所示。</block>
  <block id="a33ce44212488cbdb886d0cb26238cd8" category="list-text">为Oracle数据库创建一个具有每日计划和30天保留期限的自定义快照策略。您应根据快照频率和保留时间窗口的具体需求调整策略。</block>
  <block id="f50e19cf713434ce45c0e967a937c4b1" category="paragraph">将策略应用于配置的NFS卷以进行RMAN增量备份和合并。</block>
  <block id="4c4801c905895fc73c76eb48803356bd" category="list-text">以EC2-user身份登录到EC2实例并创建目录/nfsfsxn。为其他FSx文件系统创建其他挂载点目录。</block>
  <block id="96da60d19f53d464b46b18235e488b0c" category="list-text">将FSx ONTAP NFS卷挂载到EC2数据库实例主机。更改为FSx虚拟服务器NFS lf地址。可以从FSx ONTAP UI控制台检索NFS lf地址。</block>
  <block id="41fbd60dc26462d8127dea9ccd97bc7c" category="list-text">将挂载点所有权更改为oracle：oisntall、根据需要更改为Oracle用户名和主组。</block>
  <block id="e672188e115cfc49668faf09236fa9a3" category="section-title">将Oracle RMAN增量合并设置为FSx上的映像副本</block>
  <block id="ab8554776d6b4fb55fd0e03cf7f1cbd5" category="paragraph">RMAN增量合并会在每个增量备份/合并间隔持续更新暂存数据库数据文件映像副本。数据库备份的映像副本将与您执行增量备份/合并的频率相同。因此、在确定RMAN增量备份和合并的频率时、应考虑数据库性能、RTO和RPO目标。</block>
  <block id="e5ac82720d85625fdd4172bd3616e3c3" category="list-text">以Oracle用户身份登录到主数据库服务器EC2实例</block>
  <block id="8d0e6d4de61925d1916712bf22df2fb6" category="list-text">在挂载点/nfsfsxn下创建oracopy目录、用于存储Oracle闪存恢复区域的Oracle数据文件映像副本和归档日志目录。</block>
  <block id="7cb2cebcba99e754681eceeb65a95142" category="list-text">通过sqlplus登录到Oracle数据库、启用块更改跟踪以加快增量备份、如果Oracle闪存恢复区域当前位于主存储上、则将其更改为FSxN挂载。这样、RMAN默认控制文件/spfile自动备份和归档日志便可备份到FSxN NFS挂载以进行恢复。</block>
  <block id="92a7748d0f82560bbce2ab900cd1955b" category="paragraph">从sqlplus提示符处、执行以下命令。</block>
  <block id="4dd8e34c47ee1899b1fd445ff9555012" category="list-text">创建RMAN备份和增量合并脚本。该脚本会为并行RMAN备份和合并分配多个通道。首次执行将生成初始完整基线映像副本。在完整运行中、它会首先清除保留窗口之外的过时备份、以保持暂存区域干净。然后、它会在合并和备份之前切换当前日志文件。增量备份会在合并后进行、以便数据库映像副本会在当前数据库状态后经过一个备份/合并周期。可以反转合并和备份顺序、以便根据用户的偏好加快恢复速度。RMAN脚本可以集成到一个简单的shell脚本中、以便从主数据库服务器上的crontab执行。确保在RMAN设置中打开控制文件自动备份。</block>
  <block id="ae93d326cc9f712fe006ea475309937c" category="list-text">在EC2数据库服务器上、以Oracle用户身份本地登录到RMAN、无论是否具有RMAN目录。在此演示中、我们不会连接到RMAN目录。</block>
  <block id="ac32c637aa72dbf6f583c6230b41da8e" category="list-text">从RMAN提示符处、执行该脚本。首次执行时创建基线数据库映像副本、后续执行时合并并增量更新基线映像副本。下面介绍了如何执行该脚本以及典型输出。设置通道数、使其与主机上的CPU核匹配。</block>
  <block id="e4c4b8650bec8cf96029a44dde1880ef" category="list-text">在备份后列出数据库映像副本、以观察是否已在FSx ONTAP NFS挂载点中创建数据库映像副本。</block>
  <block id="c924bb54c35d27877a31088ac19cfa72" category="list-text">通过Oracle RMAN命令提示符报告架构、以观察当前活动数据库数据文件是否位于主存储ASM +数据磁盘组中。</block>
  <block id="3ce3b6eb52bdc641409f7139da0754cb" category="list-text">验证从操作系统NFS挂载点复制的数据库映像。</block>
  <block id="7d929a2c11ebdbe1a109452e9ed6387a" category="paragraph">至此、Oracle数据库备用映像副本备份和合并的设置完成。</block>
  <block id="4a2b45de7eb73f732fa6bff62fc81d22" category="section-title">将Oracle数据库切换到映像副本、以便快速恢复</block>
  <block id="e4524be5d2f6b10f07de14a0c1ab6d71" category="paragraph">如果因主存储问题描述发生故障(例如数据丢失或损坏)、则可以快速将数据库切换到FSx ONTAP NFS挂载上的映像副本、并将其恢复到当前状态、而无需还原数据库。消除介质还原可显著加快VLDB的数据库恢复速度。此使用情形假定数据库主机实例完好无损、并且数据库控制文件、归档日志和当前日志均可用于恢复。</block>
  <block id="537cc866e4f73e1c941f5c4d2ddab8b2" category="list-text">在切换之前、以Oracle用户身份登录到EC2数据库服务器主机并创建测试表。</block>
  <block id="61bbc132a3f6fe227d32c6a35bc77915" category="list-text">通过关闭中止数据库、然后在挂载阶段启动Oracle来模拟故障。</block>
  <block id="c4ab260ce247b7761c38125aef5a7e31" category="list-text">作为Oracle用户、通过RMAN连接到Oracle数据库、以切换要复制的数据库。</block>
  <block id="3ea66d969bd94f4cf208dd0bf63840e1" category="list-text">恢复并打开数据库、使其从上次增量备份恢复到最新状态。</block>
  <block id="271cb3a5612f55b3fb8130a4467d73ec" category="list-text">在恢复后从sqlplus检查数据库结构、观察所有数据库数据文件(控制、临时和当前日志文件除外)现在都已切换到FSx ONTAP NFS文件系统上的副本。</block>
  <block id="5466bef4632a6a1715d3679bc62c300d" category="list-text">从SQL plus中、检查切换到复制之前插入的测试表的内容</block>
  <block id="dd4adbd87c36bf460c0ab4343599cf3c" category="list-text">您可以在FSx NFS挂载中长时间运行Oracle数据库、而不会影响性能、因为FSx ONTAP是可提供高性能的冗余生产级存储。修复主存储问题描述后、您可以通过反转增量备份合并过程并将停机时间降至最低来回滚到该主存储LUN。</block>
  <block id="f433e16f47f57d938354f88fa762d7a7" category="section-title">从映像副本到不同EC2数据库实例主机的Oracle数据库恢复</block>
  <block id="d837ec95ded842996742a097ccc57d23" category="paragraph">如果主存储和EC2数据库实例主机均丢失、则无法从原始服务器执行恢复。幸运的是、冗余FSxN NFS文件系统上仍有Oracle数据库备份映像副本。您可以快速配置另一个相同的EC2数据库实例、并通过NFS轻松地将VLDB的映像副本挂载到新的EC2数据库主机中以运行恢复。在本节中、我们将演示执行此操作的分步过程。</block>
  <block id="4ffffb6fe23c2e148c9e989b623bc6b2" category="list-text">插入一行以测试我们之前为Oracle数据库还原到备用主机验证创建的表。</block>
  <block id="bb7d83c51bce8526639605fc1576a291" category="list-text">以Oracle用户身份运行RMAN增量备份并合并、以将事务转储到FSxN NFS挂载上的备份集。</block>
  <block id="ca8b6e06f9a38563ab902a368af242c6" category="list-text">关闭主EC2数据库实例主机、以模拟存储和数据库服务器主机的完全故障。</block>
  <block id="6a82ba490c8bb40b71afe1f76748f174" category="list-text">通过AWS EC2控制台访问操作系统和版本相同的新EC2数据库实例主机ora_02。使用与主EC2数据库服务器主机相同的修补程序和Oracle预安装RPM配置操作系统内核、并向主机添加交换空间。使用纯软件选项在主EC2数据库服务器主机中安装相同版本和修补程序的Oracle。这些任务可通过以下链接中提供的NetApp自动化工具包自动执行。</block>
  <block id="484b6792dca4a6754db8dc27e6c6ba0d" category="inline-link-macro">na_oracle19c_dDeploy</block>
  <block id="733387d95f4085ab891cbb1cd722240c" category="paragraph">工具包： <block ref="f2b9e8cd57c74518bbd4e9f055c1e730" category="inline-link-macro-rx"></block>
文档： <block ref="65f846fe90697736cfc063f6ee7e5776" category="inline-link-macro-rx"></block></block>
  <block id="64aaea95ae37c9da88e6fab3b2d78189" category="list-text">配置Oracle环境的方式与主EC2数据库实例主机ora_01类似、例如oratab、oraInst.loc和Oracle用户.bash_profile。最好将这些文件备份到FSxN NFS挂载点。</block>
  <block id="ae1a606cf666a9deb60f32d915ac36d4" category="list-text">FSxN NFS挂载上的Oracle数据库备份映像副本存储在跨越AWS可用性区域的FSx集群上、以实现冗余、高可用性和高性能。只要网络连接可访问、NFS文件系统就可以轻松挂载到新服务器上。以下过程会将Oracle VLDB备份的映像副本挂载到新配置的EC2数据库实例主机以进行恢复。</block>
  <block id="22e76ff31f397dc2b31e0c2a97aafc91" category="paragraph">以EC2用户身份创建挂载点。</block>
  <block id="aa0a89a579500af6cf1c8d39a6150685" category="paragraph">以EC2用户身份挂载用于存储Oracle VLDB备份映像副本的NFS卷。</block>
  <block id="e480c1e101855c22c20b280c036543fd" category="list-text">验证FSxN NFS挂载点上的Oracle数据库备份映像副本。</block>
  <block id="d2ced018319ceeba05f1f26995e1ee7f" category="list-text">验证FSxN NFS挂载上可用于恢复的Oracle归档日志、并记下最后一个日志文件日志顺序编号。在本例中、此值为175。我们的恢复点最高为日志顺序编号176。</block>
  <block id="15766642bf6adac1b2dcc3fe7efe97db" category="list-text">作为Oracle用户、将oracle_home变量设置为新EC2实例数据库主机ora_02上的当前Oracle安装、将oracle_sid设置为主Oracle实例SID。在此示例中、此值为db1。</block>
  <block id="f1e64da01cd4df308ca514431dae3f5c" category="list-text">以Oracle用户身份、在$oracle_HOME/dbs目录中创建一个通用Oracle init文件、并配置适当的管理目录。最重要的是、拥有Oracle<block ref="54205e08f5455705eb7a595f7e4f620f" prefix=" " category="inline-code"></block> 指向主Oracle VLDB实例中定义的FSxN NFS挂载路径。 <block ref="54205e08f5455705eb7a595f7e4f620f" prefix=" " category="inline-code"></block> 第节介绍了配置<block ref="e672188e115cfc49668faf09236fa9a3" prefix=" " category="inline-code"></block>。将Oracle控制文件设置为FSx ONTAP NFS文件系统。</block>
  <block id="6951e3b7844ae5d3e60eb5dcb338c299" category="paragraph">包含以下示例条目：</block>
  <block id="a3d440ae8cc0248159d37338aaf28ec4" category="paragraph">如果出现差异、应将上述init文件替换为从主Oracle数据库服务器还原的备份init文件。</block>
  <block id="6cdcdb33b7ec2edec91d323d0fe81c36" category="list-text">以Oracle用户身份启动RMAN、以便在新的EC2数据库实例主机上运行Oracle恢复。</block>
  <block id="69c8d3164b4eabc17a7068af76e859ab" category="list-text">设置数据库ID。数据库ID可从FSx NFS挂载点上映像副本的Oracle文件名中检索。</block>
  <block id="4929814f4c8b867309967d003f3472fb" category="list-text">从自动备份还原控制文件。如果启用了Oracle控制文件和spfile自动备份、则它们会在每个增量备份和合并周期中进行备份。如果有多个副本可用、则会还原最新备份。</block>
  <block id="cb4aafdbf8cfce9ea979b084999b9458" category="list-text">将init文件从spfile还原到/tmp文件夹、以便稍后更新参数文件以与主数据库实例匹配。</block>
  <block id="39f6eca6a7de81a70cddffc68c8e17e0" category="list-text">挂载控制文件并验证数据库备份映像副本。</block>
  <block id="b036aee1d02945292a171a824ce2cc7f" category="list-text">切换要复制的数据库、以便在不还原数据库的情况下运行恢复。</block>
  <block id="74f753e2cf1db0c619e10ea98cdba3a4" category="list-text">在闪存恢复区域运行Oracle恢复、直到最后一个可用归档日志为止。</block>
  <block id="b32650e2f9aad58631cbaa769519a580" category="admonition">要加快恢复速度、请使用recovery _parlism参数启用并行会话、或者在恢复命令中指定并行程度以进行数据库恢复：<block ref="72ba82e38f6375ed705cba8b43d4cf0f" prefix=" " category="inline-code"></block>。通常、并行度应等于主机上的CPU核数。</block>
  <block id="977b95efac611dc3eeaed06aba204c87" category="list-text">退出RMAN、以Oracle用户身份通过sqlplus登录到Oracle、以便在恢复不完整后打开数据库并重置日志。</block>
  <block id="6ceae78bd89e5df86bc8e81f7407b7de" category="list-text">验证是否已将数据库还原到主数据库出现故障之前已插入行的新主机。</block>
  <block id="e2f16f903230132f70121566f6a55067" category="list-text">其他恢复后任务</block>
  <block id="8072a970f6aaf76f553af23ebfef337d" category="paragraph">这样、Oracle VLDB数据库便可从FSxN NFS文件系统上的备份映像副本恢复到新的EC2数据库实例主机。</block>
  <block id="4737b996f5816f2a4f5834d13933c08f" category="section-title">克隆Oracle备用映像副本、以供其他使用情形使用</block>
  <block id="b316f3e1185d0474dbb0d60722fed440" category="paragraph">使用AWS FSx ONTAP暂存Oracle VLDB映像副本的另一个优势是、可以通过FlexCloned将其用于其他许多用途、而额外的存储投资极少。在以下用例中、我们将演示如何在FSx ONTAP上为其他Oracle用例(如开发、UAT等)创建暂存NFS卷的快照和克隆</block>
  <block id="53e8ce069d201591aa4267856420d737" category="list-text">首先、我们会在之前创建的同一测试表中插入一行。</block>
  <block id="9a10cae3a2084b172991773f39bcaa66" category="list-text">创建RMAN备份并合并到FSx ONTAP数据库映像副本、以便事务将捕获到FSx NFS挂载上的备份集中、但在恢复克隆的数据库之前不会合并到副本中。</block>
  <block id="3f29a9686f355189b274a638b5f7b4e2" category="list-text">以fsxadmin用户身份通过ssh登录到FSx集群、以观察由计划备份策略Oracle创建的快照、并创建一次性快照、以使其包含我们在步骤1中执行的事务。</block>
  <block id="f47ed0566abed1014329d477596692e1" category="list-text">从一次性快照克隆、用于在备用EC2 Oracle主机上建立新的DB1克隆实例。您可以选择从卷ora_01_copy的任何可用每日快照克隆。</block>
  <block id="d674010d79c4ca8b1548eb14dc15db19" category="list-text">关闭克隆卷的Snapshot策略、因为它会继承父卷的Snapshot策略、除非您要保护克隆的卷、否则请将其保留为独立卷。</block>
  <block id="2d5a0399afe0ebbc20ccc537e1691ac1" category="list-text">登录到一个新的EC2 Linux实例、此实例已预安装Oracle软件、并且版本和修补程序级别与主Oracle EC2实例相同、然后挂载克隆的卷。</block>
  <block id="1955f680df8fadf63d4bd9e5ce9ddf0d" category="list-text">验证FSx NFS挂载上的数据库增量备份集、映像副本和可用归档日志。</block>
  <block id="b4f1ff50bc44cf0fa23d91e3daaecc7a" category="list-text">现在、恢复过程类似于以前在发生故障后恢复到新EC2数据库实例的用例—将Oracle环境(oratab、$oracle_home、$oracle_sid)设置为与主生产实例匹配、 创建一个init文件、其中包含db_recovery文件_dest和db_recovery文件_dest、该文件指向FSx NFS挂载上的闪存恢复目录。然后、通过lanuch RMAN运行恢复。以下是命令步骤和输出。</block>
  <block id="31ef8f0e18e31ab3c319011fa3085595" category="list-text">使用Oracle nid实用程序重命名克隆的数据库实例并更改数据库ID。数据库实例需要处于状态<block ref="19822b1b15d9eefc54c07ab49f87b100" prefix=" " category="inline-code"></block> 以执行命令。</block>
  <block id="deae90bf8a8075e066b36ab46839b972" category="list-text">在oratab、init文件中将Oracle数据库环境配置更改为新的数据库名称或实例ID、并创建与新实例ID匹配的必要管理目录。然后，使用resetlogs"选项启动实例。</block>
  <block id="539484c3a56c32c91eebd8b6c6dd0c01" category="paragraph">这样、就可以在开发、UAT或任何其他使用情形下、通过FSx NFS挂载上的暂存数据库副本克隆新的Oracle实例。可以从同一暂存映像副本克隆多个Oracle实例。</block>
  <block id="b122ab6bc46093e4e498238b2da87899" category="admonition">遇到错误时<block ref="db9915ff14e5c2a62fbc300de8219575" prefix=" " category="inline-code"></block> 在将数据库切换为副本时、请检查与主生产数据库匹配的数据库配置。如果需要、请使用RMAN命令重置此转存方式、使其与主服务器匹配<block ref="762ac7c31f911d73b6a11960c393c6ad" prefix=" " category="inline-code"></block>。</block>
  <block id="420087855d0829aebf7985f8b037c0f5" category="list-text">RMAN：合并增量备份策略(文档ID 745798.1)</block>
  <block id="cebc42ddf70311bb702156ffc928e04f" category="inline-link-macro"><block ref="cebc42ddf70311bb702156ffc928e04f" category="inline-link-rx"></block></block>
  <block id="fb535d4ffc04924a6c6853e4c44cdf5e" category="paragraph"><block ref="fb535d4ffc04924a6c6853e4c44cdf5e" category="inline-link-macro-rx"></block></block>
  <block id="0c10dedf45d356e3143692b00bf17a78" category="list-text">RMAN备份和恢复用户指南</block>
  <block id="067d09ddb20edd1de533097e38987388" category="inline-link-macro"><block ref="067d09ddb20edd1de533097e38987388" category="inline-link-rx"></block></block>
  <block id="475010ac362493ac8aa5ebd15ee454e5" category="paragraph"><block ref="475010ac362493ac8aa5ebd15ee454e5" category="inline-link-macro-rx"></block></block>
  <block id="455ed42b897e59b7476b1f41b16fa943" category="cell">2023年9月6日</block>
  <block id="9c1fbb26b0f6ad48efeff242923d1570" category="cell">新增TR-4973：《在AWS FSx ONTAP上使用增量合并快速恢复和克隆Oracle VLDB》</block>
  <block id="0623403e61b2d6dd08cf57fdc3dc8789" category="sidebar">在AWS FSx ONTAP上通过增量合并快速恢复和克隆Oracle VLDB</block>
  <block id="26340070db5e3907487c23df7dcd4ddc" category="sidebar">适用于数据库的SnapCenter</block>
  <block id="37a8ebbbcf603230c17a02eb0e2dac13" category="sidebar">使用SnapCenter服务执行Oracle备份、还原和克隆—AWS</block>
  <block id="7fa7ffa04f68e2d66ac6bd8166d8ca35" category="sidebar">使用AWS FSx ONTAP快速恢复和克隆Oracle VLDB</block>
  <block id="d7b54624d819bcd713a8bade6dc96b79" category="paragraph">在Anthos 1.14集群上部署三端存储</block>
  <block id="eb31a7776d93779742d99cf1d8e165d4" category="doc">虚拟化视频和演示</block>
  <block id="7dfeac309946b61a62a7a65944ad0acb" category="paragraph">请参见 <block ref="3db733da05bd3e3967dc04592cc322a8" category="inline-link-macro-rx"></block> 用于**复制、备份和恢复**选项。</block>
  <block id="e8a4b8e8901d2f683b07625de269d152" category="paragraph">请参见 <block ref="b17026f8b157d793dc85ba49db8a185d" category="inline-link-macro-rx"></block> 有关**克隆**的更多详细信息。</block>
  <block id="bc7b3bff8f442739862cfc5d624d340d" category="paragraph">以下视频演示了使用BlueXP和Argo CD的应用程序故障转移和故障恢复场景。</block>
  <block id="a7d7ab71d74f0c10d8bcfe243ebe5243" category="paragraph">以下视频显示了在一个区域运行的ROSA应用程序的备份以及还原到另一个区域的过程。</block>
  <block id="b4aaa3fbc0d85cfa527c7cb7f59187fd" category="paragraph">使用适用于NetApp ONTAP 的Amazon FSX在AWS EC2上部署SQL Server</block>
  <block id="7dbe34f3fef2db9f333edc2d7f26f092" category="inline-link-macro">在NetApp TV上观看</block>
  <block id="2dd4d779ad3660fdc971965df3e63860" category="paragraph"><block ref="2dd4d779ad3660fdc971965df3e63860" category="inline-link-macro-rx"></block></block>
  <block id="29144a8d530212e5210d98eceae62106" category="paragraph">网络文件系统(Network File System、NFS)是一种广泛用于存储大量数据的网络文件系统。在大多数企业中、数据越来越多地由Apache Kafka等流式应用程序生成。这些工作负载需要可扩展性、低延迟以及具有现代存储功能的强大数据采集架构。要实现实时分析并提供可指导行动的洞察力、需要一个设计完善且性能高的基础架构。</block>
  <block id="dc9ae5e2a4f056e820a82eac9514fb2c" category="paragraph">有关FSx "update-file-system"的详细命令行语法、请参见：
<block ref="f3196344ef0cf3de8d956a0736aba68b" category="inline-link-rx"></block></block>
  <block id="eadd57f60c0f2d488d9abad2d2c90410" category="inline-image-macro">此图显示了基于FSxN的Kafka集群的架构。</block>
  <block id="fc5366ca7693dfbf0d27e605f38150d1" category="paragraph"><block ref="fc5366ca7693dfbf0d27e605f38150d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="447931d0542671d1817df0b8bdc35ff4" category="list-text">监控。我们将两个节点用于Prometheus-Grafana组合。为了生成工作负载、我们使用了一个单独的三节点集群、该集群可能会生成此Kafka集群并将其占用。</block>
  <block id="c06018aab55e4fa9ef871b34b2cf7897" category="section-title">OpenMessage基准测试配置。</block>
  <block id="79f0e8e2c892a7ffb6c02f9be47fd6f5" category="list-text">按照上述规范、我们使用terraform和Ans得 来配置Kafka集群。Terraform用于使用适用于Kafka集群的AWS实例构建基础架构、而Ans可 在这些实例上构建Kafka集群。</block>
  <block id="477397883986e4a6ef0944db3f171a9a" category="list-text">Sync驱动程序一致生成的总吞吐量：~ 3218 Mbps、峰值性能(~ 3352 Mbps)。</block>
  <block id="526cf61e40ed54cf3e36bc48e608fe6a" category="list-text">吞吐量驱动程序一致生成的总吞吐量：~ 3639 Mbps、峰值性能(~ 3908 Mbps)。</block>
  <block id="1d0957e5fc4340aeed631639b2076501" category="list-text">Sync驱动程序一致生成的总吞吐量：~ 1252 Mbps、峰值性能(~ 1382 Mbps)。</block>
  <block id="e18b6be6753e1c55e4474648e1073e75" category="list-text">吞吐量驱动程序一致生成的总吞吐量：~ 1218 MBps、峰值性能(以~ 1328 MBps为单位)。</block>
  <block id="5d4902b750979a6daa75a334daf3b4dd" category="inline-image-macro">此图显示了Kafka与RF1和RF3的性能</block>
  <block id="67731dd79a61f656bfde458fade09eb2" category="paragraph"><block ref="67731dd79a61f656bfde458fade09eb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7ddac9765853f96e59270871b8a3925" category="inline-image-macro">此图显示了2 GB/秒和4 GB/秒的横向扩展性能。</block>
  <block id="94043e4666620e8e09ceedcb705c7951" category="paragraph"><block ref="94043e4666620e8e09ceedcb705c7951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5e31e558823422acd821d826cc2d30e" category="inline-image-macro">此图显示了RF3中EC2与FSxN的性能比较。</block>
  <block id="6800ca66a2adebbbdc5a76b6efd0b0a8" category="paragraph"><block ref="6800ca66a2adebbbdc5a76b6efd0b0a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b05c2120fe0b40027db89aa85227b95" category="cell">2023年7月14日</block>
  <block id="ac317965fba0e8fd0be4f0af1ef1f7d6" category="cell">更新TR-4947：《使用NetApp NFS存储的Apache Kafka工作负载》(包括AWS FSxN)</block>
  <block id="cc090bcb755694ec2b8ab2fa1beb2258" category="inline-link-macro">3-2-1使用SnapCenter插件和适用于VM的BlueXP备份和恢复为VMware提供数据保护</block>
  <block id="6845b59b08e758d1f76493bad3a906c7" category="list-text"><block ref="6845b59b08e758d1f76493bad3a906c7" category="inline-link-macro-rx"></block></block>
  <block id="66b9f9c0bde1599e448251ccc5fa8591" category="inline-link-macro">NetApp和VMware—前所未有的出色</block>
  <block id="7734acb06ea7c8149179f40ae688ea8a" category="list-text"><block ref="7734acb06ea7c8149179f40ae688ea8a" category="inline-link-macro-rx"></block></block>
  <block id="6ffc220bcf68cdea1a7ee60630b3770b" category="inline-link-macro">vSphere上的Kubnetes (第1部分)</block>
  <block id="718b7fcd61673194858446821c8dea31" category="list-text"><block ref="718b7fcd61673194858446821c8dea31" category="inline-link-macro-rx"></block></block>
  <block id="c6960ae743737cb2431e58eb8f3f4c8c" category="inline-link-macro">vSphere上的Kubnetes (第2部分)</block>
  <block id="6f01eedbaa404894cc11e49fa3f62506" category="list-text"><block ref="6f01eedbaa404894cc11e49fa3f62506" category="inline-link-macro-rx"></block></block>
  <block id="1a3a2b5e6c52142797bb5c00594e2a3c" category="cell">23.04.</block>
  <block id="7d27ef580e2b25090157af5d439420b3" category="cell">2023年7月11日</block>
  <block id="5e164a0091363c6e0b1da21420856dc0" category="cell">更新技术报告- 4947：采用FSxN的Apache Kafka</block>
  <block id="66ed0c3109a99ed48b8e19b3ea3e112e" category="video-title">将FSxN与适用于ROSA集群的Asta Trident集成</block>
  <block id="1a8aad6624d7b4fac77277944621f147" category="video-title">Rosa集群与Amazon FSx for ONTAP集成</block>
  <block id="bfbf5b1dfe74d3c210d9bff256a2d37d" category="video-title"> 借助适用于NetApp ONTAP 的Amazon FSX、基于AWS的VMware Cloud可节省TCO</block>
  <block id="f14bcb2fca0b787c927519fa290c9276" category="video-title"> 采用Cloud Volumes ONTAP 、SnapCenter 和Jetstream的Azure VMware解决方案 灾难恢复</block>
  <block id="517ef02b70647f930adac5d5e8a518a2" category="paragraph">[下划线]#*使用Astra Control Center*#进行灾难恢复</block>
  <block id="a513ccac96294c17623435e7ea5fdf5b" category="doc">AWS FSx for NetApp ONTAP中的性能概述和验证</block>
  <block id="d30bd16c873aea4d3714997da3d96677" category="paragraph">在AWS FSx for NetApp ONTAP中、对NetApp NFS上挂载了存储层的Kafka集群进行了性能基准测试。以下各节将介绍这些基准测试示例。</block>
  <block id="f03d1e3325d1abef2b2d40923019ec24" category="section-title">AWS FSx for NetApp ONTAP中的Apache Kafka</block>
  <block id="515a18b2b67265864bb21b039945426f" category="paragraph">Kafka的设计支持POSIX兼容文件系统、并依靠文件系统来处理文件操作、但在NFS3文件系统上存储数据时、Kafka代理NFS客户端对文件操作的解释可能与XFS或ext4等本地文件系统不同。一个常见的示例是NFS愚蠢的重命名、该重命名导致Kafka代理在扩展集群和重新分配分区时失败。为了应对这一挑战、NetApp对开源Linux NFS客户端进行了更新、对RHEL8.7和RHEL9.1中的内容进行了一般更改、并从当前FSx for NetApp ONTAP版本ONTAP 9.12.1开始受支持。</block>
  <block id="4d0e9f7486615357fc91eeb4d7b21afe" category="paragraph">Amazon FSx for NetApp ONTAP可在云中提供一个完全托管、可扩展且高性能的NFS文件系统。FSx for NetApp ONTAP上的Kafka数据可以进行扩展、以处理大量数据并确保容错。NFS可为关键和敏感数据集提供集中式存储管理和数据保护。</block>
  <block id="26f2651d5272b19f416b75e2459d265e" category="paragraph">通过这些增强功能、AWS客户可以在AWS计算服务上运行Kafka工作负载时利用FSx for NetApp ONTAP。这些优势包括：
*降低CPU利用率以缩短I/O等待时间
* Kafka代理恢复时间更快。
*可靠性和效率。
*可扩展性和性能。
*多可用性区域可用性。
*数据保护。</block>
  <block id="a946c589e72411c6ca06f80658569055" category="section-title">Kafka位于AWS FSx for NetApp ONTAP中</block>
  <block id="8958542ca63d1c1db2794fe10ad42745" category="paragraph">采用AWS FSx for NetApp ONTAP的Kafka集群已通过AWS云中的性能基准测试。以下各节将介绍此基准测试。</block>
  <block id="6d2318a94e4971f5c792ce5ef39546a7" category="paragraph">下表显示了使用AWS FSx for NetApp ONTAP的Kafka集群的环境配置。</block>
  <block id="294a286601ea0d06d3268d1dfe0dddd8" category="cell">AWS FSx for NetApp ONTAP</block>
  <block id="9e813193a6755822d3c1628326e814e6" category="cell">多可用性(AZ)、吞吐量为4 GB/秒、IOPS为160000次</block>
  <block id="5be51511cfc1e4bffe14ee63e6319797" category="section-title">NetApp FSx for NetApp ONTAP设置</block>
  <block id="2c2b7aa212365a0a958a10494ee7d17a" category="list-text">在初始测试中、我们为NetApp ONTAP文件系统创建了一个FSx、容量为2 TB、吞吐量为400、000 IOPS、每秒2 GB。</block>
  <block id="c9d491255cca763c5febacf246a8a550" category="paragraph">在本示例中、我们将通过AWS命令行界面部署FSx for NetApp ONTAP。您需要根据需要在环境中进一步自定义此命令。此外、FSx for NetApp ONTAP还可以通过AWS控制台进行部署和管理、以减少命令行输入、获得更轻松、更简化的部署体验。</block>
  <block id="c97db261e82d5db4b96152113691af22" category="paragraph">文档在FSx for NetApp ONTAP中、测试区域(US-East-1)中2 GB/秒吞吐量文件系统可实现的最大IOPS为80、000次IOPS。FSx for NetApp ONTAP文件系统的总最大IOPS为160、000次IOPS、需要部署4 GB/秒吞吐量才能达到此目的、我们将在本文档后面进行演示。</block>
  <block id="cab28d9c3e2ebaff500104615f70cece" category="paragraph">有关FSx for NetApp ONTAP性能规格的详细信息、请随时访问AWS FSx for NetApp ONTAP文档、网址为：<block ref="f270bb91d9718c264ef59ceaf9562990" category="inline-link-rx"></block> 。</block>
  <block id="d2a50944ae04ca40cf752eb413d44240" category="paragraph">有关FSx "crea-File-system"的详细命令行语法、请参见：<block ref="6dfaa72a4db79e3cd69acb6bd09e3928" category="inline-link-rx"></block></block>
  <block id="4510c1fa7d54bc22137fc99fdee7ec14" category="paragraph">例如、您可以指定特定的KMS密钥、而不是在未指定KMS密钥时使用的默认AWS FSx主密钥。</block>
  <block id="56dcf09d20c6c8ce71e510beece4fb43" category="list-text">创建FSx for NetApp ONTAP文件系统时、请等到JSON返回中的"LifeCycle (生命周期)"状态更改为"Available (可用)"、然后按如下所示描述文件系统：</block>
  <block id="5f772c6f56452d403e6db1bd43d88805" category="list-text">使用fsxadmin用户登录到FSx for NetApp ONTAP SSH以验证凭据：
FSxadmin是创建时FSx for NetApp ONTAP文件系统的默认管理员帐户。fsxadmin的密码是我们在步骤1中完成的首次在AWS控制台中或使用AWS命令行界面创建文件系统时配置的密码。</block>
  <block id="0d4e5a2cd068395a686f870f1385128d" category="list-text">验证凭据后、在FSx for NetApp ONTAP文件系统上创建Storage Virtual Machine</block>
  <block id="949e270419f0a5ea95408c6ad9d46d49" category="paragraph">Storage Virtual Machine (SVM)是一种孤立的文件服务器、具有自己的管理凭据和端点、用于管理和访问FSx for NetApp ONTAP卷中的数据、并提供FSx for NetApp ONTAP多租户功能。</block>
  <block id="49cb05ea5d58197c396f5cc2fc3d6385" category="list-text">配置主Storage Virtual Machine后、通过SSH连接到新创建的FSx for NetApp ONTAP文件系统、然后使用以下示例命令在Storage Virtual Machine中创建卷、同样、我们会为此验证创建6个卷。根据我们的验证、保留默认成分卷(8)或更少的成分卷、这样可以提高Kafka的性能。</block>
  <block id="f82c8c9ef7e5f94bfc60abe80b30a2c1" category="list-text">我们需要在卷中增加容量以进行测试。将卷的大小扩展到2 TB、然后挂载到接合路径上。</block>
  <block id="57ffc46c7abade26210d6b279d948642" category="paragraph">在FSx for NetApp ONTAP中、可以对卷进行精简配置。在我们的示例中、扩展卷总容量超过文件系统总容量、因此我们需要扩展文件系统总容量、以便解锁额外配置的卷容量、我们将在下一步演示这一点。</block>
  <block id="f5149cad95db621501bb57a5e8f9fdc8" category="list-text">接下来、为了提高性能和容量、我们将FSx的NetApp ONTAP吞吐量容量从2 GB/秒扩展到4 GB/秒、将IOPS扩展到160000、并将容量扩展到5 TB</block>
  <block id="2586c56e24677e7ec9e689a2715d582f" category="list-text">FSx for NetApp ONTAP卷使用nconnect和默认选项挂载在Kafka代理中</block>
  <block id="f3a650428631f984ec62ea11d7184e28" category="paragraph">下图显示了基于Kafka集群的FSx for NetApp ONTAP的最终架构：</block>
  <block id="1d3c06332d47b7673bfb3de4b1873c05" category="list-text">计算。我们使用了一个三节点Kafka集群、其中一个三节点Zookeer集合运行在专用服务器上。每个代理都有六个NFS挂载点、指向FSx for NetApp ONTAP实例上的六个卷。</block>
  <block id="1eec4077fa002cb2f4b537c3a8504829" category="list-text">存储。我们使用FSx for NetApp ONTAP、其中已挂载六个2 TB卷。然后、使用NFS挂载将卷导出到Kafka代理。FSx for NetApp ONTAP卷使用Kafka代理中的16个nconnect会话和默认选项进行挂载。</block>
  <block id="2ea31b84b3c57f71152888fb4f418f80" category="paragraph">我们使用了与NetApp Cloud Volumes ONTAP相同的配置、其详细信息如下所示-
<block ref="6134638458f4b728e1bf1e106663272c" category="inline-link-rx"></block></block>
  <block id="1b45f9648944314d0313517cb18e6725" category="paragraph">对于Kafka复制因子1和FSx for NetApp ONTAP：</block>
  <block id="90a4ae0f0929d214ce8581c894aa570e" category="paragraph">对于复制因子为3的Kafka和FSx for NetApp ONTAP：</block>
  <block id="f10b62074123ea83c62b78dd7b9e3bbc" category="paragraph">在Kafka复制因子3中、读取和写入操作在FSx for NetApp ONTAP上发生了三次；在Kafka复制因子1中、读取和写入操作在FSx for NetApp ONTAP上发生了一次、因此、在这两种验证中、 我们可以达到4 GB/秒的最大吞吐量。</block>
  <block id="87da5afc68c648a72b9345b444e73dc0" category="paragraph">下图显示了NetApp ONTAP的2 GB/秒FSx和Kafka复制因子3的4 GB/秒性能。复制因子3在FSx for NetApp ONTAP存储上执行三次读取和写入操作。吞吐量驱动程序的总速率为881 MB/秒、在NetApp ONTAP文件系统的2 GB/秒FSx上执行读取和写入Kafka操作的速率约为2.64 GB/秒、吞吐量驱动程序的总速率为1328 MB/秒、执行读取和写入Kafka操作的速率约为3.98 GB/秒。Kafka的性能是线性的、可根据FSx for NetApp ONTAP吞吐量进行扩展。</block>
  <block id="af5fd1c3f0fb06bafc9ae98e66229d75" category="paragraph">下图显示了EC2实例与FSx for NetApp ONTAP之间的性能(Kafka复制因子：3)</block>
  <block id="32fbd740c28afd94422aeceef5424762" category="paragraph">NetApp AFF A400是一款中端NVMe闪存存储系统、具有以下功能：</block>
  <block id="4b78ed4e994ac9de0ed2b09e38067a6a" category="list-text">最大有效容量：~20 PB</block>
  <block id="a7e34646cec9235e89d2d2fdc097a010" category="paragraph">我们录制了 NetApp 零售助理（ Nara ）的演示视频。</block>
  <block id="19ae8131d6f70ff609fd60ac98b46986" category="section-title">视频演示的一个例子</block>
  <block id="d7fd58c27a131209e8f320d109b293cc" category="sidebar">AWS中的性能概述和验证—Cloud Volume ONTAP</block>
  <block id="3f2906298c684e48c8e4b47425c2cf34" category="sidebar">AWS中的性能概述和验证—FSxN NetApp ONTAP</block>
  <block id="9682ccea75ba1a582dd9ea16fe998427" category="paragraph">要了解有关此过程的更多信息、请随时观看以下视频：</block>
  <block id="c39fe43977e2c690fe3f545e74b066be" category="doc">3-2-1使用SnapCenter插件和适用于VM的BlueXP备份和恢复为VMware提供数据保护</block>
  <block id="73d726d10be1ea38417dcb3b42dbce61" category="paragraph">3-2-1备份策略是行业认可的数据保护方法、可提供全面的方法来保护有价值的数据。  此策略非常可靠、可确保即使发生意外灾难、仍有可用数据的副本。</block>
  <block id="509fafef5caf053ccaadfb4cc21d6d1e" category="paragraph">该战略由三条基本规则组成：</block>
  <block id="c59e6a73bffbd424d174a45535073085" category="list-text">至少保留三份数据副本。这样可以确保即使一个副本丢失或损坏、您仍至少有两个剩余副本可供回退。</block>
  <block id="3523fd69b600ce77f8d1bca567d238a8" category="list-text">将两个备份副本存储在不同的存储介质或设备上。多样化的存储介质有助于防止设备或介质特定的故障。如果一个设备损坏或一种介质发生故障、另一个备份副本不受影响。</block>
  <block id="28293b551463a96414b8b221ea51d2a4" category="list-text">最后、确保至少有一个备份副本位于异地。异地存储可防止发生火灾或洪水等本地灾难、这些灾难可能会导致现场副本不可用。</block>
  <block id="652bf9c1cb169825b57e6e7e9bce3bfe" category="paragraph">本解决方案文档介绍解决方案了使用适用于VMware vSphere的SnapCenter插件(SCV)为内部虚拟机创建主备份和二级备份的3-2-1备份、以及使用BlueXP备份和恢复为虚拟机将数据副本备份到云存储或StorageGRID。</block>
  <block id="d45fada9eb7a8910240cceebfb467b7f" category="list-text">使用适用于VMware vSphere的SnapCenter插件备份和还原内部虚拟机和数据存储库。</block>
  <block id="cdff43c972e7e0887564442e31301617" category="list-text">备份和还原ONTAP集群上托管的内部虚拟机和数据存储库、并使用适用于虚拟机的BlueXP备份和恢复功能备份到对象存储。</block>
  <block id="3fa5ba71652fad9133d2c14b46d4643b" category="section-title">NetApp ONTAP数据存储</block>
  <block id="5db39070b53880f580957857f0ef2232" category="paragraph">ONTAP是NetApp行业领先的存储解决方案、无论您是通过SAN还是NAS协议访问、它都能提供统一存储。3-2-1备份策略可确保内部数据在多种介质类型上受到保护、NetApp提供的平台从高速闪存到低成本介质不等。</block>
  <block id="2f62861d2a5e5fb79aa4172b030338eb" category="image-alt">ONTAP数据存储</block>
  <block id="6b81bed24ba6625c8f9c67f67504860b" category="inline-link">NetApp数据存储</block>
  <block id="db9f5d48e49eef57b9f1326c98fe2c3a" category="paragraph">有关NetApp所有硬件平台的详细信息、请查看<block ref="c34bf72c5a8854a98b9e0f11814bb981" category="inline-link-rx"></block>。</block>
  <block id="1107fdf7c893cd3cc0b42fe985ddcc81" category="paragraph">适用于VMware vSphere的SnapCenter插件是一款数据保护产品、与VMware vSphere紧密集成、可轻松管理虚拟机的备份和还原。作为解决方案的一部分、SnapMirror提供了一种快速可靠的方法、可在二级ONTAP存储集群上为虚拟机数据创建第二个不可变化的备份副本。采用此架构后、可以轻松地从主备份位置或二级备份位置启动虚拟机还原操作。</block>
  <block id="a6b184ab39b134eab2c079a8be61a931" category="paragraph">SCV使用OVA文件部署为Linux虚拟设备。现在、此插件将使用远程插件
架构。远程插件在vCenter Server外部运行、并托管在SCV虚拟设备上。</block>
  <block id="8c3d0c00ea667e3e0723e5cdc6473a09" category="inline-link">适用于 VMware vSphere 的 SnapCenter 插件文档</block>
  <block id="727c896d5f97fa0b914653e81a4004ae" category="paragraph">有关选择控制阀的详细信息，参见<block ref="245718e19f61bc6ffd537e61a8d903cc" category="inline-link-rx"></block>。</block>
  <block id="b6e8ba95aa7220434ae393716a0bf9d6" category="section-title">适用于虚拟机的BlueXP备份和恢复</block>
  <block id="4f577581972081fe4f346ed9fa5a8ef3" category="paragraph">BlueXP备份和恢复是一款基于云的数据管理工具、可为内部和云环境中的各种备份和恢复操作提供单一控制平台。NetApp BlueXP备份和恢复套件的一部分是一项与适用于VMware vSphere的SnapCenter插件(内部)集成的功能、用于将数据副本扩展到云中的对象存储。这样可以为来自主存储备份或二级存储备份的异地数据创建第三个副本。通过BlueXP备份和恢复、您可以轻松设置存储策略、以便从这两个内置位置中的任何一个位置传输数据副本。</block>
  <block id="f8f023e5c60168abd6ba94cb0aa6a8e7" category="paragraph">在BlueXP备份和恢复中选择主备份和二级备份作为源将导致实施以下两种拓扑之一：</block>
  <block id="167f8e4f22387317bf771adbbf4d57b5" category="paragraph">*扇出拓扑*—适用于VMware vSphere的SnapCenter插件启动备份时，会立即创建本地快照。然后、SCV启动SnapMirror操作、将最新的快照复制到二级ONTAP集群。在BlueXP备份和恢复中、策略会将主ONTAP集群指定为要传输到所选云提供商中的对象存储的数据Snapshot副本的源。</block>
  <block id="6a9a440af38ad6d846f8627b26ead457" category="image-alt">扇出拓扑</block>
  <block id="81d79c86c069e3ae594d83caf7125000" category="paragraph">*级联拓扑*–使用SCV创建主数据副本和二级数据副本与上述扇出拓扑相同。但是、这一次在BlueXP备份和恢复中创建一个策略、指定对象存储备份将源自二级ONTAP集群。</block>
  <block id="33d67182b13ad638b65acf71a1aa76a6" category="image-alt">级联拓扑</block>
  <block id="0db613f591f5c0374778e6a61b91eaf0" category="paragraph">BlueXP备份和恢复可以为内部ONTAP快照创建备份副本、并将其备份到AWS Glacie、Azure Blb和GCP归档存储。</block>
  <block id="f2bc28d75682808c368d801d60058bdb" category="inline-link">StorageGRID登录页面</block>
  <block id="ed5c83fe833f279aa143145882d6ee92" category="paragraph">此外、您还可以使用NetApp StorageGRID作为对象存储备份目标。有关StorageGRID的详细信息、请参阅<block ref="91b9d2909092a1a1573b8d4ec4f61279" category="inline-link-rx"></block>。</block>
  <block id="3633716d35b3ea5361a4fa4a42501702" category="paragraph">此列表提供了配置此解决方案以及从SCV和BlueXP备份和恢复执行备份和恢复操作所需的高级步骤：</block>
  <block id="163a7b0980d4119c657b0e0692a44075" category="list-text">在要用于主数据副本和二级数据副本的ONTAP集群之间配置SnapMirror关系。</block>
  <block id="467ff501370e8e59c449bc28908972fa" category="list-text">配置适用于VMware vSphere的SnapCenter插件。</block>
  <block id="3c1fdff568fdec856cfa61307b6fb382" category="list-text">添加存储系统</block>
  <block id="0a4a3719bc7519d1162060e0f0e08f8a" category="list-text">创建备份策略</block>
  <block id="020a36deb114af1bb518c70d5975e940" category="list-text">创建资源组</block>
  <block id="2fff8be5fc844ef3714da61ac825a784" category="list-text">运行备份优先备份作业</block>
  <block id="d2e7af1a008f2d266baa6964ec83ec90" category="list-text">为虚拟机配置BlueXP备份和恢复</block>
  <block id="ddf0d84991cb06158f6eca119f5aa89c" category="list-text">添加工作环境</block>
  <block id="00bb17e4689d02ead6add58fb47a2cb7" category="list-text">发现SCV和vCenter设备</block>
  <block id="cc1fa2ce00018956ccb6c745af1b7161" category="list-text">激活备份</block>
  <block id="5f56644222973cb771d4bc0cdb2494f1" category="list-text">使用SCV从主存储和二级存储还原虚拟机。</block>
  <block id="29eee2e7da81f7b38ac9c51c18b164c0" category="list-text">使用BlueXP备份和还原从对象存储还原虚拟机。</block>
  <block id="10a2ab5ad14a0568e5f24184a3de0c84" category="paragraph">此解决方案的目的是演示对在VMware vSphere中运行且位于由NetApp ONTAP托管的NFS数据存储库上的虚拟机的数据保护。此解决方案 假定已配置以下组件并可供使用：</block>
  <block id="eeb794f9274b58305465e4fa7b8ecb19" category="list-text">使用NFS或VMFS数据存储库连接到VMware vSphere的ONTAP存储集群。支持NFS和VMFS数据存储库。此解决方案使用了NFS数据存储库。</block>
  <block id="cec64789cb22c92bd3e83e152c7462b1" category="list-text">为用于NFS数据存储库的卷建立SnapMirror关系的二级ONTAP存储集群。</block>
  <block id="1a192383caece8526c650ea10ec56244" category="list-text">为用于对象存储备份的云提供程序安装了BlueXP连接器。</block>
  <block id="8b2d5235ad2094129ec911a569dd15b9" category="list-text">要备份的虚拟机位于主ONTAP存储集群上的NFS数据存储库中。</block>
  <block id="6ec76887b4a3a1aed8cf56c378426950" category="list-text">BlueXP连接器和内部ONTAP存储集群管理接口之间的网络连接。</block>
  <block id="88a4f5f2a88a34308791c2b2bae6bc53" category="list-text">BlueXP连接器和内部SCV设备VM之间以及BlueXP连接器和vCenter之间的网络连接。</block>
  <block id="14502956de0b18aac2e67512bf39e746" category="list-text">内部ONTAP集群间LUN和对象存储服务之间的网络连接。</block>
  <block id="f4df2638179ad69f631687a593408fb1" category="inline-link">配置 DNS 以进行主机名解析</block>
  <block id="5eead32ad2eb390a7a2be60277c27914" category="list-text">在主和二级ONTAP存储集群上为管理SVM配置了DNS。有关详细信息、请参见<block ref="07c761163331a05d2a34d62a1e39df8f" category="inline-link-rx"></block>。</block>
  <block id="7ed1d0ce67ee86ec3e3522819949c9c6" category="paragraph">此解决方案 的测试/验证是在可能与最终部署环境匹配或可能不匹配的实验室中执行的。</block>
  <block id="dff3ea20bab3486b4778fbae4dfd6d20" category="paragraph">在本解决方案中、我们详细说明了如何部署和验证解决方案、该利用适用于VMware vSphere的SnapCenter插件以及BlueXP备份和恢复功能、在内部数据中心的VMware vSphere集群中执行Windows和Linux虚拟机的备份和恢复。此设置中的虚拟机存储在ONTAP A300存储集群托管的NFS数据存储库中。此外、一个单独的ONTAP A300存储集群可用作使用SnapMirror复制的卷的二级目标。此外、Amazon Web Services和Azure Blb上托管的对象存储也用作数据第三个副本的目标。</block>
  <block id="3598805e9e62ee54d3f84340785c25f3" category="paragraph">我们将继续为SCV管理的备份的二级副本创建SnapMirror关系、并在SCV和BlueXP备份和恢复中配置备份作业。</block>
  <block id="2046eeb71e1e38497f5d706ddd361ac6" category="paragraph">有关适用于VMware vSphere的SnapCenter插件的详细信息、请参见<block ref="245718e19f61bc6ffd537e61a8d903cc" category="inline-link-rx"></block>。</block>
  <block id="c756b6b1ba6b752239a8d49eda5ad2a4" category="inline-link">BlueXP备份和恢复文档</block>
  <block id="6f89c1575d847917cac76d8e5703913d" category="paragraph">有关BlueXP备份和恢复的详细信息、请参阅<block ref="f913b694a1f9d667c4a8fd38d834b075" category="inline-link-rx"></block>。</block>
  <block id="49ff278b23e1b2a48f41c26059993a78" category="section-title">在ONTAP集群之间建立SnapMirror关系</block>
  <block id="913a4fc9e4dd2b3ae4e143f1654897a6" category="paragraph">适用于VMware vSphere的SnapCenter插件使用ONTAP SnapMirror技术管理将二级SnapMirror和/或SnapVault副本传输到二级ONTAP集群的过程。</block>
  <block id="a8c8e1c43cc229715b454d8fa5870c7c" category="paragraph">选择控制阀备份策略可以选择使用SnapMirror或SnapVault关系。主要区别在于、使用SnapMirror选项时、在策略中为备份配置的保留计划在主位置和二级位置将相同。SnapVault专为归档而设计、使用此选项时、可以通过SnapMirror关系为二级ONTAP存储集群上的Snapshot副本建立单独的保留计划。</block>
  <block id="4cb7bc8b80ea6dad6b32452e211210f0" category="paragraph">可以在BlueXP中自动执行许多步骤来设置SnapMirror关系、也可以使用System Manager和ONTAP命令行界面来设置SnapMirror关系。下面将讨论所有这些方法。</block>
  <block id="ef2376e2d99283ddc3b8c4802978ddbd" category="section-title">与BlueXP建立SnapMirror关系</block>
  <block id="f8d9e61c93c3e0e3bf563a4116f49d98" category="paragraph">必须从BlueXP Web控制台完成以下步骤：</block>
  <block id="d24e7c83eb605dbec3784d9614f113b5" category="example-title">主和二级ONTAP存储系统的复制设置</block>
  <block id="49f6d5194173a4f2c65fe97e7137f8f0" category="paragraph">首先登录到BlueXP Web控制台并导航到Canvas。</block>
  <block id="3c0f6ff9fcfb31caedb1d772b584ba4b" category="list-text">将源(主) ONTAP存储系统拖放到目标(二级) ONTAP存储系统上。</block>
  <block id="fb8e05d47d62709ef79a3548c465824b" category="image-alt">拖放存储系统</block>
  <block id="0b2f572176c0750f020444a06975efe5" category="list-text">从显示的菜单中选择*复制*。</block>
  <block id="4113739f808592642c550c5fe54ec592" category="image-alt">选择复制</block>
  <block id="e5f6d5cc562fe22168422e7aa9cc375e" category="list-text">在*目标对等设置*页面上、选择要用于存储系统之间连接的目标集群间Lifs。</block>
  <block id="236b5c3a30fbbc54d60376d51df3532d" category="image-alt">选择集群间的"Lif"</block>
  <block id="e8f6c047788f58d67e54dec98696fb0c" category="list-text">在*目标卷名称*页面上、首先选择源卷、然后填写目标卷名称并选择目标SVM和聚合。单击“*下一步*”继续。</block>
  <block id="645921f02f2dac5fa2d2e303540e32f8" category="image-alt">选择源卷</block>
  <block id="3b76070fa2cc56c5fcbd663652f98016" category="image-alt">目标卷详细信息</block>
  <block id="7a3ae81d2cdd1f20c1e0ab2cf2e5e7f1" category="list-text">选择进行复制的最大传输速率。</block>
  <block id="8030f0a596dd92c4e1ab83a92fcb2cf4" category="image-alt">最大传输速率</block>
  <block id="9aaa08ac7ae790464209fbbb75c1beaa" category="list-text">选择用于确定二级备份的保留计划的策略。此策略可以事先创建(请参见下面的*创建快照保留策略*步骤中的手动过程)，也可以在创建后根据需要进行更改。</block>
  <block id="88a94fe3ed96529f26274615154db705" category="image-alt">选择保留策略</block>
  <block id="db5c66004f1ed1f27553c6c860000ff1" category="list-text">最后，查看所有信息，然后单击*go *按钮开始复制设置过程。</block>
  <block id="47bffa5ab95e0811d3f30876e2606f2a" category="image-alt">查看并继续</block>
  <block id="d5eac7a731f52e4a649eab3e1c912c67" category="section-title">使用System Manager和ONTAP命令行界面建立SnapMirror关系</block>
  <block id="b3601aca3588268c73b133d8b499b359" category="paragraph">可以使用System Manager或ONTAP命令行界面完成建立SnapMirror关系所需的所有步骤。下一节提供了这两种方法的详细信息：</block>
  <block id="0398b97023ab8d66a2cebc9778ec3ad7" category="paragraph">对于源和目标ONTAP集群、您可以从System Manager或命令行界面检索集群间LIF信息。</block>
  <block id="d27bd36691209e1564205c3f1caf62d7" category="list-text">要使用命令行界面检索集群间IP地址、请运行以下命令：</block>
  <block id="c2fab493a5ab05eccf4bcde8e480dfa2" category="example-title">在ONTAP集群之间建立集群对等关系</block>
  <block id="f91c80d884d806d9bf4fce9df02f1af0" category="list-text">使用在目标ONTAP集群上设置对等关系<block ref="9b5825a8b104756a9fc62c8432005be0" prefix=" " category="inline-code"></block> 命令：出现提示时、输入一个唯一的密码短语、稍后在源集群上使用该密码短语以完成创建过程。</block>
  <block id="4ab68f29d4e8a5aa87841709184e59f3" category="list-text">输入用于在目标ONTAP集群上建立对等集群关系的密码短语。</block>
  <block id="fcc33672123bea59be1df35a432d2a6b" category="list-text">输入目标ONTAP集群的集群间LIF IP地址。</block>
  <block id="37f976523440bb8ebeb1a9c230d4295d" category="list-text">使用以下命令验证目标ONTAP集群的集群对等关系的状态：</block>
  <block id="26e326671f9e973061f4f87c8f4f45a7" category="paragraph">要在ONTAP上创建目标卷、以便接收源卷的Snapshot副本、请在目标ONTAP集群上运行以下命令：</block>
  <block id="0e2ee67851678bd7ea95e7e35dcc70ae" category="paragraph">要在源卷和目标卷之间创建SnapMirror关系、请在目标ONTAP集群上运行以下命令：</block>
  <block id="a9f63a791ce3894dceda58722183fb0b" category="paragraph">要创建卷、请在目标ONTAP集群上运行以下命令：</block>
  <block id="1ca34645e71e527c9cbf105d533617d8" category="section-title">配置适用于VMware vSphere的SnapCenter插件</block>
  <block id="4aaaa261348faebbaa0d92e42a350d57" category="paragraph">安装后、可从vCenter Server设备管理界面访问适用于VMware vSphere的SnapCenter插件。SCV将管理装载到ESXi主机且包含Windows和Linux VM的NFS数据存储库的备份。</block>
  <block id="820a69c65133a14dbbca6b21c7e990db" category="inline-link">数据保护工作流</block>
  <block id="1dca79d6b8350fa7277bf35fb51ba16a" category="paragraph">查看<block ref="b578afc15a11f99c74dc0f315c68211a" category="inline-link-rx"></block> 有关配置备份所涉及步骤的详细信息，请参阅选择控制阀文档的一节。</block>
  <block id="efd902c16f7cfb85502b744cd19da31f" category="paragraph">要配置虚拟机和数据存储库的备份、需要从插件界面完成以下步骤。</block>
  <block id="d807e49c227b080d4f5049bffc321a2e" category="example-title">Discovery ONTAP存储系统</block>
  <block id="bc22e247a11953d8b03cd9e4f5b6c197" category="paragraph">发现要用于主备份和二级备份的ONTAP存储集群。</block>
  <block id="07ed7524efc06d460431631e976b61f9" category="list-text">在适用于VMware vSphere的SnapCenter插件中，导航到左侧菜单中的*存储系统*，然后单击*Add*按钮。</block>
  <block id="87d2b5d50a3f94d38a8b567627e0fb58" category="image-alt">存储系统</block>
  <block id="52a6c0a49725eb4c01d8f71114a3f6e7" category="list-text">填写主ONTAP存储系统的凭据和平台类型，然后单击*Add*。</block>
  <block id="5a2a64756df08f9a9f424f03b33920fd" category="image-alt">添加存储系统</block>
  <block id="3d4893d15cb60bbc0186353b685f573e" category="list-text">对二级ONTAP存储系统重复此操作步骤。</block>
  <block id="2f7eef9ddf88248dd690f4a6ecc31f72" category="example-title">创建选择控制阀备份策略</block>
  <block id="43eae0dcccb66d4da1d0796e1c585c2b" category="paragraph">策略用于为SCV管理的备份指定保留期限、频率和复制选项。</block>
  <block id="8e76505b54822d8003db9695ebc8dded" category="inline-link">为 VM 和数据存储库创建备份策略</block>
  <block id="b098f73dbbbba5e35da3c1680d8b2531" category="paragraph">查看<block ref="17aa01733a94bdbfd1ea488a2255eeb4" category="inline-link-rx"></block> 有关详细信息、请参见文档中的第节。</block>
  <block id="97ecece1c0de6ff609f5ac95922948a1" category="paragraph">要创建备份策略、请完成以下步骤：</block>
  <block id="d65e07f581d9e8a768d928ee53e6af96" category="list-text">在适用于VMware vSphere的SnapCenter插件中、导航到左侧菜单中的*策略*、然后单击*创建*按钮。</block>
  <block id="9e476387322a5c250893cf9c5c4ce78c" category="image-alt">策略</block>
  <block id="3287abe20108fcae946deb6260cf8563" category="list-text">指定策略名称、保留期限、频率和复制选项以及快照标签。</block>
  <block id="663b8460da445a8bdcdacd5586794a5a" category="image-alt">创建策略</block>
  <block id="288f9e0d4ace01e5bcd057f2b9aa9cbd" category="admonition">在SnapCenter插件中创建策略时、您将看到SnapMirror和SnapVault的选项。如果选择SnapMirror、则主快照和二级快照在策略中指定的保留计划将相同。如果选择SnapVault、则二级快照的保留计划将基于通过SnapMirror关系实施的单独计划。如果您希望二级备份的保留期限更长、则此功能非常有用。</block>
  <block id="9a9dafcee3fdb0dbad8b58495e0676e8" category="list-text">对所需的每个策略重复操作步骤。例如、为每日、每周和每月备份分别设置策略。</block>
  <block id="b9c3c294e7e2345ef69743b4899f43f0" category="paragraph">资源组包含要包含在备份作业中的数据存储库和虚拟机、以及关联的策略和备份计划。</block>
  <block id="91157a1c630ebb8dfa5964bc5c596222" category="paragraph">查看<block ref="1100db64f963d9605fc8b4bac46beeaa" category="inline-link-rx"></block> 有关详细信息、请参见文档中的第节。</block>
  <block id="973ed29ddeed8a98e42472c954429af8" category="paragraph">要创建资源组，请完成以下步骤。</block>
  <block id="4154a97279f97cd0f19c397b26678640" category="list-text">在适用于VMware vSphere的SnapCenter插件中、导航到左侧菜单中的*资源组*、然后单击*创建*按钮。</block>
  <block id="46146f5a761be19d6f64a61bb0785507" category="list-text">在创建资源组向导中、输入组的名称和问题描述以及接收通知所需的信息。单击“*下一步*”</block>
  <block id="d448e41a78a0a01dc94ae71b6d13635a" category="list-text">在下一页上、选择要包含在备份作业中的数据存储库和虚拟机、然后单击*下一步*。</block>
  <block id="3a7784760afa67457011aa1be4248493" category="image-alt">选择数据存储库和虚拟机</block>
  <block id="306006354b17f98ebc352f2ccabe1b8c" category="admonition">您可以选择特定虚拟机或整个数据存储库。无论选择哪种方式、都会备份整个卷(和数据存储库)、因为备份是通过为底层卷创建快照来完成的。在大多数情况下、最简单的方法是选择整个数据存储库。但是、如果要在还原时限制可用VM的列表、则只能选择一部分VM进行备份。</block>
  <block id="10e47b32ebff05d654d6c620c43c81d8" category="list-text">为VMDK位于多个数据存储库上的VM选择跨数据存储库选项、然后单击*下一步*。</block>
  <block id="6b933c0b04e021dd664c8a6c4d7cdee0" category="image-alt">跨数据存储库</block>
  <block id="b18bd79c84b4f3e6ead32a02f410c9d0" category="admonition">BlueXP备份和恢复目前不支持使用跨多个数据存储库的VMDK备份VM。</block>
  <block id="9e70c3d4b1cb5df581462a740d4763a0" category="list-text">在下一页中，选择要与资源组关联的策略，然后单击*Next*。</block>
  <block id="cb5934fee2416cd37a43827ca131db09" category="image-alt">资源组策略</block>
  <block id="24e08063677b3f167cebf7ff704c5c4e" category="admonition">使用BlueXP备份和恢复将SCV管理的快照备份到对象存储时、每个资源组只能与一个策略相关联。</block>
  <block id="743bb6ade55395c48403a8fb1fbe308e" category="list-text">选择一个计划、以确定备份的运行时间。单击“*下一步*”。</block>
  <block id="65ac639efbb86b722b74780e19ce0861" category="list-text">最后，查看摘要页，然后在*Finish (完成)*上完成资源组的创建。</block>
  <block id="41e16971a21fc160e688d85314e4a9c2" category="example-title">运行备份作业</block>
  <block id="220c04f39bef382d5a0b1ed04f0d3cdd" category="paragraph">在最后一步中、运行备份作业并监控其进度。必须在SCV中至少成功完成一个备份作业、然后才能从BlueXP备份和恢复中发现资源。</block>
  <block id="e35955bf0accfd03e4d43701a216978c" category="list-text">在适用于VMware vSphere的SnapCenter插件中、导航到左侧菜单中的*资源组*。</block>
  <block id="0f984890023fbeb2a4f8723c1e495f2c" category="list-text">要启动备份作业，请选择所需的资源组，然后单击*立即运行*按钮。</block>
  <block id="1375a3914da8c67b1fcc8cf00d7fba6d" category="list-text">要监控备份作业，请导航至左侧菜单中的*Dashboard。在*近期工作活动*下，单击工作ID号以监视工作进度。</block>
  <block id="d8d2bc1b59b89418a5362bbf6a7d5ab4" category="image-alt">监控作业进度</block>
  <block id="094e2089ce7608674cadf42d6de48d97" category="section-title">在BlueXP备份和恢复中配置对象存储备份</block>
  <block id="b051972c09e4af66c724bccd4f127c1c" category="paragraph">要使BlueXP有效管理数据基础架构、需要事先安装Connector。Connector执行发现资源和管理数据操作所涉及的操作。</block>
  <block id="e6e80588e9fe7cf89218fea44300f7ca" category="inline-link">了解连接器</block>
  <block id="f785cb009d0e900109fd140553b30bea" category="paragraph">有关BlueXP Connector的详细信息、请参阅<block ref="87d489963d63aa007d917db7d08b189d" category="inline-link-rx"></block> BlueXP文档中的。</block>
  <block id="118ef4c7f068ef80971593a1b0f6c1f7" category="paragraph">为正在使用的云提供程序安装连接器后、可以从Canvas中查看对象存储的图形表示。</block>
  <block id="0f28b2dc8792829266318c92e522f520" category="paragraph">要将BlueXP备份和恢复配置为备份由内部SCV管理的数据、请完成以下步骤：</block>
  <block id="4471d745c7b622fbd04b1e5c54f7144d" category="example-title">将工作环境添加到画布中</block>
  <block id="13c030d92e30cb905d69a9a387410d73" category="paragraph">第一步是将内部ONTAP存储系统添加到BlueXP</block>
  <block id="f55260bbdb99e04d3e13ace23b35a6b5" category="list-text">从“画布”中选择*添加工作环境*开始。</block>
  <block id="d3d22c95b6f4d89140142ab07f028c50" category="list-text">从所选位置中选择*内部*，然后单击*发现*按钮。</block>
  <block id="f044344db90a471e01add0279640a8d3" category="image-alt">选择内部部署</block>
  <block id="61736da00191bcc5290a543d27b3f881" category="list-text">填写ONTAP存储系统的凭据，然后单击*Discover (发现)*按钮以添加工作环境。</block>
  <block id="989f626b77cb057aef86b227753fe6d6" category="image-alt">添加存储系统凭据</block>
  <block id="10c85a28ec77f1067105a32fcee05b7f" category="example-title">了解内部SCV设备和vCenter</block>
  <block id="d7c03e191da724f2dee3aefd6723b5ac" category="paragraph">要发现内部数据存储库和虚拟机资源、请添加SCV数据代理的信息以及vCenter管理设备的凭据。</block>
  <block id="45d6ffc5f5563975f6953d269cffc5b6" category="list-text">从BlueXP左侧菜单中选择*保护&gt;备份和恢复&gt;虚拟机*</block>
  <block id="929323ed0978848a31f6a8388e01971c" category="image-alt">选择虚拟机</block>
  <block id="b894330fc5c0772b978a804a636d8561" category="list-text">从虚拟机主屏幕访问*设置*下拉菜单并选择*适用于VMware vSphere的SnapCenter插件*。</block>
  <block id="faa24cbcb63ad75d1b2f9379a73db850" category="image-alt">设置下拉菜单</block>
  <block id="b96d255021b81b24e083afa488bc0489" category="list-text">单击*注册*按钮、然后输入SnapCenter插件设备的IP地址和端口号以及vCenter管理设备的用户名和密码。单击*注册*按钮开始发现过程。</block>
  <block id="13e581610c39d0064e2906d4de05ff41" category="image-alt">输入SCV和vCenter信息</block>
  <block id="0940589132d32822a14d679e07d78a50" category="list-text">可以通过作业监控选项卡监控作业进度。</block>
  <block id="7d9a11a5beab7a458383c2bbf93ca7f5" category="image-alt">查看作业进度</block>
  <block id="62f91073f50f8916da58763b4f46c0b7" category="list-text">发现完成后、您将能够查看所有已发现的SCV设备中的数据存储库和虚拟机。
 +
图像：：bxp-SCV hyby-23.png[查看可用资源]</block>
  <block id="465bbc0896511246f9f765c89f55e975" category="paragraph">在适用于虚拟机的BlueXP备份和恢复中、创建策略以指定保留期限、备份源和归档策略。</block>
  <block id="9fe2f95002b4b4815d52173b68bf9862" category="inline-link">创建一个策略以备份数据存储库</block>
  <block id="86bc3e584348c8421ec3567a22142b57" category="paragraph">有关创建策略的详细信息、请参见<block ref="80982186ff4a093ef0d5c383d66626f1" category="inline-link-rx"></block>。</block>
  <block id="8b91c4c18527ee91c2c399b04a87600c" category="list-text">从虚拟机的BlueXP备份和恢复主页中、访问*设置*下拉菜单并选择*策略*。</block>
  <block id="6f6ac8531dfacb86c47a059017038eb1" category="list-text">单击*创建策略*以访问*为混合备份创建策略*窗口。</block>
  <block id="f04e98350e411695587e6669af53c1db" category="list-text">为策略添加名称</block>
  <block id="b39cfffbe3df23dc25f156f4056c93b3" category="list-text">选择所需的保留期限</block>
  <block id="fa5dfe52e5710546ca90135f95d55455" category="list-text">选择是从内部ONTAP主存储系统还是从二级存储系统获取备份</block>
  <block id="b0cc94428f0fb0b61c7819be1f33212d" category="list-text">(可选)指定备份分层到归档存储的时间期限、以节省更多成本。</block>
  <block id="aad49551351256549bb40d89b7e44dc6" category="image-alt">创建备份策略</block>
  <block id="7044e2220a94c55283a8ae5b7a036a34" category="admonition">此处输入的SnapMirror标签用于标识要应用此策略的备份。标签名称必须与相应的内部SCV策略中的标签名称匹配。</block>
  <block id="6c302d6f69fc91f2572712f003676d83" category="list-text">单击*创建*以完成策略创建。</block>
  <block id="b376eb1d1a81946ce7cc5b483b394614" category="example-title">将数据存储库备份到Amazon Web Services</block>
  <block id="0683dcf442cdbe8d60b5c07d40f32d46" category="paragraph">最后一步是为各个数据存储库和虚拟机激活数据保护。以下步骤概述了如何激活备份到AWS。</block>
  <block id="1d5ad62b9217b4a3f085f517534f40bb" category="inline-link">将数据存储库备份到Amazon Web Services</block>
  <block id="aaa6437baaeb74798cea1dbc99d2449d" category="paragraph">有关详细信息、请参见<block ref="1515dd2e0ceefc55442eaf374717c8c0" category="inline-link-rx"></block>。</block>
  <block id="ea304a58f425305bd76d96e195240e41" category="list-text">从虚拟机的BlueXP备份和恢复主页中，访问要备份的数据存储库的设置下拉列表，然后选择*Activate Backup*。</block>
  <block id="addf19ca5aa2245b4311a5fda42a2a57" category="image-alt">激活备份</block>
  <block id="2d2feec53ea251226e3bc25b8f966325" category="list-text">分配要用于数据保护操作的策略，然后单击*Next*。</block>
  <block id="7b849f66aa18fbe76b4de3ccd94e7fa5" category="image-alt">分配策略</block>
  <block id="3557d184dd5b120a15f7f255a53dbd75" category="list-text">如果先前已发现数据存储库和工作环境，则会在“*添加工作环境”页面上显示带有复选标记的数据存储库和工作环境。如果以前未发现工作环境、您可以在此处添加它。单击“*下一步*”继续。</block>
  <block id="ebaf068fe62ec21456569fffa6d9a5d5" category="image-alt">添加工作环境</block>
  <block id="7f2d0b4262c191ebde406cac19a62ead" category="list-text">在*选择提供商*页面上单击AWS、然后单击*下一步*按钮继续。</block>
  <block id="1ae27ac8ad91f0165c176c34dd34e81c" category="image-alt">选择云提供商</block>
  <block id="4a3b64136cb6a2eb55f7b2dd685d6a24" category="list-text">填写AWS的提供商专用凭据信息、包括要使用的AWS访问密钥和机密密钥、区域和归档层。此外、请为内部ONTAP存储系统选择ONTAP IP空间。单击“*下一步*”。</block>
  <block id="e701699f2a50f7406e33ed8381ef2dab" category="image-alt">提供云提供凭据</block>
  <block id="3a27bf198d7aaec4b69fdd91a21db0f3" category="list-text">最后，查看备份作业详细信息，然后单击*Activate Backup*按钮以启动数据存储库的数据保护。</block>
  <block id="a87637f111ffdb2fa219abf2e190e471" category="image-alt">查看并激活</block>
  <block id="799321d74f0d57d43edc67a54c1ef707" category="admonition">此时、数据传输可能不会立即开始。BlueXP备份和恢复每小时扫描一次任何未完成的快照、然后将其传输到对象存储。</block>
  <block id="a0d35efe3991e429a3bc58db5b630996" category="section-title">在数据丢失的情况下还原虚拟机</block>
  <block id="1cc4cdfb25de99e21c56bd2f0c899a83" category="paragraph">确保数据安全只是全面数据保护的一个方面。在发生数据丢失或勒索软件攻击时、能够从任何位置快速还原数据同样至关重要。此功能对于保持无缝业务运营和满足恢复点目标至关重要。</block>
  <block id="acdac876b9032f5b222cf73fc7456ce3" category="paragraph">NetApp提供高度适应性的3-2-1策略、可对主存储、二级存储和对象存储位置的保留计划进行自定义控制。此策略可以灵活地根据特定需求定制数据保护方法。</block>
  <block id="ecbeffc5d7f9792e6cd466bdf664edb5" category="paragraph">本节简要介绍了从适用于VMware vSphere的SnapCenter插件和适用于虚拟机的BlueXP备份和恢复执行数据还原的过程。</block>
  <block id="e418db144eab640511d76294a7f2c7a2" category="section-title">从适用于VMware vSphere的SnapCenter插件还原虚拟机</block>
  <block id="0b156eb7ae06ec8e963e1dd7bed83e94" category="inline-link">从备份还原 VM</block>
  <block id="6685bca68d0a1fe5d6c289520a21e10a" category="paragraph">对于此解决方案虚拟机、已还原到原始位置和备用位置。本解决方案不会涵盖选择控制阀数据恢复能力的所有方面。有关选择控制阀所能提供的所有深度信息，参见<block ref="a56bca9fd4ed3fad8a28404cdf47ba7c" category="inline-link-rx"></block> 在产品文档中。</block>
  <block id="6f29ea0e6c61288be960099421f0a3df" category="example-title">从选择控制阀恢复虚拟机</block>
  <block id="20661d8811797af8d51dbeb80ec719d4" category="paragraph">要从主存储或二级存储还原虚拟机、请完成以下步骤。</block>
  <block id="0755ca01e2074d93355fac3527849bda" category="list-text">从vCenter Client导航到*清单&gt;存储*、然后单击包含要还原的虚拟机的数据存储库。</block>
  <block id="a2e775a3f0622c2ac41b01a1518491ec" category="list-text">从*配置*选项卡单击*备份*以访问可用备份列表。</block>
  <block id="4b06c2a993e34e13053091a3156b989b" category="image-alt">访问备份列表</block>
  <block id="774ee85fec7142248cfc405505b8721c" category="list-text">单击备份以访问VM列表、然后选择要还原的VM。单击*Restore*。</block>
  <block id="86633a603862e6f7597927afc76269c1" category="image-alt">选择要还原的虚拟机</block>
  <block id="7d2920de3c39b0742f3c5187193c6845" category="list-text">在还原向导中、选择还原整个虚拟机或特定VMDK。选择此选项可安装到原始位置或备用位置、并在还原后提供虚拟机名称和目标数据存储库。单击 * 下一步 * 。</block>
  <block id="319ab9dcd1d0bfb14d7f15b99c4db3a1" category="image-alt">提供还原详细信息</block>
  <block id="e47c862d8ff848e62e3e7d6e57c16d18" category="list-text">选择从主存储位置或二级存储位置进行备份。</block>
  <block id="d87670b3add7f5b6a740edfe8b8e91aa" category="image-alt">选择主卷或二级卷</block>
  <block id="d0a57165744947d2a15e0465f96c7224" category="list-text">最后、查看备份作业的摘要、然后单击完成开始还原过程。</block>
  <block id="d8d9151889f2e5c47ace43970e545363" category="section-title">从虚拟机的BlueXP备份和恢复还原虚拟机</block>
  <block id="c6c605b662ef94c68391b5451e95455d" category="paragraph">通过对虚拟机进行BlueXP备份和恢复、可以将虚拟机还原到其原始位置。还原功能可通过BlueXP Web控制台访问。</block>
  <block id="ffa1e37a2c6478ff157a0a7d25a607e9" category="inline-link">从云中还原虚拟机数据</block>
  <block id="94b974f7ab5ca99392d1041601e87897" category="paragraph">有关详细信息、请参见<block ref="238147c8f6c3fb89d6b3eb28f713b9cf" category="inline-link-rx"></block>。</block>
  <block id="51dac82a8b88ae2579c7783d71b88447" category="example-title">从BlueXP备份和恢复还原虚拟机</block>
  <block id="d2b7af1fe2cbeff098166770c3666278" category="paragraph">要从BlueXP备份和恢复还原虚拟机、请完成以下步骤。</block>
  <block id="37f8e514cc85f6be4997337d7410cb05" category="list-text">导航到*保护&gt;备份和恢复&gt;虚拟机*，然后单击虚拟机以查看可还原的虚拟机列表。</block>
  <block id="9f9a3f0d1822c0693db87fb0974c34c6" category="image-alt">VM的访问列表</block>
  <block id="90bb4dee875f9363dcee31bed57c0031" category="list-text">访问要还原的虚拟机的设置下拉菜单、然后选择</block>
  <block id="355082f6d43128519c5fe802a5c338f9" category="image-alt">选择Restore from settings (从设置还原)</block>
  <block id="dfe88d81f64a71a9cf846c70051b7dea" category="list-text">选择要从中进行还原的备份，然后单击*Next*。</block>
  <block id="6750403de8a1789347829725f5135c88" category="image-alt">选择备份</block>
  <block id="2f9f8f44452ee2f60602403d0ac6c097" category="list-text">查看备份作业的摘要，然后单击*Restore*以启动恢复过程。</block>
  <block id="f53f4a113807a68a2f782e05b8e0a70e" category="list-text">通过*作业监控*选项卡监控恢复作业的进度。</block>
  <block id="081875fb99dedbd0c048ca990a597eb3" category="image-alt">从作业监控选项卡查看还原</block>
  <block id="4eabedc19022ae64ee6fb8cf3eb22d25" category="paragraph">通过适用于VMware vSphere的SnapCenter插件和适用于虚拟机的BlueXP备份和恢复实施3-2-1备份策略后、可提供强大、可靠且经济高效的解决方案来实现数据保护。此策略不仅可以确保数据冗余和可访问性、还可以灵活地从任何位置以及内部ONTAP存储系统和基于云的对象存储还原数据。</block>
  <block id="d85d2913422ca9221fd9749107f26b98" category="paragraph">本文档中提供的用例重点介绍经验证的数据保护技术、这些技术重点介绍了NetApp、VMware和领先云提供商之间的集成。适用于VMware vSphere的SnapCenter插件可与VMware vSphere无缝集成、从而可以高效地集中管理数据保护操作。这种集成简化了虚拟机的备份和恢复流程、从而可以在VMware生态系统中轻松地计划、监控和灵活地执行还原操作。适用于虚拟机的BlueXP备份和恢复通过将虚拟机数据安全地通过空中映射备份到基于云的对象存储、提供3-2-1中的一(1)个备份。直观的界面和逻辑工作流为关键数据的长期归档提供了一个安全平台。</block>
  <block id="2d3786cce4bbee81c9852997cc1bef39" category="list-text"><block ref="2d3786cce4bbee81c9852997cc1bef39" category="inline-link-rx"></block></block>
  <block id="eeb8e055593f1709925a03e2ebb13265" category="inline-link">BlueXP文档</block>
  <block id="97672c1115415f474694aeff39263665" category="list-text"><block ref="97672c1115415f474694aeff39263665" category="inline-link-rx"></block></block>
  <block id="2558c618cb338262f6026774a894d746" category="doc">借助NetApp SnapCenter和Veeam复制实现应用程序一致的灾难恢复</block>
  <block id="7ae213afecb4593469214acec6ce5979" category="paragraph">许多客户都在为VMware vSphere上托管的应用程序VM寻找有效的灾难恢复解决方案。其中许多企业使用现有备份解决方案在灾难期间执行恢复。
解决方案多次增加了RTO、但并未达到他们的期望。为了减少RPO和RTO、只要具有适当权限的网络连接和环境可用、即使从内部复制到GCVE)也可以使用Veeam VM复制。
注意：Veeam VM Replication不会保护与VM子系统连接的存储设备、例如子系统VM中的iSCSI或NFS挂载。需要单独保护这些数据。</block>
  <block id="d80d0a117c54407b1f6f425ffae47614" category="paragraph">为了实现SQL VM的应用程序一致复制并减少RTO、我们使用SnapCenter来编排SQL数据库和日志卷的SnapMirror操作。</block>
  <block id="17219d098d65f47282273cb90d58dcb0" category="inline-image-macro">Application VM复制架构</block>
  <block id="85a0251ddf0da4488f77abf2784ccfdb" category="paragraph"><block ref="85a0251ddf0da4488f77abf2784ccfdb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d26b5935fc58111f2d8db9c078c08af6" category="list-text">在适当的订阅和虚拟网络中使用BlueXP为Cloud Volumes ONTAP配置正确的实例大小。</block>
  <block id="534253a0a05c40a27f9df1dfb786d936" category="list-text">发生灾难事件时、请使用BlueXP中断SnapMirror关系、并使用Veeam触发虚拟机故障转移。</block>
  <block id="8ad16dd1937de1e5fc2efa0668887d8b" category="video-title">查看使用SnapCenter保护SQL VM的情况</block>
  <block id="b76e26ed981d5f491522c965efa7c46b" category="paragraph">可以将适用于NFS数据存储库的NetApp云卷服务以及适用于SQL的Cloud Volumes ONTAP数据库和日志部署到任何VPC、并且GCVe应与该VPC建立专用连接、以便挂载NFS数据存储库并使VM连接到iSCSI LUN。</block>
  <block id="989c086533ca63f7888fce83e4a46a4a" category="inline-link-macro">使用Veeam Replication进行迁移</block>
  <block id="4bff962e3835ed7a5df1cbab1f33f819" category="paragraph">根据部署场景、需要部署的Veeam备份服务器、备份存储库和备份代理。在此使用情形下、无需为Veeam部署对象存储、也不需要横向扩展存储库。
<block ref="fe81875323ba8244cd35f234258570cc" category="inline-link-rx"></block>
有关追加信息、请参见 <block ref="57b6bba9f472c9c5faf92f0cbcc6ff10" category="inline-link-macro-rx"></block></block>
  <block id="c28fedc2a43517971c6f09573d0875cd" category="paragraph">内部vCenter和GCVE vCenter都需要向Veeam注册。<block ref="92166da7fd4418ef19e64644a99fe5e2" category="inline-link-rx"></block> 在向导的子系统处理步骤中、选择禁用应用程序处理、因为我们将利用SnapCenter 进行应用程序感知型备份和恢复。</block>
  <block id="f02831926b719e575a346f87ac04a87e" category="admonition">这些演示是使用TKG 1.3.1版和Astra Control Center 21.12版录制的技术预览版。有关受支持的官方版本、请参见支持列表。</block>
  <block id="eb86f482301303a1c0f2f5219289a73c" category="cell">（可选）指示是否将公有 IP 地址与实例关联。如果未提供，则关联将根据子网的配置完成。</block>
  <block id="1c472a7f2f4380895c82bc2ed43d727b" category="paragraph">*最佳实践*</block>
  <block id="aac915d3befc8db9d5b3a3dee5c7a58a" category="paragraph">有关详细信息、请参见 <block ref="904c80f66e5056357fd992ed854be90e" category="inline-link-macro-rx"></block>。</block>
  <block id="ab81e47672e89830ec16c581f44cb23c" category="paragraph">第 1 部分：入门，要求，自动化详细信息和初始 AWX/ 塔式配置</block>
  <block id="deb10517653c255364175796ace3553f" category="cell">产品</block>
  <block id="ede1cce9f240fed5ecc4264bd699cee1" category="sidebar">BlueXP备份和恢复</block>
  <block id="fb62fbf89ea149f795c0e8c9d524188d" category="sidebar">BlueXP备份和恢复</block>
  <block id="7f65285e967e5d62effe7b87198351bc" category="sidebar">适用于VM的BlueXP备份和恢复</block>
  <block id="6622de5008f90d398faa1e625092402e" category="example-title">创建BlueXP备份策略</block>
  <block id="8a4b419d5126ba3004ad4d071ac8a766" category="list-text">以Oracle用户身份登录到Oracle服务器并执行以下命令：</block>
  <block id="38333d478471b938020592b577fc16c2" category="list-text">登录到数据库以检查数据库配置设置以及使用以下命令集创建的PDB。</block>
  <block id="b178089f1eac81c2c81eba2c223e2740" category="list-text">使用以下命令通过侦听器连接到数据库以检查Oracle侦听器配置。更改为相应的侦听器端口和数据库服务名称。</block>
  <block id="44f9187dc57a34800a68152bf3e51e8f" category="video-title">AWX部署</block>
  <block id="9234eaf4b40d25f09b5abdd71c1e1a7b" category="video-title">AWX操作手册运行</block>
  <block id="9225d2c6eb68109e4084ab87f17664fa" category="video-title">命令行界面操作手册运行</block>
  <block id="73977a3ad17c882a666b80c9eccec0e7" category="list-text">从您的Ans负责人 控制器中、运行以下命令：</block>
  <block id="60cc8e16ee1bd6e820e063f90fd35cbe" category="list-text">下载存储库后、将目录更改为na_oracle19c_Deploy &lt;cd na_oracle19c_deploy&gt;。</block>
  <block id="ca9312842450cb1907f68cbfe9e7ebdd" category="list-text">通过传递正确的标记和ONTAP集群用户名来运行ONTAP操作手册。根据提示填写ONTAP集群的密码、然后填写vsadmin。</block>
  <block id="27dddea37ed0de0ca5959c367057ba57" category="list-text">运行Linux操作手册以执行Linux部署部分。输入admin ssh密码和sudo密码。</block>
  <block id="1c71909fca063bf285ff220dab00cfa1" category="list-text">运行Oracle操作手册以执行Oracle部署部分。输入admin ssh密码和sudo密码。</block>
  <block id="5cf04a9bbc1dcc2fadd56ff48a750287" category="video-title">自动PostgreSQL部署和保护</block>
  <block id="92a02c3e922aecfbb22227bc7a4f73e8" category="list-text">选择要备份的数据库，然后选择*Next*和(**)以添加策略(如果尚未创建)。按照*新SQL Server备份策略*创建新策略。</block>
  <block id="6cd47796208de7b1d81ffd66d5fa0744" category="video-title">将内置Oracle数据库迁移到AWS</block>
  <block id="2ad3cefd13309f11aa1b961ca1a2e942" category="video-title">使用HCX迁移工作负载</block>
  <block id="92a300f3d27268bb5dc79fc4a6a350e1" category="video-title">HCX vMotion</block>
  <block id="bad38ce6b4954ebab11050b4a7cf208c" category="video-title">适用于ONTAP VMware Cloud的Amazon FSx</block>
  <block id="f87da6f2c46cbdbedc31faf67374f8f6" category="paragraph"><block ref="f87da6f2c46cbdbedc31faf67374f8f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50a2af1b36504de3cf8dc288f0697fc4" category="video-title">FSx NetApp ONTAP for Red Hat OpenShift Service on AWS</block>
  <block id="d90d5ea5174403c0eb77b8e80b80d6ad" category="paragraph">本文档详细介绍了如何使用自动化命令行界面(CLI)部署Oracle 19c。</block>
  <block id="85ddc39126e35d4b51b71eda88f1079e" category="admonition">Snapshot标签非常有用、因为它们可用于为复制到二级ONTAP集群的SnapVault副本制定具有特定保留期限的策略。如果将SCV与BlueXP备份和还原结合使用、则Snapshot标签字段必须为空、或者[Underline]#Match#是BlueXP备份策略中指定的标签。</block>
  <block id="7a2d74417c06cd7e4b6b37ea4a50f19c" category="video-title">对ROSA集群上的应用程序进行故障转移和故障恢复</block>
  <block id="a2770d0183031f49a2f20a543819adec" category="sidebar">Anthos NetApp存储系统概述</block>
  <block id="81b0f321243d0fe75866a67d7296011f" category="sidebar">针对Anthos的NetApp存储集成概述</block>
  <block id="cc50aa54532303158c7f7e03e209b944" category="sidebar">适用于Anthos的NetApp Astra三端功能概述</block>
  <block id="e15669a3c7179323f1acc08e9c744e08" category="sidebar">高级配置选项</block>
  <block id="264b92565936d4be9efe9e910112a189" category="sidebar">探索Anthos的负载平衡器选项</block>
  <block id="40d6fca9779cb8495da4be0205bd757d" category="sidebar">适用于开发运营的NetApp存储系统概述</block>
  <block id="be0f8e8072f4ad51f221291ddb3bbc69" category="sidebar">适用于开发运营的NetApp存储集成概述</block>
  <block id="9a35e88bdf86fdb37be01073de37dd5b" category="sidebar">适用于开发运营的NetApp Astra控制中心概述</block>
  <block id="cb7d8c0edb10c8ffbf5b7c50c43e753d" category="sidebar">适用于开发运营的NetApp Astra三项技术概述</block>
  <block id="0c4c2b9659c800fc4bd3849c9c620ef4" category="sidebar">OpenShift的NetApp存储系统概述</block>
  <block id="96d0d82fb33f3070c6df908b767ccf43" category="sidebar">OpenShift的NetApp存储集成概述</block>
  <block id="ce11668bebd12fbc6a4a0e9d2d0631ee" category="sidebar">适用于OpenShift的NetApp Asta控制中心概述</block>
  <block id="ed568d2886d48bad9d31ddc83e1fe3df" category="sidebar">适用于OpenShift的NetApp Asta三项功能概述</block>
  <block id="e70b81489d79617ac558857d0e6a1b0c" category="sidebar">探索OpenShift的负载平衡器选项</block>
  <block id="b5c5877fe893c5c6cad2be01524ae8ec" category="sidebar">部署OpenShift虚拟化</block>
  <block id="b92fa187000644c044f275ff61021b0d" category="sidebar">Tanzu的NetApp存储系统概述</block>
  <block id="94c2a75f199cd33a47f8a40b94ca2c52" category="sidebar">Tanzu的NetApp存储集成概述</block>
  <block id="86336fe794a609a659986aec0bbbde32" category="sidebar">Tanzu的NetApp Astra控制中心概述</block>
  <block id="5cce16ad9ceb0671f8ff7b55779edea8" category="sidebar">适用于Tanzu的NetApp Asta三端到子概述</block>
  <block id="f275586eb38c2b7969339c9342f4aa31" category="sidebar">保护AWS/VMC上的工作负载</block>
  <block id="436fb722308ce27c05403a9d23972687" category="sidebar">在AWS/VMC上迁移工作负载</block>
  <block id="b61c513552a0b831fb699057e4aa7f4c" category="sidebar">保护AzAzure / AVS上的工作负载</block>
  <block id="4cac932fad0b1473b5035d385d45bb27" category="sidebar">在AzAzure / AVS上迁移工作负载</block>
  <block id="94922270960f6b741bb712eccc9449ba" category="sidebar">保护GCP/GCVE)上的工作负载</block>
  <block id="d9f42891011821874382a8c416af7844" category="sidebar">在GCP/GCVE)上迁移工作负载</block>
  <block id="9a72d0f7fb216c9847a7b9858ab2b456" category="sidebar">VMware混合云用例</block>
  <block id="bf18ee10eabb265ef4edba71404acb28" category="sidebar">部署VDS</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="8c50876b06b14b8a5e8c337f00bb2b87" category="cell">2023年8月2日</block>
  <block id="3c7f4710cafa0529d89c1ce0485a2ecb" category="cell">新增TR-4977：《使用SnapCenter服务执行Oracle数据库备份、还原和克隆—Azure》</block>
  <block id="9c0f90b4b7da40bb1953c2b5fff23b93" category="paragraph">目前、只有传统的SnapCenter服务器UI工具(请参见)才支持使用NFS和ASM存储选项的Oracle数据库 <block ref="b57a10e031bd9978114f200c41cc97b5" category="inline-link-macro-rx"></block> 有关使用NetApp SnapCenter UI工具进行Oracle数据库备份、还原和克隆的详细信息。</block>
  <block id="4a2b9d3fbf0ce23b647509fb31e70cde" category="doc">TR-4977：《使用SnapCenter服务进行Oracle数据库备份、还原和克隆—Azure》</block>
  <block id="63260fe4291efeee8bde616a2f5684d4" category="paragraph">SnapCenter 服务是一款SaaS版本的经典SnapCenter 数据库管理UI工具、可通过NetApp BlueXP云管理控制台访问。它是NetApp云备份和数据保护产品不可或缺的一部分、适用于在Azure NetApp Files上运行的Oracle和HANA等数据库。这种基于SaaS的服务简化了传统的SnapCenter 独立服务器部署、该部署通常需要在Windows域环境中运行的Windows服务器。</block>
  <block id="29f3642491ac9aeb7b665ce66bb22367" category="paragraph">在本文档中、我们将演示如何设置SnapCenter服务来备份、还原和克隆部署在Azure NetApp Files卷和Azure计算实例上的Oracle数据库。使用基于Web的BlueXP用户界面、可以非常轻松地为部署在Azure NetApp Files上的Oracle数据库设置数据保护。</block>
  <block id="e9077c444a6fe7487b79ae7f79962528" category="list-text">使用Azure NetApp Files和Azure VM中托管的Oracle数据库的快照进行数据库备份</block>
  <block id="3c0389598fef1a83350821d4fdeef712" category="list-text">为开发、测试环境或其他使用情形快速克隆主数据库</block>
  <block id="d187540921045cfa569cefc03bc2d168" category="list-text">负责管理在Azure NetApp Files存储上运行的Oracle数据库的数据库管理员</block>
  <block id="bd1e27892a57409e18119bb2e541f4b1" category="list-text">对在Azure中测试Oracle数据库备份、还原和克隆感兴趣的解决方案架构师</block>
  <block id="42f6ca06d2c7da03707222828f8997d0" category="list-text">支持和管理Azure NetApp Files存储的存储管理员</block>
  <block id="94afe08a60e7f6e3a5a129eb73659899" category="list-text">拥有部署到Azure NetApp Files存储和Azure VM的应用程序的应用程序所有者</block>
  <block id="3b29347d447c562ac8402016757938d0" category="paragraph">此解决方案的测试和验证是在可能与最终部署环境不匹配的实验室环境中执行的。有关详细信息，请参见一节 <block ref="8ea96e516bccf9a47ca2d74131eb7519" category="inline-xref-macro-rx"></block>。</block>
  <block id="55ee60e84e278b25241f6d746cda7b4c" category="cell">Azure NetApp Files存储</block>
  <block id="2b5527ea942b29b10a9a691160f3137b" category="cell">高级服务级别</block>
  <block id="d8e8e079bcd8fa97afc26513da9e1110" category="cell">自动QoS类型、以及测试中的4 TB存储容量</block>
  <block id="4c791dd8c709f803e2c279029455d4da" category="cell">用于计算的Azure实例</block>
  <block id="19acc071e88e4f4be6d6d2745aacfcdb" category="cell">标准B4ms (4个vCPU、16 GiB内存)</block>
  <block id="d82c3df85e2512cdff298dd446d58313" category="cell">已部署两个实例、一个用作主数据库服务器、另一个用作克隆数据库服务器</block>
  <block id="985045c742c1926df0960f2e40377fde" category="cell">Red Hat Enterprise Linux 8.7 (LVM)- x64 Gen2</block>
  <block id="ca6c2c8fbdec80fdc9c7b41d5742dec2" category="cell">版本v2.5-0-2822</block>
  <block id="d22bbe9a49e393259ebd1a700f02c6fb" category="cell">代理版本v2.5-0-2822</block>
  <block id="f6b9199115e06b52287c2e656c7170b7" category="list-text">*连接器应部署在与数据库和Azure NetApp Files相同的虚拟网络/子网中。*如果可能、连接器应部署在相同的Azure虚拟网络和资源组中、以便能够连接到Azure NetApp Files存储和Azure计算实例。</block>
  <block id="4275ae61422c34253a59329bd20a0449" category="inline-link-macro">设置Azure权限</block>
  <block id="a2c89159a457c3034a118e2f5ec42ea8" category="list-text">*Azure用户帐户或Active Directory服务原则是在SnapCenter Connector的Azure门户上创建的。*部署BlueXP Connector需要特定的权限才能创建和配置虚拟机及其他计算资源、配置网络以及访问Azure订阅。此外、它还需要稍后创建角色的权限、以及Connector运行所需的权限。在Azure中创建具有权限的自定义角色、并分配给用户帐户或服务原则。有关详细信息、请查看以下链接：<block ref="b49637e40777f5433f5c24dbb998f3cf" category="inline-link-macro-rx"></block>。</block>
  <block id="448ffe9dc9c373b8324c69a8af97c086" category="list-text">*在Azure资源组中创建的ssh密钥对。*将ssh密钥对分配给Azure VM用户以登录到连接器主机、同时分配给数据库VM主机以部署和执行插件。BlueXP控制台UI使用ssh密钥将SnapCenter服务插件部署到数据库主机、以便执行一步式插件安装和应用程序主机数据库发现。</block>
  <block id="68c6f0e24ad67438a9793997e4148b4a" category="list-text">*添加到BlueXP控制台设置的凭据。*要将Azure NetApp Files存储添加到BlueXP工作环境中、需要在BlueXP控制台设置中设置一个用于授予从BlueXP控制台访问Azure NetApp Files的权限的凭据。</block>
  <block id="7076747996fba0bd3dae4b26df9e5b81" category="list-text">*java-11-OpenJDK安装在Azure VM数据库实例主机上。* SnapCenter服务安装需要Java版本11。在尝试部署插件之前、需要将其安装在应用程序主机上。</block>
  <block id="c9643c7018a32634bcea72e6f9a9b01c" category="paragraph">我们提供了大量的NetApp文档、范围更广、可帮助您保护云原生应用程序数据。本文档的目标是提供有关使用BlueXP控制台部署SnapCenter服务的分步过程、以保护部署在Azure NetApp Files存储和Azure计算实例上的Oracle数据库。</block>
  <block id="e0abdcfd046a2653a1bda2dca7115e7a" category="list-text">阅读一般说明 <block ref="ac041fb7031b2bcbcb203adcabf84a4f" category="inline-link-macro-rx"></block> 以及与Oracle和Azure NetApp Files相关的章节。</block>
  <block id="ce953d67aae97c7fc7524432a6090e33" category="list-text">观看以下视频演示</block>
  <block id="1aa4f0058fb883a083f057768fa6878f" category="list-text">Azure VM实例上已完全部署并运行Oracle数据库的主Oracle数据库服务器。</block>
  <block id="9c1e7cfdc38dedc2e99c928ece55f763" category="list-text">部署在Azure中的Azure NetApp Files存储服务容量池、其容量可满足硬件组件部分中列出的数据库存储需求。</block>
  <block id="400fbf8e332fd888d81e51801a0c2cc4" category="list-text">Azure VM实例上的二级数据库服务器、可用于测试将Oracle数据库克隆到备用主机的操作、以支持开发/测试工作负载或任何需要完整生产Oracle数据库数据集的使用情形。</block>
  <block id="7aed6dd72c89d5402fa728857da45811" category="list-text">有关在Azure NetApp Files和Azure计算实例上部署适用于Oracle的追加信息数据库的信息、请参见 <block ref="f374c29aef481aab5d73c8e634ca15a8" category="inline-link-macro-rx"></block>。</block>
  <block id="b6ae4eb3df8e4641d8de2566803478d7" category="list-text">在Azure门户中创建Azure用户帐户或Active Directory服务原则、并为Azure Connector部署授予角色权限。</block>
  <block id="81ec66aa59e6b366dbe7a76be739caf3" category="list-text">要设置BlueXP以管理Azure资源、请添加一个BlueXP凭据、其中包含BlueXP可用于向Azure Active Directory (应用程序客户端ID)进行身份验证的Active Directory服务主体的详细信息(客户端机密)、 和您的组织的Active Directory ID (租户ID)。</block>
  <block id="15c84c91cca87e33136482d747da05a0" category="list-text">您还需要Azure虚拟网络、资源组、安全组、用于VM访问的SSH密钥等、以便为连接器配置和数据库插件安装做好准备。</block>
  <block id="ab08177e4206526be72dbdc84ee2ea8e" category="list-text">登录到BlueXP控制台。</block>
  <block id="8932d8756a027f5dc1721f3219cd98cc" category="paragraph"><block ref="8932d8756a027f5dc1721f3219cd98cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b68454c1eb2120854c603f290cc17fda" category="list-text">单击*Connecter*下拉箭头和*Add Connecter*以启动连接器配置工作流。</block>
  <block id="70cfa5e11acf34981ffdc54c850479d9" category="paragraph"><block ref="70cfa5e11acf34981ffdc54c850479d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e810044bd3b9f9b02ca265b4d3eebe93" category="list-text">选择您的云提供商(此处为*Microsoft AzAzure *)。</block>
  <block id="3f21caad7a2d3c7fa9d1c33646bde52e" category="paragraph"><block ref="3f21caad7a2d3c7fa9d1c33646bde52e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="047b152c8199802dac7e7e1ed26059ed" category="list-text">如果您已在Azure帐户中设置了*权限*、*身份验证*和*网络连接*步骤、请跳过这些步骤。如果没有、则必须先配置这些组件、然后再继续。从此处、您还可以检索上一节"<block ref="2204dd011c923b13eaa19e758c798231" category="inline-xref-macro-rx"></block>。 "</block>
  <block id="8d3e5754272a221e50fc2ccbbb7743f6" category="paragraph"><block ref="8d3e5754272a221e50fc2ccbbb7743f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5bb415e11f78e565d29b6276832d292" category="list-text">单击*跳到部署*以配置连接器*虚拟机身份验证*。添加您在登录到BlueXP期间在Azure资源组中创建的SSH密钥对、为连接器操作系统身份验证做准备。</block>
  <block id="a07c68ca2ab99f1b76268c5a5aba9312" category="paragraph"><block ref="a07c68ca2ab99f1b76268c5a5aba9312" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d5895de98f1a29d1e51aec000e336a8" category="list-text">提供连接器实例的名称，选择*Create/*并接受*Details*下的默认*Role Name*，然后选择Azure帐户的订阅。</block>
  <block id="122e8f677469e7d8cb0a298e5e1854ec" category="paragraph"><block ref="122e8f677469e7d8cb0a298e5e1854ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f92ddd8d0b54f5b5292875e85830a9e" category="list-text">使用正确的*vNet*、*Subnet*配置网络，并禁用*Public IP*，但确保连接器在Azure环境中可以访问Internet。</block>
  <block id="a14bd4bf8d6a711c8f271d13d4cdc750" category="paragraph"><block ref="a14bd4bf8d6a711c8f271d13d4cdc750" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46eaff1ae08db28efc06b6f93a0d936f" category="list-text">为允许HTTP、HTTPS和SSH访问的连接器配置*安全组*。</block>
  <block id="b3b2b257db3bcb29e03f067df9124991" category="paragraph"><block ref="b3b2b257db3bcb29e03f067df9124991" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83b7e5528d645d061628677d96552818" category="list-text">查看摘要页面、然后单击*添加*以开始创建连接器。完成部署通常需要大约10分钟。完成后、连接器实例VM将显示在Azure门户中。</block>
  <block id="6cdc962db7f4b3a37ce10e89250ddd8d" category="paragraph"><block ref="6cdc962db7f4b3a37ce10e89250ddd8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="055717b8b2a845f9fe90ecae965b1feb" category="list-text">部署连接器后，新创建的连接器将显示在*Connecter*下拉列表中。</block>
  <block id="cbcab82e2838e0aef0a8eb0171ced986" category="paragraph"><block ref="cbcab82e2838e0aef0a8eb0171ced986" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8de7e309885d21366a248cc336a9b9f" category="section-title">在BlueXP中定义用于Azure资源访问的凭据</block>
  <block id="c60c5069d027433cec0a8d7858d4cf82" category="list-text">单击BlueXP控制台右上角的设置图标以打开*帐户凭据*页面，单击*添加凭据*以启动凭据配置工作流。</block>
  <block id="e0100832f337c0b4314cbfff09001007" category="paragraph"><block ref="e0100832f337c0b4314cbfff09001007" category="inline-image-macro-rx" type="image"></block></block>
  <block id="92a4163561d0ead1f38efbf8eb4b7404" category="list-text">选择凭据位置为-* Microsoft Azure - BlueXP*。</block>
  <block id="030c494696b17baa2b9c4af5c4b4c728" category="paragraph"><block ref="030c494696b17baa2b9c4af5c4b4c728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7fd310fb0430315594373f0dfbb1417" category="list-text">使用正确的*客户端机密*、*客户端ID*和*租户ID*定义Azure凭据、这些凭据应在先前的BlueXP注册过程中收集。</block>
  <block id="f1ca379f5b9cad20b641ad5e3b55dbfe" category="paragraph"><block ref="f1ca379f5b9cad20b641ad5e3b55dbfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3142506aef795962e0d228e0323722c2" category="list-text">审查和*Add*。
<block ref="0f44ddbc6a68386befab1ef58bd4e216" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc1342cac9ac383b1ff6cb703abef64e" category="list-text">您可能还需要将*商城订阅*与凭证相关联。
<block ref="dc738b078203d3ae2c3076032bc00c99" category="inline-image-macro-rx" type="image"></block></block>
  <block id="515410530ff315add6baa9b8fec25661" category="paragraph">配置Azure凭据后、现在可以按照以下过程设置SnapCenter服务：</block>
  <block id="dda049d95317fa5a13b47acbe45fde94" category="list-text">返回"画布"页面、从*我的工作环境*中单击*添加工作环境*以发现在Azure中部署的Azure NetApp Files。</block>
  <block id="43f02e4067dfce17c2cca62c84f3e481" category="list-text">选择*Microsoft AzAzure *作为位置，然后单击*Discover。</block>
  <block id="1d16024298749f39bbf187cd337339cb" category="paragraph"><block ref="1d16024298749f39bbf187cd337339cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="81999498d9ff326372c05514e6c0f430" category="list-text">命名*工作环境*并选择在上一节中创建的*身份凭证名称*，然后单击*继续*。</block>
  <block id="e30c6b0c24a17d12ab1c013db75fb3ce" category="paragraph"><block ref="e30c6b0c24a17d12ab1c013db75fb3ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc2004ebba5da01423dc17da06b98ec5" category="list-text">BlueXP控制台返回到*我的工作环境*、并且从Azure发现的Azure NetApp Files现在显示在*Canvapp*上。</block>
  <block id="c74a9856f843e7d31354966790c3afc6" category="paragraph"><block ref="c74a9856f843e7d31354966790c3afc6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="adc19ffc08c8bfc67e1ce0cfd3eaee91" category="list-text">单击*Oracle*图标，然后单击*Enter Azure NetApp Files Working Environment *以查看存储中部署的Azure NetApp Files数据库卷。</block>
  <block id="52aed58fdd0ecaa02996f5ca0989e1e9" category="paragraph"><block ref="52aed58fdd0ecaa02996f5ca0989e1e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="506872ca506c6f8cd2efe994167fbc72" category="paragraph"><block ref="506872ca506c6f8cd2efe994167fbc72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36dc7b8a2114311837911cf5ad0176ac" category="paragraph"><block ref="36dc7b8a2114311837911cf5ad0176ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="627521257f072e1e0bb18ed662aab17a" category="list-text">选择*Oracle*作为应用程序类型，单击*Next*打开主机详细信息页面。</block>
  <block id="b4ae20600d43eb61740d59e0c0c3a25b" category="paragraph"><block ref="b4ae20600d43eb61740d59e0c0c3a25b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c26490521d58cef4fc131db2e81a94e" category="list-text">选择*使用SSH*并提供Oracle Azure VM详细信息、例如* IP地址*、*连接器*、Azure VM管理*用户名*、例如azureuser。单击*添加SSH专用密钥*以粘贴用于部署Oracle Azure VM的SSH密钥对。系统还会提示您确认指纹。</block>
  <block id="70c4bbbfbd02a546af8d59b9f0774915" category="paragraph"><block ref="ceff11557c22636c1a3ff9ea6d62118a" category="inline-image-macro-rx" type="image"></block>
<block ref="f1ba0b94657fa36dbec85cf179630e65" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6e130fb96d37b0095d24d5358f21e4b" category="list-text">转到下一个*配置*页面、在Oracle Azure VM上设置sudoer访问。</block>
  <block id="06b715a47e154b01f9731e530169f9f8" category="paragraph"><block ref="06b715a47e154b01f9731e530169f9f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ee8d75911c779ac7019740198b8f107" category="list-text">查看并单击*发现应用程序*，在Oracle Azure虚拟机上安装插件，并在虚拟机上发现Oracle数据库。</block>
  <block id="b9fd5b1cf81576e7aa2a5bd91c9a9169" category="paragraph"><block ref="b9fd5b1cf81576e7aa2a5bd91c9a9169" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e32c1f544cd9b2d6fdfd7c81e67e8d4" category="list-text">在Azure VM上发现的Oracle数据库将添加到*应用程序*中，并且*应用程序*页面列出了环境中的主机和Oracle数据库数量。数据库*Protection Status*最初显示为*unprototes*。</block>
  <block id="3b2cdbd4de59d6d82c9a11c7365b8b03" category="paragraph"><block ref="3b2cdbd4de59d6d82c9a11c7365b8b03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="91992eeb76f243096a177a51576aa930" category="list-text">我们在Azure VM中测试的Oracle数据库配置了三个卷、聚合总存储约为1.6 TiB。这提供了有关此大小数据库的快照备份、还原和克隆的时间的上下文。</block>
  <block id="5a3f2aba9cdc20567fc4f7d91f0f39d2" category="list-text">要保护数据库，请单击数据库*Protection Status*旁边的三个圆点，然后单击*Assign Policy*以查看可应用于Oracle数据库的默认预加载或用户定义的数据库保护策略。在*Settings*-*Policies*下，您可以选择使用自定义的备份频率和备份数据保留窗口创建自己的策略。</block>
  <block id="1f8dacdcb10994d391a25bf92e9bac2d" category="paragraph"><block ref="1f8dacdcb10994d391a25bf92e9bac2d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b87d60fc36851d813026dccde8a103ae" category="list-text">如果对策略配置满意，则可以*Assign*您选择的策略来保护数据库。</block>
  <block id="19edb7e4d3f3b23e4da194d556e91abc" category="paragraph"><block ref="19edb7e4d3f3b23e4da194d556e91abc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31db12a4d1827bab87af3a7cf14c8c46" category="list-text">应用此策略后、数据库保护状态将更改为*受保护*、并带有绿色复选标记。BlueXP会根据定义的计划执行快照备份。此外，还可以从三点下拉菜单中选择*按需备份*，如下所示。</block>
  <block id="3cfd18a5e97090ab9d4ebe1a94b2ea2e" category="paragraph"><block ref="3cfd18a5e97090ab9d4ebe1a94b2ea2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b344283baf9e89aa98e1a9aa97568974" category="list-text">在*Job Monitoring*选项卡中，可以查看备份作业详细信息。我们的测试结果显示、备份大约1.6 TiB的Oracle数据库大约需要4分钟。</block>
  <block id="f26f1f69b0291754b398f8186d9ba3c0" category="paragraph"><block ref="f26f1f69b0291754b398f8186d9ba3c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99abbb4565ab40d4f0845ba2bb23b66e" category="list-text">从三点下拉菜单*查看详细信息*中，您可以查看从快照备份创建的备份集。</block>
  <block id="5a46b20a51f7ec511ae0fdc9f54493f7" category="paragraph"><block ref="5a46b20a51f7ec511ae0fdc9f54493f7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c00d75f1dfb37464bcc7247839c2b868" category="list-text">数据库备份详细信息包括*备份名称*、*备份类型*、*scn*、*RMAN目录*和*备份时间*。备份集分别为数据卷和日志卷提供应用程序一致的快照。日志卷快照会在数据库数据卷快照之后发生。如果要在备份列表中查找特定备份、可以应用筛选器。</block>
  <block id="66b90d3952854f78616a55c6dc820df8" category="paragraph"><block ref="66b90d3952854f78616a55c6dc820df8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da619d6941ecdd2c7e548d9654a841ef" category="list-text">对于数据库恢复，请单击要在*Applications*中恢复的特定数据库的三点下拉菜单，然后单击*Restore*以启动数据库恢复和恢复工作流。</block>
  <block id="0503201e96685d972f44b140bfc1d508" category="paragraph"><block ref="0503201e96685d972f44b140bfc1d508" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a6466f8754f254181618465d6d07095" category="list-text">按时间戳选择您的*还原点*。列表中的每个时间戳表示一个可用的数据库备份集。</block>
  <block id="aee3bb5d1934a654336a54ea88b07326" category="paragraph"><block ref="aee3bb5d1934a654336a54ea88b07326" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8bc1a0adc65e8e1943672063a060cff" category="list-text">为Oracle数据库选择*将位置*还原到*原始位置*、以便进行原位还原和恢复。</block>
  <block id="1ee481fc2cca360695dacb7cb814322c" category="paragraph"><block ref="1ee481fc2cca360695dacb7cb814322c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2ac50fae413c6d5e5094eae408e73538" category="list-text">定义*恢复范围*和*恢复范围*。所有日志均表示完整恢复为最新状态、包括当前日志。</block>
  <block id="816fff95db7430c8ac9fdf325a133e4a" category="paragraph"><block ref="816fff95db7430c8ac9fdf325a133e4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ac2cb8dff52fa25ab3c4179d23af060" category="list-text">查看和*Restore*以启动数据库还原和恢复。</block>
  <block id="45af5bba74ad48d476b1821859e1948a" category="paragraph"><block ref="45af5bba74ad48d476b1821859e1948a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93c57cdfffd8f5678e2781396b8052ee" category="list-text">在*作业监控*选项卡中，我们发现运行完整数据库恢复和最新数据恢复需要2分钟的时间。</block>
  <block id="8114840696eab95c3787c9354e82681c" category="paragraph"><block ref="8114840696eab95c3787c9354e82681c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="10f67c792b4c3a171ec4459316640f04" category="paragraph">数据库克隆过程与还原类似、但也适用于预先安装和配置了相同Oracle软件堆栈的备用Azure VM。</block>
  <block id="0a726ae819aa445c83a06d6c6b45248d" category="admonition">确保Azure NetApp文件存储有足够的容量来容纳与要克隆的主数据库大小相同的克隆数据库。备用Azure虚拟机已添加到*应用程序*中。</block>
  <block id="78984c1b4316df6a6010d6cb1420883b" category="list-text">单击要在*Applications*中克隆的特定数据库的三点下拉菜单，然后单击*Restore*以启动克隆工作流。</block>
  <block id="9ad51a7fad933e89ae8f0294c3cb49fc" category="paragraph"><block ref="9ad51a7fad933e89ae8f0294c3cb49fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c81741abd46b5657b1b137ad6b08c60d" category="list-text">选择*还原点*并选中*还原到备用位置*。</block>
  <block id="e4a902420d19e31eccc7d91419c6d691" category="paragraph"><block ref="e4a902420d19e31eccc7d91419c6d691" category="inline-image-macro-rx" type="image"></block></block>
  <block id="821f3d32c228cdb4c83894cf7f22f5bc" category="list-text">在下一个*Configuration*页面中，将备用*Host*、新数据库*SID*和*Oracle Home*设置为在备用Azure虚拟机上配置。</block>
  <block id="da09170eabb9431dcd4c904a4315d274" category="paragraph"><block ref="da09170eabb9431dcd4c904a4315d274" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76241d79c5d5f01636b403e2ed5ec804" category="list-text">Review *General页显示了克隆数据库的详细信息，如SID、备用主机、数据文件位置、恢复范围等</block>
  <block id="95a6f17bf147c091dff88da2fafaa9b9" category="paragraph"><block ref="95a6f17bf147c091dff88da2fafaa9b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43b6971c27d0d503f52ec88935ec1382" category="list-text">Review *Database parameters*(查看*Database parameters*)页显示了克隆的数据库配置的详细信息以及一些数据库参数设置。</block>
  <block id="1f91f781805a086a17864fc8d45a859f" category="paragraph"><block ref="1f91f781805a086a17864fc8d45a859f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62dc32438ca73d555756784b39f074d2" category="list-text">通过*作业监控*选项卡监控克隆作业状态，我们发现克隆1.6 TiB Oracle数据库需要8分钟。</block>
  <block id="ab1f0cef09be60a75bba293bbeed266b" category="paragraph"><block ref="ab1f0cef09be60a75bba293bbeed266b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3c33cefae6ca0544ea18f72546fa955" category="list-text">在BlueXP *应用程序*页面中验证克隆的数据库、该页面显示克隆的数据库已立即注册到BlueXP中。</block>
  <block id="1a5aeaba4f086d0b20e1477e27770819" category="paragraph"><block ref="1a5aeaba4f086d0b20e1477e27770819" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c63639ec48ac9f3ed5e3bd19cb501647" category="list-text">验证Oracle Azure VM上显示克隆数据库按预期运行的克隆数据库。</block>
  <block id="5031207ab257cb06924bd0e19462b61c" category="paragraph"><block ref="5031207ab257cb06924bd0e19462b61c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc555bae6dace1d6d3b409d213670af3" category="paragraph">至此、我们完成了使用NetApp BlueXP控制台和SnapCenter服务在Azure中进行Oracle数据库备份、还原和克隆的演示。</block>
  <block id="855ff2118de8410b364ef10dd2bb08cf" category="inline-link-macro"><block ref="855ff2118de8410b364ef10dd2bb08cf" category="inline-link-rx"></block></block>
  <block id="cbadf086d67897b3b1aaeecf728b288c" category="paragraph"><block ref="cbadf086d67897b3b1aaeecf728b288c" category="inline-link-macro-rx"></block></block>
  <block id="27e1212a42107cfc0301ede49e34c2b6" category="list-text">开始使用Azure</block>
  <block id="1835dca082bed53483a7a062cc1bc8d0" category="inline-link-macro"><block ref="1835dca082bed53483a7a062cc1bc8d0" category="inline-link-rx"></block></block>
  <block id="a35f1c37303f15b458dc1914b868ff3f" category="paragraph"><block ref="a35f1c37303f15b458dc1914b868ff3f" category="inline-link-macro-rx"></block></block>
  <block id="200ceef64376fb4963e417594c2660f0" category="summary">解决方案提供了有关使用NetApp SnapCenter SaaS在Azure云中使用BlueXP控制台进行Oracle数据库备份、还原和克隆的概述和详细信息。</block>
  <block id="698740e9ee6a7bf04119b53400b8b9a7" category="doc">TR-4964：《使用SnapCenter服务执行Oracle数据库备份、还原和克隆—AWS》</block>
  <block id="6f4cd1b0523380b825fa78ec70975a14" category="cell">两个EC2 t2 xlarge EC2实例、一个用作主数据库服务器、另一个用作克隆数据库服务器</block>
  <block id="56427e5f1c1f5700ead6c9a9bce7060b" category="list-text">*为SnapCenter 连接器创建的AWS IAM策略。*详细的SnapCenter 服务文档中提供了JSON格式的策略。使用BlueXP控制台启动连接器部署时、系统还会提示您设置前提条件、并以JSON格式提供所需权限的详细信息。应将此策略分配给拥有此连接器的AWS用户帐户。</block>
  <block id="0c28eaf31a69bb7791a4813ad2b0bcad" category="list-text">* AWS帐户访问密钥和在AWS帐户中创建的SSH密钥对。* SSH密钥对分配给EC2-user、用于登录到连接器主机、然后将数据库插件部署到EC2 DB服务器主机。访问密钥授予使用上述IAM策略配置所需连接器的权限。</block>
  <block id="335e5cb00aff2c78312972d158d4b579" category="list-text">*添加到BlueXP控制台设置的凭据。*要将Amazon FSx for ONTAP添加到BlueXP工作环境中、需要在BlueXP控制台设置中设置一个凭据、用于授予BlueXP访问Amazon FSx for ONTAP的权限。</block>
  <block id="74a16f5a2cb515e5359c279dfe53d615" category="list-text">*EC2数据库实例主机上安装了java-11-OpenJDK。* SnapCenter服务安装需要Java版本11。在尝试部署插件之前、需要将其安装在应用程序主机上。</block>
  <block id="b16d85e1d11f85dc031a4dba6341172b" category="list-text">AWS中部署的Amazon FSx for ONTAP集群、用于托管上述数据库卷。</block>
  <block id="d15621373250f7778b58f1a57646d590" category="list-text">EC2实例上的一个可选数据库服务器、可用于测试将Oracle数据库克隆到备用主机的操作、以支持开发/测试工作负载或任何需要生产Oracle数据库的完整数据集的使用情形。</block>
  <block id="c138896742fc6fda756e11167ed75f14" category="list-text">如果您需要帮助以满足在Amazon FSX for ONTAP 和EC2计算实例上部署Oracle数据库的上述前提条件、请参见 <block ref="84dfb8b43ed6d356540ab11fdb4b0e89" category="inline-link-macro-rx"></block> 或白皮书 <block ref="028ff281fd359dd1a824cb2ca4b97f33" category="inline-link-macro-rx"></block></block>
  <block id="905649aa82828b72c7609e32261b6541" category="list-text">登录到您的AWS帐户以创建具有适当权限的IAM策略、并将该策略分配给要用于BlueXP Connector部署的AWS帐户。</block>
  <block id="2f43b4d90aacd2dff66dbba89df8d3e8" category="paragraph">应使用NetApp文档中提供的JSON字符串配置此策略。启动连接器配置并提示您分配前提条件权限时、也可以从页面中检索JSON字符串。</block>
  <block id="8a93a46df85bf33efa5d5200b6c4ce06" category="list-text">此外、您还需要准备好AWS VPC、子网、安全组、AWS用户帐户访问密钥和密码、EC2用户的SSH密钥等、以便进行连接器配置。</block>
  <block id="04592f11c82d99f55bd84f8036b45389" category="list-text">登录到BlueXP控制台。对于共享帐户、最佳做法是通过单击*帐户*&gt;*管理帐户*&gt;*工作空间*来创建单个工作空间以添加新工作空间。</block>
  <block id="dfaeef102040345b1180ea94f2b0c2ff" category="list-text">使用*访问密钥*和*机密密钥*输入您的AWS帐户身份验证。</block>
  <block id="a8f366d09f3fd92a0239f6862ee9d35e" category="list-text">使用正确的* VPC*、*子网*和SSH *密钥对*配置网络连接以访问连接器。</block>
  <block id="2e132860f3a8d1cbe124a67c4b5d67cc" category="list-text">设置连接器的*Security Group*。</block>
  <block id="74be0e1339ee168e43642c78894f516c" category="section-title">在BlueXP for AWS资源访问中定义凭据</block>
  <block id="e0d8224cb04f8209c7dd255259abe722" category="list-text">首先、从AWS EC2控制台、在*身份和访问管理(IAM)*菜单*角色*和*创建角色*中创建角色、以启动角色创建工作流。</block>
  <block id="aa5bbfe691ae80f3fbec564c34575332" category="paragraph"><block ref="aa5bbfe691ae80f3fbec564c34575332" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3f70a9b0bcfff938be5c9b967baac38" category="list-text">在*选择可信实体*页面中、选择* AWS account*、*另一个AWS account*、然后粘贴BlueXP帐户ID、该ID可从BlueXP控制台检索。</block>
  <block id="a9e01f9cc502485335e3850b8251f9ec" category="paragraph"><block ref="a9e01f9cc502485335e3850b8251f9ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c29f350fe0ef034c8595e5a9732939b3" category="list-text">按FSx筛选权限策略并将*权限策略*添加到角色。</block>
  <block id="9153cee2ecbf0805cafee7397d59641c" category="paragraph"><block ref="9153cee2ecbf0805cafee7397d59641c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61a7a81a82f0f1d0520b066c19c3e2a1" category="list-text">在“*角色详细信息*”页中，为角色命名，添加一个问题描述，然后单击*Create Role*。</block>
  <block id="d49ba55824dd5ad889fac0ad43d63df4" category="paragraph"><block ref="d49ba55824dd5ad889fac0ad43d63df4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21b7150d8525df111105dbb7e805e729" category="list-text">返回BlueXP控制台、单击控制台右上角的设置图标以打开*帐户凭据*页面、然后单击*添加凭据*以启动凭据配置工作流。</block>
  <block id="3cbfa2d74d3c41a34f366b3168220af8" category="paragraph"><block ref="3cbfa2d74d3c41a34f366b3168220af8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e555a0fd2fff62a47775a52b4b58f3b1" category="list-text">选择凭据位置为-*Amazon Web Services - BlueXP*。</block>
  <block id="9902d257190975d93f06203e0d3a538f" category="paragraph"><block ref="9902d257190975d93f06203e0d3a538f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2dc9db68323ce54999aefadc7fa6b9bf" category="list-text">使用正确的*角色ARN*定义AWS凭据、可从上述步骤1中创建的AWS IAM角色检索这些凭据。BlueXP *帐户ID*、用于在步骤1中创建AWS IAM角色。</block>
  <block id="0c9ef4cba18bfbfed8d15c0af1a01564" category="paragraph"><block ref="0c9ef4cba18bfbfed8d15c0af1a01564" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9cd441745f9ee370e5941b13ab2fb091" category="list-text">审查和*Add*。
<block ref="500cfd6ba279fd74e1c36ecb39daa157" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4f3b4caea09bcee5fb52b1e6e4756a63" category="paragraph">部署连接器并添加凭据后、现在可以使用以下操作步骤设置SnapCenter服务：</block>
  <block id="20aa78b57c1494d5482d7e3d1684845b" category="list-text">选择您在上一节中创建的*凭据名称*、为BlueXP授予管理FSx for ONTAP所需的权限。如果您尚未添加凭据、则可以从BlueXP控制台右上角的*设置*菜单中添加此凭据。</block>
  <block id="c6ce8aeb69282423f1e8709e9bece6ce" category="list-text">填写AWS EC2 Oracle应用程序主机详细信息。选择*使用SSH*作为*主机安装类型*进行一步插件安装和数据库发现。然后，单击*添加SSH专用密钥*。</block>
  <block id="64066a5a6ff28b6e3783cce928287f90" category="paragraph"><block ref="64066a5a6ff28b6e3783cce928287f90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea41a89df50cac84ab851e6f7730c00d" category="list-text">粘贴数据库EC2主机的EC2用户SSH密钥，然后单击*Valid验证*继续。</block>
  <block id="c75d185690ad385defb985932722de31" category="paragraph"><block ref="c75d185690ad385defb985932722de31" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a70359387fcaa0512296895fb4f6a4ae" category="list-text">系统将提示您*验证指纹*以继续。</block>
  <block id="e36c0283d568f55714770a9abddff851" category="paragraph"><block ref="e36c0283d568f55714770a9abddff851" category="inline-image-macro-rx" type="image"></block></block>
  <block id="032b4254e4889aa8b7e197feb31cbc5a" category="list-text">单击*下一步*以安装Oracle数据库插件并在EC2主机上发现Oracle数据库。发现的数据库将添加到*Applications*中。数据库*Protection Status*在最初发现时显示为*unprototed"(未受保护)。</block>
  <block id="db9e9ec215ebe0fc52fb46e84cda4d6e" category="sidebar">使用SnapCenter服务执行Oracle备份、还原和克隆—Azure</block>
  <block id="8a708dc28e6881f4ca61b1dac86fb745" category="sidebar">适用于Oracle的BlueXP SaaS—Azure</block>
  <block id="72fabf1add0034062f091db87a4723b3" category="sidebar">适用于Oracle的BlueXP SaaS—AWS</block>
  <block id="e5940f15f03ec96afbdff53b6955ad9c" category="cell">2023年8月15日</block>
  <block id="b3b0def4125e36860cf290ad9d17bd6f" category="cell">重新设计了虚拟化(VMware)登录页面</block>
  <block id="83669449150d17df292a91b9fdab8c54" category="paragraph">这可确认DNFS运行正常。</block>
  <block id="9f4dc1f81d694d1c48953880d5be0ea7" category="paragraph">这样可以确认Oracle侦听器工作正常。</block>
  <block id="724dafd81685ec54ccc23dfddf773250" category="doc">VMware Cloud中的Veeam备份和还原、采用Amazon FSx for ONTAP</block>
  <block id="631ad0ec67fe557296ad8ea61548e391" category="doc">适用于Google Cloud的NetApp解决方案VMware引擎(GCVe)</block>
  <block id="c034310b7a5e84163a9aa84d973faeae" category="paragraph">详细了解NetApp为Google云平台(GCP) Google Cloud VMware Engine (GCVe)带来的功能—从作为子系统连接存储设备或补充NFS数据存储库的NetApp、到迁移工作流、扩展/扩充到云、备份/还原和灾难恢复。</block>
  <block id="81e1ccd46eb4fc86f01bc70f61ea35e0" category="summary">Red Hat OpenShift 容器平台将开发和 IT 运营统一到一个平台上，以便在内部和混合云基础架构中一致地构建，部署和管理应用程序。Red Hat OpenShift基于开源创新和行业标准构建、包括Kubbernetes和Red Hat Enterprise Linux Core-OS、这是一款领先的企业级Linux发行套件、专为基于容器的工作负载而设计。</block>
  <block id="76ac5e7329e42786f73e51a65d2e7493" category="list-text">*自助式配置*开发人员可以使用最常用的工具快速轻松地按需创建应用程序，同时操作人员仍可完全控制整个环境。</block>
  <block id="22b5b37aed7d2cfc95cfe160732caff9" category="list-text">*永久性存储* OpenShift容器平台支持永久性存储、可让您同时运行有状态应用程序和云原生无状态应用程序。</block>
  <block id="2791382361fbd296cd1db54fa7343362" category="list-text">*持续集成和持续开发(CI/CD)*此源代码平台可大规模管理构建和部署映像。</block>
  <block id="ebe44bbbf82d4d56407d7bd7d116334b" category="list-text">*开源标准*除了其他开源技术之外、这些标准还包括用于容器流程编排的开放式容器计划(OCI)和Kubernetes。您不受限于特定供应商的技术或业务路线图。</block>
  <block id="276fa5efbb4f748e08e2c30a84ce282e" category="list-text">*CI/CD管道* OpenShift为CI/CD管道提供开箱即用的支持，使开发团队可以自动执行应用程序交付流程的每个步骤，并确保对应用程序代码或配置进行的每次更改都能执行该步骤。</block>
  <block id="910a2a0b5f3f5d1e49c5a0d1e0dc2138" category="list-text">*基于角色的访问控制(RBAC)*此功能提供团队和用户跟踪，以帮助组织大型开发人员组。</block>
  <block id="b93adb654910a18d3a7ab4aa9939ce46" category="list-text">*自动化构建和部署* OpenShift允许开发人员选择构建容器化应用程序、或者让平台基于应用程序源代码甚至二进制文件构建容器。然后，该平台会根据为这些应用程序定义的特征在整个基础架构中自动部署这些应用程序。例如，为了使资源符合第三方许可证的要求，应分配的资源数量以及应部署在基础架构上的什么位置。</block>
  <block id="0e214dd7b6db6f54026d60bd23570448" category="list-text">*一致的环境* OpenShift可确保为开发人员配置的环境在应用程序的整个生命周期内从操作系统、库、运行时版本(例如Java运行时)、 甚至包括正在使用的应用程序运行时(例如Tomcat)、以消除因环境不一致而产生的风险。</block>
  <block id="3324921ce520b5c2abe0d2521e8b040e" category="list-text">*配置管理*配置和敏感数据管理功能内置在平台中，以确保无论使用哪种技术构建应用程序或环境如何，都能为应用程序提供一致且不受环境限制的应用程序配置
已部署。</block>
  <block id="2d11325a996ec8e35070707ab180ca6c" category="list-text">*应用程序日志和指标。*快速反馈是应用程序开发的一个重要方面。OpenShift 集成式监控和日志管理可为开发人员提供即时指标，使他们能够研究应用程序在发生变更时的行为方式，并能够在应用程序生命周期中尽早修复问题。</block>
  <block id="93507554a1bd5b356e1ecf2a5fb0bd55" category="list-text">*安全性和容器目录* OpenShift提供多租户功能、并通过使用安全增强型Linux (SELinux)、CGroups和安全计算模式(seccomp)建立的安全性隔离和保护容器、保护用户免受有害代码执行的影响。此外，它还通过 TLS 证书为各种子系统提供加密，并可访问经过 Red Hat 认证的容器（ access.redhat.com/containers ），这些容器经过扫描和评级，并特别强调安全性，以便为最终用户提供经过认证的，可信的安全应用程序容器。</block>
  <block id="e2fb3873f5444b3e2992591c137a7885" category="list-text">访问 Red Hat OpenShift <block ref="07d9e126d73368020dd109a73fa50f95" category="inline-link-macro-rx"></block> 并使用您的 SSO 凭据登录。</block>
  <block id="c7daf823271052cb8912656769e85130" category="list-text">按照 <block ref="031f6892cefd9bd35a861ba4dda1d58c" category="inline-link-macro-rx"></block> 由 Red Hat 提供，用于部署到您选择的环境。</block>
  <block id="b6c4f27764ca359c19a70c2b1cbc1d97" category="list-text">*IPI或辅助安装程序部署*借助由安装程序配置的基础架构(IPI)在裸机服务器上部署的OpenShift集群，客户可以直接在商用服务器上部署高度通用、易于扩展的OpenShift环境，而无需管理虚拟机管理程序层。</block>
  <block id="f8ed0733873bb3b372f7a9467a850d93" category="list-text">*紧凑型集群设计*为了最大限度地降低硬件要求、裸机上的OpenShift允许用户部署仅包含3个节点的集群、方法是使OpenShift控制平台节点也充当工作节点和主机容器。</block>
  <block id="6579bfdd2d4dc076bdbb8cbece3b4cc0" category="list-text">*OpenShift虚拟化* OpenShift可以使用OpenShift虚拟化在容器内运行虚拟机。此容器本机虚拟化可在容器内运行 KVM 虚拟机管理程序，并为 VM 存储附加永久性卷。</block>
  <block id="b0500e4f37101d510007bfaf623af7ed" category="list-text">*人工智能/机器学习优化的基础架构*通过将基于GPU的工作节点整合到您的OpenShift环境中并利用OpenShift高级计划、为机器学习应用程序部署Kubeflow等应用程序。</block>
  <block id="8412476b5a3f9221e4b79f8abf725696" category="list-text">*配置网络*此网络用于启动裸机节点并安装部署OpenShift集群所需的映像和软件包。</block>
  <block id="e6eb5af4aff65961a7f350b2222a4119" category="list-text">*裸机网络*部署集群后、此网络用于集群面向公共的通信。</block>
  <block id="24749f872afed111082e4454a0583abd" category="paragraph">有关 RHV 的详细信息，请参见 <block ref="a046c007a57f7ff7a2197f69662fe957" category="inline-link-macro-rx"></block>。</block>
  <block id="d198e9ca7e59f5313859da21138acb94" category="list-text">*集中管理虚拟机和主机* RHV管理器在部署中作为物理机或虚拟机(VM)运行、并提供基于Web的图形用户界面、用于从中央界面管理解决方案。</block>
  <block id="a2ae760ef875e32aa0f6e6cea19b7843" category="list-text">*自托管引擎*为了最大限度地降低硬件要求，RHV允许将RHV Manager (RHV-M)部署为运行子VM的同一主机上的VM。</block>
  <block id="78f6af1e137635a3cea4ef964e21c7c6" category="list-text">*高可用性*为了避免主机发生故障时发生中断，RHV允许将虚拟机配置为高可用性。高可用性 VM 可通过故障恢复策略在集群级别进行控制。</block>
  <block id="dc4a50395fea041f4ee918e8c015755e" category="list-text">*高可扩展性*一个RHV集群最多可包含200台虚拟机管理程序主机、使IT能够满足大型VM的需求、从而托管资源要求较高的企业级工作负载。</block>
  <block id="3fe956f564bcb16eb1d25ab6afdf9bf7" category="list-text">*从RHV、安全虚拟化(sVirt)和安全增强Linux (SELinux)技术继承的增强安全性*被RHV用于提高主机和VM的安全性和强化。这些功能的主要优势是对虚拟机及其相关资源进行逻辑隔离。</block>
  <block id="1eb1f8a0b7a23bf292377ca6141c9764" category="paragraph">要配置相关性组，请参见 <block ref="71c7e3da1d9a2a54a294147a4cd2de31" category="inline-link-macro-rx"></block>。</block>
  <block id="cf0ddf5e6e47a8c8022acdc665895746" category="paragraph">在这些情况下，您无需立即部署集群即可运行和执行向导任务。而是会创建一个配置文件，以便稍后从该文件部署集群。如果要更改任何 IPI 默认值，或者要在环境中部署多个相同的集群以用于多租户等其他用途，则此功能非常有用。有关为 OpenShift 创建自定义安装配置的详细信息，请参见 <block ref="25daed5af84e217ef9044fffc5e957eb" category="inline-link-macro-rx"></block>。</block>
  <block id="f51df3c7eb6fd29ff4a45c600d597cdc" category="paragraph">有关 VMware vSphere 的详细信息，请参见 <block ref="274345b8e0a166805c0e4fb3d51affbd" category="inline-link-macro-rx"></block>。</block>
  <block id="ca7c883830a501eece7802d17466780e" category="list-text">* VMware vCenter Server* VMware vCenter Server 可通过一个控制台统一管理所有主机和 VM ，并聚合对集群，主机和 VM 的性能监控。</block>
  <block id="b5833c22ec8627273b0415df731c3ce7" category="list-text">*VMware vSphere vMotion* VMware vCenter允许您根据请求无中断地在集群中的节点之间热迁移VM。</block>
  <block id="634e669a6bf01bf0ef2b676eae7beb33" category="list-text">*vSphere高可用性*为了避免主机发生故障时发生中断，VMware vSphere允许将主机集群化并配置为高可用性。由于主机故障而中断的 VM 不久将在集群中的其他主机上重新启动，从而还原服务。</block>
  <block id="435136c715673552d02d1fd739606dfc" category="list-text">*分布式资源计划程序(DRS)*可以配置VMware vSphere集群，以便对其托管的VM的资源需求进行负载平衡。具有资源管理的 VM 可以热迁移到集群中的其他节点，以确保有足够的可用资源。</block>
  <block id="caa4cd40407d5fbb60417567f99dc12b" category="paragraph">要配置相关性组，请参见 <block ref="5eec17a83b1cdbe2155f458e6c616d5f" category="inline-link-macro-rx"></block>。</block>
  <block id="60d232b4b7425bdadb1962222b2c23ab" category="paragraph">在这些情况下，您无需立即部署集群即可运行和执行向导任务，但向导会创建一个配置文件，以便稍后可以从中部署集群。如果您需要更改任何 IPI 默认值，或者要在环境中部署多个相同的集群以用于多租户等其他用途，则此功能非常有用。有关为 OpenShift 创建自定义安装配置的详细信息，请参见 <block ref="425558ab055ee08d7eb4486f3ceb6631" category="inline-link-macro-rx"></block>。</block>
  <block id="588d940c602fa8b127eead0a7b20f748" category="paragraph">有关 OSP 的详细信息，请参见 <block ref="52023575482d8580431ebeb833211aae" category="inline-link-macro-rx"></block>。</block>
  <block id="b9b537b6c036ca53664ba24b95cb414b" category="paragraph">要配置相关性组，请参见 <block ref="e6d55bbdf0ab41341d925ad7a06c94d5" category="inline-link-macro-rx"></block>。</block>
  <block id="112f4e7f30ad9cbc041b99087d3e6500" category="paragraph">在这些情况下，无需立即部署集群，即可运行并执行向导任务；而是创建一个配置文件，以便稍后可以从中部署集群。如果您需要更改任何 IPI 默认值，或者要在环境中部署多个相同的集群以用于多租户等其他用途，则此功能非常有用。有关为 OpenShift 创建自定义安装配置的详细信息，请参见 <block ref="448139de1d1e7e28131a802d8158cd87" category="inline-link-macro-rx"></block>。</block>
  <block id="e4b19dda515d74b9a24acc08f7f67ae8" category="paragraph">VMware Cloud Foundation (VCF)是一组技术、可为访问混合云体验提供一条简单的途径。在VCF解决方案中、既支持本机Kub并 支持基于虚拟机的工作负载。VMware vSphere、VMware vSAN、VMware NSX-T数据中心和VMware vReal Cloud Management等基本服务是VCF软件包不可或缺的组成部分。这些服务相结合、可建立一个软件定义的基础架构、该基础架构能够管理计算、存储、网络、安全和云管理。这种综合基础架构可提供混合体验、其中VCF框架可将环境从现场数据中心扩展到Amazon Web Services (AWS)、Azure和Google Cloud。</block>
  <block id="2250dada69ecec08ffc29ac659683495" category="section-title">文档资源</block>
  <block id="4d41f0cd8710adda9c3c5d30c30db643" category="paragraph">有关适用于VMware Cloud Foundation的NetApp产品的详细信息、请参见以下四(4)部分的博客系列：</block>
  <block id="d797171ff575281d2627c11f7d7bab8d" category="inline-link-macro">NetApp和VMware Cloud Foundation让一切变得轻松第1部分：入门</block>
  <block id="9a06cf2a4979d215ab33b53cd72da781" category="list-text"><block ref="9a06cf2a4979d215ab33b53cd72da781" category="inline-link-macro-rx"></block></block>
  <block id="8d00e9302fea397bac4c031557e8ce3f" category="inline-link-macro">NetApp和VMware Cloud Foundation让一切变得轻松第2部分：vcf和ONTAP主体存储</block>
  <block id="a4e9b79b178dd47f3b625b6055127ed6" category="list-text"><block ref="a4e9b79b178dd47f3b625b6055127ed6" category="inline-link-macro-rx"></block></block>
  <block id="690540040dd69b62d63d21761f909333" category="inline-link-macro">NetApp和VMware Cloud Foundation让一切变得轻松第3部分：vcf和Element主体存储</block>
  <block id="8ca497dca1763ac50d72bc7f51bc1d0b" category="list-text"><block ref="8ca497dca1763ac50d72bc7f51bc1d0b" category="inline-link-macro-rx"></block></block>
  <block id="7968bfce9121beb704a2e98d5089aab9" category="inline-link-macro">NetApp和VMware云基础变得简单—第4部分：适用于VMware的ONTAP工具和补充存储</block>
  <block id="bcd66d866b56424ed1c1bd1726688eea" category="list-text"><block ref="bcd66d866b56424ed1c1bd1726688eea" category="inline-link-macro-rx"></block></block>
  <block id="3193c58484d0f4a1cb3460d948e722a1" category="paragraph">*VMware Cloud Foundation*的NetApp FlexPod解决方案</block>
  <block id="ee7fb51fc0550957ffc1db6ff70436f8" category="inline-link-macro">借助VMware Cloud Foundation扩展FlexPod混合云</block>
  <block id="3d6b8ef8c6e45187e6e7dea4263bce6a" category="list-text"><block ref="3d6b8ef8c6e45187e6e7dea4263bce6a" category="inline-link-macro-rx"></block></block>
  <block id="1e31ad20c01fcb7cf53c83b4763fdcb0" category="inline-link-macro">FlexPod作为VMware Cloud Foundation的工作负载域</block>
  <block id="f34d47b1ca5e266db5221c743b82a092" category="list-text"><block ref="f34d47b1ca5e266db5221c743b82a092" category="inline-link-macro-rx"></block></block>
  <block id="9b04ace9e3328cbbc477a00f5a2e1b2f" category="inline-link-macro">《FlexPod作为VMware云基础的工作负载域设计指南》</block>
  <block id="b5a5c741a920add1a2a2ee4fc4562f5b" category="list-text"><block ref="b5a5c741a920add1a2a2ee4fc4562f5b" category="inline-link-macro-rx"></block></block>
  <block id="f1eb935890ab23ad54fa47582b7627bc" category="doc">适用于vSphere 8的NetApp支持</block>
  <block id="cadc15be508d2904dd26fdd4f4303243" category="paragraph">NetApp和VMware是唯一一家由一个存储系统解决VMware定义的所有关键用例的合作伙伴关系。</block>
  <block id="5db065e1876d089afef38576083f4b94" category="section-title">适用于vSphere 8的现代化云互联全闪存</block>
  <block id="9ce9bf50c26d7491636c6f797902f887" category="paragraph">ONTAP实施可在多种平台上运行、包括由NetApp设计的设备、商用硬件和公有云。无论您是通过SAN或NAS协议进行访问、还是采用从高速闪存到低成本介质再到基于云的存储的各种配置、ONTAP均可提供统一存储。NetApp还提供了专用闪存平台、可简化和细分您的存储需求、而不会形成孤岛。此外、NetApp还提供了一款软件、可以轻松地在内部环境和云之间移动数据。最后、NetApp BlueXP提供了一个信息板、用于管理所有这些关系和存储占用空间。</block>
  <block id="f732807231a9fea58be27e6b14f46c2f" category="inline-link-macro">NetApp平台</block>
  <block id="380e1d31ecadf84b2f64c52855dd3de4" category="list-text"><block ref="380e1d31ecadf84b2f64c52855dd3de4" category="inline-link-macro-rx"></block></block>
  <block id="1c1ebfd780068b701907479b7c00ae2d" category="list-text"><block ref="1c1ebfd780068b701907479b7c00ae2d" category="inline-link-macro-rx"></block></block>
  <block id="0052754a06bf2750d73a0f73b8150d0b" category="image-alt">vmware3</block>
  <block id="79e134c8c77237f4b1c663e32a5a1ed3" category="list-text">运行ONTAP 9.8或更高版本的ONTAP存储系统(FAS/AF/CVO/ONTAP Select/Cloud Volume Service/Azure NetApp Files)</block>
  <block id="6b9d03508e366f3541833f8ec1a41e79" category="list-text">vSphere主机信息vSphere 7.0或更高版本</block>
  <block id="48914315105225d9b13f1cb96fe4d604" category="doc">基于NetApp的VMware：任意工作负载、任意应用程序、任意位置</block>
  <block id="88ddaaa39fd58a55d263f744fccaeb19" category="paragraph">NetApp ONTAP支持跨内部环境和公共云环境的关键VMware产品。</block>
  <block id="abc25459aa07682c90f2f27a97872971" category="section-title">适用于VMware的NetApp解决方案</block>
  <block id="fc8856c962dffd25772e805e558c9463" category="paragraph">NetApp提供了各种解决方案、重点介绍了NetApp与VMware的集成。  单击任何VMware产品、了解适用于该特定产品的NetApp解决方案。</block>
  <block id="9b2180068d84a1a113fa1519121b1978" category="inline-link-macro">[白色大号</block>
  <block id="e825726e9a23a071d11d02714478cf2e" category="cell">｛set：cellbgcolor：black｝ <block ref="2a8063df708a304eb79d32cd05a5892e" category="inline-link-macro-rx"></block>*VMware*]
[white big (白色大容量)]#vSphere #</block>
  <block id="553212832ed952036bd82c7ad96b7cae" category="cell"><block ref="0205b9c7ae145ee4e29df6a0a5bc1c4d" category="inline-link-macro-rx"></block>*VMware*]
[WHITE BIG]#Cloud Services#</block>
  <block id="f14f33a0ecddf3b6d5e4ff8afb5525a5" category="cell"><block ref="778d4c5acdd9f8db931b74d91d468e06" category="inline-link-macro-rx"></block>*VMware*]
[white big (白色大)]#Tanzu#</block>
  <block id="491f6edcbbca99f22ce7e31e580cc23c" category="cell"><block ref="0b3bc5bd7f1d56e24b10a91329bee8fe" category="inline-link-macro-rx"></block>*VMware*]
[WHITE BIG]#AIDA#</block>
  <block id="eefb0771e467c0d367309baa3e5a51e5" category="cell"><block ref="0d5f3268ed99236f059fddf50c4878b6" category="inline-link-macro-rx"></block>*VMware*]
[white big (白色大卷)]#Virtual Volumes#
[white big (白色大容量)#(vols)#</block>
  <block id="9ae19352e74e0a0e005e08090c5cf81b" category="cell"><block ref="8a49c184ad7407f6feb36594df453135" category="inline-link-macro-rx"></block>*VMware*]
[WHITE BIG]#Cloud Foundation#</block>
  <block id="e9dfa7636fc5323f551d86c4c7fa6ffc" category="cell"><block ref="b7d323a5736c0a1e25ec2cf0456de45d" category="inline-link-macro-rx"></block>*VMware*]
[WHITE BIG]#Site Recution#
[白色大号]#Manager#</block>
  <block id="1539b609cf78f6b94aec322edf712340" category="inline-image-macro">宽度=120</block>
  <block id="4c820d11b2fdb30eaa74ec9842e10b6f" category="cell">｛set：cellbgcolor：none｝ <block ref="0f49a04ef95388de57a1ca9977466b62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd3a2d8868e8c5aa9c14aa724493e749" category="cell">｛set：cellbgcolor：black｝ <block ref="1cadefbfa9dab839cd3a99a4fb3c7b64" category="inline-link-macro-rx"></block>*VMware*]
[白色大号]#HCX#</block>
  <block id="22d2c1f128c040f21da3c089629e9130" category="doc">NetApp和VMware：客户案例</block>
  <block id="01518225c08761a89699d02be1af10db" category="paragraph">以下是NetApp和VMware合作带来的众多客户成功案例中的几个。  单击图像、了解有关客户案例的更多信息。</block>
  <block id="b46c4c590e7da4239b40d2e8895e1ca6" category="image-alt">VMware案例1</block>
  <block id="9da5b6b05a70ca00f13e0d6a0f46d3b0" category="image-alt">VMware案例2</block>
  <block id="e227809e4c1fed3e0bab916213afd503" category="paragraph">适用于云智能VMware基础架构的现代数据存储</block>
  <block id="48a8f3667d71b3a16b8566df9513a4ec" category="image-alt">VMware案例3</block>
  <block id="266d2bd74b919b1abdd97a91b09b5784" category="paragraph">适用于Kubnetes的现代数据存储</block>
  <block id="93a5c04cccb8db1280442884f3334577" category="image-alt">VMware案例4</block>
  <block id="4116bf165564b3931fca1e4baa777382" category="paragraph">混合云和多云运营 </block>
  <block id="de6fcdd1042a444d391502baed8b850c" category="section-title">做到完美搭配：vSphere和NetApp全闪存</block>
  <block id="5c78a05518a8486f6c962c99e93c25a1" category="paragraph">*客户面临的挑战：*加快全球骨髓护理设施和研究应用的性能、移动性和可恢复性—1 PB数据库/文件。</block>
  <block id="7cadd265dd42c6ef1d1095f59043bf68" category="paragraph">*解决方案：* ONTAP全闪存主存储加上统一存储备份。SnapCenter可自动执行有关应用程序配置、复制、刷新和备份的数据库管理平台策略。</block>
  <block id="275287c6aedbc31396bf6f6475a1997e" category="paragraph">*结果：*加快了捐赠者/患者匹配性能和开发运营研究冲刺速度。自行管理的DBa操作、恢复时间不超过15分钟。</block>
  <block id="010a9af17091b1cb15cc7ac50e1cfb2b" category="paragraph">*客户评价*</block>
  <block id="650035800dfd582d2421476c8217ae45" category="list-text">"大约10年前、我们选择NetApp作为合作伙伴来帮助我们重建基础架构。现在、我们每年能够治疗的患者数量几乎是原来的两倍。" –Mike McCulloough，即将成为比赛的首席信息官</block>
  <block id="e7eb034672d1eb0c5721b09b336d4197" category="list-text">"我们不必再学习技术。它是相同的界面、在云中具有相同甚至更多的增值功能。因此、坚持使用NetApp的优势显而易见。" ——即将举行的数据中心服务主管Jsh Thostad</block>
  <block id="fe501ae7d3d9654d71fe8ac26a9010f2" category="inline-link-macro">案例研究</block>
  <block id="03c9269cc3edbc5189f764194e5a3c3d" category="paragraph">阅读 <block ref="8c7a2d652e9c68eefa42303e445cd185" category="inline-link-macro-rx"></block> 对于解决方案、为的匹配项。</block>
  <block id="02368faefabe688f662f89e96120222c" category="section-title">亚太及日本地区国家银行系统：该国最大的私有云</block>
  <block id="af7788fb3a670f4536dd2adb9f3ab5ba" category="paragraph">*客户面临的挑战：*国家环保计划(无纸币)+监管货币+支持大规模非直接付款(~40 PB容量和1、000多个应用程序)</block>
  <block id="dcf35c9d78d4a7d48bf7b6bfaa14608d" category="paragraph">*解决方案：*利用支持VMware Cloud Foundation (VCF)的ONTAP全闪存+ SnapCenter/SnapMirror打造现代化的现有基础架构</block>
  <block id="09c200c10f66e756668e273407fe9212" category="paragraph">*结果：*每天1.8亿个统一支付接口(UPI)事务(600万次IOPS和45 GB/秒吞吐量)。SRM + SnapMirror、用于复制VM和数据。SnapCenter + Commvault,用于VM备份和恢复。</block>
  <block id="4959f08c366b1de1b03e6f2e60219708" category="image-alt">VMware案例2a</block>
  <block id="b727f8536bad5a0d44c6a7d9c0ba1c30" category="paragraph">*迁移到国家加密货币*</block>
  <block id="f87aa8abf172f5056ae6f264102751da" category="paragraph">作为绿色、非接触式和受监管银行业务未来阶段的一部分、VMware云基金会和NetApp ONTAP全闪存架构将支持该国向新的国家加密货币过渡。</block>
  <block id="f5e868f394b98c78798e4f062f3e1b28" category="section-title">北美航空航天与国防：现代化的云互联Kubenetes应用程序基础架构</block>
  <block id="14faad75fa95a1d9490b4ce708edd5e4" category="paragraph">*客户挑战：* NetApp和VMware的现有客户希望扩展到云以进行现代应用程序开发。云原生存储缺乏企业级功能。</block>
  <block id="712ed966141cd5a4f61492842e2fced1" category="paragraph">*解决方案：* NetApp Cloud Volumes ONTAP (CVO)、FSxN和SnapMirror可在AWS上实现一致的企业级混合云、同时支持VMware Tanzu和RedHat OpenShift。</block>
  <block id="e2eabb7542e6694cab8a73609d095003" category="paragraph">*结果：*为GovCloud提供一致的企业级Kubernetes和文件服务存储、并利用相同的ONTAP企业级存储功能集。</block>
  <block id="be032438320d7235edf331a7c3d790a0" category="image-alt">VMware案例3a</block>
  <block id="cdf3a4c584cc917da22b83ba69d624f4" category="paragraph">*灵活的选项，一个一致的平台*</block>
  <block id="a3fb9b2a04debda720eefe5563484e6e" category="list-text">同时支持VMware Tanzu和RedHat Kubnetes工作负载</block>
  <block id="fbccd2f37dc6f375c788ccf4cd951462" category="list-text">适用于客户管理的Cloud Volumes ONTAP</block>
  <block id="9ddac51f34b53fa144892bef0c2fd050" category="list-text">适用于完全托管的AWS本机服务的FSxN</block>
  <block id="525c2bb2132ca752b2820bb8df4f200d" category="list-text">应用程序开发和企业文件服务</block>
  <block id="24181ccc736140264b97ff29623dc9c2" category="section-title">Orange Business Services：领先的网络和数字集成商</block>
  <block id="6270c54514c2c3762d05a8fbcff45137" category="paragraph">*客户挑战：*增强报告功能并缩短停机时间、以改进在ONTAP和vSphere上运行的云和基础架构即服务(Infrastructure as a-Service、IaaS)产品</block>
  <block id="bc5a6d04695a1fa07d9b8e96dad5a87e" category="paragraph">*：* VMware解决方案(vReALIe)和适用于NetApp ONTAP的真正可见性管理包、可提供更深入的存储诊断发现和报告。</block>
  <block id="88396172fed9ef4722d7fe6043bcfa6c" category="list-text">"借助适用于NetApp的vReise True Vis性 管理包提供的可见性、我们现在可以将发现停机症状的速度提高70%到80%。" ——技术主管Richard Estve</block>
  <block id="b70af36615dd14f08cbfb55ece3640a9" category="list-text">"为了有效管理IT环境、我们的客户需要了解整个环境中发生的情况。VMware的即装即用信息板正是如此、这极大地改善了我们的整体客户体验。-技术主管Richart Esteve</block>
  <block id="2c11d13b7516e23770d5944816665fb9" category="cell"><block ref="5c289fcb66258298907b645fa75dba56" category="inline-link-rx"></block></block>
  <block id="5fdeab94b6173627f1adbe0eec9af4e8" category="cell"><block ref="965936916f52d154e29c463b863a4b0f" category="inline-link-rx"></block></block>
  <block id="11921667a8e553e99f126adb8164c4f2" category="doc">NetApp和VMware公司</block>
  <block id="d2bd2bc831f134d9e71008f0f27d5451" category="paragraph">VMware解决方案是一款智能多云管理工具、它由一套产品组成、支持您一致地部署和运行应用程序、基础架构和平台服务。</block>
  <block id="4aa9fd8b5cfcab40d4f8ebf986f7e6ec" category="paragraph">借助VMware A一切、管理员可以利用一个平台和通用数据模型、跨私有云、混合云和多个云控制其环境。通过VMware AIA Automation、不仅可以在配置期间执行自动化、还可以管理虚拟机应用程序或基于Kubnetes的应用程序的整个生命周期。</block>
  <block id="900b9aa6069da4f174d24d324408ca7a" category="inline-image-macro">VMware NetApp ONTAP中的"VMware AWARA集成"选项</block>
  <block id="e39d177c464cbd8bcb7d697186274acf" category="paragraph"><block ref="e39d177c464cbd8bcb7d697186274acf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58395622ec800f70eb2e79c24b600099" category="paragraph">VMware AARIA提供了各种集成选项、包括使用REST API、Python、PowerShell、Node.js、Ansv可 手帕、厨师、盐、Terraform等 对于vSphere数据存储库配置工作流、请考虑使用ONTAP工具恢复API、因为这样可以减少要执行的任务数量。</block>
  <block id="017c4b789daf5f1a9f22907df4b58e67" category="inline-link-macro">ONTAP -++ https://&amp;lt;management IP&amp;gt；/docs/API/++</block>
  <block id="a4e7e413f1c60d93d22b1f6fa9aa3773" category="inline-link-macro">Active IQ Unified Manager -++ https://&amp;lt;management IP&amp;gt；/docs/API/++</block>
  <block id="5b1c4deda9bb714b8dcf584828a623e3" category="inline-link-macro">适用于VMware vSphere的SnapCenter插件-+++ https://&amp;lt;SCV_IP&amp;gt;:8144/api/swagger-ui/index.html++</block>
  <block id="bb115b81fb20501b5fbeac8367ad5d8b" category="paragraph">我们的大多数产品(如ONTAP、ONTAP工具、适用于VMware vSphere的SnapCenter插件、Astra Control等)都提供了可使用Swagger UI进行探索的ESTful API。
要使用Swagger UI、请参见以下URL。
<block ref="c6342dad1eba7fb754bd186701b8205b" category="inline-link-macro-rx"></block>
<block ref="1b759d8ae1e892a0d9eb35250bc76c97" category="inline-link-macro-rx"></block>
ONTAP工具-单击ONTAP工具vCenter插件概述页面上资源部分下的链接。在9.12版本中、其格式为+++API https://&lt;ONTAP工具IP&gt;：8143/API/REST /swagger-ui.html++
<block ref="c95c264132270fd593c7dce42bd4eeb4" category="inline-link-macro-rx"></block>
Astra Control -单击用户图标并单击API访问时、请访问API文档下的链接。其格式为++ https://&lt;Astra控制IP&gt;/openapi/Openapi/+++&lt;accountID&gt;</block>
  <block id="f1ee1fcc452029700f41124411e01f21" category="inline-link-macro">使用ONTAP工具API管理vSphere数据存储库的《Andsvner操作手册》示例</block>
  <block id="c5028311f8861a12167c1a783a5c067a" category="inline-link-macro">NetApp模块、用于Ansex可能</block>
  <block id="1c80fcc27a1fdc4a3e6193e8c5999857" category="inline-link-macro">ONTAP Python客户端库</block>
  <block id="95af34eb22e1127f35566f50f8f44da3" category="inline-link-macro">适用于ONTAP的PowerShell工具包</block>
  <block id="cfdec364233bc50bcbd67820cf4d5943" category="inline-link-macro">BlueXP API文档</block>
  <block id="2f39ce9fbee3aa6b24222d6fd752aa35" category="inline-link-macro">Astra Control Python SDK</block>
  <block id="7a024c570bf402406b7a81ac82d36556" category="inline-link-macro">适用于BlueXP的Terraform提供程序</block>
  <block id="724f9ca1c5a7df6ce07f68f9c43958cd" category="inline-link-macro">使用Asta Control执行应用程序一致的数据保护的脚本</block>
  <block id="90a3396e8967bc372a59a701f133c2c1" category="inline-link-macro">灾难恢复流程编排程序—AWS</block>
  <block id="81bc896ca904bd682e11ffe1d5abf3d8" category="inline-link-macro">灾难恢复流程编排程序—Azure</block>
  <block id="6049d00b73dc4321e44f8849d8742ed7" category="inline-link-macro">使用SnapCenter部署适用于VMware vSphere的VMware插件</block>
  <block id="03c47bd2899cb12e9401f463f8d3eee0" category="paragraph">VMware ARA通过实时了解管理员的基础架构来协助管理员执行与操作相关的任务。适用于NetApp FAS/AFA的VMware AFA管理包是一款适用于VMware AFA操作的嵌入式适配器。这种集成可提供有关基础架构的分析和最新信息、帮助您在出现问题时或可能出现的问题更快地发现。</block>
  <block id="c41833aa6cc278fcc92faa8cca4c82e6" category="inline-link-macro">VMware A活动 产品页面</block>
  <block id="a99a8e803ccceb46d9ab18ad17c534d1" category="list-text"><block ref="a99a8e803ccceb46d9ab18ad17c534d1" category="inline-link-macro-rx"></block></block>
  <block id="5ea3b62955668d964af44549218c221e" category="inline-link-macro">适用于NetApp FAS/AFA的VMware阿里亚操作管理包</block>
  <block id="3281130d10437ac62de94a9f23fad088" category="list-text"><block ref="3281130d10437ac62de94a9f23fad088" category="inline-link-macro-rx"></block></block>
  <block id="987b809ffed744a5a9aaffc2168557f1" category="doc">VMware和NetApp：强大的解决方案联盟</block>
  <block id="c65fb61fcf6d072f282b698adc5a8597" category="paragraph">*什么是VMware vSphere？*</block>
  <block id="9a385fe8067e94af0702cc7c5e1a8c46" category="paragraph">vSphere是VMware的服务器虚拟化产品套件的产品名称、其中包括其ESXi虚拟机管理程序和vCenter管理软件。</block>
  <block id="3e165421c074de61fceee0544b81cea0" category="inline-link-macro">为什么应使用NetApp ONTAP工具升级到vSphere 8</block>
  <block id="b6e0493d1fe527b8ae5df8ea1f781139" category="list-text"><block ref="b6e0493d1fe527b8ae5df8ea1f781139" category="inline-link-macro-rx"></block></block>
  <block id="913ca2329c9c76b0abb3af5c2ea57a6e" category="inline-link-macro">获取有关适用于vSphere的ONTAP工具的所有文档</block>
  <block id="d816b1f2f3cf0f45f6410fe7b4c3103e" category="list-text"><block ref="d816b1f2f3cf0f45f6410fe7b4c3103e" category="inline-link-macro-rx"></block></block>
  <block id="824518759339e061fdfe747d112e9ed3" category="inline-link-macro">了解适用于VMware vSphere的NetApp解决方案</block>
  <block id="01f0b435ead6e5e2161cce622ec02426" category="list-text"><block ref="01f0b435ead6e5e2161cce622ec02426" category="inline-link-macro-rx"></block></block>
  <block id="9ae531beb6351da1594f13fb421f4fb0" category="list-text"><block ref="9ae531beb6351da1594f13fb421f4fb0" category="inline-link-macro-rx"></block></block>
  <block id="f71b2bc8d485cd1654d1f2f088bb5b11" category="inline-link-macro">ONTAP中的VMware虚拟化新增功能</block>
  <block id="69e512591f38146e63eaf662fc9bc26c" category="list-text"><block ref="69e512591f38146e63eaf662fc9bc26c" category="inline-link-macro-rx"></block></block>
  <block id="245e35b4dfc0748419f8bf86b78a0530" category="inline-link-macro">详细了解适用于vSphere的SnapCenter插件</block>
  <block id="9b6675a13168837a82b6357f302efa2f" category="list-text"><block ref="9b6675a13168837a82b6357f302efa2f" category="inline-link-macro-rx"></block></block>
  <block id="75a9eb29af2260642c6cf16f51673be4" category="inline-link-macro">详细了解NetApp提供程序</block>
  <block id="8513704740781e05cfc60b42a46680bb" category="list-text"><block ref="8513704740781e05cfc60b42a46680bb" category="inline-link-macro-rx"></block></block>
  <block id="661bf42de421898212999f7564512ee8" category="paragraph">*VMware为什么关心外部存储？*</block>
  <block id="de8b4bb2d0a11137bd39a90dbb591adb" category="paragraph">客户通常具有各种工作负载需求、包括与其应用程序、用户和保护策略所需的存储相关的工作负载需求。对于VMware环境、这些需求通常以数据存储库或子系统连接存储的形式来满足。数据存储库可通过VMware vCenter配置使用、而子系统连接的存储则按虚拟机或容器使用。通常、这两种访问方法都是通过NetApp ONTAP等共享存储来实现的。</block>
  <block id="218df3a02662187bf3739a26faa70934" category="paragraph">VMware将存储分为两类：传统存储和软件定义的存储模型。传统存储型号包括SAN、NAS和原始设备映射(RDM)等配置、而软件定义的存储型号包括VMware虚拟卷(Vvol)和vSAN。从我们的产品集成、企业级功能以及解决方案的深度和广度来看、NetApp是传统存储产品和虚拟卷的理想平台。</block>
  <block id="c73469cc6c965fae121b78f04c3c0a6e" category="paragraph">*VMware数据存储库的工作原理？*</block>
  <block id="1acd89f48c28d43f7ad29d5b80061d83" category="paragraph">数据存储库是一种逻辑容器、类似于文件系统、用于隐藏物理存储的具体信息、并为存储虚拟机文件提供统一的模型。数据存储库还可用于存储ISO映像、虚拟机模板和软盘映像。</block>
  <block id="850bd5df3e4a92baf09f1c0c1c9b56b3" category="inline-link-macro">NetApp ONTAP支持所有存储协议</block>
  <block id="40dee99a733670e07affc4dd1711c90d" category="list-text"><block ref="40dee99a733670e07affc4dd1711c90d" category="inline-link-macro-rx"></block></block>
  <block id="ba23c62c40242de1d1c4f2327568e4be" category="paragraph">*什么是FlexPod？*</block>
  <block id="069c0ccdcedb874bc14066443f41c898" category="paragraph">FlexPod是由NetApp合作提供的融合基础架构解决方案。  它包含一个由计算、网络和存储组成的"一体化"虚拟数据中心。  FlexPod提供了许多基于VMware产品的解决方案。</block>
  <block id="5a17b454cb5d033065fbff2184aa0813" category="inline-link-macro">FlexPod解决方案文档库</block>
  <block id="d44e64f34a82fbf11ceb7019163cb52f" category="list-text"><block ref="d44e64f34a82fbf11ceb7019163cb52f" category="inline-link-macro-rx"></block></block>
  <block id="e4bb31096f5b1d5682646c1dadb6342f" category="paragraph">*基于TCP的NVMe为何对虚拟机很重要？*</block>
  <block id="19c554813be7ef8add27c1a8544757d8" category="paragraph">对于基于TCP的NVMe上运行的虚拟机、您可以通过将NVMe与NetApp上的虚拟卷结合使用来降低CPU利用率并提高性能和可靠性、从而实现可扩展性、精简性和自动化。</block>
  <block id="7f0f40a3d0596cc6fd436f949c52c9d1" category="inline-link-macro">了解NVMe的优势</block>
  <block id="7bdddc1c22c46904da0b446bdf877a1b" category="list-text"><block ref="7bdddc1c22c46904da0b446bdf877a1b" category="inline-link-macro-rx"></block></block>
  <block id="b575f84c1cb4667215863a05b9c35145" category="section-title">VMware HCX[[HCX]]</block>
  <block id="d4655007cab24a3280d10807a2151a4f" category="paragraph">*什么是VMware HCX？*</block>
  <block id="f2d52d0d3186086b0ced70a630f8363f" category="paragraph">VMware HCX是一款应用程序移动平台、旨在简化应用程序迁移、重新平衡工作负载并优化数据中心和云之间的灾难恢复。</block>
  <block id="4e65e810d16eced8f1a4cf90f9707f02" category="paragraph">HCX可在两个或多个不同环境之间提供服务。这些环境可能正在运行旧版vSphere、也可能正在运行现代vSphere SDDC、它们也可能是基于VMware的公共云实例。</block>
  <block id="831c6f2587ddff1e42e01fc9a68d21da" category="image-alt">VMware HCX</block>
  <block id="41d88513bd79d5fafd0cc25f4b9eea34" category="inline-link-macro">使用VMware HCX将工作负载迁移到FSx ONTAP数据存储库</block>
  <block id="a4dd461a0c26e5664a65e8666a80d34e" category="inline-link-macro">使用VMware HCX将工作负载迁移到Azure NetApp Files数据存储库</block>
  <block id="bf242a38be317795f2e79bb7408b64ca" category="inline-link-macro">使用VMware HCX将工作负载迁移到Google Cloud VMware Engine上的NetApp云卷服务数据存储库</block>
  <block id="6344973ed3a20f31369049e5b080d187" category="section-title">VMware Tanzu[[Tanzu]]</block>
  <block id="c914703a5ef258b77fd66aea30bfdb98" category="paragraph">*VMware Tanzu是什么？*</block>
  <block id="a28c53f8d15e14e26b8a723fac4b0caa" category="paragraph">采用Tanzu的vSphere是适用于容器化应用程序的新一代vSphere。这款简化的解决方案为内部和公有云中的现代云原生应用程序提供了一种新型基础架构、弥补了IT运营与开发人员之间的差距。</block>
  <block id="7977714030fcf995bd035108ded8b2af" category="inline-link-macro">使用VMware Tanzu管理Kubnetes</block>
  <block id="f48e440fc1ffb013e61447d5a8399be3" category="list-text"><block ref="f48e440fc1ffb013e61447d5a8399be3" category="inline-link-macro-rx"></block></block>
  <block id="4bcd13ea7701f6399a68e4d681be6f5b" category="inline-link-macro">适用于VMware Tanzu的NetApp解决方案</block>
  <block id="c8250582c4015ddd8f5abd9b0448bf4b" category="section-title">VMware Aria[[ARIA]]</block>
  <block id="e8ebe493045b438d2000a4f4b52190a8" category="paragraph">*什么是VMware AWARA？*</block>
  <block id="796056588d15b2029ae858c6f9a2729b" category="paragraph">VMware解决方案是一款智能多云管理工具、它由一套产品组成、支持您一致地部署和运行应用程序、基础架构和平台服务。借助ARIA，您可以通过一个平台和一个通用数据模型控制私有云、混合云和多个云的环境。</block>
  <block id="80e2a0c1c7e48391ee13f71ce2f0a130" category="paragraph">通过使用预先定义的和管理员配置的工作流库、可以使用AIA Automation Orchestrator Client的编辑器创建从简单到复杂的服务项目。通过将此库中的预定义存储任务与NetApp基于REST的API相结合、可以创建各种服务项目。只有将这些服务产品发布到自助服务目录(在AIA Automation中)中、才能实现任何业务或IT目标。</block>
  <block id="324e6f4b8629f1668d96502106163d78" category="paragraph">除了可以完成的与操作相关的任务之外、ARiA还可以帮助管理员实时了解其基础架构。适用于NetApp FAS/AFA的VMware AFA管理包是一款适用于VMware AFA操作的嵌入式适配器。这种集成可提供有关基础架构的分析和最新信息、帮助您在出现问题时或可能出现的问题更快地发现。</block>
  <block id="67b9131407393c22d3682d67e208442b" category="inline-link-macro">VMware A活动 文档</block>
  <block id="a9bbdb37fd10b390d6784de51ed1c1a0" category="list-text"><block ref="a9bbdb37fd10b390d6784de51ed1c1a0" category="inline-link-macro-rx"></block></block>
  <block id="45fc8ade5c6222e01bc08500a668a606" category="section-title">VMware虚拟卷(vvol)</block>
  <block id="1915b0118cba1138d870a7564ae2740a" category="paragraph">*什么是VMware虚拟卷(vvol)？*</block>
  <block id="111ad7cb702adc519d7efc982e4a9752" category="paragraph">VMware vvol是虚拟机的低级别存储、支持在存储阵列级别执行操作、与用于创建数据存储库的传统LUN类似。存储阵列不使用传统VMFS文件系统、而是定义了如何为使用该存储阵列的VM提供访问和组织数据。</block>
  <block id="b16a824a4e98acfb13cf7ce37bfe4541" category="inline-link-macro">了解VMware vvol可以在NetApp上执行哪些操作</block>
  <block id="beeeaa9fbcc330ad5b9c8d52aabd87c3" category="list-text"><block ref="beeeaa9fbcc330ad5b9c8d52aabd87c3" category="inline-link-macro-rx"></block></block>
  <block id="f1f8bf93f42b2cc0871b74ac3ba3abd5" category="inline-link-macro">《vols技术文档》</block>
  <block id="3bba2e9d4e572781b2cd769810380419" category="list-text"><block ref="3bba2e9d4e572781b2cd769810380419" category="inline-link-macro-rx"></block></block>
  <block id="9b3d117218c0fcea20a599c93fa177af" category="section-title">VMware Cloud Foundation (VCF)</block>
  <block id="d70c8dd7d20612e4b382beef7edc9460" category="paragraph">*VMware Cloud Foundation是什么？*</block>
  <block id="aa073a3412a3915cf42512cf33a0e899" category="paragraph">VMware Cloud Foundation (VCF)是一款适用于传统企业级应用程序和现代应用程序的混合云平台。基于VMware软件定义的堆栈构建、用于计算、存储、网络、容器和云管理； VCF中的资源可通过创建域来使用。根据最佳实践、域将计算、网络和存储分组到一个逻辑单元中。域有两种类型：初始管理域和虚拟基础架构工作负载域。</block>
  <block id="5d1d1a168bd37e80c6068d99ce4a5d3a" category="paragraph">创建初始管理域后、系统会根据需要部署后续工作负载域、以满足业务需求。工作负载域通过主体存储或补充存储分配性能和容量。通过部署这些应用程序就绪工作负载域、vcf可以为异构环境提供简化的标准体验。</block>
  <block id="d389fa8c25af5d4698485fea705ae117" category="inline-link-macro">了解NetApp基础架构如何与VCF配合使用</block>
  <block id="bee7d7f2908cfcc45512b975a852b4f8" category="list-text"><block ref="bee7d7f2908cfcc45512b975a852b4f8" category="inline-link-macro-rx"></block></block>
  <block id="d61a46d9d09dc7aca1e0179d63204d66" category="inline-link-macro">VMware VCF产品页面</block>
  <block id="eb4b53248a1281b9d28a6d7c223b7ffe" category="list-text"><block ref="eb4b53248a1281b9d28a6d7c223b7ffe" category="inline-link-macro-rx"></block></block>
  <block id="f11c4cc510a050644bd15b5b2c8fe90b" category="section-title">VMware Site Recovery Manager (SRM)</block>
  <block id="455738ab0f37197686d7bc5a6409d9f2" category="paragraph">*什么是VMware Site Recovery Manager？*</block>
  <block id="f841c5588227d38219776ab55121279f" category="paragraph">Site Recovery Manager (SRM)是行业领先的灾难恢复(Disaster Recovery、DR)管理解决方案、可在发生灾难时最大限度地减少停机时间。它可以对集中式恢复计划进行基于策略的管理、自动化流程编排和无中断测试。</block>
  <block id="2f1070623d6c4225f91940b9c5628aa3" category="list-text"><block ref="2f1070623d6c4225f91940b9c5628aa3" category="inline-link-macro-rx"></block></block>
  <block id="d8bd3d1943b5ca6825e0636a21346263" category="section-title">VMware云服务</block>
  <block id="0b67da410f8907404dc7f84043c8c42f" category="paragraph">*什么是采用VMware和NetApp的混合多云？*</block>
  <block id="cb158180bc71991c80a76757c10ecb32" category="paragraph">任何其他基础架构提供商都无法在VMware上支持内部和云(任何云)上的工作负载。  NetApp是首家在AWS、Microsoft Azure和Google Cloud上的云中支持VMware的基础架构提供商。</block>
  <block id="602f161cb8e7ab6fa7fb52e98b8a3e7c" category="paragraph">每个主要公有云提供商都提供虚拟化服务、可以在这些服务上运行内部环境中的应用程序和工作负载。</block>
  <block id="8b8c78caebdc8708680389c83acf9430" category="paragraph">NetApp为这些云虚拟化环境提供了一整套解决方案。</block>
  <block id="60ff937528a23732177161eaf3434af2" category="inline-link-macro">适用于云中虚拟化环境的NetApp解决方案</block>
  <block id="97030fb400eae9dbb8b11b89cbe03a4b" category="list-text"><block ref="97030fb400eae9dbb8b11b89cbe03a4b" category="inline-link-macro-rx"></block></block>
  <block id="b9bce0f609b45191df2a7c3ca3758b25" category="inline-link-macro">适用于AWS VMware Cloud的NetApp解决方案(VMC)</block>
  <block id="76a0efb7cfbf100a491d589299f3f658" category="list-text">运行ONTAP 9.8或更高版本的ONTAP存储系统(FAS/AF/CVO/ONTAP Select)</block>
  <block id="2b0b10373d934d015981729f451f23dc" category="list-text">vSphere 7.0或更高版本</block>
  <block id="60f1f6754d8e875c371c57253604cf16" category="paragraph">适用于VMware vSphere的SnapCenter插件可为虚拟机(VM)、数据存储库和VMDK提供快速、高效且VM一致的备份和还原操作。它可与SnapCenter服务器配合使用、为SnapCenter应用程序专用插件提供基于应用程序的备份和还原功能。</block>
  <block id="f4000e38a628184a5aa67967e064297a" category="paragraph">有关详细信息、请参见以下文档资源。</block>
  <block id="3cb6a10608021a82c77ee48cd9ab3c20" category="list-text"><block ref="3cb6a10608021a82c77ee48cd9ab3c20" category="inline-link-macro-rx"></block></block>
  <block id="e2819cc04e28f0a53071fee9c86cd983" category="section-title">解决方案资源</block>
  <block id="7fdb31dd502f941c54bc917d6117bb8a" category="paragraph">请参阅以下3-2-1备份解决方案、其中包含适用于VMware vSphere的SnapCenter插件以及适用于VM的BlueXP备份和恢复。</block>
  <block id="dcfc677605507fc9572b1d5d4e0d520d" category="paragraph">Tech OnTap博客： <block ref="8afc1f6ae777d868b091aa07614f8b82" category="inline-link-macro-rx"></block></block>
  <block id="b3a29c492f034218941b625fe457b681" category="section-title">视频资源</block>
  <block id="fcb2fa0001e17808e696c2b1d8dfab9d" category="list-text">运行ONTAP 9.8或更高版本的ONTAP存储系统(FAS/AF/CVO/ONTAP Select/ASA)</block>
  <block id="7f89dfa5884dd8ee0f16154367c4ee61" category="list-text">vSphere主机信息(vSphere 7.0或更高版本)</block>
  <block id="17743938d67ebbd6ee8bffd35a4f2003" category="doc">适用于混合云和云的NetApp数据保护解决方案</block>
  <block id="520be8f619875101ee6bbc1f7fcfafd3" category="paragraph">详细了解NetApp为AWS、Azure和GCP提供的数据保护解决方案。</block>
  <block id="2ac5a53d2842dab9588665a2a82e5ec1" category="paragraph">VMware将数据保护解决方案定义为以下三种类别之一：</block>
  <block id="65c97d8a641faab8b7867c818d492f16" category="doc">NetApp 和 amp ； VMware ：携手合作更好</block>
  <block id="0889cdd5fa88df4ddfb1341422ebda4c" category="paragraph">NetApp和VMware是唯一一家*合作伙伴关系、一个存储系统即可满足VMware定义的所有关键用例。</block>
  <block id="010cdbfd980baaeb382dbebad013238b" category="paragraph">NetApp可以最大限度地发挥VMware软件、人员和流程的价值。</block>
  <block id="4c7e1827f1658793ceea0fc3321e2884" category="list-text">[blue]#Customer Experience #- 20多年的投资、为全球所有主要行业的20、000多家客户提供服务</block>
  <block id="7c2704d0f59ba3ca64e15c37c593ebb0" category="list-text">[Blue]#Executive Vision#-所有应用程序、任何位置、一种集成的统一管理方法</block>
  <block id="7d7abe8ce33ac866423aea195b0e3774" category="list-text">[Blue]#传统和现代应用程序#—将虚拟和容器化工作负载和文件服务作为一个整体进行管理</block>
  <block id="25cdaaf7750f0ec4e20e9f829ca7e801" category="list-text">[Blue]#VMware混合云和多云#—将传统和现代应用程序迁移、扩展或保护到所选云</block>
  <block id="82542e3bcf8c718fda28e5c36597286e" category="list-text">[Blue]#适应未来需求的基础架构#—通过不断的业务变化实现一致的工作负载和数据管理操作</block>
  <block id="9a154b3bd4cd3cac2e99d3d572a5a2bf" category="paragraph">NetApp和VMware共同提供的解决方案和产品具有以下特点：</block>
  <block id="e290f3213132241b4afe75cd521e9eab" category="list-text">[blue]#Simple #—将工作负载数据管理、保护和移动性卸载到与vSphere集成的存储</block>
  <block id="ccd373a6601417d75a4512bfa60ecc4e" category="list-text">[blue]#Fast#—优化闪存/NVMe/GPU性能传统虚拟机和现代Kubernetes或AI</block>
  <block id="0ff117d7faf0212ec4f31533739db240" category="list-text">[blue]#킧 싊#—将存储减少5-30倍、数据中心效率提高85-90%、从而压缩、重复数据删除和数据缩减</block>
  <block id="a57843c559ab2d06f3fe8a73bbe1db36" category="list-text">[blue]#protore#—卸载虚拟工作负载备份、还原并提供零RPO和更低的RTO数据复制</block>
  <block id="adbde729b4dd243d4e0db60359f638fd" category="list-text">[blue]#secure#—将VMware级别的安全性和合规性扩展到数据、以保护、检测、修复、恢复</block>
  <block id="dd7134c7ffa2adad4179530f3170f222" category="section-title">NetApp和VMware：全球联合首席执行官公告</block>
  <block id="185aef56468a6136bddb65e38d8e236b" category="paragraph">NetApp和VMware宣布扩大两家公司长期的全球联盟。通过创新解决方案和市场推广计划、NetApp和VMware正在帮助客户降低在多云环境中迁移和打造现代化企业级工作负载的成本、复杂性和风险。此外、企业还可以通过VMware和NetApp数据管理基础架构之间的新集成、加快传统应用程序和新的现代应用程序的性能和交付速度、并简化日常运营。</block>
  <block id="4ea3bb267bf7fb048970332f93ec77fd" category="image-alt">vmware1</block>
  <block id="7ad63f53015f81f3953f0c531754dcdc" category="paragraph">请参见全球公告 <block ref="b230a865c0910d5f0b0550f715b3cc17" category="inline-link-macro-rx"></block>。</block>
  <block id="dd8564e24e3897acf59ac78bdbd14215" category="section-title">NetApp和VMware：统一工作负载和数据管理</block>
  <block id="dda550094ffd3d0eaf4f15ccdade6015" category="paragraph">无论组织中的角色如何、NetApp和VMware联盟都可以满足特定角色的要求和关注事项。</block>
  <block id="2f1b4a9015b04e9cac38d2d0489361d3" category="list-text">[blue]#*CIO和IT领导层*#</block>
  <block id="53a8eaa92030755465ea3b4d334b7b62" category="list-text">优化现有IT投资的价值并控制成本</block>
  <block id="9a0f4b3960b437708f9e83962661736f" category="list-text">创建新的IT容量以推动增长和创造价值</block>
  <block id="237e7fa1e054ebd435eb624daadd5e92" category="list-text">通过VMware变更降低风险并控制数据</block>
  <block id="f249e6fc3ff0c414eb6a86af8c81fbb0" category="list-text">[Blue]#*IT Operations*#</block>
  <block id="6deb0af8f35fd0180af7f91002df4652" category="list-text">最大限度地提高大规模虚拟化工作负载性能</block>
  <block id="615b9a6a2446bf519124ad1f72d1ee47" category="list-text">简化并加快日常生命周期管理任务</block>
  <block id="b6c33211ddf4eceba18e84484e9fb8cc" category="list-text">确保数据安全且合规</block>
  <block id="4d4747b1994ae9ab0546111a8a51cb53" category="list-text">[Blue]#*云运营*#</block>
  <block id="20c6a37659c54749c26d45438ec15c9e" category="list-text">将所有工作负载无缝迁移、扩展或保护到领先的混合云/多云环境</block>
  <block id="bffb8661cad75a0a6131dee346af0650" category="list-text">通过规模合适的存储、以独特方式优化VMware Cloud ~25-50%的成本</block>
  <block id="09856af4b8a406bd8b432136ecb042a0" category="list-text">[blue]#*Developers*#</block>
  <block id="230d9de3ee9f4fe411c6c5e8fb72cf4d" category="list-text">使用永久性全闪存加快新的现代应用程序开发速度</block>
  <block id="29f739800ce63c223b8e189aec9be8b9" category="list-text">增强Kubnetes生命周期管理和可用性</block>
  <block id="a894f5444a8083dc06c3f685038affda" category="image-alt">vmware2</block>
  <block id="a93a1378be3974deea7ba4ea9e0092eb" category="list-text">运行ONTAP 9.8或更高版本的ONTAP存储系统(FAS/AF/CVO/ONTAP Select/ASA)</block>
  <block id="7be8cc4a16cfefd512adb599b273f5ba" category="sidebar">最佳实践和支持</block>
  <block id="e035b5af3fcc9b53d988c789f67e1d3d" category="sidebar">《VMware硬件兼容性指南》</block>
  <block id="f7e5c0a7202a89f323de3ecd9e953ff6" category="sidebar">vSphere 8和vSphere +</block>
  <block id="32db160f35591246a9d3ab9d29b73796" category="sidebar">基于AWS VMware Cloud的NetApp (VMC)</block>
  <block id="b7a719b5a20e8f1be7c50ef06e7035bf" category="sidebar">基于Azure VMware解决方案的NetApp (AVS)</block>
  <block id="263b280f672cf705a2531480c957d232" category="sidebar">基于Google Cloud VMware Engine (GCVe)的NetApp</block>
  <block id="b7d85d232229c4b7273f08dadabc1b90" category="sidebar">VMware软件定义的数据中心</block>
  <block id="0dcbedc379da795bbf48a4ea455f0776" category="sidebar">NetApp存储与VMware Cloud Foundation</block>
  <block id="4782e61635c721d2ac646cbaa6066487" category="sidebar">适用于 ONTAP 工具的 VMware 云基础部署模式</block>
  <block id="ad7a5457787611f16a21824847117068" category="sidebar">《FlexPod云基础设计指南》</block>
  <block id="d5a8c6cf0c4e703a76c04d7a26a71978" category="sidebar">容器和Kub联网</block>
  <block id="ef428bbe75f358c7ad6b5e1df67df9e6" category="sidebar">VMware vSphere上的Kubnetes</block>
  <block id="d8ee09e7304a78e9ed280f17fb6f1043" category="sidebar">适用于 VMware vSphere 的 NetApp SnapCenter 插件</block>
  <block id="0bee26c07976b52253b5859b5fc68382" category="sidebar">适用于混合云的NetApp数据保护解决方案</block>
  <block id="ebac598e81b856acb55b59161a41bd31" category="sidebar">自动化、配置和监控</block>
  <block id="3045bc38d771736e3bb60b0394d4741c" category="sidebar">VMware AWARA</block>
  <block id="10cf385564bb2cd854b00a78ea25a1c5" category="sidebar">NetApp AIQ</block>
  <block id="8280f5b2d1831bf3e03685c3088e8723" category="sidebar">HGC设置</block>
  <block id="0b4637c872919e9ac6e7b6fbb0d36ba2" category="sidebar">MLRun设置</block>
  <block id="6ce7d8f4f3e1c7d9bd9b39dbef990193" category="sidebar">设置操作步骤</block>
  <block id="ccf66760432e212bf920c4b630bf24a8" category="section-title">NetApp BlueXP复制和同步</block>
  <block id="182c915d2a513090f731fbf85d4576bd" category="paragraph">NetApp BlueXP复制和同步是一种混合数据复制软件即服务、可在内部存储和云存储之间安全无缝地传输和同步NFS、S3和CIFS数据。此软件用于数据迁移，归档，协作，分析等。传输数据后、BlueXP复制和同步功能会持续同步源和目标之间的数据。接下来，它会传输增量数据。它还可以保护您自己网络，云或内部环境中的数据。此软件采用按需购买模式，可提供经济高效的解决方案并为数据传输提供监控和报告功能。</block>
  <block id="1ae50adfec05c416d0398e26bea5fc01" category="inline-link">BlueXP复制和同步</block>
  <block id="bc35f58684dbedfb73dd7ff64a4bd5a8" category="paragraph">为了获得最佳性能、NetApp通常建议使用多个网络接口以及直接连接或快速路由从云实例访问数据。我们还有其他数据移动解决方案、包括<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> 和<block ref="079cab06c3947ff50532e4e825fc7b2c" category="inline-link-rx"></block> 帮助客户构建应用程序感知型、安全且经济高效的混合云Spark集群。</block>
  <block id="74c03e6f525ff7a5f56d15dd77d9d7ee" category="paragraph">混合用例客户可以使用BlueXP Copy and Sync将内部数据从NFS、CIFS和S3数据迁移到云、反之亦然、以便通过NVIDIA集群中的GPU进行AI处理。BlueXP副本和同步以及XCP迁移工具均用于将NFS数据迁移到NetApp ONTAP NFS。</block>
  <block id="f11ac801004d872ca260befe72ccef06" category="image-alt">此图详细展示了BlueXP控制台中应用程序的BlueXP备份和恢复、包括其管理的UI、连接器和资源。</block>
  <block id="cbe02f66cac21399f800de4cd1e8fe3b" category="paragraph">此图详细展示了BlueXP控制台中应用程序的BlueXP备份和恢复、包括用户界面、连接器及其管理的资源。</block>
  <block id="96410c05710545cd17f642c52cfd8867" category="video-title">Oracle和ANF部署视频</block>
  <block id="0f0ed589c348106f3d56ba98e1ddab80" category="section-title">BlueXP备份和恢复工具及配置</block>
  <block id="a7d116b4f79b851af3f003fb89bb665f" category="section-title">BlueXP备份和恢复工具</block>
  <block id="c7c2ab504bc51e5c58244a8e520ba0af" category="list-text">使用 NetApp SnapMirror ® 技术将工作负载数据从内部 ONTAP 系统复制到 Cloud Volumes ONTAP 或 Amazon FSx for NetApp ONTAP ，以便使用块级机制轻松迁移。这不适用于 Azure NetApp Files 和 Cloud Volumes 服务。要将数据迁移到Azure NetApp Files或Cloud Volumes Services、请根据使用的文件协议使用NetApp XCP、BlueXP复制和同步、rysnc或Robocopy。</block>
  <block id="1b9258f782f1f43eb6c8141e179d6551" category="list-text">为Cloud Volumes ONTAP部署选择附加服务、包括BlueXP分类、BlueXP备份和恢复以及Cloud Insights。选择服务，然后单击继续。</block>
  <block id="f77f38d4087d3b85caf7e7a5d2ce7a0f" category="example-title">适用于虚拟机的BlueXP备份和恢复</block>
  <block id="abf639280c85d22acee1ee5d067cd10e" category="paragraph">适用于虚拟机的BlueXP备份和恢复在vCenter上提供了vSphere Web客户端图形用户界面、用于通过备份策略保护Azure VMware解决方案虚拟机和Azure NetApp Files数据存储库。这些策略可以定义计划、保留和其他功能。  可以使用运行命令部署适用于虚拟机的BlueXP备份和恢复功能。</block>
  <block id="eedeb9e01d71fc097a45d66a7bd05a5b" category="list-text">使用运行命令在Azure VMware解决方案私有云中为虚拟机安装BlueXP备份和恢复。</block>
  <block id="5013a6fd1f99c69173a553aeb12b1bbc" category="paragraph">本白皮书为使用NVIDIA Jarvis框架以及NetApp ONTAP AI和BlueXP复制和同步功能为零售和其他用例构建对话式人工智能(AI)解决方案的客户提供了一些指导原则。其中包括有关在为虚拟助手开发自然语言处理（ NLP ）模型时使用的高级工作流的信息，经过验证的测试用例和结果。</block>
  <block id="c869f18bf7374f26127ff1fcac433340" category="doc">使用Jarvis、BlueXP Copy and Sync和Nemo构建虚拟助手</block>
  <block id="f96192051337044e8471c7c7fbc5864c" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block> 是一项 NetApp 服务，用于快速安全地同步数据。无论您是需要在内部NFS还是SMB文件共享、NetApp StorageGRID、NetApp ONTAP S3、NetApp Cloud Volumes Service、Azure NetApp Files、Amazon Simple Storage Service (Amazon S3)、Amazon Elelic File System (Amazon EFS)、Azure Blb、Google Cloud Storage、 或者IBM Cloud Object Storage、BlueXP Copy and Sync可将文件快速安全地移动到您需要的位置。数据传输完成后，即可在源和目标上完全使用。BlueXP Copy和Syncc会根据您预定义的计划持续同步数据、仅移动增量、从而最大限度地减少数据复制所需的时间和资金。BlueXP Copy and Sync是一款软件即服务(SaaS)工具、设置和使用极其简单。由BlueXP复制和同步触发的数据传输由数据代理执行。您可以在AWS、Azure、Google Cloud Platform或内部部署BlueXP Copy and Sync数据代理。</block>
  <block id="b8bc3287c1345ab1a36c796d2de0aaa2" category="section-title">NetApp BlueXP分类</block>
  <block id="196f1872673d3381d912260929325605" category="paragraph">由强大的AI算法驱动、 <block ref="860dd213c65646bc2292a7454f4cfbac" category="inline-link-rx"></block> 在您的整个数据资产中提供自动化控制和数据监管。您可以轻松确定成本节省、发现合规性和隐私问题、并找到优化机会。BlueXP分类信息板可让您深入了解如何识别重复数据以消除冗余、映射个人数据、非个人数据和敏感数据、以及针对敏感数据和异常情况启用警报。</block>
  <block id="6b60cb834d58cfe9d8033ae023a4b412" category="paragraph">下图显示了解决方案架构。环境分为三大类：云，核心和边缘。每个类别都可能在不同的地理位置上分散。例如、云包含的对象存储在不同区域的分段中包含音频文件、而核心可能包含通过高速网络或NetApp BlueXP复制和同步链接的数据中心。边缘节点表示各个人工代理的日常工作平台，在这些平台中，交互式信息板工具和麦克风可用于直观显示情绪并从与客户的对话中收集音频数据。</block>
  <block id="d1c4e340ccc4079839c03f573adcacc1" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block> 是一项 NetApp 服务，用于快速安全地同步数据，使您可以在内部 NFS 或 SMB 文件共享之间将文件传输到以下任一目标：</block>
  <block id="12e7ca219a6a247bae3aa00ea0454969" category="paragraph">BlueXP复制和同步功能可将文件快速安全地移动到您需要的位置。数据传输完成后，即可在源和目标上完全使用。BlueXP复制和同步功能会根据预定义的计划持续同步数据、仅移动增量、从而最大限度地减少数据复制所需的时间和资金。BlueXP Copy and Sync是一款软件即服务(SaaS)工具、易于设置和使用。由BlueXP复制和同步触发的数据传输由数据代理执行。您可以在AWS、Azure、Google Cloud Platform或内部部署BlueXP Copy and Sync数据代理。</block>
  <block id="59c7b05142bcca22de50fe7efee7634e" category="paragraph">BlueXP复制和同步是一项NetApp服务、用于快速安全地同步数据。无论您是需要在内部NFS还是SMB文件共享、NetApp StorageGRID、NetApp ONTAP S3、NetApp Cloud Volumes Service、Azure NetApp Files、AWS S3、AWS EFS、Azure Blb、 Google Cloud Storage或IBM Cloud Object Storage、BlueXP Copy and Sync可将文件快速安全地移动到您需要的位置。</block>
  <block id="7e333cc0e24ef7489559129fd944c91f" category="paragraph">数据传输完成后，即可在源和目标上完全使用。BlueXP复制和同步功能可以在触发更新时按需同步数据、也可以根据预定义的计划持续同步数据。不管怎样、BlueXP复制和同步功能只会移动增量、因此可以最大限度地减少数据复制所需的时间和资金。</block>
  <block id="22716a1c6493f7fb09f4caf2084ad23c" category="paragraph">BlueXP Copy and Sync是一款软件即服务(SaaS)工具、设置和使用极其简单。由BlueXP复制和同步触发的数据传输由数据代理执行。BlueXP复制和同步数据代理可以部署在AWS、Azure、Google Cloud Platform或内部环境中。</block>
  <block id="87b09f7f1171ffad02c2e837c629e216" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block> 是一项 NetApp 服务，用于快速安全地同步数据。无论您是需要在内部NFS还是SMB文件共享、NetApp StorageGRID、NetApp ONTAP S3、NetApp Cloud Volumes Service、Azure NetApp Files、Amazon Simple Storage Service (Amazon S3)、Amazon Elelic File System (Amazon EFS)、Azure Blb、Google Cloud Storage、 或者IBM Cloud Object Storage、BlueXP Copy and Sync可将文件快速安全地移动到您需要的位置。数据传输完成后，即可在源和目标上完全使用。BlueXP复制和同步功能会根据预定义的计划持续同步数据、仅移动增量、从而最大限度地减少数据复制所需的时间和资金。BlueXP Copy and Sync是一款软件即服务(SaaS)工具、设置和使用极其简单。由BlueXP复制和同步触发的数据传输由数据代理执行。您可以在AWS、Azure、Google Cloud Platform或内部部署BlueXP Copy and Sync数据代理。</block>
  <block id="66d3e7e91c965dcc2bb5fec9d4ff0d5d" category="doc">使用NetApp BlueXP复制和同步以存档对话历史记录</block>
  <block id="95a3955f1845c0d9746e0f62e78cd2d8" category="paragraph">通过每天将对话历史记录转储到CSV文件一次、我们可以利用BlueXP Copy and Sync将日志文件下载到本地存储。下图显示了在内部和公有云中部署Jarvis、同时使用BlueXP Copy and Sync为Nemo培训发送对话历史记录的架构。有关 Nemo 培训的详细信息，请参见一节 <block ref="14a0a4dd1a1c18cba42b2036fe4dfc33" category="inline-link-macro-rx"></block>。</block>
  <block id="71afa64b9c4b330adacfbbf9c45e42ee" category="paragraph">借助 JARVIS ，可以部署虚拟助手，数字 avatars ，多模式传感器 Fusion （ CV 与 ASS/NLP/TTs 融合）或任何 ASS/NLP/TTS/CV 独立用例，如记录。我们构建了一个虚拟零售助理，可以对天气，关注点和库存定价方面的问题进行问题解答处理。我们还演示了如何通过使用BlueXP Copy and Sync归档对话历史记录并对Nemo模型进行新数据训练来提高对话AI系统的自然语言理解能力。</block>
  <block id="7c049abc901ad83a66ed63776568829a" category="section-title">NetApp ONTAP AI和BlueXP复制和同步</block>
  <block id="25d94f852eb8236dfc01d120a282e328" category="paragraph">借助NetApp BlueXP复制和同步功能、您可以通过各种协议轻松移动数据、无论是在两个NFS共享、两个CIFS共享之间、还是在一个文件共享与Amazon S3、Amazon Elelic File System (EFS)或Azure Blb存储之间。主动 - 主动操作意味着您可以继续同时使用源和目标，并在需要时逐步同步数据更改。BlueXP复制和同步功能支持您在任何源系统和目标系统(无论是内部系统还是基于云的系统)之间移动和增量同步数据、为您使用数据开辟了多种新方式。在内部系统，云入网和云迁移或协作和数据分析之间迁移数据变得非常容易。下图显示了可用的源和目标。</block>
  <block id="8d46625518c31befd50f169c1579bf83" category="paragraph">在对话式AI系统中、开发人员可以利用BlueXP Copy and Sync将对话历史记录从云归档到数据中心、以便对自然语言处理(NLP)模型进行离线训练。通过培训模式识别更多意向，对话式 AI 系统将更好地处理最终用户提出的更复杂的问题。</block>
  <block id="65a605b0178652b6d381379cb111e20b" category="paragraph">TR-4915介绍了如何将数据从任何数据存储库移动到由NetApp E系列SAN存储提供支持的BeeGFS文件系统。对于人工智能(AI)和机器学习(ML)应用程序、客户可能会经常需要将超过数PB数据的大型数据集移动到BeeGFS集群中以进行模型开发。本文档探讨如何使用NetApp XCP和NetApp BlueXP复制和同步工具来实现此目的。</block>
  <block id="3d9d252df1d439ee29952d36a2243ad9" category="list-text">为Cloud Volumes ONTAP部署选择附加服务、包括BlueXP分类、BlueXP备份和恢复以及Cloud Insights。单击 Continue （继续）。</block>
  <block id="e2345fd4c052d288390c6f86c2c4789f" category="list-text">能够在一个VPC中监控多个FSx for ONTAP文件系统</block>
  <block id="6c50e35e9c06dfe13c154919340f20e3" category="admonition">涵盖适用于ONTAP文件系统的单个FSx。</block>
  <block id="e1ce9d5c8ac3567da4228f49df78e5b0" category="list-text">进入存储分段后、单击*上传*&gt;*添加文件*、然后从系统上克隆的GitHub存储库中选择*实用程序.zip。</block>
  <block id="e796877161cfa3af2876f4bc473b909a" category="admonition">支持在一个VPC中监控多个FSx for ONTAP文件系统。</block>
  <block id="4a86a06630441d1655597fa23dc66379" category="list-text">创建图层并上传*Utilities．zip*文件。选择* Python 3.9*作为兼容运行时、然后单击*创建*。</block>
  <block id="6c51cd5dc46c2931b78f7f79a5f41525" category="cell">*fsxList*</block>
  <block id="eb9bdfa4e36f09f9fc14822772fd03c6" category="cell">2023年8月17日</block>
  <block id="6b60406f1591d6e6f410379e23bb66fc" category="cell">新增：使用Veeam复制和Azure NetApp Files数据存储库将灾难恢复到Azure VMware解决方案</block>
  <block id="4ac0795b239c621e30488feee37cd924" category="cell">新增：使用Veeam Replication和FSx for ONTAP将灾难恢复到AWS上的VMware Cloud</block>
  <block id="6f5eabf158a313cd86718b14d7379554" category="doc">使用Veeam Replication和FSx for ONTAP将灾难恢复到AWS上的VMware Cloud</block>
  <block id="1c7f3ee47ba78414fc5951b765102df8" category="paragraph">作者：Niyaz Mohamed - NetApp解决方案工程部</block>
  <block id="501ba669548ce3779a3fa0daa4d05d2e" category="paragraph">Amazon FSx for NetApp ONTAP与AWS上的VMware Cloud集成是一个AWS管理的外部NFS数据存储库、该数据存储库基于NetApp的ONTAP文件系统构建、可以连接到SDDC中的集群。它为客户提供了灵活的高性能虚拟化存储基础架构、该基础架构可独立于计算资源进行扩展。</block>
  <block id="8d32c17198f035ec3b269fb5631ef163" category="paragraph">对于希望将基于AWS SDDC的VMware Cloud用作灾难恢复目标的客户、可以使用FSx for ONTAP数据存储库通过任何经过验证的第三方从内部复制数据、此类解决方案可提供VM复制功能。通过添加FSx for ONTAP数据存储库、与在AWS SDDC上使用大量ESXi主机来容纳存储相比、它将实现成本优化的部署。</block>
  <block id="85d66a1f83ad134e81e04accccdd8b95" category="paragraph">此方法还有助于客户在VMC中使用试点轻型集群以及FSx for ONTAP数据存储库来托管VM副本。通过妥善地对复制计划进行故障转移、也可以将同一过程作为一个迁移选项扩展到AWS上的VMware Cloud。</block>
  <block id="9df44c920b4720a345f05a068b84efa1" category="section-title">问题陈述</block>
  <block id="949a0f887fad51addf7c4295467a3363" category="paragraph">本文档介绍如何使用FSx for ONTAP数据存储库以及Veeam备份和复制功能为内部VMware VM设置灾难恢复、并将其恢复到AWS上的VMware Cloud。</block>
  <block id="50155550d9bbed487f13452c08f8f2fb" category="paragraph">Veeam Backup &amp; Replication支持通过现场和远程复制实现灾难恢复(Disaster Recovery、DR)。复制虚拟机时、Veeam Backup &amp; Replication会在AWS SDDC集群上的目标VMware Cloud上以本机VMware vSphere格式创建VM的精确副本、并使该副本与原始VM保持同步。</block>
  <block id="33b5264a4351b1b7762143a9bf84b40e" category="paragraph">复制可提供最佳恢复时间目标(Recovery Time目标、Recovery Time目标、Recovery Time目标、Recovery Time目标、Recovery Time目标、Recovery Time目标、Recovery Time目标、Recovery Time目标、Recovery Time目标、Recovery Time目标、Recovery Time目标、Recovery Time目标、Recovery Time  此复制机制可确保在发生灾难事件时、工作负载可以在AWS SDDC上的VMware Cloud中快速启动。Veeam Backup &amp; Replication软件还可以优化流量传输、以便通过WAN和慢速连接进行复制。此外、它还会筛选出重复的数据块、将数据块置零、交换文件和排除的VM子操作系统文件、并压缩副本流量。</block>
  <block id="061c19aee3598a5e1e84366569d9a9d5" category="paragraph">为了防止复制作业占用整个网络带宽、可以设置WAN加速器和网络限制规则。Veeam Backup &amp; Replication中的复制过程由作业驱动、这意味着复制是通过配置复制作业来执行的。如果发生灾难事件、则可以通过故障转移到VM副本来触发故障转移以恢复VM。</block>
  <block id="b34a5dc49f68a6e6f3c9676bbf85c1fb" category="paragraph">执行故障转移时、复制的虚拟机将接管原始虚拟机的角色。可以将故障转移到副本的最新状态或任何已知正常的还原点。这样便可根据需要进行勒索软件恢复或隔离测试。在Veeam Backup &amp; Replication中、故障转移和故障恢复是临时的中间步骤、应进一步完成。Veeam Backup &amp; Replication提供了多种选项来处理不同的灾难恢复场景。</block>
  <block id="2a7995115f1adfd13812d825105a9d5e" category="inline-image-macro">使用Veeam Replication和FSx ONTAP for VMC的灾难恢复场景示意图</block>
  <block id="75b80e5b227adf21fbe0eaa9bffec77b" category="paragraph"><block ref="75b80e5b227adf21fbe0eaa9bffec77b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b25bcde8acd7bf7195e65b64a228dbd" category="section-title">高级步骤</block>
  <block id="44ea8c7a84c9828862a8017837aae869" category="list-text">Veeam Backup and Replication软件正在具有适当网络连接的内部环境中运行。</block>
  <block id="24eadee43b19443ef6eaf749c93ada65" category="inline-link-macro">《VMware Cloud on AWS与Amazon FSx for NetApp ONTAP集成部署指南》</block>
  <block id="4c6bc51fdb2364d02402eccf92c13dea" category="list-text">配置基于AWS的VMware Cloud、请参见VMware Cloud Tech Zone文章 <block ref="1f8b61b6658537d6130e81edfa2294f0" category="inline-link-macro-rx"></block> 要进行部署、请将基于AWS SDDC的VMware Cloud和适用于ONTAP的FSx配置为NFS数据存储库。(采用最低配置设置的指示灯环境可用于灾难恢复。发生意外事件时、VM将故障转移到此集群、并且可以添加其他节点)。</block>
  <block id="9121ad86c235165aa76a9e7664f75769" category="list-text">设置复制作业以使用Veeam Backup and Replication创建VM副本。</block>
  <block id="d49d8ad9dc8563c65436285afb482e25" category="list-text">创建故障转移计划并执行故障转移。</block>
  <block id="bb019a34acaf81adf99aa88e527764c3" category="list-text">灾难事件完成且主站点启动后、切换回生产VM。</block>
  <block id="49e72789e700343829d1695723b54270" category="section-title">将Veeam VM复制到适用于ONTAP数据存储库的VMC和FSx的前提条件</block>
  <block id="f14f08bbfe652b7cf1ab9215e23dfdc1" category="list-text">确保Veeam Backup &amp; Replication备份VM已连接到源vCenter以及AWS SDDC集群上的目标VMware云。</block>
  <block id="ec15ccec83c734abd29881602b5c768e" category="list-text">备份服务器必须能够解析短名称并连接到源和目标vCenter。</block>
  <block id="a5179499cee8ba59f97055fa68da8820" category="list-text">适用于ONTAP数据存储库的目标FSx必须具有足够的可用空间来存储已复制VM的VMDK</block>
  <block id="5c80d87c98b08990213aee3acac0a321" category="paragraph">对于追加信息、请参阅介绍的"注意事项和限制" <block ref="977fe0a3b86df54ae9f9a8dd61faa76b" category="inline-link-macro-rx"></block>。</block>
  <block id="993d529a07110176d7d72ab5d5af093a" category="example-title">第1步：复制VM</block>
  <block id="d205d55eab8cd05ff190d0a23cbbfeb7" category="paragraph">Veeam Backup &amp; Replication利用VMware vSphere快照功能、在复制期间、Veeam Backup &amp; Replication会请求VMware vSphere创建VM快照。VM快照是VM的时间点副本、其中包括虚拟磁盘、系统状态、配置等。Veeam Backup &amp; Replication使用快照作为复制数据源。</block>
  <block id="784e56a097e1eaccffe9afb87233eff3" category="paragraph">要复制VM、请执行以下步骤：</block>
  <block id="edd31ffe043b93ef4024aaaf3e5a8524" category="list-text">打开Veeam Backup &amp; Replication Console。</block>
  <block id="03af88a217678b7f07d983a3b5c03613" category="list-text">在主页视图中、选择复制作业&gt;虚拟机&gt; VMware vSphere。</block>
  <block id="3e594428ea9099aaae648d986ac81faf" category="list-text">指定作业名称并选中相应的高级控制复选框。单击下一步。</block>
  <block id="afe442695c8ee44f675f7794d4c97053" category="list-text">如果内部和AWS之间的连接带宽受限、请选中副本传播复选框。</block>
  <block id="1888ae9625eded9ca29e7ca87fe9733c" category="list-text">如果AWS SDDC上VMware Cloud上的区块与内部站点网络不匹配、请选中网络重新映射(适用于具有不同网络的AWS VMC站点)复选框。</block>
  <block id="31f6374c35cb2fa25717f6884c40e6a6" category="list-text">如果内部生产站点中的IP地址方案与AWS VMC站点中的方案不同、请选中"副 本重新IP (适用于具有不同IP地址方案的灾难恢复站点)"复选框。</block>
  <block id="ae2672285827de509edb4db52a02d6e3" category="image-alt">灾难恢复Veeam FSx版本2</block>
  <block id="556cf5110145daf2fba4bc968bb7864a" category="list-text">在*虚拟机*步骤中、选择需要复制到连接到AWS SDDC上的VMware Cloud的FSx for ONTAP数据存储库的VM。可以将虚拟机放置在vSAN上、以填满可用的vSAN数据存储库容量。在指示灯集群中、3节点集群的可用容量将受到限制。其余数据可以复制到FSx for ONTAP数据存储库。单击*Add*，然后在*Add Object*窗口中选择所需的VM或VM容器，然后单击*Add*。单击 * 下一步 * 。</block>
  <block id="60197ac329ac2bdfa2a759151b633ef7" category="image-alt">灾难恢复Veeam FSx版本3</block>
  <block id="78d44c549bf4580265b074f62a08c336" category="list-text">之后、选择目标作为AWS SDDC上的VMware Cloud集群/主机、并为VM副本选择相应的资源池、VM文件夹和FSx for ONTAP数据存储库。然后单击*Next*。</block>
  <block id="a8c62ed6c05f7d8663334c97f63604c6" category="image-alt">灾难恢复Veeam FSx版本4</block>
  <block id="e317d4d8b17eb36ec4fe84d6afc71518" category="list-text">在下一步中、根据需要创建源虚拟网络与目标虚拟网络之间的映射。</block>
  <block id="2e6db4bf3a79f2f6d81af7f22223bb10" category="image-alt">灾难恢复Veeam FSx版本5</block>
  <block id="9d8d1e4dac4c516dff3a62fb6203292a" category="list-text">在*作业设置*步骤中，指定要存储VM副本元数据、保留策略等的备份存储库。</block>
  <block id="94f075983ad6c929e4e7c18969136933" category="list-text">在“*数据传输*”步骤中更新*Source*和*Target*代理服务器，保留“*自动*选择”(默认)并保持“*直接*”选项处于选中状态，然后单击“*下一步*”。</block>
  <block id="6e19577434fdad5d228724e2575abb14" category="list-text">在*Guest Processing*步骤中，根据需要选择*Enable application-aware processing*选项。单击 * 下一步 * 。</block>
  <block id="536d32f40b20d0eff12974e4e02ffcd1" category="image-alt">灾难恢复Veeam FSx版本6</block>
  <block id="31f25d9eb456f1c3856b3aaa7ac66284" category="list-text">选择复制计划以定期运行复制作业。</block>
  <block id="85acb3fd553925ca5594ac206510b541" category="list-text">在向导的*摘要*步骤中，查看复制作业的详细信息。要在关闭向导后立即启动作业，请选中*单击完成时运行作业*复选框，否则不要选中该复选框。然后单击*完成*关闭向导。</block>
  <block id="9bfee1ff24f4b68f7aee7ac89111d540" category="image-alt">灾难恢复Veeam FSx版本7</block>
  <block id="f0200cb3935a7313f3ef29f4a492f201" category="paragraph">复制作业启动后、目标VMC SDDC集群/主机上将填充具有指定后缀的VM。</block>
  <block id="209ff66e79bfb1189e9733a9dca1e6e0" category="image-alt">灾难恢复Veeam FSx版本8</block>
  <block id="511688229c64cdf2013961353600f055" category="inline-link-macro">复制的工作原理</block>
  <block id="f97f53a446a12f9247bd0d8ddb52d90f" category="paragraph">有关追加信息for Veeam复制的信息、请参见 <block ref="370148c443ae2740936f568bfafc0697" category="inline-link-macro-rx"></block>。</block>
  <block id="3989dbda55e5994d81cc7be99090b046" category="example-title">第2步：创建故障转移计划</block>
  <block id="785949070ac82b292a8a4a262c1a9d0d" category="paragraph">初始复制或传播完成后、创建故障转移计划。故障转移计划有助于逐个或以组的形式自动对相关VM执行故障转移。故障转移计划是VM处理顺序(包括启动延迟)的蓝图。故障转移计划还有助于确保关键的相关VM已在运行。</block>
  <block id="f6cb62505ff59f9be3d2eed758045e7c" category="paragraph">要创建计划、请导航到名为副本的新子部分、然后选择故障转移计划。选择适当的VM。Veeam Backup &amp; Replication将查找最接近此时间点的还原点、并使用它们启动VM副本。</block>
  <block id="66274a35bd97bbdbfc622fff7dc94bf1" category="admonition">只有在初始复制完成且虚拟机副本处于就绪状态时、才能添加故障转移计划。</block>
  <block id="9a7efe362b8a177d7ab1055a8f00542e" category="admonition">在运行故障转移计划时、最多可同时启动10个VM。</block>
  <block id="2257a13c987dbd8e8fdb4254ce87c484" category="admonition">在故障转移过程中、源VM不会关闭。</block>
  <block id="90aa43668642f9181c5efdb6d91e4715" category="paragraph">要创建*故障转移计划*，请执行以下操作：</block>
  <block id="a2d5b9a9f78bc14f3bbfbd56930bdf9f" category="list-text">在主页视图中，选择*故障转移计划&gt; VMware vSphere。</block>
  <block id="6a97d4b122cb3965e695238325e70f33" category="list-text">接下来、提供计划的名称和问题描述。可以根据需要添加故障转移前和故障转移后脚本。例如、在启动复制的VM之前、请运行一个脚本来关闭VM。</block>
  <block id="704448f837fc30edc2114bc707f95712" category="image-alt">灾难恢复Veeam FSx版本9</block>
  <block id="00bd643bdbbe144ec5dfb4599443f059" category="list-text">将VM添加到计划中、并修改VM启动顺序和启动延迟、以满足应用程序依赖关系。</block>
  <block id="85dc60a4af6e02fee599da9eba368615" category="image-alt">灾难恢复Veeam FSx版本10</block>
  <block id="3e8f113173585d78b92dd70174cd91cc" category="inline-link-macro">正在创建复制作业</block>
  <block id="5c9ff597b8cb52ffef2567f24a8aae9a" category="paragraph">有关用于创建复制作业的追加信息、请参见 <block ref="b1d5f8714c42bc721d71228ca5e35b6e" category="inline-link-macro-rx"></block>。</block>
  <block id="293144611629d6cc94c702d011f5a2d8" category="example-title">第3步：运行故障转移计划</block>
  <block id="65a7331d58e18809f6d15ce33481d180" category="paragraph">在故障转移期间、生产站点中的源VM将切换到灾难恢复站点上的副本。在故障转移过程中、Veeam Backup &amp; Replication会将VM副本还原到所需的还原点、并将所有I/O活动从源VM移至其副本。不仅可以在发生灾难时使用副本、还可以用于模拟灾难恢复演练。在模拟故障转移期间、源VM将保持运行状态。执行完所有必要的测试后、您可以撤消故障转移并恢复正常操作。</block>
  <block id="4e52c750629d38d6aecaa69ec8f794e4" category="admonition">确保网络分段到位、以避免灾难恢复期间发生IP冲突。</block>
  <block id="b1271f5c2ea92c4ca8c53c9c66f50591" category="paragraph">要启动故障转移计划，只需单击*故障转移计划*选项卡，然后右键单击故障转移计划。选择 * 开始 * 。此操作将使用虚拟机副本的最新还原点进行故障转移。要故障转移到VM副本的特定还原点，请选择*Start to *。</block>
  <block id="3e609eb250503e790c2b5fa8589c48a2" category="image-alt">灾难恢复Veeam FSx image11</block>
  <block id="c1bca813c1347e67b132f7e385eb0664" category="image-alt">DR Veeam FSx版本12</block>
  <block id="d9797fdfa2491d34215fb9140928426e" category="paragraph">VM副本的状态将从"准备就绪"更改为"故障转移"、VM将在AWS SDDC集群/主机上的目标VMware Cloud上启动。</block>
  <block id="244bb5a075f7df8eb313aa1d6a7ce598" category="image-alt">灾难恢复Veeam FSx版本13.</block>
  <block id="c8e9b5ccb82328f905dee6894f80834d" category="paragraph">故障转移完成后、VM的状态将更改为"故障转移"。</block>
  <block id="3be25b5b1d3dc8fe5b3246919fd0bee4" category="image-alt">DR Veeam FSx版本14.</block>
  <block id="9e67460f82d9b308772657d1a2daccc9" category="admonition">Veeam Backup &amp; Replication会停止源VM的所有复制活动、直到其副本恢复到就绪状态为止。</block>
  <block id="e8cca7809eb17548363976cacfed95be" category="inline-link-macro">故障转移计划</block>
  <block id="4b9c003e6686a802635fb5c283db510a" category="paragraph">有关故障转移计划的详细信息、请参见 <block ref="435a73aa82873f69571502d4748c7127" category="inline-link-macro-rx"></block>。</block>
  <block id="628166e6094d0c9a6c4ea5d252539462" category="example-title">第4步：故障恢复到生产站点</block>
  <block id="b978e1007a24181478dc9ed0152ce12b" category="paragraph">当故障转移计划正在运行时、它会被视为一个中间步骤、需要根据需要最终确定。选项包括：</block>
  <block id="3f4242397e66ae78b2876c3cbff41b5f" category="list-text">*故障恢复到生产环境*-切换回原始虚拟机并将虚拟机副本运行期间发生的所有更改传输至原始虚拟机。</block>
  <block id="d9691eef72172401bf04e0d0cd7eb8cd" category="admonition">执行故障恢复时、只会传输更改、但不会发布更改。如果原始虚拟机未按预期工作，请选择*commit failback*(确认原始虚拟机按预期工作后)或*Undo failback*(撤消故障恢复)返回到虚拟机副本。</block>
  <block id="3934cd279f2d01ea48ad9e4b8eaee8b4" category="list-text">*撤消故障转移*-切换回原始虚拟机并放弃在虚拟机副本运行期间对其所做的所有更改。</block>
  <block id="426ee4e6b737d7828fe456e99dbd621a" category="list-text">*永久故障转移*-从原始虚拟机永久切换到虚拟机副本，并将此副本用作原始虚拟机。</block>
  <block id="fe36f35529273c9b101a0543cf03dd87" category="paragraph">在此演示中、我们选择了故障恢复到生产环境。在向导的目标步骤中选择了故障恢复到原始虚拟机、并启用了"Power On VM after Restoring"(还原后启动虚拟机)复选框。</block>
  <block id="14e2f5e1f9e7f5357ebc003b263a0c0c" category="image-alt">灾难恢复Veeam FSx版本15</block>
  <block id="29cc55d9d68642bd37c04337d39f1a4b" category="image-alt">DR Veeam FSx版本16</block>
  <block id="714856dcc4c91fcad24b886c57d5c46c" category="paragraph">提交故障恢复是完成故障恢复操作的方法之一。提交故障恢复后、它会确认发送到故障恢复虚拟机(生产虚拟机)的更改是否按预期工作。完成提交操作后、Veeam Backup &amp; Replication将恢复生产虚拟机的复制活动。</block>
  <block id="66db3443252ac1f1bb51225678cf9fec" category="inline-link-macro">故障转移和故障恢复以进行复制</block>
  <block id="015bce5a4812adccdfa92e8b621ebd37" category="paragraph">有关故障恢复过程的详细信息、请参见的Veeam文档 <block ref="2fe83b3b49bb24ca51cb130a80074249" category="inline-link-macro-rx"></block>。</block>
  <block id="f9aa14f8dbae63ab1e9c35e31dc0064c" category="image-alt">DR Veeam FSx版本17.</block>
  <block id="e51ba58ce1c64e49f879f5153aeacca7" category="image-alt">DR Veeam FSx版本18.</block>
  <block id="a21a44cf82d6eb52f15b3729c30bfb2c" category="paragraph">成功故障恢复到生产环境后、所有VM都会还原回原始生产站点。</block>
  <block id="7a80e2ee5643994830a90a5ac5f53586" category="image-alt">DR Veeam FSx版本19</block>
  <block id="39e7e9b6f4e41b5212b15ba7161858d4" category="paragraph">借助FSx for ONTAP数据存储库功能、Veeam或任何经过验证的第三方工具可以使用Pilot Light集群提供低成本的DR解决方案、而无需在集群中建立大量主机来容纳VM副本。这样可以提供一个功能强大的解决方案来处理定制的自定义灾难恢复计划、还可以重复使用内部现有备份产品来满足灾难恢复需求、从而通过在内部部署现有灾难恢复数据中心实现基于云的灾难恢复。发生灾难时、只需单击一个按钮、即可按计划进行故障转移或故障转移、并决定激活灾难恢复站点。</block>
  <block id="adffa5bb52f4ed1c0073d89b64041d71" category="doc">使用Veeam复制和Azure NetApp Files数据存储库将灾难恢复到Azure VMware解决方案</block>
  <block id="010a10de55332bfa0a32f2f2198ca0f6" category="paragraph">Azure NetApp Files (ANF)数据存储库可将存储与计算分离、并为任何组织提供将其工作负载迁移到云所需的灵活性。它为客户提供了灵活的高性能存储基础架构、可独立于计算资源进行扩展。Azure NetApp Files数据存储库可简化并优化Azure VMware解决方案(AVS)作为内部VMware环境灾难恢复站点的部署。</block>
  <block id="27ff2fba796b1a135c821bebde57714e" category="paragraph">可以使用基于Azure NetApp Files (ANF)卷的NFS数据存储库通过任何经过验证的第三方解决方案从内部复制数据、从而提供VM复制功能。通过添加Azure NetApp Files数据存储库、与构建具有大量ESXi主机来容纳存储的Azure VMware解决方案SDDC相比、它可以实现成本优化部署。这种方法称为“导向灯组”。试点轻型集群是一种最低的AVS主机配置(3个AVS节点)以及Azure NetApp Files数据存储库容量。</block>
  <block id="9657e55eafabb07d3c2debfd73ab4288" category="paragraph">其目标是维护一个具有所有核心组件的低成本基础架构、以处理故障转移。如果确实发生故障转移、试点轻型集群可以横向扩展并配置更多AVS主机。一旦完成故障转移并恢复正常操作、试点指示灯集群就可以向下扩展到低成本的操作模式。</block>
  <block id="3e88666ad5d556e5bee6eca9c3ddbc75" category="section-title">本文档的目的</block>
  <block id="a6854aebe8c8832db1c8563cd11a44f5" category="paragraph">本文介绍如何将Azure NetApp Files数据存储库与Veeam备份和复制结合使用、以便使用Veeam VM复制软件功能为内部VMware VM设置灾难恢复(AVS)。</block>
  <block id="2fb41bffd2477facda1d2681c9641a1f" category="paragraph">Veeam Backup &amp; Replication是一款适用于虚拟环境的备份和复制应用程序。在复制虚拟机时、Veeam Backup &amp; Replication会从AVS上进行复制、该软件将在目标AVS SDDC集群上以本机VMware vSphere格式创建VM的精确副本。  Veeam Backup &amp; Replication将使副本与原始虚拟机保持同步。复制可提供最佳恢复时间目标(Recovery Time客观、Recovery Time目标、Recovery Time目标、Recovery Time目标、Recovery Time目标、Recovery Time目标)、因为灾难恢复站点上已挂载VM副本、并且处于随时可启动的状态。</block>
  <block id="bddd776551bb214ff9dadbe3874cc9d0" category="paragraph">此复制机制可确保在发生灾难事件时、工作负载可以在AVS SDDC中快速启动。Veeam Backup &amp; Replication软件还可以优化流量传输、以便通过WAN和慢速连接进行复制。此外、它还会筛选出重复的数据块、零数据块、交换文件和"排除的VM子操作系统文件"。软件还将压缩副本流量。为了防止复制作业占用整个网络带宽、可以使用WAN加速器和网络限制规则。</block>
  <block id="cff5258042f5114d5b376f988cde25d9" category="paragraph">Veeam Backup &amp; Replication中的复制过程由作业驱动、这意味着复制是通过配置复制作业来执行的。如果发生灾难事件、则可以通过故障转移到VM副本来触发故障转移以恢复VM。执行故障转移时、复制的虚拟机将接管原始虚拟机的角色。可以将故障转移到副本的最新状态或任何已知正常的还原点。这样便可根据需要进行勒索软件恢复或隔离测试。Veeam Backup &amp; Replication提供了多种选项来处理不同的灾难恢复场景。</block>
  <block id="2706485f2f5236750f230d4b7b8577d3" category="paragraph"><block ref="2706485f2f5236750f230d4b7b8577d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="11125bccaa8c05735ba7d61bf1c112a2" category="list-text">Veeam Backup and Replication软件在具有适当网络连接的内部环境中运行。</block>
  <block id="a90917331ad0dfe22bf2f6e320ada7e8" category="inline-link-macro">部署Azure VMware解决方案(AVS)</block>
  <block id="3c0662627244f5aa8e96db2d19bc585a" category="inline-link-macro">连接Azure NetApp Files数据存储库</block>
  <block id="10a59745bff87c3581d7c750a33dd98f" category="list-text"><block ref="b7be33ad4eac6e2c71a992893b8f0a51" category="inline-link-macro-rx"></block> 私有云和 <block ref="06c837c7a128e07c5da3f9b77fcfa784" category="inline-link-macro-rx"></block> Azure VMware解决方案主机。</block>
  <block id="2571355c63dfc349de5476a18859e958" category="paragraph">采用最低配置设置的指示灯环境可用于灾难恢复。发生意外事件时、VM将故障转移到此集群、并且可以添加其他节点)。</block>
  <block id="4e96e68e3baa8424ecca3492d417670d" category="list-text">设置复制作业以使用Veeam Backup and Replication创建VM副本。</block>
  <block id="82fcee0e3d2b18bbe4614a5469ba280e" category="section-title">Veeam VM复制到AVS和ANF数据存储库的前提条件</block>
  <block id="fb56d19b352fa7bb5c92ab39795843b8" category="list-text">确保Veeam Backup &amp; Replication备份VM已连接到源和目标AVS SDDC集群。</block>
  <block id="516aad87cdd7498668675470bd1a6e9f" category="list-text">目标Azure NetApp Files数据存储库必须具有足够的可用空间来存储已复制VM的VMDK。</block>
  <block id="0d77cb2e0ae4ea54038c34e65976bfcd" category="paragraph">Veeam Backup &amp; Replication利用VMware vSphere快照功能/在复制期间、Veeam Backup &amp; Replication会请求VMware vSphere创建VM快照。VM快照是VM的时间点副本、其中包括虚拟磁盘、系统状态、配置和元数据。Veeam Backup &amp; Replication使用快照作为复制数据源。</block>
  <block id="bfbd500aa1e28d6d310392995e835a7a" category="list-text">在主页视图中。右键单击作业节点、然后选择复制作业&gt;虚拟机。</block>
  <block id="26cd1b48aa9f6296b7b62aad8dcf20ac" category="list-text">如果内部和Azure之间的连接带宽受限、请选中"副本传播"复选框。
*如果Azure VMware解决方案SDDC上的分段与内部站点网络不匹配、请选中"网络重新映射(适用于具有不同网络的AVS SDDC站点)"复选框。</block>
  <block id="2a21b1a7e725fac09d71e71ed8bd88ed" category="list-text">如果内部生产站点中的IP地址方案与目标AVS站点中的方案不同、请选中"副 本重新IP (适用于IP地址方案不同的灾难恢复站点)"复选框。</block>
  <block id="4897882992af74b1405bd15b8ee68c96" category="paragraph"><block ref="4897882992af74b1405bd15b8ee68c96" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb58f14b8c2887fcf0d846ce599bf64c" category="list-text">在*Virtual* Machines*步骤中，选择要复制到连接到Azure VMware解决方案SDDC的Azure NetApp Files数据存储库的VM。可以将虚拟机放置在vSAN上、以填满可用的vSAN数据存储库容量。在指示灯集群中、3节点集群的可用容量将受到限制。其余数据可以轻松放置在Azure NetApp Files数据存储库中、以便恢复VM、并可扩展集群以满足CPU/内存要求。单击*Add*，然后在*Add Object*窗口中选择所需的VM或VM容器，然后单击*Add*。单击 * 下一步 * 。</block>
  <block id="aae0b47e0672d77f64a05b160878908a" category="paragraph"><block ref="aae0b47e0672d77f64a05b160878908a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="251b55d8fd9c283e24d59180aa8d5c01" category="list-text">之后、选择目标作为Azure VMware解决方案SDDC集群/主机、并为VM副本选择相应的资源池、VM文件夹和FSx for ONTAP数据存储库。然后单击 * 下一步 * 。</block>
  <block id="5026b667d9da5df854ce833ff13c6347" category="paragraph"><block ref="5026b667d9da5df854ce833ff13c6347" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a18e505fd8e40c3f58f636f46cf4cab" category="paragraph"><block ref="7a18e505fd8e40c3f58f636f46cf4cab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="11611c13aa7aaf4496d44cc701fdbc37" category="paragraph"><block ref="11611c13aa7aaf4496d44cc701fdbc37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bf0a50f87b8beec8d9b2bb97dc96505" category="paragraph"><block ref="8bf0a50f87b8beec8d9b2bb97dc96505" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c8f2a2a732536226d20f6e907b272d7" category="paragraph"><block ref="6c8f2a2a732536226d20f6e907b272d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21e6918b052bad28f76658ff8ad532ff" category="paragraph">复制作业启动后、目标AVS SDDC集群/主机上将填充具有指定后缀的VM。</block>
  <block id="aaa8104b2cad128084193b0c0d41c5a7" category="paragraph"><block ref="aaa8104b2cad128084193b0c0d41c5a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8e8cc1b6e9f29ef294db0eb69359d35" category="paragraph">有关追加信息for Veeam复制的信息、请参见 <block ref="370148c443ae2740936f568bfafc0697" category="inline-link-macro-rx"></block></block>
  <block id="966be1c217c36e4b9365942c31c8d734" category="paragraph">要创建计划，请导航到名为*RELIG副 本*的新子部分，然后选择*Failover Plan*。选择适当的VM。Veeam Backup &amp; Replication将查找最接近此时间点的还原点、并使用它们启动VM副本。</block>
  <block id="8ec7e47f124ff75e7f16f8c4e28b071f" category="admonition">在运行故障转移计划时、最多可同时启动10个VM</block>
  <block id="ea606296d0241925d3908b71295397d4" category="admonition">在故障转移过程中、源VM不会关闭</block>
  <block id="54cfc181913d73f0e94b41eb7ef8b4e5" category="list-text">在主页视图中。右键单击副本节点、然后选择故障转移计划&gt;故障转移计划&gt; VMware vSphere。</block>
  <block id="9a9a4f3269744ba765003944b5959f67" category="paragraph"><block ref="9a9a4f3269744ba765003944b5959f67" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d953bc1e2c9d57399c513a44c4549cdd" category="list-text">接下来、提供计划的名称和问题描述。可以根据需要添加故障转移前和故障转移后脚本。例如、在启动复制的VM之前、请运行一个脚本来关闭VM。</block>
  <block id="5104408584186e0e89a77a2f81f6ef27" category="paragraph"><block ref="5104408584186e0e89a77a2f81f6ef27" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd35bdf8a5c79e358d7e2274886eba5" category="paragraph"><block ref="8bd35bdf8a5c79e358d7e2274886eba5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5899fddf615852ba6e64ca7a86149a0b" category="admonition">确保已建立网络分段、以避免故障转移期间发生IP冲突。</block>
  <block id="51f61136debd24def2541ea3e12887e4" category="paragraph">要启动故障转移计划，只需单击*故障转移计划*选项卡，然后右键单击您的故障转移计划。选择**开始*。此操作将使用虚拟机副本的最新还原点进行故障转移。要故障转移到VM副本的特定还原点，请选择*Start to *。</block>
  <block id="876afb7259a6c985f277d39d0b34cbaa" category="paragraph"><block ref="876afb7259a6c985f277d39d0b34cbaa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1914fa31cf9e93978faa9502f985425e" category="paragraph"><block ref="1914fa31cf9e93978faa9502f985425e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a5503ceba4e0cebbb476f43ed91d171" category="paragraph">VM副本的状态将从"准备就绪"更改为"故障转移"、VM将在目标Azure VMware解决方案(AVS) SDDC集群/主机上启动。</block>
  <block id="5366765c0c588b8f9416f2fc6d7d53d0" category="paragraph"><block ref="5366765c0c588b8f9416f2fc6d7d53d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cc3f1716d930994b8f3f59bd3ef0c43" category="paragraph"><block ref="4cc3f1716d930994b8f3f59bd3ef0c43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4f57625c42b55101b3a8db061e665f7" category="paragraph">有关故障转移计划的详细信息、请参见 <block ref="435a73aa82873f69571502d4748c7127" category="inline-link-macro-rx"></block>。</block>
  <block id="4687b6eb9a72698468a588103f76433f" category="admonition">执行故障恢复时、只会传输更改、但不会发布更改。选择*Commit failback*(确认原始虚拟机按预期工作后)或Undo failback (撤消故障恢复)以返回到虚拟机副本(如果原始虚拟机未按预期工作)。</block>
  <block id="24c20c4538b3d0bd361577418d724325" category="paragraph"><block ref="24c20c4538b3d0bd361577418d724325" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90d5a7e78b08fc7e822a235880b058f7" category="paragraph"><block ref="90d5a7e78b08fc7e822a235880b058f7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d30751eabac8bfd33ff9b7c8568473" category="paragraph"><block ref="03d30751eabac8bfd33ff9b7c8568473" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5b9a5229bcbf847fe6cbe19fa2f400c" category="paragraph"><block ref="d5b9a5229bcbf847fe6cbe19fa2f400c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="caf8b775aa69a5ba386520c85bf77ca0" category="paragraph"><block ref="caf8b775aa69a5ba386520c85bf77ca0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d47a618f27fda5779a63d84527053b2" category="paragraph"><block ref="4d47a618f27fda5779a63d84527053b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae40ac16df59df85ba7c1891e1d4fc9c" category="paragraph">借助Azure NetApp Files数据存储库功能、Veeam或任何经过验证的第三方工具可以利用试点轻型集群来提供低成本的灾难恢复解决方案、而不是仅仅通过建立大型集群来容纳VM副本。这样可以高效地处理定制的自定义灾难恢复计划、并重复使用内部现有备份产品进行灾难恢复、从而通过退出内部灾难恢复数据中心实现基于云的灾难恢复。如果发生灾难、可以通过单击按钮进行故障转移、如果发生灾难、则可以自动进行故障转移。</block>
  <block id="88f83c706b3d2e5f8d1169971db47853" category="paragraph">FSx for ONTAP是AWS上提供的第一方企业级云存储服务、可提供基于流行的NetApp ONTAP文件系统构建的高度可靠、可扩展、高性能和功能丰富的文件存储。</block>
  <block id="461935e6fc4ef009527a8b35dda4c285" category="paragraph">适用于ONTAP 的FSX可提供无缝的部署和管理体验。无需具备存储专业知识即可开始使用。为了简化监控、可以使用AWS兰达功能(根据阈值自动调整总存储容量、卷大小或LUN大小的大小)。  本文档提供了创建自动设置的分步指南、该设置会定期监控FSx for ONTAP、在超过用户指定的阈值时发出通知并调整大小、以及向管理员通知调整大小活动。</block>
  <block id="a7cd615e255b9b089f1b061e5e189abd" category="list-text">通过电子邮件接收使用情况警告和大小调整通知的警报机制</block>
  <block id="0d50ae6aa92c4ec6f263491e478e7d82" category="list-text">可以删除早于用户定义阈值的快照</block>
  <block id="703ead715d6d2f8639484c00e0ed0d5d" category="example-title">高级架构</block>
  <block id="2b9ee323cc707d4cd4f3a2a127530351" category="list-text">"fsxadmin"密码以安全字符串形式存储在AWS SSM参数存储中、用于增加一层安全保护。</block>
  <block id="a2c0867d899b117aa3870a45761a92a6" category="list-text">如果在无法访问Internet的VPC中部署解决方案、则会对适用于AWS SSM、FSx和SES的VPC端点进行设置、使Lamb达 能够通过AWS内部网络访问这些服务。</block>
  <block id="002c69c38fe81f4ebc5f950b44e22628" category="paragraph">如果要在不访问Internet的情况下部署解决方案、请执行此步骤(注意：要设置的VPC端点会增加相关成本。)</block>
  <block id="a1e0c9bd0fc75dba09f52b2963994041" category="list-text">导航到AWS控制台&gt;*AWS Simple Email Service (SES)*&gt;*SMTP Settings*，然后单击*Create SMTP credcredcredcredENTs*</block>
  <block id="8ff28e341f8985ff5b224f50aa4ffa38" category="list-text">输入IAM用户名或将其保留为默认值，然后单击*Create User*。保存*SMTP用户名*和*SMTP密码*以供将来使用。</block>
  <block id="9665e80899cc4ee16b02e57f6f6bd770" category="list-text">一旦CloudFormation部署开始、"发件人电子邮件ID"中提及的电子邮件ID将收到一封电子邮件、要求他们授权在AWS SES中使用此电子邮件地址。单击链接以验证电子邮件地址。</block>
  <block id="28b8479848099212d34ed9e8ff2f3288" category="paragraph">"发件人电子邮件ID"中提及的电子邮件ID将收到一封电子邮件、要求所有者授权AWS SES使用此电子邮件地址。单击链接以验证电子邮件地址。</block>
  <block id="ab00efb48492ba46bf143309d7d5a995" category="example-title">第5步：设置VPC端点(如果无法访问Internet、则需要此端点)</block>
  <block id="a896cb4c0f87c01212691e2e656eb9c4" category="admonition">只有在部署时不能访问Internet时才需要。与VPC端点相关的额外成本。</block>
  <block id="efd995d112fb4cf555fe5f14b1077928" category="list-text">按照相同的过程创建SES和SSM VPC端点。除将&lt;region&gt;分别对应于*com.惊奇aws.smp.smNT*和*com.惊奇aws.smssm*&lt;region&gt;的服务外，所有参数均与上述相同。</block>
  <block id="0067996368770d245be1642cf338806d" category="list-text">导航到AWS控制台&gt;* AWS Lambx*&gt;*功能*、然后单击FSx for ONTAP所在区域的*创建功能*</block>
  <block id="ced74238d4f3e0d01b23a4ded2b9663c" category="list-text">导航到新创建的Lamba函数&gt;向下滚动到*图层*部分，然后单击*添加图层*。</block>
  <block id="5ce6c1605d609112f3e70cd0eb8d92a5" category="list-text">导航到Lambda函数的*配置*选项卡、然后单击*常规配置*下的*编辑*。将超时更改为*5分钟*，然后单击*Save*。</block>
  <block id="740343954e72caba682c972de1bc4459" category="cell">(必需)将此变量设置为True、以便在存储容量/卷/LUN使用量超过75%但小于阈值时收到通知。</block>
  <block id="8a5fe4432309ce27193ef047eaf8b7ea" category="list-text">单击*Test*，创建一个包含空JSON对象的测试事件，然后通过单击*Invoke *来运行测试，以检查脚本是否运行正常。</block>
  <block id="0551dbffe30f51dd77e5f8b4a0dfb8e6" category="paragraph">借助提供的解决方案、可以轻松设置监控、该监控解决方案会定期监控FSx for ONTAP存储、根据用户指定的阈值调整其值并提供警报机制。这样、使用和监控适用于ONTAP 的FSX的过程就可以无缝地让管理员腾出时间专注于业务关键型活动、同时存储在需要时自动增长。</block>
  <block id="4955754540a3275b8091953009e5babc" category="paragraph">本解决方案 介绍了使用 Terraform 模块在 AWS （ CVO 单节点， CVO HA 和 FSX ONTAP ）和 Azure （ CVO 单节点， CVO HA 和 ANF ）上自动部署云卷的过程。可在中找到此代码<block ref="443c555d04d240afc4ca748e75f63754" category="inline-link-rx"></block></block>
  <block id="af5a37a09e4cee2968d7fd03f421a0a2" category="inline-link"><block ref="af5a37a09e4cee2968d7fd03f421a0a2" category="inline-link-rx"></block></block>
  <block id="681814eb62cc26ee1c660bd58a9ce6eb" category="list-text"><block ref="681814eb62cc26ee1c660bd58a9ce6eb" category="inline-link-rx"></block></block>
  <block id="275e63e9a49f296c063604ee4db5723e" category="paragraph">要使用PowerShell自动创建iSCSI LUN并安装NetApp SnapCenter 、请从克隆此repo<block ref="a4dae7a3e0d905f7a66835dd216b7b06" category="inline-link-rx"></block>。</block>
  <block id="9c004ebf0d7adca9e42ae6ecd9c1c4ad" category="inline-link-macro">采用NetApp Cloud Insights的现代数据中心的可观察性</block>
  <block id="d3fb43b61178ef64f1aed3855bddc8b0" category="list-text"><block ref="d3fb43b61178ef64f1aed3855bddc8b0" category="inline-link-macro-rx"></block></block>
  <block id="b39353bee738e1aa6f9140d1c72b84f9" category="summary">NetApp®AI功能支持在AI管道之间无缝管理数据和移动数据，用于训练、重新培训、微调、推理和监控生成的AI模型。</block>
  <block id="36cc0281ec7abcd20091f5d39b995cc4" category="doc">生成性AI和NetApp价值</block>
  <block id="114811a570a451ce6b4fbec5b2967979" category="paragraph">作者：Sathish Thyagarajan、NetApp</block>
  <block id="1db5bb1590f7c297fd0dbf5be34a5174" category="paragraph">对生成性人工智能(AI)的需求正在推动各行各业的变革、从而增强了业务创造力和产品创新。许多企业都在使用生成型AI来构建新的产品功能、提高工程效率、并对AI驱动的应用程序进行原型设计、以提供更好的结果和消费者体验。生成型AI (例如生成型预训练变形本(GPT))使用神经网络创建新内容、包括文本、音频和视频。鉴于大型语言模型(LLM)所涉及的极大规模数据集、构建强大的AI基础架构至关重要、该基础架构应利用内部部署、混合云和多云部署选项的极具吸引力的数据存储功能、并降低与数据移动性相关的风险、 在企业设计AI解决方案之前、先对数据进行保护和监管。本白皮书将介绍这些注意事项以及相应的NetApp®AI功能，这些功能可以在人工智能数据管道之间实现无缝数据管理和数据移动，以用于训练、再培训、微调和推理生成的人工智能模型。</block>
  <block id="a573d92b77d430af7e424879baf78e94" category="section-title">内容提要</block>
  <block id="1d28e988d29c4b73f397bf1301900174" category="paragraph">最近、在2022年11月推出GPT-3的衍生产品ChatGPT之后、用于根据用户提示生成文本、代码、图像甚至治疗性蛋白质的新AI工具获得了显著声誉。这表示用户可以使用自然语言提出请求、AI将使用经过训练的现有数据算法解释和生成文本、例如反映用户请求的新闻文章或产品说明、或者生成代码、音乐、语音、视觉效果和3D资产。因此、稳定扩散、幻想、快速工程和价值协调等短语在AI系统设计中迅速涌现。这些自我监督或半监督机器学习(ML)模式正在通过云服务提供商和其他AI公司供应商以预先训练的基础模式(FM)的形式广泛提供、这些模式正被各行各业的各种企业机构采用、用于执行各种下游NLF (自然语言处理)任务。正如McKinsey等研究分析公司所说：“生成性AI对生产率的影响可以为全球经济增加数以亿计的价值。” 虽然企业正在将AI重新视为人类的思想合作伙伴、而FMS正在同时扩展到企业和机构可以利用生成型AI实现的目标、但管理海量数据的机会仍将继续增长。本文档介绍了有关生成AI的介绍信息、以及与可为NetApp客户带来价值的NetApp功能相关的设计概念、包括内部环境以及混合或多云环境。</block>
  <block id="7b285a8cd7907bb777dc3cd704e164b9" category="paragraph">*那么、客户在AI环境中使用NetApp有何意义？* NetApp可帮助企业应对数据和云快速增长、多云管理以及采用AI等下一代技术所带来的复杂性。NetApp已将各种功能整合到智能数据管理软件和存储基础架构中、这些功能与针对AI工作负载优化的高性能实现了完美平衡。像LMs这样的生成性AI解决方案需要多次将其源数据集从存储读取并处理到内存中、以增强智能。NetApp在跨边缘到核心再到云生态系统的数据移动性、数据监管和数据安全技术方面一直处于领先地位、为企业客户构建大规模AI解决方案提供服务。NetApp与强大的合作伙伴网络一直在帮助首席数据官、AI工程师、企业架构师和数据科学家设计自由流动的数据管道、用于数据准备、数据保护、 以及AI模型训练和推理的战略数据管理职责、优化AI/ML生命周期的性能和可扩展性。NetApp数据技术和功能，例如用于深度学习数据管道的NetApp®ONTAP AI®、用于在存储端点之间无缝高效地传输数据的NetApp®SnapMirror® NetApp®FlexCache®可在数据流从批量转换到实时时进行实时渲染，并且数据工程会及时进行，从而为部署实时生成AI模型带来价值。随着各种类型的企业纷纷采用新的AI工具、他们面临着从边缘到数据中心再到云端的数据挑战、这些挑战需要可扩展、负责任且可解释的AI解决方案。作为混合云和多云数据管理领域的权威企业、NetApp致力于构建合作伙伴网络和联合解决方案、帮助构建数据管道和数据湖的方方面面、以进行生成性AI模型训练(训练前)、微调、基于上下文的推理以及对LLM的模型衰退监控。</block>
  <block id="ba4c46fa4f06702b4667d0b3a6b2bdfe" category="section-title">什么是生成型AI？</block>
  <block id="a80e3b89208c06f905b7cee55c55fdb1" category="paragraph">生成性AI正在改变我们创建内容、生成新设计概念以及探索新组成的方式。它展示了生成式抗压网络(GAN)、多种形式的自动编码器(VAE)和生成式预训练变形器(GPT)等神经网络框架、这些框架可以生成文本、代码、图像、音频、视频、 和合成数据。OpenAI的Chat-GPT、Google的Bard、hubling face’s bollama和Meta的llama等基于变压器的模型已成为支持大型语言模型许多进步的基础技术。同样、OpenAI的Dall-E、Meta的CM3leon和Google的Imagen也是文本到图像传播模型的示例、这些模型为客户提供前所未有的光刻度、让客户可以从头开始创建新的复杂图像、或者通过数据集扩充和文本到图像合成来编辑现有图像、从而生成高质量的上下文感知图像。数字艺术家开始将Nerf (神经光场)等渲染技术与生成性AI相结合、将静态2D图像转换为沉浸式3D场景。一般来说、LLM的大致特征是四个参数：(1)模型大小(通常以数十亿个参数为单位)；(2)训练数据集大小；(3)训练成本；(4)训练后的模型性能。此外、LMs还主要分为三种变压器架构。(i)仅编码器型号。例如BERT (Google、2018年)；(ii)编码器-解码器、例如BART (Meta、2020年)和(iii)仅解码器型号。例如：llama (Meta、2023)、Palm/E (Google、2023)。根据业务要求、无论公司选择哪种架构、训练数据集中的模型参数数量(N)和令牌数量(D)通常都会确定训练(训练前)或微调LLM的基线成本。</block>
  <block id="d1ddcb04dcb447b3f05fa54e9ab492d0" category="section-title">企业用例和下游NLL任务</block>
  <block id="a4a7c510156562fb9841dd055348b753" category="paragraph">各行各业的企业都在发掘越来越多的AI潜力、从现有数据中提取并产生新形式的价值、用于业务运营、销售、营销和法律服务。根据IDC (International Data Corporation)在全球生成型AI用例和投资方面的市场情报、软件开发和产品设计方面的知识管理受到的影响最大、其次是为营销创建案例以及为开发人员生成代码。在医疗保健领域、临床研究组织正在医学领域开辟新天地。ProteinBERT等经过预先训练的模型采用基因本体(GGO)注释来快速设计医疗药物的蛋白质结构、这是药物发现、生物信息学和分子生物学方面的一个重要里程碑。生物技术公司已开始人类试验AI发现的生成性药物、其目的是治疗肺部成肿(IPF)等疾病、肺部成肿(IPF)是一种导致肺组织不可逆划痕的肺病。</block>
  <block id="8e5aaca094938e3b1a2e08f48f3db558" category="inline-image-macro">图1：推动生成性AI的用例</block>
  <block id="a34a8d0a4fb3f7d00cf06efe06cd9772" category="paragraph">图1：推动生成性AI的用例
<block ref="48dbf33e0f0b05c284a13154324112fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605e4f6997ac64a7de35f4e8a02721e9" category="paragraph">在生成型AI的推动下、自动化采用率的提高也在改变许多职业工作活动的供求。如McKinsey所述、美国劳动力市场(下图)经历了快速转型、只有在考虑到AI的影响后、这种转型才可能持续下去。</block>
  <block id="14509aeb117a81412dfa4dc27107f735" category="inline-image-macro">图2：来源：McKinsey &amp;amp；公司</block>
  <block id="40ee671ceb0ca628228964328cec8be6" category="paragraph">来源：McKinsey &amp; Company
<block ref="ceaf5e0f4e023739423f516385ae490c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="072f966c176c14e4a8ac1b32dff891bc" category="section-title">存储在生成AI中的作用</block>
  <block id="6a352eac97ff84fb6680bea0e3f1582b" category="inline-link-macro">512 MB</block>
  <block id="fbba687eb3fa22314fe20baddb4c8eef" category="paragraph">LLM在很大程度上依赖于深度学习、GPU和计算。但是、当GPU缓冲区填满时、需要将数据快速写入存储。虽然某些AI模型的大小足以在内存中执行、但LLM需要高IOPS和高吞吐量存储才能快速访问大型数据集、尤其是在涉及数十亿个令牌或数百万个图像的情况下。对于LLM的典型GPU内存需求、使用10亿个参数训练模型所需的内存最高可达80 GB @32位全精度。在这种情况下、Meta的llama 2 (一个规模从70亿到700亿参数的LLM系列)可能需要70x80、大约5600 GB或5.6 TB GPU RAM。此外、所需的内存量与要生成的最大令牌数成正比。例如、如果要生成最多512个令牌(约380个字)的输出、则需要 <block ref="8b6a924b2b2c8b02d5e56762d0384bc1" category="inline-link-macro-rx"></block>。这可能看似无关紧要、但是、如果您要运行较大的批次、它就会开始累加。因此、组织在内存中进行训练或微调的成本非常高、从而使存储成为生成性AI的基石。</block>
  <block id="b0b4b15d26d559735ca79c547ebcf9b6" category="section-title">三种主要的LLMs方法</block>
  <block id="81494e703ce597558bda05952111ece7" category="inline-link-macro">《哈佛商业评论》</block>
  <block id="51d70278b5270d77e315aea72b0a01bb" category="paragraph">对于大多数企业而言、根据当前趋势、部署LLM的方法可以精简为3种基本方案。如最近的中所述 <block ref="fe5c1d5bcd451e0c1a9ba2bb93e92c88" category="inline-link-macro-rx"></block> 文章：(1)从头开始培训(预培训) LLM—成本高昂、需要专业的AI/ML技能；(2)利用企业数据微调基础模型—复杂但可行；(3)使用检索增强生成(RAG)查询包含公司数据的文档存储库、API和矢量数据库。其中每一种方法都在其实施过程中的工作量、迭代速度、成本效益和模型准确性之间进行权衡、以解决不同类型的问题(下图)。</block>
  <block id="c35884049dd0467b68f884a60d4920ea" category="inline-image-macro">图3：问题类型</block>
  <block id="a1618b6d95908a5a38caeb095f297b0b" category="paragraph">图3：问题类型
<block ref="8d33aaa620c0dc715fdaecd60b10fe36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff76a02d3da4ad3236fe1704ce7b2a4c" category="section-title">基础模型</block>
  <block id="dc3ab4e5c564f5b586639e40bd0e6ab5" category="paragraph">基础模型(FM)也称为基础模型(Base Model)、它是一种大型AI模型(LLM)、使用大规模自我监督、针对大量下游NLP"任务进行训练。由于训练数据不是由人类标记的、因此模型会出现、而不是显式编码。这意味着模型可以生成自己的故事或叙述、而无需明确编程。因此、FM的一个重要特征是同质化、这意味着在许多领域中使用相同的方法。但是、借助个性化和微调技术、如今出现的产品中集成的FMS不仅能够很好地生成文本、文本到图像和文本到代码、还可以解释特定域的任务或调试代码。例如、FMS (如OpenAI的Codex"或Meta的Code Llama)可以根据编程任务的自然语言描述以多种编程语言生成代码。这些模型精通十几种编程语言、包括Python、C#、JavaScript、Perl、Ruby、 和SQL。他们了解用户的意图、并生成特定的代码来完成对软件开发、代码优化和编程任务自动化有用的预期任务。</block>
  <block id="09505640cb74de4ed6c0043b4fd83b62" category="section-title">微调、特定域和重新培训</block>
  <block id="d70061bb0ac24d99b6a01f537dfc5836" category="inline-link-macro">元数据的Llama 2.</block>
  <block id="16121ff122f55a691993cb3efe630acb" category="paragraph">在数据准备和数据预处理之后、LLM部署的一个常见做法是、选择一个经过预先训练的模型、该模型已在庞大且多样化的数据集中进行过训练。在微调环境中、这可以是一个开源大型语言模型、例如 <block ref="40c631914d673c775e5813606a4c652a" category="inline-link-macro-rx"></block> 经过700亿个参数和2万亿个令牌的培训。选择预先训练的模型后、下一步是根据域特定的数据对其进行微调。这包括调整模型的参数并对其进行新数据训练、以适应特定的领域和任务。例如、作为一家专有LLM公司的布隆伯格GPT、就为金融行业提供的各种金融数据进行了培训。为特定任务设计和训练的域特定模型在其范围内的准确性和性能通常较高、但在其他任务或域之间的可转移性较低。当业务环境和数据在一段时间内发生变化时、与测试期间的性能相比、FM的预测准确性可能开始下降。此时、重新培训或微调模型变得至关重要。传统人工智能/机器学习中的模型再训练是指使用新数据更新已部署的机器学习模型、通常执行此操作是为了消除出现的两种类型的移动。(1)概念漂移—当输入变量和目标变量之间的链接随时间发生变化时、由于我们要预测的内容的问题描述发生变化、因此模型可能会产生不准确的预测。(2)数据漂移—当输入数据的特征发生变化时、例如客户习惯或行为随时间推移而发生变化、因此模型无法响应此类变化。以类似的方式、重新培训适用场景FMS/LLM、但是成本可能会很高(以百万美元为单位)、因此大多数企业可能不会考虑这一点。它正在积极研究、仍在LLMOps领域出现。因此、当模型在微调FMS中发生退换时、企业可能会选择使用较新的数据集再次进行微调(成本低得多)。从成本角度来看、下面列出了Azazy-OpenAI Services的模型价格表示例。对于每个任务类别、客户可以微调和评估特定数据集的模型。</block>
  <block id="95d06c21390dc25827c0fd489dc141e4" category="inline-image-macro">来源：Microsoft Azure</block>
  <block id="260d33c297226dc4da38acd65927faf9" category="paragraph">来源：Microsoft Azure
<block ref="931517220bf52a99f49acd72cdc1f4f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157d80dbb8ad88a26dfd59594b88e11c" category="section-title">提示工程和推理</block>
  <block id="e48b39374db0f3e4c1479cb81f7ebd58" category="paragraph">提示工程是指在不更新模型权重的情况下、如何与LLM进行通信以执行所需任务的有效方法。与AI模型训练和微调一样重要的是NLG应用程序、推理也同样重要、因为经过训练的模型会响应用户提示。推理的系统要求通常更多地涉及AI存储系统的读取性能、该存储系统会将数据从LLM馈送到GPU、因为它需要能够应用数十亿个已存储的模型参数来生成最佳响应。</block>
  <block id="71451daa1205b079e03924f700485fb7" category="section-title">LLMOps、Model Monitoring和Mittorstores</block>
  <block id="37dc13dd8c23bd5e417bad0376cb8642" category="paragraph">与传统机器学习操作(MLOps)一样、大型语言模型操作(LLMOps)也需要数据科学家和DevOps工程师协作、利用工具和最佳实践在生产环境中管理LLM。但是、LLM的工作流和技术堆栈可能会在某些方面有所不同。例如、使用LangChin字符串等框架构建的LLM管道将对外部嵌入端点(如矢量存储库或向量数据库)的多个LLM API调用组合在一起。将嵌入端点和矢量存储用于下游连接器(如向量数据库)代表了数据存储和访问方式的重大发展。与从零开始开发的传统ML模型不同、LMs通常依赖于转移学习、因为这些模型从FMS开始、FMS会根据新数据进行微调、以提高更具体领域的性能。因此、LLMOps提供风险管理和模型核降监测功能至关重要。</block>
  <block id="e1e7449571fe3b65d3a1e689bc700cbc" category="section-title">在生成型AI时代的风险与道德</block>
  <block id="dca7ae13b54e16a20c6bf3b96a3f894e" category="paragraph">"ChatGPT–它很流畅、但仍不实用。"–MIT Tech Review。垃圾输入-垃圾输出一直是计算领域的难题。与生成型AI的唯一区别在于、它擅长使垃圾变得高度可信、从而导致结果不准确。LLM倾向于根据自己的叙述来创造事实。因此、如果公司将生成型AI视为使用AI等效产品降低成本的绝佳机会、则需要高效检测深度假象、减少偏见并降低风险、以保持系统的诚信和道德。在设计负责任且可解释的生成型AI模型时、采用支持数据移动性、数据质量、数据监管和数据保护的强大AI基础架构的自由流动数据管道是一项杰出的功能。</block>
  <block id="b1c01c916bfeda43bbe010599a3756ef" category="section-title">客户场景和NetApp</block>
  <block id="d475afb6eaf5d8966136580d55f5a688" category="inline-image-macro">图3：机器学习/大型语言模型工作流</block>
  <block id="93afd4d24d4d3fc78b0467e81c3554da" category="paragraph">图3：机器学习/大型语言模型工作流
<block ref="0bbdf72e2f0ab887063acc43b67a85fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9dd90f4ead88ee59ec52f11bac2d164b" category="paragraph">*我们是在训练还是微调？*是(a)从头开始训练LLM模型、微调预先训练的FM、还是使用RAG从基础模型以外的文档库中检索数据并增加提示、 (b)无论是利用开源LMs (例如Llama 2)还是专有FMS (例如ChatGPT、Bard、AWS Brock)、都是企业的一项战略决策。每种方法都会在成本效益、数据惯性、操作、模型准确性和LLM管理之间进行折让。</block>
  <block id="7c98082681a099010fe6b84a2f8f2232" category="paragraph">作为一家公司、NetApp在其内部工作文化以及产品设计和工程工作方法中都采用AI。例如、NetApp的自主勒索软件保护功能是使用AI和机器学习构建的。它可以及早检测文件系统异常情况、帮助您在威胁影响操作之前识别这些威胁。其次、NetApp在销售和库存预测以及聊天机器人等业务运营中使用预测性AI、在呼叫中心产品支持服务、技术规格、保修、服务手册等方面为客户提供帮助。第三、NetApp通过为客户提供服务的产品和解决方案为AI数据管道和ML/LLM工作流带来客户价值构建预测性AI解决方案、例如需求预测、医学成像、情感分析、 和生成性AI解决方案(如用于制造业图像异常检测的GANS)，以及银行和金融服务中的反洗钱和欺诈检测，均采用NetApp®ONTAP AI®、NetApp®SnapMirror®和NetApp®FlexCache®等NetApp产品和功能。</block>
  <block id="1e79e12b94e448f7c2f614e8ab2794ba" category="section-title">NetApp功能</block>
  <block id="8eb5c2e1d395d77152ca00b1a79915b8" category="paragraph">在聊天机器人、代码生成、图像生成或基因组模型表达等生成型AI应用程序中移动和管理数据可以跨越边缘、私有数据中心和混合多云生态系统。例如、通过ChatGPT等经过预先训练的模型的API公开的最终用户应用程序、帮助乘客将机票升级到商务舱的实时人工智能机器人无法自行完成此任务、因为乘客信息不会在互联网上公开。API要求从航空公司访问乘客的个人信息和机票信息、这些信息可能存在于混合云或多云生态系统中。类似的情形可能适用于科学家通过最终用户应用程序共享药物的一种药物和患者数据、该应用程序使用LLM在涉及一对多生物医学研究机构的药物发现过程中完成临床试验。传递给FMS或LLM的敏感数据可能包括：可识别身份信息、财务信息、运行状况信息、生物识别数据、位置数据、 通信数据、在线行为和法律信息。在这种实时渲染、快速执行和边缘推理事件中、数据会通过开源或专有LLM模型从最终用户应用程序移动到存储端点、然后移动到内部或公共云平台上的数据中心。在所有这类场景中、数据移动性和数据保护对于涉及LLM的AI操作至关重要、因为这类操作依赖于大型训练数据集和此类数据的移动。</block>
  <block id="206f6329180f9a8251d5f78b853663ab" category="inline-image-macro">图4：生成性AI/LLM数据管道</block>
  <block id="f53656abb037d4d852ee5a0b5a765ec7" category="paragraph">图4：生成型AI - LLM数据管道
<block ref="77dc0a477381e81080fe649c6eb25e6a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc004144b88d4fadbbf7623c57d2c805" category="paragraph">NetApp的存储基础架构、数据和云服务产品组合由智能数据管理软件提供支持。</block>
  <block id="7d5e80d61d854ee2e646efedf9f5e72d" category="paragraph">*数据准备*：LLM技术堆栈的第一个支柱与旧的传统ML堆栈基本没有任何不同。AI管道中的数据预处理对于在训练或微调之前对数据进行规范化和清理至关重要。此步骤包括用于以Amazon S3层形式或内部存储系统(例如文件存储或对象存储(例如NetApp StorageGRID)中的任何位置导入数据的连接器。</block>
  <block id="e451293d53e117044a4f8077b1e013f4" category="paragraph">*NetApp NetApp®ONTAP *是NetApp在数据中心和云中的关键存储解决方案的基础技术。ONTAP包括各种数据管理和保护特性和功能、包括针对网络攻击的自动勒索软件保护、内置数据传输特性以及适用于各种架构的存储效率功能、从NAS、SAN、对象、 LLM部署的软件定义的存储(SDS)情况。</block>
  <block id="2dce25b3e49393d99cfa94060c689f6f" category="paragraph">*用于深度学习模型训练的NetApp®ONTAP AI®*。NetApp®ONTAP®支持使用基于RDMA的NFS的NVIDIA GPU Direct Storage™，适用于具有ONTAP存储集群和NVIDIA DGX计算节点的NetApp客户。它可以经济高效地将源数据集从存储读取并处理多次到内存中、以增强智能、从而使组织能够通过培训、微调和扩展对LLM的访问。</block>
  <block id="b5b69ad71b8f5149873353f5c354691a" category="paragraph">* NetApp®FlexCache®*是一种远程缓存功能，它可以简化文件分发并仅缓存正在读取的数据。这对于LLM培训、再培训和微调非常有用、可以为具有实时渲染和LLM推理等业务需求的客户带来价值。</block>
  <block id="dcc998675d28c4f4ccee72c4daa6bf6c" category="paragraph">* NetApp®SnapMX*是一种ONTAP功能，可在任意两个ONTAP系统之间复制卷快照。此功能可以以最佳方式将边缘数据传输到内部数据中心或云。如果客户希望在包含企业数据的RAG中开发生成性AI、则可以使用SnapMirror在内部云和超大型云之间安全高效地移动数据。它可以仅高效传输更改、节省带宽并加快复制速度、从而在FMS或LLM的训练、重新训练和微调操作期间提供基本的数据移动功能。</block>
  <block id="bd91d900ce443c514d6a779770eedf2d" category="paragraph">*ONTAP®SnapLock为基于NetApp的存储系统提供了不可变的磁盘功能，用于数据集版本控制。微核架构旨在通过FPolicy™Zero Trust引擎保护客户数据。当攻击者以特别消耗资源的方式与LLM交互时、NetApp可通过抵御拒绝服务(DoS)攻击来确保客户数据可用。</block>
  <block id="133a830cc0018b040fd905502e8730a5" category="paragraph">* NetApp®云数据感知*有助于识别、映射和分类企业数据集中的个人信息、制定策略、满足内部或云中的隐私要求、帮助改进安全防护并遵守法规。</block>
  <block id="7de80d1bfe84a41db7d756c64c628900" category="paragraph">*由NetApp Data Sense提供支持的Cloud®BlueXP™*分类。客户可以自动扫描、分析、分类和处理数据资产中的数据、检测安全风险、优化存储并加快云部署速度。它通过统一控制平台将存储和数据服务结合在一起、客户可以使用GPU实例进行计算、并使用混合多云环境进行冷存储分层以及归档和备份。</block>
  <block id="a53c242651ba307c28455026c1ab1e07" category="paragraph">NetApp文件-对象双重性*。NetApp ONTAP支持对NFS和S3进行双协议访问。借助此解决方案、客户可以通过NetApp Cloud Volumes ONTAP的S3存储分段从Amazon AWS SageMaker笔记本电脑访问NFS数据。这为需要轻松访问异构数据源并能够共享NFS和S3数据的客户提供了灵活性。  例如、在SageMaker上对FMS进行微调、例如可以访问文件对象分段的Meta的Llama 2文本生成模型。</block>
  <block id="2602c05b6d31cff76fdbe9fdd3c7d374" category="paragraph">* NetApp®Cloud Sync *服务提供了一种简单安全的方法，可以将数据迁移到云端或内部环境中的任何目标。Cloud Sync可在内部或云存储、NAS和对象存储之间无缝传输和同步数据。</block>
  <block id="e53b3c8e83c8d94be048ce5801830a49" category="paragraph">*NetApp XCP*是一款客户端软件，支持快速、可靠地将任何数据迁移到NetApp和NetApp数据迁移到NetApp。XCP还可以高效地将批量数据从Hadoop HDFS文件系统移动到ONTAP NFS、S3或StorageGRID中、而XCP文件分析可提供文件系统可见性。</block>
  <block id="e054bd020520388f61f8adf178362689" category="paragraph">* NetApp®DataOps Toolkit*是一个Python库，数据科学家、开发运营人员和数据工程师可以利用它轻松地执行各种数据管理任务，例如近乎瞬时地配置、克隆或快照数据卷或JupyterLab工作空间，这些工作空间由高性能横向扩展NetApp存储提供支持。</block>
  <block id="978a80b7d2131705bd0e4bf6bf95e096" category="paragraph">*NetApp的产品安全性*。LLM可能会无意中在其响应中泄露机密数据、因此对于研究与利用LLM的AI应用程序相关的漏洞的ISO来说、这是一个顾虑。正如开放全球应用程序安全项目(Open Worldwide Application Security Project、Open Worldwide Application Security Project)所述、数据中毒、数据泄露、拒绝服务和在LLM中迅速注入等安全问题可能会因数据暴露给未经授权的访问服务攻击者而影响企业。数据存储要求应包括结构化、半结构化和非结构化数据的完整性检查和不可变更的快照。NetApp快照和SnapLock用于数据集版本控制。它提供了严格的基于角色的访问控制(Role-Based Access Control、RBAC)以及安全协议和行业标准加密、用于保护空闲和传输中的数据。Cloud Insights和Cloud Data Sense相结合、可帮助您预先确定威胁源并确定要还原的数据的优先级。</block>
  <block id="0364ee2a32c23b9f35e29f68c79d63e1" category="section-title">*采用DGX BasePOD*的ONTAP AI</block>
  <block id="e348d79f742d42c89548cfed1d707c3c" category="paragraph">采用NVIDIA DGX BasePOD的NetApp®ONTAP®AI参考架构是一种适用于机器学习(ML)和人工智能(AI)工作负载的可扩展架构。在LLM的关键训练阶段、通常会定期将数据从数据存储复制到训练集群中。此阶段使用的服务器使用GPU来并行处理各种数据、从而产生巨大的数据需求。满足原始I/O带宽需求对于保持高GPU利用率至关重要。</block>
  <block id="9a05494b8b259619e21e3e78c47f4dc5" category="section-title">*NVIDIA AI企业版的ONTAP AI</block>
  <block id="1ad177c0b9d841f941eb7d5322dc9b52" category="section-title">*1P云平台*</block>
  <block id="ce52fc90039bb5bcf573a4725e92f95c" category="paragraph">完全托管的云存储产品以Azure NetApp Files (ANF)的形式在Microsoft Azure上提供、以Amazon FSx for NetApp ONTAP (FSxN)的形式在AWS上提供、以Google Cloud NetApp Volumes (GNCV)的形式在Google上提供。1P是一款高性能托管文件系统、支持客户在公有云中运行高可用性AI工作负载、并提高数据安全性、以便使用AWS SageMaker、Azaze-OpenAI Services和Google VertexAI等云原生ML平台微调LLM/FMS。</block>
  <block id="64992f0c01704aa99d3bd851b7673bf7" category="section-title">NetApp合作伙伴解决方案套件</block>
  <block id="0e3151175898c0a6687552a854a08b00" category="paragraph">除了核心数据产品、技术和功能之外、NetApp还与强大的AI合作伙伴网络密切合作、为客户带来附加价值。</block>
  <block id="5c682f526a6d29391ad4d45cd7c7cae9" category="paragraph">*人工智能系统中的NVIDIA防护装置*是确保以合乎道德和负责任的方式使用人工智能技术的保障措施。AI开发人员可以选择定义基于LLM的应用程序在特定主题上的行为、并防止他们参与有关不需要的主题的讨论。护栏是一个开源工具包、能够无缝安全地将LLM连接到其他服务、从而构建可靠、安全的LLM对话系统。</block>
  <block id="0b46f95333d136197f1bb757634ebae2" category="paragraph">*Domino Data Lab*提供多用途企业级工具，用于快速、安全、经济地构建生成型AI并将其产品化，无论您处于AI之旅的哪个阶段。借助Domino的企业MLOps平台、数据科学家可以使用首选工具及其所有数据、随时随地轻松训练和部署模型、并经济高效地管理风险-所有这些都可以从一个控制中心完成。</block>
  <block id="bb819c327d064b3c3f2f6e939c5ad7b7" category="paragraph">*Modzy for Edge AI*。NetApp®和Modzy携手合作，为任何类型的数据(包括图像、音频、文本和表格)提供大规模AI。Modzy是一个MLOps平台、用于部署、集成和运行AI模型、为数据科学家提供了模型监控、漂移检测和可解释性的功能、并集成了解决方案以实现无缝的LLM推定。</block>
  <block id="50841f507614d3540c25e7671dc0cdc0" category="paragraph">*Run：AI*和NetApp携手合作、展示NetApp ONTAP AI解决方案与Run：AI集群管理平台的独特功能、以简化AI工作负载的流程编排。它可以自动拆分和连接GPU资源、利用适用于Spark、Ray、dask和Rapids的内置集成框架将数据处理管道扩展到数百台计算机。</block>
  <block id="7f8ef2f7d9a73eb64e35d815049ddd46" category="paragraph">只有在模型基于大量高质量数据进行训练后、生成型AI才能产生有效结果。虽然LMs已经取得了令人瞩目的里程碑式成就、但必须认识到其与数据移动性和数据质量相关的局限性、设计挑战和风险。LMs依赖于来自异构数据源的大型且不同的训练数据集。模型产生的不准确结果或有偏见的结果可能会使企业和消费者处于危险之中。这些风险可能与LLM因数据质量、数据安全性和数据移动性相关的数据管理挑战而面临的限制相对应。NetApp可帮助企业应对因数据快速增长、数据移动性、多云管理和采用AI而带来的复杂性。大规模AI基础架构和高效的数据管理对于定义生成型AI等AI应用程序的成功至关重要。关键在于、客户必须涵盖所有部署情形、同时不影响根据企业需求进行扩展的能力、同时保持成本效益、数据监管和合乎道德的AI实践控制权。NetApp一直致力于帮助客户简化和加快AI部署。</block>
  <block id="a47a30d701c91b6f3e99208cf0007ceb" category="cell">2023年9月19日</block>
  <block id="8a8fb212134a7bd99f920d8c26fd7003" category="cell">增加了白皮书：生成性AI和NetApp价值</block>
  <block id="5b95d24dbc11f9b34c6cf18b07dcf3f7" category="list-text">您还可以使用自定义的备份频率和备份数据保留窗口创建自己的策略。</block>
  <block id="dd06e85eab955d6e3843bf0f5c71961c" category="paragraph"><block ref="dd06e85eab955d6e3843bf0f5c71961c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cfa4396db779261100202ab3f0ffdcd" category="paragraph"><block ref="6cfa4396db779261100202ab3f0ffdcd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a72cdbea9b76d7b6bbbdf396dd2634e3" category="inline-link-macro">NetApp主厨烹饪书</block>
  <block id="85248cff92afa610864cea6879da1e1c" category="inline-link-macro">ONTAP Puppet模块</block>
  <block id="f85439e6fd58c2c10bb7b6282043d280" category="cell">2023年9月29日</block>
  <block id="273d67a1e8ae0816e130d8995b509b2b" category="inline-link-macro">DataOps工具包</block>
  <block id="05da5a25aeee329a7caf8be6493209f7" category="paragraph">单击*创建参数*。
对要监控的所有FSx for ONTAP文件系统重复上述步骤。</block>
  <block id="d79b12332bd4254f1e9cd6c23201a104" category="doc">TR-4722：《基于NetApp ONTAP的MySQL数据库最佳实践》</block>
  <block id="ecb384a7266ef6f8f011aa654a810c39" category="paragraph">Anup Bharti、Manohar Kukarni、JEFEFREY STEiner NetApp</block>
  <block id="4fca42d652144c29317f1a8ee0ccf6b4" category="paragraph">MySQL及其变体(包括MariaDB和Percona)广泛用于许多企业级应用程序。这些应用程序包括全球社交网站和大型电子商务系统、以及包含数千个数据库实例的中小企业托管系统。本文档介绍了在NetApp®ONTAP®数据管理软件上部署MySQL时的配置要求，并提供了有关调整和存储配置的指导。要确定本报告中指定的环境、配置和版本是否支持您的环境、请参阅互操作性表工具(IMT)。</block>
  <block id="74836ad3df3c237074f67acbd8f54d15" category="paragraph"><block ref="74836ad3df3c237074f67acbd8f54d15" category="inline-link-macro-rx"></block></block>
  <block id="d65cd7440cb7c3d2954a848fa38e76ad" category="summary">解决方案提供了一个基于Ans得 的自动化工具包、用于在AWS中配置Oracle数据库高可用性和灾难恢复(High Availability and Disaster Recovery、HA/DR)、其中AWS FSx ONTAP用作Oracle数据库存储、EC2实例用作计算实例。</block>
  <block id="179da6be91ec55cc0787c674958241c1" category="doc">在AWS FSx ONTAP中实现自动化Oracle HA/DR</block>
  <block id="1e7007fdca2061f9d6a2ce2a055e96ef" category="paragraph">NetApp解决方案工程团队</block>
  <block id="f2329a9e32664ebaf897c18c90d9f922" category="paragraph">此工具包可利用FSx for ONTAP存储和EC2计算实例、为部署在AWS云中的Oracle数据库自动执行设置和管理高可用性和灾难恢复(HighAvailability and Disaster Recovery、HR/DR)环境的任务。</block>
  <block id="4a33bb67171f627fe4d6f7f0aab6d032" category="list-text">设置HA/DR目标主机—内核配置、与源服务器主机匹配的Oracle配置。</block>
  <block id="497e7ba562ed7bbfac16fe52b6810372" category="list-text">设置FSx ONTAP—集群对等、Vserver对等、Oracle卷SnapMirror关系设置(从源到目标)。</block>
  <block id="bda57e799072bafeaf42a5313a8206c5" category="list-text">通过Snapshot备份Oracle数据库数据—在crontab下执行</block>
  <block id="5adf1aa082234fb813d8465d075205a9" category="list-text">通过Snapshot备份Oracle数据库归档日志—在crontab下执行</block>
  <block id="4c8c6940cbdf156409787ce0cae0679d" category="list-text">在HA/DR主机上运行故障转移和恢复—测试和验证HA/DR环境</block>
  <block id="041824f980a2368afbea3529f4a85a3b" category="list-text">在故障转移测试后运行重新同步—在HA/DR模式下重新建立数据库卷SnapMirror关系</block>
  <block id="39275aba85b7b3d5e108bf8a7f06b013" category="list-text">在AWS中设置Oracle数据库以实现高可用性、数据保护和灾难恢复的数据库开发人员。</block>
  <block id="98ad1b0bb680f4935dc6ec065ab7dd53" category="list-text">对AWS云中的存储级别Oracle HA/DR解决方案感兴趣的数据库解决方案架构师。</block>
  <block id="7d780f9063c90f956c5b395f01862b2c" category="list-text">负责管理支持Oracle数据库的AWS FSx ONTAP存储的存储管理员。</block>
  <block id="cac0f059e3c711509277efdd488db471" category="list-text">希望在AWS FSX/EC2环境中为HA/DR建立Oracle数据库的应用程序所有者。</block>
  <block id="0baa4333d01c4608c10c4852824e68ad" category="inline-link-macro">许可证文件</block>
  <block id="0407397c670512dcadbf77a1ee9efa74" category="paragraph">访问、下载、安装或使用此GitHub存储库中的内容即表示您同意中列出的许可条款 <block ref="b109f24efb5af51bee6ff86849dfd222" category="inline-link-macro-rx"></block>。</block>
  <block id="eaec65e969505bc6e2570f344e081174" category="admonition">在使用此GitHub存储库中的内容制作和/或共享任何衍生作品方面存在一些限制。在使用内容之前、请确保您已阅读许可条款。如果您不同意所有条款、请勿访问、下载或使用此存储库中的内容。</block>
  <block id="fae7cbbd0ae5df13f97c6dfeea641d7c" category="section-title">下载此工具包</block>
  <block id="613fbd46486706dc14277a2503a8ddad" category="section-title">全局变量配置</block>
  <block id="91cc3cb48c2d9b7fe947f975bb6e12c2" category="paragraph">可变的AnsablePlaybooks驱动。其中包括一个示例全局变量文件FSX_vars_exple.yml、用于演示典型配置。以下是主要注意事项：</block>
  <block id="0c967c2ba96575fe1c2db47376151512" category="section-title">主机变量配置</block>
  <block id="548d628ee47e884858313f141ed3e385" category="paragraph">主机变量在名为｛｛host_name｝｝.yml的host_vars目录中定义。其中包括一个示例主机变量文件host_name.yml、用于演示典型配置。以下是主要注意事项：</block>
  <block id="dc4f36380101bead8c5e803fa39d75ac" category="section-title">数据库服务器主机文件配置</block>
  <block id="405805427d2874a5f24a3b376f51c62a" category="paragraph">默认情况下、AWS EC2实例使用IP地址命名主机。如果您在hosts文件中对Ansv可 使用不同的名称、请在/etc/hosts文件中为源服务器和目标服务器设置主机命名解析。下面是一个示例。</block>
  <block id="ba1f06e05d1c791f2b15c9e1088a97c0" category="section-title">执行操作手册-按顺序执行</block>
  <block id="f438c38014afe1cb719dbcb14f389a74" category="list-text">安装可操作控制器前提条件。</block>
  <block id="4fd73e564820faeafea813887ea61f6f" category="list-text">设置目标EC2数据库实例。</block>
  <block id="7cfc03bc74a1c83d93eecac222f51283" category="list-text">在源数据库卷和目标数据库卷之间设置FSx ONTAP SnapMirror关系。</block>
  <block id="ad995c0821f0dec2ecd6c5d1361b2ee1" category="list-text">通过Snapshot从crontab备份Oracle数据库数据卷。</block>
  <block id="06ddbe5b0f86c1d7fdff984cbe3f2ef5" category="list-text">通过Snapshot从crontab备份Oracle数据库归档日志卷。</block>
  <block id="4ffffdfa8108984ff063883f05b2cb05" category="list-text">在目标EC2数据库实例上运行故障转移并恢复Oracle数据库—测试和验证HA/DR配置。</block>
  <block id="665aea4799536e845b4d19fc4b3e4ee9" category="list-text">在故障转移测试后运行重新同步—在复制模式下重新建立数据库卷SnapMirror关系。</block>
  <block id="13b6326e5a684ad1d8a9de13b31a2069" category="paragraph">要了解有关NetApp 解决方案 自动化的详细信息、请查看以下网站 <block ref="03bbd03f7d2552fa2076b42f86a04360" category="inline-link-macro-rx"></block></block>
  <block id="784f4d9bc2efa477eafb911859744478" category="summary">解决方案提供了使用AWS FSx ONTAP作为备用站点Oracle数据库存储来配置Oracle Data Guard的概述和详细信息、以降低AWS中Oracle Data Guard HA/DR解决方案的许可和运营成本。</block>
  <block id="f9ca3bf31876c6185710d49eac400cfe" category="paragraph">Oracle Data Guard可确保主数据库和备用数据库复制配置中企业数据的高可用性、数据保护和灾难恢复。Oracle Active Data Guard使用户能够在从主数据库到备用数据库的数据复制处于活动状态时访问备用数据库。Data Guard是Oracle数据库企业版的一项功能。它不需要单独的许可。另一方面、Active Data Guard是Oracle数据库企业版选件、因此需要单独的许可。在Active Data Guard设置中、多个备用数据库可以从主数据库接收数据复制。但是、每个附加备用数据库都需要Active Data Guard许可证以及与主数据库大小相同的额外存储。运营成本会迅速增加。</block>
  <block id="1373f5f0167ef176e393747ff34f4b37" category="list-text">在关闭以进行数据复制的情况下克隆备用数据库、以满足报告、开发、测试等使用情形的要求</block>
  <block id="b7224dd0f37ea7dba810e399e48f1e1f" category="list-text">在AWS中设置Oracle Active Data Guard以实现高可用性、数据保护和灾难恢复的数据库管理人员。</block>
  <block id="550c8c85ffce2de3188f9704c188de3c" category="list-text">对AWS云中的Oracle Active Data Guard配置感兴趣的数据库解决方案架构师。</block>
  <block id="e4efb5457095eb4b55bfc3c725c45bc6" category="list-text">负责管理支持Oracle Data Guard的AWS FSx ONTAP存储的存储管理员。</block>
  <block id="3b6ea806d7ca3ec3483737a2c6b96a47" category="list-text">希望在AWS FSX/EC2环境中部署Oracle Data Guard的应用程序所有者。</block>
  <block id="bc91f44d9c65e0ff00460fc3cbf1d4a7" category="paragraph">此解决方案的测试和验证是在AWS FSx ONTAP和EC2实验室环境中执行的、该环境可能与最终部署环境不匹配。有关详细信息，请参见一节 <block ref="8ea96e516bccf9a47ca2d74131eb7519" category="inline-xref-macro-rx"></block>。</block>
  <block id="952689151ce0aec7f82b269a33a2d561" category="image-alt">此图详细展示了使用FSxN在AWS中实施的Oracle Data Guard。</block>
  <block id="2121dc715f8fee4210e0374eb562c84d" category="cell">三个EC2 T2大型EC2实例、一个用作主数据库服务器、一个用作备用数据库服务器、第三个用作克隆数据库服务器</block>
  <block id="ca8a675d4efb691e78dedc948041f3b6" category="section-title">采用从纽约到洛杉矶灾难恢复的假设设置的Oracle Data Guard配置</block>
  <block id="7a8d3dc7f0e719542e9e706dbca4f3ec" category="cell">* 数据库 *</block>
  <block id="6e63145f93e8264084d51b8487d8bb5a" category="cell">*DB_UNIQUE_NAME*</block>
  <block id="08ede96534ff1efd5b0193eda6efd01c" category="cell">*Oracle Net Service Name*</block>
  <block id="074de7e7c226d5c60f8af14c20725352" category="cell">主卷</block>
  <block id="668f361c1cd1909a84f76c9e89450691" category="cell">DB1_NY</block>
  <block id="31cedb742316bfb63604cb838e2fbd67" category="cell">db1_NY.demo.netapp.com</block>
  <block id="0bb7066f912b36d8b2abd23b39aea8bf" category="cell">物理备用</block>
  <block id="3b1ac5a2383d6bae39c010102ab76ec8" category="cell">DB1_LA</block>
  <block id="12eea44985687889a715748b159aacb5" category="cell">db1_LA.demo.netapp.com</block>
  <block id="96686b873db5b24893df16faa4703808" category="list-text">*Oracle备用数据库FlexClone的工作原理。* AWS FSx ONTAP FlexClone为可写的同一备用数据库卷提供共享副本。卷的副本实际上是指向原始数据块的指针、直到克隆开始新的写入为止。然后、ONTAP会为新写入分配新的存储块。所有读取IO都由活动复制下的原始数据块提供服务。因此、克隆的存储效率非常高、可用于许多其他使用情形、只需为新写入IO分配最少的增量新存储即可。这样可以大幅减少Active Data Guard存储占用空间、从而显著节省存储成本。NetApp建议在数据库从主存储切换到备用FSx存储时尽量减少FlexClone活动、以便将Oracle性能保持在较高水平。</block>
  <block id="714b6519d8509d6b6dd2df24196f06e4" category="inline-link-macro">support.oracle.com</block>
  <block id="152b17ea33225ac5ef2e7e8c31552009" category="list-text">* Oracle软件要求。*一般来说、物理备用数据库必须与主数据库具有相同的Database Home版本、包括修补程序集例外(Patch Set例外、PSE)、关键修补程序更新(Critical Patch Update、CPU)、 和补丁集更新(PSU)、除非正在执行Oracle Data Guard Standby-First Patch Apply进程(如上的My Oracle Support note 1265700.1中所述) <block ref="d99e1f6f4fd91fa805a3e3c6b994744c" category="inline-link-macro-rx"></block></block>
  <block id="9a74dfee83f901bbb995e7d4d9f21057" category="list-text">*备用数据库目录结构注意事项。*如果可能、主系统和备用系统上的数据文件、日志文件和控制文件应具有相同的名称和路径名称、并使用最佳灵活架构(OFA)命名约定。备用数据库上的归档目录也应在站点之间完全相同、包括大小和结构。此策略允许备份、切换和故障转移等其他操作执行相同的步骤集、从而降低维护复杂性。</block>
  <block id="76d62bcf48e1a8f37c916496440df6b5" category="list-text">*强制日志记录模式。*要防止主数据库中未记录的无法传播到备用数据库的直接写入、请在执行数据文件备份以创建备用数据库之前、在主数据库中启用强制日志记录。</block>
  <block id="6aab76a9832cdc4aedf822409a67b715" category="list-text">*数据库存储管理。*为简化操作、Oracle建议在Oracle Data Guard配置中设置Oracle自动存储管理(Oracle ASM)和Oracle托管文件(Oracle Managed Files、OMF)时、在主数据库和备用数据库上对称设置。</block>
  <block id="89a78e9473b16ecb4c8c28739f77fbbf" category="list-text">*EC2计算实例。*在这些测试和验证中，我们使用AWS EC2 T2.xlea占用 空间实例作为Oracle数据库计算实例。NetApp建议在生产部署中使用M5类型的EC2实例作为Oracle的计算实例、因为它已针对数据库工作负载进行了优化。您需要根据实际工作负载要求根据vCPU数量和RAM量适当调整EC2实例的大小。</block>
  <block id="891a36218aaef7e59d635d4a02fcd917" category="list-text">* FSX存储HA集群单区域或多区域部署。*在这些测试和验证中、我们在一个AWS可用性区域中部署了一个FSX HA集群。对于生产部署、NetApp建议在两个不同的可用性区域中部署一个FSX HA对。FSx集群始终配置在HA对中、该HA对会在一对主动-被动文件系统中同步镜像、以提供存储级别冗余。多区域部署可在单个AWS区域发生故障时进一步提高高可用性。</block>
  <block id="7714e62713b517325d1dbcb277ffec72" category="paragraph">我们假定您已将主Oracle数据库部署在VPC中的AWS EC2环境中、并以此作为设置Data Guard的起点。主数据库使用Oracle ASM进行部署以进行存储管理。  为Oracle数据文件、日志文件和控制文件等创建了两个ASM磁盘组-+data和+logs 有关使用ASM在AWS中部署Oracle的详细信息、请参阅以下技术报告以获得帮助。</block>
  <block id="88b61a3452017ca36f5aa8c16a481cdc" category="paragraph">主Oracle数据库可以运行在FSx ONTAP上、也可以运行在AWS EC2生态系统中的任何其他可选存储上。下一节介绍了在使用ASM存储的主EC2数据库实例与使用ASM存储的备用EC2数据库实例之间设置Oracle Data Guard的分步部署过程。</block>
  <block id="48c88f2a91b527275016272b31c75e1b" category="list-text">在AWS EC2控制台中、您至少需要部署三个EC2 Linux实例、一个作为主Oracle数据库实例、一个作为备用Oracle数据库实例、一个克隆目标数据库实例用于报告、开发和测试等 有关环境设置的详细信息、请参见上一节中的架构图。另请查看AWS <block ref="b75ecbbec453f67f58d497ccd97a8075" category="inline-link-macro-rx"></block> 有关详细信息 ...</block>
  <block id="193808e0311479eb0cb075549cfb7b49" category="list-text">从AWS EC2控制台中、部署Amazon FSx for ONTAP存储HA集群以托管存储Oracle备用数据库的Oracle卷。如果您不熟悉FSX存储的部署、请参见相关文档 <block ref="17d8b312d287f0afd6f44b3f25c4f20b" category="inline-link-macro-rx"></block> 了解分步说明。</block>
  <block id="de6e6d5e21c4f7d0dd4ef74edf3eb0c8" category="section-title">为Data Guard准备主数据库</block>
  <block id="4c47bc26cdbea7cfef6220602d142b03" category="paragraph">在此演示中、我们已在主EC2数据库实例上设置了一个名为db1的主Oracle数据库、其中两个ASM磁盘组采用独立的Restart配置、数据文件位于ASM磁盘组+data中、闪存恢复区域位于ASM磁盘组+logs中。下面说明了为Data Guard设置主数据库的详细过程。所有步骤均应以数据库所有者Oracle用户身份执行。</block>
  <block id="546bfa96e0a0fe70a11d127711d7cf98" category="list-text">主EC2数据库实例IP-172-30-15-45上的主数据库db1配置。ASM磁盘组可以位于EC2生态系统中的任何类型的存储上。</block>
  <block id="f3efbb87660ec6fc6923520ba7c0e4b6" category="list-text">从sqlplus中、在主系统上启用强制日志记录。</block>
  <block id="851a2cc6266fe01721754a67b63d272b" category="list-text">从sqlplus中、在主系统上启用回闪。通过回闪、可以在故障转移后轻松地将主数据库恢复为备用数据库。</block>
  <block id="1456924ad439596396b0366750feb882" category="list-text">使用Oracle密码文件配置重做传输身份验证—如果未设置、请使用orapwd实用程序在主系统上创建一个pwd文件、然后复制到备用数据库$oracle_HOME/dbs目录。</block>
  <block id="b84ef5068c2f6a0e7ab5c634421500e4" category="list-text">在主数据库上创建与当前联机日志文件大小相同的备用重做日志。日志组比联机日志文件组多一个。然后、主数据库可以根据需要快速过渡到备用角色并开始接收重做数据。</block>
  <block id="b8dcabc8241b7fa9922b791123f161c6" category="list-text">从sqlplus中、从spfile创建一个要编辑的pfile。</block>
  <block id="a58bc66502bff24a62e9167f326de414" category="list-text">修改pfile并添加以下参数。</block>
  <block id="16df6366013fa1b51fdf63103f5de61c" category="list-text">从sqlplus中、从/HOME/oracle目录中经过修订的pfile在ASM +data目录中创建spfile。</block>
  <block id="be5835a569bacd58dbd2984013ec9da7" category="list-text">在+data disk group下找到新创建的spfile (如有必要、请使用asmcmd实用程序)。使用srvCTL)修改网格，以便从新的spfile启动数据库，如下所示。</block>
  <block id="721f734d4d55c537a4bcd8247cb42f38" category="list-text">修改tnsnames.ora以添加db_UNIQUE_NAME进行名称解析。</block>
  <block id="ff9562404eb9d339e5f7ac0fd7a0a111" category="list-text">将主数据库的数据防护服务名称db1_NY_DGMGRL.demo.netapp添加到listener.ora文件中。</block>
  <block id="f0dcdb53dfe79df7c33ad468e718cf3c" category="list-text">使用srvCTL关闭 并重新启动数据库，并验证数据保护参数现在是否处于活动状态。</block>
  <block id="0a3ecc4b9c7f192a3a8eff9f43d62a49" category="paragraph">至此、Data Guard的主数据库设置完成。</block>
  <block id="8ed94134ccc7df045497fffb338e491e" category="section-title">准备备用数据库并激活Data Guard</block>
  <block id="25df9ef065954340ff37157530509f47" category="paragraph">Oracle Data Guard要求操作系统内核配置和Oracle软件堆栈(包括备用EC2数据库实例上的修补程序集)与主EC2数据库实例匹配。为了便于管理和简化、备用EC2数据库实例数据库存储配置也应与主EC2数据库实例(例如ASM磁盘组的名称、数量和大小)完美匹配。下面是为Data Guard设置备用EC2数据库实例的详细过程。所有命令都应以Oracle所有者用户id的身份执行。</block>
  <block id="100d87382d4e9f0b77c8fbd50ae70cf2" category="list-text">首先、查看主EC2实例上的主数据库配置。在此演示中、我们已在主EC2数据库实例上设置了一个名为db1的主Oracle数据库、其中两个ASM磁盘组+data和+logs采用独立的Restart配置。主ASM磁盘组可以位于EC2生态系统中的任何类型的存储上。</block>
  <block id="34754319c23ee13eb7a5d5a802622e85" category="list-text">请按照文档中的步骤进行操作 <block ref="bd945e1e32897f5f009e986b39da694c" category="inline-link-macro-rx"></block> 在备用EC2数据库实例上安装和配置GRID和Oracle以与主数据库匹配。应配置数据库存储、并将其分配给FSx ONTAP中的备用EC2数据库实例、其存储容量应与主EC2数据库实例相同。</block>
  <block id="18b8757dc8f63de46858f8a4f433e251" category="admonition">在中的步骤10处停止<block ref="b7e3e332087b6a041c83ce22cce9043c" prefix=" " category="inline-code"></block> 部分。备用数据库将使用dbca数据库复制功能从主数据库中进行初始化。</block>
  <block id="3b2b93ec0c82f6e3a38fad684bfd6663" category="list-text">安装并配置Oracle软件后、从standby $oracle_home DBS目录中、从主数据库复制Oracle密码。</block>
  <block id="3aa916a972ab6509dee982918f3d899e" category="list-text">使用以下条目创建tnsnames.ora文件。</block>
  <block id="493f867c0c59207e4189028d16dd6d26" category="list-text">将数据库数据防护服务名称添加到listener.ora文件。</block>
  <block id="bcd6424f66bc448fbe685fc80ff70e1a" category="list-text">设置Oracle主目录和路径。</block>
  <block id="143a60719ec63d00d99a825714665a55" category="list-text">使用dbca从主数据库db1中对备用数据库进行初始化。</block>
  <block id="57fbd0472b92ebaf5a1a0a8528a2f0a8" category="list-text">验证重复的备用数据库。新复制的备用数据库最初以只读模式打开。</block>
  <block id="3e003fdb2211d99cead68668fab65036" category="list-text">在中重新启动备用数据库<block ref="19822b1b15d9eefc54c07ab49f87b100" prefix=" " category="inline-code"></block> 暂存并执行以下命令以激活备用数据库受管恢复。</block>
  <block id="e87af5ff6c25c9c1c0fdf389aea9426b" category="list-text">验证备用数据库恢复状态。请注意<block ref="9bda3daa17eb022a72164386ee4bf249" prefix=" " category="inline-code"></block> 在中<block ref="1f38735e57e053804f3980f01073a19b" prefix=" " category="inline-code"></block> 操作。</block>
  <block id="d418efa4afda10fc6b0130047c165f48" category="paragraph">这样就完成了在启用受管备用恢复的情况下、将db1从主存储到备用存储的Data Guard保护设置。</block>
  <block id="9c88c2ff7d57ccdc26ed6cc8c6a551d8" category="section-title">设置Data Guard代理</block>
  <block id="e716a36152601014d22404c34a545dfb" category="paragraph">Oracle Data Guard代理是一个分布式管理框架、可自动集中创建、维护和监控Oracle Data Guard配置。以下部分演示如何设置Data Guard Broker以管理Data Guard环境。</block>
  <block id="ae65cf354bdba5f399cecafe69181bb2" category="list-text">通过sqlplus使用以下命令在主数据库和备用数据库上启动数据防护代理。</block>
  <block id="7085ea049485ef36270b678214c896bc" category="list-text">从主数据库中、作为SYSDBA连接到Data Guard Borker。</block>
  <block id="e3e1655d27b7ec5fede117507abebc04" category="list-text">创建并启用Data Guard Broker配置。</block>
  <block id="bf87cf945b0165017223255d29eb5838" category="list-text">在Data Guard Broker管理框架内验证数据库状态。</block>
  <block id="d3ee713ceb1d01a3c56111f66bf8cef8" category="paragraph">发生故障时、可以使用Data Guard Broker将主数据库瞬时故障转移到备用数据库。</block>
  <block id="c4b565b8f619a1841207c12605df0bdc" category="section-title">克隆备用数据库以用于其他使用情形</block>
  <block id="2f2d5e4f7687bc11754fc0051b64a5a8" category="paragraph">在Data Guard中的AWS FSx ONTAP上暂存备用数据库的主要优势在于、可以通过FlexCloned以最少的额外存储投资来处理许多其他用例。在下一节中、我们将演示如何在FSx ONTAP上为已挂载和正在恢复的备用数据库卷创建快照和克隆以用于其他目的、例如开发、测试、报告等。 使用NetApp SnapCenter工具。</block>
  <block id="65373b5acaf68c44756a21bcfb515cf6" category="paragraph">下面简要介绍了使用SnapCenter从Data Guard中托管的物理备用数据库克隆读/写数据库的过程。有关如何设置和配置SnapCenter的详细说明、请参阅 <block ref="abd45cc4d2eb76c4bd20bec40a5e9781" category="inline-link-macro-rx"></block> Relavant Oracle (重新初始Oracle)部分。</block>
  <block id="a225c0845c18b63c94952d45800129eb" category="list-text">我们首先创建一个测试表、然后在主数据库的测试表中插入一行。然后、我们将验证事务是否向下遍历到备用、最后遍历克隆。</block>
  <block id="815578506a24796bc380c0deef04702e" category="list-text">将FSx存储集群添加到<block ref="5c6ab1284b6b7a5a7102854a969c99be" prefix=" " category="inline-code"></block> 在具有FSx集群管理IP和fsxadmin凭据的SnapCenter中。</block>
  <block id="4d4fbfa1c7c19b55ec3f48a0d412d8eb" category="list-text">将AWS EC2-user添加到<block ref="03bc142e6422dbb9b288ad2cabee08c7" prefix=" " category="inline-code"></block> 在中<block ref="f4f70727dc34561dfde1a3c529b6205c" prefix=" " category="inline-code"></block>。</block>
  <block id="6aa54e14f0875581094dc6b2192d66b3" category="list-text">添加备用EC2数据库实例并将EC2数据库实例克隆到<block ref="8124579383e90243e4b06323d2b37f8d" prefix=" " category="inline-code"></block>。</block>
  <block id="3b1e0e523773d1a64309d849962b020d" category="admonition">克隆EC2数据库实例应安装和配置类似的Oracle软件堆栈。在我们的测试案例中、安装并配置了网格基础架构和Oracle 19C、但未创建数据库。</block>
  <block id="0d3c38b30657980a0b2c8d695bdc04d9" category="list-text">创建为脱机/挂载完整数据库备份而定制的备份策略。</block>
  <block id="03749905cda41a9a5af37311da788dc7" category="list-text">在中应用备份策略以保护备用数据库<block ref="ddcf50c29294d4414f3f7c1bbc892cb5" prefix=" " category="inline-code"></block> 选项卡。</block>
  <block id="4b541cfd01eab70b7124c0a9281d9abf" category="list-text">单击数据库名称以打开数据库备份页面。选择要用于数据库克隆的备份、然后单击<block ref="ff24590464659ee8cdec688128c35f89" prefix=" " category="inline-code"></block> 用于启动克隆工作流的按钮。</block>
  <block id="2fdf9c5dfda12930fd177f22620253c6" category="list-text">选择 ...<block ref="6d966589c645cae872f42060de0bbe70" prefix=" " category="inline-code"></block> 并将克隆实例命名为SID。</block>
  <block id="2bdb6fd7703480f999a0decdea3783dc" category="list-text">选择克隆主机、此主机用于托管备用数据库中的克隆数据库。接受数据文件、控制文件和重做日志的默认设置。将在克隆主机上创建两个ASM磁盘组、它们与备用数据库上的磁盘组对应。</block>
  <block id="7b2116fe35be064eb0458bc516aa4d13" category="list-text">基于操作系统的身份验证不需要数据库凭据。将Oracle主目录设置与克隆EC2数据库实例上配置的设置进行匹配。</block>
  <block id="ff5976c8af9ff4b0957fafc90bc2fdab" category="list-text">根据需要更改克隆数据库参数、并指定要在回放之前运行的脚本(如果有)。</block>
  <block id="34685717b91981d7859ecf81678b5b09" category="list-text">输入要在克隆后运行的SQL。在演示中、我们执行了一些命令来关闭开发/测试/报告数据库的数据库归档模式。</block>
  <block id="d197c170bbaec3c7352356cf0cbb8ac1" category="list-text">根据需要配置电子邮件通知。</block>
  <block id="6f8f71975bdd986583495fef78017b0f" category="list-text">查看摘要、单击<block ref="a20ddccbb6f808ec42cd66323e6c6061" prefix=" " category="inline-code"></block> 以启动克隆。</block>
  <block id="22d02716c7a3c135a2c329f25e9bd9ae" category="list-text">在中监控克隆作业<block ref="d2986ac8cb6bd55892099c1ffd6b1f6f" prefix=" " category="inline-code"></block> 选项卡。我们发现、克隆数据库卷大小约为300 GB的数据库大约需要8分钟。</block>
  <block id="39f89201f1ea425071614bb5bd7079a3" category="list-text">验证SnapCenter中的克隆数据库、该数据库会立即注册到中<block ref="ddcf50c29294d4414f3f7c1bbc892cb5" prefix=" " category="inline-code"></block> 克隆操作后立即单击选项卡。</block>
  <block id="8bf431d7e50f6303bf40547e5d4895df" category="list-text">从克隆EC2实例查询克隆数据库。我们验证了主数据库中发生的测试事务已向下遍历到克隆数据库。</block>
  <block id="956670247c2a1898065893fdcbce36e6" category="paragraph">这样就可以从FSx存储上的Data Guard中的备用数据库克隆和验证新的Oracle数据库、以供开发、测试、报告或任何其他使用情形使用。在Data Guard中、可以从同一备用数据库克隆多个Oracle数据库。</block>
  <block id="33b688f7c946852447f97b29aa780fe5" category="list-text">Data Guard概念和管理</block>
  <block id="8de2fc4ad1f7fa0dce48702c017a0131" category="inline-link-macro"><block ref="8de2fc4ad1f7fa0dce48702c017a0131" category="inline-link-rx"></block></block>
  <block id="f4b13dd9902b833ab09c8b2e85ee348f" category="paragraph"><block ref="f4b13dd9902b833ab09c8b2e85ee348f" category="inline-link-macro-rx"></block></block>
  <block id="ba976162adc7c0619bf3a1f2c24454f2" category="list-text">WP-7357：《基于EC2和FSx的Oracle数据库部署最佳实践》</block>
  <block id="a365d6dca7b395f6a6b72ec8b5827a23" category="inline-link-macro"><block ref="a365d6dca7b395f6a6b72ec8b5827a23" category="inline-link-rx"></block></block>
  <block id="4e373bf0e0fd6e32269c2aab88e54fb4" category="paragraph"><block ref="4e373bf0e0fd6e32269c2aab88e54fb4" category="inline-link-macro-rx"></block></block>
  <block id="0502e6755528910223db364699e71622" category="doc">TR-4590：《采用ONTAP的Microsoft SQL Server最佳实践指南》</block>
  <block id="7788b16f8e56867380c0e39b9e9a9b73" category="paragraph">Manohar Kukarni和Pat Sinthusan、NetApp</block>
  <block id="b9cbe6804d5d84ce7a89f43558ac30e6" category="paragraph">本文档介绍了在运行NetApp ONTAP®软件的NetApp存储系统上部署SQL Server的最佳实践并深入介绍了设计注意事项，目的是实现高效的存储部署以及端到端数据保护和保留规划。</block>
  <block id="ddfcd18933c13e026412b8c36996dbaf" category="inline-link-macro">TR-4590：《采用ONTAP的Microsoft SQL Server最佳实践指南》</block>
  <block id="49814a6b08319963f5bef4f7ea99cfb5" category="paragraph"><block ref="49814a6b08319963f5bef4f7ea99cfb5" category="inline-link-macro-rx"></block></block>
  <block id="b809961749987c861856cdba226ec9d6" category="summary">解决方案提供了一个基于Ans得 的自动化工具包、用于通过PDB重新定位和最大可用性方法迁移Oracle数据库。迁移可以是内部环境和云作为源或目标的任意组合</block>
  <block id="efe4709bf33362b47c6863c35ca74034" category="doc">自动化Oracle迁移</block>
  <block id="0c530f43a566539fb8e9da49f0404689" category="paragraph">此工具包可利用FSx ONTAP存储和EC2计算实例作为目标基础架构、自动将Oracle数据库从内部迁移到AWS云。假定客户已在CDB/PDB模型中部署了内部Oracle数据库。该工具包允许客户使用Oracle PDB重新定位操作步骤(具有最大可用性选项)从Oracle主机上的容器数据库重新定位命名PDB。这意味着、任何内部存储阵列上的源PDB都会重新定位到新容器数据库、而服务中断量极小。Oracle重新定位操作步骤将在数据库联机时移动Oracle数据文件。之后、当所有数据文件迁移到AWS云时、它会在切换时将用户会话从内部重新路由到重新定位的数据库服务。突出显示的技术是经验证的Oracle PDB热克隆方法。</block>
  <block id="2243370defca1a4982b4883641ab7db6" category="list-text">在内部源数据库服务器上创建迁移用户并授予所需权限。</block>
  <block id="c0e736291b01799f9f67b55a02e64b14" category="list-text">在源PDB处于联机状态时、将PDB从内部CDB重新定位到云中的目标CDB、直到切换为止。</block>
  <block id="491c7279129ef66f3b72abb0fa1c5226" category="list-text">将Oracle数据库从内部环境迁移到AWS云的数据库管理人员。</block>
  <block id="01afc77b414372b3af135907ed869982" category="list-text">一名数据库解决方案架构师、对从内部环境向AWS云迁移Oracle数据库感兴趣。</block>
  <block id="e41dc9cf512ed2ab6c255a63a5f967b4" category="list-text">喜欢将Oracle数据库从内部环境迁移到AWS云的应用程序所有者。</block>
  <block id="ed893dd012b708a5fd2d5f084ab862fb" category="paragraph">默认情况下、AWS EC2实例使用IP地址命名主机。如果您在hosts文件中对Ansv可 使用不同的名称、请在/etc/hosts文件中为源服务器和目标服务器设置主机命名解析。下面是一个示例。</block>
  <block id="d3518be78ee50170d8c5adafaa49ddaa" category="list-text">安装Ands负责 控制器的前提条件。</block>
  <block id="fc6c92008801d751651a5b8d0facab6e" category="list-text">对内部服务器执行迁移前任务—假设管理员是ssh用户、可使用sudo权限连接到内部Oracle主机。</block>
  <block id="f4c57f09769c649b5fc9d173ca0b0872" category="list-text">在AWS EC2实例中执行Oracle PDB从内置CDB到目标CDB的重新定位—假设EC2数据库实例连接为ec2-user、而使用EC2-user ssh密钥对执行db1.pm。</block>
  <block id="4bea7b97045c9b0e4ce9c8011fb9152f" category="summary">解决方案提供了一个基于Terraform的自动化工具包、用于配置FSx ONTAP集群和EC2计算实例</block>
  <block id="40fe82be1dcddf04fa06215186892fca" category="doc">AWS FSx ONTAP集群和EC2实例配置</block>
  <block id="e3637f41b7212e1a66abdc03f5c26148" category="paragraph">此工具包可自动执行AWS FSx ONTAP存储集群和EC2计算实例的配置任务、这些实例随后可用于数据库部署。</block>
  <block id="03a4416e24ed4a9b0f3d357eb5ee56b6" category="list-text">在AWS云中的预定义VPC子网中配置EC2计算实例、并将用于EC2实例访问的ssh密钥设置为EC2-user。</block>
  <block id="44188940066649e119396216339b4869" category="list-text">在所需的可用性区域中配置AWS FSx ONTAP存储集群、配置存储SVM并设置集群管理员用户fsxadmin密码。</block>
  <block id="8c695812e6b1d0da09e4112dcc98afd8" category="list-text">在AWS EC2环境中管理数据库的数据库管理员。</block>
  <block id="db0b5d976134ac432c6b546956e1fc38" category="list-text">对AWS EC2生态系统中的数据库部署感兴趣的数据库解决方案架构师。</block>
  <block id="15c649f61e0d97ef85f0d2d224019197" category="list-text">负责管理支持数据库的AWS FSx ONTAP存储的存储管理员。</block>
  <block id="bb09d79b045e0d8930bca68ba2651754" category="list-text">喜欢在AWS EC2生态系统中建立数据库的应用程序所有者。</block>
  <block id="27fdb8c570948be4eb4398435585214b" category="section-title">连接和身份验证</block>
  <block id="c69ff338618074e4998292b223cb19e5" category="paragraph">该工具包应从AWS云Shell执行。AWS云Shell是一种基于浏览器的Shell、可用于轻松安全地管理、浏览AWS资源并与之进行交互。CloudShell会使用您的控制台凭据进行预身份验证。通用开发和运营工具已预先安装、因此无需在本地安装或配置。</block>
  <block id="0669fa7d1422db0d2c494b9d3a9ff1fe" category="section-title">Terraform提供程序.tf和main.tf文件配置</block>
  <block id="08fcc92ec353c4f98b1154a2f8544890" category="paragraph">提供程序.tf定义了Terraform通过API调用配置资源的提供程序。main.tf定义了要配置的资源和资源的属性。下面是一些详细信息：</block>
  <block id="67761b4e694cd5f5a45c4ed0cc314099" category="section-title">Terraform variations.tf和terraform.tfvars配置</block>
  <block id="fd5f90c196b871dc50ecaf85f49b1656" category="paragraph">variables．tf声明了要在main.tf中使用的变量。terraform.tfvars包含变量的实际值。下面是一些示例：</block>
  <block id="7215ebabbf870f26836f50f66cc5b6fd" category="section-title">逐步过程-按顺序执行</block>
  <block id="43c9b395c61de869dc87f1da35eed2e4" category="list-text">在AWS云Shell中安装Terraform。</block>
  <block id="fc3090054fced18dc06b7eb57b234758" category="list-text">从NetApp GitHub公共站点下载该工具包</block>
  <block id="a9c7e2c70153c59e87147abf329cbb29" category="list-text">运行init以初始化terraform</block>
  <block id="3165803a1a69113b1f417123a736b5ac" category="list-text">输出执行计划</block>
  <block id="fbe54173b4068c6e761f53f237a17b68" category="list-text">应用执行计划</block>
  <block id="17f070e48ce0935f57d600652c3c8f21" category="list-text">完成后、运行销毁以删除资源</block>
  <block id="839a5e9d346e3ac874bc8e301897bdc6" category="list-text">从网格主页解压缩<block ref="63628571f2dfaeb6f0a0a676290e6e82" prefix=" " category="inline-code"></block>。</block>
  <block id="f2be6b31ed6989aef561023d439a1cd3" category="list-text">从DB主目录中、解压缩<block ref="63628571f2dfaeb6f0a0a676290e6e82" prefix=" " category="inline-code"></block>。</block>
  <block id="9d816887d40a5251f5427d7cacd2c573" category="sidebar">Microsoft SQL Server与ONTAP最佳实践指南</block>
  <block id="a778c2474db5f0263c74583332c37399" category="sidebar">基于NetApp ONTAP的MySQL数据库</block>
  <block id="ca2e1a380482fd9930ca46613b332f65" category="sidebar">DB自动化工具包</block>
  <block id="b10be6167fc647935cb532890f8c0bf5" category="sidebar">Oracle迁移</block>
  <block id="d8c849deb1477c8cfaee422dd193388f" category="sidebar">采用AWS FSx ONTAP的Oracle HA/DR</block>
  <block id="66dad052ac40ee68d24cc33be0c024b6" category="sidebar">AWS FSx ONTAP和EC2配置</block>
  <block id="e3ce8983bc629b4ee630222fd3aa446f" category="sidebar">在AWS中部署PostgreSQL</block>
  <block id="41d1f90d40c880117fe398482ef683dd" category="sidebar">Oracle数据保护</block>
  <block id="d24600498de924ea279e7306aaa43ca0" category="sidebar">Oracle RAC部署</block>
  <block id="c712825b20324ef1f5b77e495f50777c" category="list-text">导航回AWS Lamb另 一个函数&gt;*添加图层*&gt;*自定义图层*并添加实用程序图层。</block>
  <block id="8c3dbb053dda6aee3d1fc3bfcc03f78a" category="cell">(必需)列出要监控的所有FSx for ONTAP文件系统。
将所有文件系统包括在列表中以进行监控和自动调整大小。</block>
  <block id="e72dd584580bc1e71f12013e4a8d39c9" category="video-title">使用Astra Control Center保护数据</block>
  <block id="258dff02bafa822fdd86173cf3a704fd" category="inline-link-macro">在GCP上安装OpenShift集群</block>
  <block id="2926145a214ac6dbc8f3f80370e5b50e" category="paragraph">解决方案的方案1、2和3已使用下表所示的版本进行了验证：</block>
  <block id="4fd901052de585857b44590ade8bb1d7" category="paragraph">已使用下表所示的版本对解决方案的方案4进行了验证：</block>
  <block id="55ccbda3d22fd26419c5a289a561f8ab" category="cell">vSphere Client 8.0.2.00000版
VMware ESXi 8.0.2、22380479</block>
  <block id="ea29b1a558b1279ead0fbad0665e0643" category="cell">OpenShift 4.13.13.</block>
  <block id="bac685b53393219a59fa413aa6268ff9" category="cell">OpenShift 4.13.12.
内部部署和Google Cloud中</block>
  <block id="06b448ec5f485f402ba65629ece523fa" category="cell">TRIdent服务器和客户端23.07.0</block>
  <block id="f77d3e3fa77cd2d81cd0e587f696d0c9" category="cell">符合23.07.0-25标准</block>
  <block id="bd92684886c3b8e5ae4c9d6659e6d2c1" category="cell">* Cloud Volumes ONTAP *</block>
  <block id="db45e12150cbd94d6d40ba4bbb0ca975" category="cell">单可用性(AZ)、单节点、9.14.0</block>
  <block id="cb512faae75bcf972ef4805cd0eb9f65" category="paragraph">此页面显示了在VMware vSphere上运行的基于Red Hat OpenShift容器的应用程序的数据保护选项、或者使用Astra Control Center (ACC)在云中运行的应用程序。</block>
  <block id="dfb2e84198fb746cd4e6487248b49d7c" category="doc">在GCP上部署和配置Red Hat OpenShift容器平台</block>
  <block id="e602916cd8628908952aebffa0d8cc32" category="paragraph">本节简要介绍了如何在GCP中设置和管理OpenShift集群以及在这些集群上部署有状态应用程序的工作流。其中展示了如何利用NetApp Cloud Volumes ONTAP 存储在Asta三端存储的帮助下提供永久性卷。本节详细介绍了如何使用Astra Control Center为有状态应用程序执行数据保护和迁移活动。</block>
  <block id="b5d27248c0493ed39bffd33fdc70a68b" category="paragraph">下图显示了部署在GCP上并使用VPN连接到数据中心的集群。</block>
  <block id="ef9605949ae0d665d4aff767411fb135" category="paragraph"><block ref="ef9605949ae0d665d4aff767411fb135" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3e26a0e9cfd6b78723aee609cfea090" category="admonition">可以通过多种方法在GCP中部署Red Hat OpenShift容器平台集群。此高级设置问题描述 提供了所用特定方法的文档链接。您可以在中提供的相关链接中参考其他方法 <block ref="ec30323d5c1ba24d6aabb0b3df901fd1" category="inline-link-macro-rx"></block>。</block>
  <block id="d24c87c3fb14ff7ce94628c84b4d013a" category="example-title">使用命令行界面在GCP上安装OCP集群。</block>
  <block id="117ff120e260dc5e661b3393a121010b" category="list-text">确保您已满足上述所有前提条件 <block ref="be6e8249837f288f5ffa541c6556a267" category="inline-link-macro-rx"></block>。</block>
  <block id="d5d210b642bee6970b108c1292253a5c" category="list-text">对于内部和GCP之间的VPN连接、我们会创建并配置一个pfSense VM。有关说明，请参见<block ref="33b302582fb38bfafd46fff8cda0e02a" category="inline-link-rx"></block>。</block>
  <block id="2f9a3dab79b69e89256e7de23b10d434" category="list-text">只有在Google Cloud Platform中创建VPN网关后、才能在pfSense中配置远程网关地址。</block>
  <block id="3c1279ad7ce2d9e7432c1e8b385725a8" category="list-text">只有在OpenShift集群安装程序运行并为集群创建基础架构组件之后、才能配置阶段2的远程网络IP地址。</block>
  <block id="28f59099bf09170bed25b48dc37f4ead" category="list-text">只有在安装程序为集群创建基础架构组件后、才能在Google Cloud中配置VPN。</block>
  <block id="ab2eb0579850eb69196d32ec15b22505" category="list-text">现在、在GCP上安装OpenShift集群。</block>
  <block id="24483a5baa89ea10ceef5d44317a78fc" category="list-text">获取安装程序和拉取密钥、然后按照文档中提供的步骤部署集群<block ref="3eebb7ad3b7807e9668b5fb657e73594" category="inline-link-rx"></block>。</block>
  <block id="dfe469b4f1aa9b34f68bdf495d59ca6c" category="list-text">此安装将在Google Cloud Platform中创建VPC网络。它还会在云DNS中创建一个私有区域并添加A记录。</block>
  <block id="06b502c8046d1d39f47c31a888cc0f2d" category="list-text">使用VPC网络的CIDR块地址配置pfSense并建立VPN连接。确保防火墙设置正确。</block>
  <block id="48281ea19019ac903b77a194baca154d" category="list-text">使用Google Cloud DNS的A记录中的IP地址在内部环境的DNS中添加A记录。</block>
  <block id="4f27717b74673bf2705ddb857faf61a6" category="list-text">集群安装完成、并将提供一个kubeconfigfile文件以及用户名和密码以登录到集群的控制台。</block>
  <block id="2cf27e4073b329275d0a486f527a3cfe" category="example-title">使用BlueXP在GCP中部署Cloud Volumes ONTAP。</block>
  <block id="b4678d952e7b7f5b0d0e37cb5eb2a551" category="list-text">在Google Cloud中安装连接器。请参阅说明<block ref="95c699608f5df2c39b69d68c4999b1f7" category="inline-link-rx"></block>。</block>
  <block id="b5c0dfafe4740b9adef3023b57371d1f" category="list-text">使用连接器在Google Cloud中部署CVO实例。请参阅此处的说明。<block ref="5dcb8b1a71fb2a60478c95bc49e22d2b" category="inline-link-rx"></block></block>
  <block id="5e5f3f22d14c7a58d27c71af4f524786" category="example-title">在GCP的OCP集群中安装Asta Trdent</block>
  <block id="44e7722dbbf31983500802f5a735e691" category="list-text">有多种方法可用于部署Asta三端到子、如图所示<block ref="df28848dc0c60e349970187bfd75a0df" category="inline-link-rx"></block>。</block>
  <block id="7e6cdb3ce812b7b004333bb4b6485dc0" category="list-text">对于此项目、Asta Dent是按照说明手动部署Asta Dent Operator来安装的<block ref="759d5b54b27f85c8d55e8e3510853fad" category="inline-link-rx"></block>。</block>
  <block id="20bba0d8ff83a658f25d45018d82181c" category="list-text">创建后端和存储类。请参阅说明 <block ref="9086b317542fa4fec3c7a94ae13e221d" category="inline-link-macro-rx"></block>。</block>
  <block id="c80e9b23e70993fca44acabadd93932e" category="example-title">将GCP上的OCP集群添加到Asta Control Center。</block>
  <block id="638df00ea6e87c6bc62710218a43bb55" category="list-text">创建一个具有集群角色的单独KubeConfig文件、该角色包含由Astra Control管理集群所需的最低权限。可以找到相关说明
<block ref="3bb38197994cd8609278607f825410a4" category="inline-link-macro-rx"></block>。</block>
  <block id="31ca5defd3bd025f7dc6263850635a65" category="list-text">按照说明将集群添加到Astra Control Center
<block ref="dbb4c3a77c38111573280a3233162536" category="inline-link-macro-rx"></block></block>
  <block id="3a2a264571e0b55c89cc93a5273f71f0" category="paragraph">[下划线]#*演示视频*#</block>
  <block id="111ca5ccfeeed94213d6de50c5fd43cd" category="video-title">在Google Cloud Platform上安装OpenShift集群</block>
  <block id="73a519111add9e670bb23dc85496c06b" category="video-title">将OpenShift集群导入Astra Control Center</block>
  <block id="0b12a57980fb157c2011967a53fc3543" category="paragraph">内部部署和AWS
<block ref="cb4581e6ea0741c82604502d38c43995" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6df99caaf357c26e24e9893fada05831" category="paragraph">内部部署和Google Cloud
<block ref="ef9605949ae0d665d4aff767411fb135" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a68ebe5784135293863ddbedaf853969" category="paragraph">**内部：自行管理的OpenShift集群和自行管理的存储**
**Google Cloud：自行管理的OpenShift集群和自行管理的存储**</block>
  <block id="c6d4132c12cc2d48f47f0b1f72b81325" category="cell">2023年10月10日</block>
  <block id="49a8fbbbcc0734adedca1eb1757786a0" category="cell">为Google Cloud添加了新内容</block>
  <block id="ed5ce461ae7b217e8ac8f5d56ed43b11" category="sidebar">在GCP上配置Red Hat OpenShift容器工作负载</block>
  <block id="1fb59866acc6cec33533c564ded04553" category="cell">2023年11月10日</block>
  <block id="1d65126a9d1e463e9194139d69f7be61" category="cell">全新解决方案：采用Domino数据实验室和NetApp的混合多云MLOps</block>
  <block id="9fac4fc4e1be67e589c110f0c4647f2e" category="summary">采用Domino数据实验室和NetApp的混合多云MLOps—技术概述</block>
  <block id="44997fb529c7b7d20853c30af9ad918a" category="section-title">Domino数据实验室</block>
  <block id="4e00c35efcd0578992f4821557db1c9e" category="paragraph">Domino Data Lab凭借其领先的企业级AI平台为模型驱动型企业提供支持、该平台受到超过20%的财富100强企业的信赖。Domino可加快数据科学工作的开发和部署速度、同时增强协作和监管。有了Domino、全世界的企业可以开发更好的药物、种植更具生产力的作物、建造更好的汽车等等。Domino成立于2013年、由Coatue Management、Great Hill Partners、高地资本、Sequoia Capital和其他主要投资者提供支持。</block>
  <block id="582cc4e2654a5d265b3a9c8960a43e88" category="paragraph">Domino支持企业及其数据科学家在一个统一的端到端平台上快速、负责任且经济高效地构建、部署和管理AI。团队可以在任何环境中访问所需的所有数据、工具、计算、模型和项目、因此他们可以进行协作、重复利用过去的工作、跟踪生产中的模型以提高准确性、采用最佳实践进行标准化、以及让AI成为负责任和受监管的企业。</block>
  <block id="79aba99e2c2c50a4d5627b787bde8eae" category="list-text">*开放且灵活：*访问最广泛的开放源代码和商业工具及基础架构生态系统，获得最佳创新，不受制于供应商。</block>
  <block id="720b80ab9ad18c5e500ae8203bb712f2" category="list-text">*记录系统：*整个企业的人工智能运营和知识中心、支持最佳实践、跨职能协作、加快创新速度和提高效率。</block>
  <block id="8d89627678490a8b88c851ea2fac357d" category="list-text">*集成：*集成工作流和自动化—专为企业流程、控制和监管而构建—可满足您的合规性和法规要求。</block>
  <block id="9e390a9660aa9f11963ef8d4ebe9b58a" category="list-text">*混合多云：*在靠近数据的位置运行AI工作负载—内部环境、混合环境、任何云或多云—以降低成本、优化性能和合规性。</block>
  <block id="959d581df3a25c6c865cad70ca8e6dac" category="paragraph"><block ref="959d581df3a25c6c865cad70ca8e6dac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7574cd2803b94ddaa90cab193a19ba2" category="section-title">Domino Nexus</block>
  <block id="80603873e677eebf28ec5645b40f7453" category="paragraph">Domino Nexus是一个单一管理平台、支持您跨任何云、区域或内部环境中的任何计算集群运行数据科学和机器学习工作负载。它统一了整个企业中的数据科学孤岛、让您有一个地方来构建、部署和监控模型。</block>
  <block id="a2378152174d3bc98eac2974782833f1" category="paragraph">NetApp BlueXP将NetApp的所有存储和数据服务统一到一个工具中、让您可以构建、保护和管理混合多云数据资产。它可以跨内部环境和云环境为存储和数据服务提供统一的体验、并通过AIIOPS的强大功能实现运营精简性、同时还具有当今云主导环境所需的灵活使用参数和集成保护。</block>
  <block id="8814f8d780d4b85a940aa27445d68549" category="list-text">云连接。ONTAP是云互联程度最高的存储管理软件、可在所有公有云中选择软件定义的存储和云原生实例。</block>
  <block id="d93da23faa15eea02df756be1f529408" category="paragraph">Amazon FSx for NetApp ONTAP是第一方完全托管的AWS服务、可提供基于NetApp流行的ONTAP文件系统构建的高度可靠、可扩展、高性能和功能丰富的文件存储。FSX for ONTAP 将NetApp文件系统的常见特性、性能、功能和API操作与完全托管的AWS服务的灵活性、可扩展性和精简性相结合。</block>
  <block id="b8b1b0bbd1e2c4f16cc74fbcd14043de" category="paragraph">Asta Trident支持在公有云或内部环境中的所有常见NetApp存储平台上使用和管理存储资源、包括ONTAP (AFF、FAS、Select、云、 Amazon FSx for NetApp ONTAP)、Element软件(NetApp HCI、SolidFire)、Azure NetApp Files服务以及Google Cloud上的Cloud Volumes Service。Asta Trident是一款符合容器存储接口(CSI)的动态存储编排程序、可与Kubbernetes本机集成。</block>
  <block id="978ecccb92a71c90363dfd222ebdfe77" category="paragraph">Kubernetes 是一款开源分布式容器编排平台，最初由 Google 设计，现在由 Cloud 原生计算基金会（ CNCF ）维护。Kubnetes支持容器化应用程序的部署、管理和扩展功能自动化、是企业环境中的主要容器流程编排平台。</block>
  <block id="480c9b5f979d1ce95ea2a58b09826d1b" category="section-title">Amazon Elelic Kubelnetes Service (EKS)</block>
  <block id="b2a7a79ed7fe83cbfb6fe2140e6fb60a" category="paragraph">Amazon El生 性Kubelnetes Service (Amazon EKS)是AWS云中的托管Kubelnetes服务。Amazon EKS会自动管理Kubersnetes控制平台节点的可用性和可扩展性、这些节点负责计划容器、管理应用程序可用性、存储集群数据以及其他关键任务。借助Amazon EKS、您可以利用AWS基础架构的所有性能、扩展性、可靠性和可用性、以及与AWS网络和安全服务的集成。</block>
  <block id="59a6ec9eb2075dc5ac847799c3c9b4e0" category="summary">采用Domino数据实验室和NetApp的混合多云MLOps—追加信息的适用对象</block>
  <block id="1182c61de35b31af3e72f77e61442c77" category="inline-link-macro"><block ref="1182c61de35b31af3e72f77e61442c77" category="inline-link-rx"></block></block>
  <block id="bd0007c3dcc92207ee01f0427da0a4be" category="paragraph"><block ref="bd0007c3dcc92207ee01f0427da0a4be" category="inline-link-macro-rx"></block></block>
  <block id="2703dd45bd40545fb60997c2d3afe208" category="inline-link-macro"><block ref="2703dd45bd40545fb60997c2d3afe208" category="inline-link-rx"></block></block>
  <block id="14a3e5a8d5046236b5959a8860c405eb" category="paragraph"><block ref="14a3e5a8d5046236b5959a8860c405eb" category="inline-link-macro-rx"></block></block>
  <block id="43e196fd7d1a86adce26084a27e3d664" category="inline-link-macro"><block ref="43e196fd7d1a86adce26084a27e3d664" category="inline-link-rx"></block></block>
  <block id="2edabab990aa6b9914f978e6885781f2" category="paragraph"><block ref="2edabab990aa6b9914f978e6885781f2" category="inline-link-macro-rx"></block></block>
  <block id="5b8aea48f614361f60f00e194e1b0976" category="inline-link-macro"><block ref="5b8aea48f614361f60f00e194e1b0976" category="inline-link-rx"></block></block>
  <block id="59f3782142c74894e9aa57873085e394" category="paragraph"><block ref="59f3782142c74894e9aa57873085e394" category="inline-link-macro-rx"></block></block>
  <block id="13ed1686110be86a2aeef6d76d4ec65e" category="list-text">NetApp AI解决方案</block>
  <block id="501b3e03ab68e967ec7e74647ece575b" category="paragraph"><block ref="501b3e03ab68e967ec7e74647ece575b" category="inline-link-macro-rx"></block></block>
  <block id="5acaa2031a97473b7a185dc30ce9e62d" category="list-text">Domino Data Lab技术联盟SA主管Jsh Mineroff</block>
  <block id="ed2311020217442776d108d1f99b7521" category="list-text">Domino Data Lab现场首席技术官Nicolas Jablonski</block>
  <block id="5c38b0c6106b026873b5212202e5eb20" category="list-text">NetApp公司解决方案架构师Arjunan先生</block>
  <block id="958996b71437140af7dadceec3c0acf1" category="list-text">NetApp技术联盟合作伙伴全球联盟总监Brian Young</block>
  <block id="5be0395276ff3840daa0a0cb7643b68d" category="summary">采用Domino数据实验室和NetApp的混合多云MLOps—初始设置</block>
  <block id="ef81709626b455fffcd99d9f67085d18" category="paragraph">本节介绍在整合内部数据中心和AWS的混合环境中将Domino Nexus与NetApp数据服务结合使用所需执行的初始设置任务。</block>
  <block id="87b13b0a04193ccc830f23d041d6f3ba" category="paragraph">在执行本节所述的步骤之前、我们假定您已执行以下任务：</block>
  <block id="677ae9330aedf715db07a33be39cbbeb" category="list-text">您已部署和配置内部NetApp ONTAP存储平台。有关详细信息，请参见 <block ref="077b296918e9131d07388450dbd7a243" category="inline-link-macro-rx"></block>。</block>
  <block id="eb4d9bec48193b99d36e41d717ee0fe9" category="inline-link-macro">Amazon FSx for NetApp ONTAP商品页面</block>
  <block id="c77d96ce0f61ac0c80eadb378d5a7b52" category="list-text">您已在AWS中配置Amazon FSx for NetApp ONTAP实例。有关详细信息，请参见 <block ref="ef5327328c2daa4877f9fb373a954af2" category="inline-link-macro-rx"></block>。</block>
  <block id="6bd1aa1204077ccb610d72dbc07f11b1" category="inline-link-macro">Domino管理指南</block>
  <block id="83a12488d43dae9419d61f6f83fa014a" category="list-text">您已在内部数据中心中配置了Kubbernetes集群。有关详细信息，请参见 <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block>。</block>
  <block id="6b59c41a4554c4e0f63a7da5ad17b347" category="list-text">您已在AWS中配置Amazon EKS集群。有关详细信息，请参见 <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block>。</block>
  <block id="752f9ff9f4842abac53d8c0aec2188b0" category="inline-link-macro">NetApp Astra Trident 文档</block>
  <block id="464535c48f27eb8e748543ef80bf7672" category="list-text">您已在内部部署的Kubbernetes集群中安装NetApp Asta三端存储。此外、您还配置了此三项技术实例、以便在配置和管理存储资源时使用内部NetApp ONTAP存储平台。有关详细信息，请参见 <block ref="e0a80a1edbd0f7131f7ffcb00856fdaa" category="inline-link-macro-rx"></block>。</block>
  <block id="a102f854084bb7d1994f562cd8aa9869" category="list-text">您已在Amazon EKS集群中安装NetApp Asta三端磁盘。此外、您还配置了此TRIDent实例、以便在配置和管理存储资源时使用Amazon FSx for NetApp ONTAP实例。有关详细信息，请参见 <block ref="e0a80a1edbd0f7131f7ffcb00856fdaa" category="inline-link-macro-rx"></block>。</block>
  <block id="f8090d27d981a98d65c4401bdd84b3bf" category="inline-link-macro">Amazon虚拟专用网络(VPN)文档</block>
  <block id="c09961db559c7c906d851ebf8ba40ac5" category="list-text">您必须在内部数据中心和AWS中的虚拟私有云(Virtual Private Cloud、VPC)之间建立双向网络连接。有关实施此功能的各种选项的更多详细信息、请参见 <block ref="f5c50c4f502917d968e827ba0a3b9d8e" category="inline-link-macro-rx"></block>。</block>
  <block id="077b7144cc60353e8c8fdc9663398f24" category="section-title">在AWS中安装Domino Enterprise AI Platform</block>
  <block id="7b3ae6b71caf8dc86d695e0e3dbc08eb" category="paragraph">要在AWS中安装Domino Enterprise MLOps平台、请按照中所述的说明进行操作 <block ref="7ebd1f818144f08a887fe5d8dbad016a" category="inline-link-macro-rx"></block>。您必须在先前配置的同一个Amazon EKS集群中部署Domino。此外、必须已在此EKS集群中安装和配置NetApp Asta三端磁盘、并且必须在Domino/yml安装配置文件中指定一个三端磁盘管理的存储类作为共享存储类。</block>
  <block id="feee67bbfd0f30a09eeb08ca21cdf38d" category="inline-link-macro">Domino安装配置参考指南</block>
  <block id="8facc83d9ba07b807b37a1cf4c7f8a74" category="admonition">请参见 <block ref="ace9eaa491d11b57c3774d7e21b1cd72" category="inline-link-macro-rx"></block> 有关如何在Domino/yml安装配置文件中指定共享存储类的详细信息。</block>
  <block id="11f21d6309deb4cfcdc7f2cdb4fd0839" category="inline-link-macro">技术报告TR-4952</block>
  <block id="1f30f4ca051028513889e17502002ae0" category="admonition"><block ref="3de90155c2505cad82b61f16af3049bc" category="inline-link-macro-rx"></block> 介绍如何使用Amazon FSx for NetApp ONTAP在AWS中部署Domino、对于解决出现的任何问题、这可能是一个有用的参考。</block>
  <block id="aa2a36e425ea068322a0e37b07481ba8" category="section-title">启用Domino Nexus</block>
  <block id="1a942f929d8ad029b828b8e738a86a07" category="paragraph">接下来、您必须启用Domino Nexus。请参见 <block ref="31b0fd9bf4991ddcfdb80d02c1415fe4" category="inline-link-macro-rx"></block> 了解详细信息。</block>
  <block id="fa64dcf7a96dbbcd90b8729d4d59ab2f" category="section-title">在内部数据中心部署Domino数据平面</block>
  <block id="0c37ef97cec2ed3561addeb685a6fa02" category="paragraph">接下来、您必须在内部数据中心部署Domino数据平面。您必须将此数据平面部署在先前配置的内部Kubbernetes集群中。此外、必须已在此Kubbernetes集群中安装和配置NetApp Asta三端存储。请参见 <block ref="d46974ff7fcd2c0e55b6b55f2aa698e1" category="inline-link-macro-rx"></block> 了解详细信息。</block>
  <block id="7bdb77faa0d23db500f55d38c7812837" category="summary">采用Domino数据实验室和NetApp的混合多云MLOps—将现有NetApp卷公开给Domino</block>
  <block id="5f385895d8f69d19670414fea115c17e" category="doc">将现有NetApp卷公开给Domino</block>
  <block id="012942ee2856a3a30e386d999ab4decd" category="paragraph">本节介绍向Domino MLOps平台公开现有NetApp ONTAP NFS卷所需执行的任务。这些步骤同样适用于内部和AWS。</block>
  <block id="216745145dbb2663dd8ef64d1e7b70ce" category="section-title">为什么要将NetApp ONTAP卷公开给Domino？</block>
  <block id="4f49bbf1791537d3f9cea32729bcf171" category="paragraph">将NetApp卷与Domino结合使用具有以下优势：</block>
  <block id="bdf339cbdff188396b615acb6642682f" category="list-text">您可以利用NetApp ONTAP的横向扩展功能对超大型数据集执行工作负载。</block>
  <block id="ad859808af9509052afa68845ee13abf" category="list-text">您可以跨多个计算节点执行工作负载、而无需将数据复制到各个节点。</block>
  <block id="3019efb93cfae9d2074cee3ecba248ce" category="list-text">您可以利用NetApp的混合多云数据移动和同步功能跨多个数据中心和/或云访问数据。</block>
  <block id="72410fa7689169a336be6540fbab04cb" category="list-text">您希望能够在其他数据中心或云中快速轻松地创建数据缓存。</block>
  <block id="d249e01c178fdea598675fc02de5726a" category="section-title">公开Asta Trident未配置的现有NFS卷</block>
  <block id="d98d4f65b60353b6c38e74753e7eb04b" category="paragraph">如果现有的NetApp ONTAP NFS卷不是由Astra Trident配置的、请按照本小节中概述的步骤进行操作。</block>
  <block id="b0604699a0737b4da7a79ed81a611605" category="section-title">在Kubbernetes中创建PV和PVC</block>
  <block id="b2104dee9432e36f85faf685b643e330" category="admonition">对于内部部署卷、请在内部Kubbernetes集群中创建PV和PVC。对于Amazon FSx for NetApp ONTAP卷、在Amazon EKS中创建PV和PVC。</block>
  <block id="7ea686752cd0065765a1f236f52b6a86" category="inline-link-macro">NFS PV/PVC示例</block>
  <block id="21daa905ac0fe45b36e98c4b7c6cbfaf" category="paragraph">首先、您必须在Kubbernetes集群中创建永久性卷(PV)和永久性卷请求(PVC)。要创建PV和PVC、请使用 <block ref="a25b642a6322d7659714e6bd71e7cd4f" category="inline-link-macro-rx"></block> 并更新这些值以反映您的环境。请务必为指定正确的值<block ref="89801e9e98979062e84647433a8ed3e9" prefix=" " category="inline-code"></block>，<block ref="0a087fd97387c110f029a7a2550ff280" prefix=" " category="inline-code"></block>，和<block ref="34ae7d3a708b57f81af8fcfcd13c7a55" prefix=" " category="inline-code"></block> 字段。此外、我们建议为您的PV和PVC提供唯一名称、以表示相应ONTAP NFS卷上存储的数据的性质。例如、如果卷包含制造缺陷的图像、您可以将PV命名为<block ref="7146834334002e1c2c8bbb00348a951c" prefix=" " category="inline-code"></block>和PVC、<block ref="2d04ce24c553ffe8e7f9b69269696618" prefix=" " category="inline-code"></block>。</block>
  <block id="3a0e23ff2bfd7dc5b55c1aeb14b0ce33" category="section-title">在Domino中注册外部数据卷</block>
  <block id="6d38ad9604bf23123ad6f1505f8f64ce" category="paragraph">接下来、您必须在Domino中注册外部数据卷。要注册外部数据卷、请参见 <block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> 在Domino管理指南中。注册卷时、请务必从"卷类型"下拉菜单中选择"NFS"。选择"NFS"后、您应在"可用卷"列表中看到您的PVC。</block>
  <block id="7cde04ec45b99218a7d4e55ada8bf9d9" category="paragraph"><block ref="7cde04ec45b99218a7d4e55ada8bf9d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9eb2638f9331c318ed17254f9d60f14" category="section-title">公开Asta Trident配置的现有卷</block>
  <block id="aebc00c47271dad15a186d8979be91cf" category="paragraph">如果现有卷是由Asta Trident配置的、请按照本小节中概述的步骤进行操作。</block>
  <block id="57a045b809f3298056d203360becbd66" category="section-title">编辑现有PVC</block>
  <block id="bac85cf0930869df413c1a1ecda7bbaf" category="paragraph">如果您的卷是由Asta Trident配置的、则您已经拥有与您的卷对应的永久性卷请求(PVC)。要将此卷公开给Domino、必须编辑PVC并将以下标签添加到中的标签列表中<block ref="9cc59534218c9b00f7eb481861d14401" prefix=" " category="inline-code"></block> 字段：</block>
  <block id="d2790ed8ab25c08ee1efd69f0773cade" category="paragraph">接下来、您必须在Domino中注册外部数据卷。要注册外部数据卷、请参见 <block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> 在Domino管理指南中。注册卷时、请务必从"卷类型"下拉菜单中选择"通用"。选择"通用"后、您应在"可用卷"列表中看到您的PVC。</block>
  <block id="182f685e8ff46f3bde7c8c63a6d3e8eb" category="summary">采用Domino数据实验室和NetApp的混合多云MLOps—架构</block>
  <block id="22a02f1b77fcd49462c4d58a6e2425fb" category="paragraph">此解决方案将Domino Nexus的混合多云工作负载计划功能与NetApp数据服务相结合、创建统一的混合云MLOps平台。有关详细信息、请参见下表。</block>
  <block id="49ee3087348e8d44e1feda1917443987" category="cell">Name</block>
  <block id="1a01eb6a884a288b667e023501d09eea" category="cell">MLOps控制平台</block>
  <block id="51c0d15bebbbdb19d5e1bde9bf2bc1ba" category="inline-link-macro">采用Domino Nexus的Domino企业级AI平台</block>
  <block id="a0133d74aa4167bee7ec6bb2830b32ab" category="cell"><block ref="a0133d74aa4167bee7ec6bb2830b32ab" category="inline-link-macro-rx"></block></block>
  <block id="dedb71b645ad83baa13a64e834ea32a3" category="cell">MLOps平台计算环境</block>
  <block id="1f26213ee3d03d1bce28558ef8ff15ff" category="inline-link-macro">Domino Nexus数据平面</block>
  <block id="f2d3c460a5a76b316899ec775650d7ea" category="cell"><block ref="f2d3c460a5a76b316899ec775650d7ea" category="inline-link-macro-rx"></block></block>
  <block id="89f5a1a21bf30d5f2db943911b2d22f2" category="cell">AWS、内部数据中心</block>
  <block id="1698863d644408b6fdc41803a6a1c234" category="cell">内部计算平台</block>
  <block id="fd5af034e016f2062e31c3c0cc7e5aa6" category="cell"><block ref="e08fa5b25dd32bed0a8727bee0e3fdd0" category="inline-link-macro-rx"></block> 使用 <block ref="655503a998f5566f4f47d61751f1fbae" category="inline-link-macro-rx"></block></block>
  <block id="59f10558cba0587bc03fb56826f8cd4b" category="cell">内部数据中心</block>
  <block id="29e13ea538f81a8bf3cea3900519c8a1" category="cell">云计算平台</block>
  <block id="90d1544d728604bba2e45234e5a69f1c" category="cell"><block ref="4ecdb2c4c840fbc0e496687cc8bf58fe" category="inline-link-macro-rx"></block> 使用 <block ref="655503a998f5566f4f47d61751f1fbae" category="inline-link-macro-rx"></block></block>
  <block id="cd3aefaae18f11e3ecc3de62739183f3" category="cell">内部数据平台</block>
  <block id="e16a11bc6041db3c2b26ef054c8b8847" category="inline-link-macro">NetApp存储设备</block>
  <block id="b331d50869bea7c3b019d322cffc1f03" category="cell"><block ref="ea0807fcd7c8182254e93c3bfdf94abc" category="inline-link-macro-rx"></block> 由提供支持 <block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="0c9ae535d9e81d6e268c0ea087be535f" category="cell">云数据平台</block>
  <block id="f5c286d9dc4cdaffcb8e5c86388e6ed8" category="cell"><block ref="f5c286d9dc4cdaffcb8e5c86388e6ed8" category="inline-link-macro-rx"></block></block>
  <block id="fcf11430c9a19001f794bfb65cc88d1c" category="paragraph"><block ref="fcf11430c9a19001f794bfb65cc88d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f92651ef1a171bf24e3a0279a4f656f" category="summary">采用Domino数据实验室和NetApp的混合多云MLOps—跨不同环境访问相同数据</block>
  <block id="2167fcd754f38c037a8a5fc219634638" category="doc">在不同环境中访问相同的数据</block>
  <block id="2b2213cc89a71238bd2629046704d311" category="paragraph">本节介绍在不同计算环境中访问相同数据所需执行的任务。在Domino MLOps平台中、计算环境称为"数据平面"。 如果您的数据驻留在一个数据平面中的NetApp卷上、但您需要在另一个数据平面中访问该数据、请按照本节中所述的任务进行操作。这种情形通常称为"突发"、如果目标环境为云、则称为"云突发"。 处理有限或超额预订的计算资源时、通常需要此功能。例如、如果您的内部计算集群订阅过量、您可能希望将工作负载计划到云、以便立即启动。</block>
  <block id="8e259831056b970e9e9ad97044e756ea" category="paragraph">对于访问位于不同数据平面中的NetApp卷、建议使用两种方法。这些选项将在下面的小节中进行概述。根据您的特定要求、选择其中一个选项。下表介绍了这两个选项的优点和缺点。</block>
  <block id="054b4f3ea543c990f6b125f41af6ebf7" category="cell">选项</block>
  <block id="0cfc0523189294ac086e11c8e286ba2d" category="cell">缺点</block>
  <block id="a5a315a3bc09fc65d5b92a61203e604b" category="cell">选项1 -缓存</block>
  <block id="542d0200f163f8f3533463dd59fe0270" category="cell">-工作流更简单
-能够根据需要缓存一部分数据
-能够将数据写回源
-没有要管理的远程副本</block>
  <block id="7426e3bde1c62fb806a70f18c6134316" category="cell">-随着缓存水合、初始数据访问延迟会增加。</block>
  <block id="aaa4d30d61e64cea712b7c05c68eb117" category="cell">选项2 -镜像</block>
  <block id="cbefd7ef29f92291b21681c43ba469b7" category="cell">-源卷的完整副本
-缓存融合不会增加延迟(镜像操作完成后)</block>
  <block id="03dab0d003c274e0f366cd0df3efb059" category="cell">-必须等待镜像操作完成、然后才能访问数据
-必须管理远程副本
-无法回写源</block>
  <block id="f794ea935b3f3b976964bf0990d05005" category="section-title">选项1 -为驻留在其他数据平面中的卷创建缓存</block>
  <block id="79849c69657d54d5bfdd901f71375897" category="inline-link-macro">NetApp FlexCache 技术</block>
  <block id="a816bf9775484a9a7049d55ece7f5396" category="paragraph">使用 <block ref="bb0419306e9b544a3e597acbf1d444f1" category="inline-link-macro-rx"></block>，则可以为驻留在其他数据平面中的NetApp卷创建缓存。例如、如果您的内部数据平面中有一个NetApp卷、而您需要在AWS数据平面中访问该卷、则可以在AWS中为该卷创建缓存。本节概述了为驻留在其他数据平面中的NetApp卷创建缓存所需执行的任务。</block>
  <block id="d93488703b54616875bcacc4afd140a7" category="section-title">在目标环境中创建FlexCache卷</block>
  <block id="f1625bd0697a2fc3d12a2174f27f86e6" category="admonition">如果目标环境是您的内部数据中心、则需要在内部ONTAP系统上创建FlexCache卷。如果目标环境为AWS、则需要在Amazon FSx for NetApp ONTAP实例上创建FlexCache卷。</block>
  <block id="a53f62411ee21cbe84822e3eba531ca4" category="paragraph">首先、必须在目标环境中创建FlexCache卷。</block>
  <block id="671e0b00bec7311fe1a27ae3b1374868" category="inline-link-macro">BlueXP卷缓存文档</block>
  <block id="25d1d7fbc173abf20974acc2fd19014b" category="paragraph">建议使用BlueXP创建FlexCache卷。要使用BlueXP创建FlexCache卷、请按照中所述的说明进行操作 <block ref="13882193b90946980fb2e14f0dc3f833" category="inline-link-macro-rx"></block>。</block>
  <block id="eb75aeb3b4b2b9734ba3e52f5483f0b2" category="inline-link-macro">ONTAP 文档</block>
  <block id="597fd5f01aeae294735b75c08203b6dd" category="paragraph">如果您不想使用BlueXP、则可以使用ONTAP系统管理器或ONTAP命令行界面创建FlexCache卷。要使用System Manager创建FlexCache卷、请参阅中概述的说明 <block ref="01bbf1f7353a360c52874272bfd82e21" category="inline-link-macro-rx"></block>。要使用ONTAP命令行界面创建FlexCache卷、请参阅中概述的说明 <block ref="91e4088944fb7c016c63d36e00422b16" category="inline-link-macro-rx"></block>。</block>
  <block id="e4de6f9df9cd48ef525131de3cb21481" category="inline-link-macro">BlueXP API</block>
  <block id="0ec641cfacd36c8e22a334135e2abdac" category="inline-link-macro">ONTAP REST API</block>
  <block id="ebf440be7bdce857e55ec25910ae837b" category="inline-link-macro">ONTAP的"Ans征选"</block>
  <block id="dd7a007ea7e610e168238b6d6ab542a1" category="paragraph">如果要自动执行此过程、可以使用 <block ref="f07bcb7e875f8bb20680b339fb58364a" category="inline-link-macro-rx"></block>， <block ref="0966e902a53f3a5becbd165bbdc18e79" category="inline-link-macro-rx"></block>或 <block ref="62c3d824298cc8f488bda82279b91e73" category="inline-link-macro-rx"></block>。</block>
  <block id="df290fd56e07fe2a5fe877aa5d2a31c2" category="admonition">System Manager在Amazon FSx for NetApp ONTAP中不可用。</block>
  <block id="20f99b2a7f22945f3d769fa1def1e403" category="section-title">将FlexCache卷公开给Domino</block>
  <block id="c9743d6f9b7fcd7047ce3eb9d1f2a273" category="inline-link-macro">"向Domino公开现有NetApp卷"部分</block>
  <block id="06d703eba1b45e410af60ab9ee41ad0e" category="paragraph">接下来、必须将FlexCache卷公开给Domino MLOps平台。要向Domino公开FlexCache卷、请按照的"公开未由Astra Trident配置的现有NFS卷"子部分中所述的说明进行操作 <block ref="2aa7cb839772ba5634514301b1a70ec4" category="inline-link-macro-rx"></block> 解决方案。</block>
  <block id="1d25e828bd3386ce7ef8b97572c88781" category="paragraph">现在、您可以在目标数据平面中启动作业和工作空间时挂载FlexCache卷、如以下屏幕截图所示。</block>
  <block id="edaa69742537cd645340e6ec55f0e7c2" category="section-title">创建FlexCache卷之前</block>
  <block id="e33df45d0b57bf3d8832a8bb65f33710" category="paragraph"><block ref="e33df45d0b57bf3d8832a8bb65f33710" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7bf27913e6097a43d318c500146c1e1" category="section-title">将FlexCache卷公开给Domino之后</block>
  <block id="27eab0d6e74c3a592c480db85f829fa7" category="paragraph"><block ref="27eab0d6e74c3a592c480db85f829fa7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9be78ccf5bdf4dc10f0e5d25b893eeb" category="section-title">选项2 -备份驻留在其他数据平面中的卷</block>
  <block id="0e6ab030c4eacec9efa80d3df6cd643b" category="inline-link-macro">NetApp SnapMirror数据复制技术</block>
  <block id="124468d30e8b5047c5fe1b160b4fcbd2" category="paragraph">使用 <block ref="ebe914c00393f99bd92af5cffa8376b0" category="inline-link-macro-rx"></block>，则可以创建驻留在其他数据平面中的NetApp卷的副本。例如、如果您的内部数据平面中有一个NetApp卷、而您需要在AWS数据平面中访问该卷、则可以在AWS中创建该卷的副本。本节概述了为驻留在其他数据平面中的NetApp卷创建副本所需执行的任务。</block>
  <block id="050a227810327b3bcfd311be38b7d202" category="section-title">创建 SnapMirror 关系</block>
  <block id="fef6b7d4f88331bab85d2eb944d43e9b" category="paragraph">首先、必须在源卷与目标环境中的新目标卷之间创建SnapMirror关系。请注意、目标卷将在创建SnapMirror关系的过程中创建。</block>
  <block id="62390de09bd56fbb6d4533a188f4f201" category="inline-link-macro">BlueXP复制文档</block>
  <block id="6fbd84bba212db826d8a94b992bd6324" category="paragraph">建议使用BlueXP创建SnapMirror关系。要使用BlueXP创建SnapMirror关系、请按照中所述的说明进行操作 <block ref="b08e4ece79f7d1aa7f110b298b659fae" category="inline-link-macro-rx"></block>。</block>
  <block id="052be79cbb457a1391bb0a6839e610d3" category="paragraph">如果您不想使用BlueXP、则可以使用ONTAP系统管理器或ONTAP命令行界面创建SnapMirror关系。要创建与System Manager的SnapMirror关系、请参阅中概述的说明 <block ref="665d2354c4ea508e65993c5ec9dc3fa1" category="inline-link-macro-rx"></block>。要使用ONTAP命令行界面创建SnapMirror关系、请参阅中概述的说明 <block ref="bf03311f5c6980a3d817528b27741438" category="inline-link-macro-rx"></block>。</block>
  <block id="805b58c51fa6bf98d530bbc76f317e74" category="section-title">中断 SnapMirror 关系</block>
  <block id="9ee42869e01344256cee7824a61c3f00" category="paragraph">接下来、您必须中断SnapMirror关系、才能激活目标卷以进行数据访问。请等待初始复制完成、然后再执行此步骤。</block>
  <block id="c16b6b1cdf70d97ab9f143b23f304ee5" category="admonition">您可以通过在BlueXP、ONTAP系统管理器或ONTAP命令行界面中检查镜像状态来确定复制是否已完成。复制完成后、镜像状态将为"snapMirrored"。</block>
  <block id="acab4369131a8c646dc85deedc5c4abb" category="paragraph">建议使用BlueXP中断SnapMirror关系。要中断与BlueXP的SnapMirror关系、请按照中所述的说明进行操作 <block ref="eb8fade3a2fe398b39f82043fade1a22" category="inline-link-macro-rx"></block>。</block>
  <block id="96009cd50e3918957734c7c1dbe9bbb1" category="paragraph">如果您不想使用BlueXP、则可以使用ONTAP系统管理器或ONTAP命令行界面中断SnapMirror关系。要中断与System Manager的SnapMirror关系、请参阅中概述的说明 <block ref="2feb8ad9799acf2d659fb0cab9f5c802" category="inline-link-macro-rx"></block>。要中断与ONTAP命令行界面的SnapMirror关系、请参阅中概述的说明 <block ref="a5d68b350f5308762130d0f350fbb93c" category="inline-link-macro-rx"></block>。</block>
  <block id="67a1a8de2d55c1b2a31ec40db952c0cf" category="section-title">向Domino公开目标卷</block>
  <block id="27b570121136dd375957f5b056d502e8" category="paragraph">接下来、您必须将目标卷公开给Domino MLOps平台。要向Domino公开目标卷、请按照的"公开未由Astra Trident配置的现有NFS卷"子部分中所述的说明进行操作 <block ref="2aa7cb839772ba5634514301b1a70ec4" category="inline-link-macro-rx"></block> 解决方案。</block>
  <block id="aa4e6b2b0a9165bbe6adb64ff972dbb0" category="paragraph">现在、您可以在目标数据平面中启动作业和工作空间时挂载目标卷、如以下屏幕截图所示。</block>
  <block id="6c2d9f4c43e6e539a1b0bf3be24de513" category="section-title">创建SnapMirror关系之前</block>
  <block id="800f74671431bfc6b9efb2f7e294020f" category="section-title">向Domino公开目标卷之后</block>
  <block id="a2207225ebdd3d675188d927e34ace5a" category="summary">Domino Nexus是一个单一管理平台、支持您跨任何云、区域或内部环境中的任何计算集群运行数据科学和机器学习工作负载。</block>
  <block id="1882311bf64ae464a0b9653b463c8584" category="doc">采用Domino数据实验室和NetApp的混合多云MLOps</block>
  <block id="c716184d878cbe2fda94903e01c21291" category="paragraph">目前、全球各地的企业都在采用AI来实现业务和流程转型。因此、AI就绪的计算基础架构往往短缺。为了充分利用不同区域、数据中心和云之间的可用计算环境、企业纷纷采用混合多云MLOps架构、从而平衡成本、可用性和性能。</block>
  <block id="542493ebb9768d33d834c6edcade57dc" category="paragraph">Domino Data Lab的Domino Nexus是一个统一的MLOps控制平台、支持您跨任何云、区域或内部环境中的任何计算集群运行数据科学和机器学习工作负载。它统一了整个企业中的数据科学孤岛、让您有一个地方来构建、部署和监控模型。同样、NetApp的混合云数据管理功能使您能够将数据带到工作和工作空间中、无论这些数据在何处运行。将Domino Nexus与NetApp配对后、您可以灵活地跨环境计划工作负载、而无需担心数据可用性。换言之、您可以将工作负载和数据发送到相应的计算环境、从而加快AI部署速度、同时遵守有关数据隐私和控制权的法规。</block>
  <block id="3eb3ace35104f92d82777b3219f769d7" category="paragraph">此解决方案演示了如何部署统一的MLOps控制平面、其中包括内部Kubelnetes集群和在Amazon Web Services (AWS)中运行的Elapic Kubelnetes Service (EKS)集群。</block>
  <block id="c68cacac1b94f6d5935ab85f274eb122" category="sidebar">使用VMC模拟器对AWS执行DRO</block>
  <block id="1dddbcd1b30e63693a82a81f696a9bf8" category="sidebar">带有AVS模拟器的ANF的DRO</block>
  <block id="e03c0c1ce65ea25dc35c3086e8b3a380" category="sidebar">BlueXP DRaaS模拟器</block>
  <block id="c541b70a6dbf5ab7820eae79a77b5296" category="sidebar">BlueXP - VM Simulator的备份和恢复</block>
  <block id="baca58f875ace8d33681f144caf3c370" category="cell">2023年7月11日</block>
  <block id="bef15cc712c8f284d40a04b15e3d9fab" category="cell">主权云</block>
  <block id="ad37085c09db35cf0e6d6735e86b53ee" category="cell">新内容：StorageGRID作为对象存储扩展</block>
  <block id="540931ca7221d97c9e2e039639bdb180" category="cell">2023年11月6日</block>
  <block id="f1cec05ec4c89a41224288ac0cefad42" category="cell">采用NetApp的VMware Sovereign Cloud的新内容</block>
  <block id="fc09bdea873019ba7d406dda9c276e88" category="summary">主权云是一种云计算、可优先为组织提供数据驻留和控制权。这意味着、数据在地理位置进行存储和处理时、必须遵守收集数据的国家/地区的隐私法律、确保遵守隐私法律和数据保护法规。这些国家或地区法规和法律监管从数据所在地理位置到跨境数据流的所有内容。</block>
  <block id="d97c288618e32f00d576f83cf79a1fbb" category="doc">VMware Sovereign Cloud</block>
  <block id="a9adbb2aa747c9ee502f1e91d4fdaf98" category="doc">采用VMware Sovereign Cloud的Netpp：用例</block>
  <block id="54356f7407544de0f17823afa062d6a4" category="paragraph">NetApp通过集成多种NetApp技术、为VMware Sovereign Cloud概念提供支持。</block>
  <block id="46b9d5595b1003a6fdf9987da76d3bf7" category="paragraph">使用以下链接详细了解NetApp技术与VMware Sovereover Cloud的集成：</block>
  <block id="1d1d668baeb1ee7967f7ee7269b74e66" category="inline-link-macro">NetApp StorageGRID作为对象存储扩展</block>
  <block id="261145b5d38595b29f5f3864f6d1b159" category="list-text"><block ref="261145b5d38595b29f5f3864f6d1b159" category="inline-link-macro-rx"></block></block>
  <block id="6a082f1dd03c88adf975fceae24bd0aa" category="paragraph">NetApp已与VMware合作、将NetApp StorageGRID集成到VMware Cloud Director中、以支持VMware Sovereign云。此VMware Cloud Director插件支持服务提供商使用StorageGRID作为其对象存储产品(无论使用情形如何)、并允许通过服务提供商用来管理其产品目录中其他部分的相同VMware多租户解决方案(VMware Cloud Director)进行StorageGRID管理。</block>
  <block id="959982ad360500c7c295eea4f1fe625c" category="paragraph">提供VMware主权云的合作伙伴可以选择NetApp StorageGRID来帮助他们管理和维护包含非结构化数据的云环境。它在为Amazon S3 API等行业标准API提供本机支持方面实现了通用兼容性、有助于确保在各种云环境之间实现顺畅的互操作性、而自动化生命周期管理等独特创新有助于确保更经济高效地保护、存储和长期保留客户的非结构化数据。</block>
  <block id="7dedfd355611dda6ec131b71ebff2fc7" category="paragraph">NetApp的Sovereign Cloud与Cloud Director集成为客户提供以下优势：</block>
  <block id="a52196407cf310e11cea5c5353452053" category="list-text">确保敏感数据(包括元数据)仍受主权控制、同时防止可能违反数据隐私法律的外国当局访问。</block>
  <block id="ef19d0161e17a24b4324914dbc48090d" category="list-text">提高安全性和合规性、保护应用程序和数据免受快速演变的攻击向量的影响、同时保持与可信本地系统的持续合规性。基础架构、内置框架和本地专家。</block>
  <block id="a732f6531634fc4165c8ccc507832b0d" category="list-text">打造适应未来需求的基础架构、快速应对不断变化的数据隐私法规、安全威胁和地缘政治。</block>
  <block id="3ad65d8567e1c852969de5c29ec25599" category="list-text">能够通过安全的数据共享和分析释放数据的价值、从而在不违反隐私法律的情况下推动创新。数据完整性受到保护、可确保获得准确的洞察力。</block>
  <block id="949db41031ebb9912f167d04587d0eab" category="paragraph">有关StorageGRID集成的详细信息、请查看以下内容：</block>
  <block id="2c2608487c7797891628fc3b5cf81b0d" category="doc">VMware Sovereign Cloud概述</block>
  <block id="2fd283ddf062167b1c68513629c6ba3a" category="paragraph">对于许多处理和维护高度敏感数据的实体(如国家和州政府)以及监管严格的行业(如金融和医疗保健)来说、主权概念正逐渐成为云计算的必要组成部分。各国政府还希望扩大数字经济能力、减少对跨国公司云服务的依赖。</block>
  <block id="c0be0f98f4b7737e0b16a575564aa0bb" category="section-title">VMware Sovereign Cloud计划</block>
  <block id="b12f4656fa45747c0de08b7bf19f407d" category="paragraph">VMware将主权云定义为：</block>
  <block id="cc5eb332f56d706e021656ff8d5af96a" category="list-text">保护和释放关键数据(例如国家数据、公司数据和个人数据)对私营和公共部门组织的价值</block>
  <block id="84a12b86bf3223dad379824df8c27d33" category="list-text">为数字经济提供全国性能力</block>
  <block id="b75fd1508df511eef2b5a8ab064f39d6" category="list-text">利用经过审核的安全控制保护数据安全</block>
  <block id="d4d27d48bb389eeb0dfab1197d3fcb44" category="list-text">确保遵守数据隐私法律</block>
  <block id="5c2b66349cd3605d63951cc2d6e0b7c1" category="list-text">通过为数据驻留和数据主权提供完全的司法管辖控制、提高数据控制能力</block>
  <block id="9f4094442fec7c3a74c5631d73b475e9" category="section-title">与值得信赖的VMware Sovereign云服务提供商合作</block>
  <block id="f8295ac8ff360d49b1426bcc0006bc2b" category="paragraph">为了确保成功、企业必须与他们信任的合作伙伴合作、这些合作伙伴必须能够托管真正的自主主权云平台。VMware Sover参加VMware云计划的云提供商致力于设计和运营基于现代软件定义架构的云解决方案、这些架构体现了VMware Sover要 云框架中概述的关键原则和最佳实践。</block>
  <block id="d6883fcf0aa6e214cf43367fee70b2e8" category="list-text">*数据主权和管辖控制*–所有数据均为驻留数据、并受收集数据的国家/地区的专属控制和权威约束。在管辖范围内全面管理业务</block>
  <block id="4df1c6b4bf967a559c1eac1714f04932" category="list-text">*数据访问和完整性*—云基础架构具有故障恢复能力、可在辖区内至少两个数据中心位置使用、并提供安全和专用连接选项。</block>
  <block id="3357e52c9f16effb00321f3190dde157" category="list-text">*数据安全与合规性*–信息安全管理系统控制措施根据行业认可的全球(或区域)标准进行认证并定期审核。</block>
  <block id="2ab8ed7f9733cbaee665e8ffe72d1fc6" category="list-text">*数据独立性和移动性*—支持现代应用程序架构、防止受制于供应商云、实现应用程序可移植性和独立性</block>
  <block id="dbfcb0c6d1880999af4ba3bb4d1248b5" category="paragraph">有关VMware的详细信息、请访问：</block>
  <block id="a0f549f6bfdae6fdbd36070ea12a8038" category="inline-link-macro">VMware Sovereign Cloud概述</block>
  <block id="dae4f166d1bf8815de82574c9123bd1e" category="list-text"><block ref="dae4f166d1bf8815de82574c9123bd1e" category="inline-link-macro-rx"></block></block>
  <block id="b04f22685f311b0c736def02997044fc" category="inline-link-macro">什么是VMware Sover훷 좨 云？</block>
  <block id="8c5a85c795d6eefae8d80831e3cc34cf" category="list-text"><block ref="8c5a85c795d6eefae8d80831e3cc34cf" category="inline-link-macro-rx"></block></block>
  <block id="bdaaf875850ed54f9ba2d1cd40ed360d" category="inline-link-macro">隆重介绍全新VMware Sovereign Cloud计划</block>
  <block id="5b9c71ec3df81ec6ddb3b3f7a8188fb4" category="list-text"><block ref="5b9c71ec3df81ec6ddb3b3f7a8188fb4" category="inline-link-macro-rx"></block></block>
  <block id="a5af68d35cadca8efce14422ebb3c177" category="inline-link-macro">VMware Sovereign Cloud技术白皮书</block>
  <block id="dea776d3ac7a1db9ccd08deb4fcda30a" category="list-text"><block ref="dea776d3ac7a1db9ccd08deb4fcda30a" category="inline-link-macro-rx"></block></block>
  <block id="669983d47bdb9fa8052cb309166eac0b" category="sidebar">适用于主权云的VMware资源</block>
  <block id="dcfb6f5b67aa95780d10501d91c0cefa" category="sidebar">采用NetApp的VMware Sovereign Cloud：用例</block>
  <block id="abbeb77d0fd70c2e37f71c0b3324ea61" category="sidebar">StorageGRID作为对象存储扩展</block>
  <block id="7b3d5a145c3f76308664a64408c99eaa" category="sidebar">NetApp和VMware Sovereign Cloud</block>
  <block id="c3b79b7f428245629a780a6384a8a1a9" category="sidebar">主权云概述</block>
  <block id="c35913dc4f441893df75bf6ebf7ce3c0" category="sidebar">NetApp的用例</block>
  <block id="3c0f76e2d6fa82b2004270ec86f39aa7" category="paragraph">创建NFS共享后、将数据从HDFS EBS存储复制到ONTAP NFS共享中。数据驻留在 ONTAP 云的 NFS 中后，可以根据需要使用 SnapMirror 技术将数据从云镜像到内部存储，从而实现安全高效的方式。</block>
  <block id="a443e971c77259f92abfeb3191e66bd5" category="paragraph">借助NetApp NFS、客户可以对现有或新的NFSv3或NFSv4数据运行大数据分析作业、而无需移动或复制数据。它可以防止多个数据副本，并且无需将数据与源进行同步。例如，在金融领域，将数据从一个位置移动到另一个位置必须履行法律义务，这不是一项容易的任务。在这种情况下， NetApp NFS 直接访问会分析其原始位置的财务数据。另一个主要优势是，使用 NetApp NFS 直接访问可通过使用原生 Hadoop 命令简化对 Hadoop 数据的保护，并利用 NetApp 丰富的数据管理产品组合支持数据保护工作流。</block>
  <block id="ff0e15997f709c232408a5055738df05" category="paragraph">NetApp System Manager 或存储管理员提示符中的 Snapshot 副本。一致性组 Snapshot 副本是应用程序一致的组 Snapshot 副本， FlexClone 卷是根据一致性组 Snapshot 副本创建的。值得一提的是， FlexClone 卷会继承父卷的 NFS 导出策略。创建 Snapshot 副本后，必须安装一个新的 Hadoop 集群以用于 DevTest 和报告目的，如下图所示。从新Hadoop集群克隆的NFS卷可访问NFS数据。</block>
  <block id="6f2c5dcd0294b9c34430b1de4713c06d" category="paragraph">在此使用情形中、NetApp NFS卷帮助一家大型金融机构将备份时间从超过24小时缩短到几小时以内。</block>
  <block id="4ea48e5206de42785842cb864377766c" category="paragraph">如上图所示，来自传感器的数据会通过 Kafka 流式传输并输入到 AWS Spark 集群中。数据存储在 NPS 中的 NFS 共享中， NPS 位于 Equinix 数据中心内的云提供商之外。由于NetApp NPS分别通过Direct Connect和Express Route连接到Amazon AWS和Microsoft Azure、因此客户可以从Amazon和AWS分析集群访问NFS数据。这种方法解决了跨多个超大规模云提供商进行云分析的问题。</block>
  <block id="fb784db76f57bc935639ba5340089d77" category="cell">2023年11月</block>
  <block id="11ec45d75a4ad726423d44fadee3074a" category="cell">已删除NIPAM详细信息</block>
  <block id="ca9bf18599094e54193c13e68260f4a1" category="section-title">客户的现有备份解决方案</block>
  <block id="bc98837ed486c01d428d23d0c3a83d6a" category="paragraph">在解决方案A中、备份Hadoop集群会将二级备份发送到NetApp NFS存储系统、从而无需使用磁带、如下图所示。</block>
  <block id="1b449b0ea4a324dc81f41259db2c13e9" category="list-text">运行<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block> 命令利用Mapreduce"和多个映射程序、可以保护分析数据从Hadoop集群备份到NFS。</block>
  <block id="099eafc2208317136c2902383d7b0755" category="paragraph">解决方案B会将NFS卷添加到生产Hadoop集群中、从而无需备份Hadoop集群、如下图所示。</block>
  <block id="b8c0e409f361575b0a2787968f3e6737" category="paragraph">Hadoop本机<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> 命令可保护Hadoop数据从生产集群HDFS到NFS。</block>
  <block id="15089057e7e1dcee019d35458b18ed72" category="inline-link-macro">NetApp公告</block>
  <block id="17e2ffe7ea16377a3383f963821c7e4d" category="list-text"><block ref="17e2ffe7ea16377a3383f963821c7e4d" category="inline-link-macro-rx"></block></block>
  <block id="5a7ba809855186bf7ed82cff9d5e1cdf" category="summary">解决方案提供了有关在AWS中的VMware Cloud中部署和保护Oracle的概述和详细信息、其中、FSx ONTAP作为主数据库存储、Oracle数据库使用ASM作为卷管理器在独立重新启动时进行配置。</block>
  <block id="b8215f5d072996ac99e525e329cdc570" category="doc">TR-4979：《在AWS上的VMware Cloud中使用子系统装载的FSx ONTAP简化自管理Oracle》</block>
  <block id="57f6567867e5c3b757fdb3bee9c7654f" category="paragraph">几十年来、企业一直在私有数据中心运行基于VMware的Oracle。AWS上的VMware Cloud (VMC)提供了一个按钮式解决方案、可将VMware的企业级软件定义的数据中心(Software-定义 的数据中心、SDDC)软件引入AWS云的专用弹性裸机基础架构。AWS FSx ONTAP为VMC SDDC和Data Fabric提供高级存储、使客户能够在基于vSphere®的私有云、公共云和混合云环境中运行Oracle等业务关键型应用程序、并优化对AWS服务的访问。无论是现有的Oracle工作负载还是新的Oracle工作负载、AWS上的VMC都可以在VMware上提供熟悉、简化且自行管理的Oracle环境、并可享受AWS云的所有优势、同时将所有平台管理和优化工作推迟到VMware。</block>
  <block id="e73bc10aceb8a9e7c4ac45f0d1d0da5b" category="paragraph">本文档演示了如何在使用Amazon FSx ONTAP作为主数据库存储的VMC环境中部署和保护Oracle数据库。Oracle数据库可以作为直接VM子系统装载的LUN或NFS装载的VMware VMDK数据存储库磁盘部署到FSx存储上的VMC中。本技术报告重点介绍如何将Oracle数据库部署为使用iSCSI协议和Oracle ASM的VMC集群中的VM的直接子系统装载FSx存储。此外、我们还演示了如何使用NetApp SnapCenter UI工具备份、还原和克隆Oracle数据库以用于开发或测试、或者在AWS上的VMC中使用其他使用情形来实现高效存储数据库操作。</block>
  <block id="1bcbe40dab06a9681d7e0fcf5e561941" category="list-text">在AWS上的VMC中部署Oracle数据库、并将Amazon FSx ONTAP用作主数据库存储</block>
  <block id="8652360c0a7d6cf650f303d3611a363c" category="list-text">使用NetApp SnapCenter工具在AWS上的VMC中备份和还原Oracle数据库</block>
  <block id="cf30ea590ca185afdd551e920e4fade2" category="list-text">使用NetApp SnapCenter工具在AWS上的VMC中为开发/测试或其他使用情形创建Oracle数据库克隆</block>
  <block id="ef8cc3b3b7c4616678cc6819452f021a" category="list-text">希望使用Amazon FSx ONTAP在AWS上的VMC中部署Oracle的数据库开发人员</block>
  <block id="796c3d4a6179f628784371e4fb7fa9d9" category="list-text">希望在AWS云上的VMC中测试Oracle工作负载的数据库解决方案架构师</block>
  <block id="cb94ba9e822edf8670a9aedebc0852c1" category="list-text">希望使用Amazon FSx ONTAP部署和管理部署到AWS上VMC的Oracle数据库的存储管理员</block>
  <block id="b2777eda52c529f2b03fa9eced1c9680" category="list-text">希望在AWS云上的VMC中建立Oracle数据库的应用程序所有者</block>
  <block id="d172135745ee569873f61bcd3531f83e" category="paragraph">此解决方案的测试和验证是在AWS上使用VMC的实验室环境中执行的、该环境可能与最终部署环境不匹配。有关详细信息，请参见一节 <block ref="8ea96e516bccf9a47ca2d74131eb7519" category="inline-xref-macro-rx"></block>。</block>
  <block id="968ee2170dde4e5744b413462ee41e35" category="cell">一个FSx ONTAP HA集群与VMC位于同一VPC和可用性区域</block>
  <block id="a19ad08a54b29b409555bf1681f098ee" category="cell">VMC SDDC集群</block>
  <block id="cad01e8ce0c8a902e41beab182a6fe81" category="cell">Amazon EC2 i3.金属单节点/Intel Xeon E5-2686 CPU、36核/512G RAM</block>
  <block id="392bcaf841ff67a89aefe2473cff840b" category="cell">10.37 TB vSAN存储</block>
  <block id="1c212a485e9ad2c1762d607a18b009c7" category="cell">rell-8.6、4.18.0-372.9.1.el8.x86_64内核</block>
  <block id="95a90af1d5b68afaa24b9f917e25e4ec" category="cell">Windows服务器</block>
  <block id="42d321198a77603330bc430ffb26bda9" category="cell">2022标准版、10.0.20348内部版本20348</block>
  <block id="815500b6cb0b06f1db60bc89ea48ae53" category="cell">托管SnapCenter服务器</block>
  <block id="53a1507a1f45d24e7525d19279ab1ce7" category="cell">版本4.9P1</block>
  <block id="72867dcacfff3a93a471e5f8c9489599" category="cell">工作组部署</block>
  <block id="2d2a0d505d952b5fcde17cab075157a3" category="cell">1.0版</block>
  <block id="af6552ad45cff98ac3271a6c92ff6d19" category="cell">部署为一个ova vSphere插件虚拟机</block>
  <block id="6644cd5d665b50522c19c606bd2b1bde" category="cell">8.0.1.00300版</block>
  <block id="128d81403c72151caa28f9cb8909d048" category="cell">VMware Tools、版本：11365 - Linux、1352 - Windows</block>
  <block id="8ae78dca8fef9243be9f1089e2a97fb7" category="cell">打开JDK</block>
  <block id="3848bc77489b71d744f003ab713f7429" category="cell">版本java-1.8.0-OpenJDK.x86_64</block>
  <block id="3782cc74a007a1871c7229f0fc16f9f4" category="cell">DB VM上的SnapCenter插件要求</block>
  <block id="f7c55f54e2022628f07d7e62a55eec78" category="section-title">在AWS上的VMC中配置Oracle数据库</block>
  <block id="40142fee915d9c636c34c1581018dfaa" category="cell">* 服务器 *</block>
  <block id="0086e85e653acc061fd4d7315e2fa26d" category="cell">*DB存储*</block>
  <block id="460dc55b5ffb0266f2c889b06ee73344" category="cell">ORA_01</block>
  <block id="84e8b41cc4a43202bd012704510bd6b6" category="cell">cdb1 (cdb1_pdb1、cdb1_pdb2、cdb1_pdb3)</block>
  <block id="f1566e01e42cd3da5d95437ef837891d" category="cell">FSx ONTAP上的VMDK数据存储库</block>
  <block id="3e17b19d4466b08c46121ab170ec8b1d" category="cell">cdb2 (cdb2_pdb)</block>
  <block id="57fd581683176a30051cde40522ddce1" category="cell">ORA_02</block>
  <block id="be2e4558b7d000c11b6d37e9ed3f40c8" category="cell">cdb3 (cdb3_pdb1、cdb3_pdb2、cdb3_pdb3)</block>
  <block id="127cba96fa239f4b6e7834fe0c898c23" category="cell">直接子系统装载FSx ONTAP</block>
  <block id="9b7c2c624034bf5c8ad48b5e15db2c29" category="cell">cdb4 (cdb4_pdb)</block>
  <block id="6f65a6cc41917509aec67dd6572235ca" category="list-text">*FSx到VMC的连接。*当您在AWS上的VMware Cloud上部署SDDC时、它会在AWS帐户和专用于您的组织的VPC中创建、并由VMware进行管理。您还必须将SDDC连接到属于您的AWS帐户、称为客户AWS帐户。此连接允许SDDC访问属于您的客户帐户的AWS服务。FSx for ONTAP是在您的客户帐户中部署的一项AWS服务。将VMC SDDC连接到您的客户帐户后、VMC SDDC中的VM便可使用FSx存储来直接挂载子系统。</block>
  <block id="d646cd02ef2e3f2e443a3c7efd88d346" category="list-text">* FSX存储HA集群单区域或多区域部署。*在这些测试和验证中、我们在一个AWS可用性区域中部署了一个FSX HA集群。NetApp还建议在同一可用性区域中部署适用于NetApp ONTAP的FSx和基于AWS的VMware Cloud、以提高性能并避免可用性区域之间的数据传输费用。</block>
  <block id="1a38c6d0981634333a342ef435e9fcb4" category="list-text">* FSX存储集群规模估算。*适用于ONTAP 存储文件系统的Amazon FSX可提供高达160、000个原始SSD IOPS、高达4 Gbps吞吐量以及最大192 TiB容量。但是、您可以根据部署时的实际要求、根据已配置的IOPS、吞吐量和存储限制(最小1、024 GiB)来调整集群的大小。可以动态调整容量、而不会影响应用程序可用性。</block>
  <block id="3952b027a479110ef8d51b7631000bf0" category="list-text">* Oracle数据和日志布局。*在测试和验证中、我们分别为数据和日志部署了两个ASM磁盘组。在+data ASM磁盘组中、我们在一个数据卷中配置了四个LUN。在+logs ASM磁盘组中、我们在一个日志卷中配置了两个LUN。通常、在一个Amazon FSx for ONTAP卷中部署多个LUN可提高性能。</block>
  <block id="10fd1c6c748022c4eac81e0e7815e3c9" category="list-text">*iSCSI配置。* VMC SDDC中的数据库VM使用iSCSI协议连接到FSx存储。通过仔细分析Oracle AWR报告来确定应用程序和iSCSI流量吞吐量要求、衡量Oracle数据库峰值I/O吞吐量要求非常重要。NetApp还建议为正确配置多路径的两个FSX iSCSI端点分配四个iSCSI连接。</block>
  <block id="5fa486195592a222708baf1d0d84b596" category="list-text">*要用于创建的每个Oracle ASM磁盘组的Oracle ASM冗余级别。*由于FSx ONTAP已在FSx集群级别镜像存储、因此应使用外部冗余、这意味着此选项不允许Oracle ASM镜像磁盘组的内容。</block>
  <block id="5b9eec312e4891b17065381671c7234b" category="list-text">*数据库备份。* NetApp提供了一个SnapCenter软件套件、可通过用户友好的用户界面进行数据库备份、还原和克隆。NetApp建议实施此类管理工具、以实现快速(不到一分钟)的快照备份、快速(几分钟)的数据库还原和数据库克隆。</block>
  <block id="f02a238998ba2723f4626a5994f00464" category="paragraph">以下各节提供了在AWS上的VMC中将Oracle 19c部署ONTAP到单节点中的数据库VM的分步过程使用Oracle ASM作为数据库卷管理器重新启动配置。</block>
  <block id="3ebe73caee30b8d941aa7da02afb494d" category="list-text">我们创建了一个使用VMware Cloud on AWS的软件定义的数据中心(Software-definated Data Center、SDDC)。有关如何在VMC中创建SDDC的详细说明、请参见VMware文档 <block ref="8f2441f58c4fdf4959e58cb9afc7d8c0" category="inline-link-macro-rx"></block></block>
  <block id="8be484f960dc0192a878263a8ac3c41d" category="list-text">已设置AWS帐户、并已在您的AWS帐户中创建必要的VPC和网段。AWS帐户已链接到您的VMC SDDC。</block>
  <block id="1bbb79d8429a5f56d5bcc3e4783976a9" category="list-text">从AWS EC2控制台中、部署适用于ONTAP存储HA集群的Amazon FSx以托管Oracle数据库卷。如果您不熟悉FSX存储的部署、请参见相关文档 <block ref="17d8b312d287f0afd6f44b3f25c4f20b" category="inline-link-macro-rx"></block> 了解分步说明。</block>
  <block id="c7480d38cc7c53dd45b4135ac24c2e50" category="list-text">可以使用以下Terraform自动化工具包执行上述步骤、该工具包可创建一个EC2实例、作为通过SSH和FSx文件系统进行VMC访问时的SDDC的跳转主机。在执行前、请仔细阅读说明并根据您的环境更改变量。</block>
  <block id="ab75bf4284ff33ce0dff4b433e5cc77f" category="list-text">在AWS上的VMware SDDC中构建VM、用于托管要在VMC中部署的Oracle环境。在我们的演示中、我们构建了两个Linux VM作为Oracle数据库服务器、一个Windows服务器用于SnapCenter服务器、一个可选的Linux服务器作为可选的控制器、用于根据需要自动安装或配置Oracle。下面是用于解决方案验证的实验室环境的快照。</block>
  <block id="0ca3188ea78762727379ffff3db432b9" category="inline-image-macro">显示VMC SDDC测试环境的屏幕截图。</block>
  <block id="abb7f3bb8704666f8428401b2a2aea9b" category="paragraph"><block ref="abb7f3bb8704666f8428401b2a2aea9b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0f02fd8431ed2c0ed849e4a2cc644c9" category="list-text">此外、NetApp还提供了多个自动化工具包、以便在适用时运行Oracle部署和配置。请参见 <block ref="b0afda18826eac248fb3694e4dd33826" category="inline-link-macro-rx"></block> 有关详细信息 ...</block>
  <block id="d50fb02d2ad265b4dc8ea5d6a329f52c" category="admonition">确保已在Oracle VM根卷中至少分配50G、以便有足够的空间来暂存Oracle安装文件。</block>
  <block id="7b73a23b90df52ef2a02ef00b5200773" category="section-title">DB VM内核配置</block>
  <block id="9144d3423aec7a4a79da57105f06a978" category="paragraph">在配置了前提条件的情况下、以管理员用户身份通过SSH登录到Oracle VM、并使用sudo向root用户配置Linux内核以进行Oracle安装。Oracle安装文件可以暂存到AWS S3存储分段中、然后传输到VM。</block>
  <block id="5fa261bdb9bdacac6f1656fc0febc8c5" category="paragraph">请参见以下要在中说明的安装文件列表<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> 在DB VM上。</block>
  <block id="3f09cc7324f8c1244747932eaf3dc3ce" category="list-text">安装<block ref="c8dff58175a7ddfedf00d77953ef42dd" prefix=" " category="inline-code"></block>。</block>
  <block id="9b044ccb441d52e3c435f781b8c3488d" category="list-text">安装sg3_utils。</block>
  <block id="6e92674c0bf485348ed8c0cc3f038b5f" category="list-text">安装device-maper-Multipath。</block>
  <block id="5d1e157d7edb057e0d33d878529ef182" category="list-text">在中添加以下行<block ref="08561da4afe8299be4016c92bfe83435" prefix=" " category="inline-code"></block> 以禁用<block ref="d78ade61a64b6a278ed6278e7cfd91f3" prefix=" " category="inline-code"></block> 重新启动后。</block>
  <block id="b9104e6156e755e4d417f51a5619e651" category="list-text">将以下行添加到<block ref="8b5eec1c5f63341b700263cc37cbae02" prefix=" " category="inline-code"></block> 设置文件描述符限制和堆栈大小。</block>
  <block id="258d4c0ff1dcaaa41c50d5706b27500e" category="list-text">如果没有按照以下说明配置交换空间、请向DB VM添加交换空间： <block ref="53c9867a131506eab4afe1a1678bb974" category="inline-link-macro-rx"></block> 要添加的确切空间量取决于RAM大小、最高可达16G。</block>
  <block id="554a8b968dbbeb452b0d18a4f8d31077" category="list-text">为ASM管理用户(Oracle)添加ASM组。</block>
  <block id="d979e8c8a06dddf190cfc1c00bdbb48b" category="list-text">修改Oracle用户以将ASM组添加为辅助组(Oracle用户应在安装Oracle预安装RPM后创建)。</block>
  <block id="25cbc423fe11e7d196553da546d785d1" category="list-text">如果Linux防火墙处于活动状态、请停止并禁用它。</block>
  <block id="1ee999f15fe9c423eb377e0090aad2bf" category="list-text">通过取消注释为管理员用户启用无密码sudo<block ref="1cb32f4855eb0834d64969fe24edd26d" prefix=" " category="inline-code"></block> 行。更改文件权限以进行编辑。</block>
  <block id="e05fc5da4fb01e91a42e8baab993c77f" category="section-title">配置FSx ONTAP LUN并将其映射到数据库虚拟机</block>
  <block id="20767a279b850aa7f1bcaef1c31a5834" category="paragraph">通过ssh和FSx集群管理IP以fsxadmin用户身份从命令行登录到FSx集群、以配置三个卷。在卷中创建LUN以托管Oracle数据库二进制文件、数据文件和日志文件。</block>
  <block id="a4d17921e42af0c865a419c2383fc24e" category="list-text">验证已创建的卷。</block>
  <block id="fe34db0a054599cd0a406e3502d0ef5c" category="paragraph">命令的输出：</block>
  <block id="907146434a35238d633ca6753dd9c615" category="list-text">将LUN映射到上述创建的igroup。为每个附加LUN依次增加LUN ID。</block>
  <block id="223bac04448ebaf5c7f63e60fcdb0498" category="section-title">DB VM存储配置</block>
  <block id="a50ba1970162deb2e69ba6ac5cd43b03" category="paragraph">现在、导入并设置FSx ONTAP存储、用于在VMC数据库VM上安装Oracle网格基础架构和数据库。</block>
  <block id="25129372dcdad77bdf8f853444a467a1" category="list-text">从Windows跳转服务器使用Putty以管理员用户身份通过SSH登录到数据库VM。</block>
  <block id="159ce09d3368d57420a832ccbf7ef199" category="list-text">使用任一SVM iSCSI IP地址发现FSX iSCSI端点。更改特定于环境的门户地址。</block>
  <block id="669ffba4950ab12059582a3c3fa10940" category="list-text">以fsxadmin用户身份通过SSH登录到FSx ONTAP集群、以检索以6c574xxx...开头的每个LUN的串行十六进制编号、十六进制编号以3600a0980开头、即AWS供应商ID。</block>
  <block id="c44eb19dc7906a6753272e8a1de9b1cb" category="list-text">更改<block ref="a8946fa5f211c5345e3610710e471cb4" prefix=" " category="inline-code"></block> Oracle用户及其关联主组的挂载点所有权。</block>
  <block id="ebf44954c543813531faf671e318bdc9" category="list-text">以管理员用户身份通过SSH登录到DB VM、并通过取消注释启用密码身份验证<block ref="cd94e87e5216cd088acdc4de0e9c30f1" prefix=" " category="inline-code"></block> 然后进行注释<block ref="f18918133cfc22e041baab71b051c41f" prefix=" " category="inline-code"></block>。</block>
  <block id="d36d86c204f6126a4742f3c17a52b50a" category="list-text">准备<block ref="77d9f4d56c58834c8dacf6d0cb94e085" prefix=" " category="inline-code"></block> 文件以进行静默安装、并将rsp文件置于中<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> 目录。rsp文件应使用以下信息涵盖A、B和G部分：</block>
  <block id="9bd3ed1deb734d02d4b9004adb88c1ed" category="list-text">初始化磁盘设备以与Oracle ASM筛选器驱动程序结合使用。</block>
  <block id="f0c1c255ad4ee079686c5de8b56372a2" category="list-text">验证HA服务状态。</block>
  <block id="d4d4203c3b64386ed31cefd3e527f1fc" category="list-text">创建Oracle DB主目录并将其更改为该目录。</block>
  <block id="51fbc23284cfef48739fa117053b0496" category="list-text">在数据库主页中、修改<block ref="ef8657f0a0a00af93ba7f1c8885339ca" prefix=" " category="inline-code"></block> 并取消注释并替换<block ref="bb7738211dd8eb3dbadf4cc63ae8eb8a" prefix=" " category="inline-code"></block> 使用<block ref="b2affc1a941fe7e5e65933911250249c" prefix=" " category="inline-code"></block>。</block>
  <block id="900c7011e47a25c71c72d7baa3d4786b" category="list-text">从cdb3 home /u01/app/oracle/product/19.0.0/cdb3中、执行无提示纯软件DB安装。</block>
  <block id="77ca17b9b0d011a8a9693dea585ec113" category="list-text">以root用户身份运行<block ref="08030ad08b2b991d61b424afd8828758" prefix=" " category="inline-code"></block> 在纯软件安装后执行脚本。</block>
  <block id="c4cf035e92613b739d2fdb8f3f864b6e" category="list-text">以Oracle用户身份创建<block ref="c170c347c737b82ad62c48db1f7bff3c" prefix=" " category="inline-code"></block> 包含以下条目的文件：</block>
  <block id="29362c5952e8a273a25c1d86fc91d838" category="list-text">以Oracle用户身份、使用dbca启动数据库创建。</block>
  <block id="5483ea94e6740cb9506d49c7b420197b" category="paragraph">输出：</block>
  <block id="519ad91eddb5ee99b4c197b4172c79cf" category="list-text">重复步骤2中的相同过程、使用一个PDB在单独的oracle_home /u01/app/oracle/product/19.0.0/cdb4中创建容器数据库cdb4。</block>
  <block id="3a3a87b9aff1fff5afe3fd3a13cf4bec" category="list-text">作为Oracle用户、请在创建数据库后验证Oracle Restart HA服务、确认所有数据库(cdb3、cdb4)均已向HA服务注册。</block>
  <block id="1d891a18ce35238aed4ee18804d6c368" category="list-text">验证为cdb3创建的CDB/PDB。</block>
  <block id="2fa6ba00439ae530528e2071b0cae3b6" category="list-text">验证为cdb4创建的CDB/PDB。</block>
  <block id="7f1463c4022e8bf5ef77ee7b4272d57e" category="list-text">使用sqlplus以sysdba身份登录到每个cdb、并将两个CDBS的数据库恢复目标大小设置为+logs磁盘组大小。</block>
  <block id="d2dff87fed5b165c0917439bd2348ee6" category="list-text">使用sqlplus以sysdba身份登录到每个cdb、并使用以下命令集按顺序启用归档日志模式。</block>
  <block id="f2b57195a1baf4f2ad2f33b948c0307c" category="paragraph">至此、在适用于ONTAP存储的Amazon FSx和VMC DB VM上完成了Oracle 19c 19.18版重新启动部署。如果需要、NetApp建议将Oracle控制文件和联机日志文件重新定位到+logs磁盘组。</block>
  <block id="d372b360dda93a1ed98b047b474a8d14" category="section-title">使用SnapCenter进行Oracle备份、还原和克隆</block>
  <block id="d4c868638655b6a0f05ff19eb2dc90b3" category="section-title">SnapCenter设置</block>
  <block id="43b9d4da02f11505dff89d05efea04c6" category="inline-link-macro">您可以使用适用于 Oracle 数据库的插件执行什么操作</block>
  <block id="c6dd5b1c74dacee8c5ea6ea24ec47c61" category="paragraph">SnapCenter依靠数据库VM上的主机端插件来执行应用程序感知型数据保护管理活动。有关适用于Oracle的NetApp SnapCenter插件的详细信息、请参见此文档 <block ref="7a6b1ddf3a0731d31936d6522df7c6ca" category="inline-link-macro-rx"></block>。下面简要介绍了为Oracle数据库备份、恢复和克隆设置SnapCenter的步骤。</block>
  <block id="68f9ff06ec00760816a8852081d652a9" category="inline-link-macro">NetApp 支持下载</block>
  <block id="9f3f125ee631455138d3f4f0e7e3eab6" category="list-text">从NetApp 支持站点 下载最新版本的SnapCenter软件： <block ref="3cca19c7256555824970f142627f53d3" category="inline-link-macro-rx"></block>。</block>
  <block id="4e26d4a1dcc35c4e1d2dfd9c3b78e535" category="inline-link-macro">获取适用于桌面应用程序的Java</block>
  <block id="a6e522693361323d4999a459b325b038" category="list-text">以管理员身份从安装最新的Java JDK <block ref="1a0bb7a886be273015991771cf1b1190" category="inline-link-macro-rx"></block> 在SnapCenter服务器Windows主机上。</block>
  <block id="02e32891e3de53a22cecc990dca68e55" category="admonition">如果Windows服务器部署在域环境中、请将域用户添加到SnapCenter服务器本地管理员组、然后使用域用户运行SnapCenter安装。</block>
  <block id="d71146f6c986dedfe7a80892a16bf95a" category="list-text">以安装用户身份通过HTTPS端口8846登录到SnapCenter UI、以配置适用于Oracle的SnapCenter。</block>
  <block id="ce9b8e01e17b619f7f8a43211a1ffd57" category="list-text">更新<block ref="6b2d6702a0358e8df43b31cf0890a30f" prefix=" " category="inline-code"></block> 在全局设置中。</block>
  <block id="10f89a6808c7ca8a60e377ea9537da91" category="inline-image-macro">显示SnapCenter配置的屏幕截图。</block>
  <block id="85672e90c98085f57c2ae3c44917712f" category="paragraph"><block ref="85672e90c98085f57c2ae3c44917712f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c933eebaf80d285dfac08fec41a6a6b" category="list-text">创建Oracle数据库备份策略。理想情况下、请创建一个单独的归档日志备份策略、以便更频繁地进行备份、从而最大限度地减少发生故障时的数据丢失。</block>
  <block id="b7807a41275760e1b78e468d71930135" category="paragraph"><block ref="b7807a41275760e1b78e468d71930135" category="inline-image-macro-rx" type="image"></block></block>
  <block id="638c0eb2b08e7f1a3e5f520754df2492" category="list-text">添加数据库服务器<block ref="03bc142e6422dbb9b288ad2cabee08c7" prefix=" " category="inline-code"></block> 用于通过SnapCenter访问DB VM。此凭据在Linux VM上应具有sudo权限、在Windows VM上应具有管理员权限。</block>
  <block id="5e17eda957603128db38ebd2ac85c948" category="paragraph"><block ref="5e17eda957603128db38ebd2ac85c948" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd00724bb50c560f784951b9675078a9" category="list-text">将FSx ONTAP存储集群添加到<block ref="5c6ab1284b6b7a5a7102854a969c99be" prefix=" " category="inline-code"></block> 使用集群管理IP并通过fsxadmin用户ID进行身份验证。</block>
  <block id="06266ddd982682fde812804c954be4b8" category="paragraph"><block ref="06266ddd982682fde812804c954be4b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="026ec4d6f3dd2407e2e1278ccc1eb4de" category="list-text">将VMC中的Oracle数据库VM添加到<block ref="8124579383e90243e4b06323d2b37f8d" prefix=" " category="inline-code"></block> 使用上一步中创建的服务器凭据6.</block>
  <block id="7ea1ad2a56d7a348316923a11db03d9c" category="paragraph"><block ref="7ea1ad2a56d7a348316923a11db03d9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="363544b94b5ce99f22af62c11cdfb685" category="admonition">确保SnapCenter服务器名称可解析为数据库VM中的IP地址、而DB VM名称可解析为SnapCenter服务器中的IP地址。</block>
  <block id="025cf2f18f2e268b39a9e3b95afe5c03" category="section-title">数据库备份</block>
  <block id="569cda6ea25c5dbb40dbe351743ff809" category="paragraph">与基于RMAN的传统方法相比、SnapCenter利用FSx ONTAP卷快照加快数据库备份、还原或克隆速度。由于数据库在创建快照之前处于Oracle备份模式、因此这些快照是应用程序一致的。</block>
  <block id="edf9da3decc598bb9b93dc595dfb701a" category="list-text">从<block ref="ddcf50c29294d4414f3f7c1bbc892cb5" prefix=" " category="inline-code"></block> 选项卡中、将虚拟机添加到SnapCenter后、系统会自动发现虚拟机上的任何数据库。最初、数据库状态显示为<block ref="4aa6066b3ed6d1b995450c6c7ad4a3d8" prefix=" " category="inline-code"></block>。</block>
  <block id="893edc75ba61b6ca745222f511c30ed8" category="paragraph"><block ref="893edc75ba61b6ca745222f511c30ed8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a671953c31e073dfa8b0ed9da13f596" category="list-text">创建一个资源组、以按逻辑分组(如DB VM等)备份数据库 在此示例中、我们创建了一个ora_02_data组、用于对VM ora_02上的所有数据库执行完整的联机数据库备份。资源组ora_02_log仅在VM上执行归档日志备份。创建资源组还会定义执行备份的计划。</block>
  <block id="3e3cb6db0e0d4246d80184678b59bd99" category="paragraph"><block ref="3e3cb6db0e0d4246d80184678b59bd99" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b0d69d2347240232ff1724962274d17" category="list-text">单击也可以手动触发资源组备份<block ref="9af892ad254c844922acba8e89078d6d" prefix=" " category="inline-code"></block> 并使用资源组中定义的策略执行备份。</block>
  <block id="b1a4ac3cb7410f99fdf1e929fd2afa03" category="paragraph"><block ref="b1a4ac3cb7410f99fdf1e929fd2afa03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ddf172cecda6c976fecf4c27819e241" category="list-text">可通过监控备份作业<block ref="d2986ac8cb6bd55892099c1ffd6b1f6f" prefix=" " category="inline-code"></block> 选项卡、单击正在运行的作业。</block>
  <block id="b65cfc1d7fcd04e8f7f332746d62c572" category="paragraph"><block ref="b65cfc1d7fcd04e8f7f332746d62c572" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d972f47eb27d37493fd1b73f1c799699" category="list-text">成功备份后、数据库状态将显示作业状态和最近的备份时间。</block>
  <block id="24b01304b08e51fed8808b76ee6398c9" category="paragraph"><block ref="24b01304b08e51fed8808b76ee6398c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b29d7776717c0a002b1cfb23bba6ede" category="list-text">单击数据库以查看每个数据库的备份集。</block>
  <block id="4e28c2a57d60b499cdcc00a0f61b4827" category="paragraph"><block ref="4e28c2a57d60b499cdcc00a0f61b4827" category="inline-image-macro-rx" type="image"></block></block>
  <block id="381a4da48b283cb83eaca25d4d82a5a0" category="section-title">数据库恢复</block>
  <block id="5586b3dfa8d7aaa4771cba0c795dcc1c" category="paragraph">SnapCenter为Oracle数据库提供了许多从快照备份还原和恢复选项。在本示例中、我们展示了一个时间点还原、用于恢复因错误而丢弃的表。在VM ora_02上、两个数据库cdb3和cdb4共享相同的+data和+logs.磁盘组。一个数据库的数据库还原不会影响另一个数据库的可用性。</block>
  <block id="7cc816f478b8fdfd718bae0b9383c204" category="list-text">首先、创建一个测试表并在表中插入一行、以验证时间点恢复。</block>
  <block id="10196ada2a83568ea4b23ac007abb3e1" category="list-text">我们从SnapCenter运行手动快照备份。然后丢弃该表。</block>
  <block id="5ab664c5c8573a6f098f67e573077ddb" category="list-text">从上一步创建的备份集中、记下日志备份的scn编号。单击<block ref="2bd339d85ee3b33e513359ce781b60cc" prefix=" " category="inline-code"></block> 启动还原-恢复工作流。</block>
  <block id="315fed8f89b8c5b338500179379cc429" category="paragraph"><block ref="315fed8f89b8c5b338500179379cc429" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4d348e917d1812ea79e94ee7799918a" category="list-text">选择还原范围。</block>
  <block id="87db3e581fdf19b9ceda3b0023586483" category="paragraph"><block ref="87db3e581fdf19b9ceda3b0023586483" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d1ae3afc2dfbd2dfa9b6aa0b4557161" category="list-text">选择从上次完整数据库备份到日志scn的恢复范围。</block>
  <block id="5f7100fc833c9e13756fe1addbc1f2e1" category="paragraph"><block ref="5f7100fc833c9e13756fe1addbc1f2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c70ff881ea5d29e3a88b724e098e9d66" category="list-text">指定要运行的任何可选预处理脚本。</block>
  <block id="05078f6add244d809c383bed45780fd7" category="paragraph"><block ref="05078f6add244d809c383bed45780fd7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="81bc29b1b95871e6d5d7d76b917a005a" category="list-text">指定要运行的任何可选后处理脚本。</block>
  <block id="424f45782efa369bd2e988482819cd44" category="paragraph"><block ref="424f45782efa369bd2e988482819cd44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550a7e596b298565d43b08bbdc9e9502" category="list-text">根据需要发送作业报告。</block>
  <block id="daa0299e8620585899d0f25f2eb0321d" category="paragraph"><block ref="daa0299e8620585899d0f25f2eb0321d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c30b39b40cf957f005a8d97554cb792" category="list-text">查看摘要、然后单击<block ref="a20ddccbb6f808ec42cd66323e6c6061" prefix=" " category="inline-code"></block> 启动还原和恢复。</block>
  <block id="e4182860aaaaf13f444a75db3f793102" category="paragraph"><block ref="e4182860aaaaf13f444a75db3f793102" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b097285b35ac926b6e3a30da709b120" category="list-text">通过Oracle Restart网格控件、我们可以观察到、在恢复cdb3时、cdb4处于联机和可用状态。</block>
  <block id="683ed6b87193d258ccabd5e8ad26ed11" category="paragraph"><block ref="683ed6b87193d258ccabd5e8ad26ed11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b011ed6e72e83b31014ed609b024d671" category="list-text">from<block ref="d2986ac8cb6bd55892099c1ffd6b1f6f" prefix=" " category="inline-code"></block> 选项卡中、打开作业以查看详细信息。</block>
  <block id="edcbcb1388308ea29897aeba4d67d61c" category="paragraph"><block ref="edcbcb1388308ea29897aeba4d67d61c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8dc42fb122639d83a29d4d65e2b815e" category="list-text">从DB VM ora_02中、验证在成功恢复后是否已恢复丢弃的表。</block>
  <block id="82459660e8d561fc463b49540987f53f" category="section-title">数据库克隆</block>
  <block id="f6e7e97c5e19c813d868b9fef1ce8249" category="paragraph">在此示例中、使用相同的备份集克隆不同oracle_home中同一VM上的数据库。如果需要、这些过程同样适用于将数据库从备份克隆到VMC中的单独虚拟机。</block>
  <block id="166b0369d9dcd60c22b00908c9989b23" category="list-text">打开数据库cdb3备份列表。从所选的数据备份中、单击<block ref="ff24590464659ee8cdec688128c35f89" prefix=" " category="inline-code"></block> 用于启动数据库克隆工作流的按钮。</block>
  <block id="8884a3b01304139dad7b903ad06a0400" category="paragraph"><block ref="8884a3b01304139dad7b903ad06a0400" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26e18e582adb0a52168bd3417e7e507d" category="list-text">将克隆数据库命名为SID。</block>
  <block id="020ba895c5ede4e323c57c02fda1d9bd" category="paragraph"><block ref="020ba895c5ede4e323c57c02fda1d9bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1864ca75c3d9655e9c9c1fb1fea390df" category="list-text">在VMC中选择一个VM作为目标数据库主机。主机上应已安装和配置相同版本的Oracle。</block>
  <block id="f2d475f0f2d0c03930fdfb87708ed66b" category="paragraph"><block ref="f2d475f0f2d0c03930fdfb87708ed66b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c1b5c3a41783f4011163cf3a7694f36d" category="list-text">在目标主机上选择正确的oracle_home、用户和组。保留默认凭据。</block>
  <block id="9babaecbfa4c55df35c955ca48c71e0d" category="paragraph"><block ref="9babaecbfa4c55df35c955ca48c71e0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="991df28ae4ba0a10c1ae7d1cc1ea3292" category="list-text">更改克隆数据库参数以满足克隆数据库的配置或资源要求。</block>
  <block id="c6ca5ba171b4aa097ee12c8c90bdf3de" category="paragraph"><block ref="c6ca5ba171b4aa097ee12c8c90bdf3de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73ec64d1d5561a05f8953f32ccc418e3" category="list-text">选择恢复范围。<block ref="e6cb3190c21226943d9002045ab8a93a" prefix=" " category="inline-code"></block> 将克隆恢复到备份集中最后一个可用日志文件。</block>
  <block id="582f52e16891639865aa1d539ebc46aa" category="paragraph"><block ref="582f52e16891639865aa1d539ebc46aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f940cd9350acca488dc054b4cb0fd9e" category="list-text">查看摘要并启动克隆作业。</block>
  <block id="35103de66034af2bc4c3bb0e027bc3b5" category="paragraph"><block ref="35103de66034af2bc4c3bb0e027bc3b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6aaccd301944bbd2ed25852fb0e705a" category="list-text">通过监控克隆作业的执行情况<block ref="d2986ac8cb6bd55892099c1ffd6b1f6f" prefix=" " category="inline-code"></block> 选项卡。</block>
  <block id="efc1edfade1fbd6646dda59463983b2c" category="paragraph"><block ref="efc1edfade1fbd6646dda59463983b2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4eb7f9133e0f7dd8abfb2b1a117e57d8" category="list-text">克隆的数据库会立即注册到SnapCenter中。</block>
  <block id="aee2043864cad9a081fa4672728b956c" category="paragraph"><block ref="aee2043864cad9a081fa4672728b956c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65640816580ff72a56a1081922993c9f" category="list-text">从DB VM ora_02中、克隆的数据库也会注册到Oracle Restart网格控件中、而丢弃的测试表会恢复到克隆的数据库cdb3tst中、如下所示。</block>
  <block id="9f6329a70dd516951fa70a4f7a3a10ea" category="paragraph">至此、我们完成了在AWS上的VMC SDDC中对Oracle数据库进行SnapCenter备份、还原和克隆的演示。</block>
  <block id="ac9c0a61f41745e8c77a713ddf6821eb" category="list-text">VMware Cloud on AWS文档</block>
  <block id="c795642cf5dd34e946fb3142d8f52288" category="inline-link-macro"><block ref="c795642cf5dd34e946fb3142d8f52288" category="inline-link-rx"></block></block>
  <block id="450d2faa3005c2b5ef481da0fa99a49c" category="paragraph"><block ref="450d2faa3005c2b5ef481da0fa99a49c" category="inline-link-macro-rx"></block></block>
  <block id="7a84a73fe9b54c9478dfc0e58c918688" category="paragraph">ASM (Automatic Storage Management、自动存储管理)是许多Oracle安装中常用的Oracle存储卷管理器。这也是Oracle建议的存储管理解决方案。它提供了传统卷管理器和文件系统的替代方案。自Oracle 11g版以来、ASM一直采用网格基础架构而非数据库打包。因此、要在不使用RAC的情况下使用Oracle ASM进行存储管理、您必须在独立服务器中安装Oracle网格基础架构、也称为Oracle Restart。这样做无疑会增加Oracle数据库部署的复杂性。但是、顾名思义、在以重新启动模式部署Oracle时、出现故障的Oracle服务会由网格基础架构自动重新启动、或者在主机重新启动后无需用户干预、从而提供一定程度的高可用性或HA功能。</block>
  <block id="38c723472785b6d114cf9e85b7ffd3d1" category="list-text">* iSCSI配置。* EC2实例数据库服务器使用iSCSI协议连接到FSX存储。EC2实例通常使用一个网络接口或ENI进行部署。单个NIC接口可同时传输iSCSI和应用程序流量。请务必通过仔细分析Oracle AWR报告来衡量Oracle数据库峰值I/O吞吐量需求、以便选择既满足应用程序流量吞吐量要求又符合iSCSI流量吞吐量要求的正确EC2计算实例。NetApp还建议为正确配置多路径的两个FSX iSCSI端点分配四个iSCSI连接。</block>
  <block id="c5b771b8234c127dccd38858c77e24a0" category="list-text">添加要用于ASM sysASM组的ASM组。</block>
  <block id="35a8e6f6e0f2c89cd450cda8861ac889" category="list-text">停止并禁用处于活动状态的Linux防火墙。</block>
  <block id="432e3219f8a15b5476e2e71941cc6e61" category="list-text">将数据库恢复目标大小设置为+logs.磁盘组大小。</block>
  <block id="d41392db0c7e69ca86a4c8f0c8bc2a8f" category="doc">TR-4981：《借助Amazon FSx ONTAP降低Oracle Active Data Guard成本》</block>
  <block id="5afa567381b78444937fdc789ad61e1a" category="paragraph">如果您希望降低Oracle数据库运营成本、并计划在AWS中设置Active Data Guard、则应考虑另一种选择。使用Data Guard将数据从主数据库复制到Amazon FSx ONTAP存储上的单个物理备用数据库、而不是Active Data Guard。随后、可以克隆此备用数据库的多个副本并打开以进行读/写访问、以满足许多其他使用情形的需要、例如报告、开发、测试等 最终结果有效地提供了Active Data Guard的功能、同时消除了Active Data Guard许可证、并为每个额外的备用数据库节省了额外的存储成本。在本文档中、我们将演示如何在AWS中使用现有主数据库设置Oracle Data Guard、并将物理备用数据库放置在Amazon FSx ONTAP存储上。备用数据库通过Snapshot进行备份、并根据需要进行克隆、以便进行读/写访问。</block>
  <block id="309cd12bd99b7c9e7ad680fcef778228" category="list-text">在AWS中任何存储上的主数据库与Amazon FSx ONTAP存储上的备用数据库之间建立Oracle Data Guard。</block>
  <block id="1aadf275ee5a04d3c8ffb5a23e3f8f9b" category="cell">2023年11月27日</block>
  <block id="42f7b826cf30e5551e1f39ed1fa60120" category="paragraph">[Underline]#*适用于Oracle数据库的视频*#</block>
  <block id="7c0e65d458719c1a00061043a5c9b695" category="video-title">借助iSCSI在NetApp ASA上简化和自动化Oracle部署</block>
  <block id="f42a1319fb57cedbad32a23e45ec11fc" category="video-title">第1部分—在AWS和FSx中使用混合云打造Oracle现代化</block>
  <block id="91935697a3dec69875fc666d39a8fef8" category="sidebar">借助子系统装载的FSx ONTAP、在基于AWS的VMware Cloud中简化自我管理Oracle</block>
  <block id="8add5603a4a488cc171276dbbbed71ea" category="sidebar">借助AWS FSx ONTAP降低Oracle Active Data Guard成本</block>
  <block id="8d4ab3d80a936103be6c5ad407f12335" category="sidebar">基于AWS的VMware Cloud中的Oracle与子系统装载的FSx ONTAP</block>
  <block id="998e18ee910f7610303d504847d5f06d" category="sidebar">借助Amazon FSx ONTAP降低Oracle Active Data Guard成本</block>
  <block id="10d41f38bc95cdeefa9cfa148ff3ce23" category="paragraph">请访问 <block ref="401ec48193c76b048983762f48444f2d" category="inline-link-macro-rx"></block> 有关详细信息 ...</block>
  <block id="99fe6df2c175c51f618b547c9c5531ab" category="cell">2023年7月12日</block>
  <block id="9f46a807ff699639e2cc7823e6e6af0c" category="cell">TR-4983：《在采用iSCSI的NetApp ASA上简化的自动化Oracle部署》</block>
  <block id="a7577b3ed39dfbe88f44ad4e9ecf9d33" category="cell">新增TR-4981：《借助AWS FSx ONTAP降低Oracle Active Data Guard成本》</block>
  <block id="6fe128158b3a49eb57fa5fd65f346285" category="summary">解决方案提供了有关在NetApp ASA阵列中自动部署和保护Oracle的概述和详细信息、这些阵列使用iSCSI协议作为主数据库存储、而Oracle数据库则使用ASM作为卷管理器在独立重新启动时进行配置。</block>
  <block id="48b1c35e5d3a9a7a6193997c19dc15c4" category="paragraph">NetApp ASA系统为您的SAN基础架构提供现代化的解决方案。它们可以大规模简化并帮助您加快数据库等业务关键型应用程序的运行速度、确保数据始终可用(99.9999%的正常运行时间)、并降低TCO和碳排放量。NetApp ASA系统包括专为要求性能最苛刻的应用程序而设计的A系列型号和针对经济高效的大容量部署而优化的C系列型号。ASA A系列和C系列系统相结合、可提供卓越的性能、以改善客户体验并缩短取得成果的时间、保持业务关键型数据可用、受到保护和安全、并通过行业最有效的担保为任何工作负载提供更有效的容量。</block>
  <block id="5e1389ae5f652921b9ffd76077a35898" category="list-text">在NetApp ASA系统中自动部署Oracle数据库作为主数据库存储</block>
  <block id="2904575eaf0239e26839c87b5886427e" category="list-text">使用NetApp SnapCenter工具在NetApp ASA系统中进行Oracle数据库备份和还原</block>
  <block id="c9a02887c464e3024b4e7b8853bd3731" category="list-text">使用NetApp SnapCenter工具在NetApp ASA系统中为开发/测试或其他使用情形创建Oracle数据库克隆</block>
  <block id="475d53db06ccc49c194cd167ad6b6a7c" category="list-text">希望在NetApp ASA系统中部署Oracle的BA。</block>
  <block id="489fc03d48bb97d0eaaf947d524863e3" category="list-text">希望在NetApp ASA系统中测试Oracle工作负载的数据库解决方案架构师。</block>
  <block id="48b96d37ce8b7763e19ce55ff6b38bbc" category="list-text">希望在NetApp ASA系统上部署和管理Oracle数据库的存储管理员。</block>
  <block id="4d9a01e17799c2443651952a5571e588" category="list-text">希望在NetApp ASA系统中建立Oracle数据库的应用程序所有者。</block>
  <block id="0e9eaa00642412ade40b8fd3a255bf04" category="paragraph">此解决方案的测试和验证是在实验室环境中执行的、可能与最终部署环境不匹配。请参见一节 <block ref="8ea96e516bccf9a47ca2d74131eb7519" category="inline-xref-macro-rx"></block> 有关详细信息 ...</block>
  <block id="50ca835c71c489ce33e359fe138d33a1" category="cell">NetApp ASA A400</block>
  <block id="4fec937db99b8a74dd5bef9285d0e4c0" category="cell">版本9.13.1P1</block>
  <block id="37f8b8f146367f24cfb85a152645d03f" category="cell">2个NS224磁盘架、48个NVMe AFF驱动器、总容量为69.3 TiB</block>
  <block id="9c08b0397caf8f25e294bcbc2a0e51e0" category="cell">UCSB-B200-M4</block>
  <block id="e2ff57aae17fb4ecdf52974845c54701" category="cell">Intel (R) Xeon (R) CPU E5-2690 v4 @ 2.60GHz</block>
  <block id="c491601abe9558a73f61ab26d912bb5f" category="cell">4节点VMware ESXi集群</block>
  <block id="f53b4e7c2027602d331a4c185b942cc0" category="cell">VMware vSphere 虚拟机管理程序</block>
  <block id="1b0ad5208e7d764ed80119ac20af542d" category="cell">版本6.5.0.0000</block>
  <block id="696ee8cdabfa8fdd24a026188354d0b7" category="section-title">实验室环境中的Oracle数据库配置</block>
  <block id="96767712a689a097a11e94abd86cc050" category="cell">NTAP1 (NTAP1_PDB1、NTAP1_PDB2、NTAP_PDB3)</block>
  <block id="4fb5214b8185c21390fdea76917c92a6" category="cell">ASA A400上的iSCSI LUN</block>
  <block id="46be4f57ab41b19252133f7da26ea98c" category="cell">NTAP2 (NTAP2_PDB1、NTAP2_PDB2、NTAP2_PDB3)</block>
  <block id="b0398625aacfb5d5b9822b7812c9b00b" category="list-text">*Oracle数据库存储布局。*在此自动化Oracle部署中、我们默认配置四个数据库卷来托管Oracle二进制文件、数据和日志。然后、我们将使用数据和日志LUN创建两个ASM磁盘组。在+data ASM磁盘组中、我们会在每个ASA A400集群节点上的一个卷中配置两个数据LUN。在+logs ASM磁盘组中、我们会在一个ASA A400节点的日志卷中创建两个LUN。一般来说、在一个ONTAP卷中部署多个LUN可提高性能。</block>
  <block id="0d4f29ed9e7a7e62ee7c1007f59cf4fd" category="list-text">*部署多个数据库服务器。*自动化解决方案可以在一次运行的AnsablePlaybook中将一个Oracle容器数据库部署到多个数据库服务器。无论数据库服务器的数量如何、该操作手册的执行都保持不变。在部署多数据库服务器时、该操作手册会使用一种算法来构建数据库LUN、以便以最佳方式将其放置在ASA A400的双控制器上。控制器1上服务器主机索引位置中奇数数据库服务器的二进制和日志LUN。控制器2上服务器主机索引位置中偶数数据库服务器的二进制文件和日志LUN。数据库数据LUN平均分布到两个控制器。Oracle ASM将两个控制器上的数据LUN组合成一个ASM磁盘组、以充分利用这两个控制器的处理能力。</block>
  <block id="d736c1553b176f562bec3a52c7666a46" category="list-text">*iSCSI配置。*数据库VM使用iSCSI协议连接到ASA存储以进行存储访问。您应在每个控制器节点上配置双路径以实现冗余、并在数据库服务器上设置iSCSI多路径以实现多路径存储访问。在存储网络上启用巨型帧、以最大程度地提高性能和吞吐量。</block>
  <block id="324218b4c8087f7e5c5645ab81e7e37f" category="list-text">*Oracle ASM冗余级别用于创建的每个Oracle ASM磁盘组。*由于ASA A400会在RAID DP中配置存储、以便在集群磁盘级别进行数据保护、因此应使用<block ref="1f9ad4982cbae9fb459c61ba4e63bac9" prefix=" " category="inline-code"></block>，表示选项不允许Oracle ASM镜像磁盘组的内容。</block>
  <block id="e75571d5f211bacdfc757d78a94b1174" category="paragraph">以下各节提供了在NetApp ASA A400中使用直接挂载的数据库LUN通过iSCSI自动部署和保护Oracle 19c的分步过程、并将其部署到单节点中的数据库VM使用Oracle ASM作为数据库卷管理器的重新启动配置。</block>
  <block id="2b6209b8cfa6394be638dd05678f5955" category="inline-link-macro">详细指南—ASA A400</block>
  <block id="31204f552767acd2692e7c823fa43de2" category="list-text">假定已安装并配置NetApp ASA存储阵列。这包括两个控制器节点上的iSCSI广播域、LACP接口组a0a、两个控制器节点上的iSCSI &lt;iscsi-a-vlan-id&gt;端口(a0a-lacp-&lt;iscsi-b-vlan-id&gt;)。以下链接提供了详细的分步说明(如果需要帮助)。 <block ref="dac36656cf4136f69adb63b41114dcfc" category="inline-link-macro-rx"></block></block>
  <block id="4b7f6d2449e34b4ea603f0da9f1fbe25" category="list-text">克隆一份适用于iSCSI的NetApp Oracle部署自动化工具包副本。</block>
  <block id="21b9d06e7d54191458538a265ac76c29" category="list-text">配置Windows服务器以使用最新版本运行NetApp SnapCenter UI工具。有关详细信息、请参见以下链接： <block ref="131e9eb1b10c693e5b08c2ea655bbc23" category="inline-link-macro-rx"></block></block>
  <block id="708e23b82d10932400d291c3e2b3bc71" category="list-text">构建两个RHEL Oracle数据库服务器、可以是裸机VM、也可以是虚拟化VM。在不具有密码权限的sudo数据库服务器上创建一个管理员用户、并在Andsle主机和Oracle数据库服务器主机之间启用SSH专用/公共密钥身份验证。DB服务器/tmp/archive目录上的Oracle 19c安装文件后的阶段。</block>
  <block id="bed197af3286bd48fb98fb5ab7c412e8" category="admonition">请确保已在Oracle VM根卷中至少分配50G、以便有足够的空间来暂存Oracle安装文件。</block>
  <block id="c7cce81dff9cf2d89de25a04e65022ff" category="list-text">观看以下视频：</block>
  <block id="0d7d691fad590aa9a630443ea67bd9e3" category="section-title">自动化参数文件</block>
  <block id="fba0c848a47cb6bb0240eff0160df8c6" category="paragraph">Ans可 通过预定义的参数执行数据库安装和配置任务。对于此Oracle自动化解决方案、有三个用户定义的参数文件需要用户输入才能执行操作手册。</block>
  <block id="855c2f749e58e35ceee58f4017dc530f" category="list-text">主机—定义运行自动化操作手册的目标。</block>
  <block id="6f45aa108f0f48a8f2287aacfb4783b0" category="list-text">vars/vars.yml—用于定义应用于所有目标的变量的全局变量文件。</block>
  <block id="472b525267a1a194a67c4917378fdee0" category="list-text">host_vars/host_name.yml—用于定义仅适用于本地目标的变量的本地变量文件。在我们的使用情形中、这些是Oracle数据库服务器。</block>
  <block id="cab5395d741aa9c28cd5c2a21d7a0d82" category="paragraph">除了这些用户定义的变量文件之外、还有多个默认变量文件包含默认参数、除非必要、否则不需要更改这些参数。以下各节说明了如何配置用户定义的变量文件。</block>
  <block id="20cc11da843aa0ce89fbbd78488ae8e4" category="section-title">参数文件配置</block>
  <block id="d54f40d7ab3c0634ad1696cedcc056e5" category="list-text">可逆目标<block ref="85cf4e6d42a71e693fd780c8b29accdd" prefix=" " category="inline-code"></block> 文件配置：</block>
  <block id="5a4926a405d0ccf33e709fb7c676de97" category="list-text">全局<block ref="014d194d817c312b5ce910e74b4d3836" prefix=" " category="inline-code"></block> 文件配置</block>
  <block id="ca238f0541280751b05d697a897544e7" category="list-text">本地数据库服务器<block ref="0c83664bfb17d8d2c0bbc3551297e488" prefix=" " category="inline-code"></block> 配置</block>
  <block id="3fde1508528c4b7e4e8ed67ccec6aa4a" category="section-title">执行操作手册</block>
  <block id="14d9db80ea19110225e53e6d5acbfd0a" category="paragraph">自动化工具包中共有五本操作手册。每个任务执行不同的任务块、并用于不同的用途。</block>
  <block id="23dd50b88058bb1b19714aa9e0075a39" category="paragraph">使用以下命令可通过三个选项运行这些操作手册。</block>
  <block id="349525a68f403cd1f88f72915b15991b" category="list-text">使用1-4的数字顺序执行一次一个操作手册。</block>
  <block id="084e0a87eeeb8271a247c015eee77631" category="list-text">使用标记执行0-all_playbook.yml。</block>
  <block id="a9b2ae37ad24a5f409f16a4e39642547" category="list-text">撤消环境</block>
  <block id="ea74dbc6158f42a810daaf43cd099b11" category="section-title">执行后验证</block>
  <block id="4a14bc710ed72d934f5ba41fcf17501d" category="paragraph">运行该操作手册后、以Oracle用户身份登录到Oracle数据库服务器、以验证是否已成功创建Oracle网格基础架构和数据库。以下是在主机ora_01上验证Oracle数据库的示例。</block>
  <block id="4bdbd55cbefd29d973edca906ecf6bb7" category="list-text">验证创建的网格基础架构和资源。</block>
  <block id="a773c985c5b1ab20847bc20444a2ada8" category="admonition">忽略<block ref="6ea3b08636255f181e49cd8acbf4d75b" prefix=" " category="inline-code"></block> 在状态详细信息中。这是由于在侦听器中手动和动态数据库注册发生冲突而导致的、可以放心地忽略。</block>
  <block id="57f7f3c35be8fec41fec2c4cf2cd226c" category="list-text">验证ASM筛选器驱动程序是否按预期工作。</block>
  <block id="04bd1d337fb9a151a616cc5294c0c92a" category="list-text">登录到Oracle Enterprise Manager Express以验证数据库。</block>
  <block id="5c77c055267014cd170539e91c06519a" category="image-alt">此图提供Oracle Enterprise Manager Express的登录屏幕</block>
  <block id="85ebbf6138572e940325e081dbbe45e6" category="image-alt">此图提供了Oracle Enterprise Manager Express中的容器数据库视图</block>
  <block id="daacada39b443fddce73dce4738f4337" category="image-alt">此图提供了Oracle Enterprise Manager Express中的PDB数据库视图</block>
  <block id="6a56c935b27efdd9e9fde9e036ca687b" category="list-text">NetApp ASA：全闪存SAN阵列</block>
  <block id="fa78b7e09f15ae55ea12cbcb34d44847" category="inline-link-macro"><block ref="fa78b7e09f15ae55ea12cbcb34d44847" category="inline-link-rx"></block></block>
  <block id="1d2dc43013dd6328b22d33484061bd50" category="paragraph"><block ref="1d2dc43013dd6328b22d33484061bd50" category="inline-link-macro-rx"></block></block>
  <block id="2b77070b5c32e55f23537589ffd4f81f" category="list-text">将Red Hat Enterprise Linux 8.2与ONTAP结合使用</block>
  <block id="0a70ec939ee7a15f5b26fe9f48cb7667" category="inline-link-macro"><block ref="0a70ec939ee7a15f5b26fe9f48cb7667" category="inline-link-rx"></block></block>
  <block id="b37dd5ca6d78b3f11a3df8e7a9070fac" category="paragraph"><block ref="b37dd5ca6d78b3f11a3df8e7a9070fac" category="inline-link-macro-rx"></block></block>
  <block id="8c21b1cb48bb75d39598b2efc8c1246d" category="doc">TR-4979：《在AWS上的VMware Cloud中使用子系统装载的FSx ONTAP简化的自行管理Oracle》</block>
  <block id="5803335e5bcae83badcbc5583ac2d60e" category="sidebar">借助子系统装载的FSx ONTAP、在基于AWS的VMware Cloud中简化自我管理Oracle</block>
  <block id="366a32367c76504b66f48c17b771a662" category="sidebar">在采用iSCSI的NetApp ASA上简化、自动化的Oracle部署</block>
  <block id="5d2006f876181f3b98ec7d5380af6e7b" category="sidebar">适用于iSCSI的Oracle部署</block>
  <block id="2df63c64a06182bcc41618cc0e041735" category="sidebar">适用于NFS的Oracle部署</block>
  <block id="5fe141c77d102adcaccfa6da33564741" category="paragraph">这种新模式使客户能够创建更易于管理的Kafka集群、这些集群更易于迁移和镜像、以实现灾难恢复和数据保护。
我们还发现、NFS还可以通过NetApp ONTAP 提供更多优势、例如降低CPU利用率和加快恢复速度、显著提高存储效率以及提高性能。</block>
  <block id="3924240363e47a4a292119abc4a993a1" category="paragraph">本节介绍Splunk架构、包括关键定义、Splunk分布式部署、Splunk SmartStore、数据流、 硬件和软件要求、单站点和多站点要求等。</block>
  <block id="c7516072fbed3396e6f4c39a5f2356a6" category="paragraph">NetApp拥有三种存储产品组合：FAS/AFF、E系列和Cloud Volumes ONTAP。我们已通过Apache Spark验证了适用于Hadoop解决方案的AFF 和采用ONTAP 的E系列存储系统。</block>
  <block id="676df8e27b06b6dd639822191d432dc2" category="paragraph">对于此解决方案， NetApp 验证了将数据从数据湖（ HDFS ）和 MapR 集群数据迁移到 ONTAP NFS 的过程。数据驻留在 MapR-FS 和 HDFS 中。NetApp XCP 引入了一项新功能，可将数据从分布式文件系统（例如 HDFS 和 MapR-FS ）直接迁移到 ONTAP NFS 。XCP 使用异步线程和 HDFS C API 调用从 MapR- FS 以及 HDFS 进行通信和传输数据。</block>
  <block id="a19c0f0cd260f0aa330ee0c8f444da90" category="paragraph">下图显示了从数据湖（ HDFS ）和 MapR-FS 到 ONTAP NFS 的数据迁移。借助此新功能，您无需将源导出为 NFS 共享。</block>
  <block id="30f774bc5050b82b9a42fe5d8f4bc99f" category="paragraph">要使Confluent平台更具可扩展性和弹性、IT必须能够快速扩展和平衡工作负载。分层存储可减轻这种操作负担、从而使在Confluent中存储海量数据变得易于管理。</block>
  <block id="981ac9f1443bdd13b0920d6ca1ee4eb3" category="paragraph">基本理念是将数据存储与数据处理分离、这样可以更轻松地独立扩展每个存储。</block>
  <block id="1d766990d66db8e06b462398928288cd" category="paragraph">Hadoop DistCp 是一款原生工具，用于大型集群间和集群内复制。下图所示的 Hadoop DistCp 基本过程是一个典型的备份工作流，它使用诸如 MapReduce 等 Hadoop 原生工具将 Hadoop 数据从 HDFS 源复制到相应目标。</block>
  <block id="7cded69de10ed23fb288e8f481913718" category="paragraph">通过 NetApp NFS 直接访问，客户可以将 NFS 设置为 Hadoop DistCp 工具的目标，以便通过 MapReduce 将数据从 HDFS 源复制到 NFS 共享。NetApp NFS 直接访问可用作 DistCp 工具的 NFS 驱动程序。</block>
  <block id="05b28035d53f20383c30d39f0ee193a9" category="cell">2023年12月12日</block>
  <block id="f83e36a58dea42f0ef4a5a564f421ff9" category="cell">为Azure Cloud添加了新内容</block>
  <block id="77d69877921a79b6162a93d71c741849" category="paragraph">Iguazio 可以安装在内部或云提供商上。</block>
  <block id="f4a55dcbd9d85244b55a8f9c398dbba9" category="paragraph">配置可以作为一项服务来完成，并由 Iguazio 或客户进行管理。在这两种情况下， Iguazio 都会提供一个部署应用程序（ Provazio ）来部署和管理集群。</block>
  <block id="1fb5430a944de6ee0c1234772bea7c2a" category="summary">此页面介绍为Azure NetApp Files创建委派子网所需的步骤。</block>
  <block id="6977bb3543f8de6dcfa78f7970349ba1" category="paragraph">我们使用在一个NVIDIA V100 GPU上运行的PyTorch来应用混淆、并在两次运行之间清除了GPU缓存。在五次运行中、模糊步骤分别需要5.47毫秒、5.27毫秒、4.54毫秒、5.24毫秒和4.84毫秒才能完成。平均速度为5.072毫秒。</block>
  <block id="a274daca2deace9b89099b24f248715c" category="paragraph">我们会运行大量测试来评估建议的架构的性能。</block>
  <block id="37bf74d7f686cd395d40af1cc2ed7c55" category="paragraph">有六种不同的工作负载（图像分类，对象检测（小），对象检测（大），医学影像，语音到文本， 和自然语言处理（ NLP ），您可以在三种不同的情形下运行：脱机，单流和多流。</block>
  <block id="cf285ec96f684d6597b7ffbbfcf16197" category="doc">从何处查找追加信息和相关信息</block>
  <block id="994c1f46e0860094a86d2a822416646b" category="paragraph">此处验证的NetApp和联想解决方案 是一种灵活的横向扩展架构、非常适合入门级企业AI。</block>
  <block id="bcbfcce438abee9a9a41cb7e588eb4de" category="paragraph">NetApp存储可提供与本地SSD存储相同或更好的性能、并为数据科学家、数据工程师和IT决策者带来以下优势：</block>
  <block id="32941fe507e35e7690b95531087a8523" category="inline-link-macro">NetApp ONTAP可在Red Hat OpenShift容器平台中将日志的存储容量提高一倍 </block>
  <block id="21af971ee17531dadbb5445918131ac6" category="video-title">使用Asta Control Center执行故障转移故障恢复</block>
  <block id="ae4e918956cc077491dbbd3abc0d2578" category="doc">追加信息和联系信息</block>
  <block id="605f3b4a402341f522af61f8a90e124d" category="paragraph">其中包括(但不限于)以下内容：</block>
  <block id="08e39b83c06e5831db0f01a71f302ab2" category="paragraph">NetApp解决方案工程部的Allen Cao</block>
  <block id="305421fd1d1b88bcd273862dd1e901c1" category="paragraph">SnapCenter 支持的每个数据库平台都有一个专用的管理员用户 ID ，用于数据库备份，还原和 / 或灾难恢复，这一点很有意义。您也可以使用一个 ID 来管理所有数据库。在测试用例和演示中，我们分别为 Oracle 和 SQL Server 创建了一个专用管理员用户。</block>
  <block id="2f50a2bd9a618d76d31ee4053b7786ae" category="paragraph">已使用下表所示的版本对解决方案的方案5进行了验证：</block>
  <block id="cba8b033a05e59ab8229f6c91cf17c9a" category="cell">OpenShift 4.13.25
在内部和Azure中</block>
  <block id="34784cc0fea6d2267df747c34d7e8553" category="cell">通过三项技术实现的服务器和客户端以及Astra Control配置程序23.10.0</block>
  <block id="5e68558165679f67cdaeb12471891522" category="cell">行政协调会23.10.</block>
  <block id="d0b55d3b0b9d8025eb06e76618f6bf8a" category="inline-link-macro">在Azure上安装OpenShift集群</block>
  <block id="335fb62e4da3aa69274963639828ffc9" category="paragraph">以下是一些其他文档供参考：
1. <block ref="299437d2dfff10029aa68548910ed14a" category="inline-link-macro-rx"></block>
2. <block ref="7113f7690b69458a12c8968b2e7b5c94" category="inline-link-macro-rx"></block>
3. <block ref="bf8803e28a55e6b11cf02bdf9ab03853" category="inline-link-macro-rx"></block>
4. <block ref="0de84e35816fe2bf24a2d62358c71ec0" category="inline-link-macro-rx"></block>
5. <block ref="c17964cf4aee883c1f79b2b18d5cf8c5" category="inline-link-macro-rx"></block>
6. <block ref="c4a315706dd2011b5383e54e9b2917d4" category="inline-link-macro-rx"></block>
7. <block ref="e1b08234af7069664eedc35420a1cc41" category="inline-link-macro-rx"></block>
8. <block ref="97e9aa45cc61b723d7185c3008313d78" category="inline-link-macro-rx"></block>
9 <block ref="ac3186bd76a04d061f68b4574a7220d5" category="inline-link-macro-rx"></block>
10. <block ref="2f4df966d6adc25fd002d42aba0522c1" category="inline-link-macro-rx"></block>
11. <block ref="c2f5b2c54b56c4b456371849b6825da6" category="inline-link-macro-rx"></block> —Verda (开源)为常见的云原生数据密集型应用程序提供了一组参考执行挂钩
12 。 <block ref="b0fea8555edb70fb5a01c464b6a09cbb" category="inline-link-macro-rx"></block>
13. <block ref="ca0553647614febb5dfa86b86874cf2f" category="inline-link-macro-rx"></block>
14. <block ref="c869624abab2a4d09eb6e20d1fe18e5e" category="inline-link-macro-rx"></block>
15. <block ref="b6d7b323dede2a4e24afaa7b9dd5984f" category="inline-link-macro-rx"></block>
16. <block ref="30bef8c4d342eeb1d1f466a9ea23121d" category="inline-link-macro-rx"></block></block>
  <block id="7dd87b751ef68940a1312b47b05c1df8" category="doc">在Azure上部署和配置Red Hat OpenShift容器平台</block>
  <block id="c4889a04b87200a47c54bff050e1fe85" category="paragraph">本节简要介绍了如何在Azure中设置和管理OpenShift集群并在其上部署有状态应用程序的工作流。它展示了如何借助Asta三端磁盘/Asta控件配置程序使用NetApp Cloud Volumes ONTAP存储来提供永久性卷。本节详细介绍了如何使用Astra Control Center为有状态应用程序执行数据保护和迁移活动。</block>
  <block id="f83db3cc311fd924fcfeea65b9fb74a0" category="paragraph">下图显示了部署在Azure上并使用VPN连接到数据中心的集群。</block>
  <block id="d435634e1130201ebaff428f4390dbf7" category="paragraph"><block ref="d435634e1130201ebaff428f4390dbf7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af1650a16c37cdf7c7778ddd9cea8683" category="admonition">可以通过多种方法在Azure中部署Red Hat OpenShift容器平台集群。此高级设置问题描述 提供了所用特定方法的文档链接。您可以在中提供的相关链接中参考其他方法 <block ref="ec30323d5c1ba24d6aabb0b3df901fd1" category="inline-link-macro-rx"></block>。</block>
  <block id="e48a8638636d8a3f7826e829d6166418" category="example-title">使用命令行界面在Azure上安装OCP集群。</block>
  <block id="9724bc82f58f261a75898cc300f0b993" category="list-text">确保您已满足上述所有前提条件 <block ref="3aae5312888d8e9223e629f14f295a63" category="inline-link-macro-rx"></block>。</block>
  <block id="811d1cf13b4e3820eec83db1c4c05fe6" category="list-text">创建VPN、子网和网络安全组以及专用DNS区域。创建VPN网关和站点间VPN连接。</block>
  <block id="88300001929e9a793a02e0e2955279cd" category="list-text">对于内部环境与Azure之间的VPN连接、我们会创建并配置一个pfSense VM。有关说明，请参见 <block ref="be1f25e1c0fba9929238d326827b9fa7" category="inline-link-macro-rx"></block>。</block>
  <block id="b0f1e5ccb49619c57e880ef68847b35d" category="list-text">获取安装程序和拉取密钥、然后按照文档中提供的步骤部署集群 <block ref="3aae5312888d8e9223e629f14f295a63" category="inline-link-macro-rx"></block>。</block>
  <block id="c8a9f594886c5614d298ffe7ce45e839" category="paragraph">下面提供了一个示例install-config.yaml文件。</block>
  <block id="e4e0602228585217e17627fb546a2623" category="example-title">使用BlueXP在Azure中部署Cloud Volumes ONTAP。</block>
  <block id="b4f094c5d401a3bdde752abf96e221c6" category="list-text">在Azure中的中安装连接器。请参阅说明<block ref="4a3c6331bb206b0a168b594babb0a8f6" category="inline-link-rx"></block>。</block>
  <block id="da66c8a42102d0a32685084b71c01ad2" category="list-text">使用连接器在Azure中部署CVO实例。请参阅说明链接：https://docs.netapp.com/us-en/bluexp-cloud-volumes-ontap/task-getting-started-azure.html [此处]。</block>
  <block id="4a7cb2e5de8b8746b57ee586a6d7eaa9" category="example-title">在Azure的OCP集群中安装A作用 力控制配置程序</block>
  <block id="4c0c0cd6016d7bcdc06518cc7a5b640e" category="list-text">对于此项目、所有集群(即、部署了Astra Control Center的集群、Azure中的集群)上都安装了Astra Control置管程序(ACP)。了解有关Astra Control配置程序的更多信息 <block ref="a28a09f05bc8fbb0904dbf1e395066b2" category="inline-link-macro-rx"></block>。</block>
  <block id="b9f3b78ec391f6a697dfddd774f36058" category="example-title">将Azure上的OCP集群添加到Asta控制中心。</block>
  <block id="a09bb554da4ec8e5fc0324d3572de9b9" category="video-title">使用Asta Control对应用程序进行故障转移和故障恢复</block>
  <block id="31785036e45820f58909e6d05372e4de" category="paragraph">内部部署和Azure Cloud
<block ref="d435634e1130201ebaff428f4390dbf7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9425d614f064104bce0a104a933f137f" category="section-title">使用ACC进行灾难恢复(使用复制进行故障转移和故障恢复)</block>
  <block id="911dfc75aae37dbea6cc7ec160568e9e" category="section-title">方案2：使用ACC保护数据并将其从内部环境迁移到AWS环境</block>
  <block id="a528051afdc7f56e98729098e73932f0" category="section-title">方案3：数据保护以及从内部环境迁移到AWS环境</block>
  <block id="cf7ee61bd203ad352d26a506b30c3883" category="section-title">方案4：使用ACC保护数据并将数据从内部环境迁移到GCP环境</block>
  <block id="d675e9ebfebba6207b2e01c7768dd7a3" category="section-title">方案5：使用ACC保护数据并将其从内部环境迁移到Azure环境</block>
  <block id="84493eb1130bee461c87f4c31486e3e4" category="paragraph">**内部：自行管理的OpenShift集群和自行管理的存储**
**Azure云：自行管理的OpenShift集群和自行管理的存储**</block>
  <block id="7d1b310b3f292b374b1a08858d811f05" category="sidebar">具有自管理组件的混合云(内部/AWS/GCP/Azure)</block>
  <block id="2092f70b0355443a51f304e5101b3b38" category="sidebar">在Azure上配置Red Hat OpenShift容器工作负载</block>
  <block id="bad091449eff31ae9df2f59050033137" category="sidebar">保护AWS/GCP/Azure上的容器工作负载</block>
  <block id="53232fd3d5921b3fcc95da8d49e62e0e" category="sidebar">将容器工作负载迁移到AWS/GCP/Azure</block>
  <block id="6a896de8ede63deb377202193b9ffa70" category="video-title">利用DataOps工具包和Asta Control Center云爆发实现DevOps加速</block>
  <block id="3d8ec74e0747a0bf20b9d69d3b1e8b22" category="cell">2023年12月18日</block>
  <block id="9defd6af131e71c31d1fe854d4bebe84" category="summary">解决方案提供了有关在Amazon FSx ONTAP中作为主数据库存储自动部署和保护Oracle的概述和详细信息、其中、iSCSI协议和Oracle数据库配置为在使用Oracle ASM作为卷管理器的独立重新启动中进行。</block>
  <block id="5eb39e783da94614fe437cb8972074ad" category="paragraph">Amazon FSx for NetApp ONTAP是一项存储服务、支持您在AWS云中启动和运行完全托管的NetApp ONTAP文件系统。它提供了NetApp文件系统的熟悉特性、性能、功能和API、并具有完全托管的AWS服务的灵活性、可扩展性和精简性。它支持您在AWS云中运行要求最严苛的数据库工作负载、例如Oracle、让您高枕无忧。</block>
  <block id="ad023f21227a34bd31c4a07a26c3ceeb" category="paragraph">本文档演示了如何使用Ans可 自动化在Amazon FSx ONTAP文件系统中简化Oracle数据库的部署。Oracle数据库部署在独立重新启动配置中、使用iSCSI协议进行数据访问、使用Oracle ASM进行数据库存储磁盘管理。它还提供了有关使用NetApp SnapCenter UI工具在AWS云中执行高效存储数据库操作的Oracle数据库备份、还原和克隆的信息。</block>
  <block id="36efee6c5a9ee80f8e017f827d0aa10f" category="list-text">在Amazon FSx ONTAP文件系统上自动部署Oracle数据库</block>
  <block id="67edc5be7c44db05533e39c0f055b6e1" category="list-text">使用NetApp SnapCenter工具在Amazon FSx ONTAP文件系统上执行Oracle数据库备份和还原</block>
  <block id="d9fdf48773f4a0e6b5b486cb7ec20ead" category="list-text">使用NetApp SnapCenter工具在Amazon FSx ONTAP文件系统上为开发/测试或其他使用情形创建Oracle数据库克隆</block>
  <block id="b3dbcb0d704aa6ab5e0e9325ece5ed0a" category="list-text">希望在Amazon FSx ONTAP文件系统上部署Oracle的数据库开发人员。</block>
  <block id="35c5697c1fb69cf8f643be61e3004cda" category="list-text">希望在Amazon FSx ONTAP文件系统上测试Oracle工作负载的数据库解决方案架构师。</block>
  <block id="20434e12c335486055c3510da159f861" category="list-text">希望在Amazon FSx ONTAP文件系统上部署和管理Oracle数据库的存储管理员。</block>
  <block id="23daaf0d27ae240487b8a4d1938bc5ef" category="list-text">希望在Amazon FSx ONTAP文件系统上建立Oracle数据库的应用程序所有者。</block>
  <block id="2d7e4e3e15ade6aac7796a854a656276" category="cell">Amazon FSx ONTAP存储</block>
  <block id="7e6308718e9f24d724f497fc5ef23cd2" category="cell">两个EC2 T2大型EC2实例、用于并发部署</block>
  <block id="53c4eb7bf80a61459560a0d2c63d513a" category="cell">Amazon FSx ONTAP文件系统上的iSCSI LUN</block>
  <block id="94b06bafed4a2fc40a5a6d7e8836f0e6" category="list-text">*Oracle数据库存储布局。*在此自动化Oracle部署中、我们默认配置四个数据库卷来托管Oracle二进制文件、数据和日志。卷中的一个LUN分配给Oracle二进制文件。然后、我们将使用数据和日志LUN创建两个ASM磁盘组。在+data ASM磁盘组中、我们配置两个数据卷、其中一个卷包含两个LUN。在+logs ASM磁盘组中、我们会在一个日志卷中创建两个LUN。一般来说、在一个ONTAP卷中部署多个LUN可提高性能。</block>
  <block id="515a6f662581dbf5fadf71e23b6029a6" category="list-text">*部署多个数据库服务器。*自动化解决方案可以在一次运行的AnsablePlaybook中将一个Oracle容器数据库部署到多个数据库服务器。无论数据库服务器的数量如何、该操作手册的执行都保持不变。您可以将多个容器数据库部署到具有不同数据库实例ID (Oracle SID)的单个EC2实例。但是、请确保主机上有足够的内存来支持已部署的数据库。</block>
  <block id="e20408188cf4521115d65495b7b67a54" category="list-text">*要用于创建的每个Oracle ASM磁盘组的Oracle ASM冗余级别。*由于Amazon FSx ONTAP已启用HA、可在集群磁盘级别保护数据、因此应使用<block ref="1f9ad4982cbae9fb459c61ba4e63bac9" prefix=" " category="inline-code"></block>，表示选项不允许Oracle ASM镜像磁盘组的内容。</block>
  <block id="6775f2209818a69f1e1e3a6ed8b4aecf" category="paragraph">以下各节提供了在使用直接挂载的数据库LUN的Amazon FSx ONTAP文件系统上自动部署和保护Oracle 19c的分步过程、这些LUN通过iSCSI传输到EC2实例VM、采用Oracle ASM作为数据库卷管理器的单节点重新启动配置。</block>
  <block id="960e137d6acb4fa6cfda82d7568472c0" category="list-text">从AWS EC2控制台中、将EC2 Linux实例部署为Oracle数据库服务器。为EC2用户启用SSH专用/公共密钥身份验证。有关环境设置的详细信息、请参见上一节中的架构图。另请查看 <block ref="b75ecbbec453f67f58d497ccd97a8075" category="inline-link-macro-rx"></block> 有关详细信息 ...</block>
  <block id="70af9dc6b3b24812bb0ab351f929c0f8" category="list-text">从AWS FSx控制台中、配置满足要求的Amazon FSx ONTAP文件系统。查看文档 <block ref="17d8b312d287f0afd6f44b3f25c4f20b" category="inline-link-macro-rx"></block> 了解分步说明。</block>
  <block id="639b65d4c9e702c350d8464f45f4ae2d" category="list-text">将EC2 Linux实例配置为安装了最新版本的Ansv近 和Git的Ansv可 控制器节点。有关详细信息、请参见以下链接： <block ref="d1250df0700152003f00dbe5bac89608" category="inline-link-macro-rx"></block> 在第-节中<block ref="3d45b043c5518eca1e47fb4ba8a813da" prefix=" " category="inline-code"></block> 或<block ref="2afb5cc3404c6c8162722fd41895c2de" prefix=" " category="inline-code"></block>。</block>
  <block id="1f9545764510c505dd39a46cecb920cf" category="list-text">EC2实例/tmp/archive目录中的Oracle 19c安装文件后的阶段。</block>
  <block id="29a85eb1ecf92566b79f102d023963d4" category="video-title">在采用iSCSI的Amazon FSx ONTAP上简化和自动化Oracle部署</block>
  <block id="b8e52c009307e1df8a80bbea8f5176d9" category="list-text">host_vars/host_name.yml—用于定义仅适用于指定目标的变量的本地变量文件。在我们的使用情形中、这些是Oracle数据库服务器。</block>
  <block id="0e67f9b1dd3b15c078e6f2a316790949" category="paragraph">除了这些用户定义的变量文件之外、还有多个默认变量文件包含默认参数、除非必要、否则不需要更改这些参数。以下各节介绍如何配置用户定义的变量文件。</block>
  <block id="1a759fef0c9f698bb151c9b107a2fb30" category="list-text">本地数据库服务器<block ref="0c83664bfb17d8d2c0bbc3551297e488" prefix=" " category="inline-code"></block> 配置，如ora_01.yml、ora_02.yml ...</block>
  <block id="72ff430412347ee147549697444cc1b2" category="list-text">验证EC2实例上的Oracle容器数据库</block>
  <block id="c6d315df01ffba499100948d7f6d68c1" category="list-text">验证Oracle侦听器。</block>
  <block id="dd4284a741b150a5c9e18aa61fe4f607" category="list-text">验证Oracle ASM。</block>
  <block id="dc7ae7e9c638387699e356b155145c40" category="paragraph">请参阅TR-4979 <block ref="c20f17fc2e5f1396430a5d0ec62c8eda" category="inline-link-macro-rx"></block> 部分。<block ref="d372b360dda93a1ed98b047b474a8d14" prefix=" " category="inline-code"></block> 有关设置SnapCenter以及执行数据库备份、还原和克隆工作流的详细信息。</block>
  <block id="64de5a7dfd6282ca282a38cee5f5a0b6" category="sidebar">在采用iSCSI的Amazon FSx ONTAP上简化的自动化Oracle部署</block>
  <block id="600a8f54bd1410ab03d982399a7d2fc0" category="example-title">3-2-1数据保护解决方案</block>
  <block id="e43b409384cf356c7261e3c8971943f1" category="paragraph">3-2-1数据保护解决方案使用SnapMirror技术将内部主备份和二级备份与使用BlueXP备份和恢复将复制的副本整合到对象存储中。</block>
  <block id="c7bff2f2cbfa1a6b11f9a154c750cad9" category="video-title">3-2-1使用适用于VMware vSphere的SnapCenter插件和适用于虚拟机的BlueXP备份和恢复对VMFS数据存储库进行数据保护</block>
  <block id="a1722ee1a41c4364dfc3dcf1cca5c81b" category="example-title">NetApp Cloud Insights</block>
  <block id="9dca55ac55f13f701765725f8cf5c985" category="paragraph">NetApp Cloud Insights是一款全面的监控和分析平台、旨在提供对内部和云基础架构的可见性和控制。</block>
  <block id="93a31c2d8bd53682f99f570fbf24e946" category="video-title">NetApp Cloud Insights—现代数据中心的可观察性</block>
  <block id="83e9856e9d6140781dad6d19f316e08c" category="summary">本文提供了有关使用AWS SageMaker将FSxN配置为私有S3存储分段的指南。</block>
  <block id="af98be851b2e51f090cd51feafbfd4fc" category="doc">第1部分—将AWS FSx for NetApp ONTAP (FSxN)作为私有S3存储分段集成到AWS SageMaker中</block>
  <block id="e0e4adbb40dea224d3249b910112c156" category="paragraph">本页以SageMaker为例、提供将FSxN配置为私有S3存储分段的指导。</block>
  <block id="69620f6919f430e72c0f67207535605b" category="inline-link-macro">视频链接</block>
  <block id="28c7b2b0dbf1eba73ad2f4cd747b7ef9" category="paragraph">有关FSxN的更多信息、请观看此演示文稿(<block ref="f781ab67717d91cabffd32c6ef2dd731" category="inline-link-macro-rx"></block>）</block>
  <block id="7a97419a6312bf2f5dcdb87d844f3d07" category="section-title">用户指南</block>
  <block id="2f5513954af7462427835c65fbeeac6d" category="section-title">创建服务器</block>
  <block id="aa5fe14483191172e4fb6ae032e063db" category="section-title">创建SageMaker笔记本实例</block>
  <block id="22a9741b15ba6b8515c1bcf1eb1e2424" category="list-text">打开AWS控制台。在搜索面板中、搜索SageMaker并单击服务*亚马逊SageMaker *。</block>
  <block id="3476e29fba1f99a45d42fc3106ef69ff" category="inline-image-macro">错误：打开AWS控制台</block>
  <block id="7a3442fcd08aee3ef7cada38cab36691" category="paragraph"><block ref="7a3442fcd08aee3ef7cada38cab36691" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b8d9a34ee98c3b1e7231bdb38a022c7" category="list-text">打开“笔记本”选项卡下的“*笔记本实例*”，单击橙色按钮*创建笔记本实例*。</block>
  <block id="5967dd758f5e8b7a5b13714ee9eec573" category="inline-image-macro">错误：AWS SageMaker笔记本实例控制台</block>
  <block id="f4be1c22ae1980d94aba00017045fc9c" category="paragraph"><block ref="f4be1c22ae1980d94aba00017045fc9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5adb63a7f1793cbf65bf20f56169f00" category="inline-image-macro">错误：创建笔记本实例</block>
  <block id="ed37a29c5c8b3dad1766b67612c4c5ec" category="paragraph"><block ref="ed37a29c5c8b3dad1766b67612c4c5ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd5c8a6e0acf4bab9cce5bb55f03978e" category="section-title">创建FSxN文件系统</block>
  <block id="a0de53cada8c076391cb766a21d191f7" category="list-text">打开AWS控制台。在搜索面板中，搜索FSx并单击服务*FSX*。</block>
  <block id="19f7553a220ccabad6711e70473524c2" category="inline-image-macro">错误：FSx面板</block>
  <block id="08850aedb3df32c0b7aab4a82c3046e9" category="paragraph"><block ref="08850aedb3df32c0b7aab4a82c3046e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55ecf05d044f8d3b179ea6daf134664f" category="list-text">单击*创建文件系统*。</block>
  <block id="27084adb60f0bf74b1a974cc4c65c8d5" category="inline-image-macro">错误：创建文件系统</block>
  <block id="88293d0584791b5f07d37c1a6e91f115" category="paragraph"><block ref="88293d0584791b5f07d37c1a6e91f115" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4022ac9e8fc45c3abfa95a19f7a6e809" category="list-text">选择第一张卡*FSx for FS* NetApp ONTAP，然后单击*Next*。</block>
  <block id="3ad04953613178bc3114b0de1b0c7c12" category="inline-image-macro">错误：选择文件系统类型</block>
  <block id="6994b8de5ae43fcb8facf33262bb7d85" category="paragraph"><block ref="6994b8de5ae43fcb8facf33262bb7d85" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b05d3465523c46c6ece6e36ff05bba" category="list-text">在详细信息配置页面中。</block>
  <block id="720e4d0907f5f98d25c99b23a410c93c" category="list-text">选择*标准创建*选项。</block>
  <block id="e5dc5b446c153a70a036a5e53abc03fa" category="inline-image-macro">错误：创建文件系统面板</block>
  <block id="8f7864f5bc12c18ce876f1160486c73a" category="paragraph"><block ref="8f7864f5bc12c18ce876f1160486c73a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bea7f738749e0c476b2d1c016021ec5b" category="list-text">输入*文件系统名称*和* SSD存储容量*。</block>
  <block id="5acd0fbb1d9cf07686de5953c49ea482" category="inline-image-macro">错误：指定文件系统详细信息</block>
  <block id="af0b859bd35835b46955433f200653b7" category="paragraph"><block ref="af0b859bd35835b46955433f200653b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5db4aeb81b94a1ba5cdcc12c96b36cb1" category="list-text">确保使用与*SageMaker记事本*实例相同的*vpc*和*subnet*。</block>
  <block id="8fc5bda05ed12061673744ef5ca38e49" category="inline-image-macro">错误：网络和安全配置(&amp;A)</block>
  <block id="1c7c4783a7418157f53392c903c2d824" category="paragraph"><block ref="88bd06961d668e99f94dabd3d58df0df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb695bdcb362931108f41ff0ec65293" category="list-text">输入SVM (Storage Virtual Machine)的* Storage Virtual Machine*名称和*指定密码*。</block>
  <block id="fad5d48050c3ffd279ba599f2939fa96" category="inline-image-macro">错误：默认Storage Virtual Machine配置</block>
  <block id="38caa4ec56d6b1a3e15088848cfc7eff" category="paragraph"><block ref="38caa4ec56d6b1a3e15088848cfc7eff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66dfcda81b33098d49dd6b202816eac4" category="inline-image-macro">错误：确认配置</block>
  <block id="20bc5d28ff5ae2518fe7620732f8da5d" category="paragraph"><block ref="20bc5d28ff5ae2518fe7620732f8da5d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bbdba4ec2550ae26e76c7ccb1935997" category="inline-image-macro">错误：查看配置并确认创建</block>
  <block id="7830d9e7b16a77ed9086d21141c61249" category="paragraph"><block ref="7830d9e7b16a77ed9086d21141c61249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c12346192a59739b1315d8d07143db6e" category="list-text">启动FSx文件系统可能需要大约*20-40分钟*。</block>
  <block id="b4acc68213fdec586002e5bceb128160" category="inline-image-macro">错误：检查FSx控制台</block>
  <block id="55029cbc3bcf30f884f1d4e26a5906dc" category="paragraph"><block ref="55029cbc3bcf30f884f1d4e26a5906dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01ecbbb2b353cf4d915bbe1c1cd5505c" category="section-title">服务器配置</block>
  <block id="d36647d06b353fcd6fedc60898e43187" category="section-title">ONTAP配置</block>
  <block id="07afa2af969623c48103624cdb58551c" category="list-text">打开创建的FSx文件系统。请确保状态为*可用*。</block>
  <block id="a49ba1d26032654a374f6070da411e15" category="inline-image-macro">错误：等待后端创建</block>
  <block id="4264cdf948169ae396a9b55ff8d1a939" category="paragraph"><block ref="4264cdf948169ae396a9b55ff8d1a939" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cbcfc771dc80f5ee77c4deba078b135" category="list-text">选择*管理*选项卡并保留*管理端点- IP地址*和* ONTAP管理员用户名*。</block>
  <block id="e02c80eea85e6af659b706bec351e92f" category="inline-image-macro">错误：文件系统详细信息控制台</block>
  <block id="ae63a6830c7413a36ca87f5ec0f7a32e" category="paragraph"><block ref="ae63a6830c7413a36ca87f5ec0f7a32e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0164aebedfb5a99b6386ba01ffbc963" category="list-text">打开创建的*SageMaker笔记本实例*，然后单击*Open JupyterLab*。</block>
  <block id="b0170bb1aa04e46c9d11cd1c71576225" category="inline-image-macro">错误：AWS SageMaker笔记本实例控制台</block>
  <block id="6b1bc934025194c0040fad0d84c26b4b" category="paragraph"><block ref="6b1bc934025194c0040fad0d84c26b4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12dbc394c66b065a1aef771f11914dad" category="list-text">在Jupyter Lab页面中，打开一个新的*Terminal *。</block>
  <block id="f96bd7f5e2461f4da9c5cf3081a1435e" category="inline-image-macro">错误：Jupyter Lab欢迎页面</block>
  <block id="3812ac79085156c315b47611e83566ce" category="paragraph"><block ref="3812ac79085156c315b47611e83566ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783f8aafec7947fdba79675aec73c6ea" category="list-text">输入ssh命令ssh &lt;admin user name&gt;@&lt;ONTAP server IP&gt;登录到FSxN ONTAP文件系统。(用户名和IP地址从步骤2中检索)
请使用创建*Storage Virtual Machine*时使用的密码。</block>
  <block id="fbc1bb10b7dba9b1686cf5909b857d11" category="inline-image-macro">错误：Jupyter Lab终端</block>
  <block id="323c9f126a332a030cb212385df777c2" category="paragraph"><block ref="323c9f126a332a030cb212385df777c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a54fdd656710867c428c8113e54b564" category="list-text">按以下顺序执行命令。
我们使用*fsxn-ONTAP *作为* FSxN专用S3存储分段名称*的名称。
请使用*Storage Virtual Machine name*作为*-vserver*参数。</block>
  <block id="7077653c0ede48b67bb9ddf095443097" category="inline-image-macro">错误：Jupyter Lab终端输出</block>
  <block id="a5b06c1e5b238d4eca22e7fa82a9918d" category="paragraph"><block ref="a5b06c1e5b238d4eca22e7fa82a9918d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97ba33974b8521c10ce584c5eaf395e8" category="list-text">执行以下命令以检索FSxN Private S3的端点IP和凭据。</block>
  <block id="1025c82e986534d7a6a941036fce2afd" category="list-text">保留端点IP和凭据以供将来使用。</block>
  <block id="124a0d0c01ae10c84922faf0071bef0c" category="paragraph"><block ref="124a0d0c01ae10c84922faf0071bef0c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb11dcb3b0575af26386e753c028e37d" category="section-title">客户端配置</block>
  <block id="d885926aec2cdf1253c078102968eb8d" category="list-text">在SageMaker笔记本实例中、创建新的Jupyter笔记本。</block>
  <block id="a31ea702484a2995987efff159cfd25b" category="inline-image-macro">错误：打开新的Jupyter笔记本</block>
  <block id="a0e2c1ccf569aed936c0662c38ce28b7" category="paragraph"><block ref="a0e2c1ccf569aed936c0662c38ce28b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e248de3aba6cefa5adacaaee03aaa6e8" category="inline-link-macro">fsxn_dema.ipynb</block>
  <block id="b8c06acb7cb18ff2ed0496ab3d7c9b49" category="list-text">使用以下代码作为解决解决方案问题的方法、将文件上传到FSxN私有S3存储分段。
有关完整的代码示例、请参阅本笔记本。
<block ref="bba9246c0aa679574046eb4f09bdd0fc" category="inline-link-macro-rx"></block></block>
  <block id="cea26986194f845f1cc6f7d6f829d354" category="paragraph">FSxN与SageMaker实例之间的集成到此结束。</block>
  <block id="6d8aee76fb8c09877162ad6d9e5fdac9" category="section-title">有用的调试检查清单</block>
  <block id="fc9f2f85096a29f68ece7e9e7110c6a8" category="list-text">确保SageMaker笔记本实例和FSxN文件系统位于同一个VPC中。</block>
  <block id="2ec57b268e910c39ad70e1b259d09e1a" category="list-text">请记得在ONTAP上运行*set dev*命令，将权限级别设置为*dev*。</block>
  <block id="5a7d7d5f81481db284cc081576a810b0" category="section-title">常见问题解答(截至2023年9月27日)</block>
  <block id="94b999326ed2132d685df6f3ff59629d" category="paragraph">问：为什么在将文件上传到FSxN时、我在调用CreateMultipartUpload操作时收到错误"*发生错误(未实施)：您请求的S3命令未实施*"？</block>
  <block id="5fa41173cd02a7f2f51991d3fbf945fd" category="paragraph">答：作为私有S3存储分段、FSxN支持上传高达100 MB的文件。使用S3协议时、大于100 MB的文件会划分为100 MB的区块、并调用"CreateMultipartUpload"函数。但是、当前实施的FSxN Private S3不支持此功能。</block>
  <block id="f88f43eebee4cca4c6f0326f74fda45b" category="paragraph">问：为什么在将文件上传到FSxN时、调用PutObject操作时收到错误"*发生错误(AccessDenied)：访问被拒绝*"？</block>
  <block id="1b00aec10ba8509109eedd8e579fb809" category="paragraph">答：要从SageMaker笔记本实例访问FSxN私有S3存储分段、请将AWS凭据切换到FSxN凭据。但是、要为实例授予写入权限、需要使用 临时解决策 解决方案 挂载存储分段并运行"chmod" shell命令来更改权限。</block>
  <block id="a15e64da546a6b8f0df25ab3c1ae0911" category="paragraph">问：如何将FSxN Private S3存储分段与其他SageMaker ML服务集成？</block>
  <block id="91c8fe5f362fce371dcce68bb17a9f1a" category="paragraph">答：遗憾的是、SageMaker服务SDK无法为专用S3存储分段指定端点。因此、FSxN S3与SageMaker服务不兼容、例如、SagMaker Data Rangler、SagMaker Clarify、SagMaker Glue、SagMaker Athena、SagMaker AutoML、 等。</block>
  <block id="9655e73399e82a17e5955e6dcba21f87" category="summary">本文是一篇有关使用AWS FSx for NetApp ONTAP (FSxN)在SageMaker中训练PyTorch模型的教程、专门针对轮胎质量分类项目。</block>
  <block id="71a905356768d1db6813d6aba47f4ebe" category="doc">第2部分—利用AWS FSx for NetApp ONTAP (FSxN)作为SageMaker模型训练的数据源</block>
  <block id="25487964d2cbb5e36908d6c6d6e9001c" category="paragraph">本教程提供了计算机视觉分类项目的一个实际示例、提供了在SageMaker环境中构建ML模型以利用FSxN作为数据源的实践经验。该项目侧重于使用深度学习框架PyTorch、根据轮胎图像对轮胎质量进行分类。它侧重于使用FSxN作为Amazon SageMaker中的数据源来开发机器学习模型。</block>
  <block id="f2cd5132b81c1386e19a3f084d8940b9" category="section-title">什么是FSxN</block>
  <block id="441a934c03f21f09898da33a2dae3a68" category="paragraph">Amazon FSx for NetApp ONTAP确实是AWS提供的一款完全托管的存储解决方案。它利用NetApp的ONTAP文件系统提供可靠的高性能存储。由于支持NFS、SMB和iSCSI等协议、因此可以从不同的计算实例和容器无缝访问。该服务旨在提供卓越的性能、确保快速高效的数据运营。它还提供高可用性和持久性、确保您的数据始终可访问并受到保护。此外、Amazon FSx for NetApp ONTAP的存储容量可扩展、使您可以根据需要轻松调整。</block>
  <block id="925335f81021de4d22fde55ae7f0e86a" category="section-title">前提条件</block>
  <block id="05ec336213c5aa3c3a49c743c5fbad19" category="section-title">网络环境</block>
  <block id="20455c4f1650bcad90c6f90b8198a63c" category="inline-image-macro">错误：网络环境</block>
  <block id="d743633a1920a27998ecfaf136243d75" category="paragraph"><block ref="d743633a1920a27998ecfaf136243d75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="058c237f3a064c54cd4482ddc0bdee21" category="paragraph">FSxN (Amazon FSx for NetApp ONTAP)是一项AWS存储服务。它包括在NetApp ONTAP系统上运行的文件系统以及与其连接的AWS托管系统虚拟机(SVM)。在提供的图中、由AWS管理的NetApp ONTAP服务器位于VPC之外。SVM充当SageMaker和NetApp ONTAP系统之间的中介、接收来自SageMaker的操作请求并将其转发到底层存储。要访问FSxN、SageMaker必须与FSxN部署位于同一个VPC中。此配置可确保SageMaker和FSxN之间的通信和数据访问。</block>
  <block id="f8aacfa5c683858912c498f517c9b457" category="section-title">数据访问</block>
  <block id="dda624dce365defeb65011996c2313ad" category="paragraph">在实际场景中、数据科学家通常会利用存储在FSxN中的现有数据来构建机器学习模型。但是、出于演示目的、由于FSxN文件系统在创建后最初为空、因此需要手动上传训练数据。这可以通过将FSxN作为卷挂载到SageMaker来实现。成功挂载文件系统后、您可以将数据集上传到挂载位置、以便在SageMaker环境中训练模型。通过这种方法、您可以在与SageMaker合作进行模型开发和训练时利用FSxN的存储容量和功能。</block>
  <block id="30eaeebc8f9611f55e018d1dd51789ba" category="section-title">集成概述</block>
  <block id="c011a85db53a4a7d12e0146d9d89ced9" category="inline-image-macro">错误：训练工作流</block>
  <block id="53143d9ff0d27a36c7ff5ea412677076" category="paragraph"><block ref="53143d9ff0d27a36c7ff5ea412677076" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79f0ede85c2ced5f70fe62f983155c74" category="paragraph">使用FSxN中的训练数据在SageMaker中构建深度学习模型的工作流可概括为三个主要步骤：数据加载程序定义、模型训练和部署。总体而言、这些步骤构成了MLOps管道的基础。但是、每个步骤都涉及多个详细的子步骤、以实现全面实施。这些子步骤包括各种任务、例如数据预处理、数据集拆分、模型配置、超参数调整、模型评估、 和型号部署。这些步骤可确保在SageMaker环境中使用来自FSxN的训练数据构建和部署深度学习模型的流程全面有效。</block>
  <block id="2870e83ec05413b09bc7de07f60f54fa" category="section-title">分步集成</block>
  <block id="e3364bc8e125077137411ae17c13b771" category="section-title">数据加载程序</block>
  <block id="220b880a3d218e80d8fde5901827649a" category="paragraph">为了训练使用数据的PyTorch深度学习网络、我们创建了一个数据加载程序来促进数据馈送。数据加载程序不仅可以定义批大小、还可以确定用于读取和预处理批处理中每个记录的操作步骤。通过配置数据加载程序、我们可以处理批量数据处理、从而实现深度学习网络的训练。</block>
  <block id="cc0322e5278f21d6001e3995e46e2810" category="paragraph">数据加载程序由3个部分组成。</block>
  <block id="0cee527e2a952dcfca00fb6de192e2a1" category="section-title">预处理功能</block>
  <block id="50a46eb952358276ed306b6d88aadc7d" category="paragraph">上述代码段演示了使用*torchVISION．transforms*模块的图像预处理转换的定义。在此图示中、创建预处理对象以应用一系列转换。首先，*ToTendor()*转换将图像转换为张图表示。随后，*Resize((224224))*转换将图像的大小调整为固定的224x224像素大小。最后，*NORMDE()*转换通过减去平均值并除以沿每个通道的标准偏差来使张量值标准化。用于标准化的平均值和标准偏差值通常用于经过预先训练的神经网络模型。总之、该代码通过将图像数据转换为张量、调整图像大小和使像素值标准化来准备图像数据、以便进一步处理或输入到预先训练的模型中。</block>
  <block id="578a55cb1cfe6e1363a1c73fec7d9c6f" category="section-title">PyTorch数据集类</block>
  <block id="7e7159cc4ca0129a9b35d893799453b9" category="paragraph">此类提供了获取数据集中记录总数的功能，并定义了读取每个记录的数据的方法。在*__gottim_*函数中，代码利用boto3 S3存储分段对象从FSxN中检索二进制数据。从FSxN访问数据的代码模式类似于从Amazon S3读取数据。后面的说明将深入介绍私有S3对象*bket*的创建过程。</block>
  <block id="5b1b1d49dd327fbacec0eeca5f4c03d0" category="section-title">FSxN作为私有S3存储库</block>
  <block id="b8e6ec0139ec0b874bbdf3510ca77ff8" category="paragraph">要从SageMaker中的FSxN读取数据、需要创建一个处理程序、该处理程序使用S3协议指向FSxN存储。这样就可以将FSxN视为专用S3存储分段。处理程序配置包括指定FSxN SVM的IP地址、分段名称和所需凭据。有关获取这些配置项的完整说明、请参阅上的文档 <block ref="c8ff61ebc26830f9012741fc5a740a66" category="inline-link-macro-rx"></block>。</block>
  <block id="ac5d6406e8dadcbc23e9cf65fe528510" category="paragraph">在上述示例中、b分 段对象用于实例化PyTorch DataSet对象。数据集对象将在后续章节中进一步说明。</block>
  <block id="e03717a5c1692689919250506bf382a0" category="section-title">PyTorch数据加载程序</block>
  <block id="0c919f2bf87f2c6df41e7bbc52c68d04" category="paragraph">在提供的示例中、指定的批大小为64、表示每个批将包含64条记录。通过将PyTorch *DataT*类、预处理功能和训练批大小相结合，我们可以获得训练所需的数据加载程序。此数据加载程序有助于在训练阶段批量迭代数据集。</block>
  <block id="74415cec8ae4d65c228c7fa8da8eae8a" category="section-title">模型训练</block>
  <block id="74492eb8210f5168d9ee3eff7524ecde" category="paragraph">本规范实施标准的PyTorch培训流程。它定义了一个名为*TireQualityClassifyer*的神经网络模型，该模型使用卷积层和线性层对轮胎质量进行分类。训练循环会迭代数据批处理、并使用反向传播和优化功能来确定损失、然后更新模型的参数。此外、它还会打印当前时间、时期、批处理和损失、以供监控。</block>
  <block id="4d2e185dfba9f3df542300054ad07998" category="section-title">模型部署</block>
  <block id="6116a0f9a85671aec95cc56a205cf186" category="paragraph">此代码会将PyTorch模型保存到*Amazon S3*中，因为SageMaker要求将模型存储在S3中进行部署。通过将模型上传到*Amazon S3*，SageMaker便可访问模型，从而可以在已部署的模型上进行部署和引用。</block>
  <block id="075e4fb3d67ee1fb4bc39dbc5d72b129" category="paragraph">此代码有助于在SageMaker上部署PyTorch模型。它定义了一个自定义的串口器*TireQuality串 口器*，该串口器可将输入数据作为PyTorch张量进行预处理和串口处理。TireQuality谓 词*类是一个自定义的预测程序，它利用定义的串列器和*JSONDeseririter*。该代码还会创建一个*PyTorchModel*对象，用于指定模型的S3位置、IAM角色、框架版本和引用入口点。代码会生成时间戳并根据模型和时间戳构建端点名称。最后、使用Deploy方法部署模型、并指定实例计数、实例类型和生成的端点名称。这样、可以在SageMaker上部署PyTorch模型并可用于进行推入。</block>
  <block id="bfc7647fbfe6e589911d2da73377b475" category="section-title">参考</block>
  <block id="99e1766840e675b2dbd8230be049188f" category="paragraph">这是使用已部署端点执行此假定的示例。</block>
  <block id="e7ee239a021c71c67431ac1c23b9cf1e" category="summary">本文提供了使用AWS服务构建MLOps管道的指南、重点介绍自动化模型重新培训、部署和成本优化。</block>
  <block id="b77650c231f63812b48a3802736172ae" category="doc">第3部分-构建简化的MLOps管道(CI/CT/CD)</block>
  <block id="4c04d3884cafb85369c7a0a6b81d10b0" category="paragraph">在本教程中、您将了解如何利用各种AWS服务构建一个简单的MLOps管道、其中包括持续集成(CI)、持续培训(CT)和持续部署(CD)。与传统DevOps管道不同、MLOps需要额外的注意事项才能完成运营周期。通过学习本教程、您将深入了解如何将CT整合到MLOps循环中、从而可以持续训练您的模型并无缝部署数据进行推导。本教程将指导您完成利用AWS服务建立此端到端MLOps管道的过程。</block>
  <block id="76c3e002d3c052bd6a909366a8dc3845" category="section-title">清单文件</block>
  <block id="e7e0038bb30579a3120d266861982881" category="cell">功能</block>
  <block id="dc21b082b0947a93d387b8c7e8f89ee5" category="cell">数据存储</block>
  <block id="038790391c3f6a420beaed7bca0eb306" category="cell">AWS FSxN</block>
  <block id="4c5f43ed06df4b05c18ca410c7016249" category="cell">数据科学IDE</block>
  <block id="e1d9ae96a3cc2d87549ec614a5eea75b" category="cell">用于触发MLOps管道的功能</block>
  <block id="10740b99bf79c58d32e1a8e73062d05c" category="cell">AWS Lamb开发 函数</block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="0fc1223c31c6d7d5d233235c0a8f3ee0" category="cell">cron作业触发器</block>
  <block id="0abaf4e46241f987a0b4e6a434e596cd" category="cell">AWS EventBridge</block>
  <block id="e015867873eac103879d29f569610c66" category="cell">深度学习框架</block>
  <block id="6af8c08e3948b664c72a8cc3c2709254" category="cell">AWS Python SDK</block>
  <block id="6686853da3491a56c98917cc5c4ddea2" category="cell">僵尸3</block>
  <block id="4f465e36f699fcf0570d854d9f692508" category="cell">编程语言</block>
  <block id="cd9ec78e2cad962acfcab027dd62d904" category="cell">v3.10</block>
  <block id="d5fede2db8ed0319fd64b4dcc0daee60" category="list-text">一种预配置的FSxN文件系统。本教程将利用存储在FSxN中的数据进行培训。</block>
  <block id="ee6837bb5e13dcd35683a2adeb22dd85" category="list-text">一个* SageMaker笔记本电脑实例*，该实例配置为与上述FSxN文件系统共享同一个VPC。</block>
  <block id="cd201faac7e3cf792faa46c93195c65b" category="list-text">在触发*AWS Lambd*函数之前，请确保*SageMaker笔记本实例*处于*STOPPED*状态。</block>
  <block id="238f736fdf6bcdcd7f397969fe6eb36e" category="list-text">要利用深度神经网络的必要GPU加速、需要使用*毫升g4dn.x大*实例类型。</block>
  <block id="959b652147461dbebe507fbcc1b9b847" category="inline-image-macro">错误：架构</block>
  <block id="abb17d022d3042495c18ce4344c1e88c" category="paragraph"><block ref="abb17d022d3042495c18ce4344c1e88c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e320ad9e531a78d8b06272138f0f29b7" category="paragraph">此MLOps管道是一种实际实施、它利用cron作业触发无服务器功能、进而执行使用生命周期回调函数注册的AWS服务。AWS EventBridge*用作cron作业。它会定期调用一个*AWS Lambad*函数，负责对模型进行重新培训和重新部署。此过程涉及到启动*AWS SageMaker笔记本*实例以执行必要的任务。</block>
  <block id="2f53ab942978849d906d82a87554a1e2" category="section-title">逐步配置</block>
  <block id="ecce3b4394f7f06232bad571a96a0391" category="section-title">生命周期配置</block>
  <block id="8482e23b03456ee8ac2760d540c11442" category="paragraph">要为AWS SageMaker笔记本实例配置生命周期回调函数，应使用*Lifecycle configurations*。通过此服务，您可以定义在启动笔记本实例期间要执行的必要操作。具体而言，可以在*Lifecycle configuration*中实施shell脚本，以便在完成培训和部署过程后自动关闭笔记本实例。这是必需的配置、因为成本是MLOps中的主要考虑因素之一。</block>
  <block id="79d14d6493dc1a7a7d33bf031166f9a9" category="paragraph">需要注意的是，需要提前设置*生命周期配置*的配置。因此、建议在继续其他MLOps管道设置之前、优先配置此方面。</block>
  <block id="29beb103651093d4e75530e25a50f4bd" category="list-text">要设置生命周期配置，请打开*Sager*面板，然后导航到*Admin configurations*部分下的*Lifecycle configurations*。</block>
  <block id="f7d7df1c36e1944e5017b5a0efea062b" category="inline-image-macro">错误：SageMaker面板</block>
  <block id="d26bb875afdf18eb3fb5d209dcb60b22" category="paragraph"><block ref="d26bb875afdf18eb3fb5d209dcb60b22" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706c89d427897aa8c9093c9ea4ddf1cb" category="list-text">选择*笔记本实例*选项卡，然后单击*创建配置*按钮</block>
  <block id="9866cc39114ff340fe9706df15b56abb" category="inline-image-macro">错误：生命周期配置欢迎页面</block>
  <block id="3136c126f3b9d4d7056156b66f4108b5" category="paragraph"><block ref="3136c126f3b9d4d7056156b66f4108b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bfce2cb9f46fa7b22c7f04d6aa38b9e" category="list-text">将以下代码粘贴到输入区域。</block>
  <block id="14e0e0678133bba2cc24188e6bc33690" category="inline-image-macro">错误：创建生命周期配置</block>
  <block id="715f40d05a00907e935047e328538c28" category="paragraph"><block ref="715f40d05a00907e935047e328538c28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a835fb020d342258f64fe6be9b11cc29" category="list-text">创建后，导航到“笔记本实例”，选择目标实例，然后单击“操作”下拉列表中的*更新设置*。</block>
  <block id="d1e24dfc3304b4a8594b311a179da602" category="inline-image-macro">错误：更新设置下拉列表</block>
  <block id="8598f268628946a1ff092beb2c16d0f8" category="paragraph"><block ref="8598f268628946a1ff092beb2c16d0f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f80499d713c8d9fe19313ec1dc9bd45" category="list-text">选择已创建的*生命周期配置*，然后单击*更新笔记本实例*。</block>
  <block id="2a9377c3bd188cc71aaccef2f66a3166" category="inline-image-macro">错误：更新笔记本电脑的生命周期配置</block>
  <block id="8f34a5f6ac30183ff5cfe66547861732" category="paragraph"><block ref="8f34a5f6ac30183ff5cfe66547861732" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a0f9cbbefa9b9603cf2241f33621e37" category="section-title">AWS Lamb达 无服务器函数</block>
  <block id="4a799fa8d490fae92d630fe6cc65b928" category="paragraph">如前所述，*AWS Lambd*功能负责启动*AWS SageMaker笔记本实例*。</block>
  <block id="be107f93440a41fcae408e1abec6403e" category="list-text">要创建*AWS Lamba函数*，请导航到相应的面板，切换到*FUNCHUDENTS*选项卡，然后单击*Create FUNCHUD*。</block>
  <block id="524736e1a09117ec61f0aaf467c90139" category="inline-image-macro">错误：AWS兰德函数欢迎页面</block>
  <block id="7ee982c5adad9c9e36dc667dacddbd13" category="paragraph"><block ref="7ee982c5adad9c9e36dc667dacddbd13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a60f634c6f68222d8abaaa29bd057217" category="list-text">请将页面上所有必需的条目归档，并记住将运行时切换到*Python 3.10*。</block>
  <block id="a0dc224a6753dc4e9c8a13943a9ff877" category="inline-image-macro">错误：创建AWS兰德函数</block>
  <block id="27b829ff3b7d44c395691e9bdd846505" category="paragraph"><block ref="27b829ff3b7d44c395691e9bdd846505" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bee22bc8ca787cbf1475d27ae7429d6" category="list-text">请验证指定角色是否具有所需的权限*Amazon SageMakerFullAccess*，然后单击*Create Function (创建功能)*按钮。</block>
  <block id="b2509cc34b786ae706a345e57c5a14e7" category="inline-image-macro">错误：选择执行角色</block>
  <block id="c027772dae19849892cdd4d41acafd7e" category="paragraph"><block ref="c027772dae19849892cdd4d41acafd7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcc43af2494337ee641b41a13f71fc46" category="list-text">选择创建的Lamb编制 函数。在代码选项卡中、将以下代码复制并粘贴到文本区域中。此代码将启动名为*fsxn-ONTAP的笔记本实例。</block>
  <block id="c2edd2bdf75433b7f31062be9571f528" category="list-text">单击*DEPLE*按钮以应用此代码更改。</block>
  <block id="f5805fdb0f184041ac3646e5f627e695" category="inline-image-macro">错误：部署</block>
  <block id="eb20a664e23a78b3c7113aaf7fb08340" category="paragraph"><block ref="eb20a664e23a78b3c7113aaf7fb08340" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9bb44167ffa5f5dc2d30616b32fe21b" category="list-text">要指定如何触发此AWS Lambar函数、请单击添加触发器按钮。</block>
  <block id="e03f392736db7792e8bb592750ba849d" category="inline-image-macro">错误：添加AWS函数触发器</block>
  <block id="686158583f45232c55625677d31a9257" category="paragraph"><block ref="686158583f45232c55625677d31a9257" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba138d79283b1a8aad0ef0cc35ce105" category="list-text">从下拉菜单中选择EventBridge、然后单击标有创建新规则的单选按钮。在计划表达式字段中、输入<block ref="5bb28b828095c4a920fb3d34b89c2b84" prefix=" " category="inline-code"></block>，然后单击添加按钮以创建此新的cron作业规则并将其应用于AWS Lamb另 一个函数。</block>
  <block id="61303cb3574b9f65d6e49887d43be6c0" category="inline-image-macro">错误：完成触发</block>
  <block id="48e108c96af91adf1ebc67bfa420d5e8" category="paragraph"><block ref="48e108c96af91adf1ebc67bfa420d5e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe01cfd78f584d198c87bcb7f8ad2ee6" category="paragraph">每天完成两步配置后，*AWS Lambd*功能将启动*SageMaker笔记本*，使用*FSxN*存储库中的数据执行模型重新训练，将更新的模型重新部署到生产环境，并自动关闭*SageMaker笔记本实例*以优化成本。这可确保模型保持最新。</block>
  <block id="0be5bfaeb8f14cd39a235e5050cecbc9" category="paragraph">开发MLOps管道的教程到此结束。</block>
  <block id="9647f011afc518d42e6703912b04ebea" category="sidebar">适用于MLOps的AWS FSx for NetApp ONTAP (FSxN)</block>
  <block id="4bf9542c50f7b80d598d7ab1d3bef30b" category="paragraph">在此解决方案 验证中、我们使用Oracle演示灾难恢复。有关Oracle和NetApp ONTAP 最佳实践的详细信息、请参见<block ref="065c174f340523fcff4fc7ccd47e71bd" category="inline-link-rx"></block>。</block>
  <block id="003651b61fd1add7d53aa34a94149bb5" category="sidebar">在ONTAP上部署Oracle数据库</block>
  <block id="e16acc0f6a19a93c2ce155db24c7dab5" category="summary">这是FSxN MLOps部分的简介页面。</block>
  <block id="5161c5ce9ddd62084bca0b7596db0266" category="paragraph">*作者：*
Jian Jian (Ken)、NetApp高级数据和应用科学人员</block>
  <block id="e9270d7905c7162d5c16d80d7ebe1cd5" category="paragraph">本节将深入介绍AI基础架构开发的实际应用、提供使用FSxN构建MLOps管道的端到端逐步介绍。它包含三个全面的示例、可指导您通过这一强大的数据管理平台满足MLOps需求。</block>
  <block id="e2e58416305212ecee9fc44a8a57e389" category="paragraph">这些文章侧重于：</block>
  <block id="b7f3b0c22dc36cd3b8991113153958c8" category="list-text"><block ref="b7f3b0c22dc36cd3b8991113153958c8" category="inline-link-macro-rx"></block></block>
  <block id="b98e975dc2d06019b67aeb13902d6a15" category="list-text"><block ref="b98e975dc2d06019b67aeb13902d6a15" category="inline-link-macro-rx"></block></block>
  <block id="882330f00abe9178a19f6053978f5b4f" category="list-text"><block ref="882330f00abe9178a19f6053978f5b4f" category="inline-link-macro-rx"></block></block>
  <block id="5b53b7bace6f6d10be375785f215b3f4" category="paragraph">本节结束时、您将深入了解如何使用FSxN简化MLOps流程。</block>
  <block id="f26750c7b8a4a47b5c84b59141936400" category="list-text">在创建页面中、
输入*笔记本实例名称*
展开*Network*面板
保留其它条目默认值，然后选择*VPC*、*Subnet*和*Security group*。(稍后将使用此*VPC*和*Subnet*创建FSxN文件系统)
单击右下角的橙色按钮*创建笔记本实例*。</block>
  <block id="c4c7ba1524cf2b18e8592e9ceb83df71" category="list-text">保留其它条目的默认值，然后单击右下角的橙色按钮*Next*。</block>
  <block id="6d5ce0306761971a734da357efdf9e6f" category="list-text">单击查看页面右下角的橙色按钮*创建文件系统*。</block>
  <block id="09347bb6e4d6cc013c80eec20591bc29" category="paragraph">数据读取过程会将FSxN配置为专用S3存储分段。要了解详细的配置说明、请参见 <block ref="b7f3b0c22dc36cd3b8991113153958c8" category="inline-link-macro-rx"></block></block>
  <block id="501f4a3a8ef5900dadf600db64e1ba2b" category="cell">请参见 <block ref="b7f3b0c22dc36cd3b8991113153958c8" category="inline-link-macro-rx"></block>。</block>
  <block id="1c70a2829c93823d7f0314c6b4bf651c" category="cell">本教程基于中提供的Jupyter笔记本 <block ref="b98e975dc2d06019b67aeb13902d6a15" category="inline-link-macro-rx"></block>。</block>
  <block id="34388a3a0282609b02f3b2e33e8683b7" category="list-text">此脚本执行Jupyter笔记本、该笔记本负责重新训练和重新部署模型以进行引用。执行完成后、笔记本电脑将在5分钟内自动关闭。要了解有关问题陈述和代码实施的更多信息、请参见 <block ref="b98e975dc2d06019b67aeb13902d6a15" category="inline-link-macro-rx"></block>。</block>
  <block id="09df85b7e8c18a512dffc54b2483e9fb" category="admonition">根据此建议、此脚本使用<block ref="ec8ffbcaedee6a818da774b22840c665" prefix=" " category="inline-code"></block> 用于减少配置文件中意外数据丢失的可能性的生命周期参数。有关的详细信息、请参见<block ref="ec8ffbcaedee6a818da774b22840c665" prefix=" " category="inline-code"></block> 生命周期参数请参见terraform文档：<block ref="0958f540126f250f4289117b6cacbdab" category="inline-link-rx"></block>。</block>
  <block id="7e68fdcdfd32073adeaee9e4bd613f62" category="summary">解决方案提供了有关在Microsoft Azure NetApp Files中自动部署Oracle作为使用NFS协议的主数据库存储以及在启用了DNFS的情况下将Oracle数据库部署为容器数据库的概述和详细信息。</block>
  <block id="e1655476f44fb9ae3929b4294709cd58" category="doc">TR-4987：《在采用NFS的Azure NetApp Files上简化的自动化Oracle部署》</block>
  <block id="9dba703b69ec43e6d3b93ebe9143b7bc" category="paragraph">在云中运行性能密集型和延迟敏感型Oracle工作负载可能会带来挑战。借助Azure NetApp Files (ANF)、企业业务部门(LOB)和存储专业人员可以轻松迁移和运行要求苛刻的Oracle工作负载、而无需更改代码。Azure NetApp Files广泛用作各种情形下的底层共享文件存储服务、例如、在内部部署或将Oracle数据库迁移(迁移)到Azure等情形下。</block>
  <block id="71dc864bb8cdf05644d9a323eb255160" category="paragraph">本文档演示了如何使用Azure NetApp Files自动化通过NFS挂载简化Oracle数据库在Oracle中的部署。Oracle数据库部署在启用了Oracle DNFS协议的容器数据库(CDB)和可插拔数据库(PDB)配置中、以提高性能。此外、可以使用自动化PDB重新定位方法将内部Oracle单实例数据库(PDB)迁移到Azure中新部署的容器数据库中、同时最大限度地减少服务中断。此外、还提供了有关使用Azure云中的NetApp SnapCenter UI工具快速备份、还原和克隆Oracle数据库的信息。</block>
  <block id="5ddba5a30df05b067a7f1c29425f8ebe" category="list-text">在Azure NetApp Files上自动部署Oracle容器数据库</block>
  <block id="48c81fe5bacafca589a05c9d8b99cea6" category="list-text">在内部未命中和Azure云之间自动迁移Oracle数据库</block>
  <block id="8d80eec422e5f3f1e3a978925d495397" category="list-text">希望在Azure NetApp Files上部署Oracle的数据库开发人员。</block>
  <block id="3f13d9adda12e73807626015fc986092" category="list-text">希望在Azure NetApp Files上测试Oracle工作负载的数据库解决方案架构师。</block>
  <block id="7bbba384efcd8c1f1760837638bad8f5" category="list-text">希望在Azure NetApp Files上部署和管理Oracle数据库的存储管理员。</block>
  <block id="39ab0d44839c151a3d462df3c663cbfa" category="list-text">希望在Azure NetApp Files上建立Oracle数据库的应用程序所有者。</block>
  <block id="e334cd79329c228cad2c140c5b8d1466" category="cell">Azure中由Microsoft提供的最新产品</block>
  <block id="6c17db0cce1350a7ee8a752f7b961575" category="cell">一个具有高级服务级别的容量池</block>
  <block id="337f2d0a9780863bf956cbd164244280" category="cell">适用于数据库服务器的Azure VM</block>
  <block id="1ddc8f4b0d860fd1b7f66f65f3a2a4ff" category="cell">standard_B4ms—4个vCPU、16 GiB</block>
  <block id="4624ccb0e1c638f541fe98d0cb590fc4" category="cell">两个Linux虚拟机实例、用于并发部署</block>
  <block id="c79e7f0c663764033ed88cf88db55c30" category="cell">适用于SnapCenter的Azure VM</block>
  <block id="5e29f32e9b6ef61ba5af29f3ff8d79ec" category="cell">一个Windows虚拟机实例</block>
  <block id="582dc61cba794b1ebaa0f1d5a0ab6fd5" category="cell">RHEL Linux 8.6 (LVM)- x64 Gen2</block>
  <block id="c030b053d2fcc613e72470b248119720" category="cell">2022 DataCenter；Azure Edition HotPatch - x64 Gen2</block>
  <block id="738e4f16a24a9e74c1f67ae2e7c02f3b" category="cell">版本5.0</block>
  <block id="16e4f0fa15c5763a8b46a7276d96cf1c" category="cell">版本java-11-OpenJDK</block>
  <block id="bed44da4616a4ffa447c183fb1c3ca09" category="cell">已启用Oracle DNFS</block>
  <block id="a033248533a019132f66d63d159e9310" category="cell">核心2.16.2.</block>
  <block id="fc70b7599e5ae1b544d73cf02fccc91a" category="cell">Python 3.6.8</block>
  <block id="f1fc3d8c09aa84e7962b7352b4ff77d0" category="cell">ORA-01</block>
  <block id="45e595507a12edb8eba89711f9a72814" category="cell">/u01、/u02、/u03 NFS挂载到ANF容量池上</block>
  <block id="40a01cd2d5c81f8bbe1ed2d28d4cafaa" category="cell">ORA-02.</block>
  <block id="71f5cff1bdc5f944cf1edf33ff9e411f" category="list-text">*Oracle数据库存储布局。*在此自动化Oracle部署中、我们会默认为每个数据库配置三个数据库卷、以托管Oracle二进制文件、数据和日志。卷会通过NFS以/u01 -二进制、/u02 -数据、/u03 -日志的形式挂载在Oracle数据库服务器上。在/u02和/u03挂载点上配置双控制文件、以实现冗余。</block>
  <block id="755e2a8326e346588d02e48b85b044a5" category="list-text">*部署多个数据库服务器。*自动化解决方案可以在一次运行的AnsablePlaybook中将一个Oracle容器数据库部署到多个数据库服务器。无论数据库服务器的数量如何、该操作手册的执行都保持不变。通过使用不同的数据库实例ID (Oracle SID)重复部署、您可以将多个容器数据库部署到一个VM实例。但是、请确保主机上有足够的内存来支持已部署的数据库。</block>
  <block id="d15b8c5aac4428cb7f6506c56eb633f5" category="list-text">*DNFS配置。*通过使用DNFS (自Oracle 11g起提供)、在Azure虚拟机上运行的Oracle数据库可以比本机NFS客户端驱动更多的I/O。默认情况下、Oracle自动化部署会在NFSv3上配置DNFS。</block>
  <block id="d37225cccdfda955e0eb0ba299e4abd9" category="list-text">*分配大容量卷以加快部署速度。* ANF文件系统IO吞吐量根据卷大小进行调节。对于初始部署、分配大容量卷可以加快部署速度。之后、可以动态缩减卷的大小、而不会对应用程序造成影响。</block>
  <block id="e1d479f830dc9bfc4ed574a1c8cc0c98" category="list-text">*数据库备份。* NetApp提供了一个SnapCenter软件套件、可通过用户友好的用户界面进行数据库备份、还原和克隆。NetApp建议实施此类管理工具、以实现快速(不到一分钟)的快照备份、快速(几分钟)的数据库还原和数据库克隆。</block>
  <block id="2853404fffac22cebc324f82a3f1a9fe" category="paragraph">以下各节提供了在Azure NetApp Files上通过NFS直接挂载数据库卷自动部署Oracle 19c以及将数据库迁移到Azure VM的分步过程。</block>
  <block id="cefb723f87cc807402d8139074dd7ba2" category="list-text">已设置Azure帐户、并且已在Azure帐户中创建必要的vNet和网段。</block>
  <block id="897e81187b9a977579ea7b52666194e2" category="list-text">在Azure云门户中、将Azure Linux VM部署为Oracle数据库服务器。为Oracle数据库创建Azure NetApp Files容量池和数据库卷。为azureuser到DB服务器启用VM SSH私有/公共密钥身份验证。有关环境设置的详细信息、请参见上一节中的架构图。另见 <block ref="dc52e56b98922ff2fa6a8a6723666d6f" category="inline-link-macro-rx"></block> 了解详细信息。</block>
  <block id="47c878359f4c935db42a7d950cb56e05" category="admonition">对于部署了本地磁盘冗余的Azure VM、请确保在VM根磁盘中至少分配了128 G的空间、以便有足够的空间来暂存Oracle安装文件和添加操作系统交换文件。相应地展开/tmplv和/rootlv OS分区。确保数据库卷命名遵循vmname-u01、vmname-u02和vmname-u03约定。</block>
  <block id="958a975d9bb698c899681bd5b20130f9" category="list-text">从Azure云门户中、配置Windows服务器以使用最新版本运行NetApp SnapCenter UI工具。有关详细信息、请参见以下链接： <block ref="131e9eb1b10c693e5b08c2ea655bbc23" category="inline-link-macro-rx"></block></block>
  <block id="edcb3cec7bdc90699c540bbd3aa40987" category="list-text">将Linux VM配置为安装了最新版本的Ansv近 和Git的Ansv可 控制器节点。有关详细信息、请参见以下链接： <block ref="d1250df0700152003f00dbe5bac89608" category="inline-link-macro-rx"></block> 在第-节中<block ref="3d45b043c5518eca1e47fb4ba8a813da" prefix=" " category="inline-code"></block> 或<block ref="2afb5cc3404c6c8162722fd41895c2de" prefix=" " category="inline-code"></block>。</block>
  <block id="a219cd1e2fd41772e39373e9c510f73b" category="admonition">只要通过ssh端口访问Azure数据库VM、则Ansensure控制器节点就可以查找内部未命中或Azure云中的位置。</block>
  <block id="1bd19d215e29e048034930d3b3953ef8" category="list-text">克隆一份适用于NFS的NetApp Oracle部署自动化工具包副本。</block>
  <block id="d15efb03f8ec068e9d6d6926f079f1b3" category="list-text">Stage Follows Oracle 19c installation files on Azure DB VM /tmp/archive directory with 777 permission。</block>
  <block id="5fb0031d6dfea0b65cedbf5ef342e74c" category="video-title">借助NFS在Azure NetApp Files上简化并自动化Oracle部署</block>
  <block id="0950679600889e0ecb0fcb4adff23fd9" category="list-text">一次运行即可执行所有部署操作手册。</block>
  <block id="3ecdefb0fe9b92fb5dada4a1b9246b77" category="paragraph">运行此操作手册后、登录到Oracle数据库服务器VM、以验证是否已安装和配置Oracle以及是否已成功创建容器数据库。以下是在主机ora-01上验证Oracle数据库的示例。</block>
  <block id="3eb5235599c703aade8d4a3ae8a6c244" category="list-text">验证NFS挂载</block>
  <block id="aabe8782eb2ec64b895e31945ebe1e42" category="list-text">验证Oracle侦听器</block>
  <block id="39182d8bb094516788625069e7ecaf1d" category="list-text">验证Oracle数据库和DNFS</block>
  <block id="3a9e92fed2a83eee60f3bac7ce51cbed" category="section-title">将Oracle数据库迁移到Azure</block>
  <block id="ce9b5da67cd6dc3cd4e1e77ddf5c5eac" category="paragraph">Oracle数据库从内部迁移到云是一项繁重的工作。使用正确的策略和自动化可以使流程顺畅进行、并最大限度地减少服务中断和停机时间。请遵循此详细说明 <block ref="9701ccef4d74ef0a1719e8a2a189be37" category="inline-link-macro-rx"></block> 指导您的数据库迁移之旅。</block>
  <block id="03b3d2a7a581e28eade41b2069651904" category="list-text">部署Oracle Direct NFS</block>
  <block id="54d61c6a6d7438a74568da42787fa14b" category="inline-link-macro"><block ref="54d61c6a6d7438a74568da42787fa14b" category="inline-link-rx"></block></block>
  <block id="a31fb0666cfd1ef716527d49b2f71a7a" category="paragraph"><block ref="a31fb0666cfd1ef716527d49b2f71a7a" category="inline-link-macro-rx"></block></block>
  <block id="2cb397312bce847a3821d2e60cf08aff" category="admonition">虽然迁移工具包是在AWS云基础架构上开发和验证的、但它是基于Oracle应用程序级解决方案构建的。因此、该工具包适用于其他公有云平台、例如Azure、GCP等</block>
  <block id="57ae91c192e5448dfd58b60a55eaa521" category="paragraph">本文档演示了如何在使用ASA系统构建的SAN环境中使用Andsilp自动化简化Oracle数据库的部署。Oracle数据库部署在独立重新启动配置中、使用iSCSI协议在ASA存储阵列上进行数据访问、并使用Oracle ASM进行数据库磁盘管理。此外、还提供了有关使用NetApp SnapCenter UI工具在NetApp ASA系统中执行高效存储数据库操作的Oracle数据库备份、还原和克隆的信息。</block>
  <block id="f8554b7127d48d5c30c710f4cca8e8d0" category="image-alt">此图详细展示了采用iSCSI和ASM的NetApp ASA系统中的Oracle部署配置。</block>
  <block id="fbea71704c36d23a69b3aff3e60cf91a" category="list-text">将Linux VM配置为安装了最新版本的Ansv近 和Git的Ansv可 控制器节点。有关详细信息、请参见以下链接： <block ref="d1250df0700152003f00dbe5bac89608" category="inline-link-macro-rx"></block> 在第-节中<block ref="3d45b043c5518eca1e47fb4ba8a813da" prefix=" " category="inline-code"></block> 或<block ref="2afb5cc3404c6c8162722fd41895c2de" prefix=" " category="inline-code"></block>。</block>
  <block id="273fd96f97f0a813313984b6447b0c0a" category="paragraph">自动化工具包中共有六本操作手册。每个任务执行不同的任务块、并用于不同的用途。</block>
  <block id="8ba045e8292f88863e71268ec6dabc53" category="paragraph">使用最大可用性选项的Oracle PDB重新定位采用PDB热克隆技术、这样、在PDB复制到目标时、可以使用源PDB。切换时、用户连接会自动重定向到目标PDB。因此、无论PDB的大小如何、都可以最大限度地减少停机时间。NetApp提供了一个基于Ansible的工具包、用于自动执行迁移操作步骤。</block>
  <block id="3ec32ad563e52362b7be3ad6c2a06885" category="doc">TR-4986：《在采用iSCSI的Amazon FSx ONTAP上简化的自动化Oracle部署》</block>
  <block id="eb2a9deb9a6cbdb48793f025ada759d3" category="cell">2024年2月5日</block>
  <block id="ed2209cb3ae5244f45534b6a34c226a7" category="cell">新TR-4987：《在采用iSCSI的Amazon FSx ONTAP上简化的自动化Oracle部署》</block>
  <block id="81a10af5a6146ec42060dd4ea7e608fb" category="cell">新TR-4986：《在采用iSCSI的Amazon FSx ONTAP上简化的自动化Oracle部署》</block>
  <block id="3914554f3e4d9e4c6db0b30795651877" category="sidebar">使用NFS在Azure NetApp Files上简化、自动化的Oracle部署</block>
  <block id="669229547c608401722091d86f6bd5c6" category="list-text"><block ref="669229547c608401722091d86f6bd5c6" category="inline-link-macro-rx"></block></block>
  <block id="2c503a297b82f70a53a3469cc0e51326" category="list-text"><block ref="2c503a297b82f70a53a3469cc0e51326" category="inline-link-macro-rx"></block></block>
  <block id="ec3d39372bca7a850b2ffa1f442a3f9c" category="list-text"><block ref="ec3d39372bca7a850b2ffa1f442a3f9c" category="inline-link-macro-rx"></block></block>
  <block id="551b87831bb9b4feaa3ea9fedab44376" category="cell"><block ref="551b87831bb9b4feaa3ea9fedab44376" category="inline-link-macro-rx"></block></block>
  <block id="9e6af294dcab58407fffccfe797bb770" category="list-text"><block ref="9e6af294dcab58407fffccfe797bb770" category="inline-link-macro-rx"></block></block>
  <block id="48c54ea3c7cc5b66102b64a865010a84" category="list-text"><block ref="48c54ea3c7cc5b66102b64a865010a84" category="inline-link-macro-rx"></block></block>
  <block id="a8618a279ebb889fb6918b30fcfef37d" category="paragraph">第一步是在Google Cloud上配置Cloud Volumes ONTAP <block ref="125d0635d744a18f345eb177fd4e8644" category="inline-link-rx"></block>)并使用所需的频率和快照保留将所需的卷复制到Cloud Volumes ONTAP。</block>
  <block id="7c5e9d9b28a0eea226476285c42978a7" category="paragraph">有关设置SnapCenter 和复制数据的分步说明示例、请参见<block ref="20da3d8201bc4e60c4173e459cc23f0f" category="inline-link-rx"></block></block>
  <block id="754aa625b457b33bda446b6fdc65bec4" category="paragraph">要配置GCVE SDDC、请参见<block ref="feaa2b09ad8ef009d205cd65f48842bd" category="inline-link-rx"></block>。前提条件是、在建立连接后、验证位于GCVE主机上的子虚拟机是否能够使用Cloud Volumes ONTAP 中的数据。</block>
  <block id="46fb6146c9b0a05565a6b1801a38c704" category="list-text">使用现有Google Cloud VMware Engine软件定义的数据中心(SDDC)或使用此功能创建私有云<block ref="a86c0385297805d60a9d4e5ca509b2e6" category="inline-link-rx"></block> 或这一点<block ref="a00f1cbf0fed787208cc1bff752e650f" category="inline-link-rx"></block>。</block>
  <block id="f7ee91bad65dd0826496e5cdc033dd72" category="list-text"><block ref="f7ee91bad65dd0826496e5cdc033dd72" category="inline-link-macro-rx"></block></block>
  <block id="bf47e279180c3a2f7d19b1aff780e4d8" category="list-text"><block ref="bf47e279180c3a2f7d19b1aff780e4d8" category="inline-link-macro-rx"></block></block>
  <block id="058fc8d61fe5e94b0639f39b19f44100" category="paragraph">第一步是在Azure上配置Cloud Volumes ONTAP <block ref="e9d023c281c25f414b636209b14ceb93" category="inline-link-rx"></block>)并使用所需的频率和快照保留将所需的卷复制到Cloud Volumes ONTAP。</block>
  <block id="be90b85411abca4962face99da9cdc51" category="paragraph">要配置AVS SDDC (无论是按需配置还是在指示灯模式下配置)、请参见<block ref="774ecd4faa500074f9ee651f24c73d3f" category="inline-link-rx"></block>。前提条件是、在建立连接后、验证AVS主机上的子虚拟机是否能够使用Cloud Volumes ONTAP 中的数据。</block>
  <block id="ff8e7c7e5da6b69f6f86c453c3fd1839" category="list-text">使用现有Azure VMware解决方案 软件定义的数据中心(SDDC)或使用此功能创建私有云<block ref="7ed17391c9cb751d8a370badc3305b11" category="inline-link-rx"></block> 或这一点<block ref="5633c6477a16a80a8050560dab9783c9" category="inline-link-rx"></block>。</block>
  <block id="f335ab4bb63dbb0fc45791a1f7074769" category="list-text">使用现有VMC SDDC或根据此操作创建新的SDDC<block ref="144cb1c1356da972b790dae516e99437" category="inline-link-rx"></block> 或这一点<block ref="5f912d133d878a69c5af374752da199e" category="inline-link-rx"></block>。</block>
  <block id="10c1b63475fdb4bf1313973de012539b" category="list-text">适用于ONTAP NFS的FSX卷应作为补充数据存储库挂载到VMC SDDC中。  要将NFS数据存储库连接到相应的集群、请按照本节中所述的步骤进行操作<block ref="5cd7f6ac555034cac12d16bb92f64ac7" category="inline-link-rx"></block> 或这一点<block ref="6eb21d78e613b27f69be6d996a6367b3" category="inline-link-rx"></block>。</block>
  <block id="389b684e6540cf347234da0537ec5890" category="paragraph"><block ref="88a970f127e79f2a50f427561bb2a4f6" category="inline-link-macro-rx"></block> 为AWS生态系统中基于VMware的工作负载提供云原生体验。每个VMware软件定义的数据中心(SDDC)均在Amazon Virtual Private Cloud (VPC)中运行、并提供完整的VMware堆栈(包括vCenter Server)、NSX-T软件定义的网络连接、vSAN软件定义的存储以及一个或多个ESXi主机、这些主机可为工作负载提供计算和存储资源。要在AWS上配置VMC环境、请按照此处的步骤进行操作 <block ref="a5b5607a4ea0e45c7c98f3f8e4ca6b33" category="inline-link-macro-rx"></block>。此外、还可以使用引导灯集群进行灾难恢复。</block>
  <block id="ef2527ab4efefad1b628217d824fc4e7" category="paragraph">适用于NetApp ONTAP 的Amazon FSX是一种完全托管的服务、可提供基于常见NetApp ONTAP 文件系统构建的高度可靠、可扩展、高性能和功能丰富的文件存储。请按照此处的步骤进行操作 <block ref="88670de70d95804496a75134d7b6b5d1" category="inline-link-macro-rx"></block> 为ONTAP 配置和配置FSX。</block>
  <block id="06d58760364298febdbc614037120026" category="paragraph">要在Azure上配置AVS私有云、请按照中的步骤进行操作<block ref="296c144250386876b02c82396a107f56" category="inline-link-rx"></block> 适用于NetApp文档和本<block ref="21d8cba1c79bac0a64be5fa1f1f2361c" category="inline-link-rx"></block> 了解Microsoft文档。  采用最低配置设置的指示灯环境可用于灾难恢复。  此设置仅包含支持关键应用程序的核心组件、并且可以横向扩展并生成更多主机、以便在发生故障转移时承担大部分负载。</block>
  <block id="0ba365065d3470e99f397c2a76edcab5" category="inline-link"><block ref="0ba365065d3470e99f397c2a76edcab5" category="inline-link-rx"></block></block>
  <block id="3b61012f669ecd381ddae6f9a94b5af6" category="paragraph"><block ref="3b61012f669ecd381ddae6f9a94b5af6" category="inline-link-rx"></block></block>
  <block id="5a8c4de72c40380ba46a9d575ddad939" category="list-text"><block ref="5a8c4de72c40380ba46a9d575ddad939" category="inline-link-macro-rx"></block></block>
  <block id="8710c2a11be58558fb1f4880f638ae3e" category="list-text"><block ref="a79278f147b8adc728cbf65fe104eed4" category="inline-link-macro-rx"></block></block>
  <block id="f48e6f6ebf27803ea9fd6f4f8536846f" category="list-text"><block ref="f48e6f6ebf27803ea9fd6f4f8536846f" category="inline-link-macro-rx"></block></block>
  <block id="66c01a88bc3c590c03e0c7b4126f0a55" category="list-text"><block ref="66c01a88bc3c590c03e0c7b4126f0a55" category="inline-link-macro-rx"></block></block>
  <block id="8e7e1f60b48a18061ca43299d64493bf" category="list-text"><block ref="8e7e1f60b48a18061ca43299d64493bf" category="inline-link-macro-rx"></block></block>
  <block id="2db79283dd143961dabac0f6501fa401" category="list-text"><block ref="2db79283dd143961dabac0f6501fa401" category="inline-link-macro-rx"></block></block>
  <block id="35bc5bb7abf33664404d36c50c744d8a" category="list-text"><block ref="35bc5bb7abf33664404d36c50c744d8a" category="inline-link-macro-rx"></block></block>
  <block id="603b137e27cf7a9ff436f7e1941e09de" category="list-text"><block ref="603b137e27cf7a9ff436f7e1941e09de" category="inline-link-macro-rx"></block></block>
  <block id="a5e438849ef36b5a2e242388bdfe0902" category="paragraph">技术报告： <block ref="ba61c7f4bb3b8cc41ae87013f20fa70c" category="inline-link-macro-rx"></block></block>
  <block id="42e9cb9f198efe69e746c8ae88b2a208" category="list-text"><block ref="42e9cb9f198efe69e746c8ae88b2a208" category="inline-link-macro-rx"></block></block>
  <block id="2338d7990ef42797002fa205e15ab65f" category="list-text"><block ref="2338d7990ef42797002fa205e15ab65f" category="inline-link-macro-rx"></block></block>
  <block id="d7f1b42632aef918ce26a4dd6d010b4f" category="list-text"><block ref="d7f1b42632aef918ce26a4dd6d010b4f" category="inline-link-macro-rx"></block></block>
  <block id="552270fdc0ecafb961246b0bb5dc7520" category="list-text"><block ref="552270fdc0ecafb961246b0bb5dc7520" category="inline-link-macro-rx"></block></block>
  <block id="8628c3cf5f4fcba5f1600917db78b55d" category="list-text"><block ref="8628c3cf5f4fcba5f1600917db78b55d" category="inline-link-macro-rx"></block></block>
  <block id="f25e48bc4daa79e5ab8b68aab54060d0" category="list-text"><block ref="f25e48bc4daa79e5ab8b68aab54060d0" category="inline-link-macro-rx"></block></block>
  <block id="f138a8607f7628a978548192d4e77f98" category="list-text"><block ref="f138a8607f7628a978548192d4e77f98" category="inline-link-macro-rx"></block></block>
  <block id="05441238a4ac95ea5590a12260bd58b4" category="cell">2024年2月15日</block>
  <block id="7e1e9b5b7e0095d951940c85504f756e" category="cell">新TR-4988：《使用SnapCenter在ANF上执行Oracle数据库备份、恢复和克隆》</block>
  <block id="7d5231eeeadfe71a5efcd24a1d5e0be9" category="video-title">使用SnapCenter在ANF上执行Oracle数据库备份、恢复和克隆</block>
  <block id="8eb7bac9a4678cba7fbecce513dbb48d" category="paragraph">NetApp建议使用SnapCenter UI工具来管理部署在Azure云中的Oracle数据库。请参阅TR-4988： <block ref="e0df2f7dd9e56bade59bd40321e8f1c5" category="inline-link-macro-rx"></block> 了解详细信息。</block>
  <block id="e0df2f7dd9e56bade59bd40321e8f1c5" category="paragraph"><block ref="e0df2f7dd9e56bade59bd40321e8f1c5" category="inline-link-macro-rx"></block></block>
  <block id="92726ec0eae6e1e73c6db87d872ebe6e" category="summary">解决方案提供了有关在Microsoft Azure NetApp Files中自动部署Oracle作为使用NFS协议的主数据库存储以及在启用了DNFS的情况下将Oracle数据库部署为容器数据库的概述和详细信息。在Azure中部署的数据库使用SnapCenter UI工具进行保护、以简化数据库管理</block>
  <block id="2a5eba546233f90579d3260dd00dbd31" category="doc">TR-4988：《使用SnapCenter在ANF上执行Oracle数据库备份、恢复和克隆》</block>
  <block id="3c0b969f02b8a026925047057738fc1b" category="paragraph">NetApp SnapCenter 软件是一款易于使用的企业平台，可安全地协调和管理应用程序，数据库和文件系统之间的数据保护。它可以将备份、还原和克隆生命周期管理工作负载分流给应用程序所有者、而不会影响对存储系统上的活动进行监控和监管的能力、从而简化这些任务。通过利用基于存储的数据管理、它可以提高性能和可用性、并缩短测试和开发时间。</block>
  <block id="42eb4ddfe3f445ea0352aef56b5e7fdb" category="paragraph">在TR-4987中、 <block ref="0f9ba0e2eb61f2970cc50a6cb6799a08" category="inline-link-macro-rx"></block>中、我们演示了在Azure云中的Azure NetApp Files (ANF)上自动部署Oracle。在本文档中、我们使用非常友好的SnapCenter UI工具展示了Azure云中ANF上的Oracle数据库保护和管理。</block>
  <block id="81fa72cbc547f894c7c04a4127dfe5ea" category="list-text">使用SnapCenter备份和恢复Azure云中ANF上部署的Oracle数据库。</block>
  <block id="6cfd0230dc78dea7b5afceb0812f2f42" category="list-text">管理数据库快照和克隆副本、以加快应用程序开发速度并改进数据生命周期管理。</block>
  <block id="9de2392a5a7812b0166ee1ad25de89f1" category="list-text">希望在Azure NetApp Files上部署Oracle数据库的数据库管理人员。</block>
  <block id="9a0a3a7d3a2a195a355c15770cfa5372" category="list-text">希望在Azure NetApp Files上部署和管理Oracle数据库的存储管理员。</block>
  <block id="88ee29f0e07795688dabad629e6b1a38" category="cell">具有高级服务级别的容量池</block>
  <block id="5b51e2d6963535892778a3ec85923303" category="cell">两个Linux虚拟机实例</block>
  <block id="fcac956b151981c790450bffbe8a6ec5" category="cell">2022 DataCenter；AE HotPatch - x64 Gen2</block>
  <block id="66bda974b27aec9fc4c649e866e2d848" category="cell">修补p34765931_190000_Linux-x86-64.zip</block>
  <block id="e2bc304a34949cf78793eb2d9a4466f7" category="cell">修补p6880880_190000_Linux-x86-64.zip</block>
  <block id="58b1cd722de6d096e347df95b97f1708" category="list-text">* SnapCenter部署。* SnapCenter可以部署在Windows域或工作组环境中。对于基于域的部署、域用户帐户应为域管理员帐户、或者域用户属于SnapCenter托管服务器上的本地管理员组。</block>
  <block id="51b67e7136bcea8684399bd788343a3d" category="list-text">*名称解析。* SnapCenter服务器需要将名称解析为每个受管目标数据库服务器主机的IP地址。每个目标数据库服务器主机都必须将SnapCenter服务器名称解析为IP地址。如果DNS服务器不可用、请为本地主机文件添加命名以进行解析。</block>
  <block id="5201585f52455453631952654fbcfdc1" category="list-text">*资源组配置。* SnapCenter中的资源组是一个类似资源的逻辑分组、可以一起备份。因此、它可以简化大型数据库环境中的备份作业并减少备份作业的数量。</block>
  <block id="9b274f274cc2fdf5c2eaac7308f2a980" category="list-text">*单独的完整数据库和归档日志备份。*完整数据库备份包括数据卷和日志卷一致的组快照。频繁创建完整数据库快照会占用较多的存储空间、但会提高恢复能力。另一种方法是、减少创建完整数据库快照的频率、增加归档日志备份的频率、从而减少存储消耗、提高RPO、但可能会延长RTO。在设置备份方案时、请考虑您的RTO和RPO目标。此外、卷上的Snapshot备份数也有限制(1023)。</block>
  <block id="b85fa7425df71e674278fea13b4d8df3" category="list-text">*特权委派。*利用SnapCenter UI内置的基于角色的访问控制、根据需要将权限委派给应用程序和数据库团队。</block>
  <block id="e27bf8eca64c83fe8b6062fb95e333d9" category="paragraph">以下各节介绍了在Azure云中的Azure NetApp Files上部署、配置SnapCenter以及备份、恢复和克隆Oracle数据库的分步过程。</block>
  <block id="e7994b73209a873dc947f84bcf831bc5" category="paragraph">部署要求现有Oracle数据库在Azure中的ANF上运行。如果没有、请按照以下步骤创建两个Oracle数据库以进行解决方案验证。有关在Azure云中的ANF上通过自动化部署Oracle数据库的详细信息、请参见TR-4987： <block ref="0f9ba0e2eb61f2970cc50a6cb6799a08" category="inline-link-macro-rx"></block></block>
  <block id="7248ba2d36ba4b2b7deb2879ad658327" category="list-text">从Azure云门户中、配置Windows服务器以使用最新版本运行NetApp SnapCenter UI工具。有关详细信息、请参见以下链接： <block ref="131e9eb1b10c693e5b08c2ea655bbc23" category="inline-link-macro-rx"></block>。</block>
  <block id="f5823da50f0c261f93cac13c89efabe5" category="inline-link-macro">TR-4887</block>
  <block id="f0d197390e31ccddcd560c68c6c1ba54" category="list-text">克隆一份适用于NFS的NetApp Oracle部署自动化工具包副本。按照中的说明进行操作 <block ref="b96eb2a0d3fd0ab56815beb32051064b" category="inline-link-macro-rx"></block> 执行这些操作手册。</block>
  <block id="bfa29a4d1633c304ce5ea63b28050c30" category="list-text">查看<block ref="e0c4332e8c13be976552a059f106354f" prefix=" " category="inline-code"></block> 在线菜单。</block>
  <block id="b6bfa5b7d69b44a49fead07bd2c2a3ae" category="section-title">SnapCenter安装和设置</block>
  <block id="7608e75619cff3eeb4e8bce40481b456" category="inline-link-macro">SnapCenter 软件文档</block>
  <block id="d2e6519128f0c0f4297df9dfcf74f4f4" category="paragraph">我们建议您在线完成 <block ref="709a64672cb1b481d7e1d00abe15371a" category="inline-link-macro-rx"></block> 在继续SnapCenter安装和配置之前：。下面简要概括了在Azure ANF上安装和设置适用于Oracle的SnapCenter软件的步骤。</block>
  <block id="2f16590362b9a77201075964ad79edf6" category="list-text">从SnapCenter Windows服务器中、从下载并安装最新的Java JDK <block ref="1a0bb7a886be273015991771cf1b1190" category="inline-link-macro-rx"></block>。</block>
  <block id="4c432947190d17ebbfafd109af579e8b" category="inline-link-macro">NetApp |支持</block>
  <block id="252ae86269b0f2ac0af59ba9dbaf9f77" category="list-text">从SnapCenter Windows服务器中、从NetApp 支持站点 下载并安装最新版本(当前版本为5.0)的SnapCenter安装可执行文件： <block ref="f0da1a8fe9efadb5bab3d3f47fea4f67" category="inline-link-macro-rx"></block>。</block>
  <block id="06f6fe269bc66b13969ba522de05e124" category="list-text">安装SnapCenter服务器后、启动浏览器以使用Windows本地管理员用户或域用户凭据通过端口8146登录到SnapCenter。</block>
  <block id="59b99dff4b9ef65674331e7340fa08d7" category="image-alt">此图提供了SnapCenter服务器的登录屏幕</block>
  <block id="96a37aec5c27e605088aea24d5d14206" category="list-text">请查看<block ref="e0c4332e8c13be976552a059f106354f" prefix=" " category="inline-code"></block> 在线菜单。</block>
  <block id="e4ecaf6c95aea5efc31bb0908136fe57" category="image-alt">此图提供SnapCenter服务器的联机菜单</block>
  <block id="26580f485e752465df198f9ca8753224" category="list-text">在中<block ref="4d6066956a45bb2668fa0c138b1f3d03" prefix=" " category="inline-code"></block>，检查<block ref="6b2d6702a0358e8df43b31cf0890a30f" prefix=" " category="inline-code"></block> 然后单击更新。</block>
  <block id="ffae6a01cee8b80c47313ba0d044f280" category="image-alt">此图提供了SnapCenter服务器的虚拟机管理程序设置</block>
  <block id="3b970cc736d04d4b56c58fea4ad5c9da" category="list-text">根据需要进行调整<block ref="67fde4caae23fade4d1bd7de40c81bc7" prefix=" " category="inline-code"></block> 将SnapCenter UI设置为所需间隔。</block>
  <block id="d0d8ee4e483915ff866ab8323293c1d0" category="image-alt">此图提供SnapCenter服务器的会话超时</block>
  <block id="a0acc9513d8b87ae002c74de46229c03" category="list-text">根据需要向SnapCenter添加其他用户。</block>
  <block id="025955fc32ea828a9e5153bf02eac7b2" category="image-alt">此图提供SnapCenter服务器的设置-用户和访问权限</block>
  <block id="e481d0de1e224ddd98e9dfb72c1f658d" category="list-text">。<block ref="a5cd3ed116608dac017f14c046ea56bf" prefix=" " category="inline-code"></block> 选项卡列出了可分配给不同SnapCenter用户的内置角色。具有所需权限的管理员用户也可以创建自定义角色。</block>
  <block id="ee0d0d1f1f6fe1110797be4d48053fae" category="image-alt">此图提供了SnapCenter服务器的角色</block>
  <block id="3fb40cbc384305df9161da52ec4c2d0d" category="list-text">from<block ref="c4646a4d73e5bf2cf1843bda6cd9f769" prefix=" " category="inline-code"></block>，创建SnapCenter管理目标的凭据。在此演示用例中、他们是Linux用户、可登录到Azure VM、并可通过ANF凭据访问容量池。</block>
  <block id="dc06424d30636d2437b7c082a44271de" category="image-alt">此图提供SnapCenter服务器的凭据</block>
  <block id="dd4237b12d92b22e7ad381bf28522e7f" category="list-text">from<block ref="5c6ab1284b6b7a5a7102854a969c99be" prefix=" " category="inline-code"></block> 选项卡、添加<block ref="7450cfde7058dc5e1f7909d0280fd7ae" prefix=" " category="inline-code"></block> 凭据。</block>
  <block id="71e910f4881c08ea6897e22b79389cf4" category="image-alt">此图提供了适用于SnapCenter服务器的Azure NetApp Files</block>
  <block id="d7702d89b895aa6ec99def769587c405" category="list-text">from<block ref="8124579383e90243e4b06323d2b37f8d" prefix=" " category="inline-code"></block> 选项卡上、添加Azure DB VM、此操作将在Linux上安装适用于Oracle的SnapCenter插件。</block>
  <block id="b979fe379fa5345e56adf94005f84929" category="image-alt">此映像提供了SnapCenter服务器的主机</block>
  <block id="a3a63bd1ddab3e696228b7b61878c09d" category="inline-link-macro">为 Oracle 数据库创建备份策略</block>
  <block id="2166a1bececf10153acd19c3ed9b1d2e" category="list-text">在数据库服务器VM上安装主机插件后、系统会自动发现主机上的数据库、并在中显示这些数据库<block ref="ddcf50c29294d4414f3f7c1bbc892cb5" prefix=" " category="inline-code"></block> 选项卡。返回到<block ref="6c8a99d2cb03d4bc5a863f8606453994" prefix=" " category="inline-code"></block>，为Oracle数据库完全联机备份和仅归档日志备份创建备份策略。请参阅本文档 <block ref="9c987a74ad0aa597c1c522b0007ec5d5" category="inline-link-macro-rx"></block> 了解详细的分步过程。</block>
  <block id="886ca5ebbeb3beae0e42d559adb9afa6" category="image-alt">此图提供了SnapCenter服务器的设置策略</block>
  <block id="89a532a917f392c521eb9922d1a47d62" category="paragraph">NetApp快照备份会为数据库卷创建一个时间点映像、您可以在发生系统故障或数据丢失时使用该映像进行还原。Snapshot备份所需时间极少、通常不到一分钟。备份映像占用的存储空间极少、并且性能开销可以忽略不计、因为它仅会记录自上次创建Snapshot副本以来对文件所做的更改。下一节介绍了如何在SnapCenter中为Oracle数据库备份实施快照。</block>
  <block id="2622a793728d35ec6877f6afb1a153e6" category="list-text">导航到<block ref="ddcf50c29294d4414f3f7c1bbc892cb5" prefix=" " category="inline-code"></block> 选项卡、其中列出了在数据库VM上安装SnapCenter插件后发现的数据库。最初、是<block ref="58d4fcf0afd65a0eb3857a2d3e254c8c" prefix=" " category="inline-code"></block> 的数据库显示为<block ref="4aa6066b3ed6d1b995450c6c7ad4a3d8" prefix=" " category="inline-code"></block>。</block>
  <block id="4ba96929ee643a0f3d8eb215ab8d7c35" category="image-alt">此映像提供SnapCenter服务器的数据库备份</block>
  <block id="7fb0e0d4bbba69fa67fe86fdcf6fa41f" category="list-text">单击<block ref="4351cfebe4b61d8aa5efa1d020710005" prefix=" " category="inline-code"></block> 下拉列表以更改为<block ref="dd23acac46f17cbfd4d5541f8ee3c7a1" prefix=" " category="inline-code"></block>。单击<block ref="ec211f7c20af43e742bf2570c3cb84f9" prefix=" " category="inline-code"></block> 在右侧签名以添加资源组。</block>
  <block id="19ff1cea165e0fcce11d79410c000e25" category="list-text">为资源组、标记和任何自定义命名命名命名。</block>
  <block id="9cf2d7ee69e3a812dae0bd35100b6081" category="list-text">将资源添加到<block ref="dd23acac46f17cbfd4d5541f8ee3c7a1" prefix=" " category="inline-code"></block>。对类似资源进行分组可以简化大型环境中的数据库管理。</block>
  <block id="875d3bcc106894cef94c8362d4bada10" category="list-text">选择备份策略并单击下方的"+"符号设置计划<block ref="b54c2aaa814d856436c9f864ac8afdd5" prefix=" " category="inline-code"></block>。</block>
  <block id="7918c5620dbf35faced9d7a3a666da15" category="list-text">如果未在策略中配置备份验证、请按原样保留验证页面。</block>
  <block id="b2396ffd0abd0c6bffee737277b76430" category="list-text">要通过电子邮件发送备份报告和通知、环境中需要SMTP邮件服务器。或者、如果未设置邮件服务器、则将其留为黑色。</block>
  <block id="71dc91d121e985620a277b7fad0f6168" category="list-text">新资源组摘要。</block>
  <block id="9fbbeced92d891e91891234bc859d078" category="list-text">重复上述过程、使用相应的备份策略创建仅限数据库归档日志的备份。</block>
  <block id="24f86cfce0092ac5d9090957526aacbe" category="list-text">单击资源组以显示其包含的资源。除了计划的备份作业之外、单击还可以触发一次性备份<block ref="9a9852432e1a7055c64fef6ff8f6dd65" prefix=" " category="inline-code"></block>。</block>
  <block id="287f76d0aaad99fd67c4537bef25ac74" category="list-text">单击正在运行的作业可打开一个监控窗口、操作员可通过该窗口实时跟踪作业进度。</block>
  <block id="489facdfbfbab274d7adce93c4539d9f" category="list-text">成功完成备份作业后、Snapshot备份集将显示在数据库拓扑下。完整数据库备份集包括数据库数据卷的快照和数据库日志卷的快照。仅日志备份仅包含数据库日志卷的快照。</block>
  <block id="b7bd6844cb7d1a58c24be2eb5e09dd9e" category="paragraph">通过SnapCenter进行数据库恢复可还原数据库卷映像时间点的Snapshot副本。然后、数据库将按scn/时间戳前滚到所需的点、或备份集中可用归档日志所允许的点。下一节介绍了使用SnapCenter UI进行数据库恢复的工作流。</block>
  <block id="1276bda3e84c962765c7f939562edc1b" category="list-text">from<block ref="ddcf50c29294d4414f3f7c1bbc892cb5" prefix=" " category="inline-code"></block> 选项卡上、打开数据库<block ref="9075f786989ed7df222b4297bec16422" prefix=" " category="inline-code"></block> 页面。选择数据库数据卷的快照、然后单击<block ref="2bd339d85ee3b33e513359ce781b60cc" prefix=" " category="inline-code"></block> 用于启动数据库恢复工作流的按钮。如果要使用Oracle scn或时间戳运行恢复、请记下备份集中的scn编号或时间戳。</block>
  <block id="a482c65925dcf03c4f1df8c0c00d80a6" category="image-alt">此映像提供SnapCenter服务器的数据库还原</block>
  <block id="7a0d6064f45219ea8485b59931a129f9" category="list-text">选择 ...<block ref="2fff52bd70c3fc704bb228287925cfae" prefix=" " category="inline-code"></block>。对于容器数据库、SnapCenter可以灵活地执行完整容器数据库(所有数据文件)、可插拔数据库或表空间级别还原。</block>
  <block id="bac7059283bff97f7d76c4328850c8e8" category="list-text">选择 ...<block ref="ec47ba775b6cce559706e86f20fde009" prefix=" " category="inline-code"></block>。<block ref="d50d6a874b376378de702eec4c6c0b96" prefix=" " category="inline-code"></block> 表示应用备份集中所有可用的归档日志。还可以使用scn或时间戳进行时间点恢复。</block>
  <block id="e89ca0accc18535a19f3f8bf9e942886" category="list-text">。<block ref="ced009502445c11dc6162d3d7758d07b" prefix=" " category="inline-code"></block> 允许在还原/恢复操作之前对数据库执行脚本。</block>
  <block id="c23a56c7db12aa77b66795215479decf" category="list-text">。<block ref="5fa20aa4f779d0f14b1c9545ded7baa6" prefix=" " category="inline-code"></block> 允许在还原/恢复操作后对数据库执行脚本。</block>
  <block id="33402d9fc6c4297fd3a48930e49eb9e4" category="list-text">如果需要、可通过电子邮件发送通知。</block>
  <block id="4867bf6fc07300b11d5e52009f6943e3" category="list-text">还原作业摘要</block>
  <block id="a2ac78daad6f0e5548bf6b3c8a744961" category="list-text">单击正在运行的作业以打开<block ref="4f65019520415bd6c5a529f526f86dd7" prefix=" " category="inline-code"></block> 窗口。也可以从打开和查看作业状态<block ref="d2986ac8cb6bd55892099c1ffd6b1f6f" prefix=" " category="inline-code"></block> 选项卡。</block>
  <block id="fd808403d73611b482552bb655a619b6" category="paragraph">通过SnapCenter执行数据库克隆的方法是、从卷的快照创建新卷。创建快照时、系统会使用卷上的数据、使用快照信息克隆新卷。更重要的是、与其他方法相比、创建生产数据库的克隆副本以支持开发或测试的速度较快(只需几分钟)且效率较高。因此、可以显著改善数据库应用程序生命周期管理。下一节介绍了使用SnapCenter UI进行数据库克隆的工作流。</block>
  <block id="f2914a331ca3beda8620803b7496d121" category="list-text">from<block ref="ddcf50c29294d4414f3f7c1bbc892cb5" prefix=" " category="inline-code"></block> 选项卡上、打开数据库<block ref="9075f786989ed7df222b4297bec16422" prefix=" " category="inline-code"></block> 页面。选择数据库数据卷的快照、然后单击<block ref="d329fd777726c300d7a044e482b967e7" prefix=" " category="inline-code"></block> 用于启动数据库克隆工作流的按钮。</block>
  <block id="f9d20d3938f49ba79e7e71b35367dd8a" category="image-alt">此映像为SnapCenter服务器提供了数据库克隆</block>
  <block id="dd25eb8a6cd5e51eb9a829670231a42d" category="list-text">将克隆数据库命名为SID。(可选)对于容器数据库、也可以在PDB级别执行克隆。</block>
  <block id="25fa34588c9138998f469c3fd58ada8e" category="list-text">选择要放置克隆数据库副本的数据库服务器。保留默认文件位置、除非您要以不同的方式命名它们。</block>
  <block id="af6adf0da4d64fb1eb5f9d629d0dfaeb" category="list-text">应已在克隆数据库主机上安装和配置与源数据库中相同的Oracle软件堆栈。保留默认凭据、但进行更改<block ref="021e4a863e5da100e496150783eb8099" prefix=" " category="inline-code"></block> 与克隆数据库主机上的设置匹配。</block>
  <block id="1be0ae8621a560e5682f70d0ad924cb8" category="list-text">。<block ref="ced009502445c11dc6162d3d7758d07b" prefix=" " category="inline-code"></block> 允许在执行克隆操作之前执行脚本。与生产数据库相比、可以调整数据库参数以满足克隆数据库需求、例如减少SGA目标。</block>
  <block id="9b647ca121466de8e754099a317efa26" category="list-text">。<block ref="5fa20aa4f779d0f14b1c9545ded7baa6" prefix=" " category="inline-code"></block> 允许在执行克隆操作后对数据库执行脚本。克隆数据库恢复可以基于scn、基于时间戳、也可以直到取消(将数据库前滚到备份集中的最后一个归档日志)。</block>
  <block id="bf4fecad178142ecaf84d1631bd0de91" category="list-text">克隆作业摘要。</block>
  <block id="2b9ad7101315fee480147c99a1b004e9" category="list-text">克隆的数据库会立即注册到SnapCenter中。</block>
  <block id="f1a562c6e48bea55b2f5d52385feef1c" category="list-text">验证数据库服务器主机上的克隆数据库。对于克隆的开发数据库、应关闭数据库归档模式。</block>
  <block id="532841fbf704673d5f6dc65db8d8cf66" category="inline-link-macro"><block ref="532841fbf704673d5f6dc65db8d8cf66" category="inline-link-rx"></block></block>
  <block id="a88dfa4149ba3595ee197cb2ff9fdd79" category="paragraph"><block ref="a88dfa4149ba3595ee197cb2ff9fdd79" category="inline-link-macro-rx"></block></block>
  <block id="d5332bd979a7c13c13196f1f6d63e40e" category="inline-link-macro"><block ref="d5332bd979a7c13c13196f1f6d63e40e" category="inline-link-rx"></block></block>
  <block id="a1d2708a3aeb146438315b9f07b6673d" category="paragraph"><block ref="a1d2708a3aeb146438315b9f07b6673d" category="inline-link-macro-rx"></block></block>
  <block id="d7ea87ae176596e65c20709701590891" category="sidebar">在ANF上执行Oracle数据库备份、恢复和克隆</block>
  <block id="9601d44ae8130fd8540748dd2c3cbe93" category="doc">采用VMware vSphere 8的NetApp全闪存SAN阵列</block>
  <block id="78d0aa909b2ebde288307a87f31c82a1" category="section-title">使用NetApp Cloud Insights监控内部存储</block>
  <block id="0e4604ce5d94ee98840498411cb68560" category="paragraph">NetApp Cloud Insights是一款基于云的基础架构监控和分析平台、旨在提供对内部和云中IT基础架构的性能、运行状况和成本的全面可见性和洞察力。NetApp Cloud Insights的主要功能包括实时监控、可自定义的信息板、预测性分析和成本优化工具、使企业能够有效管理和优化其内部和云环境。</block>
  <block id="0e38ceb5bd4b29c1e2bfb74572626b00" category="paragraph">NetApp Cloud Insights通过采集单元软件运行、该软件使用数据收集器为VMware vSphere和NetApp ONTAP存储系统等资产设置数据收集器。这些收集器收集数据并将其传输到Cloud Insights。然后、该平台会利用各种信息板、小工具和指标查询将数据组织为具有洞察力的分析、供用户解释。</block>
  <block id="8caeb3e5d7009654b8ae44b45b52cce2" category="paragraph">Cloud Insights架构图：</block>
  <block id="b261eb23aa6ace170429517bb695f917" category="paragraph">本解决方案介绍了如何使用NetApp Cloud Insights监控内部VMware vSphere和ONTAP存储系统。</block>
  <block id="ae820891856ad53c174639e3a670fdec" category="paragraph">此列表提供了此解决方案中涉及的高级步骤：</block>
  <block id="ce62a2f327eb2e7a55b6fd2140ecced6" category="list-text">为vSphere集群配置Data Collector。</block>
  <block id="996dc9ca8ba48142f9a22416550489cd" category="list-text">为ONTAP存储系统配置数据收集器。</block>
  <block id="2bd53feb5529920394579e440badf5fa" category="list-text">使用标注规则标记资产。</block>
  <block id="17f766b6dcd97b67cb5bd12b7b79d9c4" category="list-text">浏览并关联资产。</block>
  <block id="d8079e58159b58735b981436935ad1ee" category="list-text">使用"虚拟机延迟排名前几位"信息板隔离资源争用者。</block>
  <block id="48c04ba532a298e57d5eb8d80068ae00" category="list-text">识别适当调整VM大小的机会。</block>
  <block id="1b035ce56f9987c7e71c78fe2f971e16" category="list-text">使用查询隔离指标并对其进行排序。</block>
  <block id="9b4380d7b0b95a02b272c0922e4c3a5d" category="paragraph">此解决方案使用以下组件：</block>
  <block id="6caf4d3c26cde6ea0d404ebecdb6bb6d" category="list-text">采用ONTAP 9.13的NetApp全闪存SAN阵列A400。</block>
  <block id="8cd1b27424f4e8ff8b914c834d5522f4" category="list-text">VMware vSphere 8.0集群。</block>
  <block id="4c601857b698c0d0cf4fe385c7cde37f" category="list-text">NetApp Cloud Insights帐户。</block>
  <block id="5821c501835e4353ffbad3b02fba222e" category="list-text">NetApp Cloud Insights采集单元软件安装在本地VM上、并通过网络连接到资产以进行数据收集。</block>
  <block id="995baaed007a33dba572505ffd6d726b" category="section-title">配置数据收集器</block>
  <block id="c8495ea6148aeba57f5db20ffd29140d" category="paragraph">要为VMware vSphere和ONTAP存储系统配置数据收集器、请完成以下步骤：</block>
  <block id="8f76d9118a2471c5088faeb3e0336fda" category="example-title">为ONTAP存储系统添加数据收集器</block>
  <block id="dc3af50681ed35f947b4d23cd92b3a11" category="list-text">登录到Cloud Insights后、导航到*可观察性&gt;收集器&gt;数据收集器*、然后按按钮安装新的数据收集器。</block>
  <block id="9fc31ce4550c4f68c1ea81f5a37335aa" category="image-alt">新的 Data Collector</block>
  <block id="629c1fa2ec60d8768a5e5329d3827c9d" category="list-text">从此处搜索* ONTAP，然后单击* ONTAP数据管理软件*。</block>
  <block id="fe0bf7efdc163c19bee1c87b8df10edd" category="image-alt">搜索Data Collector</block>
  <block id="60598c2a1a380be61f724ef494015012" category="list-text">在*配置收集器*页面上填写收集器的名称，指定正确的*采集单元*并提供ONTAP存储系统的凭据。单击页面底部的*保存并继续*，然后单击*完成设置*以完成配置。</block>
  <block id="e5379e28afbe6ac5e5f3f48b04c76d66" category="image-alt">配置收集器</block>
  <block id="ac423086c6f588ebc302eeca5dabeb16" category="example-title">为VMware vSphere集群添加Data Collector</block>
  <block id="c48587483a6be2639b9cebd52a8f78ac" category="list-text">再次导航到*可观察性&gt;收集器&gt;数据收集器*并按按钮安装新的数据收集器。</block>
  <block id="3a4619b2a78c43c41c267e31e51efc63" category="list-text">在此处搜索*vSphere，然后单击*VMware vSphere。</block>
  <block id="25588558efadb36d5dc61f19b41f7412" category="list-text">在*配置收集器*页面上填写收集器的名称、指定正确的*采集单元*并提供vCenter Server的凭据。单击页面底部的*保存并继续*，然后单击*完成设置*以完成配置。</block>
  <block id="f91b92808922f2332230f6e9f26803e3" category="section-title">向资产添加标注</block>
  <block id="444febb2d918a663c0ce5685514f10c5" category="paragraph">标注是一种标记资产的有用方法、可以在Cloud Insights中提供的各种视图和指标查询中对资产进行筛选和标识。</block>
  <block id="03894d7e1c327ed902ee1dcf1ce2df11" category="paragraph">在本节中，标注将添加到虚拟机资产中，以便按*Data Center*进行筛选。</block>
  <block id="54d18f1d9b7114416b78e9313490dcee" category="example-title">使用标注规则标记资产</block>
  <block id="904d657805e400820efa2b93f49318cd" category="list-text">在左侧菜单中，导航到*Observability &gt; Enrich &gt; Annotation"规则*，然后单击右上角的*+规则*按钮以添加新规则。</block>
  <block id="60e5843b712737e48617dfe8ffc932e2" category="image-alt">正在访问标注规则</block>
  <block id="35ac4a1c83fd86ef8c694e06131cd43f" category="list-text">在*添加规则*对话框中，填写规则的名称，找到要应用规则的查询、受影响的标注字段以及要填充的值。</block>
  <block id="79eccc7a50129923d69b7a90bac97105" category="image-alt">添加规则</block>
  <block id="7a971861918b94ff306b6ff66b709774" category="list-text">最后，在*Annotations R则*页面的右上角，单击*Run All R则*以运行规则并将标注应用于资产。</block>
  <block id="fcb9b755d01ad29b72e0e2c81147a893" category="image-alt">运行所有规则</block>
  <block id="64ccc771b6691aabd2058c255b7ae732" category="section-title">浏览并关联资产</block>
  <block id="ef042f2be6e5c176ef6ea8686e48bbf7" category="paragraph">Cloud Insights可根据存储系统和vSphere集群上同时运行的资产得出逻辑结论。</block>
  <block id="63da201cc31ae73ee85565fd9766fde7" category="paragraph">本节说明如何使用信息板关联资产。</block>
  <block id="6d9313468388115673fa10656c762494" category="example-title">从存储性能信息板关联资产</block>
  <block id="6aa22f1cbc91d9f8608f32c2ac7a35f9" category="list-text">在左侧菜单中，导航到*Observability &gt; Explore &gt; All D仪 表板*。</block>
  <block id="c53f6b41d65d29104c3957ecad72527c" category="image-alt">访问所有信息板</block>
  <block id="258494b1c3dfa30b188e3e2d4624e21b" category="list-text">单击*+ from Gallery*按钮可查看可导入的现成信息板列表。</block>
  <block id="f4cf3d8211e08d409d297988aefe0d87" category="image-alt">图库信息板</block>
  <block id="e8be13fb11d0c0f2c1636df3abdd55f8" category="list-text">从列表中选择一个FlexVol性能信息板，然后单击页面底部的*添加信息板*按钮。</block>
  <block id="d8c51ab14864984dd9706f3ac5209ea2" category="image-alt">FlexVol性能信息板</block>
  <block id="7cd87be03b0a792d69728ce4e76d2cb9" category="list-text">导入后、打开信息板。在这里、您可以看到包含详细性能数据的各种小工具。添加一个筛选器以查看单个存储系统、然后选择一个存储卷以深入查看其详细信息。</block>
  <block id="3ea3ce29d5241eda0ca46e30885db342" category="image-alt">深入查看存储卷</block>
  <block id="18ae18bb58820bf73dab9f002b1def7e" category="list-text">在此视图中、您可以看到与此存储卷以及此卷上运行的利用率最高且相关的虚拟机相关的各种指标。</block>
  <block id="75fec513a9986ef9ef0005999c8c8d38" category="image-alt">前几个相关VM</block>
  <block id="f0ca3a7f4a4d85ade763dee7b52b6c65" category="list-text">单击利用率最高的虚拟机可深入查看该虚拟机的指标、以查看任何潜在问题。</block>
  <block id="7216ebccde1282a4dc23c19fdc0adbe8" category="image-alt">VM性能指标</block>
  <block id="f2746ecdc7309ada1a89e92a20d973b9" category="section-title">使用Cloud Insights确定资源争用者</block>
  <block id="e9632c9c603a51e2f44d4ec197c2f520" category="paragraph">Cloud Insights的信息板可以轻松隔离对同一存储卷上运行的其他VM产生负面影响的对等VM。</block>
  <block id="806edfc8adb170c04c7d0066d1c9c294" category="example-title">使用"虚拟机延迟排名前几位"信息板隔离资源争用者</block>
  <block id="38ad465076f1aebb5d9d6a145be5c24e" category="list-text">在此示例中，访问*Gallery *中提供的名为*VMware Admin - Where do I have VM Latery?*的信息板</block>
  <block id="6cb14e5b080af4a253d9c9edaeb54d1f" category="image-alt">虚拟机延迟信息板</block>
  <block id="e55b2fc7dda90ec8adce9b50a3add015" category="list-text">接下来，按上一步中创建的*Data Center*标注进行筛选，以查看部分资产。</block>
  <block id="c1b620bf668c4442a9cf57c2f34b7b73" category="image-alt">数据中心标注</block>
  <block id="d2c1b37287c6a7182c216174e6e445ac" category="list-text">此信息板按平均延迟显示排名前10位的虚拟机的列表。从此处单击相关虚拟机以深入了解其详细信息。</block>
  <block id="32f5f5a189e0af63dd0855cd5b200308" category="image-alt">排名前10位的VM</block>
  <block id="c98e0a31b385cacfad40e5f1ba60392e" category="list-text">此时将列出可能引发工作负载争用的VM、并且这些VM可用。深入研究这些VM性能指标、调查任何潜在问题。</block>
  <block id="3075a9c81094d62a0d5bfdc07452b7e4" category="image-alt">工作负载争用</block>
  <block id="6ceeb669d57155d25380727cfe5cb50b" category="section-title">查看Cloud Insights中已利用资源的情况和未充分利用的资源</block>
  <block id="226d7481535cf3aefc2befa5f5a10c37" category="paragraph">通过将VM资源与实际工作负载需求相匹配、可以优化资源利用率、从而节省基础架构和云服务的成本。可以自定义Cloud Insights中的数据、以便轻松显示已利用或未充分利用的VM。</block>
  <block id="4f2b758fb5a1b094e3421c5b15ffebc3" category="example-title">识别适当调整VM规模的机会</block>
  <block id="46e928d02253087e8562d61d23346537" category="list-text">在此示例中，访问*Gallery *中提供的名为*VMware Admin - Where are opportunities to right size？*的信息板</block>
  <block id="fcf2b5ca70eb9c12d93fcd033b9512e8" category="image-alt">规模合适的信息板</block>
  <block id="55830df5963e048385de44153ed05701" category="list-text">首先按集群中的所有ESXi主机进行筛选。然后、您可以按内存和CPU利用率查看前N个和后N个VM的排名。</block>
  <block id="1012e953d276159faefe3c2ae41eed21" category="list-text">表允许根据所选数据列进行排序并提供更多详细信息。</block>
  <block id="96fc83812ddb9a2b4bc184421a47a697" category="image-alt">指标表</block>
  <block id="ac4104ed35a93b20f2ddc3811b1fc791" category="list-text">另一个名为*VMware Admin - Where can I Pastyed Wastere?*的信息板显示已关闭的虚拟机按其容量使用情况进行排序。</block>
  <block id="2c3ae1fd7ece93a9d4fd7b7db5436d5d" category="image-alt">已关闭VM电源</block>
  <block id="b4a3629abf3cfe4ae2c29554ee3762fb" category="section-title">使用查询隔离指标并对其进行排序</block>
  <block id="89232d7df7880c44e9656c898a3c8124" category="paragraph">Cloud Insights捕获的数据量非常全面。度量查询提供了一种功能强大的方法、可通过有用的方式对大量数据进行排序和组织。</block>
  <block id="fe34143764b4ef7dc97bf37142210676" category="example-title">在ONTAP基础知识下查看详细的VMware查询</block>
  <block id="abdd65e76639bcc7776d8fee6ceaad54" category="list-text">导航到*VMware基础知识&gt; ONTAP以访问全面的VMware指标查询。</block>
  <block id="3c8a6a1af294c26bdc986e5e6b2d38f9" category="image-alt">ONTAP Essential—VMware</block>
  <block id="bfb15b8db796b4d0755cd36f3a42921f" category="list-text">在此视图中、您可以使用多个选项在顶部筛选和分组数据。所有数据列均可自定义、并且可以轻松添加其他列。</block>
  <block id="e3ec984cfdaece4a4ec1fe78a332c8c7" category="paragraph">本解决方案旨在作为入门指南、学习如何开始使用NetApp Cloud Insights、并展示此可观察性解决方案可提供的一些强大功能。产品中内置了数百个信息板和指标查询、因此可以轻松地立即开始。完整版本的Cloud Insights可作为30天试用版提供、基本版本可供NetApp客户免费使用。</block>
  <block id="4002d2a1598188a321986ca16bb892fe" category="inline-link">NetApp BlueXP和Cloud Insights登录页面</block>
  <block id="bd39c1ca10a3fc4e08e05dd367fb82d1" category="list-text"><block ref="bd39c1ca10a3fc4e08e05dd367fb82d1" category="inline-link-rx"></block></block>
  <block id="8247c4bb63c59c139f50aae9637c0ebb" category="inline-link">NetApp Cloud Insights文档</block>
  <block id="712949bc37c0797363647e3f913be9cc" category="list-text"><block ref="712949bc37c0797363647e3f913be9cc" category="inline-link-rx"></block></block>
  <block id="cb728ffb8b3772821a11158c26cec1d2" category="list-text">iSCSI VMKernel适配器IP信息</block>
  <block id="b0edcd48e0e929657cd2dc9a64420e58" category="section-title">使用适用于VMware vSphere的ONTAP工具管理块存储</block>
  <block id="24a54e9ebab5967a70c16f29c2001e04" category="paragraph">通过适用于VMware的ONTAP工具、管理员可以直接从vSphere Client中管理NetApp存储。通过ONTAP工具、您可以部署和管理数据存储库、以及配置VVOV数据存储库。
ONTAP工具允许将数据存储库映射到存储功能配置文件、这些配置文件确定了一组存储系统属性。这样便可创建具有特定属性(例如存储性能和QoS)的数据存储库。</block>
  <block id="6dcebeb604c681ebf74c3b7b38c7dc04" category="paragraph">ONTAP工具包括以下组件：</block>
  <block id="e0638e586b5898ffa8c0e59208991e18" category="paragraph">*虚拟存储控制台(VSC)：* VSC包括与vSphere客户端集成的界面、您可以在其中添加存储控制器、配置数据存储库、监控数据存储库的性能以及查看和更新ESXi主机设置。</block>
  <block id="ec93ef8c528aead8ec9970d99b9914d0" category="paragraph">*VASA Provider：*适用于ONTAP的VMware vSphere APIS for Storage AWAREING (VASA) Provider可将有关VMware vSphere所用存储的信息发送到vCenter Server、从而可以配置VMware虚拟卷(VVOl)数据存储库、创建和使用存储功能配置文件、验证合规性以及监控性能。</block>
  <block id="a09fd8551db7fb2026cfc8efe4862a8f" category="paragraph">* Storage Replication Adapter (SRA)：*启用并与VMware Site Recovery Manager (SRM)结合使用后、SRA有助于在发生故障时恢复vCenter Server数据存储库和虚拟机、从而可以配置受保护站点和恢复站点以实现灾难恢复。</block>
  <block id="19101a1c66612e80411e774ecf1ab39b" category="paragraph">在本解决方案中、我们将演示如何使用适用于VMware vSphere的ONTAP工具配置VMware虚拟卷(VVOl)数据存储库以及在VVOl数据存储库上创建虚拟机。</block>
  <block id="1bbd6c2e8ac48e75bae3d15f6494751e" category="paragraph">在vVol数据存储库中、每个虚拟磁盘都是一个vVol、并成为存储系统上的本机LUN对象。存储系统和vSphere通过VMware API for Storage AWARMIVAIVIANGIVIANGE (VASA)提供程序(随ONTAP工具一起安装)进行集成、从而使存储系统能够识别VM数据并对其进行相应管理。vCenter Client中定义的存储策略用于分配和管理存储资源。</block>
  <block id="de87237500f3d597c647b3ad9c7a9e73" category="inline-link">虚拟卷(Virtual Volumes)与ONTAP</block>
  <block id="e045c1b06a1a2ca3df2b2efcdaeddd22" category="paragraph">有关使用ONTAP的虚拟卷的详细信息、请参见<block ref="78b73080e300ad9c4feda6b67b2ad79e" category="inline-link-rx"></block>。</block>
  <block id="520e3327a5acf8d84deaf45f44a45661" category="paragraph">此解决方案包括以下高级步骤：</block>
  <block id="841de13857d1f7d1837468a733b82244" category="list-text">在ONTAP工具中添加存储系统。</block>
  <block id="eebec2d1b32c4d22f597560afadd33d8" category="list-text">在ONTAP工具中创建存储功能配置文件。</block>
  <block id="e4c6236e8fe2a36759cb1bd7db6731e3" category="list-text">在vSphere客户端中创建VM存储策略。</block>
  <block id="7686062580e0cafa2a49f4792089ff82" category="paragraph">此解决方案使用了以下组件：</block>
  <block id="e91701c614e2d9fc4a39565492176e2c" category="list-text">在ASA上创建的iSCSI SVM、可通过网络连接到ESXi主机。</block>
  <block id="6e2d80ee18d82e249a2dad12c3fffd0a" category="list-text">适用于VMware vSphere 9.13的ONTAP工具(默认情况下、已启用VASA提供程序)。</block>
  <block id="2eefb7064408857c3046806070ad1b74" category="list-text">vSphere 8.0集群(vCenter设备和ESXi主机)。</block>
  <block id="9587808585ba699701aa03bb076f6526" category="section-title">在ONTAP工具中创建一个虚拟卷数据存储库</block>
  <block id="daab724e818dde93567ba19b476997fa" category="paragraph">要在ONTAP工具中创建虚拟卷数据存储库、请完成以下步骤：</block>
  <block id="832b76d7ab7ad3b5c0b2af0a956c640e" category="example-title">将存储系统添加到ONTAP工具。</block>
  <block id="d5f4909f277ae787c61e9f3dee2ab532" category="list-text">从vSphere Client的主菜单中选择NetApp ONTAP工具、以访问此工具。</block>
  <block id="2d850ea1ba10f3076d0b3b06385a53bb" category="image-alt">NetApp ONTAP工具</block>
  <block id="3b3e3f87686d9d629e8cd1f2b8816101" category="list-text">在ONTAP工具中，从左侧菜单中选择*Storage Systems*，然后按*Add*。</block>
  <block id="f8adfbadb1a69154007f8504337443be" category="list-text">填写IP地址、存储系统凭据和端口号。单击*Add*以启动发现过程。</block>
  <block id="038529c38a2ed7358a9b88e3384f2cc6" category="example-title">在ONTAP工具中创建存储功能配置文件</block>
  <block id="696330936092c54225660696790137b7" category="paragraph">存储功能配置文件介绍了存储阵列或存储系统提供的功能。它们包括服务质量定义、用于选择符合配置文件中定义的参数的存储系统。</block>
  <block id="4e5c2e3794b2111528e663582db055e9" category="paragraph">要在ONTAP工具中创建存储功能配置文件、请完成以下步骤：</block>
  <block id="dd8bf4538bebf71664e5132bd4d0f4c3" category="list-text">在ONTAP工具中，从左侧菜单中选择*存储功能配置文件*，然后按*Create*。</block>
  <block id="5671a8cbfb87337b09f7c0b3f03c48ec" category="image-alt">存储功能配置文件</block>
  <block id="4b012b40badfec60adbdef906900b4cf" category="list-text">在*创建存储功能配置文件*向导中，提供配置文件的名称和问题描述，然后单击*下一步*。</block>
  <block id="069aa512244afec15b9a9f17b278f68b" category="image-alt">为SCP添加名称</block>
  <block id="ba6a510873306304c379b876b552c9c0" category="list-text">选择平台类型，并将存储系统设置为纯闪存SAN阵列*A对称*为false。</block>
  <block id="12ae59328b3a45d4229e256c0ce1c608" category="image-alt">SCP平台</block>
  <block id="4f1e1765e4715bba3e1ca66ec8ab0df5" category="list-text">接下来，选择协议选项或*ANY*以允许所有可能的协议。单击 * 下一步 * 继续。</block>
  <block id="cc4291590d0523c4137086227ea5ec07" category="image-alt">SCP协议</block>
  <block id="4138e7b56f475eb2dfa9fe79922b60e1" category="list-text">"*性能"页面允许以允许的最小和最大IOPS的形式设置服务质量。</block>
  <block id="93b5dfc333754dd947693471f8293acc" category="image-alt">适用于SCP的QoS</block>
  <block id="34596ead953ef7fb5d62f68e116a4ce3" category="list-text">完成*存储属性*页面、根据需要选择存储效率、空间预留、加密和任何分层策略。</block>
  <block id="c4e4c47ba78659d618a07d39548a1879" category="image-alt">SCP的属性</block>
  <block id="d71e4b14e1f43b180cef205a454a167b" category="list-text">最后、查看摘要、然后单击完成以创建配置文件。</block>
  <block id="6944ea0c5596a5b67b5c6148f4a8b9b6" category="image-alt">SCP摘要</block>
  <block id="9d267f04429d3918125908adfcd20fda" category="list-text">在ONTAP工具中选择*Overview*，然后从*Getting Started*选项卡中单击*ProVision *以启动向导。</block>
  <block id="1f6f809e91a1dddbea9dc3be70617c6f" category="image-alt">配置数据存储库</block>
  <block id="ba9d26cf190919acc1276a78dccda646" category="list-text">在新建数据存储库向导的*常规*页面上、选择vSphere数据中心或集群目标。选择*vols*作为dastatore类型，填写数据存储库的名称，然后选择协议。</block>
  <block id="75ad77f4d0c941bb456f644f4918e260" category="image-alt">常规页面</block>
  <block id="090d00cbb454237bf791d16aa0e9e134" category="list-text">在*存储系统*页面上选择存储功能配置文件、存储系统和SVM。单击“*下一步*”继续。</block>
  <block id="f31303ddb8ada38aed08c2bb8f9d8e6c" category="image-alt">存储系统</block>
  <block id="411d8326dfe10ae9eb2097abefc2abff" category="list-text">在*Storage attributes*页面上，选择为数据存储库创建新卷，然后填写要创建的卷的存储属性。单击*Add*(添加)创建卷，然后单击*Next*(下一步)继续。</block>
  <block id="03804e006add62cab43571db2a148f6e" category="image-alt">存储属性</block>
  <block id="80859b3ea74c1d68f3b10cf0ad40cf47" category="list-text">最后、查看此摘要并单击*完成*以启动VVOV数据存储库创建过程。</block>
  <block id="89928728c928e719ef9ec5d911a3fddc" category="image-alt">摘要页面</block>
  <block id="b6d4de66d6654ed5854ca42453e0746f" category="section-title">在vSphere客户端中创建VM存储策略</block>
  <block id="bbcc03a3ee049c260554c7329298027b" category="paragraph">VM存储策略是一组规则和要求、用于定义应如何存储和管理虚拟机(VM)数据。它可为特定虚拟机指定所需的存储特征、例如性能、可用性和数据服务。</block>
  <block id="7ed75bf324683c1f6f30752a8fed5766" category="paragraph">在这种情况下、此任务需要创建VM存储策略、以指定将在VVOV数据存储库上生成虚拟机、并使用先前生成的存储功能配置文件建立一对一映射。</block>
  <block id="9220ff986a2bca304914629226baf861" category="example-title">创建VM存储策略</block>
  <block id="db2198caaa97c07dc525fc6d2e2edd3b" category="paragraph">要创建VM存储策略、请完成以下步骤：</block>
  <block id="2e29f2c7d8fae9195eb10c4ca0f5b7b0" category="list-text">从vSphere Client主菜单中选择*策略和配置文件*。</block>
  <block id="9f7c806d045fb273f3e02678b95b389d" category="image-alt">策略和配置文件</block>
  <block id="cb5e7966fffbe0621b33db7b159c3dec" category="list-text">在*Create VM Storage Policy*向导中，首先填写策略的名称和问题描述，然后单击*Next*继续。</block>
  <block id="3af4c44533b1b5eeecca8cecab3a1879" category="image-alt">VM存储策略向导</block>
  <block id="038d9db14628ed35234fa93b63a7fd86" category="list-text">在“*策略结构*”页面上，选择为NetApp集群模式Data ONTAP vVol存储启用规则，然后单击“*下一步*”。</block>
  <block id="3152d6c9ba8fc6928fcae0b7621f0069" category="image-alt">策略结构</block>
  <block id="2274f24993df83732f1407dbdeecf4fa" category="list-text">在所选策略结构的下一页上、选择用于描述要在VM存储策略中使用的存储系统的存储功能配置文件。单击“*下一步*”继续。</block>
  <block id="dc3a5ef3baf3a02eaabb864d549e06eb" category="list-text">在*存储兼容性*页面上、查看与此策略匹配的vSAN数据存储库列表、然后单击*下一步*。</block>
  <block id="5b00219114edf292e715151c839b0d81" category="list-text">最后，查看要实施的策略，然后单击*完成*以创建策略。</block>
  <block id="bcb7057e08fb621e596ec7aa7a861c8e" category="example-title">在VVOV数据存储库上创建虚拟机</block>
  <block id="cf2aacb88553bd89a9c1c5011398cb0a" category="paragraph">最后一步是使用先前创建的VM存储策略创建虚拟机：</block>
  <block id="9df0c83a03049efad7901c94c4aae28b" category="list-text">在“*新建虚拟机*”向导中，选择“*创建新虚拟机*”，然后选择“下一步*”继续。</block>
  <block id="b635fd95f8310efc5be45d39cba5f145" category="image-alt">新虚拟机</block>
  <block id="09e35a5a9842a1c413f83a41de7be578" category="list-text">填写名称并选择虚拟机的位置，然后单击*Next*。</block>
  <block id="4199cf0edbc820cd72fbebec3a441a3b" category="list-text">在“*选择计算资源*”页面上，选择一个目标，然后单击“*下一步*”。</block>
  <block id="0940322c0507debe9e1e71030412fa50" category="image-alt">计算资源</block>
  <block id="3b44d5029e3304396499cc1d12f36fd3" category="list-text">在*选择存储*页面上、选择虚拟机存储策略以及要作为虚拟机目标的Vvol数据存储库。单击“*下一步*”。</block>
  <block id="4f7f2e3248a9d26943428156fff11bbc" category="image-alt">选择存储</block>
  <block id="8b242d8a17c3fd0b48fae9acc8161b70" category="list-text">在*选择兼容性*页面上、选择虚拟机要兼容的vSphere版本。</block>
  <block id="e19367f5e821a97a41c058bb5c964471" category="list-text">为新VM选择子操作系统系列和版本，然后单击*Next*。</block>
  <block id="f80d15addf814f6098d34d85c75c1f72" category="list-text">填写*自定义硬件*页面。请注意、可以为每个硬盘(VMDK文件)选择单独的VM存储策略。</block>
  <block id="c40ff83c36de91056b6e541e69fe61a5" category="list-text">最后，查看摘要页面，然后单击*Complete*创建VM。</block>
  <block id="c502713a5af3ca9a03e4b7aafb1645d8" category="paragraph">总之、NetApp ONTAP工具可以自动在ONTAP存储系统上创建VVOV数据存储库。存储功能配置文件不仅可以定义要用于创建数据存储库的存储系统、还可以规定可在单个VMDK上实施的QoS策略。vvol提供了一个简化的存储管理模式、并且NetApp与VMware紧密集成、使其成为一个实用的解决方案、可用于对虚拟化环境进行精简、高效和精细的控制。</block>
  <block id="54a8345ff2a6a2f233047593d2765803" category="section-title">本文档的目的</block>
  <block id="9a32f2d98aeba4bf598e4940144de4c4" category="paragraph">此解决方案包含VMware和NetApp的创新技术。</block>
  <block id="03bd7c3d3ef7840ecb1250d4983b17fd" category="section-title">VMware vSphere 8.0</block>
  <block id="9841ed75ab22fd29222cc33f714541c3" category="paragraph">VMware vSphere是一个虚拟化平台、可将物理资源转换为计算、网络和存储池、以满足客户的工作负载和应用程序要求。VMware vSphere的主要组件包括：</block>
  <block id="64537e2ebc650d067b68b7d240662c95" category="list-text">*ESXi－VMware的虚拟机管理程序，支持对计算处理器、内存、网络和其他资源进行抽象化，并使其可供虚拟机和容器工作负载使用。</block>
  <block id="94333db8a33d595c686766f37d79e5ae" category="list-text">*vCento*- VMware vCenter是一个集中式管理平台，用于在虚拟基础架构中与计算资源、网络和存储进行交互。vCenter在简化虚拟化基础架构的管理方面发挥着至关重要的作用。</block>
  <block id="8e612ce8ec20411604144a698f6e8174" category="section-title">vSphere 8.0中的新增改进功能</block>
  <block id="529f2b05361a238abb764347f39d1638" category="paragraph">vSphere 8.0引入了一些新的改进功能、包括但不限于：</block>
  <block id="e6a6b9633b6fefc8ad4b1c8224743eb2" category="paragraph">*可扩展性*- vSphere 8.0支持最新的Intel和AMD CPU、并扩展了vGPU设备、ESXi主机、每个集群的VM以及VM DirectPath I/O设备的限制。</block>
  <block id="f4a01f326e8f0e8180e53acb21aae318" category="paragraph">*分布式服务引擎*-通过NSX将网络负载分流到数据处理单元(DPU)。</block>
  <block id="64983840985e2963491f0ed650865817" category="paragraph">*增强的设备效率*- vSphere 8.0通过设备组和设备虚拟化扩展(DVX)等功能增强设备管理功能。</block>
  <block id="9ff7e2b078fb57063340ff210d67a0c6" category="paragraph">*提高安全性*-包含SSH超时和TPM配置策略可增强安全框架。</block>
  <block id="3b0f92038b718d9310b4822e190f2ea9" category="paragraph">*与混合云服务集成*—此功能有助于在内部工作负载和云工作负载之间实现无缝过渡。</block>
  <block id="d9c04e38b95a4f64f99b1e706b74e215" category="paragraph">*集成的Kubernetes Runtime *—包括Tanzu后、vSphere 8.0可简化容器流程编排。</block>
  <block id="02ad284966c2817bfc9c5d9210bb5af6" category="inline-link">vSphere 8中的新增功能</block>
  <block id="d622652399002a7028cbce65d4dbda27" category="paragraph">虚拟卷是一种简化的存储管理方法、在某些使用情形中更受欢迎。</block>
  <block id="393f36eae2cbaf3ab2126633ce399282" category="inline-link">《卷入门指南》</block>
  <block id="3082269ca4479ee6e0cd860efa66ceb4" category="paragraph">有关卷的详细信息、请参见<block ref="a8334a213edf76a5b910674ca75c27b3" category="inline-link-rx"></block>。</block>
  <block id="b99f0070115778a9954997b3de522b2e" category="section-title">基于网络结构的NVMe</block>
  <block id="43950dd41102e5e8a15f877653a9e09d" category="paragraph">随着vSphere 8.0的发布、现在可以端到端支持NVMe、并通过NVMe-TCP和NVMe-FC全面支持vvol。</block>
  <block id="2030c545b2436e68ba36ace452ef25e7" category="inline-link">关于VMware NVMe存储</block>
  <block id="375a126c4b3d56322ba015088325b3e5" category="paragraph">有关将NVMe与vSphere结合使用的详细信息、请参见<block ref="9532172a9c3033de5b62728c47a952ff" category="inline-link-rx"></block> 在vSphere存储文档中。</block>
  <block id="d184b31af6f77787f123e1490f8bdaef" category="section-title">基本ONTAP功能</block>
  <block id="d2f7faa3899d8a24f761e8cdfe2d5694" category="paragraph">NetApp Snapshot副本：虚拟机或数据存储库的Snapshot副本、可确保不会对Snapshot的创建或利用率造成性能影响。这些副本可用作VM的恢复点或简单的数据保护。这些基于阵列的快照与VMware (一致性)快照不同。生成ONTAP Snapshot副本的最直接方法是通过适用于VMware vSphere的SnapCenter插件来备份VM和数据存储库。</block>
  <block id="e5bb2fdaa0fc160b22d56461bbf309f7" category="list-text">*存储效率*—ONTAP提供实时和后台重复数据删除和数据压缩、零块重复数据删除以及数据缩减。</block>
  <block id="efc02b9a22e4ded7cdb1f5fb2fef60c2" category="list-text">*卷和LUN移动*—允许在ONTAP集群中无中断移动支持vSphere数据存储库和vvol的卷和LUN、以平衡性能和容量、或者支持无中断维护和升级。</block>
  <block id="2a7760a5435f9c53e3d1a69e3bbd36a1" category="list-text">*重新定位卷和LUN*—ONTAP允许在ONTAP集群中无中断移动托管vSphere数据存储库和vvol的卷和LUN。这有助于平衡性能和容量、并实现无中断升级。</block>
  <block id="39a6de1a8d0b8e45671373fc1ac2223b" category="list-text">*服务质量*—QoS是一项用于管理单个LUN、卷或文件上的性能的功能。它可用于限制主动虚拟机或确保关键虚拟机获得足够的性能资源。</block>
  <block id="d5e0f0343baef4b3d46ccd87280d3459" category="list-text">*加密*- NetApp卷加密和NetApp聚合加密。这些选项提供了一种基于软件的简单方法来加密空闲数据、从而确保对其进行保护。</block>
  <block id="c72e717c7df845a4d93f58a32d003ac9" category="list-text">*网络结构池*-此功能可将不常访问的数据分层到单独的对象存储中、从而释放宝贵的闪存存储空间。通过在块级别运行、IT可以高效地识别和分层较冷的数据、从而帮助优化存储资源并降低成本。</block>
  <block id="ce127763899e8833d207f31226eb071a" category="list-text">*自动化*—通过利用REST API实现自动化、并利用Ans负责 无缝配置ONTAP系统管理的ONTAP模块、简化存储和数据管理任务。通过使用解决方案模块、您可以高效管理ONTAP系统的配置。这些强大的工具相结合、可以简化工作流并增强存储基础架构的整体管理。</block>
  <block id="6841bfafd725d63c1bd53993fe381d15" category="section-title">ONTAP灾难恢复功能</block>
  <block id="4c5baf5b137970028bdbc904a1ac6f21" category="paragraph">NetApp ONTAP可为VMware环境提供强大的灾难恢复解决方案。这些解决方案可在主存储系统和二级存储系统之间利用SnapMirror复制技术、以便在发生故障时进行故障转移和快速恢复。</block>
  <block id="d6a04759bb83a2b3f36c8903066888c9" category="paragraph">* Storage Replication Adapter：*
NetApp存储复制适配器(SRA)是一个软件组件、可在NetApp存储系统和VMware Site Recovery Manager (SRM)之间实现集成。它有助于跨NetApp存储阵列复制虚拟机(VM)数据、从而提供强大的数据保护和灾难恢复功能。SRA使用SnapMirror和SnapVault在不同的存储系统或地理位置之间复制VM数据。</block>
  <block id="d4efaaf21b19fd388049bcae1db91d93" category="paragraph">该适配器使用SnapMirror技术在Storage Virtual Machine (SVM)级别提供异步复制、并扩展了对SAN存储环境(iSCSI和FC)中VMFS以及NAS存储环境中NFS的支持。</block>
  <block id="5bfdcc1715b754fa018046d341308eec" category="paragraph">NetApp SRA作为适用于VMware vSphere的ONTAP工具的一部分安装。</block>
  <block id="db1d3fdba49d298df76a2d99ffa50d09" category="image-alt">VMware ASA软件3</block>
  <block id="0a0e655ee9ba6467857ebf014a268f29" category="inline-link">采用NetApp ONTAP的VMware Site Recovery Manager</block>
  <block id="8fe208cc8670321620cd27e0b5c96d39" category="paragraph">有关适用于SRM的NetApp存储复制适配器的信息、请参见<block ref="5596199b788c6dc8143867351d6427d8" category="inline-link-rx"></block>。</block>
  <block id="6a711152e82334a61301f9fbd9c0cb43" category="paragraph">*SnapMirror业务连续性：*
SnapMirror是一种NetApp数据复制技术、可在存储系统之间同步复制数据。它支持在不同位置创建多个数据副本、从而能够在发生灾难或数据丢失事件时恢复数据。SnapMirror可以灵活地调整复制频率、并允许为数据创建时间点副本、以用于备份和恢复。SM-BC会在一致性组级别复制数据。</block>
  <block id="e5bfd78654e27a857e1ac800d4573bb3" category="image-alt">VMware ASA软件4</block>
  <block id="e8fee93c1b0b14d12f18e89fb97fb018" category="inline-link">业务连续性概述</block>
  <block id="de10e198e9df805115a318fce79d36b0" category="paragraph">有关详细信息、请参见SnapMirror<block ref="d4d6485e541ce14ea14331a44daa839f" category="inline-link-rx"></block>。</block>
  <block id="633de0593a9c87ebe4854522b261b0a3" category="paragraph">* NetApp MetroCluster：*
NetApp MetroCluster是一款高可用性和灾难恢复解决方案、可在两个地理位置分散的NetApp存储系统之间提供同步数据复制。它旨在确保在发生站点级故障时数据持续可用并得到保护。</block>
  <block id="a5ae36cfd290a200f11b4b66214250d7" category="paragraph">MetroCluster使用SyncMirror同步复制RAID级别以上的数据。SyncMirror旨在在同步模式和异步模式之间高效过渡。这样、当二级站点暂时无法访问时、主存储集群可以继续在未复制状态下运行。连接恢复后、SyncMirror还会复制回RPO = 0状态。</block>
  <block id="55339be71f37de84fde34c4e032dea6a" category="paragraph">MetroCluster可以通过基于IP的网络或使用光纤通道运行。</block>
  <block id="dd9f01be175a817c127d63671d5d0fe7" category="image-alt">VMware ASA image5</block>
  <block id="8038555614266817991a5358a4145b3d" category="inline-link">MetroCluster文档站点</block>
  <block id="ee834da0f7956e1a26f6eec4763120cf" category="paragraph">有关MetroCluster架构和配置的详细信息、请参见<block ref="84e82627bbfc711a9dc35376337c9e57" category="inline-link-rx"></block>。</block>
  <block id="535a67b9b2bb2a5a00f0acaff53e5dec" category="section-title">ONTAP One许可模式</block>
  <block id="43d9c223b7adb570d0f6ee8d3969bfd6" category="paragraph">ONTAP One是一种全面的许可模式、无需额外的许可证即可访问ONTAP的所有功能。其中包括数据保护、灾难恢复、高可用性、云集成、存储效率、 性能和安全性。拥有NetApp存储系统的闪存、核心+数据保护或高级版许可的客户有权获得ONTAP One许可、以确保他们可以最大限度地利用其存储系统。</block>
  <block id="41cc51d6cdc1088a54afe9b6c3217157" category="paragraph">ONTAP One许可包括以下所有功能：</block>
  <block id="ad6c914fa2bef8e47e9dae58e7d37841" category="paragraph">*NVMeoF*—支持对NVMe/FC和NVMe/TCP前端客户端IO使用基于网络结构的NVMe。</block>
  <block id="5c5bd77e7db6c742b797f40ed2d473df" category="paragraph">*FlexCLONE *—支持基于快照快速创建节省空间的数据克隆。</block>
  <block id="0b0095efb37974dd9a6b26eb57b6bdf0" category="paragraph">*S3*—为前端客户端IO启用S3协议。</block>
  <block id="0c348dcfd23cce5eb4fb92e9e3f2020c" category="paragraph">* SnapRestore *—支持从快照快速恢复数据。</block>
  <block id="bf6fc59f4d6ebcf71801348f7f96ad73" category="paragraph">*自动防病毒保护*-在检测到异常文件系统活动时自动保护NAS文件共享。</block>
  <block id="8c88e96427141696fa81c63005ba6ee8" category="paragraph">*多租户密钥管理器*-可为系统上的不同租户提供多个密钥管理器。</block>
  <block id="2008adc53f247314ce69e51fb7647baf" category="paragraph">* SnapLock *–保护系统上的数据免受修改、删除或损坏。</block>
  <block id="345a51e59f2b4e19d980a8bf76b76d30" category="paragraph">*SnapMirror Cloud*—支持将系统卷复制到对象目标。</block>
  <block id="1c0c63c2c82234d5940b699302df5883" category="paragraph">*S3 SnapMirror–支持将ONTAP S3对象复制到与S3兼容的备用目标。</block>
  <block id="91b792506a81ccdd15668dc7d0495ee9" category="section-title">NetApp全闪存SAN阵列</block>
  <block id="80460afcca80efb046a2a1c564be9c0b" category="paragraph">NetApp全闪存SAN阵列(ASA)是一款高性能存储解决方案、专为满足现代数据中心的苛刻要求而设计。它将闪存存储的速度和可靠性与NetApp的高级数据管理功能相结合、可提供卓越的性能、可扩展性和数据保护。</block>
  <block id="adca3f4fcfa12331b32a3ee4688bc4f9" category="paragraph">ASA系列由A系列和C系列型号组成。</block>
  <block id="b880b580d3e21a1edda7f3cac49347c8" category="paragraph">NetApp A系列全NVMe闪存阵列专为高性能工作负载而设计、可提供超低延迟和高故障恢复能力、使其适合任务关键型应用程序。</block>
  <block id="dd03042bb42cf1ac7be9d608edd7acd0" category="image-alt">VMware ASA image1</block>
  <block id="6cfe69d2b4334b5e53ee2334175f7b2f" category="paragraph">C系列QLC闪存阵列适用于容量更大的用例、可提供闪存速度和混合闪存的经济效益。</block>
  <block id="ec8eb591a6ab4839358ee1e32380081b" category="image-alt">VMware ASA image2</block>
  <block id="649edef6237440c53363f5d8764fdea3" category="inline-link">NetApp ASA登录页面</block>
  <block id="61e34dd4d0d0f40f87db7ef549f9d178" category="paragraph">有关详细信息、请参见<block ref="29da109c026a61b0a781439b91c0c69b" category="inline-link-rx"></block>。</block>
  <block id="caf94c6309f16f7333b1548e4053ea03" category="section-title">NetApp ASA功能</block>
  <block id="4f3cb8b680fee6bb64689801033a808e" category="paragraph">NetApp全闪存SAN阵列具有以下功能：</block>
  <block id="037e6fb1e2b4665b274b4085e6ef1fee" category="paragraph">*性能*—全闪存SAN阵列利用固态驱动器(SSD)和端到端NVMe架构、提供快如闪电的性能、显著缩短延迟并缩短应用程序响应时间。它可提供稳定一致的高IOPS和低延迟、因此适合数据库、虚拟化和分析等对延迟敏感的工作负载。</block>
  <block id="f465c128b21f4bc1c758a58569d06590" category="paragraph">*可扩展性*—NetApp全闪存SAN阵列采用横向扩展架构构建、支持企业根据需求增长无缝扩展存储基础架构。由于能够添加更多存储节点、企业可以无中断地扩展容量和性能、从而确保其存储能够满足不断增长的数据需求。</block>
  <block id="fa4f71a03be5cf7b3faf37358b6e150f" category="paragraph">*数据管理*—NetApp的Data ONTAP操作系统为全闪存SAN阵列提供支持，提供了一套全面的数据管理功能。其中包括精简配置、重复数据删除、数据压缩和数据缩减、可优化存储利用率并降低成本。快照、复制和加密等高级数据保护功能可确保所存储数据的完整性和安全性。</block>
  <block id="e7d330a0531a3b82fb3119309b79d054" category="paragraph">*集成和灵活性*—全闪存SAN阵列可与NetApp更广泛的生态系统集成、实现与其他NetApp存储解决方案的无缝集成、例如与NetApp Cloud Volumes ONTAP的混合云部署。它还支持光纤通道(Fibre Channel、FC)和iSCSI等行业标准协议、从而能够轻松集成到现有SAN基础架构中。</block>
  <block id="8d8938cecbc71549372a4cf580437656" category="paragraph">*分析和自动化*—包括NetApp Cloud Insights在内的NetApp管理软件提供全面的监控、分析和自动化功能。管理员可以利用这些工具深入了解其存储环境、优化性能并自动执行日常任务、从而简化存储管理并提高运营效率。</block>
  <block id="08e91c29da50d2f2d3960a416802f189" category="paragraph">*数据保护和业务连续性*-全闪存SAN阵列提供内置的数据保护功能，如时间点快照、复制和灾难恢复功能。这些功能可确保数据可用性、并有助于在发生数据丢失或系统故障时快速恢复。</block>
  <block id="d80270670ed405ef2a10edf12698d18b" category="section-title">协议支持</block>
  <block id="7e5a8ab97dc1fa49d3858090a5abf1da" category="paragraph">ASA支持所有标准SAN协议、包括iSCSI、光纤通道(FC)、以太网光纤通道(FCoE)和基于网络结构的NVMe。</block>
  <block id="fa24124b3cb03b615d07b769fdd179c2" category="paragraph">*iSCSI*- NetApp ASA为iSCSI提供强大的支持，允许通过IP网络对存储设备进行块级访问。它可以与iSCSI启动程序无缝集成、从而高效地配置和管理iSCSI LUN。ONTAP的高级功能、例如多路径、CHAP身份验证和AUA支持。</block>
  <block id="cf4ed93aaa370c18af001a4e8610e3c8" category="paragraph">有关iSCSI配置的设计指导，请参阅。</block>
  <block id="4cfd27c77f3513836af8254061b00e3f" category="paragraph">*光纤通道*- NetApp ASA为光纤通道(FC)提供全面支持，光纤通道(FC)是一种常用于存储区域网络(Storage Area Network, SANS )的高速网络技术。ONTAP可与FC基础架构无缝集成、提供对存储设备的可靠高效的块级访问。它提供分区、多路径和网络结构登录(FLOGI)等功能、可优化性能、增强安全性并确保在FC环境中实现无缝连接。</block>
  <block id="7811e339fa109f4afb516cd86de358b3" category="inline-link">SAN配置参考文档</block>
  <block id="1f9feb4d8680fedbc7f376728c072ab4" category="paragraph">有关光纤通道配置的设计指导、请参见<block ref="2cbd9a40d105bcd02390449358010ef2" category="inline-link-rx"></block>。</block>
  <block id="784d99bae87f54d11371469fb7cf2c84" category="paragraph">*基于网络结构的NVMe*—NetApp ONTAP和ASA支持基于网络结构的NVMe。NVMe/FC支持通过光纤通道基础架构使用NVMe存储设备、并通过存储IP网络使用NVMe/TCP。</block>
  <block id="65f6134c6052e5dc8d002b6876d81208" category="inline-link">NVMe配置、支持和限制</block>
  <block id="db91e64f3d6cb64644b9b16d5f8c60af" category="paragraph">有关NVMe的设计指导、请参见<block ref="7aabaf46057cd03af39286b9b532db22" category="inline-link-rx"></block>。</block>
  <block id="178c86f93824be46b8e2d9dafeeb1065" category="section-title">双主动技术</block>
  <block id="738d7e27df95928f52aea1b440ee6f2a" category="paragraph">NetApp纯闪存SAN阵列支持通过两个控制器的主动-主动路径、主机操作系统无需等待某个主动路径出现故障、即可激活备用路径。这意味着、主机可以利用所有控制器上的所有可用路径、从而确保无论系统处于稳定状态还是正在执行控制器故障转移操作、活动路径始终存在。</block>
  <block id="bf17987ce5c6c55043fe723f383e843a" category="paragraph">此外、NetApp ASA还提供了一项显著提高SAN故障转移速度的独特功能。每个控制器都会将基本LUN元数据持续复制到其配对系统。因此、每个控制器都可以在其配对系统突然发生故障时接管数据服务职责。之所以能够做到这一点、是因为控制器已经拥有必要的信息、可以开始利用以前由故障控制器管理的驱动器。</block>
  <block id="6e4d536d45017f958ad5eac15a060047" category="paragraph">使用主动-主动路径时、计划内和计划外接管的IO恢复时间均为2-3秒。</block>
  <block id="37cfe5c8aad02d39e468f703a189ea35" category="inline-link">TR-4968：《NetApp纯SAS阵列—NetApp ASA的数据可用性和完整性》</block>
  <block id="eeeb2acfd6cc2f2dddf45f67fc56660d" category="paragraph">有关详细信息，请参见<block ref="13d62dd0c3e4c67d485585648ace40b6" category="inline-link-rx"></block>。</block>
  <block id="ee0a719c435c7e83e85b55eb38fd6455" category="section-title">存储担保</block>
  <block id="7913e2236b6a2afc9c3757e4c16fc468" category="paragraph">NetApp为NetApp全闪存SAN阵列提供了一组独特的存储保障。其独特优势包括：</block>
  <block id="65f24f4e8a9de149497c3016b96c21cc" category="paragraph">*存储效率担保：*通过存储效率担保实现高性能、同时最大程度地降低存储成本。SAN工作负载的比例为4：1。</block>
  <block id="940875a1f7485ef2f5eecde6067e6252" category="paragraph">* 6个九(99.9999%)数据可用性担保：*保证每年针对计划外停机超过31.56秒进行补救。</block>
  <block id="365b3544f25368e01b2b7adda9055c88" category="paragraph">*勒索软件恢复担保：*在发生勒索软件攻击时保证数据恢复。</block>
  <block id="54d73d7aa0fff8db0e4d25e8f2d657a3" category="inline-link">NetApp ASA产品门户</block>
  <block id="4345a364f4ce2fe4f2a1e2403d861ece" category="paragraph">请参见<block ref="2385ec03bab5d626a59c1eddaeed148f" category="inline-link-rx"></block> 有关详细信息 ...</block>
  <block id="935a62ca273c2635c72bcb9ff6c93b7a" category="section-title">适用于VMware vSphere的NetApp插件</block>
  <block id="a8ede36d4e70103a03b04a67027bf3a5" category="paragraph">NetApp存储服务可通过使用以下插件与VMware vSphere紧密集成：</block>
  <block id="e37a9ce9ba1b9f128287af3bf8300997" category="section-title">适用于 VMware vSphere 的 ONTAP 工具</block>
  <block id="4fb37daad8c8ed0a2c9251ea260e83f8" category="paragraph">适用于VMware vSphere的SnapCenter插件(SCV)是NetApp推出的一款软件解决方案、可为VMware vSphere环境提供全面的数据保护。它旨在简化和简化虚拟机(VM)和数据存储库的保护和管理过程。</block>
  <block id="c055a5ab971bbf65c5453f2a4dd8cf33" category="paragraph">适用于VMware vSphere的SnapCenter插件通过与vSphere客户端集成的统一界面提供以下功能：</block>
  <block id="3d225ac03c53c3e44e92d83f9151204a" category="paragraph">*基于策略的快照*- SnapCenter允许您定义策略、用于在VMware vSphere中创建和管理虚拟机(VM)的应用程序一致的快照。</block>
  <block id="9be3457d6c59a16e38059b99b7ddfc52" category="paragraph">*自动化*-基于定义的策略自动创建和管理快照有助于确保一致高效的数据保护。</block>
  <block id="135fad260d320d18581fdeb949dcf32a" category="paragraph">*虚拟机级别保护*-虚拟机级别的精细保护可高效管理和恢复各个虚拟机。</block>
  <block id="112eabc4251a474c66add9addcb10977" category="paragraph">*存储效率功能*—与NetApp存储技术集成，可为快照提供重复数据删除和数据压缩等存储效率功能，从而最大程度地降低存储需求。</block>
  <block id="63ed5102f407af8ed9f05b2f5ea2e1f3" category="paragraph">SnapCenter插件可在NetApp存储阵列上协调虚拟机静音以及基于硬件的快照。SnapMirror技术可用于将备份副本复制到二级存储系统、包括云中的存储系统。</block>
  <block id="609c561339999562beedaf58644c3b92" category="paragraph">有关详细信息，请参见<block ref="fd09d840cdc38c5c49b0c677f2a8e284" category="inline-link-rx"></block>。</block>
  <block id="44e57e00f55c3c7bc1288367a36e3504" category="paragraph">BlueXP集成支持3-2-1备份策略、将数据副本扩展到云中的对象存储。</block>
  <block id="7b74c6344c00414d3cdec5caa25b8c7a" category="paragraph">NetApp Cloud Insights可简化对内部和云基础架构的观察、并提供分析和故障排除功能来帮助解决复杂问题。Cloud Insights的工作方式是从数据中心环境中收集数据并将这些数据发送到云。这可通过本地安装的软件(称为采集单元)以及为数据中心中的资产启用特定收集器来实现。</block>
  <block id="2ebcc887856b1f0f8e07b2ae22a11dc3" category="paragraph">Cloud Insights中的资产可以通过标注进行标记、以便对数据进行组织和分类。可以使用多种小工具创建信息板以显示数据、还可以为详细的数据表格视图创建指标查询。</block>
  <block id="bbade6161059fb94b024211369b13b58" category="paragraph">Cloud Insights附带了大量现成的信息板、可帮助您精确确定特定类型的问题区域和数据类别。</block>
  <block id="4d63c006e0ffbbadda31cd41a6921f06" category="paragraph">Cloud Insights是一种异构工具、用于从多种设备收集数据。但是、有一个称为ONTAP基础知识的模板库、可帮助NetApp客户快速入门。</block>
  <block id="e0791a5c99e2886539d9c01bfee4917d" category="paragraph">有关如何开始使用Cloud Insights的详细信息、请参见<block ref="b9eb60569e2d6109a82e16fb5747b35d" category="inline-link-rx"></block>。</block>
  <block id="dee4651850517b27e87a0b006b7111c9" category="paragraph">有关设置SnapCenter 和复制数据的分步说明示例、请参见<block ref="2d82442b3e041f62eb7d102ec181d708" category="inline-link-rx"></block></block>
  <block id="2e24e26a7e2a9fde1a37e5b98f26e8d1" category="sidebar">VMware和NetApp：更好地合作</block>
  <block id="51aa9408fdae3216c11294366028fae6" category="sidebar">为什么选择VMware和NetApp？</block>
  <block id="a8ef5ee41591abea2e70721721e48dfd" category="sidebar">客户案例</block>
  <block id="c5fba67fe93c8d014f877258df805278" category="sidebar">VMware Explore中的NetApp会话</block>
  <block id="312acc68148fa022a1a2433045ac2909" category="sidebar">NetApp TV VMware会话</block>
  <block id="7ce9aa2e37f5d6f229413a5ac6836381" category="inline-link-macro">接下来：使用Jarvis、BlueXP Copy and Sync和Nemo Overview构建虚拟助手</block>
  <block id="4a03ee30ef4da835305c8534548e6347" category="paragraph"><block ref="4a03ee30ef4da835305c8534548e6347" category="inline-link-macro-rx"></block></block>
  <block id="9515e6ca96537d18f6a47819aa47cc22" category="list-text"><block ref="9515e6ca96537d18f6a47819aa47cc22" category="inline-link-macro-rx"></block></block>
  <block id="3d7129df95acd2cd7bb86d4047c105f8" category="list-text"><block ref="3d7129df95acd2cd7bb86d4047c105f8" category="inline-link-macro-rx"></block></block>
  <block id="b8e6da86588e4fe5d778fc4a343aaa80" category="list-text"><block ref="b8e6da86588e4fe5d778fc4a343aaa80" category="inline-link-macro-rx"></block></block>
  <block id="c95998835114a4e50f348f8c5e5686ed" category="inline-link-macro">NVIDIA BasePD文档</block>
  <block id="b6420553f17ebdab39fa9a1825d57651" category="section-title">管理平台服务器</block>
  <block id="3588242b057ae23fa2aff188226f0df3" category="doc">采用NVIDIA技术的NetApp AI</block>
  <block id="665a75ebe7f2eb08b429734e2cfb1639" category="summary">采用NVIDIA DGX系统的NetApp AI Pod—存储系统设计和大小规划指南</block>
  <block id="0aeeac6e481ccf5fb94ec4f4b60ebe60" category="inline-link-macro">上一页：采用NVIDIA DGX系统的NetApp AI Pod—架构。</block>
  <block id="0e612fc72e44ac3b868669c64baeba1f" category="paragraph"><block ref="0e612fc72e44ac3b868669c64baeba1f" category="inline-link-macro-rx"></block></block>
  <block id="42dc99c097c1b9b9af75ba060788e1f1" category="section-title">存储系统设计</block>
  <block id="a8bbeb39283cabdf232353640b1912a2" category="paragraph">每个AFF A800存储系统使用每个控制器中的四个100 GbE端口进行连接。每个控制器的两个端口用于从DGX系统访问工作负载数据、每个控制器的两个端口配置为LACP接口组、以支持从管理平台服务器访问集群管理项目和用户主目录。存储系统的所有数据访问均通过NFS提供、其中一个Storage Virtual Machine (SVM)专用于AI工作负载访问、另一个SVM专用于集群管理用途。</block>
  <block id="67004abc3c020854d6f0ce5c0303d67e" category="paragraph">工作负载SVM总共配置了四个逻辑接口(Logical Interface、Logical Interface、Logical Interface、简称为Logical Interface、简称为Logical Interface、简称为Logical Interface、简称为Logical Interface、简称为Logical Interface、简称为Logical Interface、简称每个物理端口托管一个两个LIP、因此每个控制器上的每个VLAN具有两个LIP。此配置可提供最大带宽、并允许每个LIF故障转移到同一控制器上的另一个端口、以便在发生网络故障时两个控制器保持活动状态。此配置还支持基于RDMA的NFS以启用GPUDirect存储访问。存储容量以一个大型FlexGroup卷的形式配置、该卷跨越两个控制器。此可从SVM上的任何FlexGroup进行访问、DGX A100系统的挂载点会分布在可用的LUN之间、以实现负载平衡。</block>
  <block id="570a94ea84b9e283c5f0051826733505" category="paragraph">管理SVM仅需要一个LIF、该LIF托管在每个控制器上配置的双端口接口组上。在管理SVM上配置了其他FlexGroup卷、用于存放集群管理项目、例如集群节点映像、系统监控历史数据和最终用户主目录。下图显示了存储系统的逻辑配置。</block>
  <block id="7775254786443c9bb9d3a8210f791295" category="paragraph"><block ref="7775254786443c9bb9d3a8210f791295" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4534545218c3df22ad30ec5ab0466128" category="section-title">存储系统大小指导</block>
  <block id="22ba4624feefdfa4ac6f4c2457463981" category="paragraph">此架构可供希望使用NVIDIA DGX系统和NetApp AFF存储系统实施深度学习基础架构的客户和合作伙伴参考。下表显示了每个AFF型号所支持的A100和H100 GPU数量的粗略估计。</block>
  <block id="0ba478911eb0d5e4ac05f4b07afc5fee" category="paragraph"><block ref="0ba478911eb0d5e4ac05f4b07afc5fee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="728adfd3607777ad12144223b13e3beb" category="inline-link-macro">此参考架构的先前版本</block>
  <block id="9bab6352a567b3c48bc08877594fe4ed" category="inline-link-macro">下一步：采用NVIDIA DGX系统的NetApp AI Pod—总结。</block>
  <block id="81be048c32cf3fb6f8ea022bb0314c88" category="paragraph">如中所示 <block ref="e7d2483a5af77a681a4ce9b70e0123d3" category="inline-link-macro-rx"></block>AFF A800系统可轻松支持八个DGX A100系统生成的深度学习训练工作负载。上述其他存储系统的估计值是根据这些结果计算的、而H100 GPU的估计值是通过将A100系统所需的存储吞吐量增加一倍来计算的。  对于存储性能要求较高的大型部署、可以在一个集群中向NetApp ONTAP集群添加更多AFF系统、最多可添加12个HA对(24个节点)。使用本解决方案中所述的FlexGroup技术、一个24节点集群可以在一个命名空间中提供超过40 PB的吞吐量和高达300 Gbps的吞吐量。其他NetApp存储系统(例如AFF A400、A250和C800)以更低的成本为小型部署提供了更低的性能和/或更高的容量选项。由于ONTAP 9支持混合模式集群、因此客户可以先减少初始占用空间、然后随着容量和性能要求的增长向集群添加更多或更大的存储系统。
<block ref="73b5ef96476759553df4b1fa88f8c59f" category="inline-link-macro-rx"></block></block>
  <block id="68674fa5fbd6fb83969183d07d48b8cd" category="section-title">NetApp AFF存储系统</block>
  <block id="3b6d33ce139758ecf9b0b83f9ecce001" category="paragraph">NetApp AFF一流的存储系统凭借行业领先的性能、卓越的灵活性、云集成和同类最佳数据管理功能、可帮助IT部门满足企业存储需求。AFF 系统专为闪存而设计、有助于加速、管理和保护业务关键型数据。</block>
  <block id="64dc43320ec1a44c390fafb5e2408f4b" category="section-title">NVIDIA DGX基本POD</block>
  <block id="d90238071267e4279a25de2c6945b227" category="section-title">NVIDIA网络</block>
  <block id="d347ba1211916e66366029d11b59ba2d" category="summary">ONTAP AI是一款基于NVIDIA BasePOD的企业级参考架构、适用于使用ONTAP AFF存储系统和NVIDIA网络和DGX系统的深度学习和人工智能。</block>
  <block id="022a857c06271f783a0d38612e98dbc0" category="doc">采用NVIDIA DGX BasePOD的NetApp AI POD—简介</block>
  <block id="8790c3b96b175989365c226e2f90762d" category="paragraph">NetApp公司Dave Arette</block>
  <block id="4aca3e6f7db20954268b5cc64ee4dd5e" category="paragraph">由NVIDIA DGX BasePOD&amp;#482和NetApp云互联存储系统提供支持的NetApp AI POD参考架构可消除设计复杂性和猜测性、简化机器学习(ML)和人工智能(AI)工作负载的基础架构部署。ONTAP AI基于NVIDIA DGX BasePOD设计构建、可为下一代工作负载提供卓越的计算性能、并添加了NetApp AFF存储系统、支持客户从小规模入手、无干扰地进行扩展、同时智能地管理从边缘到核心再到云再到云的数据。NetApp AI POD是更广泛的NetApp AI解决方案产品组合的一部分、如下图所示-</block>
  <block id="df414eefe37bdc243f5daac10fc3d749" category="paragraph"><block ref="df414eefe37bdc243f5daac10fc3d749" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4745c24df216933624630ee34257b9e3" category="paragraph">本文档介绍了AI POD参考架构的关键组件、系统连接信息和解决方案规模估算指南。本文档面向有意为ML/DL和分析工作负载部署高性能基础架构的NetApp和合作伙伴解决方案工程师以及客户战略决策者。</block>
  <block id="03479b81af64177030f17debcbe954fd" category="inline-link-macro">下一步：ONTAP AI—硬件组件</block>
  <block id="4f95edfb679a4d883a14bec5fb0b765f" category="paragraph"><block ref="4f95edfb679a4d883a14bec5fb0b765f" category="inline-link-macro-rx"></block></block>
  <block id="5475410ded0787143601d2206a245532" category="section-title">NVIDIA软件</block>
  <block id="c7bef72157cc39b6eb7c391a393a20d2" category="section-title">NVIDIA基本命令</block>
  <block id="9aeccfb63defa46cb78ffa3611d362c6" category="section-title">NetApp软件</block>
  <block id="06fccd13fe37c98002ea1b7db4383539" category="summary">采用NVIDIA DGX系统的NetApp AI Pod—总结</block>
  <block id="29960dc3f77022de2577936fc818e360" category="inline-link-macro">上一页：采用NVIDIA DGX系统的NetApp AI Pod—存储系统设计和大小指导。</block>
  <block id="a099ae3c8f02e9a97a4d28a54904ee4f" category="paragraph"><block ref="a099ae3c8f02e9a97a4d28a54904ee4f" category="inline-link-macro-rx"></block></block>
  <block id="949416db0d1989692b36b5f6f8ce5a0f" category="paragraph">DGX BasePOD架构是下一代深度学习平台、需要同等高级的存储和数据管理功能。通过将DGX BasePOD与NetApp AFF系统相结合、此架构几乎可以在任何规模下实施、从一个与AFF A250存储系统配对的DGX A100到一个24节点AFF A800集群上的48个DGX A100系统。结合NetApp ONTAP卓越的云集成和软件定义的功能、AFF支持跨边缘、核心和云端的全套数据管道、助力深度学习项目取得成功。</block>
  <block id="bbd4de8c111df7a7c885105e16d426eb" category="inline-link-macro">下一步：采用NVIDIA DGX系统的NetApp AI Pod—追加信息。</block>
  <block id="234027be73c5b020cd4dfbd23082ea4c" category="paragraph"><block ref="234027be73c5b020cd4dfbd23082ea4c" category="inline-link-macro-rx"></block></block>
  <block id="faf3bfb28373fa64aad8c3c641b272d3" category="summary">采用NVIDIA DGX系统的NetApp AI Pod—从何处查找追加信息</block>
  <block id="890699b1202f548485a4d15db59e30e9" category="inline-link-macro">上一页：采用NVIDIA DGX系统的NetApp AI Pod—总结。</block>
  <block id="7ae738bf396314b8df6c0f3531207693" category="paragraph"><block ref="7ae738bf396314b8df6c0f3531207693" category="inline-link-macro-rx"></block></block>
  <block id="3e25f5537dc80d1324e8b8639d0f3331" category="list-text">ONTAP AI- NetApp通过NVIDIA DGX A100系统验证的架构</block>
  <block id="81df4cf10cdf43ee92694f3c8c2c5ae8" category="inline-link"><block ref="81df4cf10cdf43ee92694f3c8c2c5ae8" category="inline-link-rx"></block></block>
  <block id="e4e23e4911dfd012ecb94a958409f0b9" category="paragraph"><block ref="e4e23e4911dfd012ecb94a958409f0b9" category="inline-link-rx"></block></block>
  <block id="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link"><block ref="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link-rx"></block></block>
  <block id="d99ede023f079413a479e349dcb54616" category="paragraph"><block ref="d99ede023f079413a479e349dcb54616" category="inline-link-rx"></block></block>
  <block id="0ab76d4872db09ecb57fa710fc123418" category="inline-link"><block ref="0ab76d4872db09ecb57fa710fc123418" category="inline-link-rx"></block></block>
  <block id="01bf6d43d7d61e8ecfb56c62edde16aa" category="paragraph"><block ref="01bf6d43d7d61e8ecfb56c62edde16aa" category="inline-link-rx"></block></block>
  <block id="d33e3a5f8c0cfc60c3e79f3c4a1c7d60" category="list-text">NVIDIA BasePD</block>
  <block id="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link"><block ref="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link-rx"></block></block>
  <block id="0c2cd58ffa7f091c420ae61854a0a8db" category="paragraph"><block ref="0c2cd58ffa7f091c420ae61854a0a8db" category="inline-link-rx"></block></block>
  <block id="fe9aea34e4ae9a0dee450504e80761d5" category="list-text">NVIDIA DGX A100系统</block>
  <block id="0cc2b112d6c81a7525840f7c4cd76527" category="inline-link"><block ref="0cc2b112d6c81a7525840f7c4cd76527" category="inline-link-rx"></block></block>
  <block id="64d169ecb4b9b6ca5305f7275294eaae" category="paragraph"><block ref="64d169ecb4b9b6ca5305f7275294eaae" category="inline-link-rx"></block></block>
  <block id="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link"><block ref="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link-rx"></block></block>
  <block id="a19d7568aa9c7e4c1f3bf3e831367115" category="paragraph"><block ref="a19d7568aa9c7e4c1f3bf3e831367115" category="inline-link-rx"></block></block>
  <block id="42c9b161f86365b647172182503d9520" category="inline-link"><block ref="42c9b161f86365b647172182503d9520" category="inline-link-rx"></block></block>
  <block id="f5802e2c53799babc0ac27f6cb392604" category="paragraph"><block ref="f5802e2c53799babc0ac27f6cb392604" category="inline-link-rx"></block></block>
  <block id="3389dae361af79b04c9c8e7057f60cc6" category="paragraph">*</block>
  <block id="217432d0ec5a422d97fdd8082983c438" category="paragraph">NetApp 解决方案 工程部</block>
  <block id="6190bc67623b848bb7959b33f3f0d2eb" category="list-text"><block ref="6190bc67623b848bb7959b33f3f0d2eb" category="inline-link-macro-rx"></block></block>
  <block id="ff796b13154c28039cc9b13793eda31c" category="inline-link-macro">使用Astra Control Service对带有Amazon FSx存储的ROSA集群上的应用程序进行数据管理 </block>
  <block id="99ecd458328f39eb9eca26c77f13023d" category="list-text"><block ref="99ecd458328f39eb9eca26c77f13023d" category="inline-link-macro-rx"></block></block>
  <block id="67f778c9ede0c0e222ba60a5644d0ef9" category="video-title">使用Amazon FSx for NetApp ONTAP存储在AWS上的Red Hat OpenShift Service (ROSA)集群上为应用程序创建快照/还原</block>
  <block id="577df6236e6e1a1682f65355d6d35a2c" category="doc">采用NVIDIA DGX系统的NetApp AIPod—解决方案架构</block>
  <block id="a39e45b08dafc96fc22bd34295329031" category="section-title">采用DGX H100系统的NetApp AI Pod</block>
  <block id="5dd57c2a315d3af44c2eb40eefc47111" category="section-title">网络配置：</block>
  <block id="d726f9e07242f01d038385123f6c5cae" category="section-title">用于存储访问的客户端配置</block>
  <block id="2139fe384d5ae165545994dff01961d9" category="section-title">存储系统配置：</block>
  <block id="faf6590c1a96ba32f0ab5077195bccad" category="paragraph">每个AFF A900存储系统使用每个控制器中的四个100 GbE端口进行连接。每个控制器的两个端口用于从DGX系统访问工作负载数据、每个控制器的两个端口配置为LACP接口组、以支持从管理平台服务器访问集群管理项目和用户主目录。存储系统的所有数据访问均通过NFS提供、其中一个Storage Virtual Machine (SVM)专用于AI工作负载访问、另一个SVM专用于集群管理用途。</block>
  <block id="6c9aef89eae0fd771909b15623e452df" category="paragraph">管理SVM仅需要一个LIF、该LIF托管在每个控制器上配置的双端口接口组上。在管理SVM上配置了其他FlexGroup卷、用于存放集群管理项目、例如集群节点映像、系统监控历史数据和最终用户主目录。下图显示了存储系统的逻辑配置。</block>
  <block id="19a97f58216292f6ce34aa1a3ad9e96e" category="summary">采用NVIDIA DGX系统的NetApp AIPod—从何处查找追加信息</block>
  <block id="4cc9926ab22b0001fe330910bedef302" category="doc">采用NVIDIA DGX系统的NetApp AIPod—结论和追加信息</block>
  <block id="86b221b3904230f3b61b8a59c459ae46" category="inline-link-macro">上一页：采用NVIDIA DGX系统的NetApp AIPod—解决方案验证和大小指南</block>
  <block id="3acf3b79a52ae18126bf7eb4d9bffeb9" category="paragraph"><block ref="3acf3b79a52ae18126bf7eb4d9bffeb9" category="inline-link-macro-rx"></block></block>
  <block id="68e34599e7058d633da08de84c55032d" category="paragraph">要详细了解本文档中所述的信息、请参阅以下文档和/或网站：</block>
  <block id="aa337d98559cff5848df7daaebbb9c97" category="list-text">NetApp AFF A900存储系统-</block>
  <block id="5a9e4513c7860af8a56b46990effb9bf" category="inline-link"><block ref="5a9e4513c7860af8a56b46990effb9bf" category="inline-link-rx"></block></block>
  <block id="d0740233c3ee3b1d510983b87e200157" category="paragraph"><block ref="d0740233c3ee3b1d510983b87e200157" category="inline-link-rx"></block></block>
  <block id="29b91fda4bb7baae0176d0ca5870634a" category="list-text">NetApp ONTAP RDMA信息-</block>
  <block id="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-macro"><block ref="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-rx"></block></block>
  <block id="c08c09703d9322a16ef4a93b82ff897e" category="paragraph"><block ref="c08c09703d9322a16ef4a93b82ff897e" category="inline-link-macro-rx"></block></block>
  <block id="7f86b6f2a05fc6e5c5931f73e9af29fd" category="summary">采用NVIDIA DGX系统的NetApp AIPod—硬件组件</block>
  <block id="111f9015398e1351a89728156a0215df" category="inline-link-macro">上一页：采用NVIDIA DGX系统的NetApp AIPod -简介</block>
  <block id="be78a713f4a43883d15810cd5fd05462" category="paragraph"><block ref="be78a713f4a43883d15810cd5fd05462" category="inline-link-macro-rx"></block></block>
  <block id="581d5f2c74f74ac1ae51355c4a4467b2" category="section-title">AFF A900存储系统</block>
  <block id="219d5ec1ec3903182135842c58c1dbd6" category="paragraph">由NetApp ONTAP数据管理软件提供支持的NetApp AFF A900提供内置数据保护、可选的反勒索软件功能以及支持最关键业务工作负载所需的高性能和故障恢复能力。它可以消除任务关键型运营中断、最大限度地减少性能调整、并保护数据免受勒索软件攻击。它提供：
•行业领先的性能
•不折不扣的数据安全性
•简化无中断升级</block>
  <block id="1863aa82dcf92831635aa05e975d399d" category="section-title">行业领先的性能</block>
  <block id="773efff7a0bbe1582ceff936530b5ae3" category="section-title">不折不扣的数据安全性</block>
  <block id="f6353452ddd71a9ef0e4d8578d7dc7e3" category="section-title">简化无中断升级</block>
  <block id="0a5f31a2eea3b274409614f4eb63433c" category="section-title">NVIDIA DGX H100系统</block>
  <block id="9ced46278532bc0084e0fefef090242d" category="inline-link-macro">下一步：采用NVIDIA DGX系统的NetApp AIPod—软件组件</block>
  <block id="cad5afa656ff6f36baf42ba91e59fd47" category="paragraph"><block ref="cad5afa656ff6f36baf42ba91e59fd47" category="inline-link-macro-rx"></block></block>
  <block id="77f2324c2483df30f029d522599f882e" category="summary">采用NVIDIA DGX系统的NetApp AIPod—软件组件</block>
  <block id="761b7922a1f4674560d4630525b77820" category="inline-link-macro">上一页：采用NVIDIA DGX系统的NetApp AIPod -硬件组件</block>
  <block id="b48d327ba5d492d35263e794cff48c88" category="paragraph"><block ref="b48d327ba5d492d35263e794cff48c88" category="inline-link-macro-rx"></block></block>
  <block id="b2d0aaf645ff5747fbe1e0aec0cf528c" category="list-text">数据保护ONTAP提供内置数据保护功能和业内最强大的反勒索软件担保、并在所有平台之间提供通用管理。</block>
  <block id="621721e0b0144695aabce4090fa40eed" category="list-text">快照和克隆支持协作、并行实验和增强ML/DL工作流的数据监管。</block>
  <block id="b1932ff070760d4f32c0a3701982558d" category="list-text">SnapMirror支持在混合云和多站点环境中无缝移动数据、可根据需要随时随地提供数据。</block>
  <block id="826fe2a66df89db18bb43157b2975159" category="inline-link-macro">下一步：采用NVIDIA DGX系统的NetApp AIPod—解决方案架构</block>
  <block id="e0073a8725830dcd0bd0ddc6676565fd" category="paragraph"><block ref="e0073a8725830dcd0bd0ddc6676565fd" category="inline-link-macro-rx"></block></block>
  <block id="75dccb01a6188861431ae57d6825b5dc" category="inline-link-macro">上一页：采用NVIDIA DGX系统的NetApp AIPod—解决方案架构</block>
  <block id="7771db55ec8b557d312a4d77d397e5b7" category="paragraph"><block ref="7771db55ec8b557d312a4d77d397e5b7" category="inline-link-macro-rx"></block></block>
  <block id="773a9689ba6682deeabffa6746d64105" category="section-title">解决方案验证</block>
  <block id="364bed9cbf28e51b3a87b1cece482054" category="paragraph">此解决方案中的存储配置已通过使用开源工具FIO的一系列综合工作负载进行验证。这些测试包括用于模拟由执行深度学习培训作业的DGX系统生成的存储工作负载的读写I/O模式。存储配置已通过一个双插槽CPU服务器集群进行验证、该集群可同时运行FIO工作负载、以模拟一个DGX系统集群。每个客户端都配置了与前文所述相同的网络配置、并添加了以下详细信息。</block>
  <block id="9b3cad043096c397b17339135694a7f4" category="paragraph">此验证使用了以下挂载选项-
•VERS=4.1. #启用pNFS以并行访问多个存储节点
•proto = RDMA #将传输协议设置为RDMA、而不是默认TCP
•端口=20049 #为RDMA NFS服务指定正确的端口
•max_connect = 16 #启用NFS会话中继以聚合存储端口带宽
•write=eager #可提高缓冲写入的写入性能
•rsize=262144、wsize=262144 #将I/O传输大小设置为256k</block>
  <block id="517e9f0f1cdacee61fe40e1989d9171c" category="paragraph">此外、还为客户端配置了NFS max_sSession_狭 缝值1024。在使用基于RDMA的NFS对解决方案进行测试时、存储网络端口配置了主动/被动绑定。在这项验证中使用了以下绑定参数-
•mode=active-backup #将绑定设置为主动/被动模式
主卷=&lt;interface name&gt; #所有客户端的主接口都分布在交换机之间
•MII-monitor-interval=100 #指定100毫秒的监控间隔
•故障转移-mac-policy=active #指定活动链路的MAC地址是绑定的MAC。要通过绑定接口正确运行RDMA、必须执行此操作。</block>
  <block id="13e766ae456cff38288a10e042da1460" category="paragraph">存储系统按照所述进行配置、配置有两个A900 HA对(4个控制器)、其中两个NS224磁盘架、每个HA对连接有24个1.9 TB NVMe磁盘驱动器。如架构部分所述、所有控制器的存储容量均使用FlexGroup卷进行合并、所有客户端的数据分布在集群中的所有控制器上。</block>
  <block id="c683ba7d802f6abbc28cf9842ffd6c21" category="inline-link-macro">下一步：采用NVIDIA DGX系统的NetApp AIPod—总结与追加信息</block>
  <block id="d02b39ad24851279f902e2d640a23236" category="paragraph"><block ref="d02b39ad24851279f902e2d640a23236" category="inline-link-macro-rx"></block></block>
  <block id="9f68b039fbd3ecc8729ee9a4be7903ea" category="summary">采用NVIDIA DGX系统的NetApp AIPod是一款基于NVIDIA BasePOD的企业级参考架构、可使用NetApp ONTAP AFF存储系统以及NVIDIA网络和DGX系统实现深度学习和人工智能。</block>
  <block id="c76b2a4135db1bf6b22445f907d31311" category="doc">采用NVIDIA DGX系统的NetApp AIPod—简介</block>
  <block id="89499f1c5b524f3ec39275214b8e3241" category="paragraph">本文档介绍AIPod参考架构的关键组件、系统连接信息和解决方案规模估算指导。本文档面向有意为ML/DL和分析工作负载部署高性能基础架构的NetApp和合作伙伴解决方案工程师以及客户战略决策者。</block>
  <block id="2ce56ff2610ea929e68ca98f14b571b7" category="inline-link-macro">下一步：采用NVIDIA DGX系统的NetApp AIPod -硬件组件</block>
  <block id="80ddd7f3c9e49fe76ef18afcde547154" category="paragraph"><block ref="80ddd7f3c9e49fe76ef18afcde547154" category="inline-link-macro-rx"></block></block>
  <block id="c762aaec425b12667f2a575012e48905" category="list-text">为每个目标接口配置五个iSCSI会话以获得最佳性能。</block>
  <block id="72a53f90bcbaa031cad1c79575c53094" category="list-text">配置轮循策略以获得最佳整体iSCSI性能。</block>
  <block id="168b03d713c83578e3c90be8e0a76a8e" category="list-text">格式化LUN时、请确保分区的分配单元大小设置为64K</block>
  <block id="c018e127ecd02f5fde489e4444402e79" category="section-title">使用适用于虚拟化的迁移工具包将VM从VMware迁移到OpenShift虚拟化</block>
  <block id="ed28eb7490c30b746183ce03d45078bb" category="paragraph">在本节中、我们将了解如何使用虚拟化迁移工具包(Migration Toolkit for Virtualization、Mtv)将虚拟机从VMware迁移到在OpenShift容器平台上运行并使用Asta Trident与NetApp ONTAP存储集成的OpenShift虚拟化。</block>
  <block id="4c3578ac96eaf28e931991a1ad4f0966" category="paragraph">以下视频演示了如何使用ONTAP SAN将RHEL VM从VMware迁移到OpenShift虚拟化以实现永久性存储。</block>
  <block id="1a77203f1aab519882f2e846b9d9b719" category="video-title">使用Red Hat VtTM通过NetApp ONTAP存储将VM迁移到OpenShift虚拟化</block>
  <block id="ea79c776da84047793859d6582eb03d9" category="paragraph">下图简要展示了将VM从VMware迁移到Red Hat OpenShift虚拟化的过程。</block>
  <block id="5545f87dec77c5fda3d45b6aedaa1d06" category="paragraph"><block ref="5545f87dec77c5fda3d45b6aedaa1d06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a4a5d7419037b65e3a5d2f120b2e45a" category="section-title">迁移示例的前提条件</block>
  <block id="92308586782b1ac3ca67d5246beb4254" category="section-title">**在VMware**上</block>
  <block id="ab31f70ad4d51f1953d4174e7a97998c" category="list-text">安装了一个使用RHEL 9.3的RHEL 9 VM、并具有以下配置：</block>
  <block id="c859d53505195ea9836fd1dd18a342de" category="list-text">CPU：2、内存：20 GB、硬盘：20 GB</block>
  <block id="49dcb604dd937c117e3eb904336b63a6" category="list-text">用户凭据：root用户和管理员用户凭据</block>
  <block id="45b7cf9911c7c95a3e96680e5101a366" category="list-text">虚拟机准备就绪后、安装了PostgreSQL服务器。</block>
  <block id="a1d26d1742c3c5015c533cb7b4125649" category="list-text">PostgreSQL服务器已启动并启用、可在启动时启动</block>
  <block id="ba180a6063bec76a659b566752131283" category="list-text">添加了2个数据库、其中添加了1个表和1行。请参见 <block ref="f6571761cb4f08005f15599248450b50" category="inline-link-macro-rx"></block> 有关在RHEL上安装PostgreSQL服务器以及创建数据库和表条目的说明、请参见。</block>
  <block id="d486afc72ff9ff542e8957b66aabe34f" category="admonition">确保启动PostgreSQL服务器并启用服务以在启动时启动。</block>
  <block id="3bc4bf0e263e39cc80e52b11fd83fc18" category="section-title">**在OpenShift集群上**</block>
  <block id="d6cd4900fddb3efade4a282a26e76510" category="paragraph">在安装此版本之前、已完成以下安装：</block>
  <block id="37fdc4699dbf9c03a1788f82eff3c290" category="list-text">OpenShift集群4.13.34</block>
  <block id="7a1b797fd20321e22ea865d10d6f2cf3" category="inline-link-macro">Astra三打23.10.</block>
  <block id="39d5f21c59b11d3b23ca05c3b2223f69" category="list-text"><block ref="39d5f21c59b11d3b23ca05c3b2223f69" category="inline-link-macro-rx"></block></block>
  <block id="8363d6d8b175f7d34d8dcd10b0920d9b" category="list-text">为iSCSI启用的集群节点上的多路径(对于ONONTAP SAN存储类)。请参见提供的YAML以创建一个守护进程集、以便在集群中的每个节点上启用iSCSI。</block>
  <block id="0f0f67946a5dc2825c8af27dc202945c" category="list-text">使用iSCSI的ONTAP SAN的三端和存储类。请参见为三元后端和存储类提供的YAML文件。</block>
  <block id="4662ff3eab124bb57ed62299c1453baf" category="list-text"><block ref="4662ff3eab124bb57ed62299c1453baf" category="inline-link-macro-rx"></block></block>
  <block id="ab134299dd9b7432c9b96f83421154f7" category="paragraph">要在OpenShift集群节点上安装iSCSI和多路径、请使用下面提供的YAML文件
**为iSCSI准备群集节点**</block>
  <block id="76560162775238630068f3372685523f" category="paragraph">使用以下YAML文件创建使用ONTAP SAN存储的三元后端配置
** iSCSI的三端**</block>
  <block id="eb822d62df05605c782061d2694c7416" category="paragraph">使用以下YAML文件创建要使用ONTAP SAN存储的三元存储类配置
**用于iSCSI**的三级存储类</block>
  <block id="32e2326cf08fa2b8a2d8da07af89492d" category="section-title">*安装Mst*</block>
  <block id="b20b36d31c21c88b330220afadc4c248" category="paragraph">现在、您可以安装适用于虚拟化的迁移工具包(Migration Toolkit for Virtualization、简称为迁移工具包)。请参阅提供的说明 <block ref="78541cf70d4432a26af2ad2bc2f1599e" category="inline-link-macro-rx"></block> 有关安装的帮助。</block>
  <block id="833a308c57b0294d5fc8b47fcbc273aa" category="paragraph">虚拟化迁移工具包(Migration Toolkit for Virtualization、Tmb)用户界面集成到OpenShift Web控制台中。
您可以参考 <block ref="0501eeadc64b28b9be041bb74afe3ad8" category="inline-link-macro-rx"></block> 开始使用用户界面执行各种任务。</block>
  <block id="ba34a808d5ef47822d13b6eaae380955" category="paragraph">**创建源提供程序**</block>
  <block id="9dfd530db6afa78f79d825306725d533" category="paragraph">要将RHEL VM从VMware迁移到OpenShift虚拟化、您需要先为VMware创建源提供程序。请参阅说明 <block ref="5a232a9d86f11be106236c73b37bba4f" category="inline-link-macro-rx"></block> 以创建源提供程序。</block>
  <block id="698f626f0a4cef07823d743a2dbe05f6" category="paragraph">要创建VMware源提供程序、您需要满足以下条件：</block>
  <block id="2f01f330ac5bbca687428a4aea084ec7" category="list-text">vCenter URL</block>
  <block id="f8e71877199d54f902a68305fe9e4d65" category="list-text">vCenter凭据</block>
  <block id="85b0b1a49d5b88187baef2af24bc6e5c" category="list-text">vCenter Server指纹</block>
  <block id="67410b0417131e71e5479ef47bf0b29d" category="list-text">存储库中的VDDK映像</block>
  <block id="959b7c4b71886115429518587644aebe" category="paragraph">创建源提供程序的示例：</block>
  <block id="4a7bfcd7504eb44e425e13e3debe92da" category="paragraph"><block ref="4a7bfcd7504eb44e425e13e3debe92da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="431899a140e7168ac10851938d985f34" category="admonition">虚拟化迁移工具包(Migration Toolkit for Virtualization、Mv）使用VMware虚拟磁盘开发工具包(Virtual Disk Development Kit、VDDK) SDK来加快从VMware vSphere传输虚拟磁盘的速度。因此、强烈建议创建VDDK映像、尽管这是可选的。
要使用此功能、请下载VMware虚拟磁盘开发工具包(VDDK)、构建VDDK映像、然后将VDDK映像推送到映像注册表。</block>
  <block id="4a6d1c59688d4bfd35bf9273bf11f8ea" category="paragraph">按照提供的说明进行操作 <block ref="102736775f16e15f2f98ffe552b0757e" category="inline-link-macro-rx"></block> 创建VDDK映像并将其推送到可从OpenShift集群访问的注册表。</block>
  <block id="3eb78782382908bcbe75ff430f148a0a" category="paragraph">**创建目标提供程序**</block>
  <block id="41a9e71e2ab20cb7e1db9492b652a4e7" category="paragraph">由于OpenShift虚拟化提供程序是源提供程序、因此会自动添加主机集群。</block>
  <block id="25570b7a362c49ef673bd98cf2359271" category="paragraph">**创建迁移计划**</block>
  <block id="3008c031ed8e56d6902d0efc66eaa035" category="paragraph">按照提供的说明进行操作 <block ref="39595bf3d6cb45be93d62f6764c92ee0" category="inline-link-macro-rx"></block> 以创建迁移计划。</block>
  <block id="5254832d8ded5bf2d2f6fe4975628d7b" category="paragraph">创建计划时，如果尚未创建，则需要创建以下内容：</block>
  <block id="cfd81ec3034efddb911513d79b28d9db" category="list-text">用于将源网络映射到目标网络的网络映射。</block>
  <block id="367829c9ebbf303aad8f4325f563de34" category="list-text">用于将源数据存储库映射到目标存储类的存储映射。为此、您可以选择ONTAP SAN存储类。
创建迁移计划后，该计划的状态应显示*Ready*，现在您应该能够*Start*该计划。</block>
  <block id="78949f8442528702feefd1dcf8f25406" category="paragraph"><block ref="78949f8442528702feefd1dcf8f25406" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef53e330f7c1069c8dca0ff4d2bc9430" category="paragraph">单击*Start*将运行一系列步骤来完成虚拟机的迁移。</block>
  <block id="3024dfed82e5852da00b05eb0ea5e81b" category="paragraph"><block ref="3024dfed82e5852da00b05eb0ea5e81b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65a63a95f4cf90511c46b9f9419385b1" category="paragraph">完成所有步骤后，您可以通过单击左侧导航菜单中“Virtualization”(虚拟化)下的*virtual Machines*来查看迁移的VM。
其中提供了访问虚拟机的说明 <block ref="9866532d9d0f47e3947d77adbdcf2432" category="inline-link-macro-rx"></block>。</block>
  <block id="87a2f6eb52f66b7c3f568cc74f0aae89" category="paragraph">您可以登录到虚拟机并验证pos正在 使用的数据库的内容。此表中的数据库、表和条目应与在源VM上创建的相同。</block>
  <block id="c07d7e29650467546955633b246fda6a" category="paragraph">此页面显示了使用Astra Control Service在AWS上托管Red Hat OpenShift (ROSA)集群的数据保护选项。Astra Control Service (ACS)提供了一个易于使用的图形用户界面、您可以使用该界面添加集群、定义在其中运行的应用程序以及执行应用程序感知型数据管理活动。此外、还可以使用支持工作流自动化的API访问ACS功能。</block>
  <block id="97533488bc585534ca5130378158f021" category="paragraph">NetApp Astra控制(ACS或ACC)由Astra三端驱动。Asta三端集成了多种类型的Kubernetes集群、例如Red Hat OpenShift、EKS、AKS、SUSE缓存器、Anthos等。 具有各种NetApp ONTAP存储风格、例如FAS/AFFF、ONTAP Select、CVO、Google Cloud Volumes Service、Azure NetApp Files和Amazon FSx for NetApp ONTAP。</block>
  <block id="6f1cfebfde061a4cdaf77705ab7a4009" category="paragraph">本节详细介绍了使用ACS的以下数据保护选项：</block>
  <block id="33da028b104a9f96f7020cd949c12c79" category="list-text">显示备份和还原在一个区域运行的ROSA应用程序并还原到另一个区域的视频。</block>
  <block id="733a18c6cf3c64494d2dfa21ca393537" category="list-text">显示ROSA应用程序的Snapshot和Restore的视频。</block>
  <block id="9d74bf33165a37b61ad2f50b938972e7" category="list-text">安装ROSA集群的分步详细信息、Amazon FSx for NetApp ONTAP、使用NetApp Astra三端集成到存储后端、在ROSA集群上安装PostgreSQL应用程序、使用ACS创建应用程序快照并从中还原应用程序。</block>
  <block id="11e2220ebd484b8703528a9133e1a6c6" category="list-text">一篇博客、详细介绍了如何使用ACS在使用FSx for ONTAP的ROSA集群上为myql应用程序创建快照并从快照中还原。</block>
  <block id="f1496ac3e4a3245d65c86de1ff527370" category="section-title">备份/从备份中还原</block>
  <block id="5eba799acfc56e5d19da8c3797685e2d" category="section-title">快照/从快照还原</block>
  <block id="70fe15f76a66619d2b49bdda5d02a6aa" category="paragraph">以下视频显示了如何创建ROSA应用程序的快照以及之后如何从快照中还原。</block>
  <block id="ece8e805749cce956d96c8cbcddeb1a0" category="video-title">使用Amazon FSx for NetApp ONTAP存储在AWS上的Red Hat OpenShift Service (ROSA)集群上为应用程序创建快照/还原</block>
  <block id="be8df1f28c0abc85a0ed0c6860e5d832" category="section-title">博客</block>
  <block id="3a4a68edff076c6484ed03c598313cb8" category="inline-link-macro">使用Astra Control Service对带有Amazon FSx存储的ROSA集群上的应用程序进行数据管理</block>
  <block id="df1f7fc111c2ed4d19bb019806a32882" category="list-text"><block ref="df1f7fc111c2ed4d19bb019806a32882" category="inline-link-macro-rx"></block></block>
  <block id="1ea55c3f63a034c9b2511a975c2ff928" category="section-title">创建快照并从中还原的分步详细信息</block>
  <block id="017b198d0c8d4d362a1107345764d6a2" category="section-title">前提条件设置</block>
  <block id="3a2b88b991502efccf922110610f9582" category="list-text"><block ref="27fc574b8ea5cd6312c40c8aa826b8e2" category="inline-link-macro-rx"></block></block>
  <block id="a157286734897fea2ae78eb8d5a07083" category="inline-link-macro">Red Hat OpenShift帐户</block>
  <block id="d4cc8b87ccca1a93d32d10a54f2f3096" category="list-text"><block ref="d4cc8b87ccca1a93d32d10a54f2f3096" category="inline-link-macro-rx"></block></block>
  <block id="638cbffb6101ef7301c367160b8afbea" category="inline-link-macro">适当的权限</block>
  <block id="3eb7df5974139b5c06b1b98ace64875f" category="list-text">使用的IAM用户 <block ref="e6e1437575a8e52c43b6bea47e894f06" category="inline-link-macro-rx"></block> 创建和访问ROSA集群</block>
  <block id="7820fdb5d8b3ebe0c69c86cf8bd2d0cf" category="inline-link-macro">AWS命令行界面</block>
  <block id="98301d59c6cad91a32be2e4205f6bb39" category="list-text"><block ref="98301d59c6cad91a32be2e4205f6bb39" category="inline-link-macro-rx"></block></block>
  <block id="a419a367cad390ff246057d1781b2530" category="inline-link-macro">罗莎命令行界面</block>
  <block id="e08f074ff23721e4a104f551d21fa4c3" category="list-text"><block ref="e08f074ff23721e4a104f551d21fa4c3" category="inline-link-macro-rx"></block></block>
  <block id="4fca4e9eaad689a27ecb08ff8f3f807c" category="inline-link-macro">OpenShift命令行界面</block>
  <block id="00d080f5fe32e84dd619feb7cb7bd2b9" category="list-text"><block ref="44b8b3934efa2fc5ae9867d0131fa46a" category="inline-link-macro-rx"></block>(OC)</block>
  <block id="4b8e58f2991ec92ce05bbb428c7e785f" category="list-text">具有子网以及相应网关和路由的VPC</block>
  <block id="8432e6115f09c44c98ef0d5466e1443f" category="inline-link-macro">已安装罗莎群集</block>
  <block id="9fb986e8b23a43f32df441a71e17d9a4" category="list-text"><block ref="105d5b5c7505cc3d67068ef270819c2c" category="inline-link-macro-rx"></block> VPC</block>
  <block id="43f4b12f6a6e4653ba2e9e9431316f26" category="list-text"><block ref="191e780a56cabcf83bcdf7c866f8d783" category="inline-link-macro-rx"></block> 在同一个VPC中创建</block>
  <block id="e53a614538d8dd04ae01b6f7c8fad43c" category="inline-link-macro">OpenShift混合云控制台</block>
  <block id="e701544c0a6a10d3e9fd724eb673bd08" category="list-text">从访问ROSA集群 <block ref="0adb5adbf9501e5dfbc7213724e52837" category="inline-link-macro-rx"></block></block>
  <block id="1b920337ea7c0ca3dadb73c0a64b69a7" category="section-title">后续步骤</block>
  <block id="5152194ac48cdb110daca5acc638a081" category="list-text">创建管理员用户并登录到集群。</block>
  <block id="7616094045f96860c9ac357dc99c056e" category="list-text">为集群创建一个kubeconfig.文件。</block>
  <block id="2d0ad6df83342005c040544d3e09f39f" category="list-text">在集群上安装Asta Trdent。</block>
  <block id="06c9354d40a28d74b82f80702f813d97" category="list-text">使用三端CSI配置程序创建后端、存储类和快照类配置。</block>
  <block id="7e68821a0b00ad66c94a5fa7b047fc36" category="list-text">在集群上部署PostgreSQL应用程序。</block>
  <block id="373318637d0909025d357ebb9cf844c0" category="list-text">创建数据库并添加记录。</block>
  <block id="6923c850b179787ae20741ac2da32a53" category="list-text">将集群添加到ACS中。</block>
  <block id="76827e03d5e6d5ac048a5177e18ad144" category="list-text">在ACS中定义应用程序。</block>
  <block id="bf3e8a582d777e7e4a4d17be1def01a0" category="list-text">使用ACS创建快照。</block>
  <block id="99b7da0ca39d7f2a015829c2ae6e1b15" category="list-text">删除PostgreSQL应用程序中的数据库。</block>
  <block id="ff472a20f1aad06904e323a536e2eb80" category="list-text">使用ACS从快照还原。</block>
  <block id="a795bae8ecd08ce83200e5ec3177acee" category="list-text">验证您的应用程序是否已从快照中还原。</block>
  <block id="0a3f91bec2fbb2d145638ee7f14c108b" category="section-title">**1.创建管理员用户并登录到群集**</block>
  <block id="4e3a8a5d5f66fd9fc9a976f4241338af" category="paragraph">使用以下命令创建管理员用户以访问ROSA集群：(只有在安装时未创建管理员用户时、才需要创建管理员用户)</block>
  <block id="25ee9c81495a3a98ecf40dff27da6c1d" category="paragraph"><block ref="aefcb05bda304d0dd039ce44ec039e5e" prefix="" category="inline-code"></block></block>
  <block id="f60a1c409fe0a27f22ddfa9c96fb2466" category="paragraph">此命令将提供如下输出。使用登录到集群<block ref="a9902f312ee813dfa0df20ecdd92cbfa" prefix=" " category="inline-code"></block> 命令。</block>
  <block id="01e9485a97f379eebc1941d265f8d05a" category="paragraph"><block ref="01e9485a97f379eebc1941d265f8d05a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03c52bbd6e1432956772bd1b77ca8540" category="admonition">您也可以使用令牌登录到集群。如果您在创建集群时已创建管理员用户、则可以使用管理员用户凭据从Red Hat OpenShift Hybrid Cloud控制台登录到集群。然后、通过单击右上角显示已登录用户名称的、您可以获取<block ref="a9902f312ee813dfa0df20ecdd92cbfa" prefix=" " category="inline-code"></block> 命令(令牌登录)。</block>
  <block id="da82003ccd337703657b4d5043f7b127" category="section-title">**2.为群集**创建kubeconfig*文件</block>
  <block id="dd97d9a0156710665d9a4b0ed3dbf2be" category="paragraph">按照步骤进行操作 <block ref="442330295b75a08b4add8fd36a48c8ea" category="inline-link-macro-rx"></block> 为ROSA集群创建kubeconfig.稍后在将集群添加到ACS中时、将使用此kubeconfig.文件。</block>
  <block id="80eae2f21ccc18edb27b82a3c015e4aa" category="section-title">**3.在群集上安装Asta Trdent **</block>
  <block id="ff384b8fd58939cbc5a0b01b7553fd43" category="paragraph">在ROSA集群上安装Asta Trident (最新版本)。要执行此操作、您可以按照给定的任一过程进行操作 <block ref="4a2b27d6d4bc3dd7ae85bfd131d50753" category="inline-link-macro-rx"></block>。要从集群控制台使用Helm安装Trident、请先创建一个名为Trident的项目。</block>
  <block id="5cb42da3b2d3dd848285fd2dceb88455" category="paragraph"><block ref="5cb42da3b2d3dd848285fd2dceb88455" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d6229020f19bf2c0f6c87406d8ce99" category="paragraph">然后、在"开发工具"视图中、创建Helm图表存储库。对于URL字段、请使用<block ref="20183aea3d2da33700b394e01c04c185" prefix=" " category="inline-code"></block>。然后为三端操作员创建舵版本。</block>
  <block id="755006051acaf94196661f7923f0474a" category="paragraph"><block ref="02e0c37c72a536f86ea1821d5f0b40a9" category="inline-image-macro-rx" type="image"></block>
<block ref="02fbe0a7ae321826af934bafa8e91e0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fbaa2d031fe22ec90eeb4eab3182e2ac" category="paragraph">返回控制台上的"Administrator view"(管理员视图)、然后在三级工程中选择Pod、以验证所有三级工程模块是否正在运行。</block>
  <block id="fff4dc90fd7dcd0428896700f3219ca4" category="paragraph"><block ref="fff4dc90fd7dcd0428896700f3219ca4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13f2afc5c2dcacd63d06c728337c30af" category="section-title">**4.使用三端CSI配置程序**创建后端、存储类和快照类配置</block>
  <block id="3721d2fc71eb71c5c48649880c7691bf" category="paragraph">使用下面显示的YAML文件创建三元后端对象、存储类对象和卷快照对象。请务必为您创建的Amazon FSx for NetApp ONTAP文件系统提供凭据、并在后端的YAML配置中提供管理LIF和文件系统的Vserver名称。要获取这些详细信息、请转到适用于Amazon FSx的AWS控制台并选择文件系统、然后导航到管理选项卡。此外、单击更新以设置的密码<block ref="679500f227997b45be97e3ca8115c678" prefix=" " category="inline-code"></block> 用户。</block>
  <block id="8535923874d0b7a58a93ff4527cb2572" category="admonition">您可以使用命令行创建对象、也可以从混合云控制台使用YAML文件创建对象。</block>
  <block id="7f74cd03d9b7c8fc87adbe0fcdd81351" category="paragraph"><block ref="7f74cd03d9b7c8fc87adbe0fcdd81351" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59122b849c35681f88e25b2cd4c16e23" category="paragraph">**Trident后端配置**</block>
  <block id="cb6d16d1a0ec12524c8a26a623080f31" category="paragraph">**存储类**</block>
  <block id="3c2ea64a4125f56cee84a1db41ffd2f7" category="paragraph">**快照类**</block>
  <block id="096893ffbe489ff9365c6d0f50668e7c" category="paragraph">发出下面所示的命令、验证是否已创建后端、存储类和trdent-snapshotclass对象。</block>
  <block id="440a9a438f9cce9394792d52629caa63" category="paragraph"><block ref="440a9a438f9cce9394792d52629caa63" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9430cd2c476ef4b987a050e26d03000f" category="paragraph">此时、您需要进行的一项重要修改是将ONTAP NAS设置为默认存储类、而不是GP3、以便您稍后部署的PostgreSQL应用程序可以使用默认存储类。在集群的OpenShift控制台中、在"Storage"下选择"StorageClasses"。将当前默认类的标注编辑为false、并将ONTAP NAS存储类的标注storageclass.Kubernetes.io/is-default-class设置为true。</block>
  <block id="3bdb1b8b53e7a9ac42ee9838ac712bc8" category="paragraph"><block ref="3bdb1b8b53e7a9ac42ee9838ac712bc8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75dc080ce0f898e99130f0b3644e9d77" category="paragraph"><block ref="75dc080ce0f898e99130f0b3644e9d77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d37c1822f1602c399a626ae694dbf8ee" category="section-title">**5.在群集上部署PostgreSQL应用程序**</block>
  <block id="9849f155acac1c5d527130295c617745" category="paragraph">您可以从命令行部署此应用程序、如下所示：</block>
  <block id="14153a7fe9b305b3d6594136d6cbd76e" category="paragraph"><block ref="5cda9633b40969705c2d463d9fac411d" prefix="" category="inline-code"></block></block>
  <block id="f0665a49317e959dc150a2ebddabe631" category="paragraph"><block ref="f0665a49317e959dc150a2ebddabe631" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab01f84d3512141e55a0035b8cd4914c" category="admonition">如果您看不到应用程序Pod正在运行、则可能是由于安全上下文约束而导致错误。
<block ref="777306d8cda1b533446b5e961ae1412f" category="inline-image-macro-rx" type="image"></block>
编辑以修复此错误<block ref="e70b97e1fe755b3b63eee3148167d06a" prefix=" " category="inline-code"></block> 和<block ref="c7a6c0ee60c6f68dfe700feaacf15703" prefix=" " category="inline-code"></block> 中的字段<block ref="bb2413f7c1896a1256ce050cb9d3c35c" prefix=" " category="inline-code"></block> 具有的输出中的_id的对象<block ref="9254bbe15d1b0e04ead746e78900f19e" prefix=" " category="inline-code"></block> 命令、如下所示。
<block ref="d8149d6359e97d140ab7f84f5b5238e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4133913addf4da6a9cc67e80c9318fd3" category="paragraph">PostgreSQL应用程序应正在运行、并使用Amazon FSx支持的永久性卷作为NetApp ONTAP存储。</block>
  <block id="6f38a4eb8e2bb438a090e469844c2656" category="paragraph"><block ref="6f38a4eb8e2bb438a090e469844c2656" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f32c780aa5389ad7df8c72717d10ae3f" category="paragraph"><block ref="f32c780aa5389ad7df8c72717d10ae3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c69f86a70efe7305c65ff1d6340bcbd" category="section-title">**6.创建数据库并添加记录**</block>
  <block id="73472324290d0ff0a1b449226491194c" category="paragraph"><block ref="73472324290d0ff0a1b449226491194c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d6dddc1bca3e6d90fdb148e26c32c4b" category="section-title">**7.将集群添加到ACs**中</block>
  <block id="4a6182a7ba7174ab2779d387dff86a36" category="paragraph">登录到ACS。选择cluster、然后单击Add。选择其他并上传或粘贴kubeconfig.</block>
  <block id="d4c542567c0365471f2b24c9629b0ca4" category="paragraph"><block ref="d4c542567c0365471f2b24c9629b0ca4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b905de46f0f090636c93c358d1bf512d" category="paragraph">单击*Next*并选择ONTAP－NAS作为ACS的默认存储类。单击*Next*(下一步*)，查看详细信息，然后单击*Add*(添加)群集。</block>
  <block id="29769e926dc686d9bee4643e06f02c25" category="paragraph"><block ref="29769e926dc686d9bee4643e06f02c25" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c22a664581f98929897ef8da6e94435" category="section-title">**8.在ACs**中定义应用程序</block>
  <block id="b2926c8eedc2da993a395c1f95032e0a" category="paragraph">在ACS中定义PostgreSQL应用程序。在登录页面中，选择*Applications*、*Define*并填写相应的详细信息。单击“*下一步*”几次，查看详细信息，然后单击“*定义*”。应用程序将添加到ACS。</block>
  <block id="99eaeeaa339c117cf0b288606e4ec627" category="section-title">**9.使用ACs**创建快照</block>
  <block id="4a0e0784bcd96d89e8f11679f9ed73dd" category="paragraph">可通过多种方法在ACS中创建快照。您可以从显示应用程序详细信息的页面中选择应用程序并创建快照。您可以单击创建快照来创建按需快照或配置保护策略。</block>
  <block id="d5acd48af1c6d310e4cb02f8f565c19f" category="paragraph">只需单击*创建快照*、提供名称、查看详细信息并单击*快照*、即可创建按需快照。操作完成后、快照状态将更改为"运行状况良好"。</block>
  <block id="f8c045ff74a98ecb419e1c7d2f4656b4" category="paragraph"><block ref="f8c045ff74a98ecb419e1c7d2f4656b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dad69cf86f54ffa6a676f056c8922549" category="paragraph"><block ref="dad69cf86f54ffa6a676f056c8922549" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ffd9fa793ba4244940afbe9b5de8959a" category="section-title">**10.删除PostgreSQL应用程序中的数据库**</block>
  <block id="dca0d4c6836bb6f907d9bcc880ce7b73" category="paragraph">重新登录到PostgreSQL、列出可用数据库、删除先前创建的数据库并重新列出、以确保数据库已被删除。</block>
  <block id="8fc31abb8f9b32dd12c55899d4923754" category="paragraph"><block ref="8fc31abb8f9b32dd12c55899d4923754" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21e4e8e2ffcd028f468c54e319969a1a" category="section-title">**11.使用ACs**从快照恢复</block>
  <block id="637869fd9fa9d9d4a9353f836480096c" category="paragraph">要从快照还原应用程序、请转到ACS UI登录页面、选择应用程序、然后选择还原。您需要选择要从中还原的快照或备份。(通常、您会根据所配置的策略创建多个)。在接下来的几个屏幕中做出适当的选择，然后单击*Restore*。从快照还原后、应用程序状态将从还原变为可用。</block>
  <block id="4c989fb106d4c7ab2e4542add9732a43" category="paragraph"><block ref="4c989fb106d4c7ab2e4542add9732a43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5dcb664c59022883e81f189ae7b757dd" category="paragraph"><block ref="5dcb664c59022883e81f189ae7b757dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27463305443c0a856ccaf3fc0aebe935" category="paragraph"><block ref="27463305443c0a856ccaf3fc0aebe935" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca420b4563e97c29e3b846aa3bc4d627" category="section-title">**12.验证您的应用程序是否已从快照中恢复**</block>
  <block id="0ae87dfe21efbb4555334e2467ecf6a2" category="paragraph">登录到PostgreSQL客户端、您现在应该可以看到表以及以前的表中的记录。  就是这样。只需单击一个按钮、您的应用程序便已恢复到先前的状态。这就是我们使用Astra Control为客户实现的简单体验。</block>
  <block id="c4b7e4476f0c1295b7ad2b84095afbb7" category="paragraph"><block ref="c4b7e4476f0c1295b7ad2b84095afbb7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63864fe27243a67429a0ee731461c1fd" category="sidebar">将VM从VMware迁移到OpenShift虚拟化</block>
  <block id="622b235a9123d972c612737c81eb55a1" category="doc">NetApp和VMware的NFSv3 nConnect功能</block>
  <block id="922214eccd42dc7249f715ccfe0f66fd" category="paragraph">从VMware vSphere 8.0 U1 (作为技术预览版)开始、nconnect功能可为NFS v3数据存储库卷实现多个TCP连接、从而提高吞吐量。  使用NFS版本3数据存储库的客户现在可以增加与NFS服务器的连接数、从而最大程度地提高高速网络接口卡的利用率。</block>
  <block id="2f5a0a2f5bc09f02ff2874d6f119ce71" category="inline-link-macro">VMware vSphere 8.0 Update 2发行说明</block>
  <block id="a780007c9fc76074a8010f3e0baef2ef" category="admonition">8.0 U2通常提供此功能、请参阅上的存储部分 <block ref="b47acafec9d9ecdb185067327510996c" category="inline-link-macro-rx"></block></block>
  <block id="029dffdb3a47e8a7b61eefb05272f3b6" category="list-text">在同一主机上为每个NFS数据存储库托管更多虚拟机。</block>
  <block id="c9c3ecb745a906eed9c9dc66bce091b2" category="list-text">提高NFS数据存储库性能。</block>
  <block id="e2d5091735d8049dbac491b96e7800e3" category="list-text">提供一个选项、以便为基于虚拟机和容器的应用程序提供更高级别的服务。</block>
  <block id="52eb43485175b27d516a58a137af2d9a" category="section-title">技术详细信息</block>
  <block id="456bb25eb1c4cc4d1d3167077db63dc3" category="inline-link-macro">NFS最佳实践和实施指南</block>
  <block id="80fbff02df105327c999a32ee770abbd" category="paragraph">nconnect的目的是为vSphere主机上的每个NFS数据存储库提供多个TCP连接。这有助于提高NFS数据存储库的并行处理能力和性能。  在ONTAP中、建立NFS挂载后、系统将创建连接ID (CID)。该CID可提供多达128个并发传输中操作。当客户端超过该数量时、ONTAP会启用一种流量控制形式、直到其他操作完成后、它可以释放一些可用资源为止。这些暂停通常只需几微秒、但在数百万次操作过程中、这些操作会累加并造成性能问题。nConnect可以采用128个限制、并将其乘以客户端上的nconnect会话数、这样每个CID可提供更多并发操作、并可能增加性能优势。有关更多详细信息、请参见 <block ref="2286147d95e2b48568ae4e520e809846" category="inline-link-macro-rx"></block></block>
  <block id="a117913f518b234647a8b383734ba750" category="section-title">默认NFSv3数据存储库</block>
  <block id="5362dc6cc8a918b056c07a887b52e3bd" category="paragraph">为了解决NFS数据存储库单个连接的性能限制、需要挂载更多数据存储库或添加更多主机来增加连接。</block>
  <block id="147d27fd2004a0ec68674942c780aa9a" category="image-alt">不具有nconnect功能的NFSv3数据存储库</block>
  <block id="debf3a3ee7d6a6155b69615056e5ce4b" category="section-title">使用nConnect NFSv3数据存储库</block>
  <block id="2ff2577b7287e07a33b1e780f8b40120" category="paragraph">使用ONTAP工具或其他选项创建NFS数据存储库后、可以使用vSphere命令行界面、PowerCLI、政府工具或其他API选项修改每个NFSv3数据存储库的连接数。为了避免与vMotion同时出现性能问题、请在属于vSphere集群的所有vSphere主机上保持NFS数据存储库的连接数不变。</block>
  <block id="dba363f6b127a7aeb65476b3b3edb346" category="image-alt">启用了nconnect功能的NFSv3数据存储库</block>
  <block id="5aa0dfe1002dfe6bce0026bf5a097872" category="section-title">前提条件</block>
  <block id="d7d014eeaf77806f8ad332d6854a67d8" category="paragraph">要使用nconnect功能、应满足以下依赖关系。</block>
  <block id="e8467e9b509c4924668c01eb7ab2adde" category="cell">ONTAP 版本</block>
  <block id="cd88f82366c9681ae528ea72ce607479" category="cell">vSphere版本</block>
  <block id="8413c683b4b27cc3f4dbd4c90329d8ba" category="cell">注释</block>
  <block id="9d00c1626c7c0d2a2cd78a53a717750f" category="cell">9.8或更高版本</block>
  <block id="eb0c9cc2c6a76a4089f51a287dd39018" category="cell">8更新版本1</block>
  <block id="e1d5cb4dfc779ae2355a88e6a3f38365" category="cell">技术预览、可选择增加连接数。</block>
  <block id="9b89481f1fd15e1e95aeaa045da8b998" category="cell">8更新版本2</block>
  <block id="7d1a33e2cd7619ca1e16a100c756f5b0" category="cell">通常可选择增加和减少连接数。</block>
  <block id="a3ea8d7f45af50751b41f8125b9a7129" category="section-title">更新与NFS数据存储库的连接数</block>
  <block id="92e68741358a011ae3df1c44bf7d4c35" category="paragraph">如果使用ONTAP工具或vCenter创建NFS数据存储库、则会使用单个TCP连接。要增加连接数、可以使用vSphere CLI。参考命令如下所示。</block>
  <block id="c7d92ab621306068cc4168881ed2f1ed" category="paragraph">或使用如下所示的PowerCLI</block>
  <block id="e80a22c5f59287fb8f804bd0a2e09455" category="paragraph">以下是增加与政府工具的连接数的示例。</block>
  <block id="50b0980875a7cd34545a5c01a4398252" category="inline-link-macro">VMware知识库文章91497</block>
  <block id="3ba5ed93588ff7ccc7888bd1cba3cdc7" category="paragraph">请参见 <block ref="fbb4155d7308fecba08eb8bea19301a0" category="inline-link-macro-rx"></block> 有关详细信息 ...</block>
  <block id="224bf8a6dd71d9cf8a138d3b25a8d716" category="paragraph">ONTAP支持的最大连接数取决于存储平台型号。查找上的exec_ctx <block ref="2286147d95e2b48568ae4e520e809846" category="inline-link-macro-rx"></block> 有关详细信息 ...</block>
  <block id="afd75162084fb9f067c0d9f408ee61ed" category="inline-link-macro">VMware知识库文章91481.</block>
  <block id="3a516056fd5d0047684222dc0a7805ae" category="paragraph">随着每个NFSv3数据存储库的连接数的增加、可挂载到该vSphere主机上的NFS数据存储库数量也会减少。每个vSphere主机支持的连接总数为256。检查 <block ref="d75d1c1247a51175ceaa5837dc1dae33" category="inline-link-macro-rx"></block> 每个vSphere主机的数据存储库限制。</block>
  <block id="3689679bbefbc2ba446cce4674849fa3" category="admonition">VVOV数据存储库不支持nConnect功能。但是、协议端点会计入连接限制。创建VVOV数据存储库时、系统会为SVM的每个数据lf创建一个协议端点。</block>
  <block id="6fe78fbb29bed287952ede829b7529d4" category="sidebar">nConnect功能与NetApp和VMware结合使用</block>
  <block id="46c4d9bfa1c229940459326940489ab0" category="inline-link">适用于 VMware vSphere 的 ONTAP 工具文档</block>
  <block id="29c47efbd8bbf63e61c46ec3cdc0b75a" category="paragraph">有关适用于VMware的NetApp ONTAP工具的详细信息、请参见<block ref="20b60c31d47f743ee9878127e24d7f6c" category="inline-link-rx"></block>。</block>
  <block id="a85dadcd951e9bebb0adc5c488afcd45" category="list-text">在ONTAP工具中创建一个虚拟卷数据存储库。</block>
  <block id="a3ac4ecc74a6b0ee53f6bb96ea0ba893" category="list-text">在VVOV数据存储库上创建新虚拟机。</block>
  <block id="8b79830a0101dcf4e323b785f8162808" category="paragraph">近20年来、NetApp ONTAP软件已成为VMware vSphere环境中的首要存储解决方案、并不断推出创新功能来简化管理并降低成本。NetApp是NAS和统一存储平台开发领域的公认领导者、这些平台可提供广泛的协议和连接支持。除了这一细分市场之外、还有许多客户更喜欢基于块的SAN存储平台的精简性和成本优势、这些平台专注于出色地完成一项工作。NetApp的全闪存SAN阵列(ASA)凭借大规模精简性以及适用于所有应用程序和云提供商的一致管理和自动化功能、兑现了这一承诺。</block>
  <block id="d9da6c2a7de58f678321e8645884a4c7" category="paragraph">在本文档中、我们将介绍将NetApp ASA存储系统与VMware vSphere结合使用的独特价值、并对NetApp全闪存SAN阵列进行技术概述。此外、我们还将了解其他工具、以简化VMware和ONTAP数据中心的存储配置、数据保护和监控。</block>
  <block id="021c111410060ac655a707029dd278a7" category="paragraph">本文档的部署部分介绍了如何使用适用于VMware vSphere的ONTAP工具创建VVOV数据存储库、以及如何使用NetApp Cloud Insights观察现代数据中心。</block>
  <block id="574bee4cc8ebe398e103e2a02c1ab460" category="paragraph">有关详细信息、请参见博客、<block ref="6c0e9abec6dc681507978a831ea0e777" category="inline-link-rx"></block>。</block>
  <block id="a846eb98bc1cde598651dd6e83c67dbe" category="paragraph">vvol是vSphere集群中一种全新的存储管理方法、可简化管理并更精细地控制存储资源。在vVol数据存储库中、每个虚拟磁盘都是一个vVol、并成为存储系统上的本机LUN对象。存储系统和vSphere通过* VMware API for Storage AWAREIVAIVE(VASA)*提供程序进行集成，使存储系统能够识别VM数据并对其进行相应的管理。vCenter Client中定义的存储策略用于分配和管理存储资源。</block>
  <block id="e2e58b8de23019071fea5cee3b65927c" category="paragraph">有关采用BlueXP的3-2-1备份策略的详细信息、请访问<block ref="03d75d8eabdbf0203a534d12a18ae5b7" category="inline-link-rx"></block>。</block>
  <block id="6d5fb8ff3bb6388cfbd3f38fc9e6515e" category="cell">2024年3月4日</block>
  <block id="c0d6f3125de2225f0b83f6051f4afadd" category="cell">新TR-4990：《在ANF上使用增量合并快速恢复Oracle VLDB》</block>
  <block id="0f07773d1d3bbe9fd494333211f6feaa" category="cell">1.28</block>
  <block id="4e9b156e7e2788c8cd4b0877fd922657" category="cell">24.02.</block>
  <block id="ab7854373386a8b1e9ba4f90bfee6e0a" category="paragraph">VMware上的Anthos集群可以根据客户的选择部署到vSphere 7和8环境中、以帮助匹配其当前的数据中心基础架构。</block>
  <block id="0c008dad767075dab996c133e44d5d2f" category="cell">vCenter</block>
  <block id="33fe6d8f3148d10c2ff7ce3ff095dd41" category="cell">8.0.1</block>
  <block id="50ce33a86e6915635518e9752cf0a12f" category="cell">24.02.0</block>
  <block id="d5be180cffbcebeed45fc66b922620ec" category="paragraph"><block ref="d5be180cffbcebeed45fc66b922620ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="300ff7c5525219cf0316ee35285ce086" category="summary">解决方案提供了有关快速恢复在Azure NetApp Files容量池上使用NFS挂载部署到Azure VM计算实例的Oracle VLDB的概述和详细信息、以暂存备用数据库副本、该副本将通过RMAN不断进行增量合并。</block>
  <block id="af9bda0d447d00102cfa07c616299ce9" category="doc">TR-4990：《使用ANF上的增量合并快速恢复Oracle VLDB》</block>
  <block id="36c33b5f7d9b9effb307d69b5d9bbfcd" category="paragraph">如果您对VLDB的SLA非常感兴趣、并考虑将Oracle数据库迁移到Azure等公共云、则可以使用Microsoft Azure NetApp Files (ANF)等资源设置类似的数据库保护结构、以便暂存备用数据库映像副本。在本文档中、我们将演示如何从ANF容量池配置和导出NFS文件系统、以便挂载到Oracle数据库服务器上、暂存备用数据库副本、以便在主存储发生故障时快速恢复。</block>
  <block id="7c743caa66583893abbd5fd02fcd8c44" category="list-text">Oracle VLDB映像副本通过RMAN在Microsoft ANF容量池存储以外的NFS挂载点上进行增量合并。</block>
  <block id="c7b169899b3bf3e517397a1e66b1f9ba" category="list-text">在同一Azure数据库服务器VM发生故障时快速恢复Oracle VLDB。</block>
  <block id="3ddf9d0387ffbe57231793a1a3a59444" category="list-text">在备用Azure数据库服务器VM发生故障时快速恢复Oracle VLDB。</block>
  <block id="96f297eca8d0059e7b41d63cbfa46bb8" category="list-text">在Azure中通过RMAN设置Oracle VLDB映像副本增量合并以加快数据库恢复的数据库提供商。</block>
  <block id="86cc76cfb1ceaac3aaa0bace96f788de" category="list-text">在Azure公共云中测试Oracle工作负载的数据库解决方案架构师。</block>
  <block id="a92ab2bd86f06e76dca598f233e87f33" category="list-text">负责管理部署到ANF容量池存储的Oracle数据库的存储管理员。</block>
  <block id="96ffa3242f6ce78c662078c986d2dd13" category="list-text">希望在Azure云环境中设置Oracle数据库的应用程序所有者。</block>
  <block id="c9d052a026f163663b788c2146e65703" category="paragraph">此解决方案的测试和验证是在Microsoft ANF容量池存储和Azure VM计算环境中执行的、这些环境可能与最终部署环境不匹配。有关详细信息，请参见一节 <block ref="8ea96e516bccf9a47ca2d74131eb7519" category="inline-xref-macro-rx"></block>。</block>
  <block id="df5be9cce2556109a991648585423150" category="image-alt">此图详细展示了使用ANF在Azure公共云中实施的Oracle VLDB增量合并。</block>
  <block id="952ad133c322e6ea15c7668391a420d8" category="cell">ANF存储</block>
  <block id="85dec17e5aae8074e9cc2265ba72e4f3" category="cell">Microsoft提供的当前版本</block>
  <block id="16f2328b190976509986f33db9227d85" category="cell">具有高级服务级别的2 TiB ANF容量池存储</block>
  <block id="6d06f0bd5a2f3059a22e9257d7c1a905" category="cell">2个VM、一个用作主数据库服务器、另一个用作备用</block>
  <block id="2e705b831fd1a05f9ff862ccde72a99f" category="list-text">*用于RMAN增量合并的Oracle VLDB存储布局。*在我们的测试和验证中、用于Oracle增量备份和合并的NFS卷是从一个ANF容量池中分配的、该容量池每个卷具有100 TiB的容量限制、总容量限制为1000 TiB。对于超过阈值的部署、可以将多个卷和ANF容量池与多个NFS挂载点并行连接、以提供更高的容量。</block>
  <block id="fa44cff8a0d3a1bde3e39afbd57dc266" category="list-text">*使用RMAN增量合并的Oracle可恢复性。* RMAN增量备份和合并通常根据RTO和RPO目标以用户定义的频率执行。如果主数据存储和/或归档日志完全丢失、则可能会发生数据丢失。Oracle数据库可以恢复到ANF数据库备份映像副本提供的最后一次增量备份。为了最大限度地减少数据丢失、可以在ANF NFS挂载点上设置Oracle闪存恢复区域、并将归档日志与数据库映像副本一起备份到ANF NFS挂载。</block>
  <block id="30de34c3a06eca8594944e005f614d80" category="list-text">*在ANF NFS文件系统之外运行Oracle VLDB。*与用于数据库备份的其他批量存储不同、Microsoft ANF是支持云的生产级存储、可提供高级别的性能和存储效率。Oracle VLDB从主存储切换到ANF NFS文件系统上的映像副本后、可以在解决主存储故障的同时保持较高的数据库性能。您可以放心地知道、主存储故障不会影响用户应用程序体验。</block>
  <block id="98ba9c7927b5d14764e8115588d2d54d" category="list-text">* Azure计算实例。*在这些测试和验证中、我们使用Standard"标准B4ms Azure VM作为Oracle数据库服务器。还有其他Azure VM可能已经过优化、更适合数据库工作负载。此外、您还需要根据实际工作负载要求、根据vCPU数量和RAM量相应地调整Azure VM的大小。</block>
  <block id="f09ca0335aec5f261a1b868e570f0505" category="list-text">* ANF容量池服务级别。* ANF容量池提供三种服务级别：标准、高级、超级。默认情况下、自动QoS会对容量池中创建的卷执行适用场景操作、从而限制卷上的吞吐量。可以根据容量池大小和服务级别手动调整卷上的吞吐量。</block>
  <block id="4d189a9c9e5d55cc3a34938358e133d3" category="list-text">*DNFS配置。* DNFS内置在Oracle内核中、众所周知、在将Oracle部署到NFS存储时、它可以显著提高Oracle数据库性能。DNFS打包到Oracle二进制文件中、但默认情况下不启用。对于NFS上的任何Oracle数据库部署、都应启用此功能。对于VLDB的多个ANF容量池部署、应正确配置指向不同ANF容量池存储的DNFS多路径。</block>
  <block id="5ae994fde73945264c47ce48647d57b2" category="paragraph">我们假定您已将Oracle VLDB部署在VNet中的Azure云环境中。如果您需要有关在Azure中部署Oracle的帮助、请参阅以下技术报告以获取帮助。</block>
  <block id="0f9ba0e2eb61f2970cc50a6cb6799a08" category="list-text"><block ref="0f9ba0e2eb61f2970cc50a6cb6799a08" category="inline-link-macro-rx"></block></block>
  <block id="3870968819bfb321072190bbe14d9870" category="list-text"><block ref="3870968819bfb321072190bbe14d9870" category="inline-link-macro-rx"></block></block>
  <block id="a3f00a7e147e7b84aa2b711174f65541" category="paragraph">Oracle VLDB可以运行在ANF存储上、也可以运行在Azure云生态系统中的任何其他可选存储上。下一节介绍了为Oracle VLDB的映像副本设置RMAN增量合并的分步部署过程、该副本暂存在ANF存储的NFS挂载中。</block>
  <block id="dda1820cbe40a6a04b7c08135677cb5f" category="list-text">已设置Azure帐户、并且已在Azure帐户中创建必要的Azure vNet和网段。</block>
  <block id="ee50869919154f8e0bb1c9a79b0e68bf" category="inline-link-macro">Azure虚拟机系列</block>
  <block id="12b67dd937a6aa2aac9654fe14c80158" category="list-text">从Azure门户控制台中、您必须部署两个Azure VM实例、一个用作主Oracle数据库服务器、另一个用作可选备用数据库服务器。有关环境设置的详细信息、请参见上一节中的架构图。另请查看 <block ref="0bcbff73d1e13f874b4c63b6603f9a12" category="inline-link-macro-rx"></block> 有关详细信息 ...</block>
  <block id="2439b2fcc93766c923093f1c217cff51" category="list-text">从Azure门户控制台中、部署ANF存储以托管用于存储Oracle数据库备用映像副本的NFS卷。如果您不熟悉ANF的部署、请参见文档 <block ref="1bbe5611068f9dda0e0123e846af8b8b" category="inline-link-macro-rx"></block> 了解分步说明。</block>
  <block id="c78f04ded81296476b99e27cfcf8b81e" category="admonition">确保您已在Azure VM根卷中至少分配128 G、以便有足够的空间来暂存Oracle安装文件。</block>
  <block id="57ce3e90b99a309ad26ec73de2896ff9" category="section-title">配置和导出要挂载到Oracle主VLDB服务器上的NFS卷</block>
  <block id="48e63302f12330ed309d536a92b3ff3d" category="paragraph">在本节中、我们将介绍通过Azure门户控制台从ANF容量池配置NFS卷。如果设置了多个ANF容量池来容纳数据库的大小、请对其他ANF容量池重复上述过程。</block>
  <block id="edc598e26c4191781ff6fb9a427f3e26" category="list-text">首先、从Azure门户控制台导航到用于暂存Oracle VLDB映像副本的ANF容量池。</block>
  <block id="db13e5cf484d3e563e6a6313426b51c3" category="image-alt">此图提供了使用Azure门户控制台的ANF卷配置屏幕</block>
  <block id="e5ba92870c86eabfee4cc4cc8bd42317" category="list-text">从选定容量池-<block ref="11e0eed8d3696c0a632f822df385ab3c" prefix=" " category="inline-code"></block>下、单击<block ref="c6f01c78bfe0a0a495cb5d3ed77824a9" prefix=" " category="inline-code"></block> 然后、<block ref="da20d395d0cd59983278111b9c95d6c3" prefix=" " category="inline-code"></block> 以启动添加卷工作流。</block>
  <block id="1318d277156dfc7ca8b396a8bacab47d" category="list-text">填写<block ref="7ffce295d6c61cb38fd76a4e505cdb33" prefix=" " category="inline-code"></block>，<block ref="d2d5c3e087f684e56b5b81d6212d7ccb" prefix=" " category="inline-code"></block>，<block ref="bf76cafc47141522dca89c4d6e25b822" prefix=" " category="inline-code"></block>，和<block ref="48d32046f376779858d068d73d85f80e" prefix=" " category="inline-code"></block> 移动到<block ref="888a77f5ac0748b6c8001822417df8b6" prefix=" " category="inline-code"></block> 页面。</block>
  <block id="6ca80750436bdab142d2e43cd1ef42cf" category="list-text">记下文件路径、输入允许的客户端CIDR范围、然后启用<block ref="677c422f11e77a5df1d44e4f6c517954" prefix=" " category="inline-code"></block> 卷。</block>
  <block id="3df3ccf0cba7ad3be7d9143f84d067b4" category="list-text">根据需要添加卷标记。</block>
  <block id="427d09585c379ab8f0af7219a6cac2a1" category="list-text">查看并创建卷。</block>
  <block id="d0f312ff08c789fc7e37000b9637b9c6" category="list-text">以具有sudo权限的用户身份登录到主Oracle VLDB服务器、然后挂载从ANF存储导出的NFS卷。根据需要更改ANF NFS服务器IP地址和文件路径。可以从ANF卷控制台页面检索ANF NFS服务器IP地址。</block>
  <block id="73304323457935ed833c76e67c23f068" category="section-title">将Oracle RMAN增量合并设置为ANF上的映像副本</block>
  <block id="ec95b19db84d374be749fe05dbb34147" category="list-text">以Oracle用户身份登录到主Oracle VLDB服务器。</block>
  <block id="9466e78eda574ac1c2b0373b37e691eb" category="list-text">在挂载点/nfsanf下创建oracopy目录、用于存储Oracle闪存恢复区域的Oracle数据文件映像副本和归档日志目录。</block>
  <block id="94c15d2a6c277de2e60033355a135ffd" category="list-text">通过sqlplus登录到Oracle数据库、启用块更改跟踪以加快增量备份、如果Oracle闪存恢复区域当前位于主存储上、则将其更改为ANF NFS挂载。这样可以将RMAN默认控制文件/spfile自动备份和归档日志备份到ANF NFS挂载以进行恢复。</block>
  <block id="d15e02bf0c54e008af2e8212aa7c7d4f" category="paragraph">预期输出：</block>
  <block id="fb6dc8561460f909af465eb0cfcfd84d" category="list-text">在主Oracle VLDB服务器上、以Oracle用户身份本地登录到RMAN、无论是否具有RMAN目录。在此演示中、我们不会连接到RMAN目录。</block>
  <block id="c937bbcfc1739e03f02ce386195ec2fc" category="list-text">在备份后列出数据库映像副本、以观察是否已在ANF NFS挂载点中创建数据库映像副本。</block>
  <block id="7d3185dbec5bee3286899aa1908bdbc4" category="list-text">通过Oracle RMAN命令提示符报告架构、以观察当前VLDB数据文件是否位于主存储上。</block>
  <block id="0c6f3c70d69fdbc10889c0bf3d54d400" category="paragraph">至此、Oracle VLDB备用映像副本备份和合并的设置完成。</block>
  <block id="1afaba9f41e3dd6015389dd6a151412d" category="section-title">将Oracle VLDB切换到映像副本、以便快速恢复</block>
  <block id="dfba912cd166af4cfe8896146ef629da" category="paragraph">如果因主存储问题描述发生故障(例如数据丢失或损坏)、则可以快速将数据库切换到ANF NFS挂载上的映像副本、并将其恢复到当前状态、而无需还原数据库。消除介质还原可显著加快VLDB的数据库恢复速度。此使用情形假定Oracle VLDB数据库服务器完好无损、并且数据库控制文件、归档日志和当前日志均可用于恢复。</block>
  <block id="15f67ba350e31e49f6aac9b603305228" category="list-text">在切换之前、以Oracle用户身份登录到Azure主VLDB服务器主机并创建测试表。</block>
  <block id="dce3cc3b84024400ca1056239e416340" category="list-text">在恢复后从sqlplus检查数据库结构、观察所有VLDB数据文件(控制、临时和当前日志文件除外)现在都已切换到ANF NFS文件系统上的副本。</block>
  <block id="bab07f680481d370684c7c7bb3717bae" category="list-text">从SQL plus中、检查切换到复制之前插入的测试表的内容。</block>
  <block id="26644cbe4753a4ade8012d2ba03e81e4" category="list-text">您可以在ANF NFS挂载中长时间运行Oracle VLDB、同时保持预期的性能级别。修复主存储问题描述后、您可以通过反转增量备份合并过程并将停机时间降至最低来回滚到该主存储LUN。</block>
  <block id="5a00ad02f147850c7af23fdfd27e0eaa" category="section-title">从映像副本到备用数据库服务器的Oracle VLDB恢复</block>
  <block id="17296cbb22286362e179c848e8e57295" category="paragraph">如果发生故障、并且主存储和主数据库服务器主机均丢失、则无法从原始服务器执行恢复。但是、ANF NFS文件系统上提供的Oracle数据库备份映像副本非常方便。您可以使用备份映像副本将主数据库快速恢复到备用数据库服务器(如果有)。在本节中、我们将展示此类恢复的分步过程。</block>
  <block id="6936d296c2b811c489aca0e32d359fcd" category="list-text">插入一行以测试我们之前为Oracle VLDB还原到备用主机验证创建的表。</block>
  <block id="f18d7c57a5ebb3caa3ea2bfe276de7f2" category="list-text">以Oracle用户身份运行RMAN增量备份并合并、以将事务转储到ANF NFS挂载上的备份集。</block>
  <block id="cb94a5220dfad4d0aa2f693c894fb9e9" category="list-text">关闭主VLDB服务器主机、以模拟存储和数据库服务器主机完全故障。</block>
  <block id="e761e3a893aaa3520b400ce648ab8a6a" category="list-text">在操作系统和版本相同的备用数据库服务器ora-02上、应将操作系统内核作为主VLDB服务器主机进行修补。此外、使用纯软件选项在备用数据库服务器上安装和配置了相同版本的Oracle和修补程序。</block>
  <block id="8c37710929190bb2d41b656aeceeae08" category="list-text">将Oracle环境配置为类似于主VLDB服务器ora_01、例如oratab和Oracle用户.bash_profile等 最好将这些文件备份到ANF NFS挂载点。</block>
  <block id="62b6592dd07cf67430eb62e8fa7a1134" category="list-text">然后、将ANF NFS文件系统上的Oracle数据库备份映像副本挂载到备用数据库服务器上进行恢复。以下步骤演示了流程详细信息。</block>
  <block id="d7ee3226eda2c84f098cd207f0d54f24" category="paragraph">以azueruser身份创建挂载点。</block>
  <block id="ad8e2a2e998153fae9d61ff8f9d9f743" category="paragraph">以azureuser身份挂载用于存储Oracle VLDB备份映像副本的NFS卷。</block>
  <block id="57037eb23ec9213da633092ef5499d2e" category="list-text">验证ANF NFS挂载点上的Oracle数据库备份映像副本。</block>
  <block id="ebb08557fe1c4afb90525797dd43db2e" category="list-text">验证ANF NFS挂载上可用于恢复的Oracle归档日志、并记下最后一个日志文件日志顺序号。在本例中、此值为10。我们的恢复点最高为日志顺序编号11。</block>
  <block id="a4182a7080e9f6f2151069ccb62a5457" category="list-text">作为Oracle用户、将oracle_home变量设置为备用数据库服务器ora-02上的当前Oracle安装、将oracle_sid设置为主Oracle实例SID。在本示例中、此值为NTAP1。</block>
  <block id="a0cf68f6b5b4902668150f7bd93de702" category="list-text">以Oracle用户身份、在$oracle_HOME/dbs目录中创建一个通用Oracle init文件、并配置适当的管理目录。最重要的是、拥有Oracle<block ref="54205e08f5455705eb7a595f7e4f620f" prefix=" " category="inline-code"></block> 指向主Oracle VLDB服务器中定义的ANF NFS挂载路径。 <block ref="54205e08f5455705eb7a595f7e4f620f" prefix=" " category="inline-code"></block> 第节介绍了配置<block ref="73304323457935ed833c76e67c23f068" prefix=" " category="inline-code"></block>。将Oracle控制文件设置为ANF NFS文件系统。</block>
  <block id="a43978f8f72cfac9215264289dc0bbc5" category="paragraph">如果出现差异、应将上述init文件替换为从主Oracle VLDB服务器还原的备份init文件。</block>
  <block id="763216a4e00351ecca33c64834ed517e" category="list-text">以Oracle用户身份启动RMAN、以便在备用数据库服务器主机上运行Oracle恢复。首先、在中启动Oracle实例<block ref="b407a7f2e317a40388660332475e7643" prefix=" " category="inline-code"></block> 状态。</block>
  <block id="8d54569996869aecad559c10bb1e2c87" category="list-text">设置数据库ID。数据库ID可从ANF NFS挂载点上映像副本的Oracle文件名中检索。</block>
  <block id="a36331bab1648a62444eb296287a6fdc" category="list-text">将init文件从spfile还原到/tmp文件夹、以便稍后更新参数文件以与主VLDB匹配。</block>
  <block id="245c0febb36259f78725542aabcf3a2c" category="list-text">验证已还原到新主机的数据库结构、以及在主VLDB发生故障之前插入的测试行。</block>
  <block id="5cfbf4ac8374e1dd5933aecbf7073072" category="list-text">删除无效的临时文件并将新的临时文件添加到临时表空间。</block>
  <block id="b254731bf46f569e3541aea574a9240f" category="paragraph">这样、Oracle VLDB数据库便可从ANF NFS文件系统上的备份映像副本恢复到备用数据库服务器主机。</block>
  <block id="d54a80e2830c5cb42b06497a7012bf36" category="list-text">* iSCSI配置。* EC2实例数据库服务器使用iSCSI协议连接到FSX存储。EC2实例通常使用一个网络接口或ENI进行部署。单个NIC接口可同时传输iSCSI和应用程序流量。请务必通过仔细分析Oracle AWR报告来衡量Oracle数据库峰值I/O吞吐量需求、以便选择既满足应用程序流量吞吐量要求又符合iSCSI流量吞吐量要求的正确EC2计算实例。此外、AWS EC2通常会将每个TCP流量限制为5 Gbps。每个iSCSI路径可提供5 Gbps (625 Mbps)的带宽、要满足更高的吞吐量要求、可能需要多个iSCSI连接。</block>
  <block id="c90c43251c42b6636335f78ddce9094b" category="sidebar">使用ANF上的增量合并快速恢复Oracle VLDB</block>
  <block id="1682ae9d2d4cd27a5c88db76924f2730" category="inline-link-macro">Spot API</block>
  <block id="eb698aa9c2c721d612639f1741807d8f" category="inline-link-macro">Instaclinstt配置API</block>
  <block id="1efc1a71dad2451e243efa783d9aaba0" category="summary">采用NVIDIA DGX系统的NetApp AIPod—解决方案验证和大小指导</block>
  <block id="69c6567c90cf0701d7c8040411572c42" category="paragraph">NetApp已成功完成DGX BasePOD认证、经测试的两个A900 HA对可轻松支持由八个DGX H100系统组成的集群。对于存储性能要求较高的大型部署、可以在一个集群中向NetApp ONTAP集群添加更多AFF系统、最多可添加12个HA对(24个节点)。使用本解决方案中所述的FlexGroup技术、一个24节点集群可以在一个命名空间中提供超过40 PB的吞吐量和高达300 Gbps的吞吐量。其他NetApp存储系统(例如AFF A400、A250和C800)以更低的成本为小型部署提供了更低的性能和/或更高的容量选项。由于ONTAP 9支持混合模式集群、因此客户可以先减少初始占用空间、然后随着容量和性能要求的增长向集群添加更多或更大的存储系统。下表显示了每个AFF型号所支持的A100和H100 GPU数量的粗略估计。</block>
  <block id="20cf5354f1cb1762a65f65a02053fbaf" category="paragraph">_ NetApp存储系统规模估算指南_
<block ref="a116ffc089a6818e949c12a7a63263e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb891ae3e0024b90a290ce66233d5f6a" category="paragraph">NetApp&amp;#482；采用NVIDIA DGX&amp;#482的AIPod；系统和NetApp云互联存储系统、通过消除设计复杂性和猜测、简化了机器学习(ML)和人工智能(AI)工作负载的基础架构部署。采用NVIDIA DGX系统的AIPod基于NVIDIA DGX BasePOD设计构建、可为下一代工作负载提供卓越的计算性能、并添加了NetApp AFF存储系统、支持客户从小规模入手、无故障扩展、同时智能地管理从边缘到核心再到云再到云的数据。NetApp AIPod是更广泛的NetApp AI解决方案产品组合的一部分、如下图所示-</block>
  <block id="c1bce5bf8b373a52b3c554a9aaec682e" category="paragraph">_ NetApp AI解决方案产品组合_
<block ref="28fc4ff24eeac14eb2855c3d52eb752f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90d5ac5fb2e6ff10937e8123a8a6a025" category="summary">采用NVIDIA DGX系统的NetApp AI Pod—架构</block>
  <block id="e768686aaf74da904c7c8966e526e0ad" category="inline-link-macro">上一页：ONTAP AI -软件组件</block>
  <block id="d6d5b68389c5209df0ea55ba641bb018" category="paragraph"><block ref="d6d5b68389c5209df0ea55ba641bb018" category="inline-link-macro-rx"></block></block>
  <block id="19b486adfd04484f926fbbf1ecc903e4" category="paragraph">此参考架构利用单独的网络结构实现计算集群互连和存储访问、并在计算节点之间建立400 GB/秒InfiniBand (IB)连接。下图显示了采用DGX H100系统的NetApp AIPod的整体解决方案拓扑。</block>
  <block id="d8a66baebc12d026cceddd2879c5ed5c" category="paragraph">_AIPOD NetApp解决方案拓扑_
<block ref="eb606e206352457153b2069dbeccf372" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57f55a30c80dbf621eb119c782a8b3c5" category="paragraph">在此配置中、计算集群网络结构使用一对QM9700 400Gb/s IB交换机、这些交换机连接在一起以实现高可用性。每个DGX H100系统通过八个连接连接到交换机、其中、偶数端口连接到一个交换机、奇数端口连接到另一个交换机。</block>
  <block id="dc781eabd9ccaf63b10ce1efdec713b5" category="paragraph">对于存储系统访问、带内管理和客户端访问、使用一对SN4600以太网交换机。这些交换机通过交换机间链路进行连接、并配置有多个VLAN以隔离各种流量类型。对于大型部署、可以根据需要为主干交换机添加更多交换机对并添加更多叶片、从而将以太网网络扩展为分支-主干配置。</block>
  <block id="7c5c582414ac5fac380b2852858c140b" category="paragraph">除了计算互连和高速以太网网络之外、所有物理设备还会连接到一个或多个SN2201以太网交换机、以实现带外管理。  有关DGX H100系统连接的更多详细信息、请参见 <block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block>。</block>
  <block id="b1cdc2ac23891a1bf0e697359ffeeef6" category="paragraph">每个DGX H100系统都配置有两个双端口ConnectX-7适配器、用于管理和存储流量、对于此解决方案、每个卡上的两个端口都连接到同一交换机。然后、将每个卡中的一个端口配置到LACP MAG绑定中、并将一个端口连接到每个交换机、同时在此绑定上托管用于带内管理、客户端访问和用户级存储访问的VLAN。</block>
  <block id="4c9626744333ab77779a4362b5487b40" category="paragraph">每个卡上的另一个端口用于连接到AFF A900存储系统、并可根据工作负载要求在多种配置中使用。对于使用基于RDMA的NFS来支持NVIDIA Magrum IO GPUDirect存储的配置、端口配置为主动/被动绑定、因为任何其他类型的绑定都不支持RDMA。对于不需要RDMA的部署、还可以为存储接口配置LACP绑定、以提供高可用性和额外带宽。无论是否使用RDMA、客户端都可以使用NFS v4.1 pNFS和会话中继挂载存储系统、以便能够并行访问集群中的所有存储节点。</block>
  <block id="98cf0dbe40ac25e76a11affc27b75bcb" category="paragraph">工作负载SVM总共配置了八个逻辑接口(LIP)、每个物理端口上配置两个LIP。此配置可提供最大带宽、并允许每个LIF故障转移到同一控制器上的另一个端口、以便在发生网络故障时两个控制器保持活动状态。此配置还支持基于RDMA的NFS、以启用GPUDirect存储访问。存储容量以一个大型FlexGroup卷的形式进行配置、该卷跨越集群中的所有存储控制器、每个控制器上有16个成分卷。可从SVM上的任何LIF访问此FlexGroup、并通过将NFSv4.1与pNFS和会话中继结合使用、客户端可与SVM中的每个LIF建立连接、从而可以并行访问每个存储节点的本地数据、从而显著提高性能。此外、还会为工作负载SVM和每个数据LIF配置RDMA协议访问。有关ONTAP的RDMA配置的详细信息、请参见 <block ref="98725a321399dc799a1996bdadb431f5" category="inline-link-macro-rx"></block>。</block>
  <block id="c633f1027e985992e019e4dba4b0831e" category="paragraph">_ NetApp A900存储集群逻辑配置_
<block ref="2ec795ef40b2ed0ebfe1725380b1fcc0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4aade419d921690aabaffa90ba04dbd9" category="paragraph">此参考架构还包括五个基于CPU的服务器、供管理平台使用。其中两个系统用作NVIDIA Base Command Manager的主节点、用于集群部署和管理。另外三个系统用于提供额外的集群服务、例如、在使用Slurm进行作业计划的部署中、可使用Kubornetes主节点或登录节点。利用Kubnetes的部署可以利用NetApp Asta三端CSI驱动程序为AFF A900存储系统上的管理和AI工作负载提供自动化配置和数据服务以及永久性存储。</block>
  <block id="108f9bbf932c304dff7d03edbf186c18" category="paragraph">每个服务器都会以物理方式连接到IB交换机和以太网交换机、以实现集群部署和管理、并通过管理SVM配置NFS挂载到存储系统、以便如前所述存储集群管理项目。</block>
  <block id="c426d49634261a5db71565cb2d5eaa7d" category="inline-link-macro">下一步：采用NVIDIA DGX系统的NetApp AIPod—解决方案验证和大小指导</block>
  <block id="faa1d05b920db60648f4ef68ffea727d" category="paragraph"><block ref="faa1d05b920db60648f4ef68ffea727d" category="inline-link-macro-rx"></block></block>
  <block id="f5304f273423884943ade5e9b103ef4e" category="paragraph">_ NetApp AFF A900存储系统_
<block ref="acc8c7361424cc63fe0cc639d84a09cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8ada7f348089d2d6d93ee2d703a6877" category="paragraph">AFF A900可轻松管理下一代工作负载、例如深度学习、AI和高速分析、以及Oracle、SAP HANA、Microsoft SQL Server和虚拟化应用程序等传统企业数据库。它可以使业务关键型应用程序以最高速度运行、每个HA对的IOPS高达240万次、延迟低至100µs微秒、与以前的NetApp型号相比、性能可提高多达50%。借助基于RDMA的NFS、pNFS和会话中继、客户可以使用现有数据中心网络基础架构实现下一代应用程序所需的高水平网络性能。
客户还可以通过对SAN、NAS和对象存储的统一多协议支持进行扩展和扩展、并通过统一的和单个ONTAP数据管理软件为内部或云中的数据提供最大的灵活性。此外、Active IQ和Cloud Insights提供的基于AI的预测性分析可以优化系统运行状况。</block>
  <block id="d00f08a25dc0ce9d9fe31f44f99784f4" category="paragraph">AFF A900系统包含一整套NetApp集成的应用程序一致的数据保护软件。它提供内置数据保护和尖端的反勒索软件解决方案、用于抢占资源和攻击后恢复。可以阻止恶意文件写入磁盘、并且可以轻松监控存储异常情况以获得洞察力。</block>
  <block id="eec64f4f8931672c6b7a8fdb43ac65b6" category="paragraph">AFF A900可作为无中断机箱内升级提供给现有A700客户。NetApp通过其高级可靠性、可用性、可维护性和易管理性(RASM)功能、使更新变得简单、并消除任务关键型操作中断。此外、NetApp ONTAP软件会自动对所有系统组件应用固件更新、因此可以进一步提高运营效率并简化IT团队的日常活动。</block>
  <block id="a695b7dd2f90774beed0ea5dcacb0fe1" category="paragraph">对于规模最大的部署、AFF A900系统可提供最高的性能和容量选项、而其他NetApp存储系统(例如AFF A800、AFF C800、AFF A400、AFF C400和AFF A250)则可为较小的部署提供更低成本的选项。</block>
  <block id="3ebd416d1b3232ef4125025ab8f437a9" category="paragraph">NVIDIA DGX BasePOD是一种集成的解决方案、由NVIDIA硬件和软件组件、MLOps解决方案和第三方存储组成。利用采用NVIDIA产品和经验证的合作伙伴解决方案的横向扩展系统设计最佳实践、客户可以实施一个高效易管理的AI开发平台。图1突出显示了NVIDIA DGX BasePOD的各个组件。</block>
  <block id="9752ec9df3748dade46ee922ed730b3c" category="paragraph">_NVIDIA DGX基本解决方案_
<block ref="9da8f3b99aa5e110cb73325fb8e639d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2cdfa62855978fa129d36e4602f41e0b" category="paragraph">NVIDIA DGX H100&amp;#8482；系统是AI的动力之源、它通过NVIDIA H100 T能 器核心GPU的开创性性能得到了加速。</block>
  <block id="c08f0fc48b86d32345fff7213852958b" category="paragraph">_NVIDIA DGX H100系统_
<block ref="ab4808418c5a23beddc5f963adb1b47d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90e89fb4d97b48ff06c4be46075a0ed7" category="paragraph">DGX H100系统的主要规格如下：
•八个NVIDIA H100 GPU。
•每个GPU具有80 GB GPU内存、总容量为640 GB。
•四个NVIDIA NVSwitch™芯片。
•两个56核英特尔®至强®白金级8480处理器，支持PCIe 5.0。
2 TB的系统内存。
•四个OFP端口、用于支持八个单端口NVIDIA ConnectX-7 (InfiniBand/以太网)适配器和两个双端口NVIDIA ConnectX-7 (InfiniBand/以太网)适配器。
•两个1.92 TB M.2 NVMe驱动器用于DGX操作系统、八个3.84 TB U.2 NVMe驱动器用于存储/缓存。
•10.2 kW最大功率。
DGX H100 CPU托盘的后部端口如下所示。其中四个OSFP端口为InfiniBand计算网络结构提供八个ConnectX-7适配器。每对双端口ConnectX-7适配器都提供指向存储和管理网络结构的并行路径。带外端口用于BMC访问。</block>
  <block id="884790658562f04b4be0dac8be1eace2" category="paragraph">_NVIDIA DGX H100后面板_
<block ref="b5125c9657b2b8930b40d893caf4ddc8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e64325a640583a5afbe8ce27e88608e" category="section-title">NVIDIA昆特姆-2 QM9700交换机</block>
  <block id="c27b857a7692b54ce74695ce99634faa" category="paragraph">_NVIDIA昆士兰-2 QM9700 InfiniBand交换机_
<block ref="94fa279f41086be6c7ecc457d9648053" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58e83b10341e2ec3a48b164715b6ba34" category="paragraph">具有400 Gb/秒InfiniBand连接的NVIDIA昆特姆-2 QM9700交换机为NVIDIA昆特姆-2 InfiniBand BasePOD配置中的计算网络结构提供支持。ConnectX-7单端口适配器用于InfiniBand计算网络结构。每个NVIDIA DGX系统都与每个QM9700交换机建立了双连接、从而在系统之间提供多个高带宽、低延迟路径。</block>
  <block id="88f086b3f05858ad120601108f0821a7" category="section-title">NVIDIA Spectrum 3 SN4600交换机</block>
  <block id="a7f0306e16d0211dc46b04264726e2e7" category="paragraph">_NVIDIA Spectrum -3 SN4600交换机_
<block ref="3b55279801e431118e511e3cc515832d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18c1b6d582849482eed92fec606553e3" category="paragraph">NVIDIA Spectrum 3 SN4600交换机总共提供128个端口(每个交换机64个)、可为DGX BasePOD的带内管理提供冗余连接。NVIDIA SN4600交换机可提供1 GbE到200 GbE的速度。对于通过以太网连接的存储设备、还会使用NVIDIA SN4600交换机。NVIDIA DGX双端口ConnectX-7适配器上的端口用于带内管理和存储连接。</block>
  <block id="9bc83d36ebb307eef9521860d72d6a83" category="section-title">NVIDIA Spectrum SN2201交换机</block>
  <block id="543c859c0771e24870c9885230c7a3c0" category="paragraph">_NVIDIA Spectrum SN2201 switch_
<block ref="1ca9534c00119666a7c4e181fdda7e7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6714f3120a26d6eb7222fbbd52715a6c" category="paragraph">NVIDIA Spectrum SN2201交换机提供48个端口、可为带外管理提供连接。带外管理可为DGX BasePOD中的所有组件提供整合的管理连接。</block>
  <block id="82e5da407cc33e26189f053503aa2bf6" category="section-title">NVIDIA ConnectX-7适配器</block>
  <block id="a18a0c5e5946e3bdf2a76e54fd139218" category="paragraph">_NVIDIA ConnectX-7适配器_
<block ref="e5f9156ef7fb4c9f221fbf6158c7f9fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fd88c6d9b922108de03b40377d207e8" category="paragraph">NVIDIA ConnectX-7适配器可提供25/50/100/200/400G吞吐量。NVIDIA DGX系统使用单端口和双端口ConnectX-7适配器、可通过400 Gb/秒InfiniBand和100/C200 GB以太网在DGX BasePD部署中提供灵活性。</block>
  <block id="d0ec4403733e203050a3234fa3e46d95" category="paragraph">DGX BasePOD架构是下一代深度学习平台、需要同等高级的存储和数据管理功能。通过将DGX BasePD与NetApp AFF系统相结合、NetApp AIPod与DGX系统架构几乎可以在一个24节点AFF A900集群上以任何规模扩展到48个DGX H100系统。结合NetApp ONTAP卓越的云集成和软件定义的功能、AFF支持跨边缘、核心和云端的全套数据管道、助力深度学习项目取得成功。</block>
  <block id="4613e07c94020e7ba8189d048f9d61c1" category="list-text">NetApp GPUDirect存储博客-</block>
  <block id="cf8832fa60205a911c1036fb274f649e" category="inline-link"><block ref="cf8832fa60205a911c1036fb274f649e" category="inline-link-rx"></block></block>
  <block id="0f1f9907ba0a6f040f1fa28d77e74fb8" category="paragraph"><block ref="0f1f9907ba0a6f040f1fa28d77e74fb8" category="inline-link-rx"></block></block>
  <block id="e3d6e4bdd7281f2c5d652f6f01825970" category="list-text">NVIDIA DGX H100系统</block>
  <block id="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link"><block ref="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link-rx"></block></block>
  <block id="f4e11a54d0110771220fa05425235763" category="paragraph"><block ref="f4e11a54d0110771220fa05425235763" category="inline-link-rx"></block></block>
  <block id="2a287ccd0cc570973c6890e2e8bca463" category="list-text">NVIDIA MAGNUM IO GPUDirect存储</block>
  <block id="74079d06fd0015403a15f89699e6bcba" category="inline-link"><block ref="74079d06fd0015403a15f89699e6bcba" category="inline-link-rx"></block></block>
  <block id="110c88150ddcbc728071b2fcd7848bd2" category="paragraph"><block ref="110c88150ddcbc728071b2fcd7848bd2" category="inline-link-rx"></block></block>
  <block id="bbae10fb46fb1d3604fe601d556f4187" category="inline-link"><block ref="bbae10fb46fb1d3604fe601d556f4187" category="inline-link-rx"></block></block>
  <block id="936c47b696a994feb0ad33a2addb1168" category="paragraph"><block ref="936c47b696a994feb0ad33a2addb1168" category="inline-link-rx"></block></block>
  <block id="b4675c30af15f661c8112c2853f97970" category="list-text">NVIDIA Base Command Manager</block>
  <block id="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link"><block ref="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link-rx"></block></block>
  <block id="6b36fdb81918af4b96afe2ba587a8ae1" category="paragraph"><block ref="6b36fdb81918af4b96afe2ba587a8ae1" category="inline-link-rx"></block></block>
  <block id="efd8b2c273511a09b23913c74ad7ab59" category="paragraph">本文档介绍了NetApp解决方案和ONTAP工程团队的工作：David Arnette、Olga Kornievskaie、Dups f舍 尔、Srithan Kaligotla、Motit Kumar和Rajeev Badrinath。作者还要感谢NVIDIA和NVIDIA DGX BasePOD工程团队的持续支持。</block>
  <block id="96a0475a5e6d02d46b5b8d7f1327a530" category="paragraph">NVIDIA Base Command&amp;#482；为每个DGX BasePD提供支持、使企业能够充分利用NVIDIA软件创新的优势。企业可以利用成熟可靠的平台充分发挥投资的全部潜能、该平台包括企业级流程编排和集群管理、可加快计算、存储和网络基础架构速度的库以及针对AI工作负载优化的操作系统(OS)。</block>
  <block id="6a488fd0f73d7dea9ac4d836d8d79f22" category="paragraph">_NVIDIA基本命令解决方案_
<block ref="31cdd96336bc344e7f18bc1ab38b426a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c10cc7e99f22ba17190d6964523be5c2" category="paragraph">NVIDIA NGC™提供的软件可满足具有不同AI专业知识水平的数据科学家、开发人员和研究人员的需求。NGC上托管的软件会对一组汇总的常见漏洞和风险(CVE)、加密密钥和私钥进行扫描。它经过测试和设计、可扩展到多个GPU、在许多情况下还可扩展到多节点、从而确保用户在DGX系统上的投资最大化。</block>
  <block id="11cc321e7f64bcad6e636a4c00b45ba5" category="paragraph">_NVIDIA GPU Cloud_
<block ref="0899e022f74ff7e4176989ebf790ce12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b4d69ee10ecec0ac3d21aba6691dc53" category="paragraph">NVIDIA AI Enterprise是一款端到端软件平台、可将生成性AI应用于每个企业、为生成性AI基础模型提供速度最快、最高效的运行时间、这些模型经过优化、可在NVIDIA DGX平台上运行。凭借生产级安全性、稳定性和易管理性、它简化了生成性AI解决方案的开发。DGX BasePOD附带了NVIDIA AI Enterprise、供企业开发人员访问经过预先训练的模型、优化的框架、微服务、加速库和企业支持。</block>
  <block id="7c282a19ff405710e49738f9d0a03a85" category="list-text">性能和更低的延迟。ONTAP可以以最低延迟提供最高吞吐量、包括支持使用基于RDMA的NFS的NVIDIA GPUDirect存储(GDS)、并行NFS (pNFS)和NFS会话中继。</block>
  <block id="651928f77d87184265ec1be1ab0b8aff" category="list-text">存储多租户和多因素身份验证。ONTAP 支持以最高的安全性级别共享基础架构资源。</block>
  <block id="74959a361bdb223dafbb94226dd84e3e" category="list-text">通过NetApp FlexGroup、可以在存储集群中的所有节点之间分布数据、从而为超大型数据集提供海量容量和更高的性能。</block>
  <block id="eec4aeb85db42cd9055b9aba24052c7e" category="list-text">NetApp FlexCache。提供远程卷缓存功能、可简化文件分发、减少WAN延迟并降低WAN带宽成本。FlexCache支持跨多个站点进行分布式产品开发、并加快从远程位置访问公司数据集的速度。</block>
  <block id="483e92f76323d9d7b2d7f2ec6d4c0590" category="list-text">无缝扩展和无中断运行。ONTAP支持向现有控制器和横向扩展集群联机添加容量。客户可以升级到 NVMe 和 32 Gb FC 等最新技术，而无需进行成本高昂的数据迁移或中断。</block>
  <block id="bacf2403430c9be349e22f8a7e42a5b9" category="paragraph">NetApp DataOps工具包是一款基于Python的工具、可简化开发/培训工作空间和推理服务器的管理、这些工作空间和服务器由高性能横向扩展NetApp存储提供支持。数据操作工具包可作为独立的实用程序运行、在利用NetApp Asta三端存储自动化来实现存储操作的Kubennet环境中、该工具包的效率更高。主要功能包括：</block>
  <block id="44ce48cceac53b351ab54ca5685fcf55" category="list-text">近乎即时地克隆高容量JupyterLab工作空间、以便进行实验或快速迭代。</block>
  <block id="b47bad7e2a479b14e613be5ba1af90a0" category="list-text">近乎即时地为高容量JupyterLab工作空间创建快照、用于备份和/或可追溯性/基线化。</block>
  <block id="afe9b022bbe49ebc232dc11679a61bb4" category="list-text">近乎即时地配置、克隆和创建高容量、高性能数据卷的快照。</block>
  <block id="d0519aaecb6bc98b44874eff3513f7aa" category="paragraph">Astra Trident是一款完全受支持的开源存储编排程序、适用于容器和Kubernetes分发版、包括Anthos。通过使用NetApp ONTAP等整个NetApp存储产品组合、可以支持NFS、NVMe/TCP和iSCSI连接。Trident 允许最终用户从其 NetApp 存储系统配置和管理存储，而无需存储管理员干预，从而加快了 DevOps 工作流的速度。</block>
  <block id="c56d0e442e881f176ab8894314c0f6cc" category="section-title">采用NVIDIA DGX系统的NetApp AIPod</block>
  <block id="594e3fc7b73790ecc9bd004f21cccf98" category="inline-link-macro">采用NVIDIA DGX系统的NetApp AI Pod</block>
  <block id="b7f3d4d1bc26ebcee84b474c8bf454be" category="list-text"><block ref="b7f3d4d1bc26ebcee84b474c8bf454be" category="inline-link-macro-rx"></block></block>
  <block id="b9e1a3a8b51ada26e5769669b14ee9ff" category="sidebar">硬件组件</block>
  <block id="abdab95e10f075f1f46038e7adf39694" category="sidebar">软件组件</block>
  <block id="0c39b884d012613e5506be64166da6e2" category="sidebar">验证和大小确定指导</block>
  <block id="d12eb5a54b4d33dd5ab37f615615c20d" category="sidebar">Concon싛 뫍 追加信息 ꆣ</block>
  <block id="2efc3fc2b37d3580270c66f09bb57f3f" category="cell">2024年4月16日</block>
  <block id="db2f9342403e0e147464a85b899ec12c" category="cell">Red Hat OpenShift虚拟化</block>
  <block id="f4efc57f099da586ee9e764c4aef9527" category="cell">在OpenShift虚拟化中添加了用于VM数据保护的新内容</block>
  <block id="a35185b73e84533fd73cfb8322fefa9c" category="section-title">创建VM备份的步骤</block>
  <block id="55876228853abf632dec9346a4f372ec" category="inline-link-macro">文档。</block>
  <block id="f4c2b4c588235f6ac7745db472c4d9ab" category="paragraph">要按需创建整个VM (VM元数据和VM磁盘)的备份，请单击**备份**选项卡。这将创建备份自定义资源(CR)。提供了一个示例YAML以创建备份CR。使用此YAML、将备份指定命名空间中的虚拟机及其磁盘。可以按中所示设置其他参数 <block ref="45bf4fcb30cb666d5b02b54fb671e73b" category="inline-link-macro-rx"></block>。</block>
  <block id="946a36c298d905e86e94d12bcab9ac5d" category="paragraph">您可以借助S3浏览器应用程序检查对象存储中的备份。备份路径显示在已配置的分段中、并带有前缀名称(velero/ducobackup)。您可以查看备份内容、包括卷快照、日志和虚拟机的其他元数据。</block>
  <block id="d414db715c5a0faf9dc9e0d273b68aeb" category="image-alt">S3中的备份对象</block>
  <block id="42deac4908a17efb438eb8235d8b5154" category="doc">从备份还原虚拟机</block>
  <block id="2e5000f442fd03af453e55818984dcc1" category="paragraph">要从备份中还原、我们假设虚拟机所在的命名空间被意外删除。</block>
  <block id="1f38706eb4f3fcc34033d5f026d6870b" category="image-alt">创建还原CR</block>
  <block id="eeaf1836a10a1c281451e90f85037328" category="summary">借助NetApp ONTAP实现Red Hat OpenShift虚拟化数据保护</block>
  <block id="39d968e9e86e45a17aaecf4eb0762d19" category="doc">使用OpenShift API实现数据保护(OADP)、在OpenShift虚拟化中为VM提供数据保护</block>
  <block id="ae4c2d0da7b1da91fd7f98644678ccf9" category="paragraph">OpenShift虚拟化环境中的虚拟机是在OpenShift容器平台的工作节点中运行的容器化应用程序。保护VM元数据以及VM的永久性磁盘非常重要、这样、当VM丢失或损坏时、您可以对其进行恢复。</block>
  <block id="ddf882d4f00c5a1aa695a3765e09aea4" category="inline-link-macro">Astra三端CSI</block>
  <block id="f2a7e994212d23b2ffccc1bee676f29f" category="inline-link-macro">用于数据保护的OpenShift API (OADP)</block>
  <block id="645cfb8bb0213c85adb7638ec5054531" category="paragraph">通过OADP、可以对OpenShift集群上的应用程序进行备份、还原和灾难恢复。可以使用OADP保护的数据包括Kubbernetes资源对象、永久性卷和内部映像。</block>
  <block id="57ed5e4243b7ab15efb8cc256dd4518b" category="image-alt">用于数据保护的OpenShift API</block>
  <block id="9f8db730aab5d6b3737b3fc6e78f7615" category="inline-link-macro">Velero</block>
  <block id="fa110fea65371933396f17bbaa225240" category="paragraph">Red Hat OpenShift利用了OpenSource社区开发的解决方案来实现数据保护。 <block ref="baf3dad02604469cf9b36dfd048d949d" category="inline-link-macro-rx"></block> 是一款开源工具、用于安全备份和还原、执行灾难恢复以及迁移Kubbernetes集群资源和永久性卷。为了轻松使用Velero、OpenShift开发了OADP运算符和Velero插件、以便与CSI存储驱动程序集成。公开的OADP API的核心基于Velero API。安装并配置OADP操作程序后、可以执行的备份/还原操作将基于Velero API公开的操作。</block>
  <block id="74d684a3f25550e917b95ae9fa8fddda" category="paragraph">OADP 1.3可从OpenShift集群的操作中心进行下载、版本为：它具有内置的Data Mover、可将CSI卷快照移动到远程对象存储。这样可以在备份期间将快照移动到对象存储位置、从而提高可移植性和持久性。灾难发生后、快照可供还原。</block>
  <block id="443be02ba2637faabbc0d68461011a3d" category="list-text">OpenShift集群4.14.</block>
  <block id="1bee4f1f27d6d9a577c022b39d05b420" category="list-text">通过Red Hat提供的OperatorOpenShift Virtualization Operator安装OpenShift虚拟化</block>
  <block id="27ecce8b73263f2e40c88e1f01e4d4c6" category="list-text">OADP Operator 1.13由Red Hat提供</block>
  <block id="a9cebba9c6e4541ea01eb9db38f12fff" category="list-text">适用于Linux的Velero CLI 1.13</block>
  <block id="41bda7aee3e78b3069b70a544ebe6b22" category="list-text">Astra三端到子24.02</block>
  <block id="109770c2c1397dfc771c00e133c261d7" category="list-text">ONTAP 9.12.</block>
  <block id="3fb802979ba16c02036bbf0e2ccca520" category="doc">安装OpenShift API for Data Protection (OADP) Operator</block>
  <block id="a4ee034ae431aa12e1096e9159cd3535" category="list-text">一个Red Hat OpenShift集群(版本高于版本发行版次)、安装在具有RHCOS工作节点的裸机基础架构上</block>
  <block id="2c0ddb999562d47f6204172af956c012" category="list-text">使用Astra三端磁盘与集群集成的NetApp ONTAP集群</block>
  <block id="c68c3e63f2e806666f5c48a81d49639f" category="list-text">在集群上创建的三项Snapshot类</block>
  <block id="84eaa94c21c30a8e72ad3f80250a770d" category="list-text">已安装并配置OpenShift虚拟化操作员</block>
  <block id="e21b4714c9959f7c9a1fa807e31c7116" category="list-text">部署在OpenShift虚拟化上的命名空间中的VM</block>
  <block id="c93a01c0f83c7ea0609bfb2cc8f14c20" category="admonition">如果要在VM处于running状态时为其创建备份、则必须在该虚拟机上安装QEMu子代理。如果使用现有模板安装VM、则会自动安装QEMU代理。通过QEMu、子代理可以在快照过程中将子操作系统中的传输中数据置于静机状态、并避免可能发生的数据损坏。如果未安装QEMu、则可以先停止虚拟机、然后再创建备份。</block>
  <block id="d408f71cb5fd6e747be27c658e9f7fdc" category="section-title">安装OADP Operator的步骤</block>
  <block id="5517fb73a08c07a1960011021183897d" category="image-alt">在Operator Hub中使用OpenShift API进行数据保护</block>
  <block id="e3cf4023272c20d25b66b4dca774707e" category="image-alt">OpenShift API for Data Protection Operator安装</block>
  <block id="13f3d0c72d626d4cca010a4ad2f68b56" category="image-alt">已安装OpenShift API for Data Protection Operator</block>
  <block id="14bd28b66817d866e672d1cfd75ea2d7" category="inline-link-macro">ONTAP文档中的对象存储管理一节</block>
  <block id="6472ef2c73ad502b7fcd59786c91dbf9" category="paragraph">操作员安装成功后、配置Velero实例。
您可以将Velero配置为使用S3兼容对象存储。按照中所示的过程配置ONTAP S3 <block ref="5d673d28662558605ee1703146e0f91d" category="inline-link-macro-rx"></block>。要与Velero集成，您需要从ONTAP S3配置中获取以下信息。</block>
  <block id="bedf3fd9118c5ca295c1598dd4b8eddf" category="list-text">用于访问S3的用户凭据、其中包括访问密钥和机密访问密钥</block>
  <block id="0dd1a3a2828692d2794be8354b1e1904" category="list-text">S3中具有用户访问权限的备份的分段名称</block>
  <block id="0078beddeff16d325abdba87d72ecd51" category="list-text">为了安全访问对象存储、应在对象存储服务器上安装TLS证书。</block>
  <block id="ff89d7533cfe0ae0aef578589170d1c7" category="section-title">配置Velero的步骤</block>
  <block id="411bee16b777d9bcbff8b84a2ec800eb" category="list-text">您必须已创建三端卷SnapshotClass。</block>
  <block id="17473960c94d8c852076c1ded0ed61d4" category="list-text">编辑trdent-snapshotclass的标签并将其设置为
** Velero.io/CSI-VOUESNAPECUE-CLASS=TRUE**，如下所示。</block>
  <block id="5b84ef6c22304abf29804f8916170efa" category="image-alt">三项功能Snapshot类标签</block>
  <block id="243775d2bc11b8ace4a04fb1b855ce1d" category="image-alt">应将卷SnapshotClass删除策略设置为保留</block>
  <block id="89735a04d3c597f9647cd26344ac104b" category="doc">使用Velero删除备份和恢复</block>
  <block id="4574586aa737250bfcda95872412374c" category="section-title">删除备份</block>
  <block id="506669fd187f83cd45e02820488e19b8" category="paragraph">您可以使用OC命令行界面工具删除备份CR而不删除对象存储数据。</block>
  <block id="1f2bb995ca44da2485d150c01223b5f9" category="paragraph">如果您要删除备份CR并删除关联的对象存储数据、可以使用Velero命令行界面工具执行此操作。</block>
  <block id="028e770dafec7bc4c1b2a094baa8b902" category="inline-link-macro">Velero文档</block>
  <block id="322658ed277e33b7084d15bfea1f8654" category="paragraph">按照中的说明下载命令行界面 <block ref="4084f117acec9d1e358ff87bedc14e4b" category="inline-link-macro-rx"></block>。</block>
  <block id="44698d5b7f33a7bf2307285b2bd76a50" category="paragraph">使用Velero命令行界面执行以下删除命令</block>
  <block id="5c71ba464067f7274098a1ad207e5185" category="paragraph">您也可以使用Velero命令行界面删除恢复CR</block>
  <block id="62493b3471e85f7b7102c1acae457868" category="paragraph">您可以使用oc命令以及UI删除还原CR</block>
  <block id="aa865fc0a71e354cb5438761f6a6c9ba" category="inline-link-macro">InstaclCluster监控API</block>
  <block id="dff788a6c7c858a053eeffb9e4595122" category="paragraph">下面是一些可与VMware A拨 集成的其他资源。
<block ref="dda17c7c890517ceeb30661fbdc5a21b" category="inline-link-macro-rx"></block>
<block ref="95499a321602fd640851edb11cd0652b" category="inline-link-macro-rx"></block>
<block ref="06c40e6c0f3d38ebd5ca68a5e35a36d7" category="inline-link-macro-rx"></block>
<block ref="fb7aa7e74547744c6c975e36bfb29445" category="inline-link-macro-rx"></block>
<block ref="0bc03b693cc088995a6238c26e595281" category="inline-link-macro-rx"></block>
<block ref="d60c12aedc8c0da5f4e1be13c4dc721b" category="inline-link-macro-rx"></block>
<block ref="358a5bcd9bbface85de25c9415f0fe82" category="inline-link-macro-rx"></block>
<block ref="5fc05f965f5c74950011cf97e1927c78" category="inline-link-macro-rx"></block>
<block ref="375a308e38a72a52f57edf008a10609d" category="inline-link-macro-rx"></block>
<block ref="3ac5a2677e3f6fe8f5869b429b93acff" category="inline-link-macro-rx"></block>
<block ref="56daa806549cf76d44eec0ef69c5d6c2" category="inline-link-macro-rx"></block>
<block ref="ec71f6e51d9c1ee1ea4460e13b624df0" category="inline-link-macro-rx"></block>
<block ref="89505d87a2c92f122bfb4f697f10a1ed" category="inline-link-macro-rx"></block>
<block ref="8acf1898e88961a998bf3a52f78fdb3a" category="inline-link-macro-rx"></block>
<block ref="593072cec0260f2bb27124338ab043c0" category="inline-link-macro-rx"></block>
<block ref="6968e35abd1952220c77606158074b41" category="inline-link-macro-rx"></block>
<block ref="ef09cb46023a74a11707df91db2b15f5" category="inline-link-macro-rx"></block></block>
  <block id="c3ae34e32e1b64f47fb79db64784fcd5" category="inline-link-macro">使用Asta Control Center通过备份进行灾难恢复的演示视频</block>
  <block id="ca9d44629d70b9f7b3c3cd14440f8f24" category="paragraph"><block ref="ca9d44629d70b9f7b3c3cd14440f8f24" category="inline-link-macro-rx"></block></block>
  <block id="7dd560122213e64b542e95018ff44ab1" category="paragraph">此页面显示了使用Astra Control Service在AWS上托管Red Hat OpenShift (ROSA)的数据保护选项。</block>
  <block id="cd25a3e993cfcb7dc008e56db66965e0" category="section-title">FSx NetApp ONTAP for Red Hat OpenShift Service on AWS (ROSA)</block>
  <block id="52e49f56ff0478e0156dcd83b1f3765c" category="sidebar">OADP安装</block>
  <block id="3500ba09d0538297440ca620c9dd46bf" category="sidebar">备份</block>
  <block id="2bd339d85ee3b33e513359ce781b60cc" category="sidebar">还原</block>
  <block id="1d6394982dcf1616cecf68fcde7cdf0f" category="sidebar">删除备份和还原</block>
  <block id="ca9f31b430e2d1494cf56125653b71e1" category="doc">SnapCenter Oracle克隆生命周期自动化</block>
  <block id="a95c751edfb266fb61714e4b56479b01" category="paragraph">客户喜欢NetApp ONTAP存储的FlexClone功能、该功能可为数据库节省大量存储成本。此基于Ans可 通过NetApp SnapCenter命令行实用程序按计划自动设置、克隆和刷新已克隆的Oracle数据库、以简化生命周期管理。该工具包适用于部署到ONTAP存储(内部未命中或公共云)并由NetApp SnapCenter UI工具管理的Oracle数据库。</block>
  <block id="305b49cab56a63db69a75b8a90237992" category="list-text">设置Oracle数据库克隆规范配置文件。</block>
  <block id="ffe89dfaf822383b1610d2235661b139" category="list-text">按照用户定义的计划创建和刷新克隆Oracle数据库。</block>
  <block id="5a82f1374e653dd60890a248f3da4afa" category="list-text">使用SnapCenter管理Oracle数据库的数据库管理员。</block>
  <block id="eeb8bce8b54b9d524c33c1838a0d56ff" category="list-text">使用SnapCenter管理ONTAP存储的存储管理员。</block>
  <block id="d2d0cadcec645d853fb3c7ebf1705d31" category="list-text">有权访问SnapCenter UI的应用程序所有者。</block>
  <block id="ec26bffdac6e146ef20365de82135a71" category="section-title">Ans可 处理目标主机文件配置</block>
  <block id="c57304a243a04357bd7b6a14b757cb11" category="paragraph">该工具包包含一个主机文件、用于定义运行Ands得以 执行的Playbook的目标。通常、它是目标Oracle克隆主机。下面是一个示例文件。主机条目包括目标主机IP地址以及用于管理员用户访问主机以执行克隆或刷新命令的ssh密钥。</block>
  <block id="f4516853063c4206701e5aa89787feaa" category="paragraph"># Oracle克隆主机</block>
  <block id="dd5cc97aa774a3a1c065bbb01fcf3e7d" category="paragraph">AnsablePlaybooks从多个变量文件中获取变量输入。下面是一个全局变量文件vars.yml示例。</block>
  <block id="a4f107861ae1069b802d4818e857efeb" category="paragraph">主机变量在名为｛｛host_name｝｝.yml的host_vars目录中定义。以下是显示典型配置的目标Oracle主机变量文件ora_04.cie.netapp.com.yml的示例。</block>
  <block id="b9221ffda439eb4a537f8bb3073871aa" category="section-title">其他克隆目标Oracle服务器配置</block>
  <block id="d94c052d91f30fa14b5db2ac2139bda3" category="paragraph">克隆目标Oracle服务器应与安装并修补的源Oracle服务器具有相同的Oracle软件堆栈。Oracle用户.bash_profile已配置$oracle_base和$oracle_home。此外、$oracle_home变量应与源Oracle服务器设置匹配。下面是一个示例。</block>
  <block id="9ed50a56f8c83c496fdb2d3fe909497f" category="paragraph">共有三本使用SnapCenter命令行界面实用程序执行Oracle数据库克隆生命周期的操作手册。</block>
  <block id="56f060833065e38dfd98d52734f5c81c" category="list-text">安装Andsone控制器的前提条件-仅一次。</block>
  <block id="230f70b0a7d8d86c8ea52493d17f962f" category="list-text">设置克隆规范文件—仅一次。</block>
  <block id="6a1fa0bf47a6db0c3d4281d1316fd9e0" category="list-text">使用shell脚本定期从crontab创建和刷新克隆数据库、以调用刷新操作手册。</block>
  <block id="8aafbc88c398f3b5492811671ba656ad" category="paragraph">对于其他克隆数据库、请创建一个单独的CLONE n_setup.yml和CLONE n_refresh .yml以及CLONE n_refresh。在host_vars目录中相应地配置"Andsvey"目标主机和hostname.yml文件。</block>
  <block id="465d2a2dc0602710238ac36717c64844" category="cell">2024年4月17日</block>
  <block id="2de363e9c11e72fe1c95728c8cf3e449" category="sidebar">SnapCenter Oracle克隆生命周期</block>
  <block id="a665a0615deeadccebb2b482acba8067" category="doc">在OpenShift虚拟化中为VM创建按需备份</block>
  <block id="f5895613b4fc01023daa64f694a33785" category="paragraph">CSI将创建支持磁盘的永久性卷的快照。系统会创建VM备份及其磁盘快照、并将其存储在YAML中指定的备份位置。备份将在系统中保留30天、如TTL中所指定。</block>
  <block id="b5382c0e4bf285954c930cb33792960b" category="admonition">在StorageGRID中、您还可以使用租户管理器提供的S3控制台来查看备份对象。</block>
  <block id="d894351907b5c62a82330f8b48880b61" category="section-title">在OpenShift虚拟化中为VM创建计划备份</block>
  <block id="5ecb8594d45ba6d911bd9416145be11f" category="paragraph">cron表达式07 ***表示每天7：00创建备份。
此外、还会指定要包含在备份中的空间以及备份的存储位置。因此、使用计划CR而不是备份CR来按指定的时间和频率创建备份。</block>
  <block id="2003f0bb711323d885f4b2f0ae1d61bd" category="section-title">还原到同一命名空间</block>
  <block id="19b526387a9916ff1e3f24e7910f1f12" category="paragraph">要从刚刚创建的备份进行还原、需要创建一个还原自定义资源(CR)。我们需要为其提供一个名称、提供要从中还原的备份的名称、并将restorEPVs设置为true。可以按中所示设置其他参数 <block ref="d4d5c1753093015ad4958595f6604080" category="inline-link-macro-rx"></block>。单击创建按钮。</block>
  <block id="0119ea7355249cd061216800d9972a5d" category="paragraph">当阶段显示完成时、您可以看到虚拟机已还原到创建快照时的状态。(如果备份是在虚拟机运行时创建的、则从备份中还原虚拟机将启动已还原的虚拟机并使其进入运行状态)。VM将还原到同一命名空间。</block>
  <block id="5b6c62a4db94a4f3481a2d5a0ef5af6d" category="image-alt">还原已完成</block>
  <block id="c0bfb19cff18dbe0f707ea3ed21faf24" category="section-title">还原到其他命名空间</block>
  <block id="373be542c95ab51acdf76c1ba1d5fc66" category="paragraph">要将VM还原到其他命名空间、您可以在Restore CR的YAML定义中提供一个命名空间映射。</block>
  <block id="a2289695178b47ac9d248a46fd2ba2da" category="paragraph">以下示例YAML文件会创建一个还原CR、以便在将备份还原到虚拟机命名空间时、还原虚拟机及其磁盘在virtual-Machine-demO命名空间中的位置。</block>
  <block id="7c42a4e6c0db52ae181519f469f6e201" category="paragraph">当阶段显示完成时、您可以看到虚拟机已还原到创建快照时的状态。(如果备份是在虚拟机运行时创建的、则从备份中还原虚拟机将启动已还原的虚拟机并使其进入运行状态)。虚拟机将还原到YAML中指定的其他命名空间。</block>
  <block id="35cca3f67f9c3684a5e45bf0a2d8b122" category="paragraph">作者：Banu Sunzhar、NetApp</block>
  <block id="b78fa3a575621789b7179dedef424eba" category="paragraph">本参考文档的这一部分详细介绍了如何在NetApp ONTAP S3或NetApp StorageGRID S3上使用用于数据保护的OpenShift API (OADP)和Velero创建VM备份。VM磁盘的持久卷(PV)备份是使用CSI Asta三端Snapshot创建的。</block>
  <block id="ded063633b39604bc7b1c600315571cd" category="paragraph">OpenShift虚拟化VM的永久性磁盘可以通过集成到OpenShift集群的ONTAP存储作为后备存储 <block ref="062873b3d48316bca3a2c248dcd88de0" category="inline-link-macro-rx"></block>。在本节中、我们将使用 <block ref="aae2b983a17c22c7bfaf66419d8e0186" category="inline-link-macro-rx"></block> 将虚拟机(包括其数据卷)备份到</block>
  <block id="4e62c9089f3c563d3b9c278e981a164f" category="list-text">ONTAP对象存储</block>
  <block id="684bd3b292fe41f5fcee6f80cd2303d2" category="list-text">StorageGRID</block>
  <block id="23be3887459d40814f4226e62b794ea1" category="paragraph">然后、我们会根据需要从备份中还原。</block>
  <block id="a6040c159eeb9dc3a8ee2778db8e299e" category="paragraph">**以下是本节中的示例所使用的各种组件的版本**</block>
  <block id="f2bda2a9fa50f0674bbaba251b860df8" category="paragraph"><block ref="062873b3d48316bca3a2c248dcd88de0" category="inline-link-macro-rx"></block>
<block ref="aae2b983a17c22c7bfaf66419d8e0186" category="inline-link-macro-rx"></block>
<block ref="baf3dad02604469cf9b36dfd048d949d" category="inline-link-macro-rx"></block></block>
  <block id="01fa6531f7bcef888024dd93319f31ff" category="list-text">转到集群的Operator Hub、然后选择Red Hat OADP operator。在安装页面中、使用所有默认选项、然后单击安装。在下一页上、再次使用所有默认值、然后单击安装。OADP操作符将安装在命名空间OpenShift-ADP中。</block>
  <block id="80a097bd3a7570af018db5b969b84eff" category="section-title">使用ONTAP S3详细信息配置Velero的前提条件</block>
  <block id="fed42ad347e6995a74e43865716d36f9" category="list-text">可用于访问S3的逻辑接口(LIF)</block>
  <block id="4532aae7bcd069b0eb6b2b7b3c2a9e54" category="section-title">使用StorageGRID S3详细信息配置Velero的前提条件</block>
  <block id="b32dc31939d5e424a326bf0cb3346335" category="inline-link-macro">StorageGRID文档</block>
  <block id="c202f9cfe87000c6e5b7128c7e5f1b63" category="paragraph">您可以将Velero配置为使用S3兼容对象存储。您可以使用中所示的过程配置StorageGRID S3 <block ref="00ef2c4541e5f7978cb11cef09e42f3d" category="inline-link-macro-rx"></block>。要与Velero集成，您需要从StorageGRID S3配置中获取以下信息。</block>
  <block id="91df1f1faa6e819848f91465e5e20aa3" category="list-text">可用于访问S3的端点</block>
  <block id="7d9161edeafc7f813d18fb639a34b1f1" category="list-text">首先、为ONTAP S3用户凭据或StorageGRID租户用户凭据创建一个密钥。这将用于稍后配置Velero。您可以从命令行界面或Web控制台创建密钥。
要从Web控制台创建密钥，请选择机密，然后单击密钥/值机密。提供凭据名称、密钥和值的值、如图所示。请务必使用S3用户的访问密钥ID和机密访问密钥。正确命名密钥。在以下示例中、系统会创建一个具有名为ONTAP S3-cred据 的ONTAP S3用户凭据的密钥。</block>
  <block id="af88dcba6a1b60fd13dab3b4661894f1" category="image-alt">S3用户凭据的机密</block>
  <block id="59057b98650fa41bca9719fde2c67273" category="image-alt">为S3用户凭据创建密码</block>
  <block id="72b64d2ebd0901d2e51026c57dd096fe" category="paragraph">现在转到YAML视图并替换规格信息、如下面的YAML文件示例所示。</block>
  <block id="5597a937099a8099e0a04565b9d02f97" category="paragraph">**用ONTAP S3作为备份位置来配置Velero的YAML文件样本**</block>
  <block id="0b9704b74e90ab5906d1a5fa08177856" category="paragraph">**用StorageGRID S3作为备份位置和快照位置来配置Velero的YAML文件样本**</block>
  <block id="a0f9e33cefd69b70382dd17bbaf09cb3" category="paragraph">**备份位置**
ONTAP S3或StorageGRID S3 (及其凭据和YAML中显示的其他信息)被配置为Velero的默认备份位置。</block>
  <block id="098a52e4f20328bdaf8852e706f9ad80" category="paragraph">**快照位置**
如果使用容器存储接口(CSI)快照、则无需指定快照位置、因为您将创建一个卷快照类CR来注册CSI驱动程序。在本示例中、您使用的是A作用 力的三端CSI、并且之前已使用三端CSI驱动程序创建了卷eSnap而已。</block>
  <block id="e7e77e84a12b26da5fb80a5965defbec" category="paragraph">确保即使删除了卷Snapshot对象、这些快照也可以持久保留。这可以通过将*DELERionPolicy*设置为保留来实现。否则、删除命名空间将完全丢失以前备份过的所有PVC。</block>
  <block id="6967372fdda8370bb5f60d38b150f3b9" category="cell">2024年4月19日</block>
  <block id="830c044146fe93686d0daa926ed99ca4" category="cell">为OpenShift虚拟化中的VM的CI集成添加了新内容</block>
  <block id="1326575b2c1b1308aa89618a6a3bcae9" category="summary">在Red Hat OpenShift虚拟化中使用Cloud Insights监控VM</block>
  <block id="ae09b206e51937d1c941b5c2ed9caec2" category="doc">Red Hat OpenShift虚拟化中VM的监控功能示例</block>
  <block id="954e09c829c57df5b561ec50c16878bd" category="section-title">**根据事件监视和创建警报**</block>
  <block id="9d7b50e73586cebbffa9d827af75c400" category="paragraph">以下示例根据事件监控OpenShift虚拟化中包含VM的命名空间。在此示例中、系统将基于集群中指定命名空间的** logs.Kubernetes**.event创建一个监控器。</block>
  <block id="7e5843c0f22503c836ead85bf266fa49" category="image-alt">Cloud Insights示例</block>
  <block id="e880b18d29e08ec49f9959eafc2c29e1" category="paragraph">此查询可提供命名空间中虚拟机的所有事件。(命名空间中只有一个虚拟机)。此外、还可以构建一个高级查询、以便根据原因为"失败"或"失败挂载"的事件进行筛选。通常、当问题描述在创建PV或将PV挂载到POD时会创建这些事件、这些事件指示动态配置程序中存在用于创建永久性的问题 VM的卷。
如上所示创建警报监控时、您还可以配置向收件人发送通知。此外、您还可以提供更正操作或追加信息、这些操作可能有助于解决此错误。在上述示例中、追加信息可以研究用于解析问题描述的三端配置和存储类定义。</block>
  <block id="284398d3555a12ee9182f2a6d2cd052b" category="section-title">**更改分析**</block>
  <block id="8f2fa2ef8ee00b695a9b7cf66a4200bc" category="paragraph">通过"变更分析"、您可以查看集群状态发生了哪些变化、包括哪些人进行了更改、这有助于对问题进行故障排除。</block>
  <block id="2b11386df6d3c3ea7cf88557fff9693e" category="paragraph">在上述示例中、在OpenShift集群上为包含OpenShift虚拟化VM的命名空间配置了变更分析。信息板将根据时间线显示更改。您可以向下钻取以查看更改的内容、然后单击所有更改差异以查看清单的差异。从清单中、您可以看到为永久性磁盘创建了新的备份。</block>
  <block id="d75f56a9d27e6ee97cbb41e9cb745ea5" category="section-title">**后端存储映射**</block>
  <block id="e5280c625682b6eb6068ae767d9a9f48" category="paragraph">借助Cloud Insights、您可以轻松查看VM磁盘的后端存储以及有关PVC的多项统计信息。</block>
  <block id="6a73b5a5ac4acceafec03521beaf766d" category="paragraph">您可以单击后端列下的链接、此链接将直接从后端ONTAP存储中提取数据。</block>
  <block id="fe7809ef7be15f2d6c7bed438b7b3985" category="paragraph">另一种查看所有POD到存储映射的方法是、从Explore下的Observability菜单创建一个All Metrics查询。</block>
  <block id="7086007925346179c177344a212d3bcf" category="paragraph">单击任何链接都将显示ONTP存储中的相应详细信息。例如、单击"storageVirtualMachine"列中的SVM名称将从ONTAP中提取有关SVM的详细信息。单击内部卷名称将在ONTAP中提取有关该卷的详细信息。</block>
  <block id="f606a8a15d81171e5129dc1280765ea9" category="paragraph">要按计划创建备份、您需要创建计划CR。
该计划只是一个cron表达式、允许您指定创建备份的时间。用于创建计划CR的YAML示例。</block>
  <block id="ec24608680bd87828f5a7a709d799717" category="image-alt">还原到新命名空间已完成</block>
  <block id="8ada493a022952ea7425b4b5cc13bb8b" category="doc">在Red Hat OpenShift虚拟化中与适用于VM的Cloud Insights集成</block>
  <block id="0f6853ba853aa0b425d4efc934995345" category="paragraph">要在OpenShift虚拟化中开始收集VM的数据、您需要安装：</block>
  <block id="a1d66a434285b6e60d6228b7c88f6216" category="list-text">用于收集Kubbernetes数据的Kubbernetes监控操作员和数据收集器
有关完整说明、请参见 <block ref="385d2e2a9ce9e6292c6dc761c0c62b75" category="inline-link-macro-rx"></block>。</block>
  <block id="6af2622662cbdb7f514fe4b4dbc79373" category="list-text">一个采集单元、用于从为VM磁盘提供永久性存储的ONTAP存储中收集数据
有关完整说明、请参见 <block ref="409a2f361846de5a20d7e948392bf706" category="inline-link-macro-rx"></block>。</block>
  <block id="5741b97a1c3d59400f48ced12bf93d00" category="list-text">ONTAP的数据收集器
有关完整说明、请参见 <block ref="99ebb95aaa8942e8702a8866e00b0985" category="inline-link-macro-rx"></block></block>
  <block id="0e6ebe29b11446bc982770b6eeb68b91" category="paragraph">此外、如果您使用StorageGRID进行VM备份、则还需要一个用于StorageGRID的数据收集器。</block>
  <block id="e9cd906bff4168b2db757834569b5474" category="paragraph">本参考文档的这一部分详细介绍了如何将NetApp Cloud Insights与Red Hat OpenShift集群集成以监控OpenShift虚拟化VM。</block>
  <block id="5858ee4031acd7b896faa2d3d2c1a299" category="inline-link">Cloud Insights 文档</block>
  <block id="00911ced9034aa731093735d56a2e06c" category="paragraph">NetApp Cloud Insights 是一款云基础架构监控工具，可让您深入了解整个基础架构。借助 Cloud Insights ，您可以监控，故障排除和优化所有资源，包括公有云和私有数据中心。有关NetApp Cloud Insights的详细信息、请参阅<block ref="68693b67403a80c90005e9f7b1aea49c" category="inline-link-rx"></block>。</block>
  <block id="695d7a391bb9043561bcc3c254868311" category="inline-link-macro">Cloud Insights 入职</block>
  <block id="cb637fe731d8f11e987efcc1f79cfb92" category="paragraph">要开始使用Cloud Insights、您必须在NetApp BlueXP门户上注册。有关详细信息，请参见 <block ref="3eafb0740656ee40f537cc91680fcad7" category="inline-link-macro-rx"></block></block>
  <block id="ca2b06c0229201c6bba975ee591eaee2" category="inline-link-macro">视频教程</block>
  <block id="f42ccee1558b3f9e0eae968dc12af1af" category="paragraph">Cloud Insights具有多种功能、可帮助您快速轻松地查找数据、排除问题并深入了解您的环境。您可以通过功能强大的查询轻松查找数据、在信息板中可视化数据、并针对您设置的数据阈值发送电子邮件警报。请参见 <block ref="641d67cbeba767c6e6b6cd386cc73a79" category="inline-link-macro-rx"></block> 以帮助您了解这些功能。</block>
  <block id="16c85c2f0f86fe481df1b62b9a61ca0a" category="paragraph">要使Cloud Insights开始收集数据、您需要满足以下要求</block>
  <block id="5a8271e744dee41e24e2824276645faf" category="paragraph">**数据收集器**
有3种类型的数据收集器：
*基础架构(存储设备、网络交换机、计算基础架构)
*操作系统(如VMware或Windows)
*服务(如Kafka)</block>
  <block id="07535ee15a4e26f3f181efc7c10ad7ab" category="paragraph">数据收集器可发现来自ONTAP存储设备(基础架构数据收集器)等数据源的信息。收集的信息用于分析、验证、监控和故障排除。</block>
  <block id="81a5d6cefe15c5e2192c611bd6cfdd01" category="paragraph">**采集单元**
如果您使用的是基础架构数据收集器、则还需要一个采集单元将数据注入Cloud Insights。采集单元是专门用于托管数据收集器的计算机、通常是虚拟机。此计算机通常与受监控项目位于同一数据中心/VPC中。</block>
  <block id="c7af6ac5fc868d7272f34c1dafb22f88" category="paragraph">**电报代理**
Cloud Insights还支持电报作为其收集集成数据的代理。Telegraf 是一种插件驱动的服务器代理，可用于收集和报告指标，事件和日志。</block>
  <block id="dd66c1446dae2a3090132732f32b3617" category="paragraph">Cloud Insights架构</block>
  <block id="8701b90c7fdcf3f267913eaa7d7f2492" category="sidebar">使用Cloud Insights监控</block>
  <block id="ad400e9f48073229bddccc88cd839a9b" category="sidebar">与Cloud Insights集成</block>
  <block id="44af4addaf3cb425e2b28b201e741227" category="sidebar">监控功能示例</block>
  <block id="c04e0f40b83a86fd835680d3df9ce399" category="paragraph">备份完成后、其阶段将显示为已完成。</block>
  <block id="a2eabcbade98a44462292c4666e62044" category="image-alt">备份已完成</block>
  <block id="599face14cd53a7849f684fdf7b91e65" category="paragraph">创建计划后、该计划将处于启用状态。</block>
  <block id="d3d6921625349c57f2e95781861ce577" category="image-alt">已创建计划</block>
  <block id="2b8a498ff5a5d59604f3b541192e2fb4" category="paragraph">备份将按照此计划创建、并可从备份选项卡查看。</block>
  <block id="13694d8ba2d767e027aeeac32722eb09" category="paragraph">要通过命令行界面创建名为SG-S3-cred据 的机密、您可以使用以下命令。</block>
  <block id="cdd00080e6d299ef506ce8a1b74d316d" category="image-alt">使用命令行界面为S3用户凭据创建机密</block>
  <block id="4d9ccfbdd1fc2da7be47ec9c101274d2" category="list-text">接下来，要配置Velero，请从Operators下的菜单项中选择Installed Operators，单击OADP Operator，然后选择Data分别 保护应用程序选项卡。</block>
  <block id="9008c35bfe3869440e28fa139fb2d3ec" category="image-alt">DataSetionApplication</block>
  <block id="39658e507fb56267a59206317ef9b26e" category="paragraph">单击"Create Data分别 保护应用程序"。在表单视图中、为DataProtection应用程序提供一个名称或使用默认名称。</block>
  <block id="a190a7e1ff0a242b91e3d3a6e2c9095d" category="image-alt">创建DataSetionApplication</block>
  <block id="9a61266e5f6546757f71bb6329126490" category="paragraph">YAML文件中的规范部分应针对与上述示例类似的以下参数进行适当配置</block>
  <block id="a68b2348883a87a5ea93dd25acc5cdd6" category="paragraph">**启用CSI插件**</block>
  <block id="96e71ab67ae223478d46f140d4875a14" category="paragraph">将CSI添加到Velero的DEDEPTO插 件中、以便使用CSI快照备份永久性卷。
要备份CSI支持的PVC、Velero CSI插件将在设置了**Velero.io/CSI-VOumesnAPshot-class**标签的集群中选择卷SnapshotClass。。</block>
  <block id="05bd5e78c996c165b2b1a844cb7b14b8" category="paragraph">确保已创建Data놣 rotionApplication且其状态为"病 况：已调节"。</block>
  <block id="2c1d400031827c3d65ce20bdbb3dc8e6" category="image-alt">已创建DataSetionApplication对象</block>
  <block id="910eb46960200452a3b203a9e0ccdc76" category="paragraph">OADP操作员将创建相应的备份存储位置。创建备份时将使用此位置。</block>
  <block id="3a11516868032de940e8bc2e948be30e" category="image-alt">已创建备份存储位置</block>
  <block id="5d2d4303446e0c5e9645e0b2422a1ad8" category="sidebar">OpenShift虚拟化的数据保护</block>
</blocks>