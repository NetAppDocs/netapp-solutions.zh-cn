---
sidebar: sidebar 
permalink: ai/ai-edge-test-results.html 
keywords: test, results, aff, offline, single-stream, ef 
summary: 我们会运行大量测试来评估建议的架构的性能。有六种不同的工作负载（图像分类，对象检测（小），对象检测（大），医学影像，语音到文本， 和自然语言处理（ NLP ），您可以在三种不同的情形下运行：脱机，单流和多流。 
---
= 测试结果
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
我们会运行大量测试来评估建议的架构的性能。

有六种不同的工作负载（图像分类，对象检测（小），对象检测（大），医学影像，语音到文本， 和自然语言处理（ NLP ），您可以在三种不同的情形下运行：脱机，单流和多流。


NOTE: 最后一种情形仅适用于映像分类和对象检测。

这样可以提供 15 个可能的工作负载，这些工作负载都在三种不同的设置下进行了测试：

* 单个服务器 / 本地存储
* 单个服务器 / 网络存储
* 多服务器 / 网络存储


以下各节将介绍这些结果。



== AFF 脱机情形中的 AI 推理

在这种情况下，服务器可以使用所有数据，并测量了处理所有样本所需的时间。我们会将带宽报告为每秒样本数作为测试结果。如果使用了多个计算服务器，则会报告所有服务器的总带宽总和。下图显示了所有这三种使用情形的结果。对于双服务器情形，我们会报告两个服务器的总带宽。

image::ai-edge-image12.png[AI边缘image12]

结果显示，网络存储不会对性能产生负面影响，更改极少，对于某些任务，未找到任何结果。添加第二台服务器时，总带宽恰好是两倍，或者最差情况下，更改率小于 1% 。



== 在 AFF 的单个流方案中进行 AI 推理

此基准测试可测量延迟。对于多个计算服务器案例，我们会报告平均延迟。下图显示了这组任务的结果。对于双服务器案例，我们会报告两个服务器的平均延迟。

image::ai-edge-image13.png[AI边缘image13.]

结果再次表明，网络存储足以处理这些任务。在一台服务器的情况下，本地存储与网络存储之间的差别很小或没有差别。同样，当两个服务器使用相同的存储时，两个服务器上的延迟保持不变或变化量非常小。



== 在 AFF 的多流方案中进行 AI 推理

在这种情况下，结果是系统在满足 QoS 限制的情况下可以处理的流数量。因此，结果始终为整数。对于多个服务器，我们会报告所有服务器上的流总数。并非所有工作负载都支持此方案，但我们已执行了这些工作负载。下图总结了我们的测试结果。对于双服务器案例，我们会报告两个服务器的流总数。

image::ai-edge-image14.png[AI边缘image14.]

结果显示了设置的完美性能—本地存储和网络存储的结果相同，添加第二个服务器会使建议设置可以处理的流数量增加一倍。



== EF 的测试结果

我们会运行大量测试来评估建议的架构的性能。有六种不同的工作负载（图像分类，对象检测（小），对象检测（大），医学影像，语音到文本， 和自然语言处理（ NLP ）），这两种情况下运行：脱机和单流。以下各节将介绍这些结果。



=== EF 脱机情形中的 AI 推理

在这种情况下，服务器可以使用所有数据，并测量了处理所有样本所需的时间。我们会将带宽报告为每秒样本数作为测试结果。对于单节点运行，我们会报告两个服务器的平均值，而对于两个服务器运行，我们会报告所有服务器的总带宽总和。下图显示了使用情形的结果。

image::ai-edge-image15.png[AI边缘image15.]

结果显示，网络存储不会对性能产生负面影响，更改极少，对于某些任务，未找到任何结果。添加第二台服务器时，总带宽恰好是两倍，或者最差情况下，更改率小于 1% 。



=== 在一个流场景中对 EF 进行 AI 推理

此基准测试可测量延迟。对于所有情况，我们都会报告运行中涉及的所有服务器的平均延迟。系统将提供此任务套件的结果。

image::ai-edge-image16.png[AI边缘image16.]

结果再次显示，网络存储足以处理这些任务。在一台服务器的情况下，本地存储与网络存储之间的差别很小或没有差别。同样，当两个服务器使用相同的存储时，两个服务器上的延迟保持不变或变化量非常小。
