---
sidebar: sidebar 
permalink: ai/hcaios_solution_overview.html 
keywords: NetApp, Solution, Overview, ML 
summary:  
---
= 解决方案概述
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
本节将介绍传统数据科学管道及其缺点。此外，还介绍了建议的数据集缓存解决方案的架构。



== 传统数据科学管道和缺点

ML 模型开发和部署的典型顺序涉及以下迭代步骤：

* 正在载入数据
* 数据预处理（创建多个版本的数据集）
* 运行多个涉及超参数优化，不同型号等的实验
* 部署
* Monitoringcnvrg.io 开发了一个全面的平台，可以自动执行从研究到部署的所有任务。下图显示了与管道相关的一小部分信息板屏幕截图。


image:hcaios_image2.png[""]

从公有存储库和私有数据中使用多个数据集非常常见。此外，每个数据集可能具有多个版本，这些版本是由数据集清理或功能工程产生的。需要一个信息板来提供数据集中心和版本中心，以确保团队可以使用协作和一致性工具，如下图所示。

image:hcaios_image3.png[""]

管道的下一步是培训，这需要多个并行的培训模型实例，每个实例都与一个数据集和一个特定计算实例相关联。将数据集绑定到使用特定计算实例的特定实验是一项挑战，因为某些实验可能由 Amazon Web Services （ AWS ）中的 GPU 实例执行，而其他实验则由内部 DGX-1 或 DGX-2 实例执行。可能会在 GCP 的 CPU 服务器中执行其他实验，但数据集位置与执行培训的计算资源不是很近。如果距离合理，则从数据集存储到计算实例的连接将达到全 10GbE 或更高的低延迟。

数据科学家通常会将数据集下载到执行培训和实验的计算实例中。但是，此方法可能会出现以下几个问题：

* 当数据科学家将数据集下载到计算实例时，无法保证集成计算存储具有高性能（高性能系统的一个示例是 ONTAP AFF A800 NVMe 解决方案）。
* 如果下载的数据集驻留在一个计算节点中，则在多个节点上执行分布式模型时，存储可能会成为瓶颈（与 NetApp ONTAP 高性能分布式存储不同）。
* 由于队列冲突或优先级问题，下次迭代训练实验可能会在不同的计算实例中执行，这再次导致从数据集到计算位置的网络距离过长。
* 在同一计算集群上执行训练实验的其他团队成员不能共享此数据集；每个团队成员都从任意位置执行数据集（昂贵的）下载。
* 如果后续培训作业需要使用同一数据集的其他数据集或版本，则数据科学家必须再次将数据集（昂贵）下载到执行 training.NetApp 的计算实例中，而 cnvrg.io 已创建一个新的数据集缓存解决方案来消除这些障碍。解决方案通过在 ONTAP 高性能存储系统上缓存热数据集，加快了 ML 管道的执行速度。使用 ONTAP NFS 时，数据集会在由 NetApp 提供支持的数据网络结构（例如 AFF A800 ）中缓存一次（并且只缓存一次），该数据网络结构与计算搭配使用。由于 NetApp ONTAP NFS 高速存储可以为多个 ML 计算节点提供服务，因此培训模型的性能得到了优化，从而为企业节省了成本，提高了工作效率并提高了运营效率。




== 解决方案架构

NetApp 和 cnvrg.io 提供的此解决方案可提供数据集缓存，如下图所示。通过数据集缓存，数据科学家可以选择所需的数据集或数据集版本，并将其移动到靠近 ML 计算集群的 ONTAP NFS 缓存中。现在，数据科学家可以运行多个实验，而不会造成延迟或下载。此外，所有协作工程师都可以将同一数据集与连接的计算集群结合使用（并可自由选择任何节点），而无需从数据湖中进行额外下载。数据科学家可以获得一个信息板，用于跟踪和监控所有数据集和版本，并查看缓存的数据集。

cnvrg.io 平台会自动检测某个时间内未使用的过期数据集，并从缓存中将其转出，从而为更常用的数据集保留可用的 NFS 缓存空间。需要注意的是，使用 ONTAP 的数据集缓存可在云端和内部环境中运行，从而提供最大的灵活性。

image:hcaios_image4.png[""]
