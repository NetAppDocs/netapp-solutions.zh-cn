---
sidebar: sidebar 
permalink: ai/rag_concepts_components.html 
keywords: RAG, Retrieval Augmented Generation, NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NeMo, NIM, NIMS, Hybrid, Hybrid Cloud, Hybrid Multicloud, NetApp ONTAP, FlexCache, SnapMirror, BlueXP 
summary: NetApp企业版RAG—概念和组件 
---
= 概念和组件
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/




== 生成性AI

生成型AI等AI系统通过对大型数据集应用无监督或自我监督的机器学习来设计。与预测特定数据集的传统机器学习模型不同、生成型AI模型能够根据用户提示生成新内容、例如文本、代码、图像、视频或音频。因此、生成型AI系统的功能也会根据所用数据的形式或类型进行分类。它们可以是一模式或多模式。单模系统只需要一种类型的输入(例如纯文本或纯图像)、而多模式系统可以采用多种类型的输入(例如文本、图像和音频)、同时了解并生成不同形式的内容。本质上、生成性AI正在改变企业创建内容、生成新设计概念以及从现有数据中提取价值的方式。



=== 大型语言模型(LLM)

LLM是针对海量数据预先训练的深度学习模型、除其他任务外、它还可以识别和生成文本。LLM最初是主要侧重于语言的生成性AI的子集、但是随着多模式LLM的不断涌现、这种区别正在逐渐消失。LLM中的底层变压器引入了一种不同于RNN或CNN的新型网络架构。它有一组神经网络、由编码器和解码器组成、可帮助从一系列文本中提取含义并了解单词之间的关系。LLM可以响应自然的人类语言、并使用数据分析来处理问题解答非结构化问题。但是、LLM的可靠性只能与它们所加载的数据一样、因此容易产生因垃圾输入-垃圾输出带来的挑战而产生的幻想。如果向LLM提供虚假信息、则在用户查询时、他们可能会生成不准确的输出、只是为了适应其所构建的叙述。我们基于证据的研究表明、AI工程师依靠各种方法来消除这些幻想、一种方法是通过限制不准确结果的防护措施、另一种方法是通过RAG等技术、利用与环境相关的高质量数据对学习进行微调和转移。



=== 检索增强生成(RAG)

对LLM进行了大量数据方面的培训、但未对您的数据进行培训。RAG通过将您的数据添加到LLM已有权访问的数据来解决此问题。RAG允许客户利用LLM的强大功能、对其数据进行培训、从而检索信息并使用该信息为生成型AI用户提供上下文信息。RAG是一种机器学习技术、是一种架构方法、可帮助减少幻想、提高LLM的效率和可靠性、加速AI应用程序的开发并增强企业搜索体验。



=== Ragas

现有工具和框架可帮助您构建RAG管道、但评估和量化管道性能可能会很困难。这就是Ragas (RAG评估)的作用所在。Ragas是一个框架、可帮助您评估RAG管道。Ragas旨在创建一个开放式标准、为开发人员提供在其RAG应用程序中利用持续学习的工具和技术。有关详细信息，请参见 https://docs.ragas.io/en/stable/getstarted/index.html["开始使用Ragas"^]



== LAMA 3.

Meta的Llama 3是一种仅用于解码器的转换器模型、是一种可公开访问的预训练大型语言模型(LLM)。Llama 3接受过超过15万亿令牌数据的训练、是自然语言理解(NLU)领域的变革者。它擅长了解上下文以及执行翻译和对话生成等复杂任务。llama 3有两种大小：8B用于高效部署和开发、70B用于大规模AI本机应用程序。客户可以通过Ver按照AI在Google Cloud上部署Llama 3、通过Azure AI Studio在Azure上部署、通过Amazon SagMaker在AWS上部署Llama 3。

在我们的验证中，我们在NVIDIA DGX实例中部署了采用NVIDIA Nemo™微服务的Meta Llama模型，该实例使用NVIDIA A100 GPU进行了加速计算，用于定制和评估生成性AI用例，同时支持内部应用程序中的检索增强生成(RAG)。



== 开源框架

以下有关开源技术的追加信息可能与您的部署相关。



=== LangChain

LangChin是一个开源集成框架、用于开发由大型语言模型(LLM)提供支持的应用程序。客户可以高效地构建RAG应用程序、因为它附带了文档加载器、向存储和各种其他软件包、因此开发人员可以灵活地构建复杂的工作流。他们还可以使用LangSmith检查、监控和评估应用程序、以便通过LangServe不断优化和将任何链部署到REST API中。LangChin对RAG应用程序的最佳实践进行编码、并为构建RAG应用程序所需的各种组件提供标准接口。



=== LlamaIndex

LlamaIndex是一个简单灵活的数据框架、用于将自定义数据源连接到基于大型语言模型(LLM)的应用程序。它允许您通过灵活的数据连接器从API、数据库、PDF等中导出数据。Llama 3和GPT-4等LLMS经过了海量公共数据集的预先培训、开箱即用、具有令人难以置信的自然语言处理功能。但是、如果无法访问您自己的私有数据、则其实用程序会受到限制。LlamaIndex提供了广受欢迎的Python和打字本库、在检索增强生成(RAG)技术领域处于行业领先地位。



== NVIDIA Nemo Microservices

NVIDIA Nemo是一款端到端平台、用于构建和自定义企业级生成型AI模型、这些模型可以部署在任何位置、跨云和数据中心。Nemo提供的微服务可简化大规模生成型AI开发和部署流程、使企业能够将LLM连接到其企业数据源。在撰写本文时、Nemo Microservices可通过NVIDIA的早期访问计划获得。



=== NVIDIA Nemo Infit鉴于 微服务(NIMS)

NVIDIA NIMS是NVIDIA AI Enterprise的一部分、可为开发采用AI的企业级应用程序以及在生产环境中部署AI模型提供一条简化的途径。NIMS是一种容器化的推定微服务、包括行业标准API、特定于域的代码、优化的推定引擎和企业级运行时。



=== NVIDIA Nemo还可以使用

NVIDIA Nemo取回器是NVIDIA Nemo框架中的最新服务、可优化RAG的嵌入和检索部分、以提供更高的准确性和更高效的响应。NVIDIA Nemo取回器是一种信息检索服务、可部署在内部或云中。它为企业提供了一条安全、简化的路径、可将企业级RAG功能集成到其定制生产AI应用程序中。



== NVIDIA Enterprise RAG LLM Operator

NVIDIA Enterprise检修增强代(RAG)大型语言模型(LLM)操作员支持在Kubernetes中运行RAG管道所需的软件组件和服务。它可以让操作员提前访问、该操作员负责管理RAG管道关键组件的生命周期、例如NVIDIA推送微服务和NVIDIA Nemo取送器嵌入微服务。有关详细信息，请参见 https://docs.nvidia.com/ai-enterprise/rag-llm-operator/0.4.1/index.html["NVIDIA Enterprise RAG LLM Operator"^]



== 向量数据库



=== PostgreSQL：pgvector

由于它本机与许多经典ML算法(如XGBoost)相结合、因此使用SQL进行机器学习并不是PostgreSQL的新鲜事物。最近、PostgreSQL发布了面向向量相似性搜索的开源扩展—pgvector、从而能够存储和搜索ML生成的内置、这一功能适用于使用LLM的AI用例和应用程序。

在我们使用NVIDIA Enterprise RAG LLM运算符验证的默认示例管道中、将在Pod中启动pgvector数据库。然后，查询服务器连接到pgvector数据库以存储和检索内包。聊天机器人Web应用程序和查询服务器与微服务和向量数据库进行通信、以响应用户提示。



=== Milvus

作为一个提供API的多功能向量数据库(与MongoDB非常相似)、Milvus因支持多种数据类型和多矢量化等功能而脱颖而出、因此成为数据科学和机器学习的热门选择。它能够存储、索引和管理由深度神经网络(DNN)和机器学习(ML)模型生成的超过10亿个嵌入向量。客户可以使用Nvidia NIM & Nemo微服务和Milvus作为矢量数据库来构建RAG应用程序。成功部署NVIDIA Nemo容器用于嵌入生成后、便可部署Milvus容器来存储这些嵌入。有关向量数据库和NetApp的详细信息，请参阅 https://docs.netapp.com/us-en/netapp-solutions/ai/vector-database-solution-with-netapp.html["参考架构—采用NetApp的Vector Database解决方案"^]。



=== Apache cassandr

Apache cassandr®是一种开放源代码NoSQL、具有高度可扩展性和高可用性的数据库。它附带了向量搜索功能、并支持向量数据类型和向量相似性搜索功能、对于涉及LLM和专用RAG管道的AI应用程序尤其有用。

NetApp Instaclinstr为Apache cassandr®提供完全托管的服务，托管在云端或内部环境中。它使NetApp客户能够通过Instaclinstr控制台或Instaclr配置API使用C#、Node.js、AWS PrivateLink和各种其他选项配置Apache cassandr®集群并连接到集群。

此外、NetApp ONTAP还可以作为在KubeNet上运行的容器化Apache cassandr集群的永久性存储提供程序。NetApp Asta Control可将ONTAP的数据管理优势无缝扩展到数据丰富的Kubbernetes应用程序、例如Apache cassandr。有关详细信息、请参见 https://cloud.netapp.com/hubfs/SB-4134-0321-DataStax-Cassandra-Guide%20(1).pdf["使用NetApp Asta Control和ONTAP存储为DataStax Enterprise提供应用程序感知型数据管理"^]



=== NetApp安装

Instaclinstt通过其SaaS开源技术平台支持数据基础架构、帮助企业大规模交付应用程序。希望将语法理解嵌入其搜索应用程序的生成型AI开发人员有多种选择。InstaclinstServer for Postgre支持pgvector扩展。Instaclinstor for OpenSearch支持向量搜索、以便根据输入查询以及最近邻居函数检索相关文档。Instaclinstt for Redis可以存储向量数据、检索向量和执行向量搜索。有关详细信息、请阅读 https://www.instaclustr.com/platform/["NetApp的InstaclinstTM平台"^]



== NetApp BlueXP

NetApp BlueXP将NetApp的所有存储和数据服务统一到一个工具中、让您可以构建、保护和管理混合多云数据资产。它可以跨内部环境和云环境为存储和数据服务提供统一的体验、并通过AIIOPS的强大功能实现运营精简性、同时还具有当今云主导环境所需的灵活使用参数和集成保护。



== NetApp Cloud Insights

NetApp Cloud Insights 是一款云基础架构监控工具，可让您深入了解整个基础架构。借助 Cloud Insights ，您可以监控，排除故障并优化所有资源，包括公有云和私有数据中心。Cloud Insights可通过数百个收集器在一个位置对异构基础架构和工作负载(包括Kubernetes)的基础架构和应用程序进行全栈可见性。有关详细信息，请参见 https://docs.netapp.com/us-en/cloudinsights/index.html["Cloud Insights 可以为我做什么？"^]



== NetApp StorageGRID

NetApp StorageGRID 是一款软件定义的对象存储套件、支持公共、私有和混合多云环境中的各种用例。StorageGRID 为Amazon S3 API提供本机支持、并提供行业领先的创新技术、例如自动化生命周期管理、以便长期经济高效地存储、保护和保留非结构化数据。



== NetApp Spot

Spot by NetApp可在AWS、Azure或Google Cloud中自动优化云基础架构、以尽可能低的成本提供SLA支持的可用性和性能。Spot使用机器学习和分析算法、使您能够将Spot容量用于生产和任务关键型工作负载。运行基于GPU的实例的客户可以从Spot中受益并降低计算成本。



== NetApp ONTAP

ONTAP 9是NetApp推出的最新一代存储管理软件、可帮助企业打造现代化的基础架构并过渡到云就绪数据中心。借助行业领先的数据管理功能，无论数据位于何处， ONTAP 都可以通过一组工具来管理和保护数据。您还可以将数据自由移动到需要的任何位置：边缘，核心或云。ONTAP 9包含许多功能、可简化数据管理、加快和保护关键数据、并在混合云架构中实现下一代基础架构功能。



=== 简化数据管理

数据管理对于企业IT运营和数据科学家至关重要、这样才能将适当的资源用于AI应用程序和训练AI/ML数据集。以下有关NetApp技术的追加信息 不在此验证范围内、但可能与您的部署相关。

ONTAP 数据管理软件包括以下功能、可简化操作并降低总运营成本：

* 实时数据缩减和扩展的重复数据删除。数据缩减可减少存储块中浪费的空间、重复数据删除可显著提高有效容量。此适用场景数据存储在本地，并分层到云。
* 最低、最高和自适应服务质量(AQoS)。精细的服务质量(QoS)控制有助于在高度共享的环境中保持关键应用程序的性能水平。
* NetApp FabricPool。可将冷数据自动分层到公有 和私有云存储选项、包括Amazon Web Services (AWS)、Azure和NetApp StorageGRID Storage解决方案。有关 FabricPool 的详细信息，请参见 https://www.netapp.com/pdf.html?item=/media/17239-tr4598pdf.pdf["TR-4598：FabricPool 最佳实践"^]。




=== 加速和保护数据

ONTAP 可提供卓越的性能和数据保护、并通过以下方式扩展这些功能：

* 性能和更低的延迟。ONTAP 可提供尽可能高的吞吐量和尽可能低的延迟。
* 数据保护ONTAP 可提供内置数据保护功能、并在所有平台之间进行通用管理。
* NetApp卷加密(NVE)。ONTAP 提供原生 卷级加密、并支持板载和外部密钥管理。
* 多租户和多因素身份验证。ONTAP 支持以最高的安全性级别共享基础架构资源。




=== Future-Proof 基础架构

ONTAP 可通过以下功能满足不断变化的苛刻业务需求：

* 无缝扩展和无中断运行。ONTAP 支持无中断地向现有控制器和横向扩展集群添加容量。客户可以升级到 NVMe 和 32 Gb FC 等最新技术，而无需进行成本高昂的数据迁移或中断。
* 云连接。ONTAP是云互联程度最高的存储管理软件、可在所有公有云中选择软件定义的存储和云原生实例。
* 与新兴应用程序集成。ONTAP 通过使用支持现有企业应用程序的相同基础架构、为下一代平台和应用程序(例如自动驾驶汽车、智能城市和行业4.0)提供企业级数据服务。




== 适用于 NetApp ONTAP 的 Amazon FSX

Amazon FSx for NetApp ONTAP是第一方完全托管的AWS服务、可提供基于NetApp流行的ONTAP文件系统构建的高度可靠、可扩展、高性能和功能丰富的文件存储。FSX for ONTAP 将NetApp文件系统的常见特性、性能、功能和API操作与完全托管的AWS服务的灵活性、可扩展性和精简性相结合。



== Azure NetApp Files

Azure NetApp Files是Azure原生的第一方企业级高性能文件存储服务。它支持SMB、NFS和双协议卷、并可用于以下使用情形：

* 文件共享。
* 主目录。
* 数据库。
* 高性能计算。
* 生成性AI。




== Google Cloud NetApp卷

Google Cloud NetApp Volumes是一种完全托管的基于云的数据存储服务、可提供高级数据管理功能和高度可扩展的性能。NetApp托管的数据可用于Google Verpe AI平台的RAG (检索增强型生成)操作、该平台采用预览的工具包参考架构。



== NetApp Astra Trident

Asta Trident支持在公有云或内部环境中的所有常见NetApp存储平台上使用和管理存储资源、包括ONTAP (AFF、FAS、Select、云、 Amazon FSx for NetApp ONTAP)、Element软件(NetApp HCI、SolidFire)、Azure NetApp Files服务以及Google Cloud上的Cloud Volumes Service。Asta Trident是一款符合容器存储接口(CSI)的动态存储编排程序、可与Kubbernetes本机集成。



== Kubernetes

Kubernetes 是一款开源分布式容器编排平台，最初由 Google 设计，现在由 Cloud 原生计算基金会（ CNCF ）维护。Kubnetes支持容器化应用程序的部署、管理和扩展功能自动化、是企业环境中的主要容器流程编排平台。
