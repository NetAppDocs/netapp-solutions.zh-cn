---
sidebar: sidebar 
permalink: ai/osrunai_run_ai_platform_for_ai_workload_orchestration.html 
keywords:  
summary:  
---
= 运行：适用于 AI 工作负载编排的 AI 平台
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
* 加快创新速度。通过将运行： AI 资源池化，排队和优先级划分机制与 NetApp 存储系统结合使用，研究人员可以消除基础架构管理方面的麻烦，并可以专注于数据科学。运行： AI 和 NetApp 客户可以根据需要运行任意数量的工作负载，而不会出现计算或数据管道瓶颈，从而提高工作效率。
* 提高团队工作效率。Run ： AI 公平算法可确保所有用户和团队都能获得他们应得的资源份额。可以预设优先级项目的策略，该平台支持将资源从一个用户团队动态分配到另一个用户团队，从而帮助用户及时访问所需的 GPU 资源。
* 提高 GPU 利用率。通过 Run ： AI 计划程序，用户可以轻松地使用部分 GPU ，整数 GPU 和多个 GPU 节点在 Kubernetes 上进行分布式培训。这样， AI 工作负载就可以根据需求运行，而不是根据容量运行。数据科学团队可以在同一基础架构上运行更多 AI 实验。

