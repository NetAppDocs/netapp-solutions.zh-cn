---
sidebar: sidebar 
permalink: ai/aipod_nv_architecture.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX 
summary: 采用NVIDIA DGX系统的NetApp AI Pod—架构 
---
= 采用NVIDIA DGX系统的NetApp AI Pod—架构
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:aipod_nv_sw_components.html["上一页：ONTAP AI -软件组件。"]

此参考架构利用单独的网络结构实现计算集群互连和存储访问、并可在计算节点之间选择NDR200和HDR200 InfiniBand (IB)连接。DGX H100系统预安装了ConnectX-7卡、用于进行DPRIB连接、而DGX A100系统可分别使用ConnectX-6或ConnectX-7卡进行HDR或DPR.



== 采用DGX H100系统的ONTAP AI

下图显示了将DGX H100系统与ONTAP AI结合使用时的整体解决方案拓扑。

image:oai_H100_topo.png["错误：缺少图形映像"]

在此配置中、计算集群网络使用一对QM9700 NDE IB交换机、这些交换机连接在一起以实现高可用性。每个DGX H100系统通过八个NDR200连接连接到交换机、其中、偶数端口连接到一个交换机、奇数端口连接到另一个交换机。

对于存储系统访问、带内管理和客户端访问、使用一对SN4600以太网交换机。这些交换机通过交换机间链路进行连接、并配置有多个VLAN以隔离各种流量类型。对于大型部署、可以根据需要为主干添加额外的交换机对和额外的叶片、从而将以太网网络扩展为分支-主干配置。每个DGX A100系统都配置有两个双端口ConnectX-6卡、用于以太网和存储流量、对于此解决方案、所有四个端口均以200 Gbps的速度连接到SN4600以太网交换机。将每个卡中的一个端口配置到LACP MAG绑定中、并将一个端口连接到每个交换机、同时在此绑定上托管用于带内管理、客户端访问和用户级存储访问的VLAN。每个卡上的另一个端口在单独的专用RoCE存储VLAN中单独使用、用于连接到AFF A800存储系统、这些端口支持使用NFS v3、具有pNFS的NFSv4.x以及基于RDMA的NFS进行高性能存储访问。

除了计算互连和高速以太网网络之外、所有物理设备还会连接到一个或多个SN2201以太网交换机、以实现带外管理。  有关DGX A100系统连接的更多详细信息、请参见 link:https://nvdam.widen.net/s/nfnjflmzlj/nvidia-dgx-basepod-reference-architecture["NVIDIA BasePD文档"]。



== 采用DGX A100系统的ONTAP AI

下图显示了使用DGX A100系统和采用ONTAP AI的HDR计算网络结构时的整体解决方案拓扑。

image:oai_A100_topo.png["错误：缺少图形映像"]

在此配置中、计算集群网络使用一对QM4700 HDR IB交换机、这些交换机连接在一起以实现高可用性。每个DGX A100系统使用四个速率为200 Gbps的单端口ConnectX-6卡连接到交换机、其中一个交换机连接为偶数端口、另一个交换机连接为奇数端口。

对于存储系统访问、带内管理和客户端访问、使用一对SN4600以太网交换机。这些交换机通过交换机间链路进行连接、并配置有多个VLAN以隔离各种流量类型。对于大型部署、可以根据需要为主干添加额外的交换机对和额外的叶片、从而将以太网网络扩展为分支-主干配置。每个DGX A100系统都配置有两个双端口ConnectX-6卡、用于以太网和存储流量、对于此解决方案、所有四个端口均以200 Gbps的速度连接到SN4600以太网交换机。将每个卡中的一个端口配置到LACP MAG绑定中、并将一个端口连接到每个交换机、同时在此绑定上托管用于带内管理、客户端访问和用户级存储访问的VLAN。每个卡上的另一个端口在单独的专用RoCE存储VLAN中单独使用、用于连接到AFF A800存储系统、这些端口支持使用NFS v3、具有pNFS的NFSv4.x以及基于RDMA的NFS进行高性能存储访问。

除了计算互连和高速以太网网络之外、所有物理设备还会连接到一个或多个SN2201以太网交换机、以实现带外管理。  有关DGX A100系统连接的更多详细信息、请参见 link:https://nvdam.widen.net/s/nfnjflmzlj/nvidia-dgx-basepod-reference-architecture["NVIDIA BasePD文档"]。



== 管理平台服务器

此参考架构还包括五个基于CPU的服务器、供管理平台使用。其中两个系统用作Base Command Manager的主节点、用于集群部署和管理。另外三个系统用于提供额外的集群服务、例如、在使用Slurm进行作业计划的部署中、可使用Kubornetes主节点或登录节点。利用Kubnetes的部署可以利用NetApp Asta三端CSI驱动程序为AFF A800存储系统上的管理和AI工作负载提供自动化配置和数据服务以及永久性存储。

每个服务器都会以物理方式连接到IB交换机和以太网交换机、以实现集群部署和管理、并通过管理SVM配置NFS挂载到存储系统、以便如前所述存储集群管理项目。

link:aipod_nv_storage.html["下一步：采用NVIDIA DGX系统的NetApp AI Pod—存储系统设计和大小指导。"]
