---
sidebar: sidebar 
permalink: ai/osrunai_run_ai_dashboards_and_views.html 
keywords:  
summary:  
---
= 运行： AI 信息板和视图
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
在 Kubernetes 集群上安装 Run ： AI 并正确配置容器后，您将看到以下信息板和视图 https://app.run.ai/["https://app.run.ai"^] 在浏览器中，如下图所示。

image:osrunai_image3.png["错误：缺少图形映像"]

集群中共有 16 个 GPU ，由两个 DGX-1 节点提供。您可以查看节点数，可用 GPU 总数，分配给工作负载的已分配 GPU ，正在运行的作业总数，待定作业以及闲置已分配 GPU 。右侧的条形图显示每个项目的 GPU ，其中总结了不同团队如何使用集群资源。中间是当前正在运行的作业列表，其中包含作业详细信息，包括作业名称，项目，用户，作业类型， 每个作业正在运行的节点，为此作业分配的 GPU 数量，作业的当前运行时间，作业进度百分比以及该作业的 GPU 利用率。请注意，集群利用率不足（ GPU 利用率为 23% ），因为一个团队只提交了三个正在运行的作业（`team-A` ）。

在下一节中，我们将介绍如何在 " 项目 " 选项卡中创建多个团队，并为每个团队分配 GPU ，以便在每个集群有大量用户时最大限度地提高集群利用率并管理资源。这些测试场景模拟了在训练，推理和交互式工作负载之间共享内存和 GPU 资源的企业环境。

link:osrunai_creating_projects_for_data_science_teams_and_allocating_gpus.html["接下来：为数据科学团队创建项目并分配 GPU"]
