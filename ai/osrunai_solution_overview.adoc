---
sidebar: sidebar 
permalink: ai/osrunai_solution_overview.html 
keywords:  
summary:  
---
= 解决方案概述
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/




== NetApp ONTAP AI 和 AI 控制平台

由 NetApp 和 NVIDIA 开发并验证的 NetApp ONTAP AI 架构由 NVIDIA DGX 系统和 NetApp 云连接存储系统提供支持。此参考架构为 IT 组织提供了以下优势：

* 消除设计复杂性
* 支持独立扩展计算和存储
* 支持客户从小规模入手，无缝扩展
* 为各种性能和成本点提供了一系列存储选项


NetApp ONTAP AI 将 DGX 系统和 NetApp AFF A800 存储系统与一流的网络紧密集成在一起。NetApp ONTAP AI 和 DGX 系统消除了设计复杂性和猜测性工作，从而简化了 AI 部署。客户可以从小规模入手，无中断地扩展系统，同时智能地管理从边缘到核心再到云再到云的数据。

NetApp AI 控制平台是一个全堆栈 AI ， ML 和深度学习（ DL ）数据和实验管理解决方案，适用于数据科学家和数据工程师。随着企业越来越多地使用 AI ，他们面临着许多挑战，包括工作负载可扩展性和数据可用性。NetApp AI 控制平台可通过多种功能来应对这些挑战，例如像 Git repo一样 快速克隆数据命名空间，以及定义和实施 AI 培训工作流，这些工作流可以近乎即时地创建数据和模型基线，以实现可追溯性和版本控制。借助 NetApp AI 控制平台，您可以在站点和区域之间无缝复制数据，并快速配置 Jupyter 笔记本工作空间，以便访问海量数据集。



== 运行：适用于 AI 工作负载编排的 AI 平台

运行： AI 为 AI 基础架构构建了全球首款业务流程和虚拟化平台。通过将工作负载从底层硬件中抽象出来， Run ： AI 可创建一个可动态配置的 GPU 资源共享池，从而高效地编排 AI 工作负载并优化 GPU 的使用。数据科学家可以无缝地使用大量 GPU 功能来改进和加快研究速度，同时 IT 团队可以对资源配置，队列和利用率保持集中的跨站点控制和实时可见性。Run ： AI 平台基于 Kubernetes 构建，可与现有 IT 和数据科学工作流轻松集成。

Run ： AI 平台具有以下优势：

* * 加快创新速度。 * 通过将 Run ： AI 资源池，队列和优先级划分机制与 NetApp 存储系统结合使用，研究人员可以从基础架构管理的麻烦中消除，并可以专注于数据科学。运行： AI 和 NetApp 客户可以根据需要运行任意数量的工作负载，而不会出现计算或数据管道瓶颈，从而提高工作效率。
* * 提高团队工作效率。 * 运行： AI 公平算法可确保所有用户和团队都能获得公平的资源份额。可以预设优先级项目的策略，该平台支持将资源从一个用户或团队动态分配给另一个用户或团队，从而帮助用户及时访问所需的 GPU 资源。
* * 提高了 GPU 利用率。 * 运行： AI 计划程序使用户能够轻松地使用百分比 GPU ，整数 GPU 和多个 GPU 节点在 Kubernetes 上进行分布式培训。这样， AI 工作负载就可以根据您的需求运行，而不是根据容量运行。数据科学团队可以在同一基础架构上运行更多 AI 实验。

