---
sidebar: sidebar 
permalink: ai/osrunai_submitting_jobs_in_run_ai_cli.html 
keywords:  
summary:  
---
= 在 Run ： AI 命令行界面中提交作业
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
本节详细介绍了可用于运行任何 Kubernetes 作业的基本 Run ： AI 命令。它会根据工作负载类型分为三部分。AI/ML/DL 工作负载可分为两种通用类型：

* * 无人参与的培训课程 * 。对于这些类型的工作负载，数据科学家会准备一个自运行的工作负载并将其发送给执行。执行期间，客户可以检查结果。此类工作负载通常用于生产或模型开发阶段，无需人工干预。
* * 交互式构建会话 * 。对于这些类型的工作负载，数据科学家将与 Bash ， Jupyter Notebook ，远程 PyCharm 或类似的 IDE 打开交互式会话，并直接访问 GPU 资源。我们还提供了第三种使用连接的端口运行交互式工作负载的方案，以便向容器用户显示内部端口。




== 无人参与的培训工作负载

设置项目并分配 GPU 后，您可以在命令行中使用以下命令运行任何 Kubernetes 工作负载：

....
$ runai project set team-a runai submit hyper1 -i gcr.io/run-ai-demo/quickstart -g 1
....
此命令将为团队 A 启动无人参与的培训作业，并分配一个 GPU 。此作业基于示例 Docker 映像 `gcr.io/run-ai-demo/Quickstart` 。我们将作业命名为 `hyper1` 。然后，您可以运行以下命令来监控作业的进度：

....
$ runai list
....
下图显示了 `runai list` 命令的结果。您可能看到的典型状态包括：

* `容器创建` 。正在从云存储库下载 Docker 容器。
* `待定` 。作业正在等待计划。
* `运行` 。作业正在运行。


image::osrunai_image5.png[osrunai image5.]

要获取作业的其他状态，请运行以下命令：

....
$ runai get hyper1
....
要查看作业日志，请运行 `runai logs <job-name>` 命令：

....
$ runai logs hyper1
....
在此示例中，您应看到正在运行的 DL 会话的日志，包括当前训练时间， ETA ，损失函数值，准确性以及每个步骤所用时间。

您可以在运行： AI UI 上查看集群状态，网址为 https://app.run.ai/["https://app.run.ai/"^]。在 Dashboards > Overview 下，您可以监控 GPU 利用率。

要停止此工作负载，请运行以下命令：

....
$ runai delte hyper1
....
此命令将停止训练工作负载。您可以再次运行 `runai list` 来验证此操作。有关详细信息，请参见 https://docs.run.ai/Researcher/Walkthroughs/Walkthrough-Launch-Unattended-Training-Workloads-/["启动无人参与的培训工作负载"^]。



== 交互式构建工作负载

设置项目并分配 GPU 后，您可以在命令行中使用以下命令运行交互式构建工作负载：

....
$ runai submit build1 -i python -g 1 --interactive --command sleep --args infinity
....
此作业基于示例 Docker 映像 python 。我们将作业 BUILD1 命名为。


NOTE: ` - 交互式` 标志表示作业没有开始或结束研究人员有责任完成此项工作。管理员可以为交互式作业定义一个时间限制，在该时间限制之后，系统会终止这些作业。

` -g 1` 标志可为此作业分配一个 GPU 。提供的命令和参数为 ` —命令休眠— args infinity` 。您必须提供命令，否则容器将立即启动并退出。

以下命令的工作方式与中所述的命令类似 <<无人参与的培训工作负载>>：

* `runai list` ：显示名称，状态，期限，节点，映像， 用于作业的项目，用户和 GPU 。
* `runai get build1` ：显示作业 build1 的其他状态。
* `runai delete build1` ：停止交互式工作负载 BUILD1.To get a bash shell to the container ， the following command ：


....
$ runai bash build1
....
这样就可以直接将 shell 连接到计算机。然后，数据科学家可以在容器中开发或微调其模型。

您可以在运行： AI UI 上查看集群状态，网址为 https://app.run.ai["https://app.run.ai"^]。有关详细信息，请参见 https://docs.run.ai/Researcher/Walkthroughs/Walkthrough-Start-and-Use-Interactive-Build-Workloads-/["启动和使用交互式构建工作负载"^]。



== 使用已连接端口的交互式工作负载

作为交互式构建工作负载的扩展，在使用 Run ： AI CLI 启动容器时，您可以向容器用户显示内部端口。这对于云环境，使用 Jupyter 笔记本电脑或连接到其他微服务非常有用。 https://kubernetes.io/docs/concepts/services-networking/ingress/["传入"^] 允许从 Kubernetes 集群外部访问 Kubernetes 服务。您可以通过创建一组规则来配置访问，这些规则定义哪些入站连接访问哪些服务。

为了更好地管理对集群中服务的外部访问，我们建议集群管理员安装 https://kubernetes.io/docs/concepts/services-networking/ingress/["传入"^] 并配置负载平衡器。

要使用传入作为服务类型，请在提交工作负载时运行以下命令以设置方法类型和端口：

....
$ runai submit test-ingress -i jupyter/base-notebook -g 1 \
  --interactive --service-type=ingress --port 8888 \
  --args="--NotebookApp.base_url=test-ingress" --command=start-notebook.sh
....
容器成功启动后、执行 `runai list` 以查看 `SERVICE URL(S)` 访问Jupyter笔记本。此 URL 由入口端点，作业名称和端口组成。

有关详细信息，请参见 https://docs.run.ai/Researcher/Walkthroughs/Walkthrough-Launch-an-Interactive-Build-Workload-with-Connected-Ports/["使用连接的端口启动交互式构建工作负载"^]。
